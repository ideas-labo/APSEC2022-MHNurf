,Repository,Number,State,Title,Body,Labels,Comments,Codes,Commands,class,related
0,incubator-mxnet,9216,closed,Loss of Precision in BatchNorm and output_var may be wrong,"## Description
1. BatchNorm loses a little precision
2. the output_var in BatchNorm may be wrong

## Environment Info
OS: Arch Linux 4.14.8
MXNet: 1.0.0 and 1.0.1 (the latest version, CPU version)

## Build Config
make -j8 USE_OPENCV=1 USE_BLAS=openblas
***

Hi, there.

I converted [ResNet Model on Caffe](https://github.com/KaimingHe/deep-residual-networks) to [ResNet model on MXNet](https://github.com/wkcn/resnet-v1-mx).

And I found that the output results between Caffe and MXNet are different.

The reason is that the computations of Caffe and MXNet are different.

For the BatchNorm in Caffe, the output is .

For the BatchNorm in MXNet, the output is , and .

I think the method in MXNet will **lose a little precision** but bring the **higher performance** (Reduce the times of division).

At the same time, I found that the  in BatchNorm may be wrong. 

The  is **invstd**, namely the multiplicative inverse of the standard deviation. I think it should be the variance.

## Steps to reproduce

Here is [my testing code](https://github.com/wkcn/test_mxnet_bn).

I compare three outputs:

- numpy (compute manally)
- caffe
- mxnet



The first column is the , and the second column is the .

# What I have tried to solve it

I change the BatchNorm implement in MXNet, and the output is below:



The modified BatchNorm(cpu) code is [here](https://github.com/wkcn/incubator-mxnet/commit/5ecd4882bc043cf059e962f7ce488270bafa07c7).
",Bug,"[""What's the result if we use this line instead: https://github.com/wkcn/test_mxnet_bn/blob/master/compute.py#L15. I think it may be the same as the MXNet version. Also, the rel_error is relatively small and should not be a problem."", '@sxjscience If using the line 15th, the result will be the same as that of MXNet.\r\n\r\nThe rel_error is relatively small.\r\n\r\nHowever, there may be **a bug**. \r\n\r\n\r\nThe [documents](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html?highlight=batchnorm#mxnet.symbol.BatchNorm) said that\r\noutput_mean_var (boolean, optional, default=0) – Output All,normal mean and var\r\n\r\nhttps://github.com/apache/incubator-mxnet/blob/master/src/operator/nn/batch_norm.cc#L147\r\nThe output_var is **invstd** now, I think it should be **the variance**.', ""Looks like a bug, I'm not sure. @piiswrong @cjolivier01 "", ""Caffe and MXNet will get the same BN output as I've tested before.\r\nPlease be caution that CUDNN cannot handle BN when eps <= 1e-5. In this situation, you can set cudnn_off=true in BN of MXNet.\r\n@wkcn ,Models of #9215 get a very lower error rate."", ""@chinakook Thank you!\r\n\r\nI wrote [a new code](https://github.com/wkcn/test_mxnet_bn/tree/ndarray) to test.\r\nAnd I found that using CUDNN and not using CUDNN on Caffe get the same BN output.\r\nBut there is a little difference between the CPU result and the GPU result on Caffe.\r\n```\r\nmax absolute error, max relative error, mean error\r\n8.0, 3.4666334e-07, 0.024640804\r\n```\r\n\r\nThe comparison between MXNet and Caffe is showed below.\r\n\r\nUsing the GPU result of Caffe.\r\n```\r\n('context: ', cpu(0))\r\n('cudnn_off: ', True)\r\nndarray: y = gamma * [(x - mean) / sqrt(var + eps)] + beta\r\n\r\n                max absolute error, max relative error, mean error\r\n('caffe and ndarray', 8.0, 3.4666334e-07, 0.024640804)\r\n('caffe and mx', 16.0, 3.4666334e-07, 0.057109512)\r\n('ndarray and mx', 16.0, 2.3652711e-07, 0.038025968)\r\n```\r\n\r\n```\r\n('context: ', gpu(0))\r\n('cudnn_off: ', True)\r\nndarray: y = gamma * [(x - mean) / sqrt(var + eps)] + beta\r\n\r\n                max absolute error, max relative error, mean error\r\n('caffe and ndarray', 8.0, 3.4666334e-07, 0.024640804)\r\n('caffe and mx', 16.0, 2.3644267e-07, 0.052587245)\r\n('ndarray and mx', 16.0, 2.4033051e-07, 0.054628547)\r\n```\r\n\r\n```\r\n('context: ', gpu(0))\r\n('cudnn_off: ', False)\r\nndarray: y = gamma * [(x - mean) / sqrt(var + eps)] + beta\r\n\r\n                max absolute error, max relative error, mean error\r\n('caffe and ndarray', 8.0, 3.4666334e-07, 0.024640804)\r\n('caffe and mx', 16.0, 2.3644267e-07, 0.052587245)\r\n('ndarray and mx', 16.0, 2.4033051e-07, 0.054628547)\r\n```"", '@wkcn Can you confirm that the output is invstd instead of var?', '@wkcn These errors are too small and will cause no problem. However, there is certainly a bug if the output is invstd instead of var.', ""@sxjscience \r\nThank you!\r\n\r\nI'm sure that the output_var is invstd instead of variance.\r\nhttps://github.com/apache/incubator-mxnet/blob/master/src/operator/nn/batch_norm.cc#L147\r\nhttps://github.com/apache/incubator-mxnet/blob/master/src/operator/nn/batch_norm.cc#L161"", 'the documentation should be fixed', 'I find it will be improper to output the invstd as the value will be undefined when batch_size=1. We should consider to change it back to output the variance.', 'Just FYI, CUDNN stores invstd for moving_variance rather than actual variance, if I remember correctly.\r\nThis can be seen in the unit test not checking for those being the same when CUDNN is enabled: https://github.com/apache/incubator-mxnet/blob/f9fd88bf178c0005a81ebf909750d5786bb1ec69/tests/cpp/operator/batchnorm_test.cc#L409\r\n', '@cjolivier01 I see, we need to test the correctness of the mean and ""var"" as we can fetch these two values by turning on `output_mean_var`. https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.BatchNorm', 'I believe that it was stored as invstd in order to avoid calculating it back and forth between forward and backward pass, but I am open to it being adjusted as long as everything in tests/cpp/batchnorm_test.cc still passes.', '@cjolivier01 In that case, it should be okay to keep the invstd format. We need to test the case when `output_mean_var` is turned on.']","['\r\ncaffe and numpy 0.0 0.0\r\ncaffe and mx 16.0 2.36527e-07\r\nnumpy and mx 16.0 2.36527e-07\r\n', '\r\ncaffe and numpy 0.0 0.0\r\ncaffe and mx 0.0 0.0\r\nnumpy and mx 0.0 0.0\r\n']","['(x - mean(x)) / sqrt(var(x) + eps)', '(x - mean(x)) * factor', 'factor = 1.0 / sqrt(var(x) + eps)', 'output_var', 'output_var', 'maxmimum absolute error', 'maxmimum relative error']",1,1
1,incubator-mxnet,10881,closed,mx.sym.dot() performance on CPU,"We are using mx.sym.dot() operator in Keras heavily. We observe CPU performance is suspiciously slower. On profiling a RNN LSTM example, the observation is as shown below.

dot() operator  is contributing to 90% of computation time. Is there any performance implication of mx.sym.dot() operator on CPU? 

We are using mxnet-mkl-dnn build, is the operator using gemm operations under the hood?
 
![image](https://user-images.githubusercontent.com/3403674/39853665-655d9708-53d8-11e8-8f34-58de7cbafd0e.png)

@anirudh2290 @zheng-da - Any suggestions / comments?",Backend Operator Performance,"['I see that we are still using mshadow dot here: https://github.com/apache/incubator-mxnet/blob/master/src/operator/tensor/dot-inl.h#L119 . @DickJC123 @zheng-da changed many operators to use linalg_gemm instead of mshadow::expr::dot. Can you guys provide more insight on if there was a performance gain from this change on CPU.', 'Adding @piiswrong for comment.', ""@anirudh2290 Does `mshadow::expr::dot` call GEMM as well?\r\nyes, MKL GEMM will be much faster than other implementations.\r\nThe pre-built version is not linked with MKL library. We're working on making a static link to MKL for pre-built binary.  "", 'Yes, AFAIK mshadow::expr::dot  uses gemm. `dot_engine-inl.h` has standalone implementations and also supports calling other blas implementations: https://github.com/dmlc/mshadow/blob/master/mshadow/dot_engine-inl.h#L123 and https://github.com/dmlc/mshadow/blob/master/mshadow/dot_engine-inl.h#L280', ""Thanks. So if we build from source by USE_BLASS=MKL, it will be faster. \r\n@sandeep-krishnamurthy could you take a try?\r\nFYI, you can set MKL_VERBOSE=1 so there're detailed information of MKL GEMM in the runtime.\r\nWe can do further analysis and optimizaiton for the different size of GEMM."", ""@pengzhao-intel @anirudh2290 - Thanks for your comments.\r\nNext step, I will try to build from source with USE_BLAS set to MKL and report back if there are performance gain.\r\n\r\n@anirudh2290 - To summarize your comment - are you saying mx.sym.dot() does not use efficient MKL GEMM implementation?\r\n\r\n@pengzhao-intel - If I do pip install mxnet-mkl are you saying we don't get mkl linked? If I use mxnet-mkl on a AWS C5 instance with MKL-DNN, will it use MKL?"", 'I‘m afraid mxnet-mkl package is built with USE_BLAS=openblas. You can build from source with USE_BLAS=mkl if you have mkl library installed.\r\nAlso, do you know how much of this computation time is consumed by lstm layer or other non-rnn fully connected layers? We are trying to build fused lstm operator for mxnet on cpu. Hope that will help you a lot.', 'We\'re updating the labels to better indicate MXNet Backend issues.\r\n@sandeep-krishnamurthy can you please update the label from ""C++"" to ""Backend""? Thanks!', '@pengzhao-intel is this something you guys can help with?', '@lupesko Sure', ""Regarding dot, it's a kind of library operation, GEMM. There're no much can be optimized from the framework level. Just change to Intel MKL will achieve better performance.""]",[],[],1,0
2,incubator-mxnet,10368,closed,asscalar is very slow,"The train part cost 0.01 second, but the asscalar operation cost a few seconds sometimes more than 10. I install the newest version of mxnet by pip, and this was happened with cpu and gpu context both.
Does anyone have any idea for fixing this? Thank you very much.
`",,"['How did you time it? `asscalar` is a blocking function call, while the other lines are async. It would not be accurate to simply time it line by line in Python. You will need to add `mx.nd.waitall()` before the last line to time the training part reasonably.', ""Thank you for the answer.\r\nAnd I have another problem, could you please help me fix it.\r\nWhen I use mxnet with gpu context, the first iteration is running well, but it raising a OOM error by cuda.  Dose it mean it didn't release the gpu memory after the first iteration? Thank you.\r\n```\r\nwhat():  [20:36:33] src/engine/./threaded_engine.h:359: [20:36:33] src/storage/./pooled_storage_manager.h:107: cudaMalloc failed: out of memory\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /root/miniconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2a9e78) [0x7f9f0fea2e78]\r\n[bt] (1) /root/miniconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2aa288) [0x7f9f0fea3288]\r\n[bt] (2) /root/miniconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x29056cf) [0x7f9f124fe6cf]\r\n[bt] (3) /root/miniconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x29089a8) [0x7f9f125019a8]\r\n[bt] (4) /root/miniconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x6c814f) [0x7f9f102c114f]\r\n[bt] (5) /root/miniconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x24b5568) [0x7f9f120ae568]\r\n[bt] (6) /root/miniconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x24b6313) [0x7f9f120af313]\r\n[bt] (7) /root/miniconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x24b6946) [0x7f9f120af946]\r\n[bt] (8) /root/miniconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x24379b3) [0x7f9f120309b3]\r\n[bt] (9) /root/miniconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x243e2ed) [0x7f9f120372ed]\r\n\r\nA fatal error occurred in asynchronous engine operation. If you do not know what caused this error, you can try set environment variable MXNET_ENGINE_TYPE to NaiveEngine and run with debugger (i.e. gdb). This will force all operations to be synchronous and backtrace will give you the series of calls that lead to this error. Remember to set MXNET_ENGINE_TYPE back to empty after debugging.\r\n\r\nStack trace returned 9 entries:\r\n[bt] (0) /root/miniconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2a9e78) [0x7f9f0fea2e78]\r\n[bt] (1) /root/miniconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2aa288) [0x7f9f0fea3288]\r\n[bt] (2) /root/miniconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x243e594) [0x7f9f12037594]\r\n[bt] (3) /root/miniconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2442bdb) [0x7f9f1203bbdb]\r\n[bt] (4) /root/miniconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2442db6) [0x7f9f1203bdb6]\r\n[bt] (5) /root/miniconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x243f68b) [0x7f9f1203868b]\r\n```"", 'This timing does not reflect the correct time spent on training and `asscalar` respectively. As said before, all the lines before the second `print` are async operations. You need to sync before `asscalar` is called.', ""For OOM problem, seems it's caused by always pushing operations to engine for every mini-batch in an epoch. You need to sync before another mini-batch starts. Otherwise, new memory are alway allocated when a new mini-batch starts. You can try defining `train_loss` as a scalar, and replace `train_loss += nd.mean(loss_)` with `train_loss += nd.mean(loss_).asscalar()`."", ""@reminisce Thanks for the explanation about `asscalar`.\r\nI'm sorry that I didn't make it clear about OOM. When I said iteration, it means the epoch. That is, the OOM error is raised during the second epoch, in half the task is completed.\r\n```\r\npython train_softmax.py\r\n100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:05<00:00, 59.88it/s]\r\nEpoch 0. Train loss: 4.608121, Valid loss 4.608134\r\n42%|████████████████████████████████████████████████████▌                                                                       | 1088/2565 [00:21<00:29, 50.49it/s]terminate called after throwing an instance of 'dmlc::Error'\r\n  what():  [19:33:44] src/engine/./threaded_engine.h:359: [19:33:44] src/storage/./pooled_storage_manager.h:107: cudaMalloc failed: out of memory\r\n\r\nStack trace returned 10 entries:\r\n...\r\n\r\n```"", 'The OOM was fixed by changing train_loss with `train_loss += nd.mean(loss_).asscalar()` .\r\nAppreciations @reminisce \r\n']","[' python\r\n    for epoch in range(num_epochs):\r\n        train_loss = nd.array([0.0], ctx=ctx)\r\n        for data, label in tqdm.tqdm(train_data):\r\n            label = label.as_in_context(ctx)\r\n            data = data.as_in_context(ctx)\r\n            with autograd.record():\r\n                output = net(data)\r\n                loss_ = loss(output, label)\r\n            loss_.backward()\r\n            trainer.step(batch_size, ignore_stale_grad=True)\r\n            train_loss += nd.mean(loss_)\r\n        train_loss = train_loss.asscalar()\r\n']",[],1,0
3,incubator-mxnet,3591,closed,In R prediction is running only on CPU very sow,"I have quite a deep net trained on 4 gpus which all works fine.

But when I try and run predict it is very very slow. only 1-cpu is doing anything (out of 16) and the GPUs are doing nothing. Looks like the model is loaded in gpu memory and actually I think it was never unloaded after training. Not sure if that should happen automatically or not.

How do I force the predict to run on GPU?
",,"['`predict(model, X, mx.gpu())`\n', 'too easy. Perfect, thanks.\n']",[],[],1,0
4,incubator-mxnet,13449,closed,significant performance regression in SpMV,"It seems https://github.com/apache/incubator-mxnet/pull/12380 causes significant performance regression in SpMV. It causes about 3 times slow down on p3.16x. The main reason is that the PR causes a small number of omp threads to perform computation.

Here is the minimal code for reproducing the bug. It seems the problem occurs only when a model is initialized with multiple GPUs.

use the code below to run the code.


The csr file can be downloaded from


",Performance,"['@zheng-da Thank you for reporting the regression in sparse matrix vector multiplication. \r\n\r\n', '@mxnet-label-bot add [Performance]', 'Looking at this. tried out your example, notice more than 3x speed drop with and without the change. ', 'Found the root cause of the issue: After the PR: #12380 , omp_thread_max_ is mutated in set_reserve_cores. This means for each gpu worker the omp_thread_max_ will keep dropping. For 8 GPU workers, it drops till it it is 1. After this, the dot operator execution internally calls `GetRecommendedOMPThreadCount` which `return omp_thread_max_` which is 1. Thus the dot operator executes on a single thread. For now, reverting the PR to the old behavior is a good option. We should also try to understand more on cause of the segfault which was the reason for the PR #12380 and come up with a different fix.']","['\r\npython3 sse_batch.py --graph-file ../../data/5_5_csr.nd --gpu 8\r\n', '\r\naws s3 cp s3://haibin-dgl/5_5_csr.nd .\r\n', 'python\r\n""""""\r\nLearning Steady-States of Iterative Algorithms over Graphs\r\nPaper: http://proceedings.mlr.press/v80/dai18a.html\r\n\r\n""""""\r\nimport argparse\r\nimport random\r\nimport numpy as np\r\nimport time\r\nimport math\r\nimport mxnet as mx\r\nfrom mxnet import gluon\r\n\r\ndef gcn_msg(edges):\r\n    # TODO should we use concat?\r\n    return {\'m\': mx.nd.concat(edges.src[\'in\'], edges.src[\'h\'], dim=1)}\r\n\r\ndef gcn_reduce(nodes):\r\n    return {\'accum\': mx.nd.sum(nodes.mailbox[\'m\'], 1) / nodes.mailbox[\'m\'].shape[1]}\r\n\r\nclass NodeUpdate(gluon.Block):\r\n    def __init__(self, out_feats, activation=None, alpha=0.1, **kwargs):\r\n        super(NodeUpdate, self).__init__(**kwargs)\r\n        self.linear1 = gluon.nn.Dense(out_feats, activation=activation)\r\n        # TODO what is the dimension here?\r\n        self.linear2 = gluon.nn.Dense(out_feats)\r\n        self.alpha = alpha\r\n\r\n    def forward(self, in_data, hidden_data, accum):\r\n        tmp = mx.nd.concat(in_data, accum, dim=1)\r\n        hidden = self.linear2(self.linear1(tmp))\r\n        return hidden_data * (1 - self.alpha) + self.alpha * hidden\r\n\r\ndef main(args, data):\r\n    update_hidden_train = NodeUpdate(16, \'relu\')\r\n    train_ctxs = []\r\n    for i in range(args.gpu):\r\n        train_ctxs.append(mx.gpu(i))\r\n    update_hidden_train.initialize(ctx=train_ctxs)\r\n\r\n    csr = data.astype(\'float32\')\r\n    dns = mx.nd.ones((csr.shape[1], 200))\r\n    mx.nd.waitall()\r\n    t0 = time.time()\r\n    for i in range(3):\r\n        out = mx.nd.dot(csr, dns)\r\n        out.wait_to_read()\r\n        print(i, time.time() - t0)\r\n        mx.nd.waitall()\r\n\r\nif __name__ == \'__main__\':\r\n    parser = argparse.ArgumentParser(description=\'GCN\')\r\n    parser.add_argument(""--graph-file"", type=str, default="""",\r\n            help=""graph file"")\r\n    parser.add_argument(""--gpu"", type=int, default=-1,\r\n            help=""gpu"")\r\n    args = parser.parse_args()\r\n\r\n    # load and preprocess dataset\r\n    csr = mx.nd.load(args.graph_file)[0]\r\n    rets1 = main(args, csr)\r\n    #rets2 = main(args, data)\r\n    #for hidden1, hidden2 in zip(rets1, rets2):\r\n    #    print(""hidden: "" + str(mx.nd.sum(mx.nd.abs(hidden1 - hidden2)).asnumpy()))\r\n']",[],1,1
5,incubator-mxnet,7820,closed,Low accuracy of pvanet,"I have changed a model which called pvanet from caffe [https://github.com/sanghoon/pva-faster-rcnn](https://github.com/sanghoon/pva-faster-rcnn), it is a implementation of the article by the author [https://arxiv.org/abs/1608.08021](https://arxiv.org/abs/1608.08021), my problem is why my accuracy is low than author's
What I have done:
1 Implement the classification net: [https://github.com/qingzhouzhen/incubator-mxnet/blob/pvanet-e2e/example/image-classification/symbols/pvanet.py](https://github.com/qingzhouzhen/incubator-mxnet/blob/pvanet-e2e/example/image-classification/symbols/pvanet.py)
2 feed the classification to Faster R-CNN module: [https://github.com/qingzhouzhen/incubator-mxnet/blob/pvanet-e2e/example/rcnn/rcnn/symbol/symbol_pvanet.py](https://github.com/qingzhouzhen/incubator-mxnet/blob/pvanet-e2e/example/rcnn/rcnn/symbol/symbol_pvanet.py)
Most job I have done is to atapt Faster-R-CNN,  replace the vgg pre-trained model with pvanet pre-trained model, for details see #7786 
Firstly the classification net pvanet's accuracy is 64.0%(70.6% as article)
Secondly detection net (pvanet+rpn+rcnn)'s mAP is 59.37%(82.5% as article)
I checked my net structure carefully to make it the same as author's implementation in caffe, is there anything I do wrong?  ",,"[""1. You can fix the same net weights in both caffe and mxnet, and debug layer by layer to see the result is whether the same.\r\n2. Check mean file and std scale value.\r\n3. Weights initialized with mx.random.normal in mxnet is worse than Xaviar or msra. So weights initialization is very sensitive in mxnet, otherwise you will get bad result as my experience.\r\n4. I can't understand the meaning of the line 'pool5 = mx.sym.Pooling(data=bsr, kernel=(1, 1), stride=(1, 1), pad=(0, 0), pool_type='max', name='pool5')'. Moreover, pooling is 'valid' in mxnet but 'full' in caffe.\r\n\r\nAnyway, If you want to port caffe to mxnet, fix the same net weights and compare the result of inferencing result of both framework is needed. As for training, It's complicated because the platform differences."", 'Thanks for such a detailed answer @chinakook ', 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!\nAlso, do please check out our [forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) for general ""how-to"" questions.']",[],[],1,0
6,incubator-mxnet,269,closed,About training accuracy,"Hi，
I use Alexnet.py in /example/imagenet to training with the configure unchanged,but after 20 rounds ,the accuracy is only 0.438870,much worse than the result shown in the docs(81%).
the dataset is from imagenet.
I wonder where this difference comes from.
Any help?
Thx.
",,"['1. The script is not a full script to train an AlexNet, because to train an AlexNet you need to reduce learning rate after several round\n2. Please note 81% is top-5 accurate, and `43.8` is top-1 accurate. In my memory, when top-1 accuracy reach 55%, it is almost 81%.\n3. What you need to do is stop current training now, load params from current checkpoint, then start train with learning rate of 0.001. After accuracy stops growing, switch to 0.0001 \n', 'Thanks,I will try it.\n']",[],[],1,0
7,incubator-mxnet,13454,open,Model loading became very slow after #11001,"## Description

The PR (#11001) introduced a checked in SymbolBlock.imports that makes the loading of large graph takes very long time (it used to be instantaneous):

The issue is the code checking if any symbol is row_sparse, removing this check allows to load large model instantaneously again.

## Environment info (Required)

----------Python Info----------
Version      : 3.6.5
Compiler     : GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)
Build        : ('default', 'Jun 17 2018 12:26:58')
Arch         : ('64bit', '')
------------Pip Info-----------
Version      : 18.0
Directory    : /usr/local/lib/python3.6/site-packages/pip
----------MXNet Info-----------
/usr/local/lib/python3.6/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.24) or chardet (3.0.4) doesn't match a supported version!
  RequestsDependencyWarning)
Version      : 1.3.0
Directory    : /usr/local/lib/python3.6/site-packages/mxnet
Commit Hash   : b3be92f4a48bce62a5a8424271871c2f81c8f7f1
----------System Info----------
Platform     : Darwin-16.7.0-x86_64-i386-64bit
system       : Darwin
node         : 186590d6796f.ant.amazon.com
release      : 16.7.0
version      : Darwin Kernel Version 16.7.0: Wed Oct 10 20:06:00 PDT 2018; root:xnu-3789.73.24~1/RELEASE_X86_64
----------Hardware Info----------
machine      : x86_64
processor    : i386
b'machdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT PREFETCHW RDTSCP TSCI'
b'machdep.cpu.leaf7_features: SMEP ERMS RDWRFSGS TSC_THREAD_OFFSET BMI1 AVX2 BMI2 INVPCID SMAP RDSEED ADX IPT FPU_CSDS'
b'machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C'
b'machdep.cpu.brand_string: Intel(R) Core(TM) i7-5557U CPU @ 3.10GHz'
----------Network Test----------
Setting timeout: 10
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0543 sec, LOAD: 1.2793 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0628 sec, LOAD: 0.9555 sec.
Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0802 sec, LOAD: 0.8386 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0073 sec, LOAD: 1.2169 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0521 sec, LOAD: 1.1819 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0419 sec, LOAD: 0.3027 sec.



## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. download model attached and script to load it
[model-loading-issue.zip](https://github.com/apache/incubator-mxnet/files/2629332/model-loading-issue.zip)
2. python slow_model_loading.py

## What have you tried to solve it?

1. comment check that symbol is row_sparse
",Performance,"['It will be great to test loading a large graph to avoid such regression (the model I attached could serve as a unit-test).', '@geoalgo Thank you for reporting the performance regression in , model loading.', '@mxnet-label-bot add [Performance]', 'Looks like there might be some issue with the `.get_internals()` function which is the true bottle neck, some quadratic complexity maybe.', 'meet the same problem too.']",[],[],1,0
8,incubator-mxnet,8335,open,Performance of MXNet on Windows  is lower than that on Linux by 15%-20%,"I've been testing MXNet on both Win10 and Ubuntu 16.04 in a long time. I found that the performance of Windows is lower than Linux by 15%-20% on both GPU and CPU contexts. So I wonder what makes the performance gap and I hope someone can solve this problem. My config is like following:
MXNet on Ubuntu:
MKL blas/CUDA8/CUDNN6/OpenCV 2.4.13/no jemalloc, no gperftools/building with Makefile
MXNet on Windows:
MKL blas/CUDA8/CUDNN6/OpenCV 2.4.13/no jemalloc, no gperftools/building with CMake",Performance Windows,"[""I've seen some cudnn example slower in windows than linux, then gave up windows, is this a mxnet problem?"", 'But the cpu performance of Windows is also lower. Our customers use Windows so I cannot give up.', 'What version of VC++ are you compiling with?', '@zhreshold VS2015 Update 3', ""Well, I don't think it's a specific problem related to mxnet, but a general performance issue between windows/linux"", '@zhreshold Can you elaborate on what would make Windows slower in general than Linux?  Intel claims MKL performance should be roughly similar, and the critical path when running MXNet on CPU should be MKL calls.\r\n\r\n@chinakook Are you seeing this both during training and inference?  Does it happen with a public dataset / model that someone could be used as a reference?  I think the next step would be profiling the performance on both platforms, and looking for relative differences.  For example operators that take much longer on Windows than Linux.', ""@KellenSunderland Yes, It's on both training and inferencing. I'll try to give some test cases."", 'When I installed MKL2018 and build the latest MXNet version, the performance of Windows version get nearly the same with that of Ubuntu on CPU.\r\nHowever, there is still performance gap between Windows and Linux on GPU.', 'Good to hear that the performance is similar with the new MKL version.  Thanks for the update @chinakook .  It would still be interesting to see where the perf gaps are when using GPU.', '@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', ""@nswamy please add 'Performance', 'Windows' to this topic"", 'This is really weird, as in my case windows is 4 times faster than windows for Training on CPU a Fully connected network.\r\nThe training time is exactly the same regardless using or not MKL-DNN and jemalloc. BLAS is openblas.\r\nThis is true for versions 1.2.0 and 1.3.1', '@paoloviviani the MNist dataset is too small to benchmark. The bottleneck will be io.', '@chinakook In my case is not MNIST, the iterator is made of an std::vector of NDArrays, which is already loaded in memory. But I see your point, I might look elsewhere for a bottleneck.', '@chinakook only for the record: my issue was related to OpenBLAS being compiled for a different intel architecture. Compiling it with DYNAMIC_ARCH improved the performance by a factor of 3.', 'Thx, I will try later.']",[],[],1,0
9,incubator-mxnet,11919,closed,Accuracy changes with number of GPUs,"## Description
I trained same SqueezeNet model with same hyper-parameters and dataset on p3.8xlarge and p3.16xlarge with same AMI but got ~3% lower accuracies on p3.16xlarge. I used same batch size per GPU but effective batch size is 2x in p3.16xlarge due to 2x number of GPUs.

## Environment info (Required)

p3.8xlarge


p3.16xlarge


Package used: Python

## Minimum reproducible example
Used model definition and training script from GluonCV - https://gluon-cv.mxnet.io/build/examples_classification/dive_deep_imagenet.html#sphx-glr-build-examples-classification-dive-deep-imagenet-py

## Steps to reproduce

1. p3.8xlarge - 

2. p3.16xlarge - 
",Gluon Performance,"[""Since the actual batch size differs by 2x it's not surprising that accuracy can be different."", 'You would need to change your learning rate based on the total batch size, generally proportional to the batch size (as the number of steps the training takes halves in the latter case). Try using lr 0.02 for the latter case. ', '@abhinavs95 Did you try the above suggestions? \r\n@sandeep-krishnamurthy Can you please add label: Performance, Gluon', 'Verified that behavior is as expected. Resolving. Please reopen if closed in error.']","[""\r\n----------Python Info----------\r\nVersion      : 3.6.6\r\nCompiler     : GCC 7.2.0\r\nBuild        : ('default', 'Jun 28 2018 17:14:51')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 10.0.1\r\nDirectory    : /home/ubuntu/anaconda3/envs/gln/lib/python3.6/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.3.0\r\nDirectory    : /home/ubuntu/anaconda3/envs/gln/lib/python3.6/site-packages/mxnet\r\nCommit Hash   : 65fee984437dcca3516912417e9430cf34ba7313\r\n----------System Info----------\r\nPlatform     : Linux-4.4.0-1062-aws-x86_64-with-debian-stretch-sid\r\nsystem       : Linux\r\nnode         : ip-172-31-78-153\r\nrelease      : 4.4.0-1062-aws\r\nversion      : #71-Ubuntu SMP Fri Jun 15 10:07:39 UTC 2018\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                32\r\nOn-line CPU(s) list:   0-31\r\nThread(s) per core:    2\r\nCore(s) per socket:    16\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\nStepping:              1\r\nCPU MHz:               1972.070\r\nCPU max MHz:           3000.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              4600.11\r\nHypervisor vendor:     Xen\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              46080K\r\nNUMA node0 CPU(s):     0-31\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single kaiser fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0032 sec, LOAD: 0.3394 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.1960 sec, LOAD: 0.3322 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.1599 sec, LOAD: 0.5460 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0474 sec, LOAD: 0.7632 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0039 sec, LOAD: 0.1079 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0043 sec, LOAD: 0.0531 sec.\r\n"", ""\r\n----------Python Info----------\r\nVersion      : 3.6.6\r\nCompiler     : GCC 7.2.0\r\nBuild        : ('default', 'Jun 28 2018 17:14:51')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 10.0.1\r\nDirectory    : /home/ubuntu/anaconda3/envs/gluon/lib/python3.6/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.3.0\r\nDirectory    : /home/ubuntu/anaconda3/envs/gluon/lib/python3.6/site-packages/mxnet\r\nCommit Hash   : 3051c49e3454df3b5f8909d3d76c6213d13539ad\r\n----------System Info----------\r\nPlatform     : Linux-4.4.0-1062-aws-x86_64-with-debian-stretch-sid\r\nsystem       : Linux\r\nnode         : ip-172-31-45-182\r\nrelease      : 4.4.0-1062-aws\r\nversion      : #71-Ubuntu SMP Fri Jun 15 10:07:39 UTC 2018\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                64\r\nOn-line CPU(s) list:   0-63\r\nThread(s) per core:    2\r\nCore(s) per socket:    16\r\nSocket(s):             2\r\nNUMA node(s):          2\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\nStepping:              1\r\nCPU MHz:               1581.609\r\nCPU max MHz:           3000.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              4600.07\r\nHypervisor vendor:     Xen\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              46080K\r\nNUMA node0 CPU(s):     0-15,32-47\r\nNUMA node1 CPU(s):     16-31,48-63\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq monitor est ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single kaiser fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt ida\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0032 sec, LOAD: 0.3625 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.1710 sec, LOAD: 0.3294 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0788 sec, LOAD: 0.5925 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0093 sec, LOAD: 0.3598 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0035 sec, LOAD: 0.0962 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0036 sec, LOAD: 0.0431 sec.\r\n""]","['python train_imagenet.py --data-dir ../imagenet/img_dataset --batch-size 128 --num-gpus 4 -j 32 --mode hybrid --num-epochs 100 --lr 0.01 --wd 0.0002 --lr-decay 0.1 --lr-decay-epoch 60,90 --model squeezenet1.0', 'python train_imagenet.py --data-dir ../imagenet/img_dataset --batch-size 128 --num-gpus 8 -j 64 --mode hybrid --num-epochs 100 --lr 0.01 --wd 0.0002 --lr-decay 0.1 --lr-decay-epoch 60,90 --model squeezenet1.0']",1,0
10,incubator-mxnet,913,closed,Speed has 2x difference between GTX 970 & GTX 980,"Hi, I test on my Ubuntu 14.04 GTX 970

2015-12-13 18:43:42,924 Node[0] Start training with [gpu(0)]
2015-12-13 18:44:41,062 Node[0] Iter[0] Batch [50]      Speed: 395.17 samples/sec
2015-12-13 18:44:57,556 Node[0] Iter[0] Batch [100]     Speed: 388.03 samples/sec
2015-12-13 18:45:14,045 Node[0] Iter[0] Batch [150]     Speed: 388.13 samples/sec
2015-12-13 18:45:30,548 Node[0] Iter[0] Batch [200]     Speed: 387.82 samples/sec

It said the GTX 980 is about 842 img/sec. It's nearly about 2x difference. Any ideas?
",,"['It is not normal. Have you enabled cudnn? \n', '@mli , I tried rebuild mxnet with cuDNN 4, there is some error. Any ideas?\n\n```\n/usr/local/cuda-7.5/bin/nvcc --use_fast_math -g -O3 -ccbin g++  -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -I/usr/local/cuda-7.5/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1 `pkg-config --cflags opencv` -fopenmp -DMSHADOW_USE_CUDNN=1 "" -M build/operator/dropout_gpu.o src/operator/dropout.cu >build/operator/dropout_gpu.d\n/usr/local/cuda-7.5/bin/nvcc -c -o build/operator/convolution_gpu.o --use_fast_math -g -O3 -ccbin g++  -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -I/usr/local/cuda-7.5/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1 `pkg-config --cflags opencv` -fopenmp -DMSHADOW_USE_CUDNN=1 "" src/operator/convolution.cu\n/usr/local/cuda-7.5/bin/nvcc -c -o build/operator/deconvolution_gpu.o --use_fast_math -g -O3 -ccbin g++  -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -I/usr/local/cuda-7.5/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1 `pkg-config --cflags opencv` -fopenmp -DMSHADOW_USE_CUDNN=1 "" src/operator/deconvolution.cu\n/usr/local/cuda-7.5/bin/nvcc -c -o build/operator/dropout_gpu.o --use_fast_math -g -O3 -ccbin g++  -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -I/usr/local/cuda-7.5/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1 `pkg-config --cflags opencv` -fopenmp -DMSHADOW_USE_CUDNN=1 "" src/operator/dropout.cu\nsrc/operator/./cudnn_convolution-inl.h(77): error: argument of type ""cudnnAddMode_t"" is incompatible with parameter of type ""const void *""\nsrc/operator/./cudnn_convolution-inl.h(77): error: argument of type ""float *"" is incompatible with parameter of type ""cudnnTensorDescriptor_t""\nsrc/operator/./cudnn_convolution-inl.h(77): error: argument of type ""float *"" is incompatible with parameter of type ""cudnnTensorDescriptor_t""\nsrc/operator/./cudnn_convolution-inl.h(77): error: too many arguments in function call\nsrc/operator/./cudnn_deconvolution-inl.h(77): error: argument of type ""cudnnAddMode_t"" is incompatible with parameter of type ""const void *""\nsrc/operator/./cudnn_deconvolution-inl.h(77): error: argument of type ""float *"" is incompatible with parameter of type ""cudnnTensorDescriptor_t""\nsrc/operator/./cudnn_deconvolution-inl.h(77): error: argument of type ""float *"" is incompatible with parameter of type ""cudnnTensorDescriptor_t""\nsrc/operator/./cudnn_deconvolution-inl.h(77): error: too many arguments in function call\n4 errors detected in the compilation of ""/tmp/tmpxft_00001f89_00000000-7_convolution.cpp1.ii"".\nmake: *** [build/operator/convolution_gpu.o] Error 2\nmake: *** Waiting for unfinished jobs....\n4 errors detected in the compilation of ""/tmp/tmpxft_00001f91_00000000-7_deconvolution.cpp1.ii"".\nmake: *** [build/operator/deconvolution_gpu.o] Error 2\n```\n', ""cuDNN 4 has new interface. It's not compatible with mxnet yet\n"", ""Thanks, I rebuild it with cuDNN 3. Everything seems work now. It's about 700 img/sec. There is still large difference between 850 img/sec. Maybe it comes from GTX 970 and GTX 980?\n"", '@piiswrong Is there any update on cuDNN 4 on mxnet? thanks. \nbtw, Theano now already can use cuDNN 4.0 CR\n', '@leocnj we support cuDNN 4.0. Plugin and use.\n', 'Great! Will try re-compile mxnet and update R-mxnet based on cuDNN 4.0\n']",[],[],1,0
11,incubator-mxnet,6802,closed,Periodic loss value,"The cross-entropy loss for classification task is somehow periodic during iteration, and the period is exactly an epoch of iterations of data set. The loss is lowest at the end of every epoch and  increases rapidly(relatively) at the beginning of the next epoch....   
This phenomenon appears in different networks training on different data sets in my experiments , so I think there might be something wrong with my training procedure rather than the model or data sets. Some potential mistake I probably made:
the use of metric
the use of dataIter
the use of optimizer

anyone have encountered similar problem?

here are my codes:

 

",,"['Does the model seem to converge? Periodically high loss may just be the manifestation of the same ordering of training samples. Turning on shuffle (`shuffle=True` in ImageRecordIter) will most likely make the periodic loss increase go away since the order of training samples will be randomized.', ""@szha  Actually the model can successfully converge... this phenomenon is obvious when the learning rate is small(0.001) ... Thank you for your advice. I'll try if it helps. To my understanding shuffling to distort  the order of labels  at the beginning is enough. Confusingly when using Caffe, I didn't have this problem... "", 'Feel free to reopen if the issue persists.']","[""\r\ntrain_iter = mx.io.ImageRecordIter(\r\n\tpath_imgrec=recpath,\r\n\tdata_shape=datashape,\r\n\tbatch_size=batchsize,\r\n\trand_crop=True,\r\n\trand_mirror=True)\r\n\r\n\r\nopt = mx.optimizer.SGD(\r\n\tmomentum=0.9,\r\n\trescale_grad=1.0/batchsize,\r\n\tlearning_rate=base_lr,\r\n\twd=weight_decay\r\n\t)\r\n...\r\nmetric = mx.metric.create('ce')\r\n\r\nfor epoch in range(loadEpoch + 1,maxEpoch):\r\n\ttrain_iter.reset()\r\n\tfor i,databatch in enumerate(train_iter):\r\n\t\tstep += 1\r\n\t\tmod.forward(databatch,is_train=True)\r\n\t\tmod.update_metric(metric,databatch.label)\r\n\t\tif(step % display == 0):\r\n\t\t\tt = '[' + time.asctime( time.localtime(time.time())) + ']'\r\n\t\t\tinfo = t + 'epoch['+str(epoch)+']' + ',iter['+str(step)+'] '+'loss: ' + str(metric.get()[1])\r\n\t\t\tprint info\r\n\t\t\tlog.write(info + '\\n')\r\n\t\t\tlog.flush()\r\n\t\t\tmetric.reset()\r\n\t\tmod.backward()\r\n\t\tmod.update()\r\n\tprint 'Saving checkpoint at epoch' + str(epoch)\r\n\tmod.save_checkpoint(prefix,epoch)\r\n""]",[],1,0
12,incubator-mxnet,8978,closed,Very Low Accuracy When Using Pretrained Model,"## Description
Pretrained models dont seem to be working well with gluon, specifically datasets build with Dataloader and ImageRecords or ImageFolders.

As an example, here I load the ImageNet validation dataset and feed it into alexnet downloaded from gluon model zoo



The 12% accuracy shows the issue is probably that the transforms used to train the model dont exactly align with the transforms presented in the Gluon tutorial. It would be nice if an example showing how to properly do this using the new gluon functions were added.

## Environment info (Required)
Python 3.6",,"['The issue turned out to be that both scaling and normalization are needed to match the pytorch transforms.\r\n\r\n```\r\ndef transformer(data, label):\r\n    data = mx.image.imresize(data, 256, 256)\r\n    data, _ = mx.image.center_crop(data, (224, 224))\r\n    data = data.astype(np.float32)\r\n    data = data/255\r\n    data = mx.image.color_normalize(data,\r\n                                    mean=mx.nd.array([0.485, 0.456, 0.406]),\r\n                                    std=mx.nd.array([0.229, 0.224, 0.225])) \r\n    data = mx.nd.transpose(data, (2,0,1))\r\n    return data, label\r\n```']","['\r\nctx = mx.gpu()\r\nbatch_size = 64\r\ndef transformer(data, label):\r\n    data = mx.image.imresize(data, 224, 224)\r\n    data = mx.nd.transpose(data, (2,0,1))\r\n    data = data.astype(np.float32)\r\n    return data/255, label\r\n\r\ntest_data = gluon.data.DataLoader(gluon.data.vision.ImageFolderDataset(root=""/data2/imagenet/val/"", transform=transformer),\r\n                                      batch_size, shuffle=False)\r\n\r\nmodel = gluon.model_zoo.vision.alexnet(pretrained=True, ctx=ctx)\r\n\r\ndef evaluate_accuracy(data_iterator, net):\r\n    acc = mx.metric.Accuracy()\r\n    for d, l in data_iterator:\r\n        data = d.as_in_context(ctx)\r\n        label = l.as_in_context(ctx)\r\n        output = net(data)\r\n        predictions = nd.argmax(output, axis=1)\r\n        acc.update(preds=predictions, labels=label)\r\n    return acc.get()[1]\r\n\r\nevaluate_accuracy(test_data, model, ctx=ctx)\r\n[0.12393999999999999]\r\n']",[],1,0
13,incubator-mxnet,13593,open,Low CPU usage of MXNet in subprocesses,"MXNet has low CPU usage when running CPU operations in multiple process scenarios. Specifically, for MXNet computation in a subprocess, MxNet can use only 1 or 2 CPUs to do its job. This issue shows different behavior for different variants of MxNet (see below) and on different machines ...

This issue is critical because it slows down the multiprocess object-detection data-loading in gluoncv very significantly, making Faster-RCNN training in gluoncv unusable.

This is tested on the 20181207 version, and other versions (e.g., 1.3.1) show similar problems. 

Code to reproduce the issue

Filename: 


Detailed experiments:

- Run in the main process:

![image](https://user-images.githubusercontent.com/7865903/49704337-a3807000-fbc6-11e8-9118-0c7034e52cf9.png)
Working fine for all mxnet variants (GPU or CPU-only).

- Run in two subproceses
--  on p3.16x:

![image](https://user-images.githubusercontent.com/7865903/49704395-420cd100-fbc7-11e8-9607-a0c907b2057a.png)
It uses only 2 CPUs per subprocess.
--  on p3.16x:

![image](https://user-images.githubusercontent.com/7865903/49704444-14745780-fbc8-11e8-8754-81b90af4f876.png)
Same here. It uses only 2 CPUs per subprocess.
--  on **CPU-only machine c5.18x**:

![image](https://user-images.githubusercontent.com/7865903/49704457-3d94e800-fbc8-11e8-8831-9136465fad1f.png)
**Even worse.** It uses only 1.5 CPUs per subprocess.
-- However, for vanilla CPU-version  on c5.18x:

![image](https://user-images.githubusercontent.com/7865903/49704510-e2afc080-fbc8-11e8-8548-2505a7070205.png)
It is working better. At least, it uses 5 CPUs per subprocess.
-- Weirdly, still vanilla CPU-version  but on **GPU machine p3.16x**:

![image](https://user-images.githubusercontent.com/7865903/49704532-1a1e6d00-fbc9-11e8-8009-95519fd9f1ef.png)
It is working worse, i.e., 2 CPUs per subprocesses.
- This problem seems relevant to how MXNet manage the thread per subprocess. If I do not  in the main process and instead  in each subprocess:

![image](https://user-images.githubusercontent.com/7865903/49704599-d11ae880-fbc9-11e8-8460-e7d1e53abb13.png)
Then everything is working fine. 
",Performance,"['@TaoLv to help look at this issue ', '@YutingZhang Thanks for your issue reporting! @anirudh2290 @apeforest @azai91 @samskalicky please take a look in here.', 'Hi @YutingZhang, please try:\r\n1. set OMP_NUM_THREADS manually. For this test case, I tried `OMP_NUM_THREADS=#core/#worker`;\r\n2. remove the two SetEnv form https://github.com/apache/incubator-mxnet/blob/master/src/initialize.cc#L61-L62. \r\n\r\nPlease let me know if it works for you. Thanks.', 'Related issue: https://github.com/apache/incubator-mxnet/issues/12255', 'The limitation of 1 thread per worker is deliberately set to avoid thread contention. \r\n\r\nPer offline discussion, I think a good solution is to use a ENV variable to control the limit of threads per worker can use (which defaults to 1 now).\r\n\r\n', '@zhreshold this would also require rebuild with modified `initialize.cc`, otherwise the env variable would get overwritten. ', '@anirudh2290 Yes, I mean a PR is required to address this issue.', 'Thanks everyone for discussing and solving the issue!', '@zhreshold I tried the latest version of mxnet, and do `export MXNET_MP_WORKER_NTHREADS=20`. However, the example code I posted still results in the same CPU usage. Any ideas?', ""@YutingZhang  MXNET_MP_WORKER_NTHREADS can only control how many mxnet operators run in parallel, in the case of some transformations, it might not be able to parallelize as much op as possible. Due to a openmp bug, it's disabled for the worker so unfortunately it is the case.\r\n\r\nYou might want to enable opencv multithreading for each worker which might be the most time consuming part in worker process"", '@pengzhao-intel @TaoLv @anirudh2290 @zhreshold Thank you for everyone\'s help, and happy new year! This problem seems more complicated (it might be multiple problems in the beginning). @zhreshold\'s fix solved the problem in most cases. \r\nHowever, I found, if we call `asnumpy` in each worker, it interferes among the processes. And it does not seem to be a problem for GPU-version MxNet running on a GPU-machine. It seems only happening on **CPU-only machine (I tested on c5.18large with `mxnet-mkl`)**.\r\n\r\nCode (one-line difference):\r\n```\r\nimport argparse\r\nimport sys\r\nfrom concurrent import futures\r\nimport time\r\nimport numpy as np\r\nmx=None\r\n\r\n\r\ndef run(need_import):\r\n    if need_import:\r\n        import mxnet as mx\r\n    else:\r\n        global mx\r\n    A = mx.nd.random.uniform(low=0, high=1, shape=(5000, 5000))\r\n    while True:\r\n        A = mx.nd.dot(A, A)\r\n        A.asnumpy()    # ******** only difference ***********\r\n\r\ndef parse_args():\r\n    parser = argparse.ArgumentParser(""benchmark mxnet cpu"")\r\n    parser.add_argument(\'--num-workers\', \'-j\', dest=\'num_workers\', type=int, default=0)\r\n    parser.add_argument(\'--late-import\', action=\'store_true\')\r\n    return parser.parse_args()\r\n\r\ndef main(args):\r\n\r\n    if args.num_workers == 0:\r\n        print(""Main process"")\r\n        try:\r\n            run(need_import=args.late_import)\r\n        except KeyboardInterrupt:\r\n            pass\r\n    else:\r\n        print(""Subprocesses"")\r\n        ex = futures.ProcessPoolExecutor(args.num_workers)\r\n\r\n        for _ in range(args.num_workers):\r\n            ex.submit(run, need_import=args.late_import)\r\n        while True:\r\n            try:\r\n                time.sleep(10000)\r\n            except KeyboardInterrupt:\r\n                ex.shutdown(wait=False)\r\n                break\r\n    print(""Stopped"")\r\n\r\n\r\nif __name__ == ""__main__"":\r\n    args = parse_args()\r\n    if not args.late_import:\r\n       import mxnet as mx\r\n    main(args)\r\n```\r\n\r\nLaunch 10 workers (`python3 mxnet_cpu_test.py --num-workers=10`). `MXNET_MP_WORKER_NTHREADS` does not affect the results.\r\n![image](https://user-images.githubusercontent.com/7865903/50606321-3042e480-0e7a-11e9-892a-2066a6030caf.png)\r\n\r\nBut running it only in the main process is fine:\r\n![image](https://user-images.githubusercontent.com/7865903/50606810-e1964a00-0e7b-11e9-94cb-b0f61dbbea36.png)\r\n\r\n\r\nBy the way, another issue I found with `mxnet` (cpu non-mkl version) is: when you run MxNet in a subprocess, it interferes with many other non-mxnet functions (e.g., `cv2.cvtColor`). The subprocess got stuck at those functions. This did not happen for `mxnet==1.3.1`, it started to happen in some nightly build version. Probably, we should create a new ticket for this.\r\n\r\n \r\n', '@YutingZhang thanks for the case, we will look into the issue.', ""@YutingZhang If you just want to utilize 100% cpu for each process, please try `export KMP_AFFINITY=granularity=fine,noduplicates`, it works on my environment. \r\n\r\nIf you want enable openmp multi-threading to utilize >100% cpu for each process, you need to make below change for MXNet:\r\nhttps://github.com/ZhennanQin/incubator-mxnet/commit/48fe761f0268c316477fac23d005d26b29c65a47\r\n\r\nThen you can use `export OMP_NUM_THREADS=4` to specify 4x cpu usage for each process.\r\n\r\nIf you don't want to change MXNet and just want to increase the efficiency of MKL dot, you can try `export MKL_NUM_THREADS=4`. It only works for MKL library."", '@zhreshold do you know some backgrounds why fixed the thread number to 1 in the worker processor as below line shown?\r\nZhennanQin@48fe761', 'Got some info from @YutingZhang #13449 #12380 thanks a lot.', '@anirudh2290 ', '@pengzhao-intel The thread limit is set to 1 according to comment: https://github.com/apache/incubator-mxnet/pull/13606#discussion_r240914759\r\n\r\nIf you have better understanding of the problem please let me know.', '@YutingZhang \r\nJust tested out the master version, the ENV variable `OMP_NUM_THREADS` can now effectively control the OMP threads each worker is allowed to use.\r\n\r\nFor example, `OMP_NUM_THREADS=32 python3 mxnet_cpu_test.py --num-workers=2` gives\r\n\r\n![image](https://user-images.githubusercontent.com/3307514/65360902-88f81000-dbb6-11e9-85fb-c91fc6c1f9f4.png)\r\n']","['python\r\nimport argparse\r\nimport sys\r\nfrom concurrent import futures\r\nimport time\r\nimport numpy as np\r\nmx=None\r\n\r\n\r\ndef run(need_import):\r\n    if need_import:\r\n        import mxnet as mx\r\n    else:\r\n        global mx\r\n    A = mx.nd.random.uniform(low=0, high=1, shape=(5000, 5000))\r\n    while True:\r\n        A = mx.nd.dot(A, A)\r\n\r\ndef parse_args():\r\n    parser = argparse.ArgumentParser(""benchmark mxnet cpu"")\r\n    parser.add_argument(\'--num-workers\', \'-j\', dest=\'num_workers\', type=int, default=0)\r\n    parser.add_argument(\'--late-import\', action=\'store_true\')\r\n    return parser.parse_args()\r\n\r\ndef main(args):\r\n\r\n    if args.num_workers == 0:\r\n        print(""Main process"")\r\n        try:\r\n            run(need_import=args.late_import)\r\n        except KeyboardInterrupt:\r\n            pass\r\n    else:\r\n        print(""Subprocesses"")\r\n        ex = futures.ProcessPoolExecutor(args.num_workers)\r\n\r\n        for _ in range(args.num_workers):\r\n            ex.submit(run, need_import=args.late_import)\r\n        while True:\r\n            try:\r\n                time.sleep(10000)\r\n            except KeyboardInterrupt:\r\n                ex.shutdown(wait=False)\r\n                break\r\n    print(""Stopped"")\r\n\r\n\r\nif __name__ == ""__main__"":\r\n    args = parse_args()\r\n    if not args.late_import:\r\n       import mxnet as mx\r\n    main(args)\r\n\r\n']","['mxnet_cpu_test.py', 'python3 mxnet_cpu_test.py --num-workers=0', 'mxnet-cu90', 'python3 mxnet_cpu_test.py --num-workers=2', 'mxnet-mkl', 'python3 mxnet_cpu_test.py --num-workers=2', 'mxnet-mkl', 'python3 mxnet_cpu_test.py --num-workers=2', 'mxnet', 'python3 mxnet_cpu_test.py --num-workers=2', 'mxnet', 'python3 mxnet_cpu_test.py --num-workers=2', 'import \r\n mxnet', 'import mxnet', 'python3 mxnet_cpu_test.py --num-workers=2 --late-import']",1,0
14,incubator-mxnet,2041,closed,Sudden drop in accuracy while training a deep neural net,"HI, I am using mxnet to train a 11-class image classifier. I am observing a weird behavior training accuracy was increasing slowly and went upto 39% and in next epoch it went down to 9% and then it stays close to 9% for rest of the training.
I restarted the training with saved model (with 39% training accuracy) keeping all other parameter same . Now training accuracy is increasing again. What can be the reason here ? I am not able to understand it . And its getting difficult to train the model this way as it requires me to see training accuracy values constantly.
",,"['It may because you are using too large learning rate.\nOn Thu, May 5, 2016 at 00:04 saustar notifications@github.com wrote:\n\n> HI, I am using mxnet to train a 11-class image classifier. I am observing\n> a weird behavior training accuracy was increasing slowly and went upto 39%\n> and in next epoch it went down to 9% and then it stays close to 9% for rest\n> of the training.\n> I restarted the training with saved model (with 39% training accuracy)\n> keeping all other parameter same . Now training accuracy is increasing\n> again. What can be the reason here ? I am not able to understand it . And\n> its getting difficult to train the model this way as it requires me to see\n> training accuracy values constantly.\n> \n> —\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly or view it on GitHub\n> https://github.com/dmlc/mxnet/issues/2041\n> \n> ## \n> \n> Sent from mobile phone\n', 'I am using 0.01 learning rate but still If I restart the training it starts\nincreasing and right now accuracy become 42%.\n\nOn Thu, May 5, 2016 at 12:47 PM, Bing Xu notifications@github.com wrote:\n\n> It may because you are using too large learning rate.\n> On Thu, May 5, 2016 at 00:04 saustar notifications@github.com wrote:\n> \n> > HI, I am using mxnet to train a 11-class image classifier. I am observing\n> > a weird behavior training accuracy was increasing slowly and went upto\n> > 39%\n> > and in next epoch it went down to 9% and then it stays close to 9% for\n> > rest\n> > of the training.\n> > I restarted the training with saved model (with 39% training accuracy)\n> > keeping all other parameter same . Now training accuracy is increasing\n> > again. What can be the reason here ? I am not able to understand it . And\n> > its getting difficult to train the model this way as it requires me to\n> > see\n> > training accuracy values constantly.\n> > \n> > —\n> > You are receiving this because you are subscribed to this thread.\n> > Reply to this email directly or view it on GitHub\n> > https://github.com/dmlc/mxnet/issues/2041\n> > \n> > ## \n> > \n> > Sent from mobile phone\n> \n> —\n> You are receiving this because you authored the thread.\n> Reply to this email directly or view it on GitHub\n> https://github.com/dmlc/mxnet/issues/2041#issuecomment-217091770\n\n## \n\nSaurabh Gupta\n+918377943044\n', '@saustar Could you provide an example? In fact, I also meet this kind of problem before but I failed to give an example... In fact, I find training with CPU is sometimes more stable than training with GPU...\n', 'Try momentum with 0.5, or a smaller lr\n']",[],[],1,0
15,incubator-mxnet,7582,closed,Gluon GPU memory efficiency,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
Ubuntu 16.04
Package used (Python/R/Scala/Julia):
Python
MXNet version:
0.11
Python version and distribution:
2.7

I am running a vgg+fcn model on keras + tensorflow and gluon. I can set batch_size = 32 on keras + tensorflow, but I can only set batch_size = 20 on gluon. 

The last block of my model on gluon is:

# block 7
self.net = nn.Sequential(prefix='net')
self.net.add(nn.Conv3D(256, kernel_size = 3, padding = 1, activation='relu'))
self.net.add(nn.Conv3D(4096, kernel_size = 1, padding = 0, activation='relu'))
self.net.add(nn.Conv3D(4096, kernel_size = 1, padding = 0, activation='relu'))
self.net.add(nn.Conv3D(max, kernel_size = 1, activation='sigmoid'))
 
The corresponding part on keras+tf is:

x = Conv3D(256, (3, 3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)
x = Conv3D(4096, (1, 1, 1), padding='same', activation='relu', kernel_initializer='normal', name='rpn_fc1')(x)
x = Conv3D(4096, (1, 1, 1), padding='same', activation='relu', kernel_initializer='normal', name='rpn_fc2')(x)
x_dist = Conv3D(max, (1, 1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)

",CUDA Gluon Memory,"['I also use feature pyramid network in my model. Thus there are some steps involving upsampling (or deconvolution). According to http://mxnet.io/architecture/note_memory.html, gluon should be quite GPU memory efficient.', 'Do you know which commit your mxnet is on? @piiswrong recently fixed some of the memory issues in 7d6385a5 so it would be wise to first figure out whether your version is before or after that change. ', 'Mine is commit/491f81e648639c53a68155585c53c3993a33ead5', 'Could you also compare the memory usage of only forward propagation? Thanks.', 'Could you post the full code? What card are you using? How much memory do you have?', 'I am using 4*TITAN Xp or TitianX. So I have 12G GPU memory in both cases for a single card. \r\n\r\nWhich part of the code do you want to see? @piiswrong \r\n\r\nLet me check @jermainewang ', '@jermainewang For batch_size = 40, my model only use 7395MB GPU memory in forward. ', ""If I only use vgg+fcn, then I can set batch_size = 64 for tf+keras and gluon. Here is the code:\r\n\r\n```\r\ndef get_vgg16(max):\r\n    #net = nn.HybridSequential()\r\n    net = nn.Sequential()\r\n    with net.name_scope():\r\n        # Block 1\r\n        net.add(nn.Conv3D(64, kernel_size = 3, padding = 1, activation='relu'))\r\n        net.add(nn.Conv3D(64, kernel_size = 3, padding = 1, activation='relu'))\r\n        net.add(nn.MaxPool3D(pool_size=(2, 2, 2), strides = (2, 2, 2)))\r\n        # Block 2\r\n        net.add(nn.Conv3D(128, kernel_size = 3, padding = 1, activation='relu'))\r\n        net.add(nn.Conv3D(128, kernel_size = 3, padding = 1, activation='relu'))\r\n        net.add(nn.MaxPool3D(pool_size=(2, 2, 2), strides = (2, 2, 2)))\r\n        # Block 3\r\n        net.add(nn.Conv3D(256, kernel_size = 3, padding = 1, activation='relu'))\r\n        net.add(nn.Conv3D(256, kernel_size = 3, padding = 1, activation='relu'))\r\n        net.add(nn.Conv3D(256, kernel_size = 3, padding = 1, activation='relu'))\r\n        net.add(nn.MaxPool3D(pool_size=(2, 2, 2), strides = (2, 2, 2)))\r\n        # Block 4\r\n        net.add(nn.Conv3D(512, kernel_size = 3, padding = 1, activation='relu'))\r\n        net.add(nn.Conv3D(512, kernel_size = 3, padding = 1, activation='relu'))\r\n        net.add(nn.Conv3D(512, kernel_size = 3, padding = 1, activation='relu'))\r\n        net.add(nn.MaxPool3D(pool_size=(2, 2, 2), strides = (2, 2, 2)))\r\n        # Block 5\r\n        net.add(nn.Conv3D(512, kernel_size = 3, padding = 1, activation='relu'))\r\n        net.add(nn.Conv3D(512, kernel_size = 3, padding = 1, activation='relu'))\r\n        # Block 6\r\n        net.add(nn.Conv3DTranspose(512, kernel_size = 4, strides = (4, 4, 4), activation='relu'))\r\n        # Block 7\r\n        net.add(nn.Conv3D(256, kernel_size = 3, padding = 1, activation='relu'))\r\n        net.add(nn.Conv3D(4096, kernel_size = 1, padding = 0, activation='relu'))\r\n        net.add(nn.Conv3D(4096, kernel_size = 1, padding = 0, activation='relu'))\r\n        net.add(nn.Conv3D(max, kernel_size = 1, activation='sigmoid'))\r\n        return net\r\n```"", ""Here is the code for vgg+fcn+fpn:\r\n\r\n```\r\nclass get_vgg16(gluon.Block):\r\n    def __init__(self, max, **kwargs):\r\n        super(get_vgg16, self).__init__(**kwargs)\r\n        # c2 layer\r\n        self.c2 = nn.Sequential(prefix='c2')\r\n        self.c2.add(nn.Conv3D(64, kernel_size = 3, padding = 1, activation='relu'))\r\n        self.c2.add(nn.Conv3D(64, kernel_size = 3, padding = 1, activation='relu'))\r\n        self.c2.add(nn.MaxPool3D(pool_size=(2, 2, 2), strides = (2, 2, 2)))\r\n        self.c2.add(nn.Conv3D(128, kernel_size = 3, padding = 1, activation='relu'))\r\n        self.c2.add(nn.Conv3D(128, kernel_size = 3, padding = 1, activation='relu'))\r\n        # c3 layer\r\n        self.c3 = nn.Sequential(prefix='c3')\r\n        self.c3.add(nn.MaxPool3D(pool_size=(2, 2, 2), strides = (2, 2, 2)))\r\n        self.c3.add(nn.Conv3D(256, kernel_size = 3, padding = 1, activation='relu'))\r\n        self.c3.add(nn.Conv3D(256, kernel_size = 3, padding = 1, activation='relu'))\r\n        self.c3.add(nn.Conv3D(256, kernel_size = 3, padding = 1, activation='relu'))\r\n        # c4 layer\r\n        self.c4 = nn.Sequential(prefix='c4')\r\n        self.c4.add(nn.MaxPool3D(pool_size=(2, 2, 2), strides = (2, 2, 2)))\r\n        self.c4.add(nn.Conv3D(512, kernel_size = 3, padding = 1, activation='relu'))\r\n        self.c4.add(nn.Conv3D(512, kernel_size = 3, padding = 1, activation='relu'))\r\n        self.c4.add(nn.Conv3D(512, kernel_size = 3, padding = 1, activation='relu'))\r\n        # c5 layer\r\n        self.c5 = nn.Sequential(prefix='c5')\r\n        self.c5.add(nn.MaxPool3D(pool_size=(2, 2, 2), strides = (2, 2, 2)))\r\n        self.c5.add(nn.Conv3D(512, kernel_size = 3, padding = 1, activation='relu'))\r\n        self.c5.add(nn.Conv3D(512, kernel_size = 3, padding = 1, activation='relu'))\r\n        # u5 layer\r\n        self.c5.add(nn.Conv3D(128, kernel_size = 1, padding = 0, activation='relu'))\r\n        self.c5.add(nn.Conv3DTranspose(128, kernel_size = 2, strides = (2, 2, 2), activation='relu'))\r\n        # x4 layer\r\n        self.x4 = nn.Sequential(prefix='x4')\r\n        self.x4.add(nn.Conv3D(128, kernel_size = 1, padding = 0, activation='relu'))\r\n        # u4 layer\r\n        self.u4 = nn.Sequential(prefix='u4')\r\n        self.u4.add(nn.Conv3DTranspose(128, kernel_size = 2, strides = (2, 2, 2), activation='relu'))\r\n        # x3 layer\r\n        self.x3 = nn.Sequential(prefix='x3')\r\n        self.x3.add(nn.Conv3D(128, kernel_size = 1, padding = 0, activation='relu'))\r\n        # u3 layer\r\n        self.u3 = nn.Sequential(prefix='u3')\r\n        self.u3.add(nn.Conv3DTranspose(128, kernel_size = 2, strides = (2, 2, 2), activation='relu'))\r\n        # x2 layer\r\n        self.x2 = nn.Sequential(prefix='x2')\r\n        self.x2.add(nn.Conv3D(128, kernel_size = 1, padding = 0, activation='relu'))\r\n        # Block 7\r\n        self.net = nn.Sequential(prefix='net')\r\n        self.net.add(nn.Conv3D(256, kernel_size = 3, padding = 1, activation='relu'))\r\n        self.net.add(nn.Conv3D(4096, kernel_size = 1, padding = 0, activation='relu'))\r\n        self.net.add(nn.Conv3D(4096, kernel_size = 1, padding = 0, activation='relu'))\r\n        self.net.add(nn.Conv3D(max, kernel_size = 1, activation='sigmoid'))\r\n    def forward(self, x):\r\n        x_c2 = self.c2(x)\r\n        x_c3 = self.c3(x_c2)\r\n        x_c4 = self.c4(x_c3)\r\n        x_u5 = self.c5(x_c4)\r\n        x4 = self.x4(x_c4) + x_u5\r\n        x_u4 = self.u4(x4)\r\n        x3 = self.x3(x_c3) + x_u4\r\n        x_u3 = self.u3(x3)\r\n        x2 = self.x2(x_c2) + x_u3\r\n        res = self.net(x2)\r\n        return res\r\n```"", 'I can also post my code on keras+tf if needed.\r\n\r\n', ""What's the memory consumption if you switch to HybridBlock? Since your code does not have any control flow and I/O manipulation, it should be fine to use HybridBlock."", 'Let me try.', ""The memory consumption is the same as before. And I don't gain any performance... Here is the code. I do call vgg_net.hybridize() in the main program.\r\n\r\n```\r\nclass get_vgg16(gluon.HybridBlock):\r\n    def __init__(self, max_radius, **kwargs):\r\n        super(get_vgg16, self).__init__(**kwargs)\r\n        with self.name_scope():\r\n            # c2 layer\r\n            self.c2 = nn.HybridSequential(prefix='c2')\r\n            self.c2.add(nn.Conv3D(64, kernel_size = 3, padding = 1, activation='relu'))\r\n            self.c2.add(nn.Conv3D(64, kernel_size = 3, padding = 1, activation='relu'))\r\n            self.c2.add(nn.MaxPool3D(pool_size=(2, 2, 2), strides = (2, 2, 2)))\r\n            self.c2.add(nn.Conv3D(128, kernel_size = 3, padding = 1, activation='relu'))\r\n            self.c2.add(nn.Conv3D(128, kernel_size = 3, padding = 1, activation='relu'))\r\n            # c3 layer\r\n            self.c3 = nn.HybridSequential(prefix='c3')\r\n            self.c3.add(nn.MaxPool3D(pool_size=(2, 2, 2), strides = (2, 2, 2)))\r\n            self.c3.add(nn.Conv3D(256, kernel_size = 3, padding = 1, activation='relu'))\r\n            self.c3.add(nn.Conv3D(256, kernel_size = 3, padding = 1, activation='relu'))\r\n            self.c3.add(nn.Conv3D(256, kernel_size = 3, padding = 1, activation='relu'))\r\n            # c4 layer\r\n            self.c4 = nn.HybridSequential(prefix='c4')\r\n            self.c4.add(nn.MaxPool3D(pool_size=(2, 2, 2), strides = (2, 2, 2)))\r\n            self.c4.add(nn.Conv3D(512, kernel_size = 3, padding = 1, activation='relu'))\r\n            self.c4.add(nn.Conv3D(512, kernel_size = 3, padding = 1, activation='relu'))\r\n            self.c4.add(nn.Conv3D(512, kernel_size = 3, padding = 1, activation='relu'))\r\n            # c5 layer\r\n            self.c5 = nn.HybridSequential(prefix='c5')\r\n            self.c5.add(nn.MaxPool3D(pool_size=(2, 2, 2), strides = (2, 2, 2)))\r\n            self.c5.add(nn.Conv3D(512, kernel_size = 3, padding = 1, activation='relu'))\r\n            self.c5.add(nn.Conv3D(512, kernel_size = 3, padding = 1, activation='relu'))\r\n            # u5 layer\r\n            self.c5.add(nn.Conv3D(128, kernel_size = 1, padding = 0, activation='relu'))\r\n            self.c5.add(nn.Conv3DTranspose(128, kernel_size = 2, strides = (2, 2, 2), activation='relu'))\r\n            # x4 layer\r\n            self.x4 = nn.HybridSequential(prefix='x4')\r\n            self.x4.add(nn.Conv3D(128, kernel_size = 1, padding = 0, activation='relu'))\r\n            # u4 layer\r\n            self.u4 = nn.HybridSequential(prefix='u4')\r\n            self.u4.add(nn.Conv3DTranspose(128, kernel_size = 2, strides = (2, 2, 2), activation='relu'))\r\n            # x3 layer\r\n            self.x3 = nn.HybridSequential(prefix='x3')\r\n            self.x3.add(nn.Conv3D(128, kernel_size = 1, padding = 0, activation='relu'))\r\n            # u3 layer\r\n            self.u3 = nn.HybridSequential(prefix='u3')\r\n            self.u3.add(nn.Conv3DTranspose(128, kernel_size = 2, strides = (2, 2, 2), activation='relu'))\r\n            # x2 layer\r\n            self.x2 = nn.HybridSequential(prefix='x2')\r\n            self.x2.add(nn.Conv3D(128, kernel_size = 1, padding = 0, activation='relu'))\r\n            # Block 7\r\n            self.net = nn.HybridSequential(prefix='net')\r\n            self.net.add(nn.Conv3D(256, kernel_size = 3, padding = 1, activation='relu'))\r\n            self.net.add(nn.Conv3D(4096, kernel_size = 1, padding = 0, activation='relu'))\r\n            self.net.add(nn.Conv3D(4096, kernel_size = 1, padding = 0, activation='relu'))\r\n            self.net.add(nn.Conv3D(max_radius, kernel_size = 1, activation='sigmoid'))\r\n    def hybrid_forward(self, F, x):\r\n        x_c2 = self.c2(x)\r\n        x_c3 = self.c3(x_c2)\r\n        x_c4 = self.c4(x_c3)\r\n        x_u5 = self.c5(x_c4)\r\n        x4 = self.x4(x_c4) + x_u5\r\n        x_u4 = self.u4(x4)\r\n        x3 = self.x3(x_c3) + x_u4\r\n        x_u3 = self.u3(x3)\r\n        x2 = self.x2(x_c2) + x_u3\r\n        res = self.net(x2)\r\n        return res \r\n```"", ""That's weird. Your code should perform exactly the same as writing in pure symbols. Is this how things work out for HybridBlock @piiswrong ?"", 'I never gained any performance by using Hybrid. Even in the vgg+fcn case.', ""The default data permutation of tensorflow is NHWC, but that of mxnet is NCHW. That's the different.\r\nTurn CUDNN on may notably reduce memory comsumption.\r\nI think you can compare the memory comsumption in CPU mode."", 'My observation is that if the forward computation is straight forward, then the consumption of GPU memory is almost the same (gluon vs keras+tf). But for the fully connected network, the forward computation is not straight forward, that might be the cause? ', 'There are two possible memory issues here with regards to autograd. (1) unnecessary forward data is saved, which should be fixed by https://github.com/apache/incubator-mxnet/commit/7d6385a515dbda096560271628abf34e91e9be63 ; (2) backward memory cannot reuse forward memory since autograd requires a standalone backward graph to be executed. I would try two things:\r\n(1) Make sure that using pure symbols give the same memory consumption as tf+keras. For example, you can try use SymbolBlock.\r\n(2) Do forward with autograd turned on, but without calling ""compute_gradient"". In this case, the forward data required by backward will be saved.\r\n\r\nIf both (1) and (2) have the same memory consumption compared with tf+keras, then the reason might due to forward and backward memory cannot be reused in autograd mode.', 'I tried keras+mxnet. For keras+mxnet, I can set batch_size = 20, but for keras+tf, I can set batch_size = 32.', '@jermainewang How to do (2)?', '@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', 'Does anyone know the status of this issue?', 'Any update on this?', 'I’m comparing memory usage in symbolic mode. Will also take a look at gluon memory soon ', '@eric-haibin-lin - Any comment on this issue and next steps? Any action items left here?', ""Symbolic mem usage was improved in https://github.com/apache/incubator-mxnet/pull/11142. \r\nI didn't look at gluon but @piiswrong made a few improvement already. "", 'Resolving in favor of broader Gluon memory optimization effort - https://github.com/apache/incubator-mxnet/issues/12226\r\n\r\nPlease reopen if closed in error.']",[],[],1,0
16,incubator-mxnet,5158,closed,Distributed training: Speed extremely slow,"## Environment info
Operating System: Centos 7.0
Package used (Python/R/Scala/Julia): Python
MXNet version: 0.93
Python version and distribution: 2.7

We are testing the distributed train over multi-machine mxnet.  We compile Mxnet with parameter ""USE_DIST_KVSTORE=1"" , and successful run train a MLP on mnist.   But we found that the speed of distributed training was unusually slow compared to the speed of stand-alone training.

Stand-alone commands and speed：

INFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus=None, kv_store='device', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, monitor=0, network='mlp', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)
INFO:root:Epoch[0] Batch [100]  Speed: 21875.54 samples/sec     Train-accuracy=0.771040
INFO:root:Epoch[0] Batch [200]  Speed: 21260.40 samples/sec     Train-accuracy=0.913906
INFO:root:Epoch[0] Batch [300]  Speed: 21302.58 samples/sec     Train-accuracy=0.933750
INFO:root:Epoch[0] Batch [400]  Speed: 21216.02 samples/sec     Train-accuracy=0.936875
INFO:root:Epoch[0] Batch [500]  Speed: 22835.21 samples/sec     Train-accuracy=0.933594
INFO:root:Epoch[0] Batch [600]  Speed: 21612.71 samples/sec     Train-accuracy=0.947500
INFO:root:Epoch[0] Batch [700]  Speed: 23362.35 samples/sec     Train-accuracy=0.954375
INFO:root:Epoch[0] Batch [800]  Speed: 21683.75 samples/sec     Train-accuracy=0.954219
INFO:root:Epoch[0] Batch [900]  Speed: 21656.14 samples/sec     Train-accuracy=0.955781
INFO:root:Epoch[0] Train-accuracy=0.958615
INFO:root:Epoch[0] Time cost=2.804
INFO:root:Epoch[0] Validation-accuracy=0.957803

Command and speed of distributed training on local machine by using two workers:

INFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus=None, kv_store='dist_sync', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, monitor=0, network='mlp', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)
INFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus=None, kv_store='dist_sync', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, monitor=0, network='mlp', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)
INFO:root:Epoch[0] Batch [100]  Speed: 2580.90 samples/sec      Train-accuracy=0.104425
INFO:root:Epoch[0] Batch [100]  Speed: 2574.24 samples/sec      Train-accuracy=0.096689
INFO:root:Epoch[0] Batch [200]  Speed: 4408.62 samples/sec      Train-accuracy=0.093594
INFO:root:Epoch[0] Batch [200]  Speed: 4399.50 samples/sec      Train-accuracy=0.099531
INFO:root:Epoch[0] Batch [300]  Speed: 3343.81 samples/sec      Train-accuracy=0.095469
INFO:root:Epoch[0] Batch [300]  Speed: 3342.38 samples/sec      Train-accuracy=0.097344
INFO:root:Epoch[0] Batch [400]  Speed: 3247.69 samples/sec      Train-accuracy=0.096250
INFO:root:Epoch[0] Batch [400]  Speed: 3245.97 samples/sec      Train-accuracy=0.104531
INFO:root:Epoch[0] Batch [500]  Speed: 3364.46 samples/sec      Train-accuracy=0.102188
INFO:root:Epoch[0] Batch [500]  Speed: 3364.97 samples/sec      Train-accuracy=0.098437
INFO:root:Epoch[0] Batch [600]  Speed: 3729.89 samples/sec      Train-accuracy=0.097500
INFO:root:Epoch[0] Batch [600]  Speed: 3732.76 samples/sec      Train-accuracy=0.097812
INFO:root:Epoch[0] Batch [700]  Speed: 5105.08 samples/sec      Train-accuracy=0.087969
INFO:root:Epoch[0] Batch [700]  Speed: 5097.00 samples/sec      Train-accuracy=0.104375
INFO:root:Epoch[0] Batch [800]  Speed: 3931.05 samples/sec      Train-accuracy=0.099062
INFO:root:Epoch[0] Batch [800]  Speed: 3930.63 samples/sec      Train-accuracy=0.101406
INFO:root:Epoch[0] Batch [900]  Speed: 3763.65 samples/sec      Train-accuracy=0.098906
INFO:root:Epoch[0] Batch [900]  Speed: 3758.21 samples/sec      Train-accuracy=0.099531
INFO:root:Epoch[0] Train-accuracy=0.104307
INFO:root:Epoch[0] Time cost=16.560
INFO:root:Epoch[0] Train-accuracy=0.099662
INFO:root:Epoch[0] Time cost=16.584
INFO:root:Epoch[0] Validation-accuracy=0.098029
INFO:root:Epoch[0] Validation-accuracy=0.098029

Command and speed of distributed training on two computers(with same hardware configration):

INFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus=None, kv_store='dist_sync', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, monitor=0, network='mlp', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)
INFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus=None, kv_store='dist_sync', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, monitor=0, network='mlp', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)
INFO:root:Epoch[0] Batch [100]  Speed: 614.03 samples/sec       Train-accuracy=0.097463
INFO:root:Epoch[0] Batch [100]  Speed: 613.66 samples/sec       Train-accuracy=0.096225
INFO:root:Epoch[0] Batch [200]  Speed: 577.24 samples/sec       Train-accuracy=0.097812
INFO:root:Epoch[0] Batch [200]  Speed: 576.24 samples/sec       Train-accuracy=0.096250
INFO:root:Epoch[0] Batch [300]  Speed: 609.78 samples/sec       Train-accuracy=0.094531
INFO:root:Epoch[0] Batch [300]  Speed: 610.73 samples/sec       Train-accuracy=0.098125
INFO:root:Epoch[0] Batch [400]  Speed: 624.24 samples/sec       Train-accuracy=0.100000
INFO:root:Epoch[0] Batch [400]  Speed: 623.74 samples/sec       Train-accuracy=0.100625
INFO:root:Epoch[0] Batch [500]  Speed: 642.81 samples/sec       Train-accuracy=0.096719
INFO:root:Epoch[0] Batch [500]  Speed: 643.28 samples/sec       Train-accuracy=0.099531
INFO:root:Epoch[0] Batch [600]  Speed: 613.65 samples/sec       Train-accuracy=0.097187
INFO:root:Epoch[0] Batch [600]  Speed: 613.63 samples/sec       Train-accuracy=0.096406
INFO:root:Epoch[0] Batch [700]  Speed: 626.13 samples/sec       Train-accuracy=0.106875
INFO:root:Epoch[0] Batch [700]  Speed: 626.15 samples/sec       Train-accuracy=0.096562
INFO:root:Epoch[0] Batch [800]  Speed: 621.21 samples/sec       Train-accuracy=0.098437
INFO:root:Epoch[0] Batch [800]  Speed: 620.83 samples/sec       Train-accuracy=0.099687
INFO:root:Epoch[0] Batch [900]  Speed: 589.75 samples/sec       Train-accuracy=0.098281
INFO:root:Epoch[0] Batch [900]  Speed: 589.72 samples/sec       Train-accuracy=0.104844
INFO:root:Epoch[0] Train-accuracy=0.101351
INFO:root:Epoch[0] Time cost=98.129
INFO:root:Epoch[0] Train-accuracy=0.097551
INFO:root:Epoch[0] Time cost=98.144
INFO:root:Epoch[0] Validation-accuracy=0.098029
INFO:root:Epoch[0] Validation-accuracy=0.098029
INFO:root:Epoch[1] Batch [100]  Speed: 639.28 samples/sec       Train-accuracy=0.097308
INFO:root:Epoch[1] Batch [100]  Speed: 640.32 samples/sec       Train-accuracy=0.096844

We do not know why the speed so slow in distributed training , someone can help us? 
Thanks",,"['please try a larger workload, such as `train_cifar10`. and also there are some suggestions: https://github.com/mli/mxnet/tree/master/example/image-classification#speed', ""@mli Let's add a warning somewhere to tell people training small networks on multiple machines doesn't make sense."", 'good idea.', 'I am experimenting with MXNMT from https://github.com/magic282/MXNMT.\r\nThe training data is 1million. I have 2 machines each with 8 GPUs (I only use the first 6).\r\n\r\nWhen I launch the job with `/path/to/launch.py -n 2 --launcher ssh -H hosts python main.py`, and `batch_size=360(each gpu 60)`, `kvstore=dist_sync`, the performance is:\r\n![image](https://cloud.githubusercontent.com/assets/6084282/23505194/7cd63724-ff7d-11e6-81ea-284776b142c3.png)\r\n\r\nWhen with `/path/to/launch.py -n 2 -s 4 --launcher ssh -H hosts python main.py`, the performance is:\r\n![image](https://cloud.githubusercontent.com/assets/6084282/23505240/b004e622-ff7d-11e6-8b22-2b53f5e1d015.png)\r\n\r\nWhen with `/path/to/launch.py -n 2 -s 6 --launcher ssh -H hosts python main.py`, the performance is:\r\n![image](https://cloud.githubusercontent.com/assets/6084282/23505277/dbc8b950-ff7d-11e6-842d-3fb83d36ba23.png)\r\n\r\nMy question is how to set server number, and among these servers, which are level 1 servers, which are level 2 servers (According to https://github.com/dmlc/mxnet/issues/797).']",[],"['python train_mnist.py', 'launch.py -n 2 --launcher local python train_mnist.py --kv-store dist_sync', 'launch.py -n 2 --launcher ssh -H hosts python train_mnist.py --kv-store dist_sync']",1,0
17,incubator-mxnet,938,closed,Training accuracy issue,"New to MxNet. I've set up and tested the package on three different systems, an CPU-only Linux VM, an CPU-only Windows Server and a GPU-based windows PC.

The sample I'm using is  **example/notebooks/cifar10-recipe.ipynb**

When comparing the performance across all three systems, I noticed that during the initial training ([12] in **cifar10-recipe.ipynb**), the train-accuracy and validation-accuracy I got is around 0.4~0.5, which is pretty far from the 65% accuracy as the documentation stated. 
Here's an example output during my test on an GPU-based machine.



What is causing this difference between my test and the one in the document when it's using the same code to test the same data set? 

And also the documentation says ""our model is able to achieve about 65% accuracy on testset(If not, try more times)"", what does this ""try more times"" mean? 

Thanks
",,"['@HaoTang1 ""try more times"" was added by me. It means to try to train more times from scratch. I tested that example and got accuracy around 60%, then I  tried about 3 more times to get that accuracy.  \n\nI think it\'s due to different initialization.\n', ""@wangg12  Thanks. Got the accuracy raised to 0.72 after training 3 more times as well. \n\nBut what's the reason my accuracy is lower than the documentation shows after the first epoch?\n"", ""@HaoTang1 Not sure. But I think it doesn't matter since 1 epoch is far from convergence.\n"", 'it may due to random() gives different values across different platforms, which could affect the first 1 or 2 epochs a lot\n']",['\nINFO:root:Start training with [gpu(0)]\nINFO:root:Iter[0] Batch [50]    Speed: 561.85 samples/sec\nINFO:root:Iter[0] Batch [100]   Speed: 540.63 samples/sec\nINFO:root:Iter[0] Batch [150]   Speed: 543.20 samples/sec\nINFO:root:Iter[0] Batch [200]   Speed: 543.80 samples/sec\nINFO:root:Iter[0] Batch [250]   Speed: 543.89 samples/sec\nINFO:root:Iter[0] Batch [300]   Speed: 542.24 samples/sec\nINFO:root:Iter[0] Batch [350]   Speed: 543.71 samples/sec\nINFO:root:Epoch[0] Train-accuracy=0.424153\nINFO:root:Epoch[0] Time cost=92.967\nINFO:root:Epoch[0] Validation-accuracy=0.475771\n'],[],1,0
18,incubator-mxnet,5035,closed,High memory usage with bucketing,"When using the bucketing module I'd expect the memory usage to be about the same as when using the normal module unrolled to the largest bucket size. However we observe unusually high GPU memory usage in MxNet when using multiple buckets. 
This can be reproduced/observed with the lstm_bucketing.py example from the latest MXNet commit as such:
in examples/rnn/lstm_bucketing.py change:



When using multiple buckets (see line 49), overall memory usage is 1419MB.
When changing line 49 to only use a single bucket (e.g. 60), overall memory usage is only 1185MB.

It should be noted that the initial memory usage for bucketing is the same (1185MB), but after a couple of batches the memory usage increases. We suspect this is due to the BucketingModule binding another sub module when a new bucket size is given by the data iterator and memory sharing across modules isn't working properly.

While for this model the difference is only 300 MB, we observed much higher differences in practice, making it difficult to train any reasonably sized model with bucketing.

Note: the default bucket key is of course the largest bucket.
",,"[""Diving a little deeper into this issue. This is my current understanding of memory sharing:\r\n\r\n* python land: BucketingModule\r\n  * BucketingModule has a _curr_module member that is passed to module.bind\r\n  * initially this member is the default module, however each call to self.switch_bucket will set it to a different module\r\n* C++, GraphExecutor class\r\n  * GraphExecutor::Init gets a shared_exec that is the executor of the shared module pass to module.bind\r\n  * GraphExecutor::InitDataEntryMemory gets the data_pool_ member of the shared executor\r\n  * data_pool_ is a vector of ndarrays\r\n  * After GraphExecutor::InitDataEntryMemory is called data_pool_ will contain all ndarrays borrowed from the shared executor and also potentially new ndarrays it created. Important: As no all shapes fit necessarily it might have fewer entries than the original data_pool_ coming from the shared executor.\r\n\r\nSo with the above one potential problem occurs when we first see a small bucket and then a larger bucket subsequently. This is because in this scenario _curr_module in BucketingModule will point to the small bucket, which has a data_pool_ that is smaller than the data_pool_ of the default bucket module.\r\n\r\nGiven this I tried to modify BucketingModule to always pass the default module as shared module (as my assumption was that the default module will always occupy more space than any given module). Now this actually works, but only when turning off all memory optimizations (NNVM_EXEC_ENABLE_INPLACE=false NNVM_EXEC_MATCH_RANGE=0). If they these are not turned off we still allocate new memory in InitDataEntryMemory as the shapes across buckets don't match up anymore."", 'Thanks for the analysis. Haibin will be working on this.\r\n\r\nIn the mean time the cudnn bucketing example should work better since there are less memory blobs allocated https://github.com/dmlc/mxnet/pull/5004/files\r\n\r\n@eric-haibin-lin \r\n\r\nalso see https://github.com/dmlc/mxnet/issues/4795', '@tdomhan I have met the same problem. For the nnvm version, even the default bucket key is the largest, some memory will be still allocated with new smaller keys, (may be caused by the memory plan strategy). So the memory will increase after some batches.\r\nMy current solution is:\r\n1. set the gpu storage to NaiveStorage\r\n2. bind a new executor for each key, and release the previous one. only keep the largest key executor\r\n@piiswrong @eric-haibin-lin \r\nHope this problem can be solved soon', ""I'm glad I'm not the only one who has this issue. I still need to check whether this is problem does not exist in 0.8. One potentially interesting thing is that in 0.8 the [allocator](https://github.com/dmlc/mxnet/blob/v0.8.0/src/symbol/graph_memory_allocator.cc) has access to the shared_mem_, whereas in [nnvm](https://github.com/dmlc/nnvm/blob/master/src/pass/plan_memory.cc) it doesn't actually when planning the memory."", 'Problem still exits in no nnvm version, but the increasing is not very obvious. ', ""Here are the counts of different ndarray sizes in the default bucket's memory pool (for some arbitrary model and not the RNN example, but that shouldn't change the point):\r\n```\r\n        {0: 4,\r\n         256: 1,\r\n         512: 4,\r\n         1024: 2,\r\n         16.384: 836,\r\n         30.720: 121,\r\n         32.768: 542,\r\n         49.152: 59,\r\n         65.536: 179,\r\n         131.072: 59,\r\n         983040: 2,\r\n         1.966.080: 5,\r\n         30.842.880: 2}\r\n```\r\nvs the ones from a different bucket of smaller size.\r\n```\r\n       {0: 3,\r\n         256: 1,\r\n         512: 5,\r\n         10.240: 38,\r\n         16.384: 279,\r\n         32.768: 160,\r\n         49.152: 19,\r\n         65.536: 40,\r\n         131.072: 40,\r\n         327.680: 3,\r\n         655.360: 23,\r\n         10.280.960: 2}\r\n```\r\nThe meaning of the above number is e.g. that for the default bucket we got 1 ndarray of size 256 (bytes). Now one can see that they are not really compatible with each other, as for example the 23 655360 byte arrays can't be fit into the ndarrays of the default bucket. This is probably due to the memory planning being done independently leading to incompatible sets of ndarrays.\r\n"", ""@tdomhan Thanks for the analysis. The problem with bucketing is that for each bucket, currently we first plan its memory unaware of the shared memory pool information. After the memory is planned, we try to reuse what's available in the shared memory pool. Because graph of big bucket and small bucket don't necessarily produce the same memory plan, it doesn't guarantee that no extra memory is allocated. I'm working on this to fix it. "", ""set the storage type to naive and don't keep the executor for each bucket key will  help. The memory won't increase though floating in small range @tdomhan \r\n@eric-haibin-lin  I don't understand the purpose of the PooledStorage, since the shared executor is some kind of pool. Is that useful for the temp space allocated by forward/backward pass?"", ""as the naive storage manager will do a cudaMalloc with each ndarray created (unlike the PooledStorage) I'm guessing this will decrease speed quite a bit. I don't have any numbers on this though. What's your experience with that?\r\nWhy aren't you using the PooledStorage in combination with creating a new executor? That should also work, but avoid the cudaMallocs. You would still have the overhead of creating a new executor per batch. Ideally we'd be able to fix the sharing of memory between different graphs in order to avoid both the overhead of repeatably creating executors as well as repeatedly calling cudaMalloc.\r\n\r\nFrom my understanding PooledStorage is useful for use cases where you create many short lived executors (e.g. minpy or your use case) in order to reuse memory from previously created ndarrays. For the memory sharing between different buckets the ndarrays haven't been deallocated yet, yet we still want to share them between different graphs."", ""@feiyulv Regarding PooledStorage, I believe its purpose it to avoid excessive cudaMalloc for each of the NDArrays created. We should try to reuse the NDArray malloc'ed if any in the pool. Excessive cudaMallocs could lead to much slower run time performance, depending on the workload. \r\n\r\n"", ""@eric-haibin-lin @tdomhan thx\r\n@tdomhan  My experience is it affects a little speed with NaiveStorage, since we use a default shared executor for  different keys, only a small amount of memory will be allocated for a new executor. PooledStorage with new executor won't work. The reason of memory increasing is the memory allocated by new executor using PooledStorage can't be released, and  can't be reused for the future executors. "", ""Found some inefficiency in the system and made a few changes related to memory allocation in MXNet: \r\n\r\n1.  In the bucketing module, `curr_module` is passed in as the `shared_module`, but instead the module with default_bucket_key should be passed. [Link](https://github.com/eric-haibin-lin/mxnet/blob/memory/python/mxnet/module/bucketing_module.py#L214).  \r\n2.  When the memory pool of the default bucket module doesn't hold sufficient memory for other bucket to bind, extra NDArrays are allocated. But these NDArrays are not added back to the pool.  [Link](https://github.com/eric-haibin-lin/mxnet/blob/memory/src/executor/graph_executor.cc#L517)\r\n3.  In the `PlanMemory` pass in nnvm, the memory allocator is not aware of the allocated memory pool of the shared module. [Link](https://github.com/eric-haibin-lin/nnvm/blob/memory/src/pass/plan_memory.cc#L108)\r\n4. The `NNVM_EXEC_MATCH_RANGE` variable has impact on the result of memory planning. Instead of letting the user to choose it, the backend could just try different values and choose the best one to automate the process. Some users are not even aware of this variable. [Link](https://github.com/eric-haibin-lin/nnvm/blob/memory/src/pass/plan_memory.cc#L299)\r\n\r\nFixing 1 and 2 reduce the memory quite a lot, while 3 and 4 bring marginal reduction if 1 and 2 are fixed (5% ~ 10%). \r\n\r\n\r\n\r\nBenchmark result on LSTM workload: \r\n\r\n| Version ( | 22673b6 (baseline) | 1 | 1 + 2 | 1 + 2 + 3 | 1 + 2 + 3 + 4 |\r\n| --- | --- | --- | --- | --- | --- | \r\n| Memory (MB) | > 12288 (Out of Memory) | 4297 | 1956 | 1817 | 1754\r\n\r\nBenchmark result on Neural Style workload \r\n\r\n| Version ( | 22673b6 (baseline) | 1 + 2 + 3 + 4 |\r\n| --- | --- | --- | \r\n| Memory (MB) | > 12288 (Out of Memory) | 2034 |\r\n\r\n* LSTM configuration:  python lstm_bucketing.py --gpus=0 --num-layers=4 --num-hidden=1024 --num-embed=512 --num-epochs=1\r\n* Neural style uses default configuration\r\n\r\n@whaozl  @tdomhan @piiswrong  @tqchen @mli "", 'How long does 4 take?', '@eric-haibin-lin  the bug is fixed ? the new version is ? I check the version which you said and take a look.', ""@piiswrong \r\nI profiled the total time spent on `switch_bucket` with 4 turned on. It introduces less than 1 second overhead per epoch for this LSTM network. The total training time per epoch is around 5 minutes. \r\n\r\n@whaozl I'll add one more test case before merging this in. Will keep you posted."", ""The memory planning is only run once per bucket, no? So the overhead shouldn't be per epoch but just a fixed time at the beginning of training. I assume that for a use case like minpy or any other use case where you dynamically construct a graph the overhead should be much higher. So does it take about 1s to do the sweep?"", ""Domhan, yes you're right. I shouldn't have measured it on a per epoch\nbasis. The estimate is 1 extra second to do the sweep for ~40 buckets. This\nis by default turned off in the PR, I think it's more important to get the\nfix for 1&2 into master. I'll investigate 4 more, and turn it on only if\nI'm confident it's gonna benefit with low overhead.\n\n\nOn 2017年2月26日 周日 at 12:04 Tobias Domhan <notifications@github.com> wrote:\n\n> The memory planning is only run once per bucket, no? So the overhead\n> shouldn't be per epoch but just a fixed time at the beginning of training.\n> I assume that for a use case like minpy or any other use case where you\n> dynamically construct a graph the overhead should be much higher. So does\n> it take about 1s to do the sweep?\n>\n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dmlc/mxnet/issues/5035#issuecomment-282582850>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AFSeqPaseYZL0LXMwwGVpM4bWb7sSjZZks5rgdrTgaJpZM4MCDXR>\n> .\n>\n-- \nBest Regards,\nHaibin Lin\n\nMaster of Science in Computer Science\nSchool of Computer Science\nCarnegie Mellon University\n\n+1 (412) 478-1556\nwww.linhaibin.com\n"", 'If you are building graphs for trees for parsing then you can have a different graph for every batch of data. In that case 1/40s per bucket overhead is non negligible.\r\n\r\nI think a better strategy is to run more graph optimization for the first 100-1000 bind then turn off', ""One other problem other than what was listed in 1-4 is the order of allocations in GraphExecutor::InitDataEntryMemory. Arrays were allocated in the order they're encountered in the graph. This could lead to situations where large ndarrays from the shared pool were used for much smaller ndarrays. Allocating the largest ndarrays first will further reduce the memory consumption. Here's a PR with the change:\r\nhttps://github.com/dmlc/mxnet/pull/5161"", ""Yeah that's a good point! I actually made the same change in my PR over the weekend. https://github.com/dmlc/mxnet/pull/5133/files#diff-d8b5a5b027d00584737fb6486cba38b9R488 \r\n"", ""Oh ok. I wasn't aware of that. Glad we came to similar conclusions and\nlooking forward to seeing the changes merged to master :)\n\nOn Mon, 27 Feb 2017 at 18:51, Haibin Lin <notifications@github.com> wrote:\n\n> Yeah that's a good point! I actually made the same change in my PR over\n> the weekend.\n> https://github.com/dmlc/mxnet/pull/5133/files#diff-d8b5a5b027d00584737fb6486cba38b9R488\n>\n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dmlc/mxnet/issues/5035#issuecomment-282796089>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AAWM2U3ygZbFdi468cYdFeiVLkUnFJ-kks5rgw0zgaJpZM4MCDXR>\n> .\n>\n"", 'are there any remaining blockers for merging https://github.com/dmlc/mxnet/pull/5133 ?']",['\r\nnum-layers to 4\r\nnum-hidden to 1024\r\nnum-embed to 512\r\n'],[],1,1
19,incubator-mxnet,15148,open,Very Large CPU RAM Memory Consumption (>1GB),"## Description
Mxnet consumes nearly 2GB CPU RAM even when loading a relatively small model (e.g. Resnet-18) directed on GPU (). From what I understand, there is no real need to use so much CPU memory when the model is running on GPU.

This issue is extremely prohibitive when trying to run multiple processes with mxnet on the same machine, and IMO gives it a significant disadvantage compared to other frameworks for being used in AI production systems.

## Environment info


Package used (Python/R/Scala/Julia):
I'm using Python3

## Build info
mxnet installed using pip3

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. Run the following code

2. check process memory (run top, shift M to sort processes by memory usage)
3. memory usage is about ~1.5-2GB RAM


",Memory Performance,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Performance', '@mxnet-label-bot Add [Performance, Memory]', '@rvardimon thanks for raising the issue. Have you looked at the profiler output from mxnet , when you load the model params it initially loads on cpu so you may see a spike but then it should be released after set_params is called. if not module api is adding some overhead which should be looked at: @karan6181 ', ""- I see roughly 2 GB of CPU memory usage when I ran the user script and also with the below minimum reproducible script using Gluon.\r\n\r\n- ```python\r\n  import mxnet as mx\r\n  import gluoncv\r\n  from time import sleep\r\n  \r\n  net = gluoncv.model_zoo.get_model('cifar_resnet20_v1', pretrained=True, ctx=mx.gpu())\r\n  net.hybridize()\r\n  \r\n  #print(net.summary(mx.nd.ones((1, 3,28,28), ctx=mx.gpu())))\r\n  sleep(20)\r\n  ```\r\n\r\n- I tried using different MXNet version but the CPU memory usage keeps on increasing. Not Much difference in memory consumption if using with/without MKL.\r\n\r\n- ```bash\r\n  # P3.16xLarge\r\n  # DLAMI V24\r\n  \r\n  MXNet-cu92: 1.3.1: 2.15 GB\r\n  MXNet-cu92: 1.4.1: 2.3 GB\r\n  MXNet-cu92: 1.5.0: 2.55 GB\r\n  MXNet-cu92: 1.6.0(1.6.0b20190906): 2.9 GB \r\n  ```\r\n\r\n- If I run the same above script on CPU context, then the memory usage is approx. 100 MB."", 'We ( I and @karan6181  ) looked at a bunch of things to understand where the overhead is coming from. We looked at Resource Request and attach op resources pass. We looked at object pool in threaded engine, and at turning off OPENMP and MKLDNN and checking, but the overhead is still there. We looked at the overhead caused by different arrays in the module api.  Overhead is not coming from any of these areas.\r\n\r\nWe also check that increase in memory consumption happens at the bind stage and probably coming from somewhere in the graph executor. Next step is to check this in 1.2.1 to see if the increase happened in 1.3.1.', ""    19   1488.9 MiB    252.7 MiB           sym, arg_params, aux_params = mx.model.load_checkpoint(prefix, epoch)\r\n    20   1489.0 MiB      0.1 MiB           all_layers = sym.get_internals()\r\n    21   1489.1 MiB      0.1 MiB           sym = all_layers['fc1_output']\r\n    22   1489.2 MiB      0.1 MiB           self.model = mx.mod.Module(symbol=sym, context=ctx, label_names=None)\r\n    23   3331.3 MiB   1842.2 MiB           self.model.bind(data_shapes=[('data', (1, 3, 112, 112))])\r\n    24   3333.9 MiB      2.5 MiB           self.model.set_params(arg_params, aux_params)\r\n\r\nI used mxnet-cu100mkl        1.4.1 in win10. ""]","[""\r\n/usr/bin/python3.6 /home/ran-face/src/CameraResearch/workspace/mxnet_diagnose.py\r\n----------Python Info----------\r\nVersion      : 3.6.7\r\nCompiler     : GCC 8.2.0\r\nBuild        : ('default', 'Oct 22 2018 11:32:17')\r\nArch         : ('64bit', 'ELF')\r\n------------Pip Info-----------\r\nVersion      : 9.0.1\r\nDirectory    : /usr/lib/python3/dist-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.3.1\r\nDirectory    : /usr/local/lib/python3.6/dist-packages/mxnet\r\nCommit Hash   : 19c501680183237d52a862e6ae1dc4ddc296305b\r\n----------System Info----------\r\nPlatform     : Linux-4.15.0-45-generic-x86_64-with-Ubuntu-18.04-bionic\r\nsystem       : Linux\r\nnode         : ranface-Lenovo-Y720-15IKB\r\nrelease      : 4.15.0-45-generic\r\nversion      : #48-Ubuntu SMP Tue Jan 29 16:28:13 UTC 2019\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:        x86_64\r\nCPU op-mode(s):      32-bit, 64-bit\r\nByte Order:          Little Endian\r\nCPU(s):              8\r\nOn-line CPU(s) list: 0-7\r\nThread(s) per core:  2\r\nCore(s) per socket:  4\r\nSocket(s):           1\r\nNUMA node(s):        1\r\nVendor ID:           GenuineIntel\r\nCPU family:          6\r\nModel:               158\r\nModel name:          Intel(R) Core(TM) i7-7700HQ CPU @ 2.80GHz\r\nStepping:            9\r\nCPU MHz:             2411.711\r\nCPU max MHz:         3800.0000\r\nCPU min MHz:         800.0000\r\nBogoMIPS:            5616.00\r\nVirtualization:      VT-x\r\nL1d cache:           32K\r\nL1i cache:           32K\r\nL2 cache:            256K\r\nL3 cache:            6144K\r\nNUMA node0 CPU(s):   0-7\r\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp flush_l1d\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0694 sec, LOAD: 0.9665 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0841 sec, LOAD: 1.2019 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0988 sec, LOAD: 0.9435 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0708 sec, LOAD: 1.2242 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0637 sec, LOAD: 1.3118 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0499 sec, LOAD: 0.3116 sec.\r\n\r\nProcess finished with exit code 0\r\n"", ""\r\nimport mxnet as mx\r\nimport time\r\n\r\nif __name__ == '__main__':\r\n\r\n    path='http://data.mxnet.io/models/imagenet/'\r\n    [mx.test_utils.download(path+'resnet/18-layers/resnet-18-0000.params'),\r\n     mx.test_utils.download(path+'resnet/18-layers/resnet-18-symbol.json'),\r\n     mx.test_utils.download(path+'synset.txt')]\r\n\r\n    ctx = mx.gpu()\r\n\r\n    sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-18', 0)\r\n    mod = mx.mod.Module(symbol=sym, context=ctx, label_names=None)\r\n    mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))],\r\n             label_shapes=mod._label_shapes)\r\n    mod.set_params(arg_params, aux_params, allow_missing=True)\r\n\r\n    time.sleep(100)\r\n""]",['ctx=mxnet.gpu()'],1,0
20,incubator-mxnet,16687,closed,[Performance Regression] Scala/Java SSD inference,"## Description
After #16602 merge, java/scala SSD GPU inference latency increased by 20x (from 70ms to 1400ms)

### Steps to reproduce
(Paste the commands you ran that produced the error.)

@PatricZhao @ZhennanQin
Thanks in advance & Happy Halloween!",Bug MKLDNN,['Thanks to reporting the issue ~~~\r\n@ZhennanQin  will look into the issue. \r\n'],"['\r\n1. lanuch an ec2 instance (Deep Learning Base AMI (Ubuntu 16.04) Version 20.0) with at least one gpu \r\n2. ssh into the instance\r\n3. git clone --recursive https://github.com/apache/incubator-mxnet.git\r\n4. git clone https://github.com/andrewfayres/deeplearning-benchmark.git\r\n\r\n# dd4eaf5 is the first commit that introduces the regression\r\n# you can compare this &  bde443e which is the last commit without regression\r\n5. cd incubator-mxnet && git reset --hard dd4eaf5\r\n\r\n# build mxnet from source\r\n6. make -j$(nproc) USE_CUDA=1 USE_CUDA_PATH=/usr/local/cuda USE_CUDNN=1 USE_OPENMP=1 USE_MKLDNN=1 USE_OPENCV=1\r\n7. cd scala-package\r\n8. sudo apt install maven\r\n\r\n# this will build & deploy all the artifacts into local repository\r\n9. mvn deploy -Drepo_url=file://$HOME/.m2/repository\r\n10. cd ~/deeplearning-benchmark/scala-mxnet/java-bm\r\n11. make change to pom.xml in current directory\r\n\r\nreplace this section\r\n<repositories>\r\n    <repository>\r\n      <id>Apache Snapshot</id>\r\n      <url>https://repository.apache.org/content/groups/snapshots</url>\r\n    </repository>\r\n  </repositories>\r\nwith\r\n<repositories>\r\n     <repository>\r\n       <id>Apache Snapshot</id>\r\n       <url>file:/home/ubuntu/.m2/repository</url>\r\n     </repository>\r\n   </repositories>\r\n\r\nIt then will use the local repo instead of our public maven repo\r\n\r\n12. make change to bin/run_ssd.sh\r\n\r\nreplace MXNET_VERSION=""[1.5.0-SNAPSHOT,)""\r\nwith MXNET_VERSION=""[1.6.0-SNAPSHOT,)""\r\n\r\n# run the benchmark script in current directory (......./java-bm)\r\n13. bash bin/get_resnet50_ssd_data.sh && export SCALA_TEST_ON_GPU=1 && bash bin/run_ssd.sh gpu /tmp/resnet50_ssd/resnet50_ssd_model /tmp/resnet50_ssd/images/dog.jpg 4 500\r\n']",[],1,1
21,incubator-mxnet,3378,closed,"Train accuracy high, low validation accuracy","I am trying do the inception-bn-full on my own dataset. (near 1400w and 5190 classes).

python train_imagenet.py --network inception-bn-full --batch-size 100 --lr 0.05 --lr-factor 0.9 --gpus 2,3 --num-epoch 60 --data-dir /data5/rd/xiajizhong/parts_17kClasses/ --train-dataset small_rec/ --val-dataset small_rec_val/ --num-examples=14040000

and, when use the latest mxnet I get bad validation accuracy. 

> 2016-09-24 02:49:24,212 Node[0] Epoch[0] Batch [140400] Speed: 47.30 samples/sec    Train-accuracy=0.546400
> 2016-09-24 02:49:24,213 Node[0] Epoch[0] Batch [140400] Speed: 47.30 samples/sec    Train-top_k_accuracy_5=0.787400
> 2016-09-24 02:49:24,213 Node[0] Epoch[0] Batch [140400] Speed: 47.30 samples/sec    Train-top_k_accuracy_10=0.842400
> 2016-09-24 02:49:24,213 Node[0] Epoch[0] Batch [140400] Speed: 47.30 samples/sec    Train-top_k_accuracy_20=0.884800
> 2016-09-24 02:49:25,074 Node[0] Update[140401]: Change learning rate to 4.50000e-02
> 2016-09-24 02:49:31,389 Node[0] Epoch[0] Resetting Data Iterator
> 2016-09-24 02:49:31,390 Node[0] Epoch[0] Time cost=301141.343
> 2016-09-24 02:49:31,645 Node[0] Saved checkpoint to ""model/inception_bn_full_Vdian-0001.params""
> 2016-09-24 05:15:15,472 Node[0] Epoch[0] Validation-accuracy=**0.142758**
> 2016-09-24 05:15:15,472 Node[0] Epoch[0] Validation-top_k_accuracy_5=0.280551
> 2016-09-24 05:15:15,472 Node[0] Epoch[0] Validation-top_k_accuracy_10=0.350004
> 2016-09-24 05:15:15,472 Node[0] Epoch[0] Validation-top_k_accuracy_20=0.418618

But, I was doing the experiment well in the old version mxnet, which the validation accuracy is also very high near top1=50%, after one epoch. So I am wondering why this happened? I am not very clear about different changed in the new version mxnet. Is it caused by the Pooling layer behavior changed? 

and on the old version, the result below,

> 2016-06-10 10:26:15,591 Node[0] Epoch[0] Batch [140350] Speed: 50.40 samples/sec    Train-accuracy=0.406846
> 2016-06-10 10:27:53,871 Node[0] Epoch[0] Batch [140400] Speed: 50.88 samples/sec    Train-accuracy=0.406867
> 2016-06-10 10:27:53,875 Node[0] Update[140401]: Change learning rate to 4.05000e-01
> 2016-06-10 10:27:59,645 Node[0] Epoch[0] Resetting Data Iterator
> 2016-06-10 10:27:59,647 Node[0] Epoch[0] Train-accuracy=0.406869
> 2016-06-10 10:27:59,647 Node[0] Epoch[0] Time cost=258948.773
> 2016-06-10 10:28:01,107 Node[0] Saved checkpoint to ""model/vdian5190-0-0001.params""
> 2016-06-10 12:50:10,700 Node[0] Epoch[0] Validation-accuracy=**0.457665**
",,"['If you do not meet InferShape Error, then it should not be pooling issue. The most probable cause is BatchNorm layer, especially if you use fix_gamma.\n', '@winstywang you mean the BatchNorm layer changed in new version mxnet? Because I trained and  got good result both train and val in old version? Can you explain more specific?\n', '@George19890617 Yes, you had better double check it.\n', '@winstywang thanks so much for you time. \nI am turn back to the mxnet 0.5.0 is OK in training inception-bb-full. If you train successfully on the latest the mxnet, can you tell me more about your lr-schechulr? Actually, I set --lr 0.5 --lr-factor 0.9 --lr-factor-epoch 0.5 is OK in old one. \n', 'Please check the latest pre-trained model here. https://github.com/dmlc/mxnet/pull/3506\n']",[],[],1,1
22,incubator-mxnet,9396,closed,inference speed drop after updating mxnet from 0.10.0 to 1.0.0,"Hi, I just updated mxnet today from 0.10.0 to 1.0.0 in order to use some new features. Both versions are installed with pip like . However, after a detailed benchmark test, I observed a significant speed drop when running resnet inference especially when batch size is small. The result for resnet152 is like below (network json file is downloaded from [here](http://data.mxnet.io/models/imagenet/resnet/152-layers/resnet-152-symbol.json))





PS. I noticed that when batch size is small (i.e. batch_size=1), the GPU usage is 95~100% in mxnet 0.10.0 and 80-83% in mxnet 1.0.0 which means the GPU is not fully utilized at all.

Software env: Ubuntu 16.04, Python 3.5, CUDA 8.0, CUDNN 5.1.
GPU: GTX 1080 Ti.

I also test on a server with Titan XP and got a similar result. The speed test script is pasted below:
",Performance,"['might be related to #9055 \r\n', '@eric-haibin-lin , great to see this work. I will test the performance after it is merged.', '@nicklhy #9055 was merged. Can you please build latest and re-test?\r\n\r\n@eric-haibin-lin can you please label:\r\n- Pending Requester Info\r\n- Performance', '@lupesko , Hi, just made a test and the result is listed below:\r\n\r\n```\r\nMXNet version: 0.10.0\r\n########################################################\r\nspeed test for batch size: 1\r\n\tavg forward speed: 84.061132 samples/s\r\n\tavg forward time: mean = 0.011895 s, std = 0.000187 s\r\n########################################################\r\nspeed test for batch size: 4\r\n\tavg forward speed: 208.959420 samples/s\r\n\tavg forward time: mean = 0.019141 s, std = 0.000436 s\r\n########################################################\r\nspeed test for batch size: 16\r\n\tavg forward speed: 284.647810 samples/s\r\n\tavg forward time: mean = 0.056207 s, std = 0.001876 s\r\n########################################################\r\nspeed test for batch size: 64\r\n\tavg forward speed: 299.845795 samples/s\r\n\tavg forward time: mean = 0.213439 s, std = 0.004175 s\r\n########################################################\r\nspeed test for batch size: 128\r\n\tavg forward speed: 306.651349 samples/s\r\n\tavg forward time: mean = 0.417408 s, std = 0.008048 s\r\n```\r\n```\r\nMXNet version: 1.0.1\r\n########################################################\r\nspeed test for batch size: 1\r\n\tavg forward speed: 76.590411 samples/s\r\n\tavg forward time: mean = 0.013055 s, std = 0.000209 s\r\n########################################################\r\nspeed test for batch size: 4\r\n\tavg forward speed: 197.583762 samples/s\r\n\tavg forward time: mean = 0.020243 s, std = 0.000270 s\r\n########################################################\r\nspeed test for batch size: 16\r\n\tavg forward speed: 281.058522 samples/s\r\n\tavg forward time: mean = 0.056925 s, std = 0.000418 s\r\n########################################################\r\nspeed test for batch size: 64\r\n\tavg forward speed: 300.547282 samples/s\r\n\tavg forward time: mean = 0.212941 s, std = 0.002727 s\r\n########################################################\r\nspeed test for batch size: 128\r\n\tavg forward speed: 309.225150 samples/s\r\n\tavg forward time: mean = 0.413934 s, std = 0.001367 s\r\n```\r\nAs I mentioned [here](https://github.com/apache/incubator-mxnet/pull/9055), the inference speed of resnet152 did increased a lot when batch size is small, but still a bit lower than the 0.10.0 version. GPU usage are 100% in 0.10.0, 83% in 1.0.0, 95% in 1.0.1 respectively. By analyzing the CUDA calls, I noticed that the avg time cost of `cudaStreamSynchronize` in mxnet 1.0.1 is a bit larger than 0.10.0.\r\n```\r\n# mxnet 0.10.0\r\n# GPU usage: 99~100%\r\n==21421== API calls:\r\nTime(%)      Time     Calls       Avg       Min       Max  Name\r\n 52.04%  7.76526s      3691  2.1038ms  1.4510us  9.5652ms  cudaStreamSynchronize\r\n 21.31%  3.17943s    659205  4.8230us  3.3450us  1.2354ms  cudaLaunch\r\n 11.92%  1.77868s         4  444.67ms  60.328us  889.60ms  cudaStreamCreate\r\n```\r\n```\r\n==11655== API calls:\r\nTime(%)      Time     Calls       Avg       Min       Max  Name\r\n 53.84%  8.38694s      3695  2.2698ms  1.5780us  12.897ms  cudaStreamSynchronize\r\n 20.01%  3.11738s    661308  4.7130us  3.3310us  2.6520ms  cudaLaunch\r\n  7.98%  1.24364s        16  77.727ms  8.0110us  620.95ms  cudaStreamCreateWithFlags\r\n  4.59%  715.63ms       292  2.4508ms     346ns  176.42ms  cudaFree\r\n  4.52%  703.51ms       787  893.91us  160.25us  537.44ms  cudaMemGetInfo\r\n```\r\n\r\nWhen batch size is large enough (i.e. 64, 128), the new mxnet\'s performance looks good.\r\n\r\nIn conclusion, [#9055](https://github.com/apache/incubator-mxnet/pull/9055) fixed a large part of this problem, but I guess there still exists some other potential ""bugs"" that we should work on.', 'Hi @nicklhy what network are you using? Does it include any custom operators? ', '@eric-haibin-lin The above results are tested with a ResNet152 json file downloaded from [http://data.mxnet.io/models/imagenet/resnet/152-layers/resnet-152-symbol.json](http://data.mxnet.io/models/imagenet/resnet/152-layers/resnet-152-symbol.json).\r\n\r\nBTW, I also tested [ResNet101](http://data.mxnet.io/models/imagenet/resnet/101-layers/resnet-101-symbol.json) and got a similar result:\r\n```\r\nMXNet version: 0.10.0\r\n########################################################\r\nspeed test for batch size: 1\r\n\tavg forward speed: 116.469000 samples/s\r\n\tavg forward time: mean = 0.008585 s, std = 0.000308 s\r\n########################################################\r\nspeed test for batch size: 4\r\n\tavg forward speed: 293.537501 samples/s\r\n\tavg forward time: mean = 0.013625 s, std = 0.000497 s\r\n########################################################\r\nspeed test for batch size: 16\r\n\tavg forward speed: 407.152972 samples/s\r\n\tavg forward time: mean = 0.039295 s, std = 0.000929 s\r\n########################################################\r\nspeed test for batch size: 64\r\n\tavg forward speed: 432.887962 samples/s\r\n\tavg forward time: mean = 0.147841 s, std = 0.001603 s\r\n########################################################\r\nspeed test for batch size: 128\r\n\tavg forward speed: 443.354422 samples/s\r\n\tavg forward time: mean = 0.288704 s, std = 0.003057 s\r\n```\r\n```\r\nMXNet version: 1.0.1\r\n########################################################\r\nspeed test for batch size: 1\r\n\tavg forward speed: 109.414104 samples/s\r\n\tavg forward time: mean = 0.009137 s, std = 0.000553 s\r\n########################################################\r\nspeed test for batch size: 4\r\n\tavg forward speed: 288.660234 samples/s\r\n\tavg forward time: mean = 0.013856 s, std = 0.000231 s\r\n########################################################\r\nspeed test for batch size: 16\r\n\tavg forward speed: 412.575750 samples/s\r\n\tavg forward time: mean = 0.038778 s, std = 0.001016 s\r\n########################################################\r\nspeed test for batch size: 64\r\n\tavg forward speed: 447.079919 samples/s\r\n\tavg forward time: mean = 0.143147 s, std = 0.001947 s\r\n########################################################\r\nspeed test for batch size: 128\r\n\tavg forward speed: 458.120138 samples/s\r\n\tavg forward time: mean = 0.279399 s, std = 0.004146 s\r\n```', 'can you try setting OMP_NUM_THREADS=1 in the environment and try again? does it speed up?', '(set before running python)', '@cjolivier01 Same result after setting it. The GPU usage is still 93~95% when testing ResNet101 or ResNet152(batch_size=1). However, mxnet 0.10.0 can easily reach 99-100%.\r\n\r\nNotice there are no disk IO or image pre-processing operations in my speed test script. The bottleneck should be in GPU, or more specifically, `cudaStreamSynchronize`. I guess ""OMP_NUM_THREADS"" won\'t be able to solve this problem?', 'Apparently not -- was checking if something cpu-related was bottleneck but it seems not.', ""@nicklhy what happens if you call `mx.nd.waitall()` before all the forward calls, remove `output.wait_to_read()`, and call `mx.nd.waitall()` after all 100 batches are done? \r\nI don't know see any reason why streamSync becomes more expensive ... "", '@eric-haibin-lin , Still the same result. There is always a small speed gap between mxnet 0.10.0 and the current version.', '@nicklhy I bisected the changes between 0.10.0 and 1.0 and found the following on a p2.xlarge(K80) instance. The commits are patched with the fix in PR 9055\r\n```bash\r\ngit checkout xxx; \r\ngit submodule update --recursive; \r\ngit cherry-pick 9cc8ea3be23fb7adf4630e4cf065a2473094fbc8 -X theirs\r\nmake\r\n```\r\nand below is the result\r\n```\r\nff21e1f Changed FullyConnected to use new linalg gemm, plus TensorCore if fp16 I/O. (#7505)\r\n\r\nspeed test for batch size: 1\r\n        avg forward speed: 24.484983 samples/s\r\n        avg forward time: mean = 0.040839 s, std = 0.000095 s\r\n```\r\n```\r\n56eae58 Fixed Makefile so a null CUDA_ARCH is treated like an unset one. (#7515) - Fast\r\n\r\n########################################################\r\nspeed test for batch size: 1\r\n        avg forward speed: 25.461191 samples/s\r\n        avg forward time: mean = 0.039270 s, std = 0.000095 s\r\n########################################################\r\n```\r\nLooks like the commit ff21e1f caused the 4% slowdown during inference. \r\n\r\n@DickJC123 were you aware of this? ', 'I was not.  Is it easy for you to run your perf test on newer architectures than Kepler?\n\n> On March 15, 2018 at 11:38 AM Haibin Lin <notifications@github.com> wrote:\n> \n> \n>     @nicklhy https://github.com/nicklhy I bisected the changes between 0.10.0 and 1.0 and found the following on a p2.xlarge(K80) instance. The commits are patched with the fix in PR 9055\n> \n>     git checkout xxx; \n>     git submodule update --recursive; \n>     git cherry-pick 9cc8ea3be23fb7adf4630e4cf065a2473094fbc8 -X theirs\n>     make\n> \n>     and below is the result\n> \n>     ff21e1f Changed FullyConnected to use new linalg gemm, plus TensorCore if fp16 I/O. (#7505)\n> \n>     speed test for batch size: 1\n>             avg forward speed: 24.484983 samples/s\n>             avg forward time: mean = 0.040839 s, std = 0.000095 s\n> \n>     56eae58 Fixed Makefile so a null CUDA_ARCH is treated like an unset one. (#7515) - Fast\n> \n>     ########################################################\n>     speed test for batch size: 1\n>             avg forward speed: 25.461191 samples/s\n>             avg forward time: mean = 0.039270 s, std = 0.000095 s\n>     ########################################################\n> \n>     Looks like the commit ff21e1f https://github.com/apache/incubator-mxnet/commit/ff21e1fd41f118dbbaf55d8f02a9669842ef565f caused the 4% slowdown during inference.\n> \n>     @DickJC123 https://github.com/dickjc123 were you aware of this?\n> \n>     —\n>     You are receiving this because you were mentioned.\n>     Reply to this email directly, view it on GitHub https://github.com/apache/incubator-mxnet/issues/9396#issuecomment-373480684 , or mute the thread https://github.com/notifications/unsubscribe-auth/ABn95cDNeZmmZxQZ_Jskw0yivlr9C3eNks5terUOgaJpZM4RcJ9U .\n> \n>      \n> \n', 'Let me try v100', 'Hi @DickJC123 \r\n\r\nff21e1f with PR 9055 fix:\r\n\r\n```\r\n########################################################\r\nspeed test for batch size: 1\r\n        avg forward speed: 58.503896 samples/s\r\n        avg forward time: mean = 0.017091 s, std = 0.000046 s\r\n########################################################\r\n```\r\n\r\n56eae58 with PR 9055 fix:\r\n```\r\n########################################################\r\nspeed test for batch size: 1\r\n        avg forward speed: 62.070470 samples/s\r\n        avg forward time: mean = 0.016109 s, std = 0.000014 s\r\n########################################################\r\n```\r\nLooks like it is also slower on V100... @DickJC123 what should be the next step?', 'Hi @DickJC123 could you share some benchmark result for updated FC operator in ff21e1f ? That will be helpful information to decide how to fix the performance degradation for resnet, or revert the change ', ""Sorry for the delay.  I've been busy with prep for an upcoming conference.  I should be able to look at this perf regression next week.\n\n> On March 21, 2018 at 11:35 AM Haibin Lin <notifications@github.com> wrote:\n> \n> \n>     Hi @DickJC123 https://github.com/dickjc123 could you share some benchmark result for updated FC operator in ff21e1f https://github.com/apache/incubator-mxnet/commit/ff21e1fd41f118dbbaf55d8f02a9669842ef565f ? That will be helpful information to decide how to fix the performance degradation for resnet, or revert the change\n> \n>     —\n>     You are receiving this because you were mentioned.\n>     Reply to this email directly, view it on GitHub https://github.com/apache/incubator-mxnet/issues/9396#issuecomment-375051209 , or mute the thread https://github.com/notifications/unsubscribe-auth/ABn95QoDoTvRij3zS6tJ-aGKabJJlTnwks5tgp1ggaJpZM4RcJ9U .\n> \n>      \n> \n"", '@DickJC123 thanks! That will be great. ', ""@DickJC123 gentle ping - any update? Were you able to reproduce the issue? Just want to check if there's any update since the next release candidate will be cut in a week or so"", '@eric-haibin-lin @DickJC123 , any update about this ?', '@DickJC123  bouncing again.', ""@DickJC123 did you get a chance to check this issue with the latest code or @eric-haibin-lin's inputs? "", '@DickJC123 bouncing once more... ', '@DickJC123 Requesting an update regarding the issue, have the recent version(s) of the mxnet solved the issue for you?', '@lanking520 @aaronmarkham requesting to close this issue due to lack of activity', '@DickJC123 @nicklhy looks like this has been stale for a while. Please test it over again and feel free to reopen this issue if you are still facing the failure. Close for now.']","['\r\nMXNet version: 0.10.0\r\n########################################################\r\nspeed test for batch size: 1\r\n\tavg forward speed: 85.146210 samples/s\r\n\tavg forward time: mean = 0.011743 s, std = 0.000341 s\r\n########################################################\r\nspeed test for batch size: 4\r\n\tavg forward speed: 215.284806 samples/s\r\n\tavg forward time: mean = 0.018579 s, std = 0.000175 s\r\n########################################################\r\nspeed test for batch size: 16\r\n\tavg forward speed: 297.233244 samples/s\r\n\tavg forward time: mean = 0.053827 s, std = 0.001030 s\r\n########################################################\r\nspeed test for batch size: 64\r\n\tavg forward speed: 316.399717 samples/s\r\n\tavg forward time: mean = 0.202272 s, std = 0.001754 s\r\n########################################################\r\nspeed test for batch size: 128\r\n\tavg forward speed: 321.620336 samples/s\r\n\tavg forward time: mean = 0.397981 s, std = 0.002363 s\r\n', '\r\nMXNet version: 1.0.0\r\n########################################################\r\nspeed test for batch size: 1\r\n\tavg forward speed: 67.866811 samples/s\r\n\tavg forward time: mean = 0.014733 s, std = 0.000391 s\r\n########################################################\r\nspeed test for batch size: 4\r\n\tavg forward speed: 188.020417 samples/s\r\n\tavg forward time: mean = 0.021272 s, std = 0.000563 s\r\n########################################################\r\nspeed test for batch size: 16\r\n\tavg forward speed: 286.253890 samples/s\r\n\tavg forward time: mean = 0.055892 s, std = 0.000565 s\r\n########################################################\r\nspeed test for batch size: 64\r\n\tavg forward speed: 310.045353 samples/s\r\n\tavg forward time: mean = 0.206418 s, std = 0.004860 s\r\n########################################################\r\nspeed test for batch size: 128\r\n\tavg forward speed: 320.566647 samples/s\r\n\tavg forward time: mean = 0.399289 s, std = 0.002575 s\r\n', '\r\n#!/usr/bin/env python\r\n# -*- coding: utf-8 -*-\r\n\r\n\r\nimport time\r\nimport argparse\r\nimport mxnet as mx\r\nimport numpy as np\r\n\r\n\r\nif __name__ == ""__main__"":\r\n    parser = argparse.ArgumentParser(description=\'speed test\')\r\n    parser.add_argument(\'--net\', type=str, required=True,\r\n                        help=\'network symbol json file\')\r\n    parser.add_argument(\'--size\', type=int, default=224,\r\n                        help=\'image size\')\r\n    parser.add_argument(\'--n-batch\', type=int, default=100,\r\n                        help=\'batch number for test\')\r\n    parser.add_argument(\'--gpu\', type=int, default=0,\r\n                        help=\'gpu device id\')\r\n    args = parser.parse_args()\r\n\r\n    print(\'MXNet version: %s\' % mx.__version__)\r\n\r\n    ctx = mx.gpu(args.gpu)\r\n\r\n    batch_size_list = [1, 4, 16, 64, 128]\r\n\r\n    mod = mx.mod.Module(symbol=mx.sym.load(args.net),\r\n                        context=ctx,\r\n                        data_names=[\'data\', ],\r\n                        label_names=[\'softmax_label\', ])\r\n    mod.bind(data_shapes=[(\'data\', (1, 3, args.size, args.size))],\r\n             label_shapes=[(\'softmax_label\', (1,))],\r\n             for_training=False)\r\n    mod.init_params(initializer=mx.init.Normal())\r\n\r\n    for batch_size in batch_size_list:\r\n        print(\'########################################################\')\r\n        print(\'speed test for batch size: %d\' % batch_size)\r\n        mod.reshape(data_shapes=[(\'data\', (batch_size,\r\n                                           3,\r\n                                           args.size,\r\n                                           args.size))],\r\n                    label_shapes=[(\'softmax_label\', (batch_size,))])\r\n\r\n        #  pre-allocate\r\n        batch_data = mx.nd.random_normal(0, 0.5, (batch_size, 3, args.size, args.size), ctx=ctx)\r\n\r\n        #  warm up GPU\r\n        for _ in range(50):\r\n            mod.forward(mx.io.DataBatch(data=[batch_data, ],\r\n                                        label=None),\r\n                        is_train=False)\r\n            out = mod.get_outputs()[0].asnumpy()\r\n\r\n        k = 0\r\n        t_start = time.time()\r\n        t_fwd_list = []\r\n        for _ in range(args.n_batch):\r\n            t1 = time.time()\r\n            mod.forward(mx.io.DataBatch(data=[batch_data, ],\r\n                                        label=None),\r\n                        is_train=False)\r\n            out = mod.get_outputs()[0]\r\n            out.wait_to_read()\r\n            t2 = time.time()\r\n            t_fwd_list.append(t2-t1)\r\n        t_end = time.time()\r\n        n_samples = args.n_batch*batch_size\r\n\r\n        print(\'\\tavg forward speed: %f samples/s\' % (n_samples/(t_end-t_start)))\r\n        print(\'\\tavg forward time: mean = %f s, std = %f s\' %\r\n              (np.mean(t_fwd_list), np.std(t_fwd_list)))\r\n']",['pip3 install mxnet-cu80==1.0.0'],1,0
23,incubator-mxnet,11575,closed,inconsistent results of mae acc rmse,"Hi,

I'm trying to train my model with the following code. It has only to classes to predict from 0 and 1.



Here are the results : 
.

> 2018-07-06 00:54:38,926 Epoch[0] Batch [100]	Speed: 20.37 samples/sec	accuracy=0.544554	rmse=0.591505	mae=0.500000
> 2018-07-06 00:54:43,694 Epoch[0] Batch [200]	Speed: 20.97 samples/sec	accuracy=0.470000	rmse=0.586368	mae=0.500000
> 2018-07-06 00:54:48,509 Epoch[0] Batch [300]	Speed: 20.77 samples/sec	accuracy=0.520000	rmse=0.587208	mae=0.500000
> 2018-07-06 00:54:53,286 Epoch[0] Batch [400]	Speed: 20.93 samples/sec	accuracy=0.560000	rmse=0.602946	mae=0.500000
> 2018-07-06 00:54:58,057 Epoch[0] Batch [500]	Speed: 20.96 samples/sec	accuracy=0.460000	rmse=0.576723	mae=0.500000
> 2018-07-06 00:55:02,886 Epoch[0] Batch [600]	Speed: 20.71 samples/sec	accuracy=0.490000	rmse=0.577645	mae=0.500000
> 2018-07-06 00:55:07,703 Epoch[0] Batch [700]	Speed: 20.76 samples/sec	accuracy=0.600000	rmse=0.585552	mae=0.500000
> 2018-07-06 00:55:12,453 Epoch[0] Batch [800]	Speed: 21.05 samples/sec	accuracy=0.560000	rmse=0.585788	mae=0.500000
> 2018-07-06 00:55:17,236 Epoch[0] Batch [900]	Speed: 20.91 samples/sec	accuracy=0.500000	rmse=0.567332	mae=0.500000
> 2018-07-06 00:55:21,993 Epoch[0] Batch [1000]	Speed: 21.02 samples/sec	accuracy=0.590000	rmse=0.580251	mae=0.500000
> 2018-07-06 00:55:26,776 Epoch[0] Batch [1100]	Speed: 20.91 samples/sec	accuracy=0.550000	rmse=0.564997	mae=0.500000
> 2018-07-06 00:55:31,532 Epoch[0] Batch [1200]	Speed: 21.02 samples/sec	accuracy=0.620000	rmse=0.564062	mae=0.500000
> 2018-07-06 00:55:36,281 Epoch[0] Batch [1300]	Speed: 21.06 samples/sec	accuracy=0.650000	rmse=0.566788	mae=0.500000
> 2018-07-06 00:55:41,062 Epoch[0] Batch [1400]	Speed: 20.92 samples/sec	accuracy=0.590000	rmse=0.574353	mae=0.500000
> 2018-07-06 00:55:45,845 Epoch[0] Batch [1500]	Speed: 20.91 samples/sec	accuracy=0.690000	rmse=0.569736	mae=0.500000
> 2018-07-06 00:55:50,623 Epoch[0] Batch [1600]	Speed: 20.93 samples/sec	accuracy=0.700000	rmse=0.579918	mae=0.500000
> 2018-07-06 00:55:55,407 Epoch[0] Batch [1700]	Speed: 20.90 samples/sec	accuracy=0.730000	rmse=0.585157	mae=0.500000
> 2018-07-06 00:56:00,170 Epoch[0] Batch [1800]	Speed: 20.99 samples/sec	accuracy=0.810000	rmse=0.590722	mae=0.500000
> 2018-07-06 00:56:04,944 Epoch[0] Batch [1900]	Speed: 20.95 samples/sec	accuracy=0.860000	rmse=0.601612	mae=0.500000
> 2018-07-06 00:56:09,704 Epoch[0] Batch [2000]	Speed: 21.01 samples/sec	accuracy=0.800000	rmse=0.593426	mae=0.500000
> 2018-07-06 00:56:14,460 Epoch[0] Batch [2100]	Speed: 21.02 samples/sec	accuracy=0.860000	rmse=0.618266	mae=0.500000
> 2018-07-06 00:56:19,215 Epoch[0] Batch [2200]	Speed: 21.03 samples/sec	accuracy=0.760000	rmse=0.605838	mae=0.500000
> 2018-07-06 00:56:23,997 Epoch[0] Batch [2300]	Speed: 20.92 samples/sec	accuracy=0.840000	rmse=0.616089	mae=0.500000
> 2018-07-06 00:56:28,773 Epoch[0] Batch [2400]	Speed: 20.94 samples/sec	accuracy=0.850000	rmse=0.620063	mae=0.500000
> 2018-07-06 00:56:33,562 Epoch[0] Batch [2500]	Speed: 20.88 samples/sec	accuracy=0.820000	rmse=0.608637	mae=0.500000
> 2018-07-06 00:56:38,401 Epoch[0] Batch [2600]	Speed: 20.67 samples/sec	accuracy=0.880000	rmse=0.631159	mae=0.500000
> 2018-07-06 00:56:43,179 Epoch[0] Batch [2700]	Speed: 20.93 samples/sec	accuracy=0.850000	rmse=0.624896	mae=0.500000
> 2018-07-06 00:56:47,975 Epoch[0] Batch [2800]	Speed: 20.85 samples/sec	accuracy=0.830000	rmse=0.631906	mae=0.500000
> 2018-07-06 00:56:52,744 Epoch[0] Batch [2900]	Speed: 20.97 samples/sec	accuracy=0.890000	rmse=0.634412	mae=0.500000
> 2018-07-06 00:56:57,510 Epoch[0] Batch [3000]	Speed: 20.98 samples/sec	accuracy=0.810000	rmse=0.628204	mae=0.500000
> 2018-07-06 00:57:02,293 Epoch[0] Batch [3100]	Speed: 20.91 samples/sec	accuracy=0.900000	rmse=0.648476	mae=0.500000
> 2018-07-06 00:57:07,066 Epoch[0] Batch [3200]	Speed: 20.95 samples/sec	accuracy=0.920000	rmse=0.642261	mae=0.500000

This result looks very strange to me. 
1) mae is always the same.
2) accuracy is almost optimal (near to 1)
3) rmse is worse then the random

How can these 3 things happen at the same time?",,"[""For questions, please submit on MXNet discussion forum (https://discuss.mxnet.io), where it will get a wider audience and allow other to learn as well.\r\nI'm closing this issue now in favor of the discussion forum issue you will file, please feel free to re-open if closed in error.\r\nThanks!\r\n\r\n@sandeep-krishnamurthy please close this issue""]","['\r\n    def fit(symbol, arg_params, aux_params, train, val, test, batch_size, num_gpus):\r\n        devs = [mx.gpu(i) for i in range(num_gpus)]\r\n        mod = mx.mod.Module(symbol=symbol, context=devs)\r\n        metrics = [mx.metric.Accuracy(), mx.metric.RMSE(), mx.metric.MAE()]\r\n\r\n        mod.fit(train, val,\r\n            num_epoch=args.epoch,\r\n            arg_params=arg_params,\r\n            aux_params=aux_params,\r\n            allow_missing=True,\r\n            batch_end_callback = mx.callback.Speedometer(batch_size, 100),\r\n            epoch_end_callback = mx.callback.do_checkpoint(args.prefix, 1),\r\n            kvstore=\'KVStore\',\r\n            optimizer=\'sgd\',\r\n            optimizer_params={\'learning_rate\':0.01},\r\n            initializer=mx.init.Xavier(rnd_type=\'gaussian\', factor_type=""in"", magnitude=2),\r\n            eval_metric=metrics)\r\n\r\n        return mod.score(test, metrics)\r\n']",[],1,0
24,incubator-mxnet,951,closed,run two machine with two gpu is slower than one machine with one gpu,"I used two machine(every machine has one gpu) to use Alexnet run multile machine.the result saids that it is slower than one machine use one gpu. the net is km. 
is multi machine is limited by the net?
",,"['could you please give more information? e.g. cpu/gpu info, network bandwidth, batch size you use, dist_sync or dist_async?\n', 'gpu k80 only use gpu=0, network bandwidth= 1Gbps,   dist_sync;    use one machine batch size=256,use two machine batch size=512.  train_imagenet  Alexnet\n', 'are you train on imagenet? i suggest to change the batch size into 1024\n', 'alexnet has a high network bandwidth need.\nI suggest you try inception-bn again\n', '@freepjf  try incepiton-bn, this model has about 1/10 network bandwidth need of alexnet\n', '@qiaohaijun there is a trick to reduce 4x network traffic which has been tested on cxxnet before. that is, convert a float into an int8 with randomized rounding. \n', '@mli  we use infiniband connect to eash other with two machine（every one with one gpu），set batch size=512 every pc，the speed is only 200 picture/s，but when we use one machine with one gpu ，the speed is 260。what is the problem\n', ""what's the network usage? you can check it by `nmon` if you are using linux\n"", 'I test with the alexnet, win7, infiniband \nlocal:                               195samples/s (1pc with 1gpu)                 613(1pc with 4gpu)\nlocal_allreduce_cpu:       319samples/s(up on)                              1240samples/s(up on)\ndist_sync                         300(2pc with 2gpu)                                 1200(2pc with 8gpu)\n\none machine two cpu with 8 gpu on two sides is similar with 4gpu on the same side\n@mli  is it normal?  \nand I want to know How many cluster systems are supported in theory with mxnet?\n', ""@freepjf  \r\ni met the same issue. what's the bandwidth of your IB net? 56G or 100G？\r\nAdding more parameter server may help, but i think bandwidth is the main bottleneck here""]",[],[],1,0
25,incubator-mxnet,16568,open,"Different (not uniform) behavior in RMSE,MSE,MAE","Looking at metrics it seems like they behave in a slightly different way depending on how they sum up all the batch inputs. For example, Accuracy does not calculate the mean of single batches, but sums all them up and evaluates a single mean in the get method:

https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/metric.py#L507

On the contrary, RMSE evaluates the single RMSE for each batch, and then the average in the get method.

https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/metric.py#L1273

This leads to some discrepancy in the metrics for example when using metrics which are non-linear (f.i. MAE, MSE, RMSE, PCC) where metric(samples)!=mean(metric(batch_samples)).",Feature request,"['@mxnet-label-bot add [Feature]', 'I think this is more a bug than a new feature, since different metrics are calculated with different methodologies (mean of sample vs mean of means of samples) which does not make metrics conceptually interchangeable (if I want the calculate the global RMSE with the current implementation I should estimate all the predictions and then update the metric, while in the case of accuracy I can update it at every batch). It is also true that, for linear metrics, the two methodologies produce very close results and, in some cases, exactly the same result. \r\nMy feeling is that all metrics should reflect the way RMSE is calculated (mean of means) as default, since they are usually updated in loops with batch training.\r\nWhich approach is taken should also be clarified a little bit in the documentation.']",[],[],1,0
26,incubator-mxnet,10167,open,HybridBlock can be slower than Block,"Here's an interesting example that HybridBlock can sometimes be much slower than Block. We define an Identity block using two strategies and compare the running time.



The result is:

We can find that in this case, using Block is a better choice than using HybridBlock.",Discussion Performance,"['@sandeep-krishnamurthy  Could you please label this issue as discussion', ""In my opinion, I don't think your hybrid block is actually running in the `symbol` mode. Instead, if not, it will fall back to `Ndarray` mode, which is the same is the block. However, there are complicated code in the hybrid block to check whether it should run in `symbol` mode or `Ndarray` mode, so it will be slower."", 'I edited the above example to include `HybridLoopIdentityBlock` for comparison.']","[""python\r\nimport mxnet as mx\r\nimport time\r\nfrom mxnet.gluon import Block, HybridBlock\r\n\r\n\r\nclass HybridIdentity(HybridBlock):\r\n    def hybrid_forward(self, F, x):\r\n        return x\r\n\r\nclass NoHybridIdentity(Block):\r\n    def forward(self, x):\r\n        return x\r\n\r\n\r\nclass LoopIdentityBlock(Block):\r\n    def __init__(self, use_hybrid=False, prefix=None, params=None):\r\n        super(LoopIdentityBlock, self).__init__(prefix=prefix, params=params)\r\n        if use_hybrid:\r\n            self.identity = HybridIdentity()\r\n        else:\r\n            self.identity = NoHybridIdentity()\r\n\r\n    def forward(self, x):\r\n        for i in range(100000):\r\n            x = self.identity(x)\r\n        return x\r\n\r\n\r\nclass HybridLoopIdentityBlock(HybridBlock):\r\n    def __init__(self, prefix=None, params=None):\r\n        super(HybridLoopIdentityBlock, self).__init__(prefix=prefix, params=params)\r\n        self.identity = HybridIdentity()\r\n\r\n    def hybrid_forward(self, F, x):\r\n        for i in range(100000):\r\n            x = self.identity(x)\r\n        return x\r\n\r\n\r\nfor _ in range(5):\r\n    _ = mx.nd.ones((100, 100)).sum().asscalar()\r\n\r\nhybrid_loop_block = LoopIdentityBlock(use_hybrid=True)\r\nloop_block = LoopIdentityBlock(use_hybrid=False)\r\nx = mx.nd.ones((1024, 1024, 512))\r\nstart = time.time()\r\nfor _ in range(5):\r\n    loop_block(x)\r\n    mx.nd.waitall()\r\nend = time.time()\r\nprint('Identity W/o Hybrid:', end - start)\r\n\r\nstart = time.time()\r\nfor _ in range(5):\r\n    hybrid_loop_block(x)\r\n    mx.nd.waitall()\r\nend = time.time()\r\nprint('Identity With Hybrid:', end - start)\r\n\r\n\r\nhybrid_loop_block.hybridize()\r\nstart = time.time()\r\nfor _ in range(5):\r\n    hybrid_loop_block(x)\r\n    mx.nd.waitall()\r\nend = time.time()\r\nprint('Identity With Hybrid + hybridize:', end - start)\r\n\r\n\r\nhybrid_loop_block = HybridLoopIdentityBlock()\r\nhybrid_loop_block.hybridize()\r\nstart = time.time()\r\nfor _ in range(5):\r\n    hybrid_loop_block(x)\r\n    mx.nd.waitall()\r\nend = time.time()\r\nprint('Hybridized identity With Hybrid + hybridize:', end - start)\r\n\r\n"", 'log\r\nIdentity W/o Hybrid: 0.6371102333068848\r\nIdentity With Hybrid: 3.2682743072509766\r\nIdentity With Hybrid + hybridize: 12.879750728607178\r\nHybridized identity With Hybrid + hybridize: 1.038146734237671\r\n']",[],1,0
27,incubator-mxnet,11192,open,BatchNorm operator on GPUs are slow with channels_last,"[mx.sym.BatchNorm operator](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.BatchNorm) is considerably slower on GPUs with channels_last (axis=-1).

My understanding is that, with channels_first (axis=1) operator calls cuDNN implementation and with channels_last(axis=-1) MXNet has its own implementation.

",Operator Performance,['Thanks for submitting this tracking issue @sandeep-krishnamurthy'],[],[],1,0
28,incubator-mxnet,5052,closed,"MXNET R, GPU speed-up much less for regression example than classification","In the example code below I run simple classification and regression examples for MXNET running from R. In both examples I first solve with CPU, and then GPU.

In the classification example I get a ~ 32x speed-up when using a GPU, however the speed-up when running the regression example is much less (about 3x).

Details are given below, my main questions would be:
1. Is there are reason the speed-up is much less significant for the regression example?
2. Do people who have mxnet get similar/comparable results to me? (Alternatively is there a benchmark I can run and compare to benchmark performances?)

The output I get:


Example code:



Details of my set-up

## Environment info
Operating System: Ubuntu 16.04
R details:

",R,"[""My results with\r\nCPU: Intel(R) Core(TM) i5-6500 CPU @ 3.20GHz\r\nGPU: GTX1060\r\n```\r\n> source('~/.active-rstudio-document')\r\nClassification CPU time:: 1.045 sec elapsed\r\nClassification GPU time:: 1.038 sec elapsed\r\nRegression CPU time:: 11.341 sec elapsed\r\nRegression GPU time:: 6.812 sec elapsed\r\n> source('~/.active-rstudio-document')\r\nClassification CPU time:: 0.988 sec elapsed\r\nClassification GPU time:: 0.818 sec elapsed\r\nRegression CPU time:: 11.484 sec elapsed\r\nRegression GPU time:: 6.915 sec elapsed\r\n```\r\n"", ""@matt32106 @khalida \r\nWith the latest MXNetR version (Windows GPU - cuda 80), I got the following results \r\n \r\nRun1:\r\nClassification CPU time:: 1.88 sec elapsed\r\nClassification GPU time:: 2.03 sec elapsed\r\nRegression CPU time:: 19.58 sec elapsed\r\nRegression GPU time:: 19.45 sec elapsed\r\n\r\nRun2:\r\nClassification GPU time:: 1.97 sec elapsed\r\nClassification CPU time:: 1.75 sec elapsed\r\nRegression GPU time:: 19.73 sec elapsed\r\nRegression CPU time:: 20.83 sec elapsed\r\n\r\nThis is the result obtained on Windows server ec2 instance with p2.xlarge instances (Nvidia Tesla K80). \r\n\r\nDoesn't seems like we have a benchmark to compare performances but it should depend too much on GPU/CPU/OS and system load and other issues like cold start. Trying to get results on few more configurations to analyze the numbers. \r\n"", ""@khalida Please try to run the examples again to see the speedup. In my opinion , you are facing the problem of cold start and hence classsification CPU time is significantly more than other numbers. I also faced a similar issue. While comparing again, I didn't find too much of a difference in speedup for classification/regression example while running on Windows ec2 server. \r\nClassification GPU time:: 1.65 sec elapsed\r\nClassification CPU time:: 1.74 sec elapsed\r\nRegression GPU time:: 16.11 sec elapsed\r\nRegression CPU time:: 16.19 sec elapsed\r\nHope that answers your query."", '@sandeep-krishnamurthy Could you please close the issue as the query has been answered.\r\n\r\n@khalida Please feel free to reopen in case of more question or closed in error.']","['\r\nClassification CPU time:: 50.104 sec elapsed\r\nClassification GPU time:: 1.54 sec elapsed\r\nRegression CPU time:: 50.39 sec elapsed\r\nRegression GPU time:: 15.762 sec elapsed\r\n', '\r\n## Load required packages\r\nrequire(mlbench)\r\nrequire(mxnet)\r\nrequire(tictoc)\r\n\r\n## Options:\r\nnHidden <- 100\r\nnRounds <- 200\r\nbatchSize <- 32\r\n\r\n## Classification VS Regression GPU-speedup example\r\ndata(Sonar, package=""mlbench"")\r\nSonar[,61] = as.numeric(Sonar[,61])-1\r\ntrain.ind = c(1:50, 100:150)\r\ntrain.x = data.matrix(Sonar[train.ind, 1:60])\r\ntrain.y = Sonar[train.ind, 61]\r\ntest.x = data.matrix(Sonar[-train.ind, 1:60])\r\ntest.y = Sonar[-train.ind, 61]\r\n\r\ntic(""Classification CPU time:"")\r\nmx.set.seed(0)\r\nmodel <- mx.mlp(train.x, train.y, hidden_node=nHidden, out_node=2,\r\n                out_activation=""softmax"", num.round=nRounds,\r\n                array.batch.size=batchSize, learning.rate=0.07, momentum=0.9, \r\n                eval.metric=mx.metric.accuracy, array.layout=""rowmajor"",\r\n                device=mx.cpu(), verbose=FALSE\r\n)\r\ntoc()\r\n\r\ntic(""Classification GPU time:"")\r\nmx.set.seed(0)\r\nmodel <- mx.mlp(train.x, train.y, hidden_node=nHidden, out_node=2,\r\n                out_activation=""softmax"", num.round=nRounds,\r\n                array.batch.size=batchSize, learning.rate=0.07, momentum=0.9, \r\n                eval.metric=mx.metric.accuracy, array.layout=""rowmajor"",\r\n                device=mx.gpu(), verbose=FALSE\r\n)\r\ntoc()\r\n\r\ntic(""Regression CPU time:"")\r\nmx.set.seed(0)\r\nmodel <- mx.mlp(train.x, train.y, hidden_node=5*nHidden, out_node=1,\r\n                out_activation=""rmse"", num.round=10*nRounds,\r\n                array.batch.size=batchSize, learning.rate=0.07, momentum=0.9, \r\n                eval.metric=mx.metric.rmse, array.layout=""rowmajor"",\r\n                device=mx.cpu(), verbose=FALSE\r\n)\r\ntoc()\r\n\r\ntic(""Regression GPU time:"")\r\nmx.set.seed(0)\r\nmodel <- mx.mlp(train.x, train.y, hidden_node=5*nHidden, out_node=1,\r\n                out_activation=""rmse"", num.round=10*nRounds,\r\n                array.batch.size=batchSize, learning.rate=0.07, momentum=0.9, \r\n                eval.metric=mx.metric.rmse, array.layout=""rowmajor"",\r\n                device=mx.gpu(), verbose=FALSE\r\n)\r\ntoc()\r\n', '\r\nplatform       x86_64-pc-linux-gnu         \r\narch           x86_64                      \r\nos             linux-gnu                   \r\nsystem         x86_64, linux-gnu           \r\nstatus                                     \r\nmajor          3                           \r\nminor          3.2                         \r\nyear           2016                        \r\nmonth          10                          \r\nday            31                          \r\nsvn rev        71607                       \r\nlanguage       R                           \r\nversion.string R version 3.3.2 (2016-10-31)\r\nnickname       Sincere Pumpkin Patch  \r\n']",[],1,0
29,incubator-mxnet,8126,open,Not able to train a neural network [XOR added],"## Environment info
Operating System: Ubuntu 16.04 
Compiler: g++
Package used (Python/R/Scala/Julia): C++

MXNet version: 0.11

Or if installed from source:
MXNet commit hash ():  branch 0.11.0

## Error Message:
**There is no error but the training accuracy always remains ZERO.** Is there a problem with the code for constructing the neural network (the  symbol) or/and is the training procedure correct, i.e. the gradient updates are correctly specified?

## Minimum reproducible example

1. I defined a siamese net like architecture with  as final layer using the code provided below:



The output of the code is always something like:


## What have you tried to solve it?

1. Tried different variations on training data but the network is always predicting ZERO as its output.
",C++ Pending Requester Info,"['I am adding a very simple example here in which I tried to fit a neural network on the XOR function but unable to do so as well.\r\n```C++\r\n#include <iostream>\r\n#include <map>\r\n#include <string>\r\n#include ""mxnet-cpp/MxNetCpp.h""\r\n// Allow IDE to parse the types\r\n#include ""../include/mxnet-cpp/op.h""\r\n\r\nusing namespace std;\r\nusing namespace mxnet::cpp;\r\n\r\n\r\nSymbol mlp(const vector<int> &layers, const vector<Symbol> & weights,\r\n            const std::vector<Symbol> & biases, const string & inp_name )\r\n{\r\n  auto x = Symbol::Variable(inp_name);\r\n\r\n  vector<Symbol> outputs(layers.size());\r\n\r\n  for (size_t i = 0; i < layers.size(); ++i)\r\n  {\r\n    string istr = to_string(i);\r\n    Symbol fc = FullyConnected(\r\n      i == 0? x : outputs[i-1],  // data\r\n      weights[i],\r\n      biases[i],\r\n      layers[i]);\r\n    outputs[i] = i == layers.size()-1 ? fc :  Activation(string(""act"") + istr, fc, \r\n    ActivationActType::kTanh);\r\n  }\r\n\r\n  return outputs.back();\r\n}\r\n\r\nint main(int argc, char** argv)\r\n{\r\n    const int feature_size = 2;\r\n    const vector<int> layers{8, 4, 1};\r\n    const int batch_size = 4;\r\n    const int max_epoch = 100000;\r\n    const float learning_rate = 0.001;\r\n    const float weight_decay = 1e-2;\r\n\r\n    auto ctx = Context::cpu(); // Use GPU for training\r\n    auto ctx_cpu = Context::cpu();\r\n\r\n    vector<Symbol> weights(layers.size());\r\n    vector<Symbol> biases(layers.size());\r\n\r\n    for (size_t i = 0; i < layers.size(); ++i)\r\n    {\r\n        string istr = to_string(i);\r\n        weights[i] = Symbol::Variable(""w"" + istr);\r\n        biases[i] = Symbol::Variable(""b"" + istr);\r\n    }\r\n\r\n    auto Net = mlp(layers, weights, biases, ""X"");\r\n    auto sym_label = Symbol::Variable(""label"");\r\n    auto output = LogisticRegressionOutput(string(""sigmoid""), Net, sym_label);\r\n\r\n    map<string, NDArray> args_map;\r\n    args_map[""X""] = NDArray(Shape(batch_size, feature_size) , ctx);\r\n    args_map[""label""] = NDArray(Shape(batch_size, 1), ctx);\r\n\r\n    auto *exec = output.SimpleBind(ctx, args_map);\r\n    output.InferArgsMap(ctx, &args_map, args_map);\r\n    auto arg_names = output.ListArguments();\r\n\r\n    Xavier xavier = Xavier(Xavier::gaussian, Xavier::avg);\r\n    for (auto &arg : args_map)\r\n    {\r\n        xavier(arg.first, &arg.second);\r\n    }\r\n\r\n    Optimizer* opt = OptimizerRegistry::Find(""adam"");\r\n    opt->SetParam(""rescale_grad"", 1.0 / batch_size)\r\n        ->SetParam(""lr"", learning_rate)\r\n        ->SetParam(""wd"", weight_decay);\r\n\r\n    // XOR Function\r\n    mx_float* aptr_x = new mx_float[batch_size * feature_size];\r\n    mx_float* aptr_y = new mx_float[batch_size];\r\n\r\n    aptr_x[0] = 0.; aptr_x[1] = 0.; aptr_y[0] = 0;\r\n    aptr_x[2] = 0; aptr_x[3] = 1.; aptr_y[1] = 1;\r\n    aptr_x[4] = 1.; aptr_x[5] = 0.; aptr_y[2] = 1;\r\n    aptr_x[6] = 1.; aptr_x[7] = 1.; aptr_y[3] = 0;\r\n\r\n    NDArray train_data = NDArray(Shape(batch_size, 2), ctx_cpu, false);\r\n    NDArray train_label = NDArray(Shape(batch_size), ctx_cpu, false);\r\n    train_data.SyncCopyFromCPU(aptr_x, batch_size * 2);\r\n    train_label.SyncCopyFromCPU(aptr_y, batch_size);\r\n    train_data.WaitToRead();\r\n    train_label.WaitToRead();\r\n\r\n    Accuracy acu_train;\r\n    for (int ITER = 0; ITER < max_epoch ; ++ITER)\r\n    {\r\n        acu_train.Reset();\r\n        args_map[""X""] = train_data.Copy(ctx);\r\n        args_map[""label""] = train_label.Copy(ctx);\r\n        NDArray::WaitAll();\r\n\r\n        exec->Forward(true);\r\n        acu_train.Update(args_map[""label""], exec->outputs[0]);\r\n\r\n        if(ITER % 5000 == 0){\r\n            auto out = (exec->outputs[0]).Copy(ctx_cpu);\r\n            auto labels = args_map[""label""].Copy(ctx_cpu);\r\n            NDArray::WaitAll();\r\n            const mx_float * outs = out.GetData();\r\n            auto lbs = labels.GetData();\r\n            for (int i = 0 ; i < batch_size ; i++)\r\n                cout << lbs[i] << "":"" << outs[i] << "" "";\r\n            cout << endl;\r\n            LG << ""ITER: "" << ITER << "" Train Accuracy: "" << acu_train.Get();\r\n        }\r\n        exec->Backward();\r\n        // Update parameters\r\n        for (size_t i = 0; i < arg_names.size(); ++i)\r\n        {\r\n            if (arg_names[i] == ""X"" || arg_names[i] == ""label"") continue;\r\n            opt->Update(i, exec->arg_arrays[i], exec->grad_arrays[i]);\r\n        }\r\n    }\r\n\r\n    delete exec;\r\n    delete [] aptr_x;\r\n    delete [] aptr_y;\r\n    MXNotifyShutdown();\r\n    return 0;\r\n }\r\n```\r\nThe output is (True_label : Predicted_label):\r\n```\r\n0:0.95178 1:0.880215 1:0.944654 0:0.86154 \r\n[19:14:56] xor.cpp:114: ITER: 0 Train Accuracy: 0.5\r\n0:0.786497 1:1 1:0.799124 0:3.35246e-13 \r\n[19:14:57] xor.cpp:114: ITER: 5000 Train Accuracy: 0.5\r\n0:0.786137 1:1 1:0.800972 0:1.01632e-21 \r\n[19:14:58] xor.cpp:114: ITER: 10000 Train Accuracy: 0.5\r\n0:0.783514 1:1 1:0.802832 0:3.29902e-30 \r\n[19:14:58] xor.cpp:114: ITER: 15000 Train Accuracy: 0.5\r\n0:0.785589 1:1 1:0.805458 0:1.13999e-38 \r\n[19:14:59] xor.cpp:114: ITER: 20000 Train Accuracy: 0.5\r\n0:0.785148 1:1 1:0.808582 0:0 \r\n[19:15:00] xor.cpp:114: ITER: 25000 Train Accuracy: 0.5\r\n0:0.786545 1:1 1:0.812904 0:0 \r\n[19:15:00] xor.cpp:114: ITER: 30000 Train Accuracy: 0.5\r\n0:0.784969 1:1 1:0.8189 0:0 \r\n[19:15:01] xor.cpp:114: ITER: 35000 Train Accuracy: 0.5\r\n0:0.784798 1:1 1:0.82841 0:0 \r\n[19:15:02] xor.cpp:114: ITER: 40000 Train Accuracy: 0.5\r\n0:0.787042 1:1 1:0.845301 0:0 \r\n[19:15:02] xor.cpp:114: ITER: 45000 Train Accuracy: 0.5\r\n0:0.784718 1:1 1:0.879533 0:0 \r\n[19:15:03] xor.cpp:114: ITER: 50000 Train Accuracy: 0.5\r\n0:0.783628 1:1 1:0.934087 0:0 \r\n[19:15:04] xor.cpp:114: ITER: 55000 Train Accuracy: 0.5\r\n0:0.786908 1:1 1:0.948499 0:0 \r\n[19:15:04] xor.cpp:114: ITER: 60000 Train Accuracy: 0.5\r\n0:0.784415 1:1 1:0.948458 0:0 \r\n[19:15:05] xor.cpp:114: ITER: 65000 Train Accuracy: 0.5\r\n0:0.784358 1:1 1:0.948456 0:0 \r\n[19:15:06] xor.cpp:114: ITER: 70000 Train Accuracy: 0.5\r\n0:0.784338 1:1 1:0.948455 0:0 \r\n[19:15:07] xor.cpp:114: ITER: 75000 Train Accuracy: 0.5\r\n0:0.797159 1:1 1:0.948738 0:0 \r\n[19:15:07] xor.cpp:114: ITER: 80000 Train Accuracy: 0.5\r\n0:0.784321 1:1 1:0.948455 0:0 \r\n[19:15:08] xor.cpp:114: ITER: 85000 Train Accuracy: 0.5\r\n0:0.7837 1:1 1:0.948445 0:0 \r\n[19:15:09] xor.cpp:114: ITER: 90000 Train Accuracy: 0.5\r\n0:0.78427 1:1 1:0.948449 0:0 \r\n[19:15:09] xor.cpp:114: ITER: 95000 Train Accuracy: 0.5\r\n```\r\nEven after 10000 iterations, the neural net is not able to predict the XOR function correctly. I have tried different layer sizes (both increasing/decreasing the number of neurons) but it didn\'t help at all. \r\n**Is this a bug in the C++ API or is there any problem with my code.** \r\n@piiswrong @szha ', 'I\'m just starting to study MXNet, but this example is working here (CPU only).\r\n\r\n```c++\r\n#include ""mxnet-cpp/MxNetCpp.h""\r\n\r\n#include <chrono>\r\n#include <iostream>\r\n\r\nusing namespace std;\r\nusing namespace mxnet::cpp;\r\n\r\nSymbol mlp(const vector<int> &layers) {\r\n\tauto x = Symbol::Variable(""X"");\r\n\tauto label = Symbol::Variable(""label"");\r\n\r\n\tvector<Symbol> weights(layers.size());\r\n\tvector<Symbol> biases(layers.size());\r\n\tvector<Symbol> outputs(layers.size());\r\n\r\n\tfor (size_t i = 0; i < layers.size(); ++i) {\r\n\t\tweights[i] = Symbol::Variable(""w"" + to_string(i));\r\n\t\tbiases[i] = Symbol::Variable(""b"" + to_string(i));\r\n\t\tSymbol fc = FullyConnected(\r\n\t\t\t\ti == 0 ? x : outputs[i-1],\r\n\t\t\t\t\t\tweights[i],\r\n\t\t\t\t\t\tbiases[i],\r\n\t\t\t\t\t\tlayers[i]);\r\n\r\n\t\toutputs[i] = i == layers.size() - 1 ? fc :\r\n\t\t\t\tActivation(fc, ActivationActType::kRelu);\r\n\t}\r\n\r\n\treturn SoftmaxOutput(outputs.back(), label);\r\n\r\n}\r\n\r\n\r\nint main(int argc, char *argv[]) {\r\n\r\n\tconst int input_width = 2;\r\n\tconst int input_height = 1;\r\n\tconst int output_length = 2;\r\n\tconst size_t train_num = 8000;\r\n\tconst size_t val_num = 2000;\r\n\tconst vector<int> layers{8, 8, 2};\r\n\tconst int batch_size = 64;\r\n\tconst int max_epoch = 10;\r\n\tconst float learning_rate = 0.01;\r\n\tconst float weight_decay = 1e-2;\r\n\r\n\tvector<float> data;\r\n\tvector<float> labels;\r\n\r\n\tfor (int i = 0; i < 10000; ++i) {\r\n\r\n\t\tint x1 = rand() % 2;\r\n\t\tint x2 = rand() % 2;\r\n\r\n\t\tint y = x1 ^ x2;\r\n\r\n\t\tdata.push_back(x1);\r\n\t\tdata.push_back(x2);\r\n\r\n\t\tlabels.push_back(y == 0 ? 1 : 0);\r\n\t\tlabels.push_back(y == 0 ? 0 : 1);\r\n\r\n\t}\r\n\r\n\tconst float *dptr = data.data();\r\n\tconst float *lptr = labels.data();\r\n\r\n\tContext ctx = Context::cpu();\r\n\r\n\tNDArray data_array = NDArray(Shape(10000, 1, input_width, input_height), ctx);\r\n\tNDArray label_array = NDArray(Shape(10000, output_length), ctx);\r\n\r\n\tdata_array.SyncCopyFromCPU(dptr, 10000 * input_width * input_height);\r\n\tlabel_array.SyncCopyFromCPU(lptr, 10000 * output_length);\r\n\tdata_array.WaitToRead();\r\n\tlabel_array.WaitToRead();\r\n\r\n\tNDArray train_data = data_array.Slice(0, 8000);\r\n\tNDArray train_label = label_array.Slice(0, 8000);\r\n\r\n\tNDArray val_data = data_array.Slice(8000, 10000);\r\n\tNDArray val_label = label_array.Slice(8000, 10000);\r\n\r\n\tauto net = mlp(layers);\r\n\r\n\tstd::map<string, NDArray> args;\r\n\r\n\targs[""X""] = NDArray(Shape(batch_size, 1, input_width, input_height), ctx);\r\n\targs[""label""] = NDArray(Shape(batch_size, output_length), ctx);\r\n\r\n\tnet.InferArgsMap(ctx, &args, args);\r\n\r\n\tauto initializer = Uniform(0.001);\r\n\tfor (auto &arg : args) {\r\n\t\tinitializer(arg.first, &arg.second);\r\n\t}\r\n\r\n\tOptimizer* opt = OptimizerRegistry::Find(""adam"");\r\n\topt->SetParam(""lr"", learning_rate)\r\n\t\t\t->SetParam(""wd"", weight_decay);\r\n\r\n\tauto *exec = net.SimpleBind(ctx, args);\r\n\tauto arg_names = net.ListArguments();\r\n\r\n\tfor (int iter = 0; iter < max_epoch; ++iter) {\r\n\r\n\t\tint samples = 0;\r\n\r\n\t\tauto tic = chrono::system_clock::now();\r\n\r\n\t\tsize_t start_index = 0;\r\n\t\tsize_t correct_count = 0;\r\n\t\tsize_t all_count = 0;\r\n\r\n\t\twhile (start_index < train_num) {\r\n\r\n\t\t\tif (start_index + batch_size > train_num) {\r\n\t\t\t\tstart_index = train_num - batch_size;\r\n\t\t\t}\r\n\r\n\t\t\ttrain_data.Slice(start_index, start_index + batch_size).CopyTo(&args[""X""]);\r\n\t\t\ttrain_label.Slice(start_index, start_index + batch_size).CopyTo(&args[""label""]);\r\n\r\n\t\t\tNDArray::WaitAll();\r\n\r\n\t\t\texec->Forward(true);\r\n\t\t\texec->Backward();\r\n\r\n\t\t\tfor (size_t i = 0; i < arg_names.size(); ++i) {\r\n\t\t\t\tif (arg_names[i] == ""X""  || arg_names[i] == ""label"")\r\n\t\t\t\t\tcontinue;\r\n\r\n\t\t\t\topt->Update(i, exec->arg_arrays[i], exec->grad_arrays[i]);\r\n\t\t\t}\r\n\r\n\t\t\tNDArray y(Shape(batch_size, output_length), ctx);\r\n\t\t\tNDArray y_pred(Shape(batch_size, output_length), ctx);\r\n\r\n\t\t\ttrain_label.Slice(start_index, start_index + batch_size).CopyTo(&y);\r\n\t\t\texec->outputs[0].CopyTo(&y_pred);\r\n\r\n\t\t\tNDArray::WaitAll();\r\n\r\n\t\t\tconst mx_float *ptr_y = y.GetData();\r\n\t\t\tconst mx_float *ptr_y_pred = y_pred.GetData();\r\n\r\n\t\t\tfor(int i = 0; i < batch_size; ++i) {\r\n\r\n\t\t\t\tall_count++;\r\n\r\n\t\t\t\tint correct = ptr_y[2*i] < ptr_y[2*i+1] ? 1 : 0;\r\n\t\t\t\tint predicted = ptr_y_pred[2*i] < ptr_y_pred[2*i+1] ? 1 : 0;\r\n\r\n\t\t\t\tif (correct == predicted)\r\n\t\t\t\t\tcorrect_count++;\r\n\r\n\t\t\t}\r\n\r\n\t\t\tstart_index += batch_size;\r\n\t\t\tsamples += batch_size;\r\n\r\n\t\t}\r\n\r\n\t\tauto toc = chrono::system_clock::now();\r\n\t\tfloat duration = chrono::duration_cast<chrono::milliseconds> (toc - tic).count() / 1000.0;\r\n\t\tfloat train_acc = (float) correct_count / all_count;\r\n\r\n\t\tcorrect_count = 0;\r\n\t\tall_count = 0;\r\n\r\n\t\tstart_index = 0;\r\n\r\n\t\twhile (start_index < val_num) {\r\n\r\n\t\t\tif (start_index + batch_size > val_num) {\r\n\t\t\t\tstart_index = val_num - batch_size;\r\n\t\t\t}\r\n\r\n\t\t\tval_data.Slice(start_index, start_index + batch_size).CopyTo(&args[""X""]);\r\n\t\t\tval_label.Slice(start_index, start_index + batch_size).CopyTo(&args[""label""]);\r\n\r\n\t\t\tstart_index += batch_size;\r\n\r\n\t\t\tNDArray::WaitAll();\r\n\r\n\t\t\texec->Forward(false);\r\n\r\n\t\t\tconst auto &out = exec->outputs;\r\n\r\n\t\t\tNDArray label_cpu(Shape(batch_size, output_length), ctx);\r\n\t\t\tNDArray out_cpu(Shape(batch_size, output_length), ctx);\r\n\r\n\t\t\tout[0].CopyTo(&out_cpu);\r\n\t\t\tval_label.Slice(start_index - batch_size, start_index).CopyTo(&label_cpu);\r\n\r\n\t\t\tNDArray::WaitAll();\r\n\r\n\t\t\tconst mx_float *dptr_out = out_cpu.GetData();\r\n\t\t\tconst mx_float *dptr_label = label_cpu.GetData();\r\n\r\n\t\t\tfor(int i = 0; i < batch_size; ++i) {\r\n\t\t\t\tall_count++;\r\n\r\n\t\t\t\tint correct = dptr_label[2*i] < dptr_label[2*i+1] ? 1 : 0;\r\n\t\t\t\tint predicted = dptr_out[2*i] < dptr_out[2*i+1] ? 1 : 0;\r\n\r\n\t\t\t\tif (correct == predicted)\r\n\t\t\t\t\tcorrect_count++;\r\n\r\n\t\t\t}\r\n\r\n\t\t}\r\n\r\n\t\tLG << ""Epoch: "" << iter << "" "" << samples/duration << "" samples/sec Train-Accuracy: "" << train_acc << "" Val-Accuracy: "" << (float) correct_count / all_count;\r\n\r\n\t}\r\n\r\n\tdelete exec;\r\n\tMXNotifyShutdown();\r\n\r\n\treturn 0;\r\n\r\n}\r\n```', ""I'm having the same problem, but for the lenet.cpp example using just the CPU (example in https://github.com/apache/incubator-mxnet/blob/master/cpp-package/example/lenet.cpp). I built v1.0.0 Mxnet with MKL, but that shouldn't be the issue since you have the same problem. Does lenet.cpp fail to learn for you too? "", ""I'm also experiencing the same problem here, but with LinearRegressionOutput (even with a single neuron and no activation).\r\nI see that gradients are extremely small and weight are not moving so much.\r\nAny idea?\r\n"", 'I\'m implementing a multi layer perceptron for naïve regression. I succeeded in training by creating DataBatch objects from NDArray and using them to train the model:\r\n\r\n```cpp\r\n    vector<DataBatch> data_loader;\r\n    size_t samples = 0;\r\n    while (samples < data_count) {\r\n        DataBatch mini_batch;\r\n        mini_batch.data = data_array.Slice(samples, samples + batch_size).Copy(ctx);\r\n        mini_batch.label = label_array.Slice(samples, samples + batch_size).Copy(ctx);\r\n        if (data_count-samples < batch_size)\r\n            mini_batch.pad_num = padding;\r\n        else\r\n            mini_batch.pad_num = 0;\r\n        data_loader.push_back(mini_batch);\r\n        samples += batch_size;\r\n    }\r\n\r\n```\r\nthen this can be used to train as following:\r\n\r\n```cpp\r\nfor (auto mb : data_loader) {\r\n\r\n            mb.data.CopyTo(&args[""X""]);\r\n            mb.label.CopyTo(&args[""label""]);\r\n\r\n            exec->Forward(true);\r\n            exec->Backward();\r\n\r\n            for (size_t i = 0; i < arg_names.size(); ++i) {\r\n                if (arg_names[i] == ""X"" || arg_names[i] == ""label"") continue;\r\n                opt->Update(i, exec->arg_arrays[i], exec->grad_arrays[i]);\r\n            }\r\n        }\r\n```', '@mxnet-label-bot [Training]', ""@theSparta , it seems you are using C++ API for training the model. Would you mind sharing your use case? Namely, what made you chose C++ API for training purposes over, let's say, Python API?"", 'It was a long time ago but I was trying to use the C++ API because the trained network was supposed to be interfaced with some C++ library after training to collect more training data (similar to DAgger). The final solution I ended up with was : \r\n(1) train the model in python, \r\n(2) export the trained model to C++ to run inference \r\n(3) collect more data using trained network\r\n (4) Go back to step (1)', '@theSparta ,\r\n\r\nThere were recent fixes to cpp-package. Can you please try again to see if the program works as you have expected? \r\n\r\n', '@mxnet-label-bot add [Pending Requester Info]', ""@leleamol I don't have access to my machine anymore and I stopped using MXNet a long time ago."", '@theSparta : I know you have already solved this and are not facing this issue, but could you point to the python training code that you had used to train the same model? \r\n\r\nAlso, can we close this issue now? We can reopen it if you face this issue. ', '@vdantu  I switched to Tensorflow instead to solve my problem instead of using MXNet.', ""@theSparta sorry to hear that. We still owe this issue a proper closure so I'm reopening it.\r\n@vdantu did you try to verify the code above and see if it's working? If not, why would you want to close an unsolved issue?"", 'I looked at the example given here https://github.com/apache/incubator-mxnet/issues/8126#issuecomment-333847990\r\nIt seems the example is training the xor gate with only 4 data points. This might be insufficient data to train the neural network.\r\nThe example given by @f-matt  has similar architecture but runs the training with 8000 data samples.\r\n\r\n', ""There are only 4 unique data points to train a XOR gate. Are you saying that the possible reason could have been that the network was not trained for enough epochs? Other than that, changing the batch size doesn't have any other effect in this case.""]","['C++\r\n#include <iostream>\r\n#include <map>\r\n#include <string>\r\n#include ""mxnet-cpp/MxNetCpp.h""\r\n#include ""../include/mxnet-cpp/op.h""\r\n\r\nusing namespace std;\r\nusing namespace mxnet::cpp;\r\n\r\nSymbol mlp(const vector<int> &layers, const vector<Symbol> & weights,\r\n            const std::vector<Symbol> & biases, const string & inp_name )\r\n{\r\n  auto x = Symbol::Variable(inp_name);\r\n  vector<Symbol> outputs(layers.size());\r\n\r\n  for (size_t i = 0; i < layers.size(); ++i)\r\n  {\r\n    string istr = to_string(i);\r\n    Symbol fc = FullyConnected(\r\n      i == 0? x : outputs[i-1],  // data\r\n      weights[i],\r\n      biases[i],\r\n      layers[i]);\r\n    outputs[i] = i == layers.size()-1 ? fc : LeakyReLU(string(""act"") + istr, fc, \r\n    LeakyReLUActType::kLeaky);\r\n  }\r\n  return outputs.back();\r\n}\r\n\r\nint main(int argc, char** argv)\r\n{\r\n    const int feature_size = 2;\r\n    const vector<int> layers{32, 16, 1};\r\n    const int batch_size = 100;\r\n    const int max_epoch = 10;\r\n    const float learning_rate = 0.01;\r\n    const float weight_decay = 1e-2;\r\n\r\n    auto ctx = Context::gpu(); // Use GPU for training\r\n    auto ctx_cpu = Context::cpu();\r\n\r\n    vector<Symbol> weights(layers.size());\r\n    vector<Symbol> biases(layers.size());\r\n\r\n    for (size_t i = 0; i < layers.size(); ++i)\r\n    {\r\n        string istr = to_string(i);\r\n        weights[i] = Symbol::Variable(""w"" + istr);\r\n        biases[i] = Symbol::Variable(""b"" + istr);\r\n    }\r\n    \r\n    // CONSTRUCT the network\r\n    /**********************************************************************/\r\n    auto Net = mlp(layers, weights, biases, ""X"");\r\n    auto Net2 = mlp(layers, weights, biases, ""X1"");\r\n\r\n    auto sym_label = Symbol::Variable(""label"");\r\n    auto siamese = LogisticRegressionOutput(string(""sigmoid""), Net - Net2, sym_label);\r\n\r\n    map<string, NDArray> args_map;\r\n    map<string, NDArray> aux_map;\r\n\r\n    /*we should tell mxnet the shape of data and label*/\r\n    args_map[""X""] = NDArray(Shape(batch_size, feature_size) , ctx);\r\n    args_map[""X1""] = NDArray(Shape(batch_size, feature_size) , ctx);\r\n    args_map[""label""] = NDArray(Shape(batch_size, 1), ctx);\r\n\r\n    /*with data and label, executor can be generated automatically*/\r\n    auto *exec = siamese.SimpleBind(ctx, args_map);\r\n    siamese.InferArgsMap(ctx, &args_map, args_map);\r\n    auto arg_names = siamese.ListArguments();\r\n    /**********************************************************************/\r\n\r\n    Xavier xavier = Xavier(Xavier::gaussian, Xavier::in, 2.34);\r\n    for (auto &arg : args_map)\r\n    {\r\n        if (arg.first == ""X"" || arg.first == ""X1"" || arg.first == ""label"") continue;\r\n        xavier(arg.first, &arg.second);\r\n    }\r\n\r\n    Optimizer* opt = OptimizerRegistry::Find(""adam"");\r\n    // opt->SetParam(""rescale_grad"", 1.0 / batch_size)\r\n        opt->SetParam(""lr"", learning_rate)\r\n        ->SetParam(""wd"", weight_decay);\r\n\r\n     /** DATA SETUP **/\r\n    /**********************************************************************/\r\n    int data_count = batch_size * 100;\r\n    mx_float* aptr_x = new mx_float[data_count * 2];\r\n    mx_float* aptr_x1 = new mx_float[data_count * 2];\r\n    mx_float* aptr_y = new mx_float[data_count];\r\n\r\n    // we make the data by hand, in 10 classes, with some pattern\r\n    for (int i = 0; i < data_count; i++)\r\n    {\r\n        for (int j = 0; j < 2; j++)\r\n        {\r\n          aptr_x[i * 2 + j] = (i%100 + j) *1.0f;\r\n          aptr_x1[i * 2 + j] = -(i%100 + j) *1.0f;\r\n        }\r\n        aptr_y[i] = 1;\r\n    }\r\n\r\n    NDArray data_array = NDArray(Shape(data_count, 2), ctx_cpu, false);  \r\n    NDArray data1_array = NDArray(Shape(data_count, 2), ctx_cpu, false);  \r\n    NDArray label_array = NDArray(Shape(data_count), ctx_cpu, false);\r\n    data_array.SyncCopyFromCPU(aptr_x, data_count * 2);\r\n    data1_array.SyncCopyFromCPU(aptr_x1, data_count*2);\r\n    label_array.SyncCopyFromCPU(aptr_y, data_count);\r\n    data_array.WaitToRead();\r\n    data1_array.WaitToRead();\r\n    label_array.WaitToRead();\r\n\r\n    int val_fold = 1;\r\n    size_t train_num = data_count * (1 - val_fold / 10.0);\r\n    NDArray train_data, train1_data, val_data, val1_data;\r\n    NDArray train_label, val_label;\r\n    train_data = data_array.Slice(0, train_num);\r\n    train1_data = data1_array.Slice(0, train_num);\r\n    train_label = label_array.Slice(0, train_num);\r\n    /**********************************************************************/\r\n\r\n    // TRAINING the network\r\n    Accuracy acu_train;\r\n    for (int ITER = 0; ITER < max_epoch*100; ++ITER)\r\n    {\r\n        size_t start_index = 0;\r\n        /*reset the metric every epoch*/\r\n        acu_train.Reset();\r\n        while (start_index < train_num)\r\n        {\r\n            if (start_index + batch_size > train_num)\r\n            {\r\n              start_index = train_num - batch_size;\r\n            }\r\n            args_map[""X""] =\r\n                train_data.Slice(start_index, start_index + batch_size).Copy(ctx);\r\n            args_map[""X1""] =\r\n                train1_data.Slice(start_index, start_index + batch_size).Copy(ctx);\r\n            args_map[""label""] =\r\n                train_label.Slice(start_index, start_index + batch_size).Copy(ctx);\r\n            start_index += batch_size;\r\n            NDArray::WaitAll();\r\n\r\n            exec->Forward(true);\r\n            exec->Backward();\r\n            // Update parameters\r\n            for (size_t i = 0; i < arg_names.size(); ++i)\r\n            {\r\n                if (arg_names[i] == ""X"" || arg_names[i] == ""X1"" || arg_names[i] == ""label"") continue;\r\n                opt->Update(i, exec->arg_arrays[i], exec->grad_arrays[i]);\r\n            }\r\n            NDArray::WaitAll();\r\n            acu_train.Update(args_map[""label""], exec->outputs[0]);\r\n        }\r\n        LG << ""ITER: "" << ITER << "" Train Accuracy: "" << acu_train.Get();\r\n    }\r\n\r\n    delete exec;\r\n    delete [] aptr_x;\r\n    delete [] aptr_x1;\r\n    delete [] aptr_y;\r\n    MXNotifyShutdown();\r\n    return 0;\r\n }\r\n', '\r\n[18:43:06] neural_net_eval.cpp:172: ITER: 0 Train Accuracy: 0\r\n[18:43:06] neural_net_eval.cpp:172: ITER: 1 Train Accuracy: 0\r\n[18:43:06] neural_net_eval.cpp:172: ITER: 2 Train Accuracy: 0\r\n[18:43:06] neural_net_eval.cpp:172: ITER: 3 Train Accuracy: 0\r\n[18:43:06] neural_net_eval.cpp:172: ITER: 4 Train Accuracy: 0\r\n[18:43:06] neural_net_eval.cpp:172: ITER: 5 Train Accuracy: 0\r\n[18:43:06] neural_net_eval.cpp:172: ITER: 6 Train Accuracy: 0\r\n']","['git rev-parse HEAD', 'siamese', 'LogisticRegressionOutput']",1,0
30,incubator-mxnet,7615,closed,accuracy sacrificed with multi-gpu using gluon,"## Environment info
Operating System:
Ubuntu 16.04

MXNet version: 
0.11.0

Or if installed from source:
no, using pip install mxnet-cu80

Python version and distribution:
Python27

I run the demo in [](https://github.com/zackchase/mxnet-the-straight-dope/blob/master/P06-C03-object-detection.ipynb)

and try to modify to use multi-gpu version as follows

and I try to train single-gpu and multi-gpu respectively
here are the results after 165 epochs from scratch

1. single-gpu
![](http://ww1.sinaimg.cn/mw690/9ddd8b3bly1fiw9iwppcsj20rs0rsapr.jpg)

2. multi-gpu
![](http://ww1.sinaimg.cn/mw690/9ddd8b3bly1fiw9kgp9loj20rs0rs7k0.jpg)

Is that resonable? I am not familiar with new grammar and not sure wether I made a mistale. ",,"['for 4 gpu training batchsize is 256\r\nfor 1 gpu training batchsize is 32', ""Probably because you changed batchsize but didn't adjust learning rate?\r\n\r\n@zhreshold "", '@GarrickLin So you manually modified the batchsize right?', 'yes', ""Try to reduce the batch-size, since there's a hidden mini-batch in the algorithm itself. "", 'I get the proper result after set batch_size back to 32, but the speed is obviously slowing down even worse than single-gpu. How can I adjust learning rate to suit the 256 batchsize for 4 gpu training?', 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!\nAlso, do please check out our [forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) for general ""how-to"" questions.']","['\r\n    for epoch in range(start_epoch, epochs):\r\n        train_data.reset()\r\n        cls_metric.reset()\r\n        box_metric.reset()\r\n        tic = time.time()\r\n        # iterate through all batch\r\n        for i, batch in enumerate(train_data):\r\n            btic = time.time()\r\n            # record gradients:\r\n            with ag.record():\r\n                if isinstance(ctx, mx.context.Context):\r\n                    X = [batch.data[0].as_in_context(ctx)]\r\n                    Y = [batch.label[0].as_in_context(ctx)]\r\n                elif isinstance(ctx, list):\r\n                    X = gluon.utils.split_and_load(batch.data[0], ctx)\r\n                    Y = gluon.utils.split_and_load(batch.label[0], ctx)\r\n                else:\r\n                    raise Exception(""Unexpected context type"")\r\n                loss = []\r\n                for x, y in zip(X, Y):\r\n                    default_anchors, class_predictions, box_predictions = net(x)\r\n                    box_target, box_mask, cls_target = training_targets(default_anchors, class_predictions, y)\r\n                    # losses\r\n                    loss1 = cls_loss(class_predictions, cls_target)\r\n                    loss2 = box_loss(box_predictions, box_target, box_mask)\r\n                    # sum all losses\r\n                    loss.append(loss1 + loss2)\r\n                for l in loss:\r\n                    # backpropagate\r\n                    l.backward()\r\n            # apply\r\n            trainer.step(batch_size)\r\n            # update metrics\r\n            cls_metric.update([cls_target], [nd.transpose(class_predictions, (0, 2, 1))])\r\n            box_metric.update([box_target], [box_predictions * box_mask])\r\n            if (i + 1) % log_interval == 0:\r\n                name1, val1 = cls_metric.get()\r\n                name2, val2 = box_metric.get()\r\n                print \'[Epoch %d Batch %d] speed: %f samples/s, training: %s=%f, %s=%f\' % \\\r\n                      (epoch, i, batch_size / (time.time() - btic), name1, val1, name2, val2)\r\n        nd.waitall()\r\n        # end of epoch logging\r\n        name1, val1 = cls_metric.get()\r\n        name2, val2 = box_metric.get()\r\n        print \'[Epoch %d] training: %s=%f, %s=%f\' % (epoch, name1, val1, name2, val2)\r\n        print \'[Epoch %d] time cost: %f\' % (epoch, time.time() - tic)\r\n']",['P06-C03-object-detection.ipynb'],1,0
31,incubator-mxnet,17086,closed,[MKLDNN] RNN Op gradient computation is broken,"## Description
RNN op gradient computation on CPU is broken for the source built mxnet. 

I was running a language model training script on my ec2 instance. I tested the script with the latest source built mxnet. During training, I ran into the following log:

### Log Message

The loss value does not change any more. If I use the mxnet build by pip installation  .  The log is normal. There is no gradient  warning and the loss keeps changing:

## To Reproduce
The training script can be found at .  To reproduce the log message, I ran the script with the following command:


## What have you tried to solve it?

The problem occurred when computing gradients (https://github.com/dmlc/gluon-nlp/blob/master/scripts/language_model/word_language_model.py#L381)

Some gradient values are of order . Normally the gradient value should be within .

Thanks to @leezu , he found the error was introduced because of the MKLDNN option. If we use mxnet built from source with MKLDNN turned on, i.e., , the gradient error appears whereas the problem is gone when . Therefore the issue can be traced back to the MKLDNN. @zixuanweeei @ciyongch @pengzhao-intel  

## Environment

My environment specs can be found here

",Bug MKLDNN,"['Thanks for reporting this issue. We will take a look.', '@liuzh91 I can reproduce the result. The gradients of bias in LSTM are very large as you mentioned, and the gradient of weights in LSTM looks normal. Currently, we can `export MXNET_USE_MKLDNN_RNN=0` for a workaround. It would be highly appreciated if you could give a try  upon 52c9a45abc8d1f8228ec9ed1bad7f137137fd96b.', '@zixuanweeei I previously confirmed the issue still happens with 897f4fae075c5261958de1a07cded0b5b3058a7a ', '> @zixuanweeei I previously confirmed the issue still happens with [897f4fa](https://github.com/apache/incubator-mxnet/commit/897f4fae075c5261958de1a07cded0b5b3058a7a)\r\n\r\nThanks for the reply. Can `MXNET_USE_MKLDNN_RNN=0` work with 897f4fa and 52c9a45?', 'Yes, `MXNET_USE_MKLDNN_RNN=0` on 52c9a45 is a workaround for the issue.', '52c9a45 is applied to max pooling. I think it has nothing to do with RNN?', ""> [52c9a45](https://github.com/apache/incubator-mxnet/commit/52c9a45abc8d1f8228ec9ed1bad7f137137fd96b) is applied to max pooling. I think it has nothing to do with RNN?\r\n\r\nNah. It didn't fix the gradient explosion issue. "", ""@szhengac @liuzh91 The current gradient explosion issue is not fixed yet, we're working on this. For now, the `MXNET_USE_MKLDNN_RNN=0` is the workaround after the commit [897f4fa](https://github.com/apache/incubator-mxnet/commit/897f4fae075c5261958de1a07cded0b5b3058a7a), and is also applicable to [52c9a45](https://github.com/apache/incubator-mxnet/commit/52c9a45abc8d1f8228ec9ed1bad7f137137fd96b) ."", ""Hi, @liuzh91 @szhengac. We have posted https://github.com/apache/incubator-mxnet/pull/17183 to fix the gradient explosion issue in RNN Backward. Thanks for reporting this issue again. And it would be greatly appreciated if you could give a test on this patch. Thanks.\r\n\r\nBTW, we got the below training log:\r\n```\r\n❯ python word_language_model.py --log-interval=1\r\n/path/to/mxnet/python/mxnet/optimizer/optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\r\n  Optimizer.opt_registry[name].__name__))\r\nNamespace(alpha=2, batch_size=80, beta=1, bptt=70, clip=0.25, dropout=0.4, dropout_e=0.1, dropout_h=0.2, dropout_i=0.65, emsize=400, epochs=750, eval_only=False, gpu=None, log_interval=1, lr=30, lr_update_factor=0.1, lr_update_interval=30, model='lstm', nhid=1150, nlayers=3, ntasgd=False, optimizer='sgd', save='model.params', test_mode=False, tied=False, wd=1.2e-06, weight_dropout=0.5)\r\nUse AWDRNN\r\nAWDRNN(\r\n  (embedding): HybridSequential(\r\n    (0): Embedding(33278 -> 400, float32)\r\n    (1): Dropout(p = 0.65, axes=(0,))\r\n  )\r\n  (encoder): HybridSequential(\r\n    (0): LSTM(400 -> 1150, TNC)\r\n    (1): LSTM(1150 -> 1150, TNC)\r\n    (2): LSTM(1150 -> 1150, TNC)\r\n  )\r\n  (decoder): HybridSequential(\r\n    (0): Dense(None -> 33278, linear)\r\n  )\r\n)\r\n[Epoch 0 Batch 1/372] current loss 20.50, ppl 796977445.38, throughput 18.37 samples/s, lr 30.86\r\n[Epoch 0 Batch 2/372] current loss 9.51, ppl 13511.50, throughput 39.56 samples/s, lr 28.29\r\n[Epoch 0 Batch 3/372] current loss 17.53, ppl 41003388.51, throughput 40.65 samples/s, lr 27.43\r\n[Epoch 0 Batch 4/372] current loss 9.45, ppl 12761.47, throughput 40.39 samples/s, lr 27.43\r\n[Epoch 0 Batch 5/372] current loss 14.34, ppl 1695623.66, throughput 35.59 samples/s, lr 31.71\r\n[Epoch 0 Batch 6/372] current loss 9.40, ppl 12113.46, throughput 35.10 samples/s, lr 32.14\r\n[Epoch 0 Batch 7/372] current loss 8.56, ppl 5232.00, throughput 37.62 samples/s, lr 30.00\r\n[Epoch 0 Batch 8/372] current loss 9.32, ppl 11163.67, throughput 42.00 samples/s, lr 26.57\r\n[Epoch 0 Batch 9/372] current loss 8.44, ppl 4642.37, throughput 61.95 samples/s, lr 17.14\r\n[Epoch 0 Batch 10/372] current loss 8.92, ppl 7494.76, throughput 41.39 samples/s, lr 27.00\r\n```"", ""> Hi, @liuzh91 @szhengac. We have posted #17183 to fix the gradient explosion issue in RNN Backward. Thanks for reporting this issue again. And it would be greatly appreciated if you could give a test on this patch. Thanks.\r\n> \r\n> BTW, we got the below training log:\r\n> \r\n> ```\r\n> ❯ python word_language_model.py --log-interval=1\r\n> /path/to/mxnet/python/mxnet/optimizer/optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\r\n>   Optimizer.opt_registry[name].__name__))\r\n> Namespace(alpha=2, batch_size=80, beta=1, bptt=70, clip=0.25, dropout=0.4, dropout_e=0.1, dropout_h=0.2, dropout_i=0.65, emsize=400, epochs=750, eval_only=False, gpu=None, log_interval=1, lr=30, lr_update_factor=0.1, lr_update_interval=30, model='lstm', nhid=1150, nlayers=3, ntasgd=False, optimizer='sgd', save='model.params', test_mode=False, tied=False, wd=1.2e-06, weight_dropout=0.5)\r\n> Use AWDRNN\r\n> AWDRNN(\r\n>   (embedding): HybridSequential(\r\n>     (0): Embedding(33278 -> 400, float32)\r\n>     (1): Dropout(p = 0.65, axes=(0,))\r\n>   )\r\n>   (encoder): HybridSequential(\r\n>     (0): LSTM(400 -> 1150, TNC)\r\n>     (1): LSTM(1150 -> 1150, TNC)\r\n>     (2): LSTM(1150 -> 1150, TNC)\r\n>   )\r\n>   (decoder): HybridSequential(\r\n>     (0): Dense(None -> 33278, linear)\r\n>   )\r\n> )\r\n> [Epoch 0 Batch 1/372] current loss 20.50, ppl 796977445.38, throughput 18.37 samples/s, lr 30.86\r\n> [Epoch 0 Batch 2/372] current loss 9.51, ppl 13511.50, throughput 39.56 samples/s, lr 28.29\r\n> [Epoch 0 Batch 3/372] current loss 17.53, ppl 41003388.51, throughput 40.65 samples/s, lr 27.43\r\n> [Epoch 0 Batch 4/372] current loss 9.45, ppl 12761.47, throughput 40.39 samples/s, lr 27.43\r\n> [Epoch 0 Batch 5/372] current loss 14.34, ppl 1695623.66, throughput 35.59 samples/s, lr 31.71\r\n> [Epoch 0 Batch 6/372] current loss 9.40, ppl 12113.46, throughput 35.10 samples/s, lr 32.14\r\n> [Epoch 0 Batch 7/372] current loss 8.56, ppl 5232.00, throughput 37.62 samples/s, lr 30.00\r\n> [Epoch 0 Batch 8/372] current loss 9.32, ppl 11163.67, throughput 42.00 samples/s, lr 26.57\r\n> [Epoch 0 Batch 9/372] current loss 8.44, ppl 4642.37, throughput 61.95 samples/s, lr 17.14\r\n> [Epoch 0 Batch 10/372] current loss 8.92, ppl 7494.76, throughput 41.39 samples/s, lr 27.00\r\n> ```\r\n\r\nThank you for the commit. We will double check whether the bug still exists."", '@liuzh91 Did you have any chance to try the patch? Happy new year~', ""> @liuzh91 Did you have any chance to try the patch? Happy new year~\r\n\r\nI haven't. I'll take a try this week."", '@zixuanweeei @TaoLv  I can confirm the new patch works correctly on the language model script. Thanks for the patch.', '> @zixuanweeei @TaoLv I can confirm the new patch works correctly on the language model script. Thanks for the patch.\r\n\r\nThanks for your kindness. Very happy to receive the good news. Happy new year~', '@liuzh91 Nice to hear that and thank you for trying it out. Would you mind approving #17183 if it looks good to you? Also please propose if you feel the issue is critical and hope the fix to be included into 1.6 release. Thanks!', '@TaoLv I checkd and this issue affects 1.6. As it was recently decided to distribute the MKL builds by default this fix must be backported.\r\nCC @ptrendx ']","[""\r\nubuntu@ip-172-31-23-26:~/bug_fix/gluon-nlp/scripts/language_model$ python word_language_model.py --log-interval=1\r\n/home/ubuntu/clean_mxnet/incubator-mxnet/python/mxnet/optimizer/optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\r\n  Optimizer.opt_registry[name].__name__))\r\nNamespace(alpha=2, batch_size=80, beta=1, bptt=70, clip=0.25, dropout=0.4, dropout_e=0.1, dropout_h=0.2, dropout_i=0.65, emsize=400, epochs=750, eval_only=False, gpu=None, log_interval=1, lr=30, lr_update_factor=0.1, lr_update_interval=30, model='lstm', nhid=1150, nlayers=3, ntasgd=False, optimizer='sgd', save='model.params', test_mode=False, tied=False, wd=1.2e-06, weight_dropout=0.5)\r\nUse AWDRNN\r\nAWDRNN(\r\n  (embedding): HybridSequential(\r\n    (0): Embedding(33278 -> 400, float32)\r\n    (1): Dropout(p = 0.65, axes=(0,))\r\n  )\r\n  (encoder): HybridSequential(\r\n    (0): LSTM(400 -> 1150, TNC)\r\n    (1): LSTM(1150 -> 1150, TNC)\r\n    (2): LSTM(1150 -> 1150, TNC)\r\n  )\r\n  (decoder): HybridSequential(\r\n    (0): Dense(None -> 33278, linear)\r\n  )\r\n)\r\nword_language_model.py:382: UserWarning: nan or inf is detected. Clipping results will be undefined.\r\n  gluon.utils.clip_global_norm(grads, args.clip)\r\n[Epoch 0 Batch 1/372] current loss 20.83, ppl 1107330721.37, throughput 0.71 samples/s, lr 29.14\r\n[Epoch 0 Batch 2/372] current loss 10.41, ppl 33276.90, throughput 1.39 samples/s, lr 29.57\r\n[Epoch 0 Batch 3/372] current loss 10.41, ppl 33276.58, throughput 1.42 samples/s, lr 28.71\r\n[Epoch 0 Batch 4/372] current loss 10.41, ppl 33276.17, throughput 1.33 samples/s, lr 30.43\r\n[Epoch 0 Batch 5/372] current loss 10.41, ppl 33276.86, throughput 1.40 samples/s, lr 29.14\r\n"", ""\r\npython word_language_model.py --log-interval=1                                                         /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/optimizer/optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\r\n  Optimizer.opt_registry[name].__name__))\r\nNamespace(alpha=2, batch_size=80, beta=1, bptt=70, clip=0.25, dropout=0.4, dropout_e=0.1, dropout_h=0.2, dropout_i=0.65, emsize=400, epochs=750, eval_only=False, gpu=None, log_interval=1, lr=30, lr_update_factor=0.1, lr_update_interval=30, model='lstm', nhid=1150, nlayers=3, ntasgd=False, optimizer='sgd', save='model.params', test_mode=False, tied=False, wd=1.2e-06, weight_dropout=0.5)\r\nUse AWDRNN\r\nAWDRNN(\r\n  (embedding): HybridSequential(\r\n    (0): Embedding(33278 -> 400, float32)\r\n    (1): Dropout(p = 0.65, axes=(0,))\r\n  )\r\n  (encoder): HybridSequential(\r\n    (0): LSTM(400 -> 1150, TNC)\r\n    (1): LSTM(1150 -> 1150, TNC)\r\n    (2): LSTM(1150 -> 1150, TNC)\r\n  )\r\n  (decoder): HybridSequential(\r\n    (0): Dense(None -> 33278, linear)\r\n  )\r\n)\r\n[Epoch 0 Batch 1/372] current loss 20.50, ppl 796093229.98, throughput 2.13 samples/s, lr 29.14\r\n[Epoch 0 Batch 2/372] current loss 9.57, ppl 14283.55, throughput 4.20 samples/s, lr 29.57\r\n[Epoch 0 Batch 3/372] current loss 17.85, ppl 56261658.19, throughput 4.32 samples/s, lr 28.71\r\n[Epoch 0 Batch 4/372] current loss 9.50, ppl 13370.27, throughput 4.08 samples/s, lr 30.43\r\n[Epoch 0 Batch 5/372] current loss 14.46, ppl 1903888.17, throughput 4.26 samples/s, lr 29.14\r\n"", ""\r\n----------Python Info----------\r\nVersion      : 3.6.6\r\nCompiler     : GCC 7.2.0\r\nBuild        : ('default', 'Jun 28 2018 17:14:51')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 19.2.3\r\nDirectory    : /home/ubuntu/anaconda3/lib/python3.6/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.6.0\r\nDirectory    : /home/ubuntu/clean_mxnet/incubator-mxnet/python/mxnet\r\nNum GPUs     : 0\r\nHashtag not found. Not installed from pre-built package.\r\n----------System Info----------\r\nPlatform     : Linux-4.15.0-1056-aws-x86_64-with-debian-buster-sid\r\nsystem       : Linux\r\nnode         : ip-172-31-23-26\r\nrelease      : 4.15.0-1056-aws\r\nversion      : #58-Ubuntu SMP Tue Nov 26 15:14:34 UTC 2019\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:        x86_64\r\nCPU op-mode(s):      32-bit, 64-bit\r\nByte Order:          Little Endian\r\nCPU(s):              8\r\nOn-line CPU(s) list: 0-7\r\nThread(s) per core:  2\r\nCore(s) per socket:  4\r\nSocket(s):           1\r\nNUMA node(s):        1\r\nVendor ID:           GenuineIntel\r\nCPU family:          6\r\nModel:               79\r\nModel name:          Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\nStepping:            1\r\nCPU MHz:             2702.241\r\nCPU max MHz:         3000.0000\r\nCPU min MHz:         1200.0000\r\nBogoMIPS:            4600.12\r\nHypervisor vendor:   Xen\r\nVirtualization type: full\r\nL1d cache:           32K\r\nL1i cache:           32K\r\nL2 cache:            256K\r\nL3 cache:            46080K\r\nNUMA node0 CPU(s):   0-7\r\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt\r\n""]","['pip install https://apache-mxnet.s3-us-west-2.amazonaws.com/dist/2019-12-15/dist/mxnet_cu100-1.6.0b20191215-py2.py3-none-manylinux1_x86_64.whl', 'Inf', 'https://github.com/dmlc/gluon-nlp/blob/master/scripts/language_model/word_language_model.py', 'python word_language_model.py --log-interval=1', '10^34', '[-10, 10]', '-DUSE_MKLDNN=ON', 'MKLDNN=OFF']",1,0
32,incubator-mxnet,6974,closed,NDArray.asnumpy() very slow,"I want to get network output in numpy array, which can be achieved with the  method. But I found this very slow since it copies all the elements. The computation takes only a few ms, while the  call takes 100+ ms. How can I obtain the numpy array more efficiently?

I also tried to directly manipulate the mxnet NDArray. I used  or , since ""multi-dimension indexing is not supported"". But both methods only support slicing a contiguous region. This makes a big trouble for me.

BTW, I run my program on CPU and the arrays are of size ~2000x6.",,"['NDArray computations are async, when you run a = b + c etc, the op is issued to the engine and returns immediately. `.asnumpy()` is waiting on that computation to be done. You can see this by calling NDArray.wait_to_read() before `.asnumpy()`', ""@piiswrong Thanks! My bad. I didn't realize that the computation was actually still running. I understand it now.""]",[],"['NDArray.asnumpy()', 'NDArray.asnumpy()', 'slice()', 'slice_axis()']",1,0
33,incubator-mxnet,9026,closed,why is it so slow (MXNET0.12)even with NVIDIA V100 GPU?,"I test my py on AWS EC2 P3.2xlarge(GPU:V100), AMI: ami-77eb3a0f, python version : 2.7. The .py is as follow:

On my own host, win10, mx0.12, gpu:940M,  I got near 110 samples/seconds with default params,  but surprisingly, on p3.2xlarge, I got only 170 samples/seconds. In detail, with ,  I found the volatile GPU utile is always near 0%, up t0 4%.  WHY???   Is that just because I got a custom DataIter?




",Application Data-loading Performance,"[""Hi @dbsxdbsx, thanks for posting demo code.  Looking quickly at your code I would guess you're correct, it's probably data iterator related.  If you run htop while training do you see one thread with near 100% cpu usage?"", '@KellenSunderland ,thanks for your answer.  This time , I change to another GPU EC2 called p2.xlarge. Anyway , this change would not make big difference.\r\n#[the cpu usage pic](https://share.weiyun.com/324107260459aa96240ad475577d419c)\r\n#[the gpu usage pic](https://share.weiyun.com/38c9f8703edb1e71c7308ad9f9026435)\r\nAs you can see , there are 6 threads running this script, one shows 101---I guess it means  over 100% usage?     And without exception, the gpu usage is still low. \r\n\r\nand on contrary, running the mnist example below would give over 50% of GPU usage, and it really depends on batch_size:\r\n```\r\nimport mxnet as mx\r\n\r\nimport  argparse\r\ndef parse_args(description):\r\n    parser = argparse.ArgumentParser(description=description)\r\n    parser.add_argument(\'--batch_size\', dest=\'batch_size\', type=int, default=8)\r\n    parser.add_argument(\'--train_exp_num\', dest=\'train_exp_num\', type=int, default=2000)\r\n    parser.add_argument(\'--epoch_num\', dest=\'epoch_num\', type=int, default=50)\r\n    parser.add_argument(\'--gpu_num\', dest=\'gpu_num\', type=int, default=1)\r\n    parser.add_argument(\'--lr\', dest=\'lr\', type=float, default=0.00075)\r\n\r\n    args = parser.parse_args()\r\n    return args\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    args=parse_args(\'for mnist\')\r\n    mnist = mx.test_utils.get_mnist()\r\n\r\n    batch_size =args.batch_size #100\r\n    train_iter = mx.io.NDArrayIter(mnist[\'train_data\'], mnist[\'train_label\'], batch_size, shuffle=True)\r\n    val_iter = mx.io.NDArrayIter(mnist[\'test_data\'], mnist[\'test_label\'], batch_size)\r\n\r\n    data = mx.sym.var(\'data\')\r\n    # first conv layer\r\n    conv1 = mx.sym.Convolution(data=data, kernel=(5, 5), num_filter=20)\r\n    tanh1 = mx.sym.Activation(data=conv1, act_type=""tanh"")\r\n    pool1 = mx.sym.Pooling(data=tanh1, pool_type=""max"", kernel=(2, 2), stride=(2, 2))\r\n    # second conv layer\r\n    conv2 = mx.sym.Convolution(data=pool1, kernel=(5, 5), num_filter=50)\r\n    tanh2 = mx.sym.Activation(data=conv2, act_type=""tanh"")\r\n    pool2 = mx.sym.Pooling(data=tanh2, pool_type=""max"", kernel=(2, 2), stride=(2, 2))\r\n    # first fullc layer\r\n    flatten = mx.sym.flatten(data=pool2)\r\n    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\r\n    tanh3 = mx.sym.Activation(data=fc1, act_type=""tanh"")\r\n    # second fullc\r\n    fc2 = mx.sym.FullyConnected(data=tanh3, num_hidden=10)\r\n    # softmax loss\r\n    lenet = mx.sym.SoftmaxOutput(data=fc2, name=\'softmax\')\r\n\r\n    import logging\r\n\r\n    logging.getLogger().setLevel(logging.DEBUG)  # logging to stdout\r\n    # create a trainable module on GPU 0\r\n    lenet_model = mx.mod.Module(symbol=lenet, context=mx.gpu())\r\n    # train with the same\r\n    lenet_model.fit(train_iter,\r\n                    eval_data=val_iter,\r\n                    optimizer=\'sgd\',\r\n                    optimizer_params={\'learning_rate\': 0.1},\r\n                    eval_metric=\'acc\',\r\n                    batch_end_callback=mx.callback.Speedometer(batch_size, 100),\r\n                    num_epoch=10)\r\n\r\n```\r\nSo I wonder how to make full usage of gpu? As far as I know, that increasing batch_size is useful--- but not for my script.\r\nAnd as the gpu usage often  fluctuates from 0 to 19 in no time. I guess whether  it is due to my dataiter  creating data for every batch at real time ?   If this is the problem, how to fix it?\r\n\r\n', ""Could we switch to some faster way for data feeding?  I didn't see any way to do multi-thread with DataIter.  I don't think `PrefetchingIter` works here because the data is already in memory.\r\n\r\nAny suggestions are welcome.  Thank you!"", '@dbsxdbsx I suggest that you switch to Gluon and use a `DataLoader` with `num_workers`>1.\r\nThe bottleneck seems to be your image generation that is currently done synchronously rather than asynchronously.\r\nWith Gluon you could simply subclass the `Dataset` class to generate your captcha asynchronously using a `DataLoader`. That should solve your I/O issue and you should witness an increase in the GPU utilization.', ""@ThomasDelteil ,thanks for your answer.  I think the problem here is that the dataset of captcha is generated online while training. Therefore, the gpu has to wait  until cpu generates new batches of data.   I guess this is the main issue, and I guess this is what you mean, right?  And another problem  is that I didn't see any example about using gluon Dataloader with data produced online---Could you show one?\r\n I DO WANT TO make everything with Dataloader."", ""@dbsxdbsx It's quite easy to use DataLoader with a custom DataSet object. Your custom DataSet class needs to implement only two functions: `__len__()` and `__getitem_()`. You can then easily use DataLoader with num_workers>1. Here is a dummy example of a custom dataset class that contains 1000 elements, each one the index plus some random noise:\r\n\r\n```\r\nclass MyRandomDataset(object):\r\n    def __getitem__(self, idx):\r\n        return nd.array([idx]) + nd.random.normal()\r\n\r\n    def __len__(self):\r\n        return 1000\r\n```"", '@safrooze Thanks']","['\r\n\'\'\'this is a py used to predict capts num ranging from 4 to 10~\r\nTherefore, the DataIter should predict capt examples of different size, even in a batch_size\'\'\'\r\n\r\nfont_name = \'segoeuib.ttf\'\r\n\r\nimport sys\r\n\r\nsys.path.insert(0, ""../../python"")\r\nsys.path.append(\'../\')\r\nsys.path.append(\'../../\')\r\nimport mxnet as mx\r\nimport numpy as np\r\nimport cv2, random\r\nfrom captcha.image import ImageCaptcha\r\n\r\n\r\nclass OCRBatch(object):\r\n    def __init__(self, data_names, data, label_names, label):\r\n        self.data = data\r\n        self.label = label\r\n        self.data_names = data_names\r\n        self.label_names = label_names\r\n\r\n    @property\r\n    def provide_data(self):\r\n        return [(n, x.shape) for n, x in zip(self.data_names, self.data)]\r\n\r\n    @property\r\n    def provide_label(self):\r\n        return [(n, x.shape) for n, x in zip(self.label_names, self.label)]\r\n\r\n\r\ndef gen_rand(capt_num):\r\n    buf = """"\r\n    for i in range(capt_num):\r\n        buf += str(random.randint(0, 9))\r\n    return buf\r\n\r\n\r\ndef get_label(capt_str, capt_max_num):\r\n    a = [int(x) for x in capt_str]\r\n    # for max 10 label, if the capt_num is less than 10, fulfill with -1\r\n    min_pos = len(a)\r\n    for i in range(min_pos, capt_max_num):\r\n        a.append(11)  # -1\r\n    return np.array(a)\r\n\r\n\r\ndef gen_sample(captcha, width, height, capt_num):\r\n    num = gen_rand(capt_num)\r\n    img = captcha.generate(num)\r\n    img = np.fromstring(img.getvalue(), dtype=\'uint8\')\r\n    img = cv2.imdecode(img, cv2.IMREAD_COLOR)\r\n    img = cv2.resize(img, (width, height))\r\n\r\n    img = np.multiply(img, 1 / 255.0)\r\n    img = img.transpose(2, 0, 1)\r\n    return (num, img)\r\n\r\n\r\nclass OCRIter(mx.io.DataIter):\r\n    def __init__(self, count, batch_size, height, width):\r\n        super(OCRIter, self).__init__()\r\n        self.captcha = ImageCaptcha(fonts=[font_name])\r\n\r\n        self.batch_size = batch_size\r\n        self.count = count\r\n        self.height = height\r\n        self.width = width\r\n        self.provide_data = [(\'data\', (batch_size, 3, height, width))]\r\n        self.capt_max_num = 10\r\n        self.provide_label = [(\'softmax_label\', (self.batch_size, self.capt_max_num))]  # ori version\r\n        # self.provide_label = [(\'softmax1_label\', (self.batch_size,)),\r\n        #                       (\'softmax2_label\', (self.batch_size,)),\r\n        #                       # (\'softmax3_label\', (self.batch_size,)),\r\n        #                       # (\'softmax4_label\', (self.batch_size,)),\r\n        #                       ]\r\n\r\n    def __iter__(self):\r\n        for k in range(self.count / self.batch_size):\r\n            data = []\r\n            label = []  # ori version\r\n            # label = [[], [], [], []]\r\n            for i in range(self.batch_size):\r\n                capt_num_for_1_example = np.random.randint(4, 10, size=1)\r\n                capt_num, img = gen_sample(self.captcha, self.width, self.height, capt_num_for_1_example)\r\n                data.append(img)\r\n                label.append(get_label(capt_num, self.capt_max_num))\r\n                # num = [int(x) for x in num]\r\n                # for i in range(4):\r\n                #     label[i].append(num[i])\r\n\r\n            data_all = [mx.nd.array(data)]\r\n            label_all = [mx.nd.array(label)]\r\n            data_names = [\'data\']\r\n            label_names = [\'softmax_label\']\r\n\r\n            data_batch = OCRBatch(data_names, data_all, label_names, label_all)  # ori version\r\n            # data_batch = mx.io.DataBatch(data=data_all, label=label_all)\r\n            yield data_batch\r\n\r\n    def reset(self):\r\n        pass\r\n\r\n\r\ndef get_ocrnet():\r\n    data = mx.symbol.Variable(\'data\')\r\n    label = mx.symbol.Variable(\'softmax_label\')\r\n    conv1 = mx.symbol.Convolution(data=data, kernel=(5, 5), num_filter=32)\r\n    pool1 = mx.symbol.Pooling(data=conv1, pool_type=""max"", kernel=(2, 2), stride=(1, 1))\r\n    relu1 = mx.symbol.Activation(data=pool1, act_type=""relu"")\r\n\r\n    conv2 = mx.symbol.Convolution(data=relu1, kernel=(5, 5), num_filter=32)\r\n    pool2 = mx.symbol.Pooling(data=conv2, pool_type=""avg"", kernel=(2, 2), stride=(1, 1))\r\n    relu2 = mx.symbol.Activation(data=pool2, act_type=""relu"")\r\n\r\n    conv3 = mx.symbol.Convolution(data=relu2, kernel=(3, 3), num_filter=32)\r\n    pool3 = mx.symbol.Pooling(data=conv3, pool_type=""avg"", kernel=(2, 2), stride=(1, 1))\r\n    relu3 = mx.symbol.Activation(data=pool3, act_type=""relu"")\r\n\r\n    conv4 = mx.symbol.Convolution(data=relu3, kernel=(3, 3), num_filter=32)\r\n    pool4 = mx.symbol.Pooling(data=conv4, pool_type=""avg"", kernel=(2, 2), stride=(1, 1))\r\n    relu4 = mx.symbol.Activation(data=pool4, act_type=""relu"")\r\n\r\n    flatten = mx.symbol.Flatten(data=relu4)\r\n    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=256)\r\n    fc21 = mx.symbol.FullyConnected(data=fc1, num_hidden=10)\r\n    fc22 = mx.symbol.FullyConnected(data=fc1, num_hidden=10)\r\n    fc23 = mx.symbol.FullyConnected(data=fc1, num_hidden=10)\r\n    fc24 = mx.symbol.FullyConnected(data=fc1, num_hidden=10)\r\n    fc25 = mx.symbol.FullyConnected(data=fc1, num_hidden=10)\r\n    fc26 = mx.symbol.FullyConnected(data=fc1, num_hidden=10)\r\n    fc27 = mx.symbol.FullyConnected(data=fc1, num_hidden=10)\r\n    fc28 = mx.symbol.FullyConnected(data=fc1, num_hidden=10)\r\n    fc29 = mx.symbol.FullyConnected(data=fc1, num_hidden=10)\r\n    fc210 = mx.symbol.FullyConnected(data=fc1, num_hidden=10)\r\n\r\n    fc2 = mx.symbol.Concat(*[fc21, fc22, fc23, fc24, fc25, fc26, fc27, fc28, fc29, fc210], dim=0)\r\n    label = mx.symbol.transpose(data=label)\r\n    label = mx.symbol.Reshape(data=label, target_shape=(0,))\r\n    return mx.symbol.SoftmaxOutput(data=fc2, label=label, name=""softmax"")\r\n\r\n\r\ndef Accuracy(label, pred):\r\n    """"""the old version, I just think the pos is calculated wrong~""""""\r\n    label = label.T.reshape((-1,))\r\n    hit = 0\r\n    total = 0\r\n    for i in range(pred.shape[0] / capt_num):\r\n        ok = True\r\n        for j in range(capt_num):\r\n            k = i * capt_num + j\r\n            if np.argmax(pred[k]) != int(label[k]):\r\n                ok = False\r\n                break\r\n        if ok:\r\n            hit += 1\r\n        total += 1\r\n    return 1.0 * hit / total\r\n\r\n\r\ndef Accuracy2(label, pred):\r\n    """"""new  version made by me""""""\r\n    hit = 0\r\n    total = 0\r\n    batch_size = pred.shape[0] / capt_num\r\n    for i in range(batch_size):\r\n        ok = True\r\n        for j in range(capt_num):\r\n            k = j * batch_size + i\r\n            if np.argmax(pred[k]) != int(label[i, j]):\r\n                ok = False\r\n                break\r\n        if ok:\r\n            hit += 1\r\n        total += 1\r\n    return 1.0 * hit / total\r\n\r\n\r\nimport argparse\r\n\r\n\r\ndef parse_args(description):\r\n    parser = argparse.ArgumentParser(description=description)\r\n    parser.add_argument(\'--batch_size\', dest=\'batch_size\', type=int, default=8)\r\n    parser.add_argument(\'--train_exp_num\', dest=\'train_exp_num\', type=int, default=2000)\r\n    parser.add_argument(\'--epoch_num\', dest=\'epoch_num\', type=int, default=50)\r\n    parser.add_argument(\'--gpu_num\', dest=\'gpu_num\', type=int, default=1)\r\n    parser.add_argument(\'--lr\', dest=\'lr\', type=float, default=0.00075)\r\n\r\n    args = parser.parse_args()\r\n    return args\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    import logging\r\n\r\n    head = \'%(asctime)-15s %(message)s\'\r\n    logging.basicConfig(level=logging.DEBUG, format=head)\r\n\r\n    args = parse_args(\'train 4 to 10 capt in 1 net\')\r\n    network = get_ocrnet()\r\n    batch_size = args.batch_size  # 50\r\n    train_exp_num = args.train_exp_num  # 10000  # 50000\r\n    test_exp_num = 1000\r\n    epoch_num = args.epoch_num  # 2000\r\n    gpu_num = args.gpu_num\r\n    lr = args.lr\r\n    devs = [mx.gpu(i) for i in range(gpu_num)]\r\n    # model = mx.model.FeedForward(ctx=devs,\r\n    #                              symbol=network,\r\n    #                              num_epoch=epoch_num,\r\n    #                              learning_rate=lr,\r\n    #                              wd=0.00001,\r\n    #                              initializer=mx.init.Xavier(factor_type=""in"", magnitude=2.34),\r\n    #                              momentum=0.9)\r\n    global capt_num\r\n    capt_num = 10\r\n    data_train = OCRIter(train_exp_num, batch_size, 30, 80)\r\n    data_test = OCRIter(test_exp_num, batch_size, 30, 80)\r\n\r\n    # model.fit(X=data_train,\r\n    #           eval_data=data_test,\r\n    #           eval_metric=[Accuracy, Accuracy2],\r\n    #           batch_end_callback=mx.callback.Speedometer(batch_size, 50),\r\n    #           epoch_end_callback=mx.callback.do_checkpoint(prefix=\'param\', period=2))\r\n\r\n\r\n\r\n\r\n    # new version\r\n    lenet_model = mx.mod.Module(symbol=network, context=devs)\r\n    # train with the same\r\n    lenet_model.fit(data_train,\r\n                    eval_data=data_test,\r\n                    optimizer=\'sgd\',\r\n                    optimizer_params={\'learning_rate\': lr, \'momentum\': 0.9, \'wd\': 0.00001},\r\n                    eval_metric=[Accuracy, Accuracy2],\r\n                    initializer=mx.init.Xavier(factor_type=""in"", magnitude=2.34),\r\n                    batch_end_callback=mx.callback.Speedometer(batch_size, 50),\r\n                    epoch_end_callback=mx.callback.do_checkpoint(prefix=\'param\', period=2),\r\n                    num_epoch=epoch_num)\r\n\r\n\r\n    # model.save(""cnn-ocr"")\r\n']",['watch -n 1 nvidia-smi'],1,0
34,incubator-mxnet,4163,closed,'fixed_param_names' and 'lr_mult' behave differently,"I was using the python version of MXNet on a 64-bit Ubuntu 16.04 OS.

I changed the fully connected layers in the VGG-16 network and I wanted to fine-tune it.
At first I used the 'fixed_param_names' in mx.mod.Module class and it seemed to be working very well. The accuracy was getting better and better, with a 75% accuracy at 10th epoch.
Then I saved a checkpoint at the 10th epoch, changed the module by removing the 'fixed_param_names' parameters, set the 'lr_mult' to 0 by calling 'opt.set_lr_mult()', and finally loaded the checkpoint file to continue the training process. However, the accuracy rapidly dropped to about 50% (2 classes were included in the training set.)

Here's the code segment for using 'fixed_param_names':
net, arg_params, aux_params = mx.model.load_checkpoint('../model/vgg16', 0)
name_list = [k for k in arg_params if not 'fc' in k]
mod = mx.module.Module(net, context=ctx, work_load_list=wl, fixed_param_names=name_list)

Here's the codes for 'set_lr_mult' method:
opt = mx.optimizer.Adam(learning_rate=0.001)
mult_dict = {k:0.0 for k in arg_params if not 'fc' in k}
opt.set_lr_mult(mult_dict)
mod.init_optimizer(optimizer=opt)

I understand that the 'fixed_param_names' parameter is related to 'grad_req' when calling the executor, and no memory is allocated for gradients in this way. For 'lr_mult' case, the gradients are calculated, but  are not added to the weights as the learning rate was 0.
But I guess this should only make difference in memory occupation and computation speed. The result should have been the same, as the weights are the same in both cases. Why were they different??

Maybe I was wrong in understanding the matters. Could someone help me with that?

By the way, I cannot understand the difference between 'fixed_param_names' and the 'BlockGrad' operator. I guess both of them save the memory cosuming, only that 'BlockGrad' cut off the backpropagation completely. I guess this could be implemented with 'fixed_param_names' by specifying all layers before the blocking node, right? Furthermore, if I wanted to freeze the middle part of a network while keep the rest parts trainable: {trainable parts} <-- {frozen parts} <-- {trainable parts} <--{deviation}, I guess that 'BlockGrad' would not help, but 'fixed_param_names' would function.

As the results of my training was not correct, I guess there must have been something wrong in my understanding. Would someone please help me? THX.
",,"['BlockGrad sets the gradient to 0, but you are still learning weight decay.\r\nI suggest a ""HowTo"" label to this issue and change the subject to ""How to freeze certain layers in finetune"".', ""@precedenceguo Thanks for reply.\r\n\r\nI found out that I did not understand the mechanism of opt.set_lr_mult() method.\r\n\r\nThe program would lookup the attributes in the whole network recursively when the 'set_lr_mult()' method was called.\r\nIf the variables did not have such attributes, nothing would be done. The weights would be updated with the original learning rate. In other words, the set_lr_mult() method took no effects.\r\n\r\nI added the 'lr_mult' attributes to the variables in advance, and then installed the optimizer. Everything was OK then."", ""@back2yes I met the same issue. How can I add the 'lr_mult' attributes to the variables in advance ? In symbol, how can I implement this ? Please tell me more detailed information, thanks!"", '@bruinxiong Check out this comment: https://github.com/apache/incubator-mxnet/issues/8584#issuecomment-343150185.']",[],[],1,0
35,incubator-mxnet,1092,closed,accuracy  of train_mnist.py are different on single gpu and multi-gpus ,"I run the examples/image_classification/train_mnist.py on single gpu and double gpus. what out of my expectation is that accuracies are slightly different.(around 0.1% different). though it is not a big issue but still i am very confused because they should be completely equal in theory. can you explain what cause this slight difference? thank u!
",,"['why you think they should be equal in theory?\n', 'mxnet is not deterministic due to various in-determinism in dependencies. Even two runs on the same GPU are not guaranteed to give identical results. 0.1% sounds like a reasonable difference caused by randomness.\n', 'The problem was due to indeterminism in CuDNN convolution, if you turn that off, they should be equivalent if you do not use dropout\n', 'also you need to fix seed for python, numpy and mxnet\n']",[],[],1,0
36,incubator-mxnet,12612,closed,cannot converge use the dcgan with mnist and cifar10 dataset?,"i use the dcgan.py to train dataset with mnist, after 25 epochs the netDs loss is a little high, and it looks like don`t converge 

below is netD loss and netG loss:
![d_and_g_loss](https://user-images.githubusercontent.com/28485566/45806511-d582e400-bcf3-11e8-9972-462bece22ccb.png)




",,"['Thanks for submitting the issue @pengxin99 \r\n@mxnet-label-bot [question, example]\r\nYou can also post the question here [link](https://discuss.mxnet.io/) to get more help from the community.', '@pengxin99 can you share qualitative example of images generated by your generator? Could you also share your full code? ', '![fake_img_iter_19500](https://user-images.githubusercontent.com/28485566/46070249-df9f5980-c1af-11e8-8739-f260b0e583cf.png)\r\n![fake_img_iter_21700](https://user-images.githubusercontent.com/28485566/46070252-df9f5980-c1af-11e8-8025-d59d8c558165.png)\r\n@ThomasDelteil  this is the generated images, the mnist pic generated at iter 21700, and the cifar10 at 19500.\r\n\r\nthe code is [https://github.com/ThomasDelteil/incubator-mxnet/blob/master/example/gluon/dcgan.py](mxnet/example/gluon/dcgan.py), i only record the loss of generator and discriminator, then draw them.\r\n', '@pengxin99  qualitatively the images look pretty good, do you expect them to become better?', '@ThomasDelteil Thanks, and I use the inception score mertic, it looks converge. ']",[],"['s performance pretty well , train acc is around 0.9, but the netG']",1,0
37,incubator-mxnet,6975,closed,a problem in distribute training,"
## Environment info
Operating System:ubuntu14.04

Package used (Python/R/Scala/Julia):Python

MXNet version:0.10.1

Or if installed from source:install from source

If you are using python package, please provide

Python version and distribution:python 2.7


## Problem Message:
1. When I train a model in distribute computers in MXNet-0.10.1, I find it slower than train it in MXNet-0.9.4.
2. I use profile to analyze the program. In MXnet-0.10.1, I find the grad_arrays were pushed to kv-store after all the backward layers compute finished. So the compute can't cover the time of data communicate.
3. In MXNet-0.9.4 the grad_array in each convolution layer will push to kv-store directly after this layers' backward compute.
Why do I meet this problem and how to resolve it?",,"['Delete ""send_buf.WaitToRead();"" in line 217 of the file \'src/kvstore/kvstore_dist.h\' can solve the problem.\r\nThe compute can\'t cover the time of data communicate in backward.', ""I don't know why the following chunk of code is not moved inside `PushAsync(lambda, ...)` \r\n```\r\n// push to servers\r\n\xa0  size_t size = send_buf.shape().Size();\r\n\xa0  #if MKL_EXPERIMENTAL == 1\r\n\xa0  mkl_set_tblob_eager_mode(send_buf.data());\r\n\xa0  #endif\r\n\xa0  real_t* data = static_cast<real_t*>(send_buf.data().dptr_)\r\n```\r\nIf it is moved inside the lambda, the `WaitToRead()` call is not necessary. \r\nOtherwise you need to wait to read since you're accessing `send_buf.data()`\r\n"", ""1. Why when add waittoread() , all the param_arrays will be clocked until all the backward convolution finished? The param in one layer can't push to kvstore directly after this layers' backward compute.\r\nWe can Observe this phenomenon by using profiler when training a image classificcation model,such as resnet.\r\n2. The 'data' used in lamda is a real_t pointer. In the PushAsync, 'send_buf' is a const_var. It will wait send_buf to read before process the lamda function. So when the program process the lamda function the pointer 'data' can point to sendbuf.data() which can be read. Why we need add 'send_buf.WaitToRead();' before?"", 'sir, will you instruct me for distribute training on two machines, thank you very much. I dit it according the official document, but it did not work on two machines', ""@idealboy  There's an example for running dist training here https://mxnet.incubator.apache.org/how_to/multi_devices.html \r\nPlease post your code / error message if it doesn't work for you. \r\n\r\nThe original issue should be resolved now with https://github.com/apache/incubator-mxnet/pull/7489 so I'm closing it for now. \r\n\r\nFor further discussions/questions, we're moving to https://discuss.mxnet.io/ ""]",[],[],1,0
38,incubator-mxnet,3656,closed,accuracy level on 50%,"I tried to learn mxnet on my data, but achieved only 50%.
This is my arch:

 
    


`

But i rly need mxnet, so my question is: ""What am i doing wrong?""
",,"['you can debug with examples/python-howto/monitor_weight.py\nMy guess is try tuning learning rate or batchsize a little\n', 'what is the kind of your GPU?\n', 'NVIDIA GTX 950\n', '@alexionby \nI think it‘s ok.\nsome GPUs can cause the  problem.\n', 'add `shuffle=True` in NDArrayIter?\n', ""Yep, if i don't, it stay on 1.00 . I tried both.\n"", 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],"['', '\nX = np.reshape(train, (train.shape[0], 1, kernel_size, kernel_size))\nY = label\nprint(X.shape, Y.shape)\n\n(trainData, testData, trainLabels, testLabels) = train_test_split(\n    X / 255.0, Y.astype(""int""), test_size=0.1)\n\ndata = mx.symbol.Variable(\'data\')\n\nconv1 = mx.symbol.Convolution(data=data, kernel=(6, 6), num_filter=48)\nrelu1 = mx.symbol.Activation(data=conv1, act_type=""relu"")\npool1 = mx.symbol.Pooling(data=relu1, pool_type=""max"",\n                          kernel=(2, 2), stride=(2, 2))\n# second conv\nconv2 = mx.symbol.Convolution(data=pool1, kernel=(5, 5), num_filter=48)\nrelu2 = mx.symbol.Activation(data=conv2, act_type=""relu"")\npool2 = mx.symbol.Pooling(data=relu2, pool_type=""max"",\n                          kernel=(2, 2), stride=(2, 2))\n# first fullc\nconv3 = mx.symbol.Convolution(data=pool2, kernel=(4, 4), num_filter=48)\nrelu3 = mx.symbol.Activation(data=conv3, act_type=""relu"")\npool3 = mx.symbol.Pooling(data=relu3, pool_type=""max"",\n                          kernel=(2, 2), stride=(2, 2))\n\nconv4 = mx.symbol.Convolution(data=pool3, kernel=(2, 2), num_filter=48)\nrelu4 = mx.symbol.Activation(data=conv4, act_type=""relu"")\npool4 = mx.symbol.Pooling(data=relu4, pool_type=""max"",\n                          kernel=(2, 2), stride=(2, 2))\n\nflatten = mx.symbol.Flatten(data=pool4)\nfc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=100)\nrelu5 = mx.symbol.Activation(data=fc1, act_type=""relu"")\n# second fullc\nfc2 = mx.symbol.FullyConnected(data=relu5, num_hidden=2)\n# loss\nconvnet = mx.symbol.SoftmaxOutput(data=fc2, name=\'softmax\')\n\n\ntrain = mx.io.NDArrayIter(\n    data=trainData,\n    label=trainLabels,\n    batch_size=100)\n\nval = mx.io.NDArrayIter(\n    data=testData,\n    label=testLabels,\n    batch_size=100)\n\n\nlogging.basicConfig(level=logging.DEBUG)\n\nmodel = mx.model.FeedForward(\n    ctx=mx.gpu(),\n    symbol=convnet,\n    num_epoch=10,\n    optimizer = \'sgd\',\n    learning_rate=0.01)\n\nmodel.fit(\n    X=train,\n    eval_data=val,\n    eval_metric=\'acc\',\n    batch_end_callback=mx.callback.Speedometer(100))', '', '\n\nThen I tried to do the same on the another framework _Keras_ ( _tensorFlow_ as backend).\nAnd achieved 75% accuracy after 10 epochs on the **same data**.\n\nThere is the arch:\n', '', '\nX = np.reshape(train,(train.shape[0],1,kernel_size,kernel_size))\nY = np.reshape(label,(label.shape[0],1))\nprint(X.shape, Y.shape)\n\nprint(""[INFO] compiling model..."")\nopt = SGD(lr=0.01)\n\ndepth = 1 \nheight = 65\nwidth = 65\nclasses = 2\n\n    # initialize the model\nmodel = Sequential()\n\n# first set of CONV => RELU => POOL\nmodel.add(Convolution2D(48, 6, 6, border_mode=""same"",\n                        input_shape=(depth, height, width)))\nmodel.add(Activation(""relu""))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n# second set of CONV => RELU => POOL\nmodel.add(Convolution2D(48, 5, 5, border_mode=""same""))\nmodel.add(Activation(""relu""))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n# second set of CONV => RELU => POOL\nmodel.add(Convolution2D(48, 4, 4, border_mode=""same""))\nmodel.add(Activation(""relu""))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n# second set of CONV => RELU => POOL\nmodel.add(Convolution2D(48, 2, 2, border_mode=""same""))\nmodel.add(Activation(""relu""))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n# set of FC => RELU layers\nmodel.add(Flatten())\nmodel.add(Dense(100))\nmodel.add(Activation(""relu""))\n\n# softmax classifier\nmodel.add(Dense(classes))\nmodel.add(Activation(""softmax""))\n\n\nmodel.compile(loss=""categorical_crossentropy"", optimizer=opt, metrics=[""accuracy""])\n\n(trainData, testData, trainLabels, testLabels) = train_test_split( \n    X / 255.0, Y.astype(""int""), test_size=0.1)\n\ntrainLabels = np_utils.to_categorical(trainLabels, 2)\ntestLabels = np_utils.to_categorical(testLabels, 2)\n\nprint(""[INFO] training..."")\nmodel.fit(trainData, trainLabels, batch_size=128, nb_epoch=10, verbose=1)\n\n# show the accuracy on the testing set\nprint(""[INFO] evaluating..."")\n(loss, accuracy) = model.evaluate(testData, testLabels,\n                                  batch_size=128, verbose=1)\nprint(""[INFO] accuracy: {:.2f}%"".format(accuracy * 100))', '']",1,0
39,incubator-mxnet,1228,closed,Windows GPU accuracy extremely bad,"Hey i'm quite new to mxnet, I followed the installation instructions and succeeded in installing it on windows 8.1 64 bit, I then ran the train_mnist.py --network lenet without a problem, quite slow but the accuracy at the end is good at around 99.2, but when I run it as --network lenet --gpus 0 to use my gpu its definitely a lot faster but the accuracy never gets above 10% which is terrible, there must be something wrong theoretically it should be the same accuracy right? I installed cuda 7.5 and also extracted cuddn v3 just as indicated, everything runs without a problem except the accuracy is terrible, i'm running on a laptop with a nvidia 660m graphics card, it has compute capability 3.0.

After running the file I get Train-accuracy=0.098825
",,"[""Here is my output from train_mnist.py:\n\n```\n2016-01-09 12:48:47,622 Node[0] start with arguments Namespace(batch_size=128, data_dir='mnist/', gpus=None, kv_store='local', load_epoch=None, lr=0.1, lr_factor=1, lr_factor_epoch=1, model_prefix=None, network='mlp', num_epochs=10, num_examples=60000)\n[12:48:51] src/io/iter_mnist.cc:91: MNISTIter: load 60000 images, shuffle=1, shape=(128,784)\n[12:48:52] src/io/iter_mnist.cc:91: MNISTIter: load 10000 images, shuffle=1, shape=(128,784)\n2016-01-09 12:48:52,053 Node[0] Start training with [cpu(0)]\n2016-01-09 12:48:53,105 Node[0] Epoch[0] Batch [50] Speed: 6447.52 samples/sec  Train-accuracy=0.686719\n2016-01-09 12:48:53,829 Node[0] Epoch[0] Batch [100]    Speed: 8836.63 samples/sec  Train-accuracy=0.793828\n2016-01-09 12:48:54,660 Node[0] Epoch[0] Batch [150]    Speed: 7707.90 samples/sec  Train-accuracy=0.836302\n2016-01-09 12:48:55,366 Node[0] Epoch[0] Batch [200]    Speed: 9064.13 samples/sec  Train-accuracy=0.858555\n2016-01-09 12:48:56,192 Node[0] Epoch[0] Batch [250]    Speed: 7749.72 samples/sec  Train-accuracy=0.873969\n2016-01-09 12:48:57,027 Node[0] Epoch[0] Batch [300]    Speed: 7662.28 samples/sec  Train-accuracy=0.885052\n2016-01-09 12:48:57,808 Node[0] Epoch[0] Batch [350]    Speed: 8206.58 samples/sec  Train-accuracy=0.893951\n2016-01-09 12:48:58,552 Node[0] Epoch[0] Batch [400]    Speed: 8606.22 samples/sec  Train-accuracy=0.900723\n2016-01-09 12:48:59,377 Node[0] Epoch[0] Batch [450]    Speed: 7758.36 samples/sec  Train-accuracy=0.906563\n```\n\nIt looks fine. Did you try pulling the newest change and make clean && make?\n"", ""here is mine:\n\n```\n\nC:\\mxnet\\nocudnn\\python\\image-classification>D:\\Python27\\python.exe train_mnist.\npy --network lenet --gpus 0\n2016-01-09 20:52:15,706 Node[0] start with arguments Namespace(batch_size=128, d\nata_dir='mnist/', gpus='0', kv_store='local', load_epoch=None, lr=0.1, lr_factor\n=1, lr_factor_epoch=1, model_prefix=None, network='lenet', num_epochs=10, num_ex\namples=60000)\n[20:52:17] D:\\chhong\\mxnet\\src\\io\\iter_mnist.cc:94: MNISTIter: load 60000 images\n, shuffle=1, shape=(128, 1, 28, 28)\n[20:52:18] D:\\chhong\\mxnet\\src\\io\\iter_mnist.cc:94: MNISTIter: load 10000 images\n, shuffle=1, shape=(128, 1, 28, 28)\n2016-01-09 20:52:18,315 Node[0] Start training with [gpu(0)]\n2016-01-09 20:52:20,598 Node[0] Epoch[0] Batch [50]     Speed: 4719.76 samples/s\nec      Train-accuracy=0.096719\n2016-01-09 20:52:21,969 Node[0] Epoch[0] Batch [100]    Speed: 4668.13 samples/s\nec      Train-accuracy=0.098203\n2016-01-09 20:52:23,334 Node[0] Epoch[0] Batch [150]    Speed: 4688.64 samples/s\nec      Train-accuracy=0.100625\n2016-01-09 20:52:24,688 Node[0] Epoch[0] Batch [200]    Speed: 4723.25 samples/s\nec      Train-accuracy=0.100039\n2016-01-09 20:52:26,042 Node[0] Epoch[0] Batch [250]    Speed: 4726.74 samples/s\nec      Train-accuracy=0.098344\n2016-01-09 20:52:27,424 Node[0] Epoch[0] Batch [300]    Speed: 4634.32 samples/s\nec      Train-accuracy=0.099635\n2016-01-09 20:52:28,793 Node[0] Epoch[0] Batch [350]    Speed: 4671.53 samples/s\nec      Train-accuracy=0.099955\n```\n\nAs you can see the accuracy remains at the 9% range, and even after the 10 epochs it remains the same, as far as the make part, I downloaded and installed pre-built package for gpu from here\nhttps://github.com/dmlc/mxnet/releases\n"", ""My output with exactly the same command on linux:\n\n```\npython train_mnist.py --network lenet --gpus 0\n2016-01-09 14:18:41,245 Node[0] start with arguments Namespace(batch_size=128, data_dir='mnist/', gpus='0', kv_store='local', load_epoch=None, lr=0.1, lr_factor=1, lr_factor_epoch=1, model_prefix=None, network='lenet', num_epochs=10, num_examples=60000)\n[14:18:43] src/io/iter_mnist.cc:94: MNISTIter: load 60000 images, shuffle=1, shape=(128, 1, 28, 28)\n[14:18:43] src/io/iter_mnist.cc:94: MNISTIter: load 10000 images, shuffle=1, shape=(128, 1, 28, 28)\n2016-01-09 14:18:43,402 Node[0] Start training with [gpu(0)]\n2016-01-09 14:18:46,866 Node[0] Epoch[0] Batch [50] Speed: 2515.84 samples/sec  Train-accuracy=0.810000\n2016-01-09 14:18:49,499 Node[0] Epoch[0] Batch [100]    Speed: 2431.10 samples/sec  Train-accuracy=0.876484\n2016-01-09 14:18:52,040 Node[0] Epoch[0] Batch [150]    Speed: 2518.40 samples/sec  Train-accuracy=0.903073\n2016-01-09 14:18:54,563 Node[0] Epoch[0] Batch [200]    Speed: 2537.25 samples/sec  Train-accuracy=0.918750\n2016-01-09 14:18:57,251 Node[0] Epoch[0] Batch [250]    Speed: 2380.75 samples/sec  Train-accuracy=0.928750\n2016-01-09 14:18:59,741 Node[0] Epoch[0] Batch [300]    Speed: 2570.31 samples/sec  Train-accuracy=0.936120\n2016-01-09 14:19:02,343 Node[0] Epoch[0] Batch [350]    Speed: 2459.97 samples/sec  Train-accuracy=0.941897\n2016-01-09 14:19:04,880 Node[0] Epoch[0] Batch [400]    Speed: 2523.58 samples/sec  Train-accuracy=0.946660\n2016-01-09 14:19:07,560 Node[0] Epoch[0] Batch [450]    Speed: 2387.78 samples/sec  Train-accuracy=0.950122\n```\n\nThis seems to be a windows specific issue. @hjk41 Could you look into it?\n\nMean while, @jonathanponce try using monitor (example in example/python-howto/monitor_weights.py) to check the internal weights and outputs to see if anything is wrong.\n"", ""Hey I used the monitor to check up on things and something is definitely happening, when I run the program using my cpu, things look quite normal\n\n```\n\nC:\\mxnet\\nocudnn\\python\\image-classification>D:\\Python27\\python.exe train_mnist.py --network lenet\n2016-01-09 22:31:09,315 Node[0] start with arguments Namespace(batch_size=128, data_dir='mnist/', gpus=None, kv_store='lo\ncal', load_epoch=None, lr=0.1, lr_factor=1, lr_factor_epoch=1, model_prefix=None, network='lenet', num_epochs=10, num_exa\nmples=60000)\n[22:31:11] D:\\chhong\\mxnet\\src\\io\\iter_mnist.cc:94: MNISTIter: load 60000 images, shuffle=1, shape=(128, 1, 28, 28)\n[22:31:11] D:\\chhong\\mxnet\\src\\io\\iter_mnist.cc:94: MNISTIter: load 10000 images, shuffle=1, shape=(128, 1, 28, 28)\n2016-01-09 22:31:11,933 Node[0] Start training with [cpu(0)]\n2016-01-09 22:31:13,413 Node[0] Batch:       1 convolution0_output            0.32209\n2016-01-09 22:31:13,413 Node[0] Batch:       1 activation0_output             0.263409\n2016-01-09 22:31:13,413 Node[0] Batch:       1 pooling0_output                0.264198\n2016-01-09 22:31:13,413 Node[0] Batch:       1 convolution1_output            0.280998\n2016-01-09 22:31:13,413 Node[0] Batch:       1 activation1_output             0.259359\n2016-01-09 22:31:13,413 Node[0] Batch:       1 pooling1_output                0.283388\n2016-01-09 22:31:13,413 Node[0] Batch:       1 flatten0_output                0.283388\n2016-01-09 22:31:13,413 Node[0] Batch:       1 fullyconnected0_output         0.246848\n2016-01-09 22:31:13,413 Node[0] Batch:       1 activation2_output             0.23317\n2016-01-09 22:31:13,413 Node[0] Batch:       1 fullyconnected1_output         0.16215\n2016-01-09 22:31:13,413 Node[0] Batch:       1 softmax_output                 0.101191\n2016-01-09 22:31:13,413 Node[0] Batch:       1 softmax_backward_data          0.301412\n2016-01-09 22:31:13,413 Node[0] Batch:       1 softmax_backward_label         0.0\n2016-01-09 22:31:13,413 Node[0] Batch:       1 fullyconnected1_backward_data  0.0376285\n2016-01-09 22:31:13,413 Node[0] Batch:       1 fullyconnected1_backward_weight 1.13253\n2016-01-09 22:31:13,413 Node[0] Batch:       1 fullyconnected1_backward_bias  3.8101\n2016-01-09 22:31:13,413 Node[0] Batch:       1 activation2_backward_data      0.0356833\n2016-01-09 22:31:13,413 Node[0] Batch:       1 fullyconnected0_backward_data  0.0252012\n2016-01-09 22:31:13,413 Node[0] Batch:       1 fullyconnected0_backward_weight 0.163174\n2016-01-09 22:31:13,413 Node[0] Batch:       1 fullyconnected0_backward_bias  0.458921\n2016-01-09 22:31:13,413 Node[0] Batch:       1 flatten0_backward_data         0.0252012\n2016-01-09 22:31:13,413 Node[0] Batch:       1 pooling1_backward_data         0.0126023\n2016-01-09 22:31:13,413 Node[0] Batch:       1 activation1_backward_data      0.0116884\n2016-01-09 22:31:13,413 Node[0] Batch:       1 convolution1_backward_data     0.010943\n2016-01-09 22:31:13,413 Node[0] Batch:       1 convolution1_backward_weight   0.494861\n2016-01-09 22:31:13,413 Node[0] Batch:       1 convolution1_backward_bias     1.24864\n2016-01-09 22:31:13,413 Node[0] Batch:       1 pooling0_backward_data         0.00705877\n2016-01-09 22:31:13,413 Node[0] Batch:       1 activation0_backward_data      0.00671425\n2016-01-09 22:31:13,413 Node[0] Batch:       1 convolution0_backward_data     0.0251948\n2016-01-09 22:31:13,428 Node[0] Batch:       1 convolution0_backward_weight   0.832047\n2016-01-09 22:31:13,428 Node[0] Batch:       1 convolution0_backward_bias     4.85974\n2016-01-09 22:31:13,428 Node[0] Batch:       1 data                           0.33463\n2016-01-09 22:31:13,428 Node[0] Batch:       1 convolution0_weight            0.175653\n2016-01-09 22:31:13,428 Node[0] Batch:       1 convolution0_bias              0.00379667\n2016-01-09 22:31:13,428 Node[0] Batch:       1 convolution1_weight            0.0395973\n2016-01-09 22:31:13,428 Node[0] Batch:       1 convolution1_bias              0.000975498\n2016-01-09 22:31:13,428 Node[0] Batch:       1 fullyconnected0_weight         0.031241\n2016-01-09 22:31:13,428 Node[0] Batch:       1 fullyconnected0_bias           0.000358532\n2016-01-09 22:31:13,428 Node[0] Batch:       1 fullyconnected1_weight         0.0393582\n2016-01-09 22:31:13,428 Node[0] Batch:       1 fullyconnected1_bias           0.00297664\n2016-01-09 22:31:13,428 Node[0] Batch:       1 softmax_label                  5.14174\n```\n\nbut when I use my gpu, most of the weights are zero, maybe they are being rounded off or something is wrong with the precision?\n\n```\nC:\\mxnet\\nocudnn\\python\\image-classification>D:\\Python27\\python.exe train_mnist.py --network lenet --gpus 0\n2016-01-09 22:31:49,494 Node[0] start with arguments Namespace(batch_size=128, data_dir='mnist/', gpus='0', kv_store='loc\nal', load_epoch=None, lr=0.1, lr_factor=1, lr_factor_epoch=1, model_prefix=None, network='lenet', num_epochs=10, num_exam\nples=60000)\n[22:31:51] D:\\chhong\\mxnet\\src\\io\\iter_mnist.cc:94: MNISTIter: load 60000 images, shuffle=1, shape=(128, 1, 28, 28)\n[22:31:52] D:\\chhong\\mxnet\\src\\io\\iter_mnist.cc:94: MNISTIter: load 10000 images, shuffle=1, shape=(128, 1, 28, 28)\n2016-01-09 22:31:52,048 Node[0] Start training with [gpu(0)]\n2016-01-09 22:31:52,996 Node[0] Batch:       1 convolution0_output            0.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 activation0_output             152988.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 pooling0_output                0.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 convolution1_output            0.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 activation1_output             32342.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 pooling1_output                0.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 flatten0_output                0.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 fullyconnected0_output         0.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 activation2_output             0.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 fullyconnected1_output         0.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 softmax_output                 0.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 softmax_backward_data          0.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 softmax_backward_label         0.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 fullyconnected1_backward_data  0.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 fullyconnected1_backward_weight 0.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 fullyconnected1_backward_bias  0.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 activation2_backward_data      0.0\n2016-01-09 22:31:52,996 Node[0] Batch:       1 fullyconnected0_backward_data  0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 fullyconnected0_backward_weight 0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 fullyconnected0_backward_bias  0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 flatten0_backward_data         0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 pooling1_backward_data         0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 activation1_backward_data      0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 convolution1_backward_data     0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 convolution1_backward_weight   0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 convolution1_backward_bias     0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 pooling0_backward_data         0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 activation0_backward_data      0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 convolution0_backward_data     0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 convolution0_backward_weight   0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 convolution0_backward_bias     0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 data                           0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 convolution0_weight            0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 convolution0_bias              0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 convolution1_weight            0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 convolution1_bias              0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 fullyconnected0_weight         39.2047\n2016-01-09 22:31:53,013 Node[0] Batch:       1 fullyconnected0_bias           0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 fullyconnected1_weight         0.0\n2016-01-09 22:31:53,013 Node[0] Batch:       1 fullyconnected1_bias           390.408\n2016-01-09 22:31:53,013 Node[0] Batch:       1 softmax_label                  0.0\n```\n"", 'Could you try to do some simple arithmetic on gpu with \n\n``` Python\nx = mx.nd.zeros((10,10), ctx=mx.gpu(0))\nx[:] = 1\nx = x*2\nprint x.asnumpy()\n```\n', 'It returns an array of zeros, seems as if the operations are not taking place or are all returning zero\n\n```\n>>> print x.asnumpy()\n[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n```\n', 'Could you try to run cuda\'s sample code for matrix multiply and see if the\nresults are normal?\nOn Jan 9, 2016 6:18 PM, ""jonathanponce"" notifications@github.com wrote:\n\n> It returns an array of zeros, seems as if the operations are not taking\n> place or are all returning zero\n> \n> > > > print x.asnumpy()\n> > > > [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n> > > >  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n> > > >  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n> > > >  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n> > > >  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n> > > >  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n> > > >  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n> > > >  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n> > > >  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n> > > >  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n> \n> —\n> Reply to this email directly or view it on GitHub\n> https://github.com/dmlc/mxnet/issues/1228#issuecomment-170301104.\n', 'I ran the sample code and everything seems to be ok\n\n```\n[Matrix Multiply Using CUDA] - Starting...\nGPU Device 0: ""GeForce GTX 660M"" with compute capability 3.0\n\nMatrixA(320,320), MatrixB(640,320)\nComputing result using CUDA Kernel...\ndone\nPerformance= 4.40 GFlop/s, Time= 29.805 msec, Size= 131072000 Ops, WorkgroupSize\n= 1024 threads/block\nChecking computed result for correctness: Result = PASS\n\nNOTE: The CUDA Samples are not meant for performance measurements. Results may v\nary when GPU Boost is enabled.\n```\n\nThe results are as expected, seems to be something to do with mxnet\n', ""I can't reproduce the problem locally so I can't think of anything now.\nYou can try git bisect https://git-scm.com/docs/git-bisect to see if it's a recently introduced bug.\n"", 'I tried out the previous Windows build and it worked without a problem, so that means windows binary build 20160106 has a bug in the gpu computation section, there have been 29 commits since then so its possible that it has been fixed already.\n', 'Even if it is just to back @jonathanponce, I have exactly the same problem. Running train_mnist.py without the --gpus 0 command gives an accuracy of about 0.97, but running with --gpus 0 gives an accuracy of about 0.07\n\nI use Windows 7 64bit with Python 2.7 and have tried windows binary build 20160120 and windows binary build 20160113. Both have the same problem for me.\n', '@hjk41 Looks like gpu code is not running but not reporting error on windows with their cards. Could you look into it?\n', '@piiswrong I watched the gpu load with GPU-Z when running the mxnet code and the gpu load is around 25%, so the code is using my gpu.\n', 'This post reports on the same issue:\nhttps://www.kaggle.com/c/second-annual-data-science-bowl/forums/t/18079/end-to-end-deep-learning-tutorial-0-0392/105458#post105458\n\nI ran into the same situation as well. Not sure yet if the earlier releases solve the problem.\n', ""Same issue here with mxnet and python. I installed the latest windows build 20160202 and while training a network the accuracy wasn't increasing. The computation was taking place on the gpu because I checked it with gpu-z.... \nDid the simple arithmetic tests on gpu  mentioned by @piiswrong and it gave me zeroes.\n\nSo I switched to the 20151228 build and now it works ok.\n\nSo definately the bug from 20160106 still exists in 20160202. Hope it helps.....\n"", '@piiswrong @Quares @JohanManders @gpapadop79 \nSorry it take me so long to respond. I was fully occupied with an internal conference last few weeks. I just tried with 20160202 and simple test seems to work alright for me. I guess it must be something in the system configuration side. I am using Windows Server 2012 Datacenter, Python 2.7.10 x64. I will try to switch to some other platform and see if it works there.\n\nMeanwhile, could you help me narrow down the problem a little bit? Here are some speculations:\n1. run ""where libmxnet.dll"" and see if you are using the right version of libmxnet.dll\n2. run matrixMulCuBLAS from nvidia CUDA samples and see if it works\n3. try building mxnet from source and do the test again\n\n```\nPython 2.7.10 (default, May 23 2015, 09:44:00) [MSC v.1500 64 bit (AMD64)] on win32\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\n>>> import mxnet as mx\nOpenCV is unavailable.\n>>> a = mx.nd.ones((2,3), mx.gpu(0))\n>>> a.asnumpy()\narray([[ 1.,  1.,  1.],\n       [ 1.,  1.,  1.]], dtype=float32)\n>>> x = mx.nd.zeros((10,10), ctx=mx.gpu(0))\n>>> x[:] = 1\n>>> x = x*2\n>>> print x.asnumpy()\n[[ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]]\n```\n', 'Just tried on another machine with Windows Server 2012R2, Python 2.7.10 x64, it also works fine. :-(\nI think I need some help here. It would be great if someone is willing to share a machine that can reproduce the problem.\n', ""Looks like it's caused by low cuda compute capability GPUs.\n"", 'Could be. I am running Titan. Does this also occur for low compute capability GPUs on Linux?\n', 'I have a GTX 670 and when I boot into Ubuntu, mxnet works fine. In Windows I cannot get it to work.\n\nI ran some tests on my Windows 7 64bit, using windows binary build 20160216. Using a build earlier, does the same for me.\n- libmxnet.dll is in the right place\n\n```\nC:\\Users\\XXXXX>where libmxnet.dll\nC:\\Anaconda\\Lib\\site-packages\\mxnet-0.5.0-py2.7.egg\\mxnet\\libmxnet.dll\n```\n- matrixMulCuBLAS passes\n\n```\nC:\\ProgramData\\NVIDIA Corporation\\CUDA Samples\\v7.5\\bin\\win64\\Release>matrixMulC\nUBLAS.exe\n[Matrix Multiply CUBLAS] - Starting...\nGPU Device 0: ""GeForce GTX 670"" with compute capability 3.0`\n\nMatrixA(640,480), MatrixB(480,320), MatrixC(640,320)\nComputing result using CUBLAS...done.\nPerformance= 1059.89 GFlop/s, Time= 0.185 msec, Size= 196608000 Ops\nComputing result using host CPU...done.\n```\n- but mxnet gives me 0. 0. 0.\n\n```\nPython 2.7.11 |Anaconda 2.3.0 (64-bit)| (default, Jan 29 2016, 14:26:21) [MSC v.\n1500 64 bit (AMD64)] on win32\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\nAnaconda is brought to you by Continuum Analytics.\nPlease check out: http://continuum.io/thanks and https://anaconda.org\n>>> import mxnet as mx\n>>> a = mx.nd.ones((2,3), mx.gpu(0))\n>>> a.asnumpy()\narray([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.]], dtype=float32)\n>>> x = mx.nd.zeros((10,10), ctx=mx.gpu(0))\n>>> x[:] = 1\n>>> x = x*2\n>>> print x.asnumpy()\n[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n>>>\n```\n', '@jonathanponce So it is not related to compute capability, since both GTX670 and Titan have compute capability 3.0.\nCould you try to run a C++ program? You can try to this one:\nhttps://github.com/hjk41/MxNet.cpp.git\n\nCheckout the _test_ branch and copy libmxnet.lib/libmxnet.dll to lib/windows/, then build the solution in windows/vs/MxNetTestApp/MxNetTestApp.sln with _x64_. The program just creates an NDArray on GPU, populate it with ones and then print it out. This is pretty much what mx.nd.ones((2,3), mx.gpu(0)) does.\n', ""@hjk41 Did you want me to do the test? If so, I cloned the test branch, copied the dll and lib file (also needed the lib file) and build the solution successfully. I don't know what should happen or how long it should take, but running the program seems to do nothing.\n"", '@JohanManders The program should output a series of digits from 0 to 5. If it prints nothing, then there must b something wrong. It means the problem also occurs for c++ programs.\n', '@hjk41 Mmm... Strange... Building CUDA samples like marchingCubes, matrixMulCUBLAS and particles seem to be no problem and run perfectly.\n', 'I also ran matrixMulCUBLAS and it passes. \n\nMy environment is Windows 7 x64 python 2.7.11 (Anaconda 2.5.0) and GTX 960 (which has compute capability 5.2)\n', ""Thanks guys. I think I will have to reinstall one of my machines to use Windows 7 to reproduce the problem, which will need some time. Meanwhile, if someone can try to debug the problem, it would be great. With the C++ program, it shouldn't be too hard.\n"", ""So I assume the new (7th) release doesn't solve the issue yet? How is it with you @JohanManders? I haven't had time to work on my desktop to test it yet.\n"", '@Quares I have tried the latest build, Windows binary build 20160216, and I still have the problem.\n', 'I just found that I have the same problem, tried both mnist and cifar10 examples. I am using GTX980 and Windows 10.\n\nI tried different builds and found that all snapshots after build20151228 do not work, also spotted that the file size has been reduced very much since build 20151228 --- are there changes in compilation config? \n', 'I tried link to the provided CUDA/CuDNN DLL files and also my own DLLs (same version) via different PATH, did not work either. \n\nPerhaps it maybe a compiler / OS level issue. \n', '@thyu Could you try the C++ program in the test branch of https://github.com/hjk41/MxNet.cpp.git\nI have recreated the problem with a Windows 10 machine in Python, but the C++ program runs just fine\n', '@hjk41 \nSeems fine?\n\n``` bash\n$ ./MxnetTestApp.exe\n0 1 2 3 4 5\n```\n', 'Yes. So it seems to be something in Python/R binding or how they use the\nlibrary.\n\nOn Fri, Feb 19, 2016 at 3:34 AM, thyu notifications@github.com wrote:\n\n> @hjk41 https://github.com/hjk41\n> Seems fine?\n> \n> $ ./MxnetTestApp.exe\n> 0 1 2 3 4 5\n> \n> —\n> Reply to this email directly or view it on GitHub\n> https://github.com/dmlc/mxnet/issues/1228#issuecomment-185882232.\n\n## \n\nHONG Chuntao\nSystem Research Group\nMicrosoft Research Asia\n', ""@thyu @jonathanponce @JohanManders @Quares @piiswrong \nCould you help me check with the latest binary build here? [https://github.com/dmlc/mxnet/releases/tag/20160223](https://github.com/dmlc/mxnet/releases/tag/20160223)\nI think it is the problem with CUDA library. Windows Server 2012 and Windows 10/8 uses different CUDA binaries so I assume there is some difference between the libraries we link. The libmxnet.dll compiled on Windows 2012 does not work on Windows 10/8, and vice versa. \n\nThe latest binary was compiled on Windows 10 and it works well on my machine. But I don't have another Windows 10/8/7 machine to test on. So could you help me validate this?\n"", '@hjk41 Your latest builds seems to work perfectly! Thanks man, this helps me a lot! The mnist example now outputs a train accuracy of 0.999 and validation accuracy of 0.991.\n', '@JohanManders Great! I will use Windows 10 in the future for building the binary distribution.\n', 'Great news! I will test it in the evening and will let you know.\n', '@hjk41 The latest build works!!! Thanks!    You rock!!!! \n', '@JohanManders @Quares @hjk41 \nDid anyone else notice a small decrease in performace on the latest release? \n\nWhen I trained a model with the 20151228 release, needed about 15.5 sec/epoch. Now with the latest release training the exact same model takes 18.5 sec/epoch.\n', 'I am happy that it works, but I also see a big speed difference between Windows and Ubuntu. For Windows I downloaded the latest pre-built package 20160223. For Ubuntu I just downloaded the latest version and build it.\n\nI did two tests on my dual-boot i7 system with a GTX 670:\n\ntrain_mnist.py\n\n```\nWindows 7 | Build 20160223                        : ~  6750 samples / sec\nUbuntu    | Downloaded en build a few minutes ago : ~ 20000 samples / sec\n```\n\nTraining on other data\n\n```\nWindows 7 | Build 20160223                        : ~ 49 sec / epoch\nUbuntu    | Downloaded en build a few minutes ago : ~ 31 sec / epoch\n```\n', 'Darn! I must switch to linux! :-P\n\nMy speed difference is on win7 between pre-built 20151228 and 20160223. I also tried CuDNN 4 but had no difference.\n', ""The new release (20160223) works on my Windows10 machine. Great work guys!\n\nSide note: I also noticed (in my case substantial) performance decrease in terms of speed, but that's probably related to various other things happening.\n\nEDIT: Btw. is it possible to use CUDNN v4? Till now I was under the impression that only v3 is supported.\n"", ""The new release works on my machine as well, awesome!\n\nI also observe that Linux is faster than Windows for quite a while, I have Linux box with GTX970 which runs around 700 images per sec something over train_cifar10, but in my company's Windows machine it is only slightly higher than 620 img per sec. It might not be just a single-factor issue and perhaps we can improve it afterwards...\n"", ""Interesting. I will take a look into it. I expect there to be some\nperformance difference between Windows and Linux, but didn't expect it to\nbe so huge.\n\nOn Wed, Feb 24, 2016 at 7:33 AM, thyu notifications@github.com wrote:\n\n> The new release works on my machine as well, awesome!\n> \n> I also observe that Linux is faster than Windows for quite a while, I have\n> Linux box with GTX970 which runs around 700 images per sec something over\n> train_cifar10, but in my company's Windows machine it is only slightly\n> higher than 620 img per sec. It might not be just a single-factor issue and\n> perhaps we can improve it afterwards...\n> \n> —\n> Reply to this email directly or view it on GitHub\n> https://github.com/dmlc/mxnet/issues/1228#issuecomment-187965807.\n\n## \n\nHONG Chuntao\nSystem Research Group\nMicrosoft Research Asia\n"", 'Here is my results:\npython train_mnist.py:\n\n```\nGTX980, Windows 10:               20000 samples/sec\nTitan, Ubuntu 14.04:                  40000 samples/sec\n```\n\nAlso, CPU runs much faster in this case, at around 50000 samples/sec.\n\npython train_cifa10.py:\n\n```\nGTX980, Windows 10:               396 samples/sec\nTitan, Ubuntu 14.04:                  445 samples/sec\n```\n\nSo my guess is that Windows has higher overhead with regard to small GPU operations. In MNIST, the computation is so light that this overhead dominates, and thus CPU > GPU-Linux > GPU-Windows. In Cifa10, there are much less operations and hence the difference is much smaller. Has anyone tried running heavier workloads like ImageNet?\n', '@Quares \nAccording to this: https://github.com/dmlc/mxnet/pull/1449\ncudnn 4 is supported\n', ""@gpapadop79 cool! great to know! I was under the impression about cuddn3 because the documentation doesn't reflect on cuddn4 yet. I am interested to see how the performance changes between cudnn3 and cudnn4. I am running both GTX660Ti and GTX980Ti on two seperate machines so have a nice overview of the performance upgrade between the two cards.\n"", ""Hi,\n\nInstalled the GPU enabled R library (R version: 3.2.3) on Windows 7 today. Looks like it's working on the CPU but not on my GPU. The code seems to execute on the GPU (confirmed with GPU-Z), but error improvement stalls on the second round using example code (as above merged issue), and mx.nd.ones(c(2,3), mx.gpu()) generates a table of 0's not 1's.\n\nI'm using the latest files for everything, and the precompiled GPU package for R. I read in this thread: https://github.com/dmlc/mxnet/issues/250, that indicates 'remove USE_CUDNN' to compile for Cuda Compute GPUs 2.1 (and lower). I'm using a 2.1 GPU. Could this be the problem? \n\nCould using an earlier 2015 release be a solution? Also might I have to compile my own GPU-enabled files without USE_CUDNN to fix this? I'm hoping I don't have to upgrade my computer to get his working as I'm only doing preliminary testing.\n\nAny help would be appreciated.\n\nThanks, Gavin.\n"", ""I haven't tested it on GPU with with compute capability 2.1. I guess the\npre-built binary may not work for you, since it is compiled with compute\ncapability 3.5. Could you try to compile from source and see if it works?\n\nOn Sun, Mar 6, 2016 at 11:49 PM, xenmind notifications@github.com wrote:\n\n> Hi,\n> \n> Installed the GPU enabled R library (R version: 3.2.3) on Windows 7 today.\n> Looks like it's working on the CPU but not on my GPU. The code seems to\n> execute on the GPU (confirmed with GPU-Z), but error improvement stalls on\n> the second round using example code (as above merged issue), and\n> mx.nd.ones(c(2,3), mx.gpu()) generates a table of 0's not 1's.\n> \n> I'm using the latest files for everything, and the precompiled GPU package\n> for R. I read in this thread: #250\n> https://github.com/dmlc/mxnet/issues/250, that indicates 'remove\n> USE_CUDNN' to compile for Cuda Compute GPUs 2.1 (and lower). I'm using a\n> 2.1 GPU. Could this be the problem?\n> \n> Could using an earlier 2015 release be a solution? Also might I have to\n> compile my own GPU-enabled files without USE_CUDNN to fix this? I'm hoping\n> I don't have to upgrade my computer to get his working as I'm only doing\n> preliminary testing.\n> \n> Any help would be appreciated.\n> \n> Thanks, Gavin.\n> \n> —\n> Reply to this email directly or view it on GitHub\n> https://github.com/dmlc/mxnet/issues/1228#issuecomment-192919248.\n\n## \n\nHONG Chuntao\nSystem Research Group\nMicrosoft Research Asia\n"", 'Will do, thanks.\n', 'Just wanted to report that compiling the shared dll, with USE_CUDNN turned off worked. Thanks for your help.\n', 'The error is back in the latest release the accuracy remain terrible, the 20160223 build works fine, but the rest appear to have the error again\n', 'Gosh... Which windows version are you using?\n\nOn Tue, Mar 22, 2016 at 8:40 PM, jonathanponce notifications@github.com\nwrote:\n\n> The error is back in the latest release the accuracy remain terrible, the\n> 20160223 build works fine, but the rest appear to have the error again\n> \n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly or view it on GitHub\n> https://github.com/dmlc/mxnet/issues/1228#issuecomment-199791777\n\n## \n\nHONG Chuntao\nSystem Research Group\nMicrosoft Research Asia\n', 'Windows 8.1\n', 'I found the 20160419 binary release has the same problem on my computer, then I compiled mxnet from the latest source and it now works fine.\nMy hardware and software configurations:\nGPU: GTX850M\nOS: Windows 8.1 x64\nCompiler: Visual Studio 2013 Update 5\n3rdparty Software: CUDA 7.5, CUDNN V4, OpenCV 3.1, OpenBLAS 0.2.14\nWith the default options it produces a 63,658KB libmxnet.dll，with Link-Time Code Generation turned on the size is reduced to 19,900KB, both work fine in GPU mode and the speed is about the same.\n', ""Hi @wdx04,\nWould you mind sharing the compiled libmxnet.dll (63,658kb) or update the instruction. I have same setting but can't make it work.\nThank you.\n"", ""Hi @piiswrong @hjk41 \n\nI found the GPU-based mxnet didn't work well on my laptop. I have the same problem about mxnet mentioned above. The performance was very good when using CPU-based mxnet, while the GPU-based method had a low accuracy around 10% on mnist dataset.\n\nMy OS is win 10 64-bits, and the device graphic is nividia GTX 960M,  CUDA 7.5. I used 20160531-win 10-baniry-release to install the mxnet on my laptop. In addition, I have tested the CUDA with C and pycuda, both of them were Ok. \n\nSo, I would like ask how to deal with it? Any help could be appreciated. Thank you.  \n"", ""Hi @juanlp ,\nYou may download my version of libmxnet.dll here(built on 5/22):\nhttp://pan.baidu.com/s/1bzxnvK\nI'm facing compiling errors with the latest source so I can't provide the latest libmxnet.dll binary.\n"", 'Compiling errors are fixed, here is the latest binary:\nhttp://pan.baidu.com/s/1dFrzQet\n', ""I'm having the same issue. Windows 10 64bit, GTX 1080, VS2013 + CUDA 8.0 + CuDNN v5, Python 2.7.11 x64, compiling from the source code. CPU works fine but GPU fails - remains at 10% for MNIST example. CUDA samples work OK, but a = mx.nd.ones((2,3), mx.gpu(0)) returns all zeros instead of ones. I can't find a solution in the thread above.\n"", 'Hi @wdx04,\n\nI downloaded your libmxnet-0612.dll and unpacked it, and put it into the original mxnet file instead of the previous libmxnet.dll. But aftering install it using python setup.py install, there are some mistakes when runing import mxnet. What is up ? Thank you\n', ""Hi @pablozhang,\nProbably you don't have OpenCV 3.1 and/or cuDNN v4 dlls, my libmxnet.dll was dynamically linked to these libraries, as opposed to the official one. You can download them here:\nhttp://pan.baidu.com/s/1bpbURXt\n"", 'Hi @wdx04 ,\n\nI have a confuse about it whether or not I unpack the file and put the two .dll into the 3rdparty file of mxnet is Ok? \n', 'Hi @wdx04,\n\nThank you for your help, my mxnet does work now. The error has been fixed. Thank you.\n', 'Hi @pablozhang,\nYou are welcome. I think placing the two .dll in any directory listed in your PATH environment variable will be OK.\n', 'Really appreciate the job by @wdx04 . This can be a temporary fix for the problem.\n', '@piiswrong @hjk41\nThe problem persists for CUDA 8.0. Is there a known cause for GPU to fail like this? Is there a known solution?\n', 'I use pre-builded mxnet 20160531_win10_x64_gpu package and I install cuda_8.0.27_win10,but I still have the same problems. DId anyone know the reason ? \n', '@cemkeskin  have you solve you problem? I have the same question with you? \n', ""Here is the problem:\nGTX 1080 + CUDA 8.0 = mxnet returns zeros for mx.nd.ones()\nGTX 1080 + CUDA 7.5 = curand() doesn't work (NVIDIA issue) and mxnet relies on curand for some tasks. But training on CPU works\nSo you either need to remove all references to curand (e.g. initialize your arrays manually), or switch back to an older card.\n"", ""Hi, I got the same problem about training accuracy lower than 10%, I got the same issue like @JohanManders.\nI use R 3.3.0, Windows10, cudnn v3, CUDA 7.5, GPU card is GTX 1080.\nI tried to create the table like what you did on R, The GPU table is wrong and couldn't do any compute, this might be the reason. And switch the gpu version to cpu works fine.\n\n```\n> a = mx.nd.ones(c(2,3), mx.gpu(0))\n> a\n     [,1] [,2] [,3]\n[1,]    0    0    0\n[2,]    0    0    0\n> a+1\n     [,1] [,2] [,3]\n[1,]    0    0    0\n[2,]    0    0    0\n```\n\n```\n> a = mx.nd.ones(c(2,3), mx.cpu(0))\n> a\n     [,1] [,2] [,3]\n[1,]    1    1    1\n[2,]    1    1    1\n> a+1\n     [,1] [,2] [,3]\n[1,]    2    2    2\n[2,]    2    2    2\n```\n"", 'I switch From W10 to Ubnutu16.04 ,train minist both on cpu and gpu  work  correctly. My Environment is  GTX 1080 + CUDA 8.0  + Ubuntu16.04 , \n', 'Hey, @yuantangliang thanks for sharing. I will try it on ubuntu. I have checked the mxnet C++  version on windows10 with CUDA 7.5, cudnn v3. It seems works fine. So the problem might be how R using the library of CUDA on windows.\n', ""@yuantangliang Hi, thanks for your tips, but I am a totally newbie of ubuntu, while I was trying to compile mxnet of ubuntu for R, I got this message:\n\n```\n$ make -j$(nproc)\nmake: Nothing to be done for `all'.\n```\n\nI followed this [page](https://read01.com/zeaJ.html) to edit some lines of the **config.mk** .\n\n```\nUSE_CUDA = 1 \nUSE_CUDA_PATH = /usr/local/cuda \nUSE_BLAS = atlas\n```\n\nI don't know what make this problem. May you help me with it?\n"", 'Did you run cmake first ? you should first run cmake to generate MakeFile.\n', '@yuantangliang Hey, Finally I successfully run mxnet package on R with Ubuntu without the low accurate problem and correctly ones matrix of counting on GPU. Thanks for helping. My environment is GTX1080, Ubuntu 14.04, CUDA 8.0, R 3.3.1. This is a really nice experience to try it on Ubuntu. I learned a lot. :D\n', 'Has anyone made R to work with GPU on Windows?\n', '@rfcv not yet, but it works pretty well on ubuntu.\n', 'I can confirm that it works fine on Windows and R on the latest version\nwith CUDA 7.5\n\nOn 12 Jul 2016 08:39, ""long-jian"" notifications@github.com wrote:\n\n> @rfcv https://github.com/rfcv not yet, but it works pretty well on\n> ubuntu.\n> \n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/dmlc/mxnet/issues/1228#issuecomment-231906667, or mute\n> the thread\n> https://github.com/notifications/unsubscribe/AChJ6DHGmWrIMdcL4h9asv06ANqTNysTks5qUuJXgaJpZM4HBwc2\n> .\n', ""@juanlp can't make sure what made my problem, what is your GPU environment? \n"", 'I think it is related to cudnn version.\nI tested cudnn4+cuda8 in ubuntu 16.04 with gtx1080. I got very bad accuracy.\nBut I get very good accuracy when change to cudnn5\n', ""I'm having exactly same problem with windows 10 64bit, Visual Studio 2013, CUDA 8.0 RC, CUDNN5, built from source as of 8/10. Has anyone figured out what is the root cause of this issue?\n\nIt appears NDArray assignment by numerical value doesn't work, but setting by numpy array is fine, as in this short example.\n\n```\nimport mxnet\narr = mxnet.ndarray.empty( (2,2), mxnet.gpu(0) )\narr[:] = 1.\narr.asnumpy()\narray([[ 0.,  0.],\n       [ 0.,  0.]], dtype=float32)\nimport numpy\narr[:] = numpy.ones((2,2))\narr.asnumpy()\narray([[ 1.,  1.],\n       [ 1.,  1.]], dtype=float32)\n\n```\n\nAlso, when I built mxnet debug version the gpu is working fine, e.g. mnist example converges quickly.\n"", ""Same Problem with pre-built20160531 on my win7 64bit and CUDA8.0 RC, CUDNN5, VS2013. Also passed cuda samples' matrix multiply.\n\nI'm going to back to 20160223 and see if it works.\n"", 'Using GTX 1080, CUDA 8.0, CuDNN v5.1, VS2015, Win10, libmxnet.dll built from the source code. Release version still fails with mx.nd.ones, but the debug version works. So the problem is only with the release version.\n', 'The problem still exists in release `20160531_win10_x64_gpu.7z` and `v0.7.0`. Using GT 740, CUDA 7.5, cuDNN v3, in Win7.\n', 'I have the same problem on release 20160531_win10_x64_gpu.7z:\n\n> > > a=mx.nd.ones((2, 3), mx.gpu())\n> > > a.asnumpy()\n> > > array([[ 0.,  0.,  0.],\n> > >        [ 0.,  0.,  0.]], dtype=float32)\n> > > \n> > > b=mx.nd.ones((2, 3), mx.cpu())\n> > > b.asnumpy()\n> > > array([[ 1.,  1.,  1.],\n> > >        [ 1.,  1.,  1.]], dtype=float32)\n', ""I tested the windows binary build 20160223,it hasn't this bug.\n"", ""I tested 20160531_win2012_x64_gpu.7z,it hasn't this bug too\n"", '@qggjonny  Can you share your cudnn version, cuda version and GPU hardware?\n\nI tested 20160223_win10_x64_gpu.7z on cudnn v3, cuda 8.0 and GTX1080.\nI tested 20160223_win10_x64_gpu.7z on cudnn v5.1 cuda 8.0 and GTX1080.\nStill not working.\n\nIn [1]: import mxnet as mx\n   ...: a=mx.nd.ones((2, 3), mx.gpu())\n   ...: print(a.asnumpy())\n   ...:\n   ...: b=mx.nd.ones((2, 3), mx.cpu())\n   ...: print(b.asnumpy())\n   ...:\n[[ 0.  0.  0.]\n [ 0.  0.  0.]]\n[[ 1.  1.  1.]\n [ 1.  1.  1.]]\n', 'My cuda version is 7.5,GPU is GT730。\nPerhaps you can try 20160531_win2012_x64_gpu.7z,It can run on win10\n', '@qggjonny  When I installed win2012 version and call `import mxnet` in python console, it tells me that `missing cudnn64_70.dll`, but I have put my cudnn in the correct folder and cudnn v5 & v5.1 are both named `cudnn64_5.dll`, can you look at the `3rdparty` folder and see what is your cudnn version?\n', 'I put cudnn64_70.dll in mxnet\\3rdparty\\cudnn and mxnet\\3rdparty\\cudnn\\bin.\n', 'I have the same problem with `20160531_win10_x64_gpu` and also with `20160531_win2012_x64_gpu`:\n\n```\nIn [3]: (mxnet.nd.ones((2,2), mxnet.cpu())*100).asnumpy()\nOut[3]:\narray([[ 100.,  100.],\n       [ 100.,  100.]], dtype=float32)\n\nIn [4]: (mxnet.nd.ones((2,2), mxnet.gpu())*100).asnumpy()\nOut[4]:\narray([[ 0.,  0.],\n       [ 0.,  0.]], dtype=float32)\n```\n', 'I return the 20160223_win10_x64_gpu.7z, the GPU works also.  But in the newest verision, it does not work...\n', '@jf003320018 I also tried 20160223_win10_x64_gpu.7z, but not work. I use cuda8.0 with cudnn3.\nWhat is your cuda and cudnn?\n', '@auroralinan Maybe you can try cudnn v3, it has cudnn64_70.dll\n', '@yunzhou I have the same environment with you and mxnet does not work either.\n', '@MaticsL  I tried 20160223_win10_x64_gpu.7z + cuda7.5 + cudnn3. The gpu ones functions returns 0\n Also my hardware is gtx1080.\nI also notice that even if I put nothing under 3rdparty\\cudnn 20160223_win10_x64_gpu, it still runs, but the gpu ones function returns 0.\nI will try cuda 7.0 later\n', '@yunzhou my CUDA is 8.0 and cudnn is V3.  Just following the readme 20160223_win10_x64_gpu.7z, it will work. \n', '@jf003320018 thanks. Since CUDA 7.0 can not recognize gtx 1080. I will return to CUDA8.0 and try 20160223_win10_x64_gpu.7z.\n', 'i used to compile mxnet with CUDA 8.0 RC  cudnn 5.1 opencv 3.0  mkl in windows 10 and had the this problem too\nnow, i change  CUDA 8.0 RC to CUDA 8.0 and find no problem\nP.S i use gtx 1060\n', 'Using R-package, I have this exact problem with:\nWindows 10\nCUDA 8.0\ncudnn V3\nGTX 1060\n20160531_win10_x64_gpu as well as 20160223_win10_x64_gpu\nDoes anyone have a reliable solution ?\n', '@sanson87 You can use prebuild version at [https://github.com/dmlc/mxnet/issues/2813](https://github.com/dmlc/mxnet/issues/2813)\n', ""@MaticsL Thanks, do you know how I can build my GPU R-package from those? The folder 3rdparty seems to be missing from the 20161101_mxnet_x64_gpu for instance. Sorry if it's a dumb question.\n"", 'I have the same problem on windows 10 using\nCUDA 8.0\ncudnn V3\nGeForce 840M\nI have tried both 20160531_win10_x64_gpu and 20161104_win10_x64_gpu\nbut running on GPU the train accuracy remaine always fixed.\nWhich version can I try to solve this problem?\nThanks.\n', ""It seems like this problem can't be solved...\n"", 'Actually compiling from the latest source code with the new CUDA 8.0.44, cuDNN 5.1 and VS2015 worked for me finally. The issue seems to be solved, most likely due to the new CUDA release. With CUDA 8.0.27 only the Debug version was working correctly. \n', 'Thanks cemkeskin, but the problem still persists..\nI\'m using the same versions you mentioned (CUDA 8.0.44, cuDNN 5.1, VS2015), but using the R-Package folder from the GitHub repository (precisely, this: https://github.com/dmlc/mxnet/) and editing with the windows binary build 20160531 (see the first attachment) i get this error when try to installing (see the second attachment). I tried to editing the ""NAMESPACE"" file removing those names that can\'t be found, and the installation seems to work, but when i run the models in R under the GPU the train accuracy remains fixed after the second epoch. \nAny suggestion? What do you mean with ""compiling from the source code""?\n\n![immagine](https://cloud.githubusercontent.com/assets/23234023/20039784/62221698-a44a-11e6-89ee-58006bff713c.png)\n![error-binary-build-may-nosourcecode](https://cloud.githubusercontent.com/assets/23234023/20039787/6d8f2b4c-a44a-11e6-93a0-1a4db8eb30d3.png)\n', ""I don't want to be annoying, but can someone help me? I really need a solution\n"", ""To build MxNet from source, please follow the instructions here:\nhttp://mxnet.io/get_started/setup.html#build-mxnet-on-windows\n\nThe prebuilt binary sometimes have strange problems with different OS/CUDA\nconfigurations. Building from source usually solves the problem\n\nOn Wed, Nov 9, 2016 at 5:49 PM, No41Name notifications@github.com wrote:\n\n> I don't want to be annoying, but can someone help me? I really need a\n> solution\n> \n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/dmlc/mxnet/issues/1228#issuecomment-259373691, or mute\n> the thread\n> https://github.com/notifications/unsubscribe-auth/ABFI4Zv4-sAyjuVyF59GgkeqUHK0w9K-ks5q8ZcYgaJpZM4HBwc2\n> .\n"", 'When I use the `20160531_win10_x64_gpu.7z`, I have same problem on :\r\nWindows8.1, CUDA 8.0, cuDNN v3 or v5, VS 2015, GTX 860m.\r\nBut I do solve this problem by using this [https://github.com/yajiedesign/mxnet/releases ](https://github.com/yajiedesign/mxnet/releases) version, I follow actions:\r\n\r\n1. Uninstall mxnet from python. (if you already install it.)\r\n2. Download the `20161125_mxnet_x64_gpu.7z` , unpack it, copy all files into path you previous unpack `20160531_win10_x64_gpu.7z` and replace those there.\r\n3. Do download the cuDNNv4 and unpack it into .../3rdparty/cudnn/\r\n4. Run the `setupenv.cmd` or  set the enviornment path.\r\n5. cd to .../python and type python setup.py install.\r\n\r\nThere is one thing to note that it requires `cudnn64_4.dll` which belongs to cuDNNv4.', ""I met the same problem when using python in Ubuntu16.0.4 LTS , with CUDA 8.0.44, CuDNN 5.1. And my GPU is Tesla K40c\r\nThis also happen when I use CPU to compute, but it doesn't happen all the time. \r\n@piiswrong \r\nIt seems that lenet.py causes this low accuracy, both in CPU and GPU modes.\r\nIf I use mlp, it works well."", ""I am facing the simliar issue which is even more interesting. I have single binary runs twice and get totally different result.\r\n\r\nD:\\mxnet\\example\\image-classification>python train_mnist.py --gpus 0 --network lenet\r\nINFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus='0', kv_store='device', load_epoch=None, lr=0.1, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, network='lenet', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)\r\nWARNING:root:\x1b[91m[Deprecation Warning] mxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\x1b[0m\r\nINFO:root:Start training with [gpu(0)]\r\nINFO:root:Epoch[0] Batch [100]  Speed: 1418.34 samples/sec      Train-accuracy=0.116719\r\nINFO:root:Epoch[0] Batch [200]  Speed: 1402.49 samples/sec      Train-accuracy=0.101875\r\nINFO:root:Epoch[0] Batch [300]  Speed: 1404.02 samples/sec      Train-accuracy=0.092188\r\nINFO:root:Epoch[0] Batch [400]  Speed: 1404.78 samples/sec      Train-accuracy=0.097656\r\nINFO:root:Epoch[0] Batch [500]  Speed: 1400.95 samples/sec      Train-accuracy=0.107188\r\n\r\nI run again, without touch any file or reboot. even in same cmd promot:\r\nD:\\mxnet\\example\\image-classification>python train_mnist.py --gpus 0 --network lenet\r\nINFO:root:start with arguments Namespace(batch_size=64, disp_batches=100, gpus='0', kv_store='device', load_epoch=None, lr=0.1, lr_factor=0.1, lr_step_epochs='10', model_prefix=None, mom=0.9, network='lenet', num_classes=10, num_epochs=20, num_examples=60000, num_layers=None, optimizer='sgd', test_io=0, top_k=0, wd=0.0001)\r\nWARNING:root:\x1b[91m[Deprecation Warning] mxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\x1b[0m\r\nINFO:root:Start training with [gpu(0)]\r\nINFO:root:Epoch[0] Batch [100]  Speed: 1418.85 samples/sec      Train-accuracy=0.823750\r\nINFO:root:Epoch[0] Batch [200]  Speed: 1407.11 samples/sec      Train-accuracy=0.915937\r\nINFO:root:Epoch[0] Batch [300]  Speed: 1405.28 samples/sec      Train-accuracy=0.939063\r\nINFO:root:Epoch[0] Batch [400]  Speed: 1405.67 samples/sec      Train-accuracy=0.948281\r\nINFO:root:Epoch[0] Batch [500]  Speed: 1390.74 samples/sec      Train-accuracy=0.953594\r\nINFO:root:Epoch[0] Batch [600]  Speed: 1344.73 samples/sec      Train-accuracy=0.957031\r\nINFO:root:Epoch[0] Batch [700]  Speed: 1345.86 samples/sec      Train-accuracy=0.955781\r\nINFO:root:Epoch[0] Batch [800]  Speed: 1380.60 samples/sec      Train-accuracy=0.960781\r\nINFO:root:Epoch[0] Batch [900]  Speed: 1350.45 samples/sec      Train-accuracy=0.962344\r\n\r\nI bet this is due to some error related to initialization of weights. if i got another repro, i will try to debug."", 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],1,0
40,incubator-mxnet,11469,closed,Performance regression in augmentation,"## Description
There'a big performance regression in the Augmentation for RecordIO pipeline (slowing down from ~5000 samples/sec to ~3000 samples/sec for Resnet50 on Imagenet). This is linked to this PR https://github.com/apache/incubator-mxnet/pull/11027 

What the PR tries to do itself is not problematic, I can get 5k samples/sec with an older commit d37f3a3e63cef5a79c3e673cec30e70f8bf83b3e  on that PR from May24. But in the form it got merged in there's a big slowdown.

## Environment info 
Package used (Python/R/Scala/Julia): Python 3

## Build info
pip nightly (mxnet-cu90-1.3.0b20180627) , as well as built from source from master any commit after the above PR got merged

MXNet commit hash: N/A

Build config: Tried with and without USE_LIBJPEG_TURBO, using that increases the speed a bit (~3500), but still much slower than before. Also enabled USE_CUDA, USE_CUDNN

## Steps to reproduce


## What have you tried to solve it?
I've tried to profile it and see what might be wrong with the tool perf. It looks like opencv is causing a wait for some reason. Please see figure 3 

1.  Here's a perf summary now 
![image](https://user-images.githubusercontent.com/3457240/42059154-67db4e46-7ad7-11e8-875d-2ce64984cdfc.png)

2. Perf summary from the May 24 commit 
![image](https://user-images.githubusercontent.com/3457240/42059170-71a59904-7ad7-11e8-83da-e7701e8dc69a.png)

3. Call graph using perf
![image](https://user-images.githubusercontent.com/3457240/42059189-7e1170aa-7ad7-11e8-8f8a-aab7dbfddd2b.png)



@hetong007 @piiswrong Any ideas?",Performance,"[""Checking if it's due to performing other augmentations before cropping. "", 'That was it. Was accidentally performing an unnecessary affine transform before cropping. \r\nTong is sending out a PR to fix it. \r\nWill close the issue after that PR goes in. ']","['\r\npython example/image-classification/train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 2048 --dtype float16 --network resnet-v1b --data-nthreads 40 --optimizer sgd --data-train /media/ramdisk/pass-through/train-passthrough.rec --data-train-idx /media/ramdisk/pass-through/train-passthrough.idx --data-val /media/ramdisk/pass-through/val-passthrough.rec --data-val-idx /media/ramdisk/pass-through/val-passthrough.idx \r\n']",[],1,1
41,incubator-mxnet,5074,closed,Why is the training speed too slow and is the performance so weird on 4 Titan X GPU ?,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: Ubuntu 14.04.5

Compiler:  gcc 4.8.4

Package used (Python/R/Scala/Julia): python

MXNet version: 

Or if installed from source:  installed by git clone https://github.com/dmlc/mxnet.git ~/mxnet --recursive

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution: python 2.7.13 anaconda 4.3.0

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.
2.
3.

## What have you tried to solve it?

1.
2.
3.
Build environment
nvidia 375.26, cuda 8.0, gcc 4.8.4, ubundu 14.04.5, cudnn 5.1

When I use 4 pascal GPUs ( Titan X) to retrain ResNet 50 from model_load_epoch=90 on imagenet'12 dataset. The speed is very slow. Furthermore, the accuracy is also wrong. The following picture shows two procedures. And there are two weird accuracy. ( MXNET is the latest version )

I don't know why. Before change to pascal GPU, I use 4 M40 GPU have no issue ( Old MXNET version, please see the second picture ) .

![image](https://cloud.githubusercontent.com/assets/3366247/23129516/f19b3afe-f7bd-11e6-9f29-e089c7888c68.png)

Obviously, this is an abnormal phenomenon.

Normally, the results should be shown following as 

![image](https://cloud.githubusercontent.com/assets/3366247/23129668/89631b9a-f7be-11e6-8c94-3951d057b8f8.png)


",,"['@ap-hynninen Any idea?', ""I've trained resnet on Titan X Pascal and didn't see a slow down. How does the code perform when you run it on a single Titan X Pascal ?"", ""@ap-hynninen  Sorry for late reply. We need some time to test. \r\nWe uses pre-installed mxnet example, first, we train cifar 10 with single GPU,   with python train_cifar10.py --gpus 7. **There is no problem.** The training procedure is listed as following\r\n\r\n➜  image-classification git:(master) ✗ sudo python train_cifar10.py --gpus 7\r\nINFO:root:start with arguments Namespace(batch_size=128, benchmark=0, data_nthreads=4, data_train='data/cifar10_train.rec', data_val='data/cifar10_val.rec', disp_batches=20, gpus='7', image_shape='3,28,28\r\n', kv_store='device', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='200,250', max_random_aspect_ratio=0, max_random_h=36, max_random_l=50, max_random_rotate_angle=0, max_random_s=50, max_random\r\n_scale=1, max_random_shear_ratio=0, min_random_scale=1, model_prefix=None, mom=0.9, monitor=0, network='resnet', num_classes=10, num_epochs=300, num_examples=50000, num_layers=110, optimizer='sgd', pad_si\r\nze=4, random_crop=1, random_mirror=1, rgb_mean='123.68,116.779,103.939', test_io=0, top_k=0, wd=0.0001)\r\n[10:23:37] src/io/iter_image_recordio.cc:221: ImageRecordIOParser: data/cifar10_train.rec, use 4 threads for decoding..\r\n[10:23:37] src/io/iter_image_recordio.cc:221: ImageRecordIOParser: data/cifar10_val.rec, use 4 threads for decoding..\r\n[10:24:34] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to \r\ndisable)\r\nINFO:root:Epoch[0] Batch [20]   Speed: 1322.98 samples/sec      Train-accuracy=0.152530\r\nINFO:root:Epoch[0] Batch [40]   Speed: 1388.75 samples/sec      Train-accuracy=0.171875\r\nINFO:root:Epoch[0] Batch [60]   Speed: 1375.13 samples/sec      Train-accuracy=0.221094\r\nINFO:root:Epoch[0] Batch [80]   Speed: 1383.92 samples/sec      Train-accuracy=0.225000\r\nINFO:root:Epoch[0] Batch [100]  Speed: 1390.25 samples/sec      Train-accuracy=0.246484\r\nINFO:root:Epoch[0] Batch [120]  Speed: 1363.02 samples/sec      Train-accuracy=0.260937\r\nINFO:root:Epoch[0] Batch [140]  Speed: 1377.46 samples/sec      Train-accuracy=0.262109\r\nINFO:root:Epoch[0] Batch [160]  Speed: 1386.32 samples/sec      Train-accuracy=0.291406\r\nINFO:root:Epoch[0] Batch [180]  Speed: 1402.37 samples/sec      Train-accuracy=0.289062\r\nINFO:root:Epoch[0] Batch [200]  Speed: 1375.69 samples/sec      Train-accuracy=0.299219\r\nINFO:root:Epoch[0] Batch [220]  Speed: 1389.71 samples/sec      Train-accuracy=0.313672\r\nINFO:root:Epoch[0] Batch [240]  Speed: 1398.73 samples/sec      Train-accuracy=0.310156\r\nINFO:root:Epoch[0] Batch [260]  Speed: 1374.34 samples/sec      Train-accuracy=0.317578\r\nINFO:root:Epoch[0] Batch [280]  Speed: 1391.53 samples/sec      Train-accuracy=0.332031\r\nINFO:root:Epoch[0] Batch [300]  Speed: 1382.85 samples/sec      Train-accuracy=0.335547\r\nINFO:root:Epoch[0] Batch [320]  Speed: 1353.69 samples/sec      Train-accuracy=0.358203\r\nINFO:root:Epoch[0] Batch [340]  Speed: 1371.99 samples/sec      Train-accuracy=0.344922\r\nINFO:root:Epoch[0] Batch [360]  Speed: 1395.19 samples/sec      Train-accuracy=0.364844\r\n\r\n**However, we train with 2 GPUs, the training speed is extremely slow:**\r\n\r\n➜  image-classification git:(master) ✗ sudo python train_cifar10.py --gpus 6,7\r\nINFO:root:start with arguments Namespace(batch_size=128, benchmark=0, data_nthreads=4, data_train='data/cifar10_train.rec', data_val='data/cifar10_val.rec', disp_batches=20, gpus='6,7', image_shape='3,28,28', kv_store='device', load_epoch=None, lr=0.05, lr_factor=0.1, lr_step_epochs='200,250', max_random_aspect_ratio=0, max_random_h=36, max_random_l=50, max_random_rotate_angle=0, max_random_s=50, max_random_scale=1, max_random_shear_ratio=0, min_random_scale=1, model_prefix=None, mom=0.9, monitor=0, network='resnet', num_classes=10, num_epochs=300, num_examples=50000, num_layers=110, optimizer='sgd', pad_size=4, random_crop=1, random_mirror=1, rgb_mean='123.68,116.779,103.939', test_io=0, top_k=0, wd=0.0001)\r\n[10:25:19] src/io/iter_image_recordio.cc:221: ImageRecordIOParser: data/cifar10_train.rec, use 4 threads for decoding..\r\n[10:25:19] src/io/iter_image_recordio.cc:221: ImageRecordIOParser: data/cifar10_val.rec, use 4 threads for decoding..\r\n[10:25:22] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\nINFO:root:Epoch[0] Batch [20]   Speed: 7.56 samples/sec Train-accuracy=0.101562 \r\n\r\n\r\nSo, please help us to solve this problem\r\n\r\nThank you very much.\r\n "", 'I can\'t reproduce this. I think it\'s something to do with your particular setup. I suggest just trying things like\r\nrunning in benchmark mode ( --benchmark 1), run it through a profiler that shows you where the CPU is spending it\'s time. You can profile the GPU with:\r\n""nvprof python train_cifar10.py --gpus 6,7""\r\n\r\nLook for the [CUDA memcpy HtoD] and [CUDA memcpy DtoH] tags, they tell you how much is spent in copying data between CPU and GPU.\r\n\r\nBtw. Why are you running this under sudo?\r\n', '@ap-hynninen \r\nSorry for late reply. We final find the reason by consulting our server vendor. This is a bug in how the Intel V4 Quick Path interconnect interfaces with PCI-E. Finally, we disable the ACS control in Bios->Advanced->Chipset Configuration->North Bridge->IO Configuration->Intel VT for Directed I/O(VT-d)->ACS Control.\r\n\r\nBut we have another issue about speed (xxx samples/sec) in training procedure. Please see this link https://github.com/dmlc/mxnet/issues/5365 ']",[],"['git rev-parse HEAD', 'sessionInfo()']",1,0
42,incubator-mxnet,9171,closed,"MXNet: Using FusedRNNCell with its ""bidirectional"" flag turned True, can lead to hanging of training run.","## Description
MXNet
Using FusedRNNCell with its ""bidirectional"" flag turned True, can lead to hanging (i.e. infinite pause without progress/error/crash) of training run.

## Details
I am running a single training run of a Sequence-to-Sequence model using the BucketingModule. Iam using an Encoder-Decoder network. I am using a FusedRNNCell with its ""bidirectional"" flag turned on for the Encoder and an unfused RNNCell for the Decoder.
GPU utilization is 15000MB / 16000MB. CPU utilization is 95%.
For each batch during training, I do a forward() pass and a backward() pass. After a 5-15 epochs, the training run gets stuck in the forward() pass of one of the mini-batches. The forward pass does not complete. No errors are thrown nor does anything crash. GPU/CPU utilization remains identically the same.

I have tried an ablation of many-many things in my training run (architecture, data, code etc). The conclusion is that specifically using the FusedRNNCell with the ""bidirectional"" flag turned True causes this problem.


## Package used
Python

## Environment info
----------Python Info----------
Version      : 3.5.2
Compiler     : GCC 5.4.0 20160609
Build        : ('default', 'Nov 23 2017 16:37:01')
Arch         : ('64bit', 'ELF')
------------Pip Info-----------
Version      : 9.0.1
Directory    : /usr/local/lib/python3.5/dist-packages/pip
----------MXNet Info-----------
Version      : 1.0.0
Directory    : /usr/local/lib/python3.5/dist-packages/mxnet
Commit Hash   : 25720d0e3c29232a37e2650f3ba3a2454f9367bb
----------System Info----------
Platform     : Linux-4.4.0-1039-aws-x86_64-with-Ubuntu-16.04-xenial
system       : Linux
node         : ip-172-31-85-194
release      : 4.4.0-1039-aws
version      : #48-Ubuntu SMP Wed Oct 11 15:15:01 UTC 2017
----------Hardware Info----------
machine      : x86_64
processor    : x86_64
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                64
On-line CPU(s) list:   0-63
Thread(s) per core:    2
Core(s) per socket:    16
Socket(s):             2
NUMA node(s):          2
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 79
Model name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz
Stepping:              1
CPU MHz:               1200.582
CPU max MHz:           3000.0000
CPU min MHz:           1200.0000
BogoMIPS:              4600.09
Hypervisor vendor:     Xen
Virtualization type:   full
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              46080K
NUMA node0 CPU(s):     0-15,32-47
NUMA node1 CPU(s):     16-31,48-63
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq monitor est ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt ida
----------Network Test----------
Setting timeout: 10
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0300 sec, LOAD: 0.0514 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.1141 sec, LOAD: 0.1956 sec.
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0016 sec, LOAD: 0.4062 sec.
Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.1799 sec, LOAD: 0.3847 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0046 sec, LOAD: 0.0126 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0154 sec, LOAD: 0.1567 sec.
`
",Bug Python RNN,"['I am using:\r\nMXNet==1.0.0\r\nCUDA==9.0\r\ncuDNN==7.0\r\n\r\nAs I understand, the FusedRNNCell is faster than the unused RNNCell because it makes direct function calls to a cuda kernel. It seems that the ""bidirectional"" flag in FusedRNNCell is directly passed to the cuda kernel call. This is just fyi. This might imply some cuda kernel issue but I am not a cuda expert.\r\n\r\n@eric-haibin-lin ', '## Want (but leads to hanging)\r\ncell = FusedRNNCell(.... bidirectional=True....)\r\n\r\n## best workaround (but still slow)\r\nl_cell = FusedRNNCell(.... bidirectional=False....)\r\nr_cell = FusedRNNCell(.... bidirectional=False....)\r\ncell = BidirectionalCell(l_cell, r_cell....)\r\n\r\nAll other workarounds are 3x-10x slower than what we ideally ""Want"" to use above. This workaround is ""only"" 2x slower.', ""What's the patch version for cudnn? Would you confirm if the hanging still happens with the latest cuda 9.0.176/9.1.x and cudnn 7.0.5? Also, what's the GPU?"", 'Could you provide runnable code snippet that reproduces the hanging problem? You can use random input if data is not related to the hanging problem.', '@szha \r\nI tested CUDA 9.0.176 with cuDNN 7.0.3  and with cuDNN 7.0.5.\r\nIn both cases, the hanging problem happens.\r\n', 'Proposed labels: Bug, Python, RNN', '@kalpitdixit does the problem still happen?', ""Hi @DickJC123 this is the issue I mentioned with fused RNN with bidirectional=True. \r\n@sxjscience this is also related to the error you're seeing? \r\n"", ""Looks similar. I'm trying to give a MWE."", 'The error message:\r\n```\r\nTraceback (most recent call last):\r\n  File ""sentiment_analysis.py"", line 270, in <module>\r\n    train(args)\r\n  File ""sentiment_analysis.py"", line 261, in train\r\n    test_avg_L, test_acc = evaluate(net, test_dataloader, context)\r\n  File ""sentiment_analysis.py"", line 136, in evaluate\r\n    total_L += L.sum().asscalar()\r\n  File ""/home/ubuntu/mxnet/python/mxnet/ndarray/ndarray.py"", line 1844, in asscalar\r\n    return self.asnumpy()[0]\r\n  File ""/home/ubuntu/mxnet/python/mxnet/ndarray/ndarray.py"", line 1826, in asnumpy\r\n    ctypes.c_size_t(data.size)))\r\n  File ""/home/ubuntu/mxnet/python/mxnet/base.py"", line 149, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [22:08:57] src/operator/./cudnn_rnn-inl.h:457: Check failed: e == CUDNN_STATUS_SUCCESS (8 vs. 0) cuDNN: CUDNN_STATUS_EXECUTION_FAILED\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /home/ubuntu/mxnet/python/mxnet/../../lib/libmxnet.so(dmlc::StackTrace[abi:cxx11]()+0x5b) [0x7f4cee092c5b]\r\n[bt] (1) /home/ubuntu/mxnet/python/mxnet/../../lib/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x28) [0x7f4cee093798]\r\n[bt] (2) /home/ubuntu/mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::op::CuDNNRNNOp<float>::Init(mshadow::Stream<mshadow::gpu>*, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)+0x2142) [0x7f4cf27b4f22]\r\n[bt] (3) /home/ubuntu/mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::op::CuDNNRNNOp<float>::Forward(mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)+0xa5d) [0x7f4cf27c2f1d]\r\n```', '@kalpitdixit Could you provide a script with which this issue occurs?', '@vandanavk \r\nRe-ran my code on the latest version of MXNet. This issues does not happen any longer.']",[],[''],1,1
43,incubator-mxnet,12891,closed,[MKLDNN] Performance on Windows - Upgrading MKLDNN submodule?,"Hi, I tried MXNet + MKLDNN on AVX 512 capable Windows machine, but performance was terrible. I noticed that MKLDNN pulled by mxnet is quite old, and older version of MKLDNN does not enable OpenMP on Windows (omp support was added in [this commit](https://github.com/intel/mkl-dnn/pull/260)). 

Do you have a plan to upgrade MKLDNN version?",,"['Yes, we will file PR in the next week.', 'Great! Thanks for the quick reply.', '@masahi updated, please double check if your issue is fixed :)', 'yes, I tried that PR before it was merged. Performance is good now.']",[],[],1,1
44,incubator-mxnet,16220,open,`NDArray.clip()` works very slow in imperative execution on GPU.,"## Description
 works very slow in imperative execution on GPU (~x3 slower than ReLU).
More details below

## Environment info (Required)



I'm using Python

## Build info (Required if built from source)
N/A

## Error Message:
Running GluonCV resnet18_v2 on ImageNet:
Imperative, with  as activation: throughput ~900 samples/sec.
~x3 slower compared to:
Imperative, with ReLU activation (original version): throughput ~3000 samples/sec.
Hybrid, with ReLU activation (original version): throughput ~3000 samples/sec.
Hybrid, with  as activation: throughput ~3000 samples/sec.


## Minimum reproducible example / Steps to reproduce
1. Start an AWS p3.8xlarge with Deep Learning AMI (Ubuntu) Version 24.1 machine
2. Activate mxnet env: 
3. Install gluoncv: pip install gluoncv
4. Download train_imagenet.py from gluoncv: https://gluon-cv.mxnet.io/_downloads/3bb06a6d6d085b1bb501b30aaf6c21c5/train_imagenet.py (source: https://gluon-cv.mxnet.io/model_zoo/classification.html#imagenet )
5. Modify line 257 ( https://github.com/dmlc/gluon-cv/blob/745ed855d769534eb2e23f0c136cd5f1bc9b60b7/gluoncv/model_zoo/resnet.py#L257 ) in /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluoncv/model_zoo/resnet.py , replace  with 
6. run:



## What have you tried to solve it?
N/A

Might be related to #11683",Operator Performance,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended label(s): Performance']","['\r\n----------Python Info----------\r\nVersion      : 3.6.5\r\nCompiler     : GCC 7.2.0\r\nBuild        : (\'default\', \'Apr 29 2018 16:14:56\')\r\nArch         : (\'64bit\', \'\')\r\n------------Pip Info-----------\r\nVersion      : 10.0.1\r\nDirectory    : /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.4.1\r\nDirectory    : /home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet\r\nCommit hash file ""/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/COMMIT_HASH"" not found. Not installed from pre-built package or built from source.\r\nLibrary      : [\'/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so\']\r\nBuild features:\r\nNo runtime build feature info available\r\n----------System Info----------\r\nPlatform     : Linux-4.4.0-1092-aws-x86_64-with-debian-stretch-sid\r\nsystem       : Linux\r\nnode         : ip-XXX-XX-X-XXX\r\nrelease      : 4.4.0-1092-aws\r\nversion      : #103-Ubuntu SMP Tue Aug 27 10:21:48 UTC 2019\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                32\r\nOn-line CPU(s) list:   0-31\r\nThread(s) per core:    2\r\nCore(s) per socket:    16\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\nStepping:              1\r\nCPU MHz:               2699.984\r\nCPU max MHz:           3000.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              4600.08\r\nHypervisor vendor:     Xen\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              46080K\r\nNUMA node0 CPU(s):     0-31\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0018 sec, LOAD: 0.5233 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.1289 sec, LOAD: 0.4413 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.2271 sec, LOAD: 0.5561 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0098 sec, LOAD: 0.4055 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0145 sec, LOAD: 0.3227 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0135 sec, LOAD: 0.0799 sec.\r\n----------Environment----------\r\n\r\n\r\n']","['NDArray.clip()', 'ndarray.clip(0,6)', 'ndarray.clip(0,6)', 'source activate mxnet_p36', ""x = F.Activation(x, act_type='relu')"", 'x = x.clip(a_min=0, a_max=6)', 'python train_imagenet.py --rec-train /home/ubuntu/path/to/train.rec --rec-train-idx /home/ubuntu/path/to/train.idx --rec-val /home/ubuntu/path/to/val.rec --rec-val-idx /home/ubuntu/path/to/val.idx --model resnet18_v2 --mode imperative --lr 0.4 --lr-mode cosine --num-epochs 120 --batch-size 256 --num-gpus 4 -j 30 --warmup-epochs 5 --use-rec --save-dir params_resnet18_v2']",1,0
45,incubator-mxnet,12255,closed,Pretty high cpu load when import mxnet,"When i import mxnet in 8 processes simultaneously, all cpu resources will be used and the program stagnates for almost 5 minutes.

It works fine for mxnet1.1 but failed for mxnet1.2 and mxnet1.3
Following is the sample code



Any solution to this for mxnet1.2 and mxnet1.3? Thanks.",Python,"['@fighting-liu : Just to understand your problem a little further, could you give details of your environment? This is given in the issue template. Also, what was the issue? Was the ""after import"" being printed after 5 minutes? How long did it take for 1.1 and also, how long does it take for one process import\'ing mxnet with .12?  System/environment information would be useful to help you further.\r\n\r\nFor reference of the issue template: https://github.com/apache/incubator-mxnet/blob/master/.github/ISSUE_TEMPLATE.md\r\n\r\n@mxnet-label-bot : [Python, Question]', ""@vdantu   Thanks for your attention.\r\n\r\n**1. Environment info**\r\n```\r\n----------System Info----------\r\n('Platform     :', 'Linux-3.10.0-693.17.1.el7.x86_64-x86_64-with-centos-7.4.1708-Core')\r\n('system       :', 'Linux')\r\n('node         :', '*****************')\r\n('release      :', '3.10.0-693.17.1.el7.x86_64')\r\n('version      :', '#1 SMP Thu Jan 25 20:13:58 UTC 2018')\r\n----------Hardware Info----------\r\n('machine      :', 'x86_64')\r\n('processor    :', 'x86_64')\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                56\r\nOn-line CPU(s) list:   0-55\r\nThread(s) per core:    2\r\nCore(s) per socket:    14\r\nSocket(s):             2\r\nNUMA node(s):          2\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz\r\nStepping:              1\r\nCPU MHz:               2401.000\r\nCPU max MHz:           2401.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              4800.04\r\nVirtualization:        VT-x\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              35840K\r\nNUMA node0 CPU(s):     0-13,28-41\r\nNUMA node1 CPU(s):     14-27,42-55\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 invpcid_single intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.3104 sec, LOAD: 5.1832 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.5159 sec, LOAD: 6.2714 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.5885 sec, LOAD: 2.0516 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.5425 sec, LOAD: 1.0500 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 1.4049 sec, LOAD: 4.5601 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 2.1899 sec, LOAD: 2.9143 sec.\r\n```\r\n\r\n**2. Sample code**\r\n```\r\nimport multiprocessing\r\nimport time\r\n\r\ndef mxnet_worker():\r\n    b_time = time.time()\r\n    import mxnet \r\n    print 'time consumes: {}'.format(time.time()-b_time)\r\n\r\nread_process = [multiprocessing.Process(target=mxnet_worker) for i in range(8)]\r\nfor p in read_process:\r\n    p.daemon = True\r\n    p.start()\r\n```\r\n\r\n**3. Test results**\r\n3.1  pip install mxnet-cu90==1.1  \r\n![image](https://user-images.githubusercontent.com/10908786/44385340-ad1b9480-a551-11e8-99e0-dc3e4c24a53f.png)\r\n\r\n3.2 pip install mxnet-cu90==1.2\r\n![image](https://user-images.githubusercontent.com/10908786/44385365-c3295500-a551-11e8-9926-1ee19abfecfb.png)\r\n\r\n3.3 pip install --pre mxnet-cu90 (mxnet_cu90-1.3.0b20180820)\r\n![image](https://user-images.githubusercontent.com/10908786/44385380-ce7c8080-a551-11e8-8067-534575dc491e.png)\r\n\r\n**4. Cpu status from htop monitor**\r\n![image](https://user-images.githubusercontent.com/10908786/44385436-fd92f200-a551-11e8-935e-441578df8fd0.png)\r\n\r\nIt takes too much time to import mxnet with mxnet 1.2 and mxnet 1.3"", 'Thanks for sharing this info. This is a good observation. I think it would be good to have a larger audience for this, could you also start a thread on discuss.mxnet.io? ', ""@vdantu Can you solve this problem??  I've start a thread on discuss.mxnet.io, but nobody answers."", ""```\r\nimport ctypes\r\nimport time\r\n\r\nstart = time.time()\r\nctypes.CDLL('libmxnet_1.1.so', ctypes.RTLD_LOCAL)\r\nprint 'load libmxnet1.1.so', time.time() - start\r\n\r\nstart = time.time()\r\nctypes.CDLL('libmxnet_1.3.so', ctypes.RTLD_LOCAL)\r\nprint 'load libmxnet1.3.so', time.time() - start\r\n```\r\n\r\n```\r\nload libmxnet1.1.so 0.0203261375427\r\nload libmxnet1.3.so 1.06584215164\r\n```\r\n\r\nFYI，this might the reason why it costs too much time."", '@vdantu ', '@kardoszc using the example provided by you , i was able to get the same result on run 1 on a MAC, on consecutive runs of the above, the speed was better, or similar\r\n```bash\r\n$python mxnet11.py \r\nload libmxnet1.1.so  0.019122838973999023\r\nload libmxnet1.3.so  0.035729169845581055\r\n$python mxnet11.py \r\nload libmxnet1.1.so  0.01851797103881836\r\nload libmxnet1.3.so  0.034262895584106445\r\n$ python mxnet11.py \r\nload libmxnet1.1.so  0.019358158111572266\r\nload libmxnet1.3.so  0.03675413131713867\r\n$ python mxnet11.py \r\nload libmxnet1.1.so  0.01902318000793457\r\nload libmxnet1.3.so  0.03872489929199219\r\n```\r\n\r\nThe files are about 10MB different is size, so the loading time itself is slightly higher on 1.3\r\n\r\nls -l libmxnet1.*.so \r\n```bash\r\n27494556 Oct  2 15:50 libmxnet1.1.so\r\n37263368 Oct  2 15:51 libmxnet1.3.so\r\n```', ""@fighting-liu \r\nsimilar results to above were observed running your example \r\n\r\n```bash\r\n>>> def mxnet_worker():\r\n...     b_time = time.time()\r\n...     import mxnet \r\n...     print 'time consumes: {}'.format(time.time()-b_time)\r\n... \r\n>>> read_process = [multiprocessing.Process(target=mxnet_worker) for i in range(8)]\r\n>>> for p in read_process:\r\n...     p.daemon = True\r\n...     p.start()\r\n... \r\n>>> time consumes: 15.8834888935\r\ntime consumes: 15.884565115\r\ntime consumes: 15.8791670799\r\ntime consumes: 15.8853030205\r\ntime consumes: 15.8832161427\r\ntime consumes: 15.882764101\r\ntime consumes: 15.8819229603\r\ntime consumes: 15.8869299889\r\n\r\n>>> read_process = [multiprocessing.Process(target=mxnet_worker) for i in range(8)]\r\n>>> for p in read_process:\r\n...     p.daemon = True\r\n...     p.start()\r\n... \r\n>>> time consumes: 1.01575899124\r\ntime consumes: 1.02250099182\r\ntime consumes: 1.03319501877\r\ntime consumes: 1.03118515015\r\ntime consumes: 1.03451776505\r\ntime consumes: 1.03348302841\r\ntime consumes: 1.03426003456\r\ntime consumes: 1.03685307503\r\n```\r\n\r\nThe second run gets the speed up again, I observed a similar trend in 1.1 as well, although the gap is smaller.\r\n\r\nI am investigating this issue further"", 'More updates this issue seems to specific to linux, reproduced Original posters issue on a linux box\r\nmxnet 1.1\r\n```python\r\n>>> import multiprocessing\r\n>>> import time\r\n>>> \r\n>>> def mxnet_worker():\r\n...     b_time = time.time()\r\n...     import mxnet \r\n...     print \'time consumes: {}\'.format(time.time()-b_time)\r\n... \r\n>>> read_process = [multiprocessing.Process(target=mxnet_worker) for i in range(8)]\r\n>>> for p in read_process:\r\n...     p.daemon = True\r\n...     p.start()\r\n... \r\n>>> time consumes: 0.513573884964\r\ntime consumes: 0.518635988235\r\ntime consumes: 0.553323984146\r\ntime consumes: 0.549813985825\r\ntime consumes: 0.558361053467\r\ntime consumes: 0.556171894073\r\ntime consumes: 0.566649913788\r\ntime consumes: 0.569785118103\r\n```\r\n\r\nmxnet 1.3\r\n```python\r\npython\r\nPython 2.7.12 (default, Dec  4 2017, 14:50:18) \r\n[GCC 5.4.0 20160609] on linux2\r\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\r\n>>> import multiprocessing\r\n>>> import time\r\n>>> \r\n>>> def mxnet_worker():\r\n...     b_time = time.time()\r\n...     import mxnet \r\n...     print \'time consumes: {}\'.format(time.time()-b_time)\r\n... \r\n>>> read_process = [multiprocessing.Process(target=mxnet_worker) for i in range(8)]\r\n>>> for p in read_process:\r\n...     p.daemon = True\r\n...     p.start()\r\n... \r\n>>> time consumes: 8.75463604927\r\ntime consumes: 17.4193239212\r\ntime consumes: 17.656072855\r\ntime consumes: 18.1875190735\r\ntime consumes: 18.4937279224\r\ntime consumes: 18.5608999729\r\ntime consumes: 18.5980598927\r\ntime consumes: 18.6172778606\r\n```', '@fighting-liu is your MXNet built from source, or installed via pip? if installed via pip - which version of MXNet? (mxnet/mxnet-mkl/mxnet-cu90mkl/...), if built from source can you provide the build flags?\r\n\r\n@vrakesh the original report is that program stagnates for 5 mins... what is the total time you are seeing? ', '@lupesko I do not see times as high was 5 minutes, overall, the who run is under 30s. But it should take take more than a second or so to complete a C library import\r\n\r\nWhen a single instance is imported it takes about half a second to import , as the number of parallel import increases , the time taken drastically increases.', 'Hey Guys, we need to start getting consistent in what and how were testing this. \r\n\r\nHere was I tried:\r\n\r\n1. spin up a C5.large instance with DLAMI v19.0\r\n2. pip install mxnet-cu90 --user\r\n3. time python -c ""import mxnet""\r\n\r\nHere was the output:\r\n\r\nreal\t0m24.955s\r\nuser\t0m0.827s\r\nsys\t0m0.189s\r\n\r\nDoing it a second time resulted in the following (and for every subsequent time too).\r\n\r\nreal\t0m0.855s\r\nuser\t0m0.798s\r\nsys\t0m0.123s\r\n\r\nSpinning up a new instance, reinstalling the pip and running the script above for running 8 processes in parallel resulted in:\r\n\r\n$ time python load_time.py \r\ntime consumes: 24.740694046020508\r\ntime consumes: 24.74588418006897\r\ntime consumes: 24.746330499649048\r\ntime consumes: 24.759278059005737\r\ntime consumes: 24.75693655014038\r\ntime consumes: 24.76559042930603\r\ntime consumes: 24.780791997909546\r\ntime consumes: 24.783067226409912\r\n\r\nreal\t0m24.829s\r\nuser\t0m8.753s\r\nsys\t0m0.742s\r\n\r\nAnd running it a 2nd (and every subsequent) time:\r\n\r\n$ time python load_time.py \r\ntime consumes: 4.612242221832275\r\ntime consumes: 4.625608682632446\r\ntime consumes: 4.641973257064819\r\ntime consumes: 4.690966844558716\r\ntime consumes: 4.7061262130737305\r\ntime consumes: 4.699116945266724\r\ntime consumes: 4.703948259353638\r\ntime consumes: 4.718777418136597\r\n\r\nreal\t0m4.770s\r\nuser\t0m8.823s\r\nsys\t0m0.650s\r\n\r\nI terminated that instance and spun up a new one and after installing the pip wheel I modified the file in \r\n```\r\n/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/__init__.py\r\n```\r\n (where the packages are installed with --user) to get an idea which imports where causing the most delay. Heres what I found were the biggest offenders:\r\n\r\n```\r\nfrom .context import Context, current_context, cpu, gpu, cpu_pinned\r\nfrom . import engine\r\nfrom .base import MXNetError\r\nfrom . import base\r\nfrom . import contrib\r\nfrom . import ndarray\r\nfrom . import ndarray as nd\r\nfrom . import name\r\n```\r\ntime = 20.388737678527832\r\n\r\n```\r\nfrom . import random as rnd\r\nfrom . import random\r\nfrom . import optimizer\r\nfrom . import model\r\nfrom . import metric\r\nfrom . import notebook\r\nfrom . import initializer\r\n```\r\ntime = 0.5453829765319824\r\n\r\n```\r\nfrom . import image\r\nfrom . import image as img\r\n\r\nfrom . import test_utils\r\n\r\nfrom . import rnn\r\n\r\nfrom . import gluon\r\n```\r\ntime = 0.4957273006439209\r\n\r\nRunning the 2nd time resulted in 0.6350719928741455 for the first block and 0.01 for the other two. \r\n\r\nNow that we know the biggest delay is coming from that first group, i terminated and spun up a new instance, reinstalled and timed around those imports and found these two were causing the most delay:\r\n\r\n```\r\nfrom .context import Context, current_context, cpu, gpu, cpu_pinned\r\nfrom . import contrib\r\n```\r\n9.019979238510132\r\n14.68500018119812\r\n\r\nSo those two make up the majority of the 24 seconds we\'re seeing. If someone else could help out and jump in and follow a similar approach for the context and contrib, we can zoom in on the culprit.', 'I took the script from above and added another loop to try from 1 to 36 processes testing a local build from source (not pip package):\r\n\r\n```\r\nimport multiprocessing\r\nimport time\r\n\r\ndef mxnet_worker():\r\n    #t1 = time.time()\r\n    import mxnet\r\n    #t2 = time.time()\r\n    #elapsed = t2-t1\r\n    #print(times)\r\n\r\ntimes = []\r\nfor i in range(37):\r\n    t1 = time.time()\r\n    read_process = [multiprocessing.Process(target=mxnet_worker) for i in range(i)]\r\n    for p in read_process:\r\n        p.daemon = True\r\n        p.start()\r\n\r\n    for p in read_process:\r\n        p.join()\r\n    t2 = time.time()\r\n    times.append(t2-t1)\r\n\r\nfor i in times:\r\n    print(i)\r\n```\r\n\r\nHere are the results when compiling with the following cmake flags:\r\n\r\n```\r\ncmake -DUSE_CUDA=OFF -DUSE_CUDNN=OFF -DUSE_MKLDNN=OFF -DBLAS=Open -DCMAKE_BUILD_TYPE=Debug  ..\r\n```\r\n\r\n1: 5.77136611938\r\n2: 7.65716195107\r\n3: 13.9892320633\r\n4: 16.6815569401\r\n5: 22.9886288643\r\n6: 27.6006569862\r\n7: 30.7331540585\r\n8: 33.8466141224\r\n9: 34.18151021\r\n10: 37.1062369347\r\n11: 43.6272640228\r\n12: 44.1143600941\r\n13: 45.8406460285\r\n14: 46.6692020893\r\n15: 47.8332960606\r\n16: 52.4621579647\r\n17: 56.1070458889\r\n18: 56.8046569824\r\n19: 54.1124491692\r\n20: 65.2930281162\r\n21: 62.0744900703\r\n22: 60.4670469761\r\n23: 69.6229948997\r\n24: 71.4172370434\r\n25: 70.9572968483\r\n26: 74.8509230614\r\n27: 77.0419559479\r\n28: 78.2489409447\r\n29: 80.1934709549\r\n30: 74.9342000484\r\n31: 84.4639661312\r\n32: 83.6565339565\r\n33: 91.3137798309\r\n34: 88.20520401\r\n35: 96.2017951012\r\n36: 96.4477438927\r\n\r\nThen I tested against the pip wheel:\r\n\r\n1: 1.86075401306\r\n2: 2.52445602417\r\n3: 27.84821105\r\n4: 272.775645971\r\n5: 532.317739964\r\n6: 785.189717054\r\n\r\nand i killed it after 6 processes. I think we get the picture. \r\n\r\nHeres another set of results when compiling without openmp:\r\n\r\n```\r\ncmake -DUSE_CUDA=OFF -DUSE_CUDNN=OFF -DUSE_MKLDNN=OFF -DBLAS=Open -DCMAKE_BUILD_TYPE=Debug -DUSE_OPENMP=OFF ..\r\n```\r\n\r\n\r\n1: 0.827432\r\n2: 0.859651\r\n3: 0.858839\r\n4: 0.833471\r\n5: 0.884956\r\n6: 0.883090\r\n7: 0.862174\r\n8: 0.888009\r\n9: 0.891180\r\n10: 0.917642\r\n11: 0.894244\r\n12: 0.947771\r\n13: 0.944967\r\n14: 0.956380\r\n15: 0.932657\r\n16: 0.991420\r\n17: 0.956935\r\n18: 0.924413\r\n19: 0.935913\r\n20: 0.944736\r\n21: 0.996702\r\n22: 0.934430\r\n23: 0.966333\r\n24: 1.022540\r\n25: 1.038306\r\n26: 1.175906\r\n27: 1.056674\r\n28: 1.022513\r\n29: 1.083556\r\n30: 1.151226\r\n31: 1.078056\r\n32: 1.046550\r\n33: 1.220279\r\n34: 1.256747\r\n35: 1.334894\r\n36: 1.377328\r\n\r\nClearly theres a problem with OpenMP seeing as the results are very reasonable to load when OpenMP is not used. \r\n\r\n@szha, can you take a look at this? Theres a huge discrepancy between building from source and the pip wheel. Is there something different that is done when building the pip wheel related to OpenMP?', 'Looks like the processes are stuck at gomp_team_start if I use multiprocessing\r\n\r\n```\r\n#0  0x00007f5a797a774a in do_spin (val=22256, addr=addr@entry=0x55f45a6451c4)\r\n    at /opt/conda/conda-bld/compilers_linux-64_1534514838838/work/.build/x86_64-conda_cos6-linux-gnu/src/gcc/libgomp/config/linux/x86/futex.h:130\r\n#1  do_wait (addr=addr@entry=0x55f45a6451c4, val=val@entry=22256) at /opt/conda/conda-bld/compilers_linux-64_1534514838838/work/.build/x86_64-conda_cos6-linux-gnu/src/gcc/libgomp/config/linux/wait.h:66\r\n#2  0x00007f5a797a7813 in gomp_barrier_wait_end (bar=0x55f45a6451c0, state=22256)\r\n    at /opt/conda/conda-bld/compilers_linux-64_1534514838838/work/.build/x86_64-conda_cos6-linux-gnu/src/gcc/libgomp/config/linux/bar.c:48\r\n#3  0x00007f5a797a6a1d in gomp_simple_barrier_wait (bar=<optimized out>)\r\n    at /opt/conda/conda-bld/compilers_linux-64_1534514838838/work/.build/x86_64-conda_cos6-linux-gnu/src/gcc/libgomp/config/posix/simple-bar.h:60\r\n#4  gomp_team_start (fn=<optimized out>, data=<optimized out>, nthreads=7, flags=<optimized out>, team=0x55f45a646790)\r\n    at /opt/conda/conda-bld/compilers_linux-64_1534514838838/work/.build/x86_64-conda_cos6-linux-gnu/src/gcc/libgomp/team.c:829\r\n#5  0x00007f5a4f6cd8a8 in ?? () from /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so\r\n#6  0x00007f5a4f6dee3c in ?? () from /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so\r\n#7  0x00007f5a4f6df9fd in ?? () from /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so\r\n#8  0x00007f5a4f6dfb53 in ?? () from /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so\r\n#9  0x00007f5a4cb5f794 in ?? () from /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so\r\n#10 0x00007f5a7f5336ba in call_init (l=<optimized out>, argc=argc@entry=2, argv=argv@entry=0x7ffd800cd128, env=env@entry=0x55f45a0422b0) at dl-init.c:72\r\n#11 0x00007f5a7f5337cb in call_init (env=0x55f45a0422b0, argv=0x7ffd800cd128, argc=2, l=<optimized out>) at dl-init.c:30\r\n#12 _dl_init (main_map=main_map@entry=0x55f45a485c90, argc=2, argv=0x7ffd800cd128, env=0x55f45a0422b0) at dl-init.c:120\r\n#13 0x00007f5a7f5388e2 in dl_open_worker (a=a@entry=0x7ffd800c8610) at dl-open.c:575\r\n```\r\n\r\nBut instead if I use threads, like below, threads don\'t get stuck. \r\n\r\n```\r\ndef mxnet_worker():\r\n    print(""before import: pid:{}"".format(getpid()))\r\n    st_time = time.time()\r\n    import mxnet\r\n    end_time = time.time()\r\n    print(""after import: pid:{} time:{}"".format(getpid(), end_time - st_time))\r\n\r\n#read_process = [multiprocessing.Process(target=mxnet_worker) for i in range(8)]\r\nfrom threading import Thread\r\ni=0\r\nwhile i<8:\r\n    t1 = Thread(target=mxnet_worker)\r\n    t1.start()\r\n    i=i+1\r\n#for p in read_process:\r\n#    p.daemon = True\r\n#    time.sleep(3)\r\n#    p.start()\r\n#time.sleep(100000)\r\n```\r\n\r\n\r\nLooks like there is issue with fork + openmp , \r\nWe should check if this is related : https://bisqwit.iki.fi/story/howto/openmp/#OpenmpAndFork\r\n\r\n', 'I added a 2 second delay between launching each process in the script and found that most processes complete the import between 1.7-1.9 seconds. This 2 second delay prevents processes from competing for resources at the same time. There appears to be some bad contention going on thats causing the large delay. Adding the 2 second delay prevented large exponential increase in import delay. Heres the data for 1-36 processes with this 2 second delay using the pip wheel:\r\n\r\n1: 2.002468\r\n2: 4.005214\r\n3: 6.007431\r\n4: 8.617790\r\n5: 10.012702\r\n6: 12.015214\r\n7: 14.018058\r\n8: 16.020579\r\n9: 18.022354\r\n10: 20.025505\r\n11: 22.027436\r\n12: 24.030987\r\n13: 26.033214\r\n14: 28.035729\r\n15: 30.037884\r\n16: 32.041215\r\n17: 34.043598\r\n18: 36.044175\r\n19: 38.048719\r\n20: 40.051221\r\n21: 42.053396\r\n22: 44.055702\r\n23: 46.058514\r\n24: 48.060241\r\n25: 50.063950\r\n26: 52.727346\r\n27: 54.068652\r\n28: 56.071813\r\n29: 58.073548\r\n30: 60.076997\r\n31: 62.079071\r\n32: 64.081306\r\n33: 66.716197\r\n34: 68.085373\r\n35: 70.088400\r\n36: 72.092169\r\n\r\nSo while the 12 seconds for 6 processes isnt ideal, it much better than the 785 that was found earlier without the 2 second delay. \r\n\r\nSo short-term workaround is to measure about how long it takes to ""import mxnet"" in a single process and then add an appropriately longer (~2second) delay between launching each process to avoid contention. The delay length might need to be tuned for each use case to avoid contention. \r\n\r\nWe\'ll continue debugging and trace the OpenMP problem and try to resolve it.\r\n', 'if you fork and then try to use OMP in thenforked process and are using libgomp, the process will hang because libgomp does not support forking.', 'OMP has a very high overhead in ec2 instances with 36+ cores. this is a known problem with ec2 instances.', 'There is huge number of threads getting created in operator-tune-inl.h that causes huge cpu load, threads take long time to determine whether they should use openmp for operator or not.\r\nThis problem gets worse with machines with more cores. \r\nAnd multiplies with more processes. \r\nAs an experiment if I change the omp parallelism to thread count 1, and launch 32 processes it just take 6 seconds to load.', 'This is the code in https://github.com/apache/incubator-mxnet/blob/master/src/operator/operator_tune-inl.h#L359\r\n```\r\nconst auto max_cores = static_cast<size_t>(omp_get_num_procs()) >> 1;\r\n    if (max_cores >= 2) {\r\n      std::vector<duration_t> core_times;\r\n      // Take care of any OMP lazy-init with a throwaway call\r\n      for (size_t omp_threads = 2; omp_threads <= max_cores; ++omp_threads) {\r\n        GetOMPLoopOverhead(omp_threads);\r\n}\r\n```\r\nIf there are 36 cores, total threads will be 2+3+4+...18 = 170 threads \r\nif there are 32 mxnet python processes = 170*32 = 5440 threads launched to determine tuning. Then there is resource conetention + omp_badness . \r\nWe would need to reduce the num of threads to determine tuning, making it bounded if possible.\r\n', '@cjolivier01 Would running with MXNET_USE_OPERATOR_TUNING=0 mitigate this issue?', 'Hi @larroy , setting that env var does seem to avoid the issue. Heres the testing with and without it:\r\n\r\n```\r\n$ python parallel_test.py \r\n1: 3.71833109856\r\n2: 2.17086696625\r\n3: 46.48721385\r\n\r\nubuntu@ip-172-31-83-54:~$ export MXNET_USE_OPERATOR_TUNING=0\r\nubuntu@ip-172-31-83-54:~$ python parallel_test.py \r\n1: 0.798185110092\r\n2: 0.792401075363\r\n3: 0.818596124649\r\n```\r\n\r\nNotice that in the 2nd run with the env var, that all runs take ~0.8 seconds\r\n\r\n@cjolivier01 what are the performance implications for setting this env var? Does it only affect non-MKL/MKLDNN operators executing on CPU context? ', 'Closing this issue since the related PR is merged. Will track in a new issue, turning off omp tuning for the subprocess.']","[""\r\nimport multiprocessing\r\n\r\ndef mxnet_worker():\r\n    print 'before import'\r\n    import mxnet \r\n    print 'after import'\r\n\r\nread_process = [multiprocessing.Process(target=mxnet_worker) for i in range(8)]\r\nfor p in read_process:\r\n    p.daemon = True\r\n    p.start()\r\n""]",[],1,1
46,incubator-mxnet,3039,closed,mx.nd.zeros() slow on GPU,"It seems that mx.nd.zeros() runs pretty slow on GPU, rather than CPU.
Tested on my 980Ti and AWS g2.8xlarge instance (K520 GPU). CUDA 7.0/cudnn R5.
Python codes and results commented:


",,"['There seem to be some issue causing the first CUDA api call to be very slow. Can you make a call of `zeros` on both GPU and CPU first to warm up, and then measure the call time?\n', 'I ran it 4 times. Results in seconds.\n\nOn 980Ti:\n\nmx.nd.zeros(cpu):0.000653982162476\nmx.nd.zeros(gpu):0.963800907135\nmx.nd.zeros(cpu):0.000212907791138\nmx.nd.zeros(gpu):0.00437688827515\nmx.nd.zeros(cpu):0.000227928161621\nmx.nd.zeros(gpu):0.000316143035889\nmx.nd.zeros(cpu):0.000238180160522\nmx.nd.zeros(gpu):0.000317096710205\n\nOn K520 (AWS g2.8xlarge instance):\n\nmx.nd.zeros(cpu):0.000871896743774\nmx.nd.zeros(gpu):77.7828960419\nmx.nd.zeros(cpu):0.000491857528687\nmx.nd.zeros(gpu):0.000550031661987\nmx.nd.zeros(cpu):0.00060510635376\nmx.nd.zeros(gpu):0.000512838363647\nmx.nd.zeros(cpu):0.000540971755981\nmx.nd.zeros(gpu):0.000426054000854\n', 'There are [many issues](https://github.com/dmlc/mxnet/issues?utf8=%E2%9C%93&q=opencv%20GPU%20slow) that seem to be related. Recompiling openCV withOUT GPU support seem to resolve those issues.\n', 'Building Opencv without GPU should solve this issue. Please reopen it if you find it do not work.\n', 'confirmed on my side. if you build opencv from scratch, it will enable gpu in default. we need to have a FAQ for all these things. \n', 'there are instructions for how to build opencv without gpu:\n\nhttps://github.com/dmlc/mxnet/blob/master/docs/how_to/build.md#build-opencv-from-source\n\nrelated issue https://github.com/dmlc/mxnet/issues/3012\n']","[""\nimport mxnet as mx\nimport time\nshapes = [[100, 100]] * 10\n\nstart_time = time.time()\nresult = [mx.nd.zeros(shape, mx.cpu()) for shape in shapes]\nstop_time = time.time()\nprint 'mx.nd.zeros(cpu):' + str(stop_time-start_time)\n# mx.nd.zeros(cpu):0.000483989715576\n\nstart_time = time.time()\nresult = [mx.nd.zeros(shape, mx.gpu(0)) for shape in shapes]\nstop_time = time.time()\nprint 'mx.nd.zeros(gpu):' + str(stop_time-start_time)\n# mx.nd.zeros(gpu):0.752362966537\n""]",[],1,0
47,incubator-mxnet,1889,closed,Benchmarking on 8 GPU System,"Alright, I'm running the out-of-box CIFAR10 image training script on an 8 GPU system.

It seems like I'm getting the best performance using just 4 GPUs (graph attached.)  Is this expected to be expected or possibly i need to do some additional configuration ?  

Thanks !

![mxnet_cifar10_gpus](https://cloud.githubusercontent.com/assets/442121/14619220/4a43764e-056b-11e6-9fc1-f8259789ca7f.png)
",,"['the workload of cifar10 with inception is quite tiny. i suggest you to try the imagenet dataset\n', ""great, thats what i needed to know.  i figured i'd try a smaller dataset first and work my way to imagenet...\n"", 'Hey, Mu - maybe you can point me in the right direction.  \n\nAs you recommended - I have downloaded imagenet and i\'m ready to reproduce the experiment here- http://mxnet-bing.readthedocs.org/en/latest/tutorial/imagenet_full.html\n\nThere seems to be some missing documentation links in the **step-by-step tutorial** here - https://mxnet.readthedocs.org/en/latest/python/io.html#create-dataset-using-recordio\n\nShould I just use the train_imagenet.py script and point it to the imagenet directory ?  Do I need to use ""recordio"" files ?\n\nThanks...\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],1,0
48,incubator-mxnet,4195,closed,problem with bucketing lstm and cnn for text recognition,"Hi everyone, I want to use lstm and cnn to implement text recognition from image. for example recognize 'good' from a text image bounding box.
and I use warp-ctc as loss function but I find my softmax out are always the same.
## Environment info
Operating System: ubuntu 16.04

Compiler: gcc 5.4


Package used (Python/R/Scala/Julia): Python

MXNet commit hash (): 32cb6bc 

Python version and distribution: Python 2.7.11 |Anaconda 4.0.0 (x86_64)

## Error Message:
The following is my output of final fullyconnected layer as pred:

array([[ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051],
       [ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051],
       [ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051],
       ..., 
       [ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051],
       [ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051],
       [ 0.01282051,  0.01282051,  0.01282051, ...,  0.01282051,
         0.01282051,  0.01282051]], dtype=float32))

0.01282051=1/78 as I have 78 different chars to classify.
my dataiter is based on bucket_io.py in rnn example dir, and lstm part is based on warp-ctc example.

## Minimum reproducible example

1.my network structure:

2.metric function:

3.DataIter:


## What have you tried to solve it?

1.I try to use bi-lstm but get the same output problem
2.do mxnet provide API to get the middle layers' output when fitting the model?",,"['you can use monitor to get intermediate results: example/python-howto/monitor_weights.py\r\n\r\nHave you tried the examples? Does it work?', ""@piiswrong I've tried warp-ctc before, it works, but I have not tried lstm-ptb yet, you're right I should try ptb in a bucketing way. Thanks a lot."", '@piiswrong Sorry to bother you, I try to use monitor but get this error ：\r\n```\r\nNotImplementedError: Monitoring is not implemented for bucketing\r\n```\r\nHow could I monitor weights in a bucketing model?', 'and I tried the lstm_bucketing in example/rnn dir, it does work.', '@piiswrong A strange thing is that when I resized all images with same aspect ratio and use only one bucket, the model works fine . but if I  use default_gen_buckets to generate different buckets according to different images aspect ratio, the output from the final ctc layer are always the same during training.', 'Can you set the batch_size=1 and retry?', '@formath I have tried it, I found that if I used 2 buckets ,only one bucket updated during training and the other stayed the same.', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']","['\r\npred = mx.sym.FullyConnected(data=hidden_concat, num_hidden=78)\r\n', '\r\ndef lenet(data):\r\n    conv1 = mx.symbol.Convolution(data=data, kernel=(3,3), num_filter=32,pad=(1,1))\r\n    relu1 = mx.symbol.Activation(data=conv1, act_type=""relu"")\r\n    conv2 = mx.symbol.Convolution(data=relu1, kernel=(3,3), num_filter=32,pad=(1,1))\r\n    relu2 = mx.symbol.Activation(data=conv2, act_type=""relu"")\r\n    pool1 = mx.symbol.Pooling(data=relu2, pool_type=""max"", kernel=(2,2), stride=(2, 2))\r\n\r\n    conv3 = mx.symbol.Convolution(data=pool1, kernel=(3,3), num_filter=64,pad=(1,1))\r\n    relu3 = mx.symbol.Activation(data=conv3, act_type=""relu"")\r\n    conv4 = mx.symbol.Convolution(data=relu3, kernel=(3,3), num_filter=64,pad=(1,1))\r\n    relu4 = mx.symbol.Activation(data=conv4, act_type=""relu"")\r\n    pool2 = mx.symbol.Pooling(data=relu4, pool_type=""max"", kernel=(2,2), stride=(2, 2))\r\n    return pool2\r\ndef lstm_unroll(num_lstm_layer, seq_len,\r\n                num_hidden, num_label):\r\n    param_cells = []\r\n    last_states = []\r\n    for i in range(num_lstm_layer):\r\n        param_cells.append(LSTMParam(i2h_weight=mx.sym.Variable(""l%d_i2h_weight"" % i),\r\n                                     i2h_bias=mx.sym.Variable(""l%d_i2h_bias"" % i),\r\n                                      h2h_weight=mx.sym.Variable(""l%d_h2h_weight"" % i),\r\n                                     h2h_bias=mx.sym.Variable(""l%d_h2h_bias"" % i)))\r\n        state = LSTMState(c=mx.sym.Variable(""l%d_init_c"" % i),\r\n                          h=mx.sym.Variable(""l%d_init_h"" % i))\r\n        last_states.append(state)\r\n    assert(len(last_states) == num_lstm_layer)\r\n\r\n    # embeding layer\r\n    data = mx.sym.Variable(\'data\')\r\n    label = mx.sym.Variable(\'label\')\r\n    conv=lenet(data)\r\n    column_features = mx.sym.SliceChannel(data=conv, num_outputs=seq_len,axis=3, squeeze_axis=1)\r\n    hidden_all = []\r\n    for seqidx in range(seq_len):\r\n        hidden =mx.sym.Flatten(data=column_features[seqidx])\r\n        for i in range(num_lstm_layer):\r\n            next_state = lstm(num_hidden, indata=hidden,\r\n                              prev_state=last_states[i],\r\n                              param=param_cells[i],\r\n                              seqidx=seqidx, layeridx=i)\r\n            hidden = next_state.h\r\n            last_states[i] = next_state\r\n        hidden_all.append(hidden)\r\n\r\n    hidden_concat = mx.sym.Concat(*hidden_all, dim=0)\r\n    pred = mx.sym.FullyConnected(data=hidden_concat, num_hidden=78)\r\n\r\n    label = mx.sym.Reshape(data=label, shape=(-1,))\r\n    label = mx.sym.Cast(data = label, dtype = \'int32\')\r\n    sm = mx.sym.WarpCTC(data=pred, label=label, label_length = num_label, input_length = seq_len)\r\n    return sm\r\n', '\r\ndef Accuracy(label, pred):\r\n    global BATCH_SIZE\r\n    global SEQ_LENGTH\r\n    print (label,pred)\r\n    hit = 0.\r\n    total = 0.\r\n    for i in range(BATCH_SIZE):\r\n        l = remove_blank(label[i])\r\n        p = []\r\n        #print (""pred length : "", len(pred))\r\n        for k in range(len(pred)/BATCH_SIZE):\r\n            p.append(np.argmax(pred[k * BATCH_SIZE + i]))\r\n        p = ctc_label(p)\r\n        if len(p) == len(l):\r\n            match = True\r\n            for k in range(len(p)):\r\n                if p[k] != int(l[k]):\r\n                    match = False\r\n                    break\r\n            if match:\r\n                hit += 1.0\r\n        total += 1.0\r\n    return hit / total\r\n', '\r\nclass BucketimageIter(mx.io.DataIter):\r\n    def __init__(self, path, vocab, buckets, batch_size,\r\n                 init_states, data_name=\'data\', label_name=\'label\',\r\n                 seperate_char=\' <eos> \', get_image_function=None, read_content=None, model_parallel=False):\r\n        super(BucketimageIter, self).__init__()\r\n\r\n        if get_image_function == None:\r\n            self.get_image_function = get_image_fit_bucket\r\n        else:\r\n            self.get_image_function = get_image_fit_bucket\r\n        if read_content == None:\r\n            self.read_content = default_read_content\r\n        else:\r\n            self.read_content = read_content\r\n        content = self.read_content(path)\r\n        labels = default_get_labels(path)\r\n        labels = string2id(labels,vocab)\r\n        #print (labels)\r\n        images = default_get_images(path)\r\n        self.labels=labels\r\n        #print (self.label)\r\n        if len(buckets) == 0:\r\n            buckets = default_gen_buckets(images, batch_size)\r\n        self.max_label_length=get_max_label_length(labels)\r\n        self.vocab_size = len(vocab)\r\n        self.data_name = data_name\r\n        self.label_name = label_name\r\n        self.model_parallel = model_parallel\r\n\r\n        buckets.sort()\r\n        self.buckets = buckets\r\n        print (self.buckets)\r\n        self.data = [[] for _ in buckets]\r\n        self.label = [[] for _ in buckets]\r\n        # pre-allocate with the largest bucket for better memory sharing\r\n        self.default_bucket_key = max(buckets)\r\n\r\n        for index,image in enumerate(images):\r\n            #print (image)\r\n            image = self.get_image_function(image)\r\n            # if len(image) == 0:\r\n            #     continue\r\n            for i, bkt in enumerate(buckets):\r\n                if bkt >= get_image_ratio(image)*factor:\r\n                    self.data[i].append(image)\r\n                    self.label[i].append(self.labels[index])\r\n                    break\r\n            # we just ignore the image it is longer than the maximum\r\n            # bucket size here\r\n\r\n        # convert data into ndarrays for better speed during training\r\n        # data = [np.zeros((len(x), x[0].shape)) for i, x in enumerate(self.data)]\r\n        # for i_bucket in range(len(self.buckets)):\r\n        #     for j in range(len(self.data[i_bucket])):\r\n        #         image = self.data[i_bucket][j]\r\n        #         data[i_bucket][j, :len(image)] = image\r\n        data=np.asarray(self.data)\r\n        label=np.asarray(self.label)\r\n        self.data = data\r\n        self.label=label\r\n        print (self.label.shape)\r\n        # #check alignment for image and label\r\n        # img=np.transpose(self.data[0][0],(1,2,0))\r\n        # cv2.imwrite(\'show.jpg\',img)\r\n        # print (self.label[0])\r\n        #Get the size of each bucket, so that we could sample\r\n        #uniformly from the bucket\r\n        bucket_sizes = [len(x) for x in self.data]\r\n\r\n        print(""Summary of dataset =================="")\r\n        for bkt, size in zip(buckets, bucket_sizes):\r\n            print(""bucket of len %3d : %d samples"" % (bkt, size))\r\n\r\n        self.batch_size = batch_size\r\n        self.make_data_iter_plan()\r\n\r\n        self.init_states = init_states\r\n        self.init_state_arrays = [mx.nd.zeros(x[1]) for x in init_states]\r\n\r\n        self.provide_data = [(\'data\', (batch_size, 3,base_hight, base_hight*self.default_bucket_key/factor))] + init_states\r\n        self.provide_label = [(\'label\', (self.batch_size,self.max_label_length ))]\r\n\r\n    def make_data_iter_plan(self):\r\n        ""make a random data iteration plan""\r\n        # truncate each bucket into multiple of batch-size\r\n        bucket_n_batches = []\r\n        for i in range(len(self.data)):\r\n            bucket_n_batches.append(len(self.data[i]) / self.batch_size)\r\n            self.data[i] = self.data[i][:int(bucket_n_batches[i]*self.batch_size)]\r\n            self.label[i] = self.label[i][:int(bucket_n_batches[i]*self.batch_size)]\r\n        bucket_plan = np.hstack([np.zeros(n, int)+i for i, n in enumerate(bucket_n_batches)])\r\n        np.random.shuffle(bucket_plan)\r\n\r\n        bucket_idx_all = [np.random.permutation(len(x)) for x in self.data]\r\n\r\n        self.bucket_plan = bucket_plan\r\n        self.bucket_idx_all = bucket_idx_all\r\n        self.bucket_curr_idx = [0 for x in self.data]\r\n\r\n        self.data_buffer = []\r\n        self.label_buffer = []\r\n        for i_bucket in range(len(self.data)):\r\n            if not self.model_parallel:\r\n                data = np.zeros((self.batch_size, 3,base_hight, base_hight*self.buckets[i_bucket]/factor))\r\n                label = np.zeros((self.batch_size,self.max_label_length))\r\n                self.data_buffer.append(data)\r\n                self.label_buffer.append(label)\r\n            else:\r\n                data = np.zeros((3,base_hight, base_hight*self.buckets[i_bucket], self.batch_size))\r\n                self.data_buffer.append(data)\r\n\r\n        if self.model_parallel:\r\n            # Transpose data if model parallel \r\n            for i in range(len(self.data)):\r\n                bucket_data = self.data[i]\r\n                self.data[i] = np.transpose(bucket_data)\r\n\r\n    def __iter__(self):\r\n\r\n        for i_bucket in self.bucket_plan:\r\n            data = np.array(self.data_buffer[i_bucket])\r\n            i_idx = self.bucket_curr_idx[i_bucket]\r\n            idx = self.bucket_idx_all[i_bucket][i_idx:i_idx+self.batch_size]\r\n            self.bucket_curr_idx[i_bucket] += self.batch_size\r\n            #print (self.label.shape) \r\n            # Model parallelism \r\n            if self.model_parallel:\r\n                if self.data[i_bucket][:, idx].shape[1] == 0:\r\n                    print ""WARNING: detected shape "" + str(self.data[i_bucket][:, idx].shape)\r\n                    continue\r\n                data[:] = self.data[i_bucket][:, idx]\r\n                data_batch = ModelParallelBatch(data, self.buckets[i_bucket])\r\n                yield data_batch\r\n            \r\n            # Data parallelism\r\n            else:\r\n                init_state_names = [x[0] for x in self.init_states]\r\n                data[:] = np.array(self.data[i_bucket])[idx]\r\n                #print (data)\r\n                for image in data:\r\n                    ratio=image.shape[2]/image.shape[1]\r\n                    assert factor*ratio == self.buckets[i_bucket]\r\n                \r\n                label = self.label_buffer[i_bucket]\r\n                #print(label.shape)\r\n                label_pad = pad2max_length(self.label[i_bucket],self.max_label_length)\r\n                label[:] = np.array(label_pad)[idx]\r\n                #label = pad2max_length(label,self.max_label_length)\r\n\r\n                data_all = [mx.nd.array(data)] + self.init_state_arrays\r\n                label_all = [mx.nd.array(label)]\r\n                data_names = [\'data\'] + init_state_names\r\n                label_names = [\'label\']\r\n\r\n                data_batch = SimpleBatch(data_names, data_all, label_names, label_all,\r\n                                         self.buckets[i_bucket])\r\n                print (data_batch.data[0])\r\n                yield data_batch\r\n']",['git rev-parse HEAD'],1,0
49,incubator-mxnet,2147,closed,High training accuracy but low validation accuracy?,"I'm fine-tuning a model (based on Inception-BN) by using a image dataset with 10 classes (my case is a multi-class problem). I randomly split the whole dataset into training and test subsets. During the training phase, I observe that the training accuracy is very high (i.e., > 90%), while the validation accuracy is rather low (i.e., ~20%).

I also tried to use the model to predict tens of test images. It seems the prediction scores of the 10 classes are roughly the same for each test image, i.e., all the test images were predicted to be of the same class.

I've double checked the  files I generated. They are good. And also, for fine-tuning, I simply copied the Inception-BN symbol file into a new one and modified the last fully connected layer to have its  and its name renamed. Things look pretty good to me.. (what I did is very similar to fine-tuning in , i.e., only need to rename the fully connected layer and reset its  in ).

Did anyone encounter the same problem before? Thanks.
",,['The stated issue is due to the pre-trained Inception-BN model. Please see #2155 for the solution.\n'],[],"['.rec', 'num_hidden=10', 'Caffe', 'num_output', 'train_val.prototxt']",1,0
50,incubator-mxnet,14821,open, Always getting stuck for many hours when run `python lstm_ocr_train.py` under dir `example/ctc`,"Hello, I get a problem. 
When I run  under dir , it always gets stuck for many hours. 

Linux distro and version:
LSB Version:	:core-4.1-amd64:core-4.1-noarch
Distributor ID:	CentOS
Description:	CentOS Linux release 7.2.1511 (Core)
Release:	7.2.1511
Codename:	Core

Other envirs:
GPU type: Tesla V100/P100
nvidia driver version: NVIDIA-SMI 410.48/384.81
CUDA version: 9.2/9.0
CUDNN version: 7.5.0/7.3.1
mxnet(using pip): mxnet-cu92/mxnet-cu90

Anyone can give some advises?",Performance,"['@IvyGongoogle Hi, Thanks for reporting this issue. Do you have any error logs to share?\r\n@roywei Do you know anyone can solve this?', '@lanking520  Thanks for your reply. No any logs.']",[],"['python lstm_ocr_train.py --gpu 1 --num_proc 4 --loss ctc font/Ubuntu-M.ttf', 'example/ctc']",1,0
51,incubator-mxnet,2277,closed,Running on multi-gpu is slower than single gpu,"I find for some tasks, using multi-gpu will be slower than single GPU. What may be the main reason for this?

For example. I try to use mxnet to solve image caption problem. I find two strange results:
1. using large batch size (100) will be much slower than small batch size (4)
2. using 4 GPU will be much slower than use 1 GPU.

I other tasks, I does not find similar phenomenon.
",,"['It depends on computation to parameter ratio. Basically conv layers are good for multi gpu, fully connected layers are bad\n', 'Is this because reduce speed is slow when parameter is too large?\n', 'you should find the bottleneck of your task. for example, I find that the alexnet is not suitable for multi gpu but inception is suitable\n', 'maybe network is a bottleneck.Also some times the computer is not stable,one or more gpus work slow in a while time and use synchronize way to update parameter. (I/O rate and  unstable power supply) \n', 'Yes, I do nvprof and find most time are cost on reduce. Increase batch size will reduce this time.\n']",[],[],1,0
52,incubator-mxnet,1767,closed,Performance issue in libmxnet_predict.so,"Hi all,

I tried to predict by using libmxnet_predict.so and libmxnet.so and I find libmxnet_predict.so is much slower than libmxnet.so.
I use inception-bn with  224*224 input image, I am run in CPU 0 and both share same predict.py script.
by using libmxnet.so. predict a image cost
    time elapsed: 0.445577.
by using  libmxnet_predict.so  predict a image cost
    time elapsed: 2.475879.
6 times slower than libmxnet.so I can't figure out what is wrong with libmxnet_predict.so , anybody have ideas ?

thank you in advance!
Haria
",,[],[],[],1,0
53,incubator-mxnet,6888,closed,distributed mxnet is too slow when parameter size are increased,"As input are sparse feature, the total parameters are 1.3G , the speed of distributed trainning are too slow.So mxnet can't support large parameters?
 ",,"[""MXNet don't support sparse update now. Sparse tensor is in developing https://github.com/dmlc/mxnet/issues/5498"", 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!']",[],[],1,0
54,incubator-mxnet,8681,closed,training on P100 gets slower and slower,"i am training on a machine with P100. At the begining, the training speed is about 400images/secod. It decreases gradually to about 130 images/second at the 100 epoch. Some others user pytorch on the same machine did not meet this this problem. Anyone knows the possibile reasons? ",,"['Can you be more specific? Could you provide your system info using tools/diagnose.py and post it here.\r\nAlso, what code are you using?', 'This issue seems abandoned. @eric-haibin-lin can you please help close this ?', 'Closing due to inactivity']",[],[],1,0
55,incubator-mxnet,1516,closed,Why is Adam much slower than sgd?,"I tried to use Adam to replace sgd. I did nothing but replaced the optimiser, then I found the speed dropped too much, which was confusing. Using sgd, I got 0.6 sample per sec (I use a large input for fcn). Then using Adam, I got 0.4 sample per sec. I dont know if this makes sense, since the complexity of Adam seems not that high that caused so much difference in speed. Any idea?
",,"['And also, Adam takes 2g memory more than ccsgd. In my case, ccsgd only takes 2.5g, but Adam takes 4.5, sometimes, near 5g. Is there any way that this can be optimised? Or is it supposed to be like this?\n', ""ccsgd saves memory because it's implemented in C++ and doesn't allocate any temp memory. You can implement adam in cpp to get similar performance.\n"", 'The Stanford CS class CS231n: Convolutional Neural Networks for Visual Recognition compared various optimization algorithms and concluded that ""[in practice Adam is currently recommended as the default algorithm to use, and often works slightly better than RMSProp](http://cs231n.github.io/neural-networks-3/#update)"". It\'s definitely worthy to implement Adam in C++.\n', 'AdamUpdate is now available in cpp. Closing it for now. ', ""Could you help me, and give me some examples of Adam's implementation in C++? I'm looking for that in MLPACK, but it's really don't clear."", 'in https://github.com/apache/incubator-mxnet/blob/master/src/operator/optimizer_op-inl.h#L841', 'Internally, adams need two more variables for each weight. Therefore, more operations are required than Gradient descent and the learning time by sample is increased.']",[],[],1,0
56,incubator-mxnet,6892,closed,Stop metric made increasing memory usage,"## Environment info
Ubuntu 16.04, GCC-5.4.0, MXNet 0.9.5, Python 2.7

## Error Message
I'd like to train a model without a metric, so I use the code just as follows. But I find that the memory usage keeps increasing until it's full. 

Then I define a class named 'NoMetric' as follows and use it as the metric.

But the memory still keeps increasing, so I try this:

Luckily, the memory usage doesn't increase anymore. But I want to know why I must call asnumpy()?


## Latest

I find that whether I use  or not, the memory keeps increasing. Similarly, if I use multi-process to read data in a queue for acceleration, this problem will also appear.

The latest version of MXNet doesn't fix my bug.
",,"['I found that it is extremely fast when training RCNN with metric disabled.', 'I’ve run [train_cifar10.py](https://github.com/dmlc/mxnet/blob/master/example/image-classification/train_cifar10.py) with ```eval_metrics = mx.metric.CompositeEvalMetric()``` however the memory is normal on my machine  you can try a new version of MXNet?', ""@CNevd I've updated the error message. \r\nI really find that the memory is normal if I don't use PrefetchIter. But I still need to accelerate the training procedure such as I/O. I will have a try for the new version of MXNet."", ""@CNevd I've tried the latest version of MXNet, but nothing changed. \r\nI'm sorry to say that I made a mistake yesterday. And now I find there's no difference whether I use PrefetchIter or not. The memory usage will keep increasing if I disable metric."", 'Could you post your code  to reproduce it?', '@CNevd I have found the reason. If using metric, it will wait for the data processed by GPU and then start a new iteration. But if not using metric, it will keep loading data whether GPU finishes processing data or not. So the previous data would not be freed.\r\nThank you very much, I will close the issue.', ""Hello, @GodBlessZhk @CNevd . other than the solution above, has this issue been addressed in a more principled way?What if we don't want to call metric after every iteration?""]","['\r\neval_metrics = mx.metric.CompositeEvalMetric()\r\ntrain_data = mx.io.PrefetchingIter(train_data)\r\nmod.fit(train_data, eval_metric=eval_metrics, ...)\r\n', ""\r\nclass NoMetric(mx.metric.EvalMetric):\r\n    def __init__(self):\r\n        super(NoMetric, self).__init__('NoMetric')\r\n\r\n    def update(self, labels, preds):\r\n        self.sum_metric += 1\r\n        self.num_inst += 1\r\n"", ""\r\nclass NoMetric(mx.metric.EvalMetric):\r\n    def __init__(self):\r\n        super(NoMetric, self).__init__('NoMetric')\r\n        self.e2e = config.TRAIN.END2END\r\n        self.rcnn_ohem = config.TRAIN.RCNN_OHEM\r\n        self.pred, self.label = get_rcnn_names()\r\n\r\n    def update(self, labels, preds):  \t\r\n    \tbbox_loss = preds[self.pred.index('rcnn_bbox_loss')].asnumpy()\r\n        if self.e2e:\r\n            label = preds[self.pred.index('rcnn_label')].asnumpy()\r\n        else:\r\n            label = labels[self.label.index('rcnn_label')].asnumpy()\r\n        \r\n        self.sum_metric += 1\r\n        self.num_inst += 1\r\n""]",['train_data = mx.io.PrefetchingIter(train_data)'],1,0
57,incubator-mxnet,10095,open,BatchNorm on axis=-1 is very slower than axis=1,"As profiler shows, the ""nn.BatchNorm(axis=-1)"" will cause 10x lower speed on my application than ""nn.BatchNorm(axis=1)"".
However, We often need a ""nn.BatchNorm(axis=-1)"" after ""nn.Dense(flatten=False)"".",Operator Performance,"[""What's the dimension of the data fed into BatchNorm? If the input is 4D, `axis=-1` will normalize the last dimension, which is different from `axis=1`."", 'Yes, it\'s 4D and sometimes 3D.\r\nI wonder that why it\'s different, ""NHWC"" and ""NCHW"" will be treated diffrently?', 'Yes, CUDNN has very different performance characteristics on these two formats. \n\nOn 2018年5月13日, at 17:41, chinakook <notifications@github.com> wrote:\n\nYes, it\'s 4D and sometimes 3D.\nI wonder that why it\'s different, ""NHWC"" and ""NCHW"" will be treated diffrently?\n\n—\nYou are receiving this because you were assigned.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n', ""I got it. \r\nAs I've tested, Tensorflow's batchnorm on the last axis is OK. It may not use cudnn."", 'Yeah TF doesn’t use CUDNN. We’re waiting for CUDNN 7.2 which has lots of improvements on NHWC']",[],[],1,0
58,incubator-mxnet,1138,closed,Validation-accuracy on imagenet with inception-bn starts to drop after 5 epochs,"Train-accuracy continues to increase but not for the Validation-accuracy. This is what I have observed from the log. Is this normal or did I miss something?  

I am using the following settings

python example/image-classification/train_imagenet.py --network inception-bn \
--data-dir /media/SSD/imagenet_mxnet/ --batch-size 128 --num-examples 1281167 \
--model-prefix imagenet --kv-store local_allreduce_device --lr-factor 0.9

2016-01-01 21:43:39,380 Node[0] Update[48956]: Change learning rate to 5.90490e-03
2016-01-01 21:43:49,904 Node[0] Epoch[4] Train-accuracy=0.548824
2016-01-01 21:43:49,904 Node[0] Epoch[4] Time cost=20670.702
2016-01-01 21:46:44,073 Node[0] Epoch[4] Validation-accuracy=0.406630

2016-01-02 03:30:58,979 Node[0] Update[58747]: Change learning rate to 5.31441e-03
2016-01-02 03:31:11,608 Node[0] Epoch[5] Train-accuracy=0.577686
2016-01-02 03:31:11,608 Node[0] Epoch[5] Time cost=20667.375
2016-01-02 03:34:05,323 Node[0] Epoch[5] Validation-accuracy=0.404347

2016-01-02 09:18:14,071 Node[0] Update[68538]: Change learning rate to 4.78297e-03
2016-01-02 09:18:28,803 Node[0] Epoch[6] Train-accuracy=0.600828
2016-01-02 09:18:28,803 Node[0] Epoch[6] Time cost=20663.319
2016-01-02 09:21:23,119 Node[0] Epoch[6] Validation-accuracy=0.380495

Thanks for the great tool you guys have developed
",,"[""The concept of validation accuracy dropping is related to overfitting, which deep nets are exceptionally good at, so I'd be inclined to say this is normal. many people employ early-stopping to prevent this from happening. However, I've also been told that the validation accuracy rarely goes down on imagenet.\n"", 'hi fengjun can you give more info about it?\nand are you using the lastest code of mxnet?\n', ""Hi qiaohaijun,\n\nThanks for looking into this.\n\nThe version I am using is 0927a28d52b720d545b0b05f5658afdc458c9d56 - Mu Li, Thu Dec 31 00:36:02 2015.  I am doing Imagenet training with inception-bn model, using the following settings:\n\npython example/image-classification/train_imagenet.py --network inception-bn \\\n--data-dir /media/SSD/imagenet_mxnet/ --batch-size 128 --num-examples 1281167 \\\n--model-prefix imagenet --kv-store local_allreduce_device --lr-factor 0.9\n\nThe  training accuracy looks normal. It continues to increase to about 0.619 after 7 epochs, but the Validation-accuracy starts to drop after 5 epochs and the trend continues like this:\n2016-01-01 21:46:44,073 Node[0] Epoch[4] Validation-accuracy=0.406630\n2016-01-02 03:34:05,323 Node[0] Epoch[5] Validation-accuracy=0.404347\n2016-01-02 09:21:23,119 Node[0] Epoch[6] Validation-accuracy=0.380495\n2016-01-02 15:09:03,101 Node[0] Epoch[7] Validation-accuracy=0.361358\n\nThis is something unexpected, isn't it?\n"", 'This may be the bug in updater. Please check recent PRs: https://github.com/dmlc/mxnet/pull/1134/files and https://github.com/dmlc/mxnet/pull/1113/files\n', 'Update in https://github.com/dmlc/mxnet/pull/1142\n', 'Hi guys,\n\nThanks for your answers and effort.  I will re-run the training with the latest code.\n', 'I train inception-bn again, and the problem has fixed\n', 'Yeah, it is confirmed everything looks normal this time.  Thank you guys for the great job. Really appreciate it.\n']",[],[],1,1
59,incubator-mxnet,11763,closed,"When Train SSD, It hold on during read the data","
## Description
I run the  with  my own voc dataset. I handle on during the data read like fllow:

![image](https://user-images.githubusercontent.com/3112825/42734787-4d3dd150-887c-11e8-8b9a-0bf9409406f5.png)

![image](https://user-images.githubusercontent.com/3112825/42734807-7c3bbbb6-887c-11e8-9179-abeb78933e8c.png)



## Environment info (Required)



## Steps to reproduce
I write my own VOCDetection, here is the code:

foohttp://gluon-cv.mxnet.io/build/examples_datasets/index.html./transforms
and I replace the VOCDetection in .

## What have you tried to solve it?

1. I have add some display info to check my VOCDetection, It should be ok to produce the batch images and merge labels(bbox\cls label\...).
2. I add display info in  ， and it seem the  is a empty dict and when run the ， It will be hold on and never restore to run.
![image](https://user-images.githubusercontent.com/3112825/42734875-a82954da-887d-11e8-8004-e46abac52a11.png)

",Gluon,"['@burness where is the train_ssd.py coming from? could you provide a complete code to test with? What do you mean by your own VOCDetection dataset, did you modify the dataset for your use-case? \r\n\r\n@vishaalkapoor could you please review this?', 'Yes, I make my own data to be VOC format, and here is my train_ssd.py\r\n\r\n```\r\n""""""Train SSD""""""\r\nimport argparse\r\nimport os\r\nimport logging\r\nimport time\r\nimport numpy as np\r\nimport mxnet as mx\r\nfrom mxnet import nd\r\nfrom mxnet import gluon\r\nfrom mxnet import autograd\r\nimport gluoncv as gcv\r\nfrom gluoncv import data as gdata\r\nfrom gluoncv import utils as gutils\r\nfrom gluoncv.model_zoo import get_model\r\nfrom gluoncv.data.batchify import Tuple, Stack, Pad\r\nfrom gluoncv.data.transforms.presets.ssd import SSDDefaultTrainTransform\r\nfrom gluoncv.data.transforms.presets.ssd import SSDDefaultValTransform\r\nfrom gluoncv.utils.metrics.voc_detection import VOC07MApMetric\r\nfrom gluoncv.utils.metrics.coco_detection import COCODetectionMetric\r\nfrom gluoncv.utils.metrics.accuracy import Accuracy\r\nfrom own_voc_detection import VOCDetection\r\n\r\ndef parse_args():\r\n    parser = argparse.ArgumentParser(description=\'Train SSD networks.\')\r\n    parser.add_argument(\'--network\', type=str, default=\'vgg16_atrous\',\r\n                        help=""Base network name which serves as feature extraction base."")\r\n    parser.add_argument(\'--data-shape\', type=int, default=300,\r\n                        help=""Input data shape, use 300, 512."")\r\n    parser.add_argument(\'--batch-size\', type=int, default=32,\r\n                        help=\'Training mini-batch size\')\r\n    parser.add_argument(\'--dataset\', type=str, default=\'voc\',\r\n                        help=\'Training dataset. Now support voc.\')\r\n    parser.add_argument(\'--num-workers\', \'-j\', dest=\'num_workers\', type=int,\r\n                        default=4, help=\'Number of data workers, you can use larger \'\r\n                        \'number to accelerate data loading, if you CPU and GPUs are powerful.\')\r\n    parser.add_argument(\'--gpus\', type=str, default=\'0\',\r\n                        help=\'Training with GPUs, you can specify 1,3 for example.\')\r\n    parser.add_argument(\'--epochs\', type=int, default=240,\r\n                        help=\'Training epochs.\')\r\n    parser.add_argument(\'--resume\', type=str, default=\'\',\r\n                        help=\'Resume from previously saved parameters if not None. \'\r\n                        \'For example, you can resume from ./ssd_xxx_0123.params\')\r\n    parser.add_argument(\'--start-epoch\', type=int, default=0,\r\n                        help=\'Starting epoch for resuming, default is 0 for new training.\'\r\n                        \'You can specify it to 100 for example to start from 100 epoch.\')\r\n    parser.add_argument(\'--lr\', type=float, default=0.001,\r\n                        help=\'Learning rate, default is 0.001\')\r\n    parser.add_argument(\'--lr-decay\', type=float, default=0.1,\r\n                        help=\'decay rate of learning rate. default is 0.1.\')\r\n    parser.add_argument(\'--lr-decay-epoch\', type=str, default=\'160,200\',\r\n                        help=\'epoches at which learning rate decays. default is 160,200.\')\r\n    parser.add_argument(\'--momentum\', type=float, default=0.9,\r\n                        help=\'SGD momentum, default is 0.9\')\r\n    parser.add_argument(\'--wd\', type=float, default=0.0005,\r\n                        help=\'Weight decay, default is 5e-4\')\r\n    parser.add_argument(\'--log-interval\', type=int, default=100,\r\n                        help=\'Logging mini-batch interval. Default is 100.\')\r\n    parser.add_argument(\'--save-prefix\', type=str, default=\'\',\r\n                        help=\'Saving parameter prefix\')\r\n    parser.add_argument(\'--save-interval\', type=int, default=10,\r\n                        help=\'Saving parameters epoch interval, best model will always be saved.\')\r\n    parser.add_argument(\'--val-interval\', type=int, default=1,\r\n                        help=\'Epoch interval for validation, increase the number will reduce the \'\r\n                             \'training time if validation is slow.\')\r\n    parser.add_argument(\'--seed\', type=int, default=233,\r\n                        help=\'Random seed to be fixed.\')\r\n    args = parser.parse_args()\r\n    return args\r\n\r\ndef get_dataset(dataset, args):\r\n    if dataset.lower() == \'voc\':\r\n        train_dataset = VOCDetection(\r\n            splits=[(2007, \'trainval\')])\r\n        val_dataset = gdata.VOCDetection(\r\n            splits=[(2007, \'test\')])\r\n        val_metric = VOC07MApMetric(iou_thresh=0.5, class_names=val_dataset.classes)\r\n    elif dataset.lower() == \'coco\':\r\n        train_dataset = gdata.COCODetection(splits=\'instances_train2017\')\r\n        val_dataset = gdata.COCODetection(splits=\'instances_val2017\', skip_empty=False)\r\n        val_metric = COCODetectionMetric(\r\n            val_dataset, args.save_prefix + \'_eval\', cleanup=True,\r\n            data_shape=(args.data_shape, args.data_shape))\r\n        # coco validation is slow, consider increase the validation interval\r\n        if args.val_interval == 1:\r\n            args.val_interval = 10\r\n    else:\r\n        raise NotImplementedError(\'Dataset: {} not implemented.\'.format(dataset))\r\n    return train_dataset, val_dataset, val_metric\r\n\r\ndef get_dataloader(net, train_dataset, val_dataset, data_shape, batch_size, num_workers):\r\n    """"""Get dataloader.""""""\r\n    width, height = data_shape, data_shape\r\n    # use fake data to generate fixed anchors for target generation\r\n    with autograd.train_mode():\r\n        _, _, anchors = net(mx.nd.zeros((1, 3, height, width)))\r\n    batchify_fn = Tuple(Stack(), Stack(), Stack())  # stack image, cls_targets, box_targets\r\n    train_loader = gluon.data.DataLoader(\r\n        train_dataset.transform(SSDDefaultTrainTransform(width, height, anchors)),\r\n        batch_size, True, batchify_fn=batchify_fn, last_batch=\'rollover\', num_workers=num_workers)\r\n    val_batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\r\n    val_loader = gluon.data.DataLoader(\r\n        val_dataset.transform(SSDDefaultValTransform(width, height)),\r\n        batch_size, False, batchify_fn=val_batchify_fn, last_batch=\'keep\', num_workers=num_workers)\r\n    return train_loader, val_loader\r\n\r\ndef save_params(net, best_map, current_map, epoch, save_interval, prefix):\r\n    current_map = float(current_map)\r\n    if current_map > best_map[0]:\r\n        best_map[0] = current_map\r\n        net.save_params(\'{:s}_best.params\'.format(prefix, epoch, current_map))\r\n        with open(prefix+\'_best_map.log\', \'a\') as f:\r\n            f.write(\'\\n{:04d}:\\t{:.4f}\'.format(epoch, current_map))\r\n    if save_interval and epoch % save_interval == 0:\r\n        net.save_params(\'{:s}_{:04d}_{:.4f}.params\'.format(prefix, epoch, current_map))\r\n\r\ndef validate(net, val_data, ctx, eval_metric):\r\n    """"""Test on validation dataset.""""""\r\n    eval_metric.reset()\r\n    # set nms threshold and topk constraint\r\n    net.set_nms(nms_thresh=0.45, nms_topk=400)\r\n    net.hybridize()\r\n    for batch in val_data:\r\n        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\r\n        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\r\n        det_bboxes = []\r\n        det_ids = []\r\n        det_scores = []\r\n        gt_bboxes = []\r\n        gt_ids = []\r\n        gt_difficults = []\r\n        for x, y in zip(data, label):\r\n            # get prediction results\r\n            ids, scores, bboxes = net(x)\r\n            det_ids.append(ids)\r\n            det_scores.append(scores)\r\n            # clip to image size\r\n            det_bboxes.append(bboxes.clip(0, batch[0].shape[2]))\r\n            # split ground truths\r\n            gt_ids.append(y.slice_axis(axis=-1, begin=4, end=5))\r\n            gt_bboxes.append(y.slice_axis(axis=-1, begin=0, end=4))\r\n            gt_difficults.append(y.slice_axis(axis=-1, begin=5, end=6) if y.shape[-1] > 5 else None)\r\n\r\n        # update metric\r\n        eval_metric.update(det_bboxes, det_ids, det_scores, gt_bboxes, gt_ids, gt_difficults)\r\n    return eval_metric.get()\r\n\r\ndef train(net, train_data, val_data, eval_metric, args):\r\n    """"""Training pipeline""""""\r\n    net.collect_params().reset_ctx(ctx)\r\n    trainer = gluon.Trainer(\r\n        net.collect_params(), \'sgd\',\r\n        {\'learning_rate\': args.lr, \'wd\': args.wd, \'momentum\': args.momentum})\r\n\r\n    # lr decay policy\r\n    lr_decay = float(args.lr_decay)\r\n    lr_steps = sorted([float(ls) for ls in args.lr_decay_epoch.split(\',\') if ls.strip()])\r\n\r\n    mbox_loss = gcv.loss.SSDMultiBoxLoss()\r\n    ce_metric = mx.metric.Loss(\'CrossEntropy\')\r\n    smoothl1_metric = mx.metric.Loss(\'SmoothL1\')\r\n\r\n    # set up logger\r\n    logging.basicConfig()\r\n    logger = logging.getLogger()\r\n    logger.setLevel(logging.INFO)\r\n    log_file_path = args.save_prefix + \'_train.log\'\r\n    log_dir = os.path.dirname(log_file_path)\r\n    if log_dir and not os.path.exists(log_dir):\r\n        os.makedirs(log_dir)\r\n    fh = logging.FileHandler(log_file_path)\r\n    logger.addHandler(fh)\r\n    logger.info(args)\r\n    logger.info(\'Start training from [Epoch {}]\'.format(args.start_epoch))\r\n    best_map = [0]\r\n    for epoch in range(args.start_epoch, args.epochs):\r\n        while lr_steps and epoch >= lr_steps[0]:\r\n            new_lr = trainer.learning_rate * lr_decay\r\n            lr_steps.pop(0)\r\n            trainer.set_learning_rate(new_lr)\r\n            logger.info(""[Epoch {}] Set learning rate to {}"".format(epoch, new_lr))\r\n        ce_metric.reset()\r\n        smoothl1_metric.reset()\r\n        tic = time.time()\r\n        btic = time.time()\r\n        net.hybridize()\r\n        for i, batch in enumerate(train_data):\r\n            batch_size = batch[0].shape[0]\r\n            data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\r\n            cls_targets = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\r\n            box_targets = gluon.utils.split_and_load(batch[2], ctx_list=ctx, batch_axis=0)\r\n            with autograd.record():\r\n                cls_preds = []\r\n                box_preds = []\r\n                for x in data:\r\n                    cls_pred, box_pred, _ = net(x)\r\n                    cls_preds.append(cls_pred)\r\n                    box_preds.append(box_pred)\r\n                sum_loss, cls_loss, box_loss = mbox_loss(\r\n                    cls_preds, box_preds, cls_targets, box_targets)\r\n                autograd.backward(sum_loss)\r\n            # since we have already normalized the loss, we don\'t want to normalize\r\n            # by batch-size anymore\r\n            trainer.step(1)\r\n            ce_metric.update(0, [l * batch_size for l in cls_loss])\r\n            smoothl1_metric.update(0, [l * batch_size for l in box_loss])\r\n            if args.log_interval and not (i + 1) % args.log_interval:\r\n                name1, loss1 = ce_metric.get()\r\n                name2, loss2 = smoothl1_metric.get()\r\n                logger.info(\'[Epoch {}][Batch {}], Speed: {:.3f} samples/sec, {}={:.3f}, {}={:.3f}\'.format(\r\n                    epoch, i, batch_size/(time.time()-btic), name1, loss1, name2, loss2))\r\n            btic = time.time()\r\n\r\n        name1, loss1 = ce_metric.get()\r\n        name2, loss2 = smoothl1_metric.get()\r\n        logger.info(\'[Epoch {}] Training cost: {:.3f}, {}={:.3f}, {}={:.3f}\'.format(\r\n            epoch, (time.time()-tic), name1, loss1, name2, loss2))\r\n        if not (epoch + 1) % args.val_interval:\r\n            # consider reduce the frequency of validation to save time\r\n            map_name, mean_ap = validate(net, val_data, ctx, eval_metric)\r\n            val_msg = \'\\n\'.join([\'{}={}\'.format(k, v) for k, v in zip(map_name, mean_ap)])\r\n            logger.info(\'[Epoch {}] Validation: \\n{}\'.format(epoch, val_msg))\r\n            current_map = float(mean_ap[-1])\r\n        else:\r\n            current_map = 0.\r\n        save_params(net, best_map, current_map, epoch, args.save_interval, args.save_prefix)\r\n\r\nif __name__ == \'__main__\':\r\n    args = parse_args()\r\n    # fix seed for mxnet, numpy and python builtin random generator.\r\n    gutils.random.seed(args.seed)\r\n\r\n    # training contexts\r\n    ctx = [mx.gpu(int(i)) for i in args.gpus.split(\',\') if i.strip()]\r\n    ctx = ctx if ctx else [mx.cpu()]\r\n\r\n    # network\r\n    net_name = \'_\'.join((\'ssd\', str(args.data_shape), args.network, args.dataset))\r\n    args.save_prefix += net_name\r\n    net = get_model(net_name, pretrained_base=True)\r\n    if args.resume.strip():\r\n        net.load_params(args.resume.strip())\r\n    else:\r\n        for param in net.collect_params().values():\r\n            if param._data is not None:\r\n                continue\r\n            param.initialize()\r\n\r\n    # training data\r\n    train_dataset, val_dataset, eval_metric = get_dataset(args.dataset, args)\r\n    train_data, val_data = get_dataloader(\r\n        net, train_dataset, val_dataset, args.data_shape, args.batch_size, args.num_workers)\r\n\r\n    # training\r\n    train(net, train_data, val_data, eval_metric, args)\r\n\r\n```', 'Hi Burness,\r\n\r\nApologies for the delay, there was a mixup with my handle and another Vishaal K was tagged :) \r\n\r\nI\'m able to repro the situation you\'re seeing when building by source with the 1.2 branch.\r\n\r\nHere are my instructions for reproducibility:\r\n\r\n1. Set up the Pascal VOC Dataset by running python pascal_voc.py as per these [instructions]( https://gluon-cv.mxnet.io/build/examples_datasets/pascal_voc.html#sphx-glr-build-examples-datasets-pascal-voc-py).\r\n2. Copied the source code you provided above into train_ssd.py and own_voc_detection.py\r\n3. Run python train_ssd.py --gpus 0 --network resnet50_v1 --data-shape 512 --num-worker 8\r\n\r\nObserved apparent hanging after failure to read an image file. When I Ctrl-C I see the same stack trace:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File ""train_ssd.py"", line 253, in <module>\r\n    train(net, train_data, val_data, eval_metric, args)\r\n  File ""train_ssd.py"", line 185, in train\r\n    for i, batch in enumerate(train_data):\r\n  File ""/work/mxnet/python/mxnet/gluon/data/dataloader.py"", line 222, in next\r\n    return self.__next__()\r\n  File ""/work/mxnet/python/mxnet/gluon/data/dataloader.py"", line 218, in __next__\r\n    idx, batch = self._data_queue.get()\r\n  File ""/usr/lib/python2.7/multiprocessing/queues.py"", line 117, in get\r\n    res = self._recv()\r\n  File ""/work/mxnet/python/mxnet/gluon/data/dataloader.py"", line 87, in recv\r\n    buf = self.recv_bytes()\r\n```\r\n\r\nI\'ll have to step through the code to further understand things better, I\'ll update today. Thanks for your patience.\r\n\r\nVishaal', ""Hi @burness,\r\n\r\nI noticed you converted the jpg files in the VOC dataset to png files as the line below is modified from .jpg to .png \r\n\r\n        self._image_path = os.path.join('{}', 'JPEGImages', '{}.png')\r\n\r\nI'm unable to repro the exact situation without knowing the dimensions of the png file (what convert command did you use to convert the jpg to png).\r\n\r\nNote: Previously, I was seeing the run hang because of a different issue - that is, the jpg files weren't found because the wrong extension was used. This was causing an extension in __get_item__ and after all the threads stopped, the program would be hanging.\r\n\r\nThanks!\r\nVishaal"", 'Hi, @vishaalkapoor  Thanks for your help, I have not convert the jpeg data to png, I just use my own train data to be the voc format to reuse your api, I have test the data read and it maybe not the issue. As you see in pic 1, I have print the image shape and content, I have check the code, and I think it maybe the queue and multithread to cause the hang ', '@vishaalkapoor  And the train data is acquired by LabelImg', 'Hi @burness,\r\nAre you able to repro the issue with a minimal example and post a list of instructions that I could follow including pointers to files to download? Perhaps an example involving one or two images? It will be difficult for me to repro otherwise. Many thanks!\r\nVishaal', 'Hi @burness ,\r\nCould you try to decrease ""--num-workers"" and try the experiments again?', '@vishaalkapoor, I am sorry that recently I have no time to do it! I will do as quicky as possible.\r\n@xcgoner Thanks, I will do that  with no multi workers  but It will be not efficient', '@burness Understood. My concern is that sometimes using multiple worker threads in the dataloader may exhaust the cpu resources and make the training stuck. You can try to set this option to be 1 or even 0 (0 will trigger a single-thread dataloader in a different mode) and check whether it is still stuck or not. So that we can identify what is exactly the problem there.\r\nBy the way, I noticed that in your snapshot, there is a typo. It should be ""num-workers"" instead of ""num-worker""', 'I meet same question, any update? thanks.', ""@tuoyuxiang would you mind giving exact repo steps. I was having difficulty\nreproducing burness's experiment. What code are your running, or better\nyet, what is a minimal snippet if the code, and what is a pointer to the\ndata set with steps on any transformations on that set.\n\nThank you!\n\nOn Mon, Jul 30, 2018, 1:02 AM tuoyuxiang <notifications@github.com> wrote:\n\n> I meet same question, any update? thanks.\n>\n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/apache/incubator-mxnet/issues/11763#issuecomment-408780460>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/Am8fCxmmWX4V4yQwnfDdjVkHFlEy6IHOks5uLr2qgaJpZM4VQQ6G>\n> .\n>\n"", '@tuoyuxiang maybe you could po the reproduce code, Now I have no time to reproduce it. Thanks! Or I will do it maybe  two or three week later.', 'See https://github.com/apache/incubator-mxnet/issues/11872\r\n\r\nYou shared memory is full then the program is stuck waiting more data to train.', ""@burness I am closing this issue as it's related to a more general issue rather than SSD training specifically. If you cannot fix the problem following #11872, feel free to ping me."", ""Thanks for your help, I will try to fix this issue    later\n\n发自我的 iPhone\n\n> 在 2018年8月3日，上午6:49，Joshua Z. Zhang <notifications@github.com> 写道：\n> \n> @burness I am closing this issue as it's related to a more general issue rather than SSD training specifically. If you cannot fix the problem following #11872, feel free to ping me.\n> \n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n""]","[""\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                12\r\nOn-line CPU(s) list:   0-11\r\nThread(s) per core:    1\r\nCore(s) per socket:    1\r\nSocket(s):             12\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz\r\nStepping:              1\r\nCPU MHz:               2399.954\r\nBogoMIPS:              4799.90\r\nHypervisor vendor:     KVM\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              4096K\r\nNUMA node0 CPU(s):     0-11\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat\r\n----------Python Info----------\r\n('Version      :', '2.7.12')\r\n('Compiler     :', 'GCC 5.4.0 20160609')\r\n('Build        :', ('default', 'Dec  4 2017 14:50:18'))\r\n('Arch         :', ('64bit', 'ELF'))\r\n------------Pip Info-----------\r\n('Version      :', '10.0.1')\r\n('Directory    :', '/usr/local/lib/python2.7/dist-packages/pip')\r\n----------MXNet Info-----------\r\n('Version      :', '1.2.0')\r\n('Directory    :', '/mxnet/python/mxnet')\r\nHashtag not found. Not installed from pre-built package.\r\n----------System Info----------\r\n('Platform     :', 'Linux-4.4.0-101-generic-x86_64-with-Ubuntu-16.04-xenial')\r\n('system       :', 'Linux')\r\n('node         :', '7ba53a149808')\r\n('release      :', '4.4.0-101-generic')\r\n('version      :', '#124-Ubuntu SMP Fri Nov 10 18:29:59 UTC 2017')\r\n----------Hardware Info----------\r\n('machine      :', 'x86_64')\r\n('processor    :', 'x86_64')\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.2855 sec, LOAD: 3.5680 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.7080 sec, LOAD: 9.9240 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0006 sec, LOAD: 1.9474 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0005 sec, LOAD: 0.7651 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0005 sec, LOAD: 1.3618 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0005 sec, LOAD: 1.0744 sec.\r\n\r\n""]","['train_ssd.py', '', '\r\n""""""Pascal VOC object detection dataset.""""""\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nimport os\r\nimport logging\r\nimport numpy as np\r\ntry:\r\n    import xml.etree.cElementTree as ET\r\nexcept ImportError:\r\n    import xml.etree.ElementTree as ET\r\nimport mxnet as mx\r\n\r\nimport os\r\nfrom mxnet.gluon.data import dataset\r\n\r\nclass ClassProperty(object):\r\n    """"""Readonly @ClassProperty descriptor for internal usage.""""""\r\n    def __init__(self, fget):\r\n        self.fget = fget\r\n\r\n    def __get__(self, owner_self, owner_cls):\r\n        return self.fget(owner_cls)\r\n\r\n\r\nclass VisionDataset(dataset.Dataset):\r\n    """"""Base Dataset with directory checker.\r\n    Parameters\r\n    ----------\r\n    root : str\r\n        The root path of xxx.names, by defaut is \'~/.mxnet/datasets/foo\', where\r\n        ', ' is the name of the dataset.\r\n    """"""\r\n    def __init__(self, root):\r\n        if not os.path.isdir(os.path.expanduser(root)):\r\n            helper_msg = ""{} is not a valid dir. Did you forget to initalize \\\r\n                         datasets described in: \\\r\n                         ', '? \\\r\n                         You need to initialize each dataset only once."".format(root)\r\n            raise OSError(helper_msg)\r\n\r\n    @property\r\n    def classes(self):\r\n        raise NotImplementedError\r\n\r\n    @property\r\n    def num_class(self):\r\n        """"""Number of categories.""""""\r\n        return len(self.classes)\r\n\r\n\r\nclass VOCDetection(VisionDataset):\r\n    """"""Pascal VOC detection Dataset.\r\n    Parameters\r\n    ----------\r\n    root : str, default \'~/mxnet/datasets/voc\'\r\n        Path to folder storing the dataset.\r\n    splits : list of tuples, default ((2007, \'trainval\'), (2012, \'trainval\'))\r\n        List of combinations of (year, name)\r\n        For years, candidates can be: 2007, 2012.\r\n        For names, candidates can be: \'train\', \'val\', \'trainval\', \'test\'.\r\n    transform : callable, defaut None\r\n        A function that takes data and label and transforms them. Refer to\r\n        :doc:', ' for examples.\r\n        A transform function for object detection should take label into consideration,\r\n        because any geometric modification will require label to be modified.\r\n    index_map : dict, default None\r\n        In default, the 20 classes are mapped into indices from 0 to 19. We can\r\n        customize it by providing a str to int dict specifying how to map class\r\n        names to indicies. Use by advanced users only, when you want to swap the orders\r\n        of class labels.\r\n    preload_label : bool, default True\r\n        If True, then parse and load all labels into memory during\r\n        initialization. It often accelerate speed but require more memory\r\n        usage. Typical preloaded labels took tens of MB. You only need to disable it\r\n        when your dataset is extreamly large.\r\n    """"""\r\n    CLASSES = (""shuxiangliefeng"",""xiexiangliefeng"",""jiefengposui"",""liefeng"",""banjiaoboluo"",\r\n                ""xiaobuding"",""hengxiangliefeng"",""shousuoliefeng"",""qipi"",""zongxiangliefeng"",\r\n                ""kengdong"",""qianfengliaosun"",""qipiguilie"",""zhongxiangliefeng"",""jiaochaliefeng"",\r\n                ""banjiaotuoluo"",""jiaoyuduanlie"",""zhongxianghengxiangliefeng"")\r\n    def __init__(self, root=os.path.join(\'~\', \'.mxnet\', \'datasets\', \'voc\'),\r\n                 splits=((2007, \'trainval\'), (2012, \'trainval\')),\r\n                 transform=None, index_map=None, preload_label=True):\r\n        super(VOCDetection, self).__init__(root)\r\n        self._im_shapes = {}\r\n        self._root = os.path.expanduser(root)\r\n        self._transform = transform\r\n        self._splits = splits\r\n        self._items = self._load_items(splits)\r\n        self._anno_path = os.path.join(\'{}\', \'Annotations\', \'{}.xml\')\r\n        self._image_path = os.path.join(\'{}\', \'JPEGImages\', \'{}.png\')\r\n        self.index_map = index_map or dict(zip(self.classes, range(self.num_class)))\r\n        self._label_cache = self._preload_labels() if preload_label else None\r\n\r\n    def __str__(self):\r\n        detail = \',\'.join([str(s[0]) + s[1] for s in self._splits])\r\n        return self.__class__.__name__ + \'(\' + detail + \')\'\r\n\r\n    @property\r\n    def classes(self):\r\n        """"""Category names.""""""\r\n        return type(self).CLASSES\r\n\r\n    def __len__(self):\r\n        return len(self._items)\r\n\r\n    def __getitem__(self, idx):\r\n        img_id = self._items[idx]\r\n        img_path = self._image_path.format(*img_id)\r\n        label = self._label_cache[idx] if self._label_cache else self._load_label(idx)\r\n        print(img_path)\r\n        img = mx.image.imread(img_path, 1)\r\n        if self._transform is not None:\r\n            return self._transform(img, label)\r\n        print(label, img.shape)\r\n        return img, label\r\n\r\n    def _load_items(self, splits):\r\n        """"""Load individual image indices from splits.""""""\r\n        ids = []\r\n        for year, name in splits:\r\n            root = os.path.join(self._root, \'VOC\' + str(year))\r\n            lf = os.path.join(root, \'ImageSets\', \'Main\', name + \'.txt\')\r\n            with open(lf, \'r\') as f:\r\n                ids += [(root, line.strip()) for line in f.readlines()]\r\n        return ids\r\n\r\n    def _load_label(self, idx):\r\n        """"""Parse xml file and return labels.""""""\r\n        img_id = self._items[idx]\r\n        anno_path = self._anno_path.format(*img_id)\r\n        root = ET.parse(anno_path).getroot()\r\n        size = root.find(\'size\')\r\n        width = float(size.find(\'width\').text)\r\n        height = float(size.find(\'height\').text)\r\n        if idx not in self._im_shapes:\r\n            # store the shapes for later usage\r\n            self._im_shapes[idx] = (width, height)\r\n        label = []\r\n        for obj in root.iter(\'object\'):\r\n            difficult = int(obj.find(\'difficult\').text)\r\n            cls_name = obj.find(\'name\').text.strip().lower()\r\n            if cls_name not in self.classes:\r\n                continue\r\n            cls_id = self.index_map[cls_name]\r\n            xml_box = obj.find(\'bndbox\')\r\n            xmin = (float(xml_box.find(\'xmin\').text) - 1)\r\n            ymin = (float(xml_box.find(\'ymin\').text) - 1)\r\n            xmax = (float(xml_box.find(\'xmax\').text) - 1)\r\n            ymax = (float(xml_box.find(\'ymax\').text) - 1)\r\n            try:\r\n                self._validate_label(xmin, ymin, xmax, ymax, width, height)\r\n            except AssertionError as e:\r\n                raise RuntimeError(""Invalid label at {}, {}"".format(anno_path, e))\r\n            label.append([xmin, ymin, xmax, ymax, cls_id, difficult])\r\n        return np.array(label)\r\n\r\n    def _validate_label(self, xmin, ymin, xmax, ymax, width, height):\r\n        """"""Validate labels.""""""\r\n        assert xmin >= 0 and xmin < width, (\r\n            ""xmin must in [0, {}), given {}"".format(width, xmin))\r\n        assert ymin >= 0 and ymin < height, (\r\n            ""ymin must in [0, {}), given {}"".format(height, ymin))\r\n        assert xmax > xmin and xmax <= width, (\r\n            ""xmax must in (xmin, {}], given {}"".format(width, xmax))\r\n        assert ymax > ymin and ymax <= height, (\r\n            ""ymax must in (ymin, {}], given {}"".format(height, ymax))\r\n\r\n    def _preload_labels(self):\r\n        """"""Preload all labels into memory.""""""\r\n        logging.debug(""Preloading %s labels into memory..."", str(self))\r\n        return [self._load_label(idx) for idx in range(len(self))]\r\n\r\n', '', 'train_ssd.py', 'dataloader.py', 'self._data_buffer', 'idx, batch = self._data_queue.get()']",1,1
60,incubator-mxnet,5747,closed,Questions about CSVIter,"@piiswrong I have some questions about :

 * If , is the data shuffled after every epoch? 
 * Speed when using multiple  in different jobs. When I launch a second training job, it uses different CSV file, the training speed drops, is it normal? And why?

",,"['@zihaolucky , i have came across same problem that the same program run in different machine, and there appear different result, one is normal, the other is a vibrating result.\r\n#4546', 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!']","['\r\n2017-04-09 21:51:13,815 Epoch[363] Batch [50]\tSpeed: 4057.94 samples/sec\tTrain-accuracy=0.992647\r\n2017-04-09 21:51:14,457 Epoch[363] Batch [100]\tSpeed: 2490.57 samples/sec\tTrain-accuracy=0.991250\r\n2017-04-09 21:51:15,210 Epoch[363] Batch [150]\tSpeed: 2127.01 samples/sec\tTrain-accuracy=0.990625\r\n2017-04-09 21:51:15,962 Epoch[363] Batch [200]\tSpeed: 2126.88 samples/sec\tTrain-accuracy=0.995625\r\n2017-04-09 21:51:16,715 Epoch[363] Batch [250]\tSpeed: 2126.10 samples/sec\tTrain-accuracy=0.992500\r\n2017-04-09 21:51:17,468 Epoch[363] Batch [300]\tSpeed: 2126.81 samples/sec\tTrain-accuracy=0.992500\r\n']","['CSVIter', 'shuffle=True', 'CSVIter']",1,0
61,incubator-mxnet,14838,open,regression from cudnn upgrade from 7.3.1 to 7.5.0,"We have recently found a performance regression on training imagenet with resnet50v1 when upgrading from **cudnn 7.3.1 to 7.5.0**

**Speed droped from ~5800 images/s to ~4800 images/s**

Environment is AWS DLAMI with AMI ID : ami-2dcceb57 (available in us-east)


command:

code at: https://github.com/rahul003/deep-learning-benchmark-mirror/blob/master/mxnet_benchmark/train_imagenet.py

our nightly pip packages were impacted because now we are building with cuddn 7.5.0.
Stable version of mxnet pip packages are not impacted.

I m using this issue to keep track so everyone can be updated.

cc
@szha @DickJC123 @stu1130 @pinaraws",CUDA Performance,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Cuda, Performance', '@mxnet-label-bot add[Cuda, Performance]', '@roywei - could you tell me which 2 nightly versions could I use to compare performance (1 with 7.3 and other with 7.5)?', '@ptrendx  Thanks for looking into it.\r\n7.3: `pip install mxnet-cu90==1.5.0b20190312`\r\n7.5: `pip instlal mxnet-cu90 --pre` or any timestamp after 03/13\r\n\r\ncc @stu1130 who is currently upgrading cuda and cudnn for mxnet', 'I built from source with latest master with CUDA 10.1 & cuDNN 7.5.1, ran twice and got 4992, 5067 respectively', '@ptrendx were you able to get any pointers on this regression?', 'Hi @ptrendx did you get a chance to look into this?']","['\r\npython mxnet_benchmark/train_imagenet.py --use-rec --batch-size 256 --dtype float16 --num-data-workers 40 --num-epochs 90 --gpus 0,1,2,3,4,5,6,7 --lr 0.8 --lr-decay-epoch 30,60,80 --warmup-epochs 5 --last-gamma --mode hybrid --model resnet50_v1b\r\n']",[],1,0
62,incubator-mxnet,14073,closed,Fp16 support for layernorm,"Currently, given fp16 inputs, nd.LayerNorm/sym.LayerNorm perform reduction in fp16, which losses precision. The reduction should be done in fp32 instead. @sxjscience ",FP16 Feature request Operator,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Feature', ""Current I propose to solve the issue following these two steps:\r\n\r\n- [ ] ~~Add a new 'reduer_dtype' flag to the LayerNorm operator. When the flag is set, the reduction will be performed in the specified dtype.~~ Always use the dtype-safe reductions in LayerNorm (https://github.com/apache/incubator-mxnet/pull/14699)\r\n- [ ] Accelerate the implementation of LayerNorm by taking advantage of the techniques in https://github.com/NVIDIA/apex/blob/master/csrc/layer_norm_cuda_kernel.cu, e.g., welford online sum (https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance)"", ""Once #14616 is merged then we can simply switch the LayerNorm's reduction to the safe version to achieve the 1st step @sxjscience proposed. Then we can possibly explore the implementation of the 2nd step later. @eric-haibin-lin What do you think?"", '@haojin2 Yes, should first try to directly change the reduce to the safe version.', 'This can probably be closed as https://github.com/apache/incubator-mxnet/pull/15002 is merged']",[],[],1,1
63,incubator-mxnet,16891,closed,Upgrading MKLDNN to 1.0 causes performance regression.,"## Description
The change that upgraded MKLDNN to 1.0 caused performance (images/sec) to drop by 200 points. 

### Error Message
The through-put performance (images/sec) during training dropped to 1300 images/sec.
Prior to this change the throughput was in the range of 1500-1530 images/sec.


## To Reproduce

The attached gzip file contains the training script that trains resnet18_v2 network on Cifar10 dataset.
[image_classification.tar.gz](https://github.com/apache/incubator-mxnet/files/3881313/image_classification.tar.gz)
The above numbers were measured on C5.18xlarge ubuntu instance.


### Steps to reproduce
(Paste the commands you ran that produced the error.)

1. Build and install the mxnet-mkl pip wheel that contains the above changes on the test machine.
2. Unzip the attached gzip file on the test machine.
3. Install the psutil and gluoncv and Export the KMP_AFFINITY anf OMP_NUM_THREADS variable as below.

4. Run the following command to start the training.



The sample output looks like below.


## Environment
1. c5.18xlarge
2. ubuntu 14.04 LTS


",Bug MKLDNN R1.6.0,"['#16555 \r\n\r\n@TaoLv @pengzhao-intel @zixuanweeei @samskalicky ', '@mxnet-label-bot add [R1.6.0]', '@leleamol How did you install the mxnet package, from source code or the nightly build? If build from source code, could you please share the make line also? #16555 removed the libiomp5 library from mxnet default build to comply with Apache License requirements. That could be the reason of this issue but I still need reproduce to confirm. If possible, could you please try to build mxnet with `USE_BLAS=mkl`? It will pull in the libiomp5 library. To install MKL BLAS, please refer to https://github.com/apache/incubator-mxnet/blob/master/ci/docker/install/ubuntu_mkl.sh. Thanks!', 'Our test results, https://github.com/apache/incubator-mxnet/issues/16845#issuecomment-557757080\r\n', '@TaoLv I have build the mxnet package from source.\r\n\r\nI followed the instructions that are mentioned in the [README.md](https://github.com/apache/incubator-mxnet/blob/master/tools/staticbuild/README.md)\r\n\r\nI just put them in the script form for quicker execution like below.\r\n\r\nFor building the mkl variant, invoke the following script with ""mkl"" as command line parameter.\r\n\r\n```\r\n#!/usr/bin/env bash\r\n  \r\n\r\nCURRNET_DIR=`pwd`\r\necho $CURRNET_DIR\r\nPIP_BUILD=$HOME/pip_build\r\nMXNET_BUILD=$PIP_BUILD/mxnet-build\r\ncd $HOME\r\n\r\nmkdir $PIP_BUILD\r\nmv $HOME/incubator-mxnet $MXNET_BUILD\r\ncd $MXNET_BUILD\r\necho ""Building mxnet.""\r\nsource tools/staticbuild/build.sh $1 pip\r\n\r\ncd $PIP_BUILD\r\ncp -r $MXNET_BUILD/tools/pip/. .\r\nexport mxnet_variant=$1\r\npython setup.py bdist_wheel\r\n```', '@zachgk assign [@apeforest ]', 'cpu test on both v1.5.x and v1.6.x mkldnn + openblas, but no regression issue was found.\r\nSo can you try to use USE_BLAS=mkl as Taolv said above and test again?\r\n\r\n\r\nI have tried to use build.sh but failed for: CMake Error at simd/CMakeLists.txt:41 (enable_language):\r\n  No CMAKE_ASM_NASM_COMPILER could be found.\r\nSo for v1.5 and v1.6 I build use cmd:\r\nmake -j USE_MKLDNN=1  USE_BLAS=openblas USE_GPERFTOOLS=0\r\nand setting openblas include and lib directory.\r\nplatform: skx-8180\r\n1.5: \r\n[rongzha1@mlt-ace ds2_training_inference]$ cd mxnet_1.5/\r\n[rongzha1@mlt-ace mxnet_1.5]$ ldd lib/libmxnet.so | grep open\r\n        libopenblas.so.0 => /lib64/libopenblas.so.0 (0x00007f8db5ff9000)\r\n        libopencv_highgui.so.2.4 => /lib64/libopencv_highgui.so.2.4 (0x00007f8dacdaf000)\r\n        libopencv_imgproc.so.2.4 => /lib64/libopencv_imgproc.so.2.4 (0x00007f8dac931000)\r\n        libopencv_core.so.2.4 => /lib64/libopencv_core.so.2.4 (0x00007f8dac4f7000)\r\n[rongzha1@mlt-ace mxnet_1.5]$ ldd lib/libmxnet.so | grep mkl\r\n        libmklml_intel.so => /home/rongzha1/project/mxnet/ds2_training_inference/mxnet_1.5/lib/libmklml_intel.so (0x00007f9707c8d000)\r\n        libmkldnn.so.0 => /home/rongzha1/project/mxnet/ds2_training_inference/mxnet_1.5/lib/libmkldnn.so.0 (0x00007f970671d000)\r\n(mxnet) [rongzha1@mlt-ace mxnet_1.5]$ ldd lib/libmxnet.so | grep omp\r\n        libiomp5.so => /home/rongzha1/project/mxnet/ds2_training_inference/mxnet_1.5/lib/libiomp5.so (0x00007f75cbc42000)\r\n        libXcomposite.so.1 => /lib64/libXcomposite.so.1 (0x00007f75c2647000)\r\n\r\n1.6.x:\r\n[rongzha1@mlt-skx141 perf_regression]$ ldd lib/libmxnet.so | grep open\r\n        libopenblas.so.0 => /usr/lib64/libopenblas.so.0 (0x00007fc101c03000)\r\n        libopencv_highgui.so.2.4 => /usr/lib64/libopencv_highgui.so.2.4 (0x00007fc1004cf000)\r\n        libopencv_imgproc.so.2.4 => /usr/lib64/libopencv_imgproc.so.2.4 (0x00007fc100051000)\r\n        libopencv_core.so.2.4 => /usr/lib64/libopencv_core.so.2.4 (0x00007fc0ffc18000)\r\n[rongzha1@mlt-skx141 perf_regression]$ ldd lib/libmxnet.so | grep mkl\r\n        libmkldnn.so.1 => /home/rongzha1/project/mxnet/ds2_training_inference/perf_regression/lib/libmkldnn.so.1 (0x00007f8378240000)\r\n[rongzha1@mlt-skx141 perf_regression]$ ldd lib/libmxnet.so | grep omp\r\n        libgomp.so.1 => /usr/lib64/libgomp.so.1 (0x00007f1357b17000)\r\n        libXcomposite.so.1 => /usr/lib64/libXcomposite.so.1 (0x00007f13509a1000)\r\n\r\nv1.5.x:\r\nOMP=56\r\n  1 [21:43:26] src/io/iter_image_recordio_2.cc:172: ImageRecordIOParser2: data/cifar/train.rec, use 4 threads for decoding..\r\n  2 [21:43:26] src/io/iter_image_recordio_2.cc:172: ImageRecordIOParser2: data/cifar/test.rec, use 4 threads for decoding..\r\n  3 INFO:root:Epoch[0] Batch [0-50] Speed: 1668.60 samples/sec  accuracy=0.273897\r\n  4 INFO:root:Epoch[0] Batch [50-100] Speed: 1699.64 samples/sec  accuracy=0.380312\r\n  5 INFO:root:Epoch[0] Batch [100-150]  Speed: 1692.57 samples/sec  accuracy=0.425000\r\n  6 INFO:root:Epoch[0] Batch [150-200]  Speed: 1696.67 samples/sec  accuracy=0.444063\r\n  7 INFO:root:Epoch[0] Batch [200-250]  Speed: 1698.27 samples/sec  accuracy=0.465000\r\n  8 INFO:root:Epoch[0] Batch [250-300]  Speed: 1693.87 samples/sec  accuracy=0.497812\r\n  9 INFO:root:Epoch[0] Batch [300-350]  Speed: 1698.26 samples/sec  accuracy=0.505625\r\n 10 INFO:root:Epoch[0] Batch [350-400]  Speed: 1691.21 samples/sec  accuracy=0.520000\r\n 11 INFO:root:Epoch[0] Batch [400-450]  Speed: 1694.42 samples/sec  accuracy=0.538750\r\n 12 INFO:root:Epoch[0] Batch [450-500]  Speed: 1693.73 samples/sec  accuracy=0.576875\r\n 13 INFO:root:Epoch[0] Batch [500-550]  Speed: 1688.67 samples/sec  accuracy=0.579063\r\n 14 INFO:root:Epoch[0] Batch [550-600]  Speed: 1686.91 samples/sec  accuracy=0.585313\r\n 15 INFO:root:Epoch[0] Batch [600-650]  Speed: 1691.39 samples/sec  accuracy=0.605313\r\n 16 INFO:root:Epoch[0] Batch [650-700]  Speed: 1693.22 samples/sec  accuracy=0.612812\r\n 17 INFO:root:Epoch[0] Batch [700-750]  Speed: 1692.32 samples/sec  accuracy=0.603750\r\n 18 INFO:root:Epoch[0] Train-accuracy=0.511549\r\n 19 INFO:root:Epoch[0] Time cost=29.955\r\n 20 INFO:root:Epoch[0] Validation-accuracy=0.642317\r\n\r\nOMP=36\r\n  1 [22:10:31] src/io/iter_image_recordio_2.cc:172: ImageRecordIOParser2: data/cifar/train.rec, use 4 threads for decoding..\r\n  2 [22:10:31] src/io/iter_image_recordio_2.cc:172: ImageRecordIOParser2: data/cifar/test.rec, use 4 threads for decoding..\r\n  3 INFO:root:Epoch[0] Batch [0-50] Speed: 1969.98 samples/sec  accuracy=0.279412\r\n  4 INFO:root:Epoch[0] Batch [50-100] Speed: 2014.50 samples/sec  accuracy=0.380937\r\n  5 INFO:root:Epoch[0] Batch [100-150]  Speed: 2009.43 samples/sec  accuracy=0.428125\r\n  6 INFO:root:Epoch[0] Batch [150-200]  Speed: 2013.70 samples/sec  accuracy=0.450313\r\n  7 INFO:root:Epoch[0] Batch [200-250]  Speed: 2012.61 samples/sec  accuracy=0.460625\r\n  8 INFO:root:Epoch[0] Batch [250-300]  Speed: 2014.29 samples/sec  accuracy=0.497812\r\n  9 INFO:root:Epoch[0] Batch [300-350]  Speed: 2013.60 samples/sec  accuracy=0.505000\r\n 10 INFO:root:Epoch[0] Batch [350-400]  Speed: 2009.98 samples/sec  accuracy=0.532500\r\n 11 INFO:root:Epoch[0] Batch [400-450]  Speed: 2014.39 samples/sec  accuracy=0.557500\r\n 12 INFO:root:Epoch[0] Batch [450-500]  Speed: 2015.02 samples/sec  accuracy=0.576250\r\n 13 INFO:root:Epoch[0] Batch [500-550]  Speed: 2015.25 samples/sec  accuracy=0.577187\r\n 14 INFO:root:Epoch[0] Batch [550-600]  Speed: 2012.03 samples/sec  accuracy=0.581250\r\n 15 INFO:root:Epoch[0] Batch [600-650]  Speed: 2014.64 samples/sec  accuracy=0.608437\r\n 16 INFO:root:Epoch[0] Batch [650-700]  Speed: 2017.28 samples/sec  accuracy=0.616563\r\n 17 INFO:root:Epoch[0] Batch [700-750]  Speed: 2017.49 samples/sec  accuracy=0.604688\r\n 18 INFO:root:Epoch[0] Train-accuracy=0.514086\r\n 19 INFO:root:Epoch[0] Time cost=24.895\r\n 20 INFO:root:Epoch[0] Validation-accuracy=0.635052\r\n\r\nv1.6.x:\r\nOMP = 36\r\n 1 [22:02:24] src/io/iter_image_recordio_2.cc:178: ImageRecordIOParser2: data/cifar/train.rec, use 4 threads for decoding..\r\n  2 [22:02:25] src/io/iter_image_recordio_2.cc:178: ImageRecordIOParser2: data/cifar/test.rec, use 4 threads for decoding..\r\n  3 [22:02:25] src/executor/graph_executor.cc:1979: Subgraph backend MKLDNN is activated.\r\n  4 /home/rongzha1/anaconda3/envs/mxnet/lib/python3.6/site-packages/scipy/__init__.py:115: UserWarning: Numpy 1.13.3 or above is required for this version of scipy (detected version 1.13.1)\r\n  5   UserWarning)\r\n  6 INFO:root:Epoch[0] Batch [0-50] Speed: 2119.74 samples/sec  accuracy=0.280025\r\n  7 INFO:root:Epoch[0] Batch [50-100] Speed: 2161.65 samples/sec  accuracy=0.392500\r\n  8 INFO:root:Epoch[0] Batch [100-150]  Speed: 2145.79 samples/sec  accuracy=0.425938\r\n  9 INFO:root:Epoch[0] Batch [150-200]  Speed: 2145.72 samples/sec  accuracy=0.448125\r\n 10 INFO:root:Epoch[0] Batch [200-250]  Speed: 2158.03 samples/sec  accuracy=0.461250\r\n 11 INFO:root:Epoch[0] Batch [250-300]  Speed: 2151.47 samples/sec  accuracy=0.498125\r\n 12 INFO:root:Epoch[0] Batch [300-350]  Speed: 2157.60 samples/sec  accuracy=0.515312\r\n 13 INFO:root:Epoch[0] Batch [350-400]  Speed: 2133.91 samples/sec  accuracy=0.530625\r\n 14 INFO:root:Epoch[0] Batch [400-450]  Speed: 2143.35 samples/sec  accuracy=0.545625\r\n 15 INFO:root:Epoch[0] Batch [450-500]  Speed: 2153.24 samples/sec  accuracy=0.577187\r\n 16 INFO:root:Epoch[0] Batch [500-550]  Speed: 2154.20 samples/sec  accuracy=0.577500\r\n 17 INFO:root:Epoch[0] Batch [550-600]  Speed: 2151.89 samples/sec  accuracy=0.580625\r\n 18 INFO:root:Epoch[0] Batch [600-650]  Speed: 2162.29 samples/sec  accuracy=0.596250\r\n 19 INFO:root:Epoch[0] Batch [650-700]  Speed: 2161.74 samples/sec  accuracy=0.609062\r\n 20 INFO:root:Epoch[0] Batch [700-750]  Speed: 2156.80 samples/sec  accuracy=0.597812\r\n 21 INFO:root:Epoch[0] Train-accuracy=0.512828\r\n 22 INFO:root:Epoch[0] Time cost=23.642\r\n 23 INFO:root:Epoch[0] Validation-accuracy=0.613455\r\n', ""Considering @rongzha1 comment I don't consider this issue to be a blocker for 1.6 release. Please comment if you disagree @leleamol @samskalicky ."", '@ptrendx @rongzha1 @PatricZhao thanks for looking into this, but the issue is not resolved until we verify by running the script @leleamol shared. The build.sh is the script used to generate the pip wheels. using make doesnt follow the same steps and reproduce the problem.\r\n\r\nIf you cant reproduce the build using the same scripts, I can share a pre-built pip wheel with you separately.', 'Regarding the following error:\r\n```\r\nNo CMAKE_ASM_NASM_COMPILER could be found.\r\n```\r\nyou can install with `sudo apt-get install nasm`', ""Hi @samskalicky  I applied AWS Deep learning AMI, c5.18xlarge and ubuntu 14.04 as yours\r\nUsing @leleamol shared script to build mxnet:\r\n\r\n1. mxnet1.5:\r\n      git checkout v1.5.x(commit c9818480680f84daa6e281a974ab263691302ba8)\r\n      when training, some error happens:\r\n      mxnet.base.MXNetError: [08:18:23] src/operator/nn/mkldnn/mkldnn_base.cc:372: Unknown MKLDNN format for 4 dimensions: 53\r\n      So which version did you use?  what's the commit id ?\r\n\r\n2. mxnet1.6:\r\n     git checkout v1.6.x(commit 200f0ec8ff55c7264554786822d8467dd9b15174)\r\n      both script build and make cmd build, training speed is about 1700 samples/sec\r\n\r\nCannot reproduce performance regression issue.\r\n\r\n\r\nDetails:\r\nUsing @leleamol shared script to build mxnet; 2 minor issue:\r\n1. script error : source tools/staticbuild/build.sh $1 pip    sh can not recognize ' source' cmd;\r\n   remove 'source ' can work\r\n2. link error:  can't find /usr/lib/gcc/x86_64-linux-gnu/5/libgfortran.so\r\n    try to link gcc5 lib, works well:\r\n    ln -s /usr/lib/gcc/x86_64-linux-gnu/5/libgfortran.so /usr/lib/gcc/x86_64-linux-gnu/4.8/libgfortran.so\r\nafter build: cd mxnet-build/python && python setup.py install\r\nrun cifar training\r\n\r\nResult is as following:\r\n[08:45:29] src/io/iter_image_recordio_2.cc:178: ImageRecordIOParser2: data/cifar/train.rec, use 4 threads for decoding..\r\n[08:45:29] src/io/iter_image_recordio_2.cc:178: ImageRecordIOParser2: data/cifar/test.rec, use 4 threads for decoding..\r\n[08:45:29] src/executor/graph_executor.cc:1984: Subgraph backend MKLDNN is activated.\r\nINFO:root:Epoch[0] Batch [0-50]\tSpeed: 1444.97 samples/sec\taccuracy=0.267770\r\nINFO:root:Epoch[0] Batch [50-100]\tSpeed: 1657.16 samples/sec\taccuracy=0.381563\r\nINFO:root:Epoch[0] Batch [100-150]\tSpeed: 1629.53 samples/sec\taccuracy=0.423438\r\nINFO:root:Epoch[0] Batch [150-200]\tSpeed: 1686.67 samples/sec\taccuracy=0.441875\r\nINFO:root:Epoch[0] Batch [200-250]\tSpeed: 1671.42 samples/sec\taccuracy=0.462187\r\nINFO:root:Epoch[0] Batch [250-300]\tSpeed: 1723.94 samples/sec\taccuracy=0.510000\r\nINFO:root:Epoch[0] Batch [300-350]\tSpeed: 1699.66 samples/sec\taccuracy=0.507500\r\nINFO:root:Epoch[0] Batch [350-400]\tSpeed: 1665.39 samples/sec\taccuracy=0.523125\r\nINFO:root:Epoch[0] Batch [400-450]\tSpeed: 1724.03 samples/sec\taccuracy=0.531250\r\nINFO:root:Epoch[0] Batch [450-500]\tSpeed: 1723.66 samples/sec\taccuracy=0.577187\r\nINFO:root:Epoch[0] Batch [500-550]\tSpeed: 1724.53 samples/sec\taccuracy=0.574375\r\nINFO:root:Epoch[0] Batch [550-600]\tSpeed: 1721.45 samples/sec\taccuracy=0.581250\r\nINFO:root:Epoch[0] Batch [600-650]\tSpeed: 1658.77 samples/sec\taccuracy=0.607500\r\nINFO:root:Epoch[0] Batch [650-700]\tSpeed: 1725.24 samples/sec\taccuracy=0.606250\r\nINFO:root:Epoch[0] Batch [700-750]\tSpeed: 1726.21 samples/sec\taccuracy=0.606563\r\n\r\nI also use build cmd:\r\nmake -j USE_MKLDNN=1 USE_BLAS=openblas USE_GPERFTOOLS=0\r\ncd python/ && python setup.py install\r\nresults as following:\r\nArchive:  cifar10.zip\r\n   creating: cifar/\r\n  inflating: cifar/test.rec          \r\n  inflating: cifar/test.lst          \r\n  inflating: cifar/train.lst         \r\n  inflating: cifar/train.rec         \r\n[07:38:12] src/io/iter_image_recordio_2.cc:178: ImageRecordIOParser2: data/cifar/train.rec, use 4 threads for decoding..\r\n[07:38:12] src/io/iter_image_recordio_2.cc:178: ImageRecordIOParser2: data/cifar/test.rec, use 4 threads for decoding..\r\n[07:38:12] src/executor/graph_executor.cc:1984: Subgraph backend MKLDNN is activated.\r\nINFO:root:Epoch[0] Batch [0-50]\tSpeed: 1416.12 samples/sec\taccuracy=0.278799\r\nINFO:root:Epoch[0] Batch [50-100]\tSpeed: 1673.98 samples/sec\taccuracy=0.385313\r\nINFO:root:Epoch[0] Batch [100-150]\tSpeed: 1624.87 samples/sec\taccuracy=0.424687\r\nINFO:root:Epoch[0] Batch [150-200]\tSpeed: 1668.53 samples/sec\taccuracy=0.438750\r\nINFO:root:Epoch[0] Batch [200-250]\tSpeed: 1664.30 samples/sec\taccuracy=0.478438\r\nINFO:root:Epoch[0] Batch [250-300]\tSpeed: 1696.48 samples/sec\taccuracy=0.511250\r\nINFO:root:Epoch[0] Batch [300-350]\tSpeed: 1701.83 samples/sec\taccuracy=0.517188\r\nINFO:root:Epoch[0] Batch [350-400]\tSpeed: 1616.46 samples/sec\taccuracy=0.545000\r\nINFO:root:Epoch[0] Batch [400-450]\tSpeed: 1697.75 samples/sec\taccuracy=0.556875\r\nINFO:root:Epoch[0] Batch [450-500]\tSpeed: 1703.83 samples/sec\taccuracy=0.575625\r\nINFO:root:Epoch[0] Batch [500-550]\tSpeed: 1703.13 samples/sec\taccuracy=0.572812\r\nINFO:root:Epoch[0] Batch [550-600]\tSpeed: 1699.32 samples/sec\taccuracy=0.587187\r\nINFO:root:Epoch[0] Batch [600-650]\tSpeed: 1682.87 samples/sec\taccuracy=0.604688\r\nINFO:root:Epoch[0] Batch [650-700]\tSpeed: 1671.12 samples/sec\taccuracy=0.612187\r\nINFO:root:Epoch[0] Batch [700-750]\tSpeed: 1705.85 samples/sec\taccuracy=0.611875\r\nINFO:root:Epoch[0] Train-accuracy=0.516964\r\nINFO:root:Epoch[0] Time cost=30.561\r\nINFO:root:Epoch[0] Validation-accuracy=0.628085\r\n\r\nattach screenshot:\r\n![1 6_make1](https://user-images.githubusercontent.com/28431214/69811413-fb294880-1228-11ea-86eb-6aac58533845.png)\r\n![1 6_make2](https://user-images.githubusercontent.com/28431214/69811414-fbc1df00-1228-11ea-8b02-a5df49306fee.png)\r\n![1 6_script_build](https://user-images.githubusercontent.com/28431214/69811415-fbc1df00-1228-11ea-8eeb-f86d15ac9a8c.png)\r\n\r\n"", ""Hi @TaoLv, is there an ETA to have this issue fixed? It's causing quite some concern around here.\r\n\r\nThanks,\r\n\r\nOmar"", 'Added a script for easy repro: \r\n\r\nhttp://ix.io/23fU\r\n\r\nhttp://ix.io/23fV\r\n\r\nTo run:\r\n```\r\npiotr@34-215-197-42:130:~$ for i in 1 2 4 8 16 32 64 128 256 512 1024 2048; do ./imagenet.sh $i 2>&1 | tee run_$i.log; done\r\npiotr@34-215-197-42:1:~$ ./table.py\r\n\r\n\r\n```', ""@oorqueda @samskalicky @leleamol As mentioned in https://github.com/apache/incubator-mxnet/issues/16891#issuecomment-557760466, I suspect that the regression is caused by the removal of libiomp5.so. To verify, please try to apply the below patch to `make/pip_linux_mkl.mk`:\r\n\r\n```\r\ndiff --git a/make/pip/pip_linux_mkl.mk b/make/pip/pip_linux_mkl.mk\r\nindex 1cf389ae4..dd23434fa 100644\r\n--- a/make/pip/pip_linux_mkl.mk\r\n+++ b/make/pip/pip_linux_mkl.mk\r\n@@ -49,7 +49,7 @@ ADD_CFLAGS += -I$(DEPS_PATH)/include -ffunction-sections -fdata-sections\r\n # choose the version of blas you want to use\r\n # can be: mkl, blas, atlas, openblas\r\n # in default use atlas for linux while apple for osx\r\n-USE_BLAS=openblas\r\n+USE_BLAS=mkl\r\n\r\n # whether use opencv during compilation\r\n # you can disable it, however, you will not able to use\r\n@@ -98,7 +98,7 @@ USE_LAPACK_PATH = $(DEPS_PATH)/lib\r\n\r\n # add path to intel library, you may need it for MKL, if you did not add the path\r\n # to environment variable\r\n-USE_INTEL_PATH = NONE\r\n+USE_INTEL_PATH = /opt/intel/\r\n```\r\nAnd then build MXNet with:\r\n```\r\ntools/staticbuild/build.sh mkl pip\r\n```\r\nIf it's true, I don't think we have any choice to avoid the regression in pip packages as removing libiomp5.so is a requirement from Apache. Please refer to https://github.com/apache/incubator-mxnet/issues/15544. Thanks!"", ""@leleamol could you help to confirm the current test status based on our feedback? \r\nI don't want it to block 1.6 release.\r\n\r\ncc @samskalicky @apeforest "", ""> @oorqueda @samskalicky @leleamol As mentioned in [#16891 (comment)](https://github.com/apache/incubator-mxnet/issues/16891#issuecomment-557760466), I suspect that the regression is caused by the removal of libiomp5.so. To verify, please try to apply the below patch to `make/pip_linux_mkl.mk`:\r\n> \r\n> ```\r\n> diff --git a/make/pip/pip_linux_mkl.mk b/make/pip/pip_linux_mkl.mk\r\n> index 1cf389ae4..dd23434fa 100644\r\n> --- a/make/pip/pip_linux_mkl.mk\r\n> +++ b/make/pip/pip_linux_mkl.mk\r\n> @@ -49,7 +49,7 @@ ADD_CFLAGS += -I$(DEPS_PATH)/include -ffunction-sections -fdata-sections\r\n>  # choose the version of blas you want to use\r\n>  # can be: mkl, blas, atlas, openblas\r\n>  # in default use atlas for linux while apple for osx\r\n> -USE_BLAS=openblas\r\n> +USE_BLAS=mkl\r\n> \r\n>  # whether use opencv during compilation\r\n>  # you can disable it, however, you will not able to use\r\n> @@ -98,7 +98,7 @@ USE_LAPACK_PATH = $(DEPS_PATH)/lib\r\n> \r\n>  # add path to intel library, you may need it for MKL, if you did not add the path\r\n>  # to environment variable\r\n> -USE_INTEL_PATH = NONE\r\n> +USE_INTEL_PATH = /opt/intel/\r\n> ```\r\n> \r\n> And then build MXNet with:\r\n> \r\n> ```\r\n> tools/staticbuild/build.sh mkl pip\r\n> ```\r\n> \r\n> If it's true, I don't think we have any choice to avoid the regression in pip packages as removing libiomp5.so is a requirement from Apache. Please refer to #15544. Thanks!\r\n\r\nRetried with this patch after installing MKL BLAS with https://github.com/apache/incubator-mxnet/blob/master/ci/docker/install/ubuntu_mkl.sh and got these results:\r\n\r\n**Average Throughput: 1663.49 samples/sec**\r\n\r\n```\r\nINFO:root:Epoch[0] Batch [0-50]\tSpeed: 1414.31 samples/sec\taccuracy=0.281863\r\nINFO:root:Epoch[0] Batch [50-100]\tSpeed: 1610.74 samples/sec\taccuracy=0.382500\r\nINFO:root:Epoch[0] Batch [100-150]\tSpeed: 1625.33 samples/sec\taccuracy=0.430000\r\nINFO:root:Epoch[0] Batch [150-200]\tSpeed: 1649.23 samples/sec\taccuracy=0.432500\r\nINFO:root:Epoch[0] Batch [200-250]\tSpeed: 1663.87 samples/sec\taccuracy=0.465000\r\nINFO:root:Epoch[0] Batch [250-300]\tSpeed: 1640.63 samples/sec\taccuracy=0.495625\r\nINFO:root:Epoch[0] Batch [300-350]\tSpeed: 1671.83 samples/sec\taccuracy=0.502500\r\nINFO:root:Epoch[0] Batch [350-400]\tSpeed: 1669.90 samples/sec\taccuracy=0.516563\r\nINFO:root:Epoch[0] Batch [400-450]\tSpeed: 1600.49 samples/sec\taccuracy=0.548125\r\nINFO:root:Epoch[0] Batch [450-500]\tSpeed: 1669.11 samples/sec\taccuracy=0.562500\r\nINFO:root:Epoch[0] Batch [500-550]\tSpeed: 1671.51 samples/sec\taccuracy=0.558750\r\nINFO:root:Epoch[0] Batch [550-600]\tSpeed: 1667.67 samples/sec\taccuracy=0.586875\r\nINFO:root:Epoch[0] Batch [600-650]\tSpeed: 1670.19 samples/sec\taccuracy=0.591562\r\nINFO:root:Epoch[0] Batch [650-700]\tSpeed: 1652.81 samples/sec\taccuracy=0.611250\r\nINFO:root:Epoch[0] Batch [700-750]\tSpeed: 1630.58 samples/sec\taccuracy=0.600000\r\nINFO:root:Epoch[0] Train-accuracy=0.508252\r\nINFO:root:Epoch[0] Time cost=30.680\r\nINFO:root:Epoch[0] Validation-accuracy=0.632166\r\nINFO:root:Epoch[1] Batch [0-50]\tSpeed: 1648.76 samples/sec\taccuracy=0.625613\r\nINFO:root:Epoch[1] Batch [50-100]\tSpeed: 1660.23 samples/sec\taccuracy=0.629375\r\nINFO:root:Epoch[1] Batch [100-150]\tSpeed: 1616.19 samples/sec\taccuracy=0.640312\r\nINFO:root:Epoch[1] Batch [150-200]\tSpeed: 1670.47 samples/sec\taccuracy=0.643125\r\nINFO:root:Epoch[1] Batch [200-250]\tSpeed: 1670.92 samples/sec\taccuracy=0.657500\r\nINFO:root:Epoch[1] Batch [250-300]\tSpeed: 1671.10 samples/sec\taccuracy=0.655625\r\nINFO:root:Epoch[1] Batch [300-350]\tSpeed: 1669.03 samples/sec\taccuracy=0.651250\r\nINFO:root:Epoch[1] Batch [350-400]\tSpeed: 1669.22 samples/sec\taccuracy=0.655312\r\nINFO:root:Epoch[1] Batch [400-450]\tSpeed: 1671.08 samples/sec\taccuracy=0.672813\r\nINFO:root:Epoch[1] Batch [450-500]\tSpeed: 1671.26 samples/sec\taccuracy=0.673750\r\nINFO:root:Epoch[1] Batch [500-550]\tSpeed: 1650.34 samples/sec\taccuracy=0.682500\r\nINFO:root:Epoch[1] Batch [550-600]\tSpeed: 1663.81 samples/sec\taccuracy=0.681250\r\nINFO:root:Epoch[1] Batch [600-650]\tSpeed: 1671.43 samples/sec\taccuracy=0.695625\r\nINFO:root:Epoch[1] Batch [650-700]\tSpeed: 1622.47 samples/sec\taccuracy=0.698438\r\nINFO:root:Epoch[1] Batch [700-750]\tSpeed: 1671.23 samples/sec\taccuracy=0.687187\r\nINFO:root:Epoch[1] Train-accuracy=0.664633\r\nINFO:root:Epoch[1] Time cost=30.096\r\nINFO:root:Epoch[1] Validation-accuracy=0.673878\r\nINFO:root:Epoch[2] Batch [0-50]\tSpeed: 1668.44 samples/sec\taccuracy=0.701900\r\nINFO:root:Epoch[2] Batch [50-100]\tSpeed: 1673.86 samples/sec\taccuracy=0.698750\r\nINFO:root:Epoch[2] Batch [100-150]\tSpeed: 1669.55 samples/sec\taccuracy=0.712500\r\nINFO:root:Epoch[2] Batch [150-200]\tSpeed: 1673.31 samples/sec\taccuracy=0.713750\r\nINFO:root:Epoch[2] Batch [200-250]\tSpeed: 1673.31 samples/sec\taccuracy=0.726562\r\nINFO:root:Epoch[2] Batch [250-300]\tSpeed: 1672.89 samples/sec\taccuracy=0.717187\r\nINFO:root:Epoch[2] Batch [300-350]\tSpeed: 1651.81 samples/sec\taccuracy=0.725938\r\nINFO:root:Epoch[2] Batch [350-400]\tSpeed: 1623.66 samples/sec\taccuracy=0.718750\r\nINFO:root:Epoch[2] Batch [400-450]\tSpeed: 1672.81 samples/sec\taccuracy=0.729688\r\nINFO:root:Epoch[2] Batch [450-500]\tSpeed: 1672.86 samples/sec\taccuracy=0.736563\r\nINFO:root:Epoch[2] Batch [500-550]\tSpeed: 1669.99 samples/sec\taccuracy=0.730625\r\nINFO:root:Epoch[2] Batch [550-600]\tSpeed: 1670.90 samples/sec\taccuracy=0.728750\r\nINFO:root:Epoch[2] Batch [600-650]\tSpeed: 1673.84 samples/sec\taccuracy=0.739375\r\nINFO:root:Epoch[2] Batch [650-700]\tSpeed: 1675.46 samples/sec\taccuracy=0.750313\r\nINFO:root:Epoch[2] Batch [700-750]\tSpeed: 1675.23 samples/sec\taccuracy=0.739062\r\nINFO:root:Epoch[2] Train-accuracy=0.725112\r\nINFO:root:Epoch[2] Time cost=29.959\r\nINFO:root:Epoch[2] Validation-accuracy=0.699419\r\nINFO:root:Epoch[3] Batch [0-50]\tSpeed: 1620.48 samples/sec\taccuracy=0.747243\r\nINFO:root:Epoch[3] Batch [50-100]\tSpeed: 1665.64 samples/sec\taccuracy=0.747188\r\nINFO:root:Epoch[3] Batch [100-150]\tSpeed: 1669.65 samples/sec\taccuracy=0.744375\r\nINFO:root:Epoch[3] Batch [150-200]\tSpeed: 1672.57 samples/sec\taccuracy=0.756563\r\nINFO:root:Epoch[3] Batch [200-250]\tSpeed: 1673.09 samples/sec\taccuracy=0.755625\r\nINFO:root:Epoch[3] Batch [250-300]\tSpeed: 1672.16 samples/sec\taccuracy=0.757500\r\nINFO:root:Epoch[3] Batch [300-350]\tSpeed: 1671.06 samples/sec\taccuracy=0.757812\r\nINFO:root:Epoch[3] Batch [350-400]\tSpeed: 1670.54 samples/sec\taccuracy=0.754687\r\nINFO:root:Epoch[3] Batch [400-450]\tSpeed: 1673.20 samples/sec\taccuracy=0.774375\r\nINFO:root:Epoch[3] Batch [450-500]\tSpeed: 1656.83 samples/sec\taccuracy=0.768750\r\nINFO:root:Epoch[3] Batch [500-550]\tSpeed: 1672.77 samples/sec\taccuracy=0.772813\r\nINFO:root:Epoch[3] Batch [550-600]\tSpeed: 1662.18 samples/sec\taccuracy=0.770312\r\nINFO:root:Epoch[3] Batch [600-650]\tSpeed: 1672.07 samples/sec\taccuracy=0.770000\r\nINFO:root:Epoch[3] Batch [650-700]\tSpeed: 1642.67 samples/sec\taccuracy=0.780000\r\nINFO:root:Epoch[3] Batch [700-750]\tSpeed: 1670.11 samples/sec\taccuracy=0.776875\r\nINFO:root:Epoch[3] Train-accuracy=0.762764\r\nINFO:root:Epoch[3] Time cost=30.022\r\nINFO:root:Epoch[3] Validation-accuracy=0.731771\r\nINFO:root:Epoch[4] Batch [0-50]\tSpeed: 1667.95 samples/sec\taccuracy=0.778493\r\nINFO:root:Epoch[4] Batch [50-100]\tSpeed: 1672.75 samples/sec\taccuracy=0.790312\r\nINFO:root:Epoch[4] Batch [100-150]\tSpeed: 1669.29 samples/sec\taccuracy=0.776875\r\nINFO:root:Epoch[4] Batch [150-200]\tSpeed: 1673.50 samples/sec\taccuracy=0.792500\r\nINFO:root:Epoch[4] Batch [200-250]\tSpeed: 1672.97 samples/sec\taccuracy=0.783438\r\nINFO:root:Epoch[4] Batch [250-300]\tSpeed: 1672.72 samples/sec\taccuracy=0.796250\r\nINFO:root:Epoch[4] Batch [300-350]\tSpeed: 1658.90 samples/sec\taccuracy=0.784687\r\nINFO:root:Epoch[4] Batch [350-400]\tSpeed: 1669.21 samples/sec\taccuracy=0.790937\r\nINFO:root:Epoch[4] Batch [400-450]\tSpeed: 1664.05 samples/sec\taccuracy=0.800312\r\nINFO:root:Epoch[4] Batch [450-500]\tSpeed: 1637.17 samples/sec\taccuracy=0.789375\r\nINFO:root:Epoch[4] Batch [500-550]\tSpeed: 1665.37 samples/sec\taccuracy=0.799687\r\nINFO:root:Epoch[4] Batch [550-600]\tSpeed: 1668.98 samples/sec\taccuracy=0.806562\r\nINFO:root:Epoch[4] Batch [600-650]\tSpeed: 1672.85 samples/sec\taccuracy=0.809375\r\nINFO:root:Epoch[4] Batch [650-700]\tSpeed: 1674.14 samples/sec\taccuracy=0.816562\r\nINFO:root:Epoch[4] Batch [700-750]\tSpeed: 1674.87 samples/sec\taccuracy=0.800000\r\nINFO:root:Epoch[4] Train-accuracy=0.794457\r\nINFO:root:Epoch[4] Time cost=29.996\r\nINFO:root:Epoch[4] Validation-accuracy=0.741740\r\nINFO:root:Epoch[5] Batch [0-50]\tSpeed: 1668.07 samples/sec\taccuracy=0.809436\r\nINFO:root:Epoch[5] Batch [50-100]\tSpeed: 1673.35 samples/sec\taccuracy=0.810312\r\nINFO:root:Epoch[5] Batch [100-150]\tSpeed: 1651.66 samples/sec\taccuracy=0.807500\r\nINFO:root:Epoch[5] Batch [150-200]\tSpeed: 1667.67 samples/sec\taccuracy=0.809063\r\nINFO:root:Epoch[5] Batch [200-250]\tSpeed: 1668.76 samples/sec\taccuracy=0.808750\r\nINFO:root:Epoch[5] Batch [250-300]\tSpeed: 1672.72 samples/sec\taccuracy=0.810937\r\nINFO:root:Epoch[5] Batch [300-350]\tSpeed: 1671.69 samples/sec\taccuracy=0.816562\r\nINFO:root:Epoch[5] Batch [350-400]\tSpeed: 1672.54 samples/sec\taccuracy=0.818750\r\nINFO:root:Epoch[5] Batch [400-450]\tSpeed: 1631.24 samples/sec\taccuracy=0.822187\r\nINFO:root:Epoch[5] Batch [450-500]\tSpeed: 1665.93 samples/sec\taccuracy=0.815937\r\nINFO:root:Epoch[5] Batch [500-550]\tSpeed: 1674.52 samples/sec\taccuracy=0.819063\r\nINFO:root:Epoch[5] Batch [550-600]\tSpeed: 1670.75 samples/sec\taccuracy=0.812500\r\nINFO:root:Epoch[5] Batch [600-650]\tSpeed: 1673.81 samples/sec\taccuracy=0.825937\r\nINFO:root:Epoch[5] Batch [650-700]\tSpeed: 1676.04 samples/sec\taccuracy=0.827187\r\nINFO:root:Epoch[5] Batch [700-750]\tSpeed: 1675.77 samples/sec\taccuracy=0.817813\r\nINFO:root:Epoch[5] Train-accuracy=0.815501\r\nINFO:root:Epoch[5] Time cost=29.948\r\nINFO:root:Epoch[5] Validation-accuracy=0.749399\r\nINFO:root:Epoch[6] Batch [0-50]\tSpeed: 1669.17 samples/sec\taccuracy=0.837623\r\nINFO:root:Epoch[6] Batch [50-100]\tSpeed: 1661.24 samples/sec\taccuracy=0.813750\r\nINFO:root:Epoch[6] Batch [100-150]\tSpeed: 1667.14 samples/sec\taccuracy=0.830313\r\nINFO:root:Epoch[6] Batch [150-200]\tSpeed: 1667.80 samples/sec\taccuracy=0.826250\r\nINFO:root:Epoch[6] Batch [200-250]\tSpeed: 1673.15 samples/sec\taccuracy=0.826562\r\nINFO:root:Epoch[6] Batch [250-300]\tSpeed: 1646.27 samples/sec\taccuracy=0.836875\r\nINFO:root:Epoch[6] Batch [300-350]\tSpeed: 1666.01 samples/sec\taccuracy=0.829375\r\nINFO:root:Epoch[6] Batch [350-400]\tSpeed: 1672.95 samples/sec\taccuracy=0.834688\r\nINFO:root:Epoch[6] Batch [400-450]\tSpeed: 1673.64 samples/sec\taccuracy=0.835625\r\nINFO:root:Epoch[6] Batch [450-500]\tSpeed: 1675.71 samples/sec\taccuracy=0.843437\r\nINFO:root:Epoch[6] Batch [500-550]\tSpeed: 1674.81 samples/sec\taccuracy=0.849688\r\nINFO:root:Epoch[6] Batch [550-600]\tSpeed: 1670.66 samples/sec\taccuracy=0.848750\r\nINFO:root:Epoch[6] Batch [600-650]\tSpeed: 1674.67 samples/sec\taccuracy=0.850000\r\nINFO:root:Epoch[6] Batch [650-700]\tSpeed: 1676.15 samples/sec\taccuracy=0.852187\r\nINFO:root:Epoch[6] Batch [700-750]\tSpeed: 1662.28 samples/sec\taccuracy=0.840625\r\nINFO:root:Epoch[6] Train-accuracy=0.837408\r\nINFO:root:Epoch[6] Time cost=29.926\r\nINFO:root:Epoch[6] Validation-accuracy=0.755609\r\nINFO:root:Epoch[7] Batch [0-50]\tSpeed: 1669.53 samples/sec\taccuracy=0.851409\r\nINFO:root:Epoch[7] Batch [50-100]\tSpeed: 1673.99 samples/sec\taccuracy=0.851875\r\nINFO:root:Epoch[7] Batch [100-150]\tSpeed: 1664.78 samples/sec\taccuracy=0.845000\r\nINFO:root:Epoch[7] Batch [150-200]\tSpeed: 1643.95 samples/sec\taccuracy=0.848125\r\nINFO:root:Epoch[7] Batch [200-250]\tSpeed: 1673.32 samples/sec\taccuracy=0.846250\r\nINFO:root:Epoch[7] Batch [250-300]\tSpeed: 1674.50 samples/sec\taccuracy=0.854062\r\nINFO:root:Epoch[7] Batch [300-350]\tSpeed: 1667.81 samples/sec\taccuracy=0.868750\r\nINFO:root:Epoch[7] Batch [350-400]\tSpeed: 1672.58 samples/sec\taccuracy=0.856875\r\nINFO:root:Epoch[7] Batch [400-450]\tSpeed: 1674.09 samples/sec\taccuracy=0.856563\r\nINFO:root:Epoch[7] Batch [450-500]\tSpeed: 1674.60 samples/sec\taccuracy=0.855000\r\nINFO:root:Epoch[7] Batch [500-550]\tSpeed: 1674.48 samples/sec\taccuracy=0.868125\r\nINFO:root:Epoch[7] Batch [550-600]\tSpeed: 1670.71 samples/sec\taccuracy=0.854688\r\nINFO:root:Epoch[7] Batch [600-650]\tSpeed: 1674.68 samples/sec\taccuracy=0.859375\r\nINFO:root:Epoch[7] Batch [650-700]\tSpeed: 1675.54 samples/sec\taccuracy=0.867812\r\nINFO:root:Epoch[7] Batch [700-750]\tSpeed: 1636.57 samples/sec\taccuracy=0.861250\r\nINFO:root:Epoch[7] Train-accuracy=0.856634\r\nINFO:root:Epoch[7] Time cost=29.935\r\nINFO:root:Epoch[7] Validation-accuracy=0.751202\r\nINFO:root:Epoch[8] Batch [0-50]\tSpeed: 1666.25 samples/sec\taccuracy=0.862745\r\nINFO:root:Epoch[8] Batch [50-100]\tSpeed: 1667.20 samples/sec\taccuracy=0.871563\r\nINFO:root:Epoch[8] Batch [100-150]\tSpeed: 1638.39 samples/sec\taccuracy=0.859688\r\nINFO:root:Epoch[8] Batch [150-200]\tSpeed: 1668.52 samples/sec\taccuracy=0.874687\r\nINFO:root:Epoch[8] Batch [200-250]\tSpeed: 1664.86 samples/sec\taccuracy=0.866875\r\nINFO:root:Epoch[8] Batch [250-300]\tSpeed: 1670.59 samples/sec\taccuracy=0.866250\r\nINFO:root:Epoch[8] Batch [300-350]\tSpeed: 1672.36 samples/sec\taccuracy=0.872500\r\nINFO:root:Epoch[8] Batch [350-400]\tSpeed: 1667.79 samples/sec\taccuracy=0.876250\r\nINFO:root:Epoch[8] Batch [400-450]\tSpeed: 1672.58 samples/sec\taccuracy=0.875938\r\nINFO:root:Epoch[8] Batch [450-500]\tSpeed: 1672.51 samples/sec\taccuracy=0.871250\r\nINFO:root:Epoch[8] Batch [500-550]\tSpeed: 1671.49 samples/sec\taccuracy=0.878750\r\nINFO:root:Epoch[8] Batch [550-600]\tSpeed: 1668.27 samples/sec\taccuracy=0.884062\r\nINFO:root:Epoch[8] Batch [600-650]\tSpeed: 1656.65 samples/sec\taccuracy=0.882812\r\nINFO:root:Epoch[8] Batch [650-700]\tSpeed: 1671.64 samples/sec\taccuracy=0.884062\r\nINFO:root:Epoch[8] Batch [700-750]\tSpeed: 1673.34 samples/sec\taccuracy=0.874687\r\nINFO:root:Epoch[8] Train-accuracy=0.873581\r\nINFO:root:Epoch[8] Time cost=30.010\r\nINFO:root:Epoch[8] Validation-accuracy=0.766421\r\nINFO:root:Epoch[9] Batch [0-50]\tSpeed: 1669.04 samples/sec\taccuracy=0.879289\r\nINFO:root:Epoch[9] Batch [50-100]\tSpeed: 1671.88 samples/sec\taccuracy=0.887188\r\nINFO:root:Epoch[9] Batch [100-150]\tSpeed: 1662.53 samples/sec\taccuracy=0.867500\r\nINFO:root:Epoch[9] Batch [150-200]\tSpeed: 1672.37 samples/sec\taccuracy=0.881875\r\nINFO:root:Epoch[9] Batch [200-250]\tSpeed: 1672.11 samples/sec\taccuracy=0.886563\r\nINFO:root:Epoch[9] Batch [250-300]\tSpeed: 1635.77 samples/sec\taccuracy=0.870938\r\nINFO:root:Epoch[9] Batch [300-350]\tSpeed: 1670.30 samples/sec\taccuracy=0.884062\r\nINFO:root:Epoch[9] Batch [350-400]\tSpeed: 1671.09 samples/sec\taccuracy=0.879375\r\nINFO:root:Epoch[9] Batch [400-450]\tSpeed: 1667.68 samples/sec\taccuracy=0.883125\r\nINFO:root:Epoch[9] Batch [450-500]\tSpeed: 1673.33 samples/sec\taccuracy=0.885000\r\nINFO:root:Epoch[9] Batch [500-550]\tSpeed: 1672.83 samples/sec\taccuracy=0.883750\r\nINFO:root:Epoch[9] Batch [550-600]\tSpeed: 1668.54 samples/sec\taccuracy=0.887500\r\nINFO:root:Epoch[9] Batch [600-650]\tSpeed: 1672.97 samples/sec\taccuracy=0.890312\r\nINFO:root:Epoch[9] Batch [650-700]\tSpeed: 1653.01 samples/sec\taccuracy=0.889062\r\nINFO:root:Epoch[9] Batch [700-750]\tSpeed: 1673.44 samples/sec\taccuracy=0.889062\r\nINFO:root:Epoch[9] Train-accuracy=0.883263\r\nINFO:root:Epoch[9] Time cost=29.960\r\nINFO:root:Epoch[9] Validation-accuracy=0.762520\r\nINFO:root:Epoch[10] Batch [0-50]\tSpeed: 1666.71 samples/sec\taccuracy=0.887868\r\nINFO:root:Epoch[10] Batch [50-100]\tSpeed: 1672.06 samples/sec\taccuracy=0.882500\r\nINFO:root:Epoch[10] Batch [100-150]\tSpeed: 1668.15 samples/sec\taccuracy=0.881250\r\nINFO:root:Epoch[10] Batch [150-200]\tSpeed: 1667.18 samples/sec\taccuracy=0.899062\r\nINFO:root:Epoch[10] Batch [200-250]\tSpeed: 1670.72 samples/sec\taccuracy=0.881563\r\nINFO:root:Epoch[10] Batch [250-300]\tSpeed: 1671.63 samples/sec\taccuracy=0.890000\r\nINFO:root:Epoch[10] Batch [300-350]\tSpeed: 1669.62 samples/sec\taccuracy=0.905625\r\nINFO:root:Epoch[10] Batch [350-400]\tSpeed: 1664.69 samples/sec\taccuracy=0.904375\r\nINFO:root:Epoch[10] Batch [400-450]\tSpeed: 1671.13 samples/sec\taccuracy=0.901250\r\nINFO:root:Epoch[10] Batch [450-500]\tSpeed: 1666.08 samples/sec\taccuracy=0.896250\r\nINFO:root:Epoch[10] Batch [500-550]\tSpeed: 1670.59 samples/sec\taccuracy=0.905312\r\nINFO:root:Epoch[10] Batch [550-600]\tSpeed: 1667.69 samples/sec\taccuracy=0.894687\r\nINFO:root:Epoch[10] Batch [600-650]\tSpeed: 1671.95 samples/sec\taccuracy=0.895938\r\nINFO:root:Epoch[10] Batch [650-700]\tSpeed: 1672.98 samples/sec\taccuracy=0.909375\r\nINFO:root:Epoch[10] Batch [700-750]\tSpeed: 1624.72 samples/sec\taccuracy=0.909375\r\nINFO:root:Epoch[10] Train-accuracy=0.896667\r\nINFO:root:Epoch[10] Time cost=29.974\r\nINFO:root:Epoch[10] Validation-accuracy=0.764123\r\n```"", ""@NihalHarish thanks for verifying\r\n\r\n@TaoLv \r\nThe patch doesn't seem to be merged on the master branch. Any reason why it's not being done along with the PR that bumped MKLDNN to v1.0 https://github.com/apache/incubator-mxnet/pull/16555\r\n\r\n```\r\ndiff --git a/make/pip/pip_linux_mkl.mk b/make/pip/pip_linux_mkl.mk\r\nindex 1cf389ae4..dd23434fa 100644\r\n--- a/make/pip/pip_linux_mkl.mk\r\n+++ b/make/pip/pip_linux_mkl.mk\r\n@@ -49,7 +49,7 @@ ADD_CFLAGS += -I$(DEPS_PATH)/include -ffunction-sections -fdata-sections\r\n # choose the version of blas you want to use\r\n # can be: mkl, blas, atlas, openblas\r\n # in default use atlas for linux while apple for osx\r\n-USE_BLAS=openblas\r\n+USE_BLAS=mkl\r\n\r\n # whether use opencv during compilation\r\n # you can disable it, however, you will not able to use\r\n@@ -98,7 +98,7 @@ USE_LAPACK_PATH = $(DEPS_PATH)/lib\r\n\r\n # add path to intel library, you may need it for MKL, if you did not add the path\r\n # to environment variable\r\n-USE_INTEL_PATH = NONE\r\n+USE_INTEL_PATH = /opt/intel/\r\n```\r\n\r\nIf it was omitted by mistake and since it is required, I could push a PR for the same.\r\n\r\n2. Also, do you folks have any data about performance tests run AFTER this patch is applied?\r\n\r\nThanks."", '@ChaiBapchya The file is used to build mxnet-mkl pip package. If you want to change the configurations, I think you need have a proposal on dev@.', 'What is the status of this issue? From the conversation it seems to me that Intel people think it is not an issue (or at least it is unavoidable) and Amazon people are concerned about this. Is that accurate? If so, how does it affect the 1.6 release - should I go ahead and make the RC despite this issue or is there active work going on to fix it?', '@TaoLv are you saying that we should keep the current config where we build the mkl flavor with openblas:\r\nmaster:\r\nhttps://github.com/apache/incubator-mxnet/blob/7895f93e67dc3e9da360f7a9c667e3c0f1e76c0f/make/staticbuild/linux_mkl.mk#L52\r\n1.6.x branch:\r\nhttps://github.com/apache/incubator-mxnet/blob/a576531836c5a5c4fb6dfbc944de94b619d6ccfa/make/pip/pip_linux_mkl.mk#L52\r\nOr are you proposing that it needs to be changed to build the mkl flavor with mkl blas instead of openblas?', 'mkl flavor packages are always built with USE_BLAS=openblas. We can change that to MKL BLAS if we are allowed to include dependency with category x license [1] into MXNet convenient releases. \r\n\r\n[1] https://www.apache.org/legal/resolved.html#category-x', ""Thanks @TaoLv \r\n\r\nI was able to rebuild and reproduce Nihal's results:\r\n```\r\n$ python deeplearning-benchmark/image_classification/image_classification.py --model resnet18_v2 --dataset cifar10 --mode symbolic --gpus 0 --epochs 25 --log-interval 50 --kvstore local --dtype='float32' --batch-size=64\r\nNamespace(batch_norm=False, batch_size=64, benchmark=False, dataset='cifar10', dtype='float32', epochs=25, gpus=0, kvstore='local', log_interval=50, lr=0.01, mode='symbolic', model='resnet18_v2', seed=123, use_pretrained=False, use_thumbnail=False, wd=0.0001)\r\nArchive:  cifar10.zip\r\n   creating: cifar/\r\n  inflating: cifar/test.rec          \r\n  inflating: cifar/test.lst          \r\n  inflating: cifar/train.lst         \r\n  inflating: cifar/train.rec         \r\n[05:12:00] src/io/iter_image_recordio_2.cc:178: ImageRecordIOParser2: data/cifar/train.rec, use 4 threads for decoding..\r\n[05:12:00] src/io/iter_image_recordio_2.cc:178: ImageRecordIOParser2: data/cifar/test.rec, use 4 threads for decoding..\r\n[05:12:00] src/executor/graph_executor.cc:1979: Subgraph backend MKLDNN is activated.\r\nINFO:root:Epoch[0] Batch [0-50]\tSpeed: 1583.17 samples/sec\taccuracy=0.285846\r\nINFO:root:Epoch[0] Batch [50-100]\tSpeed: 1508.38 samples/sec\taccuracy=0.388750\r\nINFO:root:Epoch[0] Batch [100-150]\tSpeed: 1623.32 samples/sec\taccuracy=0.433125\r\nINFO:root:Epoch[0] Batch [150-200]\tSpeed: 1613.61 samples/sec\taccuracy=0.443437\r\nINFO:root:Epoch[0] Batch [200-250]\tSpeed: 1642.54 samples/sec\taccuracy=0.455000\r\nINFO:root:Epoch[0] Batch [250-300]\tSpeed: 1625.45 samples/sec\taccuracy=0.506250\r\nINFO:root:Epoch[0] Batch [300-350]\tSpeed: 1620.83 samples/sec\taccuracy=0.515312\r\nINFO:root:Epoch[0] Batch [350-400]\tSpeed: 1637.02 samples/sec\taccuracy=0.537500\r\nINFO:root:Epoch[0] Batch [400-450]\tSpeed: 1635.96 samples/sec\taccuracy=0.550937\r\nINFO:root:Epoch[0] Batch [450-500]\tSpeed: 1641.26 samples/sec\taccuracy=0.574688\r\nINFO:root:Epoch[0] Batch [500-550]\tSpeed: 1643.39 samples/sec\taccuracy=0.569063\r\nINFO:root:Epoch[0] Batch [550-600]\tSpeed: 1639.69 samples/sec\taccuracy=0.573125\r\nINFO:root:Epoch[0] Batch [600-650]\tSpeed: 1644.01 samples/sec\taccuracy=0.598437\r\nINFO:root:Epoch[0] Batch [650-700]\tSpeed: 1644.10 samples/sec\taccuracy=0.614375\r\nINFO:root:Epoch[0] Batch [700-750]\tSpeed: 1644.86 samples/sec\taccuracy=0.601250\r\n```\r\n\r\nThe root cause of this performance regression is from the difference of BLAS libraries (switching from MKL BLAS to OpenBLAS) and removing the libiomp5.so library.\r\n\r\nNow the next step is to determine how we want to proceed. **Do we continue with OpenBLAS and take the hit on performance, or as @TaoLv mentioned can we use the category x licensed dependency?**"", 'Hi @TaoLv, @samskalicky, \r\n\r\nIntel MKL-DNN includes GEMM implementation that is comparable in terms of performance to Intel MKL. Is using `mkldnn_gemm` an option here?', ""@TaoLv @pengzhao-intel  Are there features in MXNet that require MKL as the BLAS library? I was able to find this line:\r\nhttps://github.com/apache/incubator-mxnet/blob/c82af38211dbf8356a4f3b35f023632c5bf880ae/src/operator/quantization/quantized_fully_connected.cc#L291\r\n\r\nIm rereading the previous comment and now im confused:\r\n> @oorqueda @samskalicky @leleamol As mentioned in [#16891 (comment)](https://github.com/apache/incubator-mxnet/issues/16891#issuecomment-557760466), I suspect that the regression is caused by the removal of libiomp5.so.\r\n> ...\r\n> If it's true, I don't think we have any choice to avoid the regression in pip packages as removing libiomp5.so is a requirement from Apache. Please refer to #15544. Thanks!\r\n\r\nIs the performance difference coming from using Intel's OpenMP library (libiomp5) or from using the MKL BLAS library itself and some routines like GEMM (as @vpirogov mentions)?"", ""@vpirogov @samskalicky Although MKL BLAS may also have positive impact to the case demonstrated above, I think the main gap is from different OMP runtimes. Setting `USE_BLAS=mkl` will help to pull in iomp5. Sure I'm going to replace `cblas_sgemm` and `cblas_sgemm_batch` with the MatMul primitive from DNNL once it's release, but I don't think that will help to fill the gap between gomp and iomp5.\r\n\r\n@samskalicky The code you referred will not be called in the ResNet18 case. Most of the computation in ResNet18 should go to DNNL."", '@TaoLv, is anything preventing us from using LLVM OpenMP runtime (libomp)? It is pretty much an open source version of libiomp5.', ""@vpirogov We can do that. My only concern is the interoperability of it. Also from MXNet perspective, we need move the release process from make to cmake which I don't think can be done within the schedule of the 1.6.0 release."", 'What do you mean by interoperability exactly?', '@TaoLv To get a closure on this topic, would it be possible to move the discussion forward\r\nThanks', '@vpirogov @ChaiBapchya The interoperability means:\r\n- how to pass the threading model to the dependencies of MXNet, eg. openblas, lapack, opencv, dnnl, mkl.\r\n- how to cooperate with other tools, eg. gomp based numpy or pytorch.', ""@TaoLv,\r\n\r\nYou are right that when different OpenMP runtimes are used in the same application there's a potential for interoperability issues. For this particular discussion it's important to note that the interoperability considerations are the same for libiomp5 and libomp. From that perspective using libomp does not introduce any additional issues in comparison to what MXNet used before (i.e. libiomp5). "", ""@vpirogov, yes, that's true. libomp and libiomp5 should have the same interoperability issue. From this perspective, the current release build solution (makefile + gomp) sounds a safer choice though it has relatively worse performance. I assume that gomp has better interoperability than the other two runtimes, maybe not true."", ""@samskalicky and all, \r\nThe problem is very clean now. I think we need to make a decision and going forward.\r\nTwo possible paths as below\r\n\r\n- Keep the build as-is with gomp\r\n   cons, stable and mature now\r\n   pros, a slight performance drop\r\n\r\n- Re-build with llvm by CMake\r\n   cons, same performance as before\r\n   pros, efforts on improving CMake path and potential interoperability issues\r\n\r\nFrom my side, I prefer the first option. What's your opinion?\r\n\r\n\r\n\r\n"", 'Hi @pengzhao-intel, in MXNet 2.0 Cmake is planned to be the only build system: https://github.com/apache/incubator-mxnet/projects/18#card-30594044\r\n\r\nWould that address the cons in Option 2?', ""> Hi @pengzhao-intel, in MXNet 2.0 Cmake is planned to be the only build system: https://github.com/apache/incubator-mxnet/projects/18#card-30594044\r\n> \r\n> Would that address the cons in Option 2?\r\n\r\nIt's a good chance to make the system clean :)"", 'closing since the fix has alrady updated with latest MKLDNN version.']","[""\r\npip install psutil gluoncv\r\nexport KMP_AFFINITY='granularity=fine,compact,1,0' && export OMP_NUM_THREADS=36\r\n"", ""\r\npython deeplearning-benchmark/image_classification/image_classification.py --model resnet18_v2 --dataset cifar10 --mode symbolic --gpus 0 --epochs 25 --log-interval 50 --kvstore local --dtype='float32' --batch-size=64\r\n"", ""\r\n/usr/local/lib/python2.7/dist-packages/mxnet/numpy_op_signature.py:61: UserWarning: Some mxnet.numpy operator signatures may not be displayed consistently with their counterparts in the official NumPy package due to too-low Python version 2.7.12 (default, Oct  8 2019, 14:14:10)\r\n[GCC 5.4.0 20160609]. Python >= 3.5 is required to make the signatures display correctly.\r\n  .format(str(sys.version)))\r\nNamespace(batch_norm=False, batch_size=64, benchmark=False, dataset='cifar10', dtype='float32', epochs=25, gpus=0, kvstore='local', log_interval=50, lr=0.01, mode='symbolic', model='resnet18_v2', seed=123, use_pretrained=False, use_thumbnail=False, wd=0.0001)\r\n[01:23:04] src/io/iter_image_recordio_2.cc:178: ImageRecordIOParser2: data/cifar/train.rec, use 4 threads for decoding..\r\n[01:23:04] src/io/iter_image_recordio_2.cc:178: ImageRecordIOParser2: data/cifar/test.rec, use 4 threads for decoding..\r\n[01:23:04] src/executor/graph_executor.cc:1936: Subgraph backend MKLDNN is activated.\r\nINFO:root:Epoch[0] Batch [0-50] Speed: 892.55 samples/sec       accuracy=0.288909\r\nINFO:root:Epoch[0] Batch [50-100]       Speed: 1390.86 samples/sec      accuracy=0.390625\r\nINFO:root:Epoch[0] Batch [100-150]      Speed: 987.58 samples/sec       accuracy=0.421250\r\nINFO:root:Epoch[0] Batch [150-200]      Speed: 1407.58 samples/sec      accuracy=0.440312\r\nINFO:root:Epoch[0] Batch [200-250]      Speed: 1310.79 samples/sec      accuracy=0.468438\r\nINFO:root:Epoch[0] Batch [250-300]      Speed: 1331.61 samples/sec      accuracy=0.500313\r\nINFO:root:Epoch[0] Batch [300-350]      Speed: 1420.91 samples/sec      accuracy=0.522500\r\nINFO:root:Epoch[0] Batch [350-400]      Speed: 1469.40 samples/sec      accuracy=0.527813\r\nINFO:root:Epoch[0] Batch [400-450]      Speed: 1195.95 samples/sec      accuracy=0.550312\r\nINFO:root:Epoch[0] Batch [450-500]      Speed: 1146.35 samples/sec      accuracy=0.573125\r\nINFO:root:Epoch[0] Batch [500-550]      Speed: 1543.27 samples/sec      accuracy=0.568125\r\nINFO:root:Epoch[0] Batch [550-600]      Speed: 1251.45 samples/sec      accuracy=0.574688\r\nINFO:root:Epoch[0] Batch [600-650]      Speed: 1303.13 samples/sec      accuracy=0.602187\r\nINFO:root:Epoch[0] Batch [650-700]      Speed: 1283.89 samples/sec      accuracy=0.618750\r\nINFO:root:Epoch[0] Batch [700-750]      Speed: 955.70 samples/sec       accuracy=0.607187\r\nINFO:root:Epoch[0] Train-accuracy=0.514007\r\n""]",[],1,1
64,incubator-mxnet,3325,closed,Low validation accuracy if I split the training data manually when training with multi-machine,"I training my model with a mpi cluster of 10 machines.  Because the training dataset is very large, distributing the whole  to each machine requires much time and space. So I manually split the  into 10 non-overlap text file such as  . Then I use  to make 10 ImageRecordIO dataset.

When training with multi machine, in each machine it will download  and use it as the source of training iterator. I don't forget to change the parameters  and    as  of the training ImageRecordIter. 
I don't change the validation dataset. I distribute the complete  to each machine.

So I believe the training procedure should be roughly same as when I use only one . 
But the result is disappointing. The training accuracy curve is good, even slightly better than previous. However the validation curve is much worse. 
![image](https://cloud.githubusercontent.com/assets/3807357/18622871/2e7c70e8-7e68-11e6-9d02-0ef70b3edfcf.png)
The blue curves are the training and val curves when I use one complete  while red curves are those when using splited ....
Is there any mistake that I may have?
",,"['@mli \n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],"['train.rec', 'train.lst', 'train_0.lst, train_1.lst....', 'im2rec.py', 'train_${OMPI_COMM_WORLD_RANK}.rec', 'num_parts', 'part_index', '1, 0', 'val.rec', 'train.rec', 'train.rec', 'train_0.rec, train_1.rec']",1,0
65,incubator-mxnet,10839,open,Execute all runs in CI without cache as part of nightly,"Instead of using the cached Dockerfiles, make a run that downloads and installs everything from scratch. This ensure that all third party dependencies are actually still valid.

See https://github.com/apache/incubator-mxnet/issues/10837 for an example",CI Feature request,[':+1:'],[],[],0,0
66,incubator-mxnet,9335,open,mxnet.random.seed() doesn't work for mxnet.gluon.data.DataLoader with shuffle=True,"I want to use the same sequence of mini-batches to compare the performance of different optimizers.
I used ""mxnet.random.seed(1)"".
However, it only works for the initializer.
For mxnet.gluon.data.DataLoader with shuffle=True, it needs an extra ""import random; random.seed(1);""",Gluon,['I think one solution is to always use `numpy.random`. And we will only need to use `np.random.seed(...)` at the beginning.'],[],[],0,0
67,incubator-mxnet,14704,open,[clojure][documentation] improve docstrings,"Some docstrings can still be improved for better user experience. Adding parameter descriptions and examples in docstrings.

Example:
modopts-mapkvstoreoptimizersgdreset-optimizertruerescaleGradidx2nameforce-initfalse

Below is a list of namespaces that still need to be improved:

- [ ] 
- [ ] 
- [ ] 
- [ ] 
- [x] 
- [ ] 
- [ ] 
- [ ] 
- [x] 
- [ ] 
- [ ] 
- [ ] 
- [x] 
- [ ] 
- [ ] 
- [ ] ",Clojure Doc v1.x,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Doc', '@mxnet-label-bot add [clojure, doc]', '@mxnet-label-bot add [Good First Issue]']",[],"['', 'clojure\r\n(defn init-optimizer\r\n  ""Install and initialize optimizers.\r\n    ', ': Module\r\n    ', ' {\r\n      ', ': string - Default is \\""local\\""\r\n      ', ': Optimizer - Default is ', '\r\n      ', ': boolean - Default is ', '\r\n          Indicating whether we should set ', ' & ', ' for\r\n          optimizer according to executorGroup.\r\n      ', ': boolean - Default is ', '\r\n          Indicating whether we should force re-initializing the optimizer\r\n          in the case an optimizer is already installed.\r\n   Ex:\r\n     (init-optimizer {:optimizer (optimizer/sgd {:learning-rate 0.1})})""\r\n  ([mod {:keys [kvstore optimizer reset-optimizer force-init] :as opts\r\n         :or {kvstore ""local""\r\n              optimizer (optimizer/sgd)\r\n              reset-optimizer true\r\n              force-init false}}]\r\n   (util/validate! ::init-optimizer-opts opts ""Invalid init-optimizer options"")\r\n   (doto mod\r\n     (.initOptimizer kvstore optimizer reset-optimizer force-init)))\r\n  ([mod]\r\n   (init-optimizer mod {})))\r\n', '', 'callback.clj', 'context.clj', 'executor.clj', 'eval_metric.clj', 'image.clj', 'infer.clj', 'initializer.clj', 'io.clj', 'module.clj', 'ndarray.clj', 'optimizer.clj', 'profile.clj', 'random.clj', 'symbol.clj', 'util.clj', 'visualization.clj']",0,0
68,incubator-mxnet,16431,open,[RFC] MXNet Multithreaded Inference Interface,"Thanks to @nswamy for his inputs and design discussions related to this project and @frankfliu for explaining the requirements and the use case from customer perspective.

# Problem Statement

One of the big un-catered for use cases in MXNet is loading a model and being able to run parallel inference on the model from multiple threads while sharing the parameters. There are multiple user requests for the same [[1]](https://github.com/apache/incubator-mxnet/issues/3946). There also has been a lot of confusion around the current state of MXNet with respect to thread safety.

This doc attempts to address three things : 

1. Tries to clarify the current state of MXNet with respect to thread safety.
2. Tries to give an idea of the benefits to expect from adding this feature.
3. Attempts to solve the problem of parallel inference by providing a multi-threaded inference API ( C APIs and frontend APIs in CPP and Python), 

# Current State of MXNet Thread Safety

## MXNet Dependency Engine Thread Safety

Examining MXNet dependency engine code, it looks like it was designed  to be thread safe. Tried to push Convolution op from multiple threads into MXNet Engine, to see if there are any issues with thread safety. Used CPP Package for the same. The script is provided here : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/cpp-package/example/multithreading_engine_push_mxnet_op.cpp



The script pushes Convolution op to the engine from multiple threads. You can verify the correctness of the op with this script : 
https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/test_cached_op_ts_check.py



## MXNet Graph Executor Thread Safety

Removed NaiveEngine only restriction for C Predict API and tried to run multi threaded inference with C Predict API using ThreadedEngine by commenting the check : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/src/c_api/c_predict_api.cc

When running this example the program core dumps with memory leaks in Graph Executor Bind. This shows that graph executor is not thread safe. 

## Cached Op (Gluon Backend) Thread Safety

Try to create cached op in the main thread and spawn multiple threads to invoke the same cached op inside each of the threads. Here is the script which does the same : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/cpp-package/example/multithreading_engine_push_cached_op.cpp



Multiple failures seen when I run this: one is in the dmlc ThreadLocalStore [[2]](https://github.com/dmlc/dmlc-core/issues/571),  other is in MXPlanMemory, retrieving forward_ref_count attribute. These errors are because of race condition w.r.t reading and writing of shared states in CachedOp.

# Proposed Solution

### Additions (Prioritized for 1.6)

Proposing to add a minimal thread safe cached op for inference which will be the following :
1. Similar to cached op, except it supports only inference use cases. 
2. Doesn’t support inlining, dynamic shapes, bulking, static alloc. 
3. Use static thread_local variables for GraphInfo which maintains the fwd_graph state, buff which maintains all ndarray states and for op_states. [ There is scope for additional optimization here w.r.t separation of buffers for inputs and params]
4. The above addition means that we can instantiate only one thread safe cached op per process. The frontend API for SymbolBlockThreadSafe needs to be a singleton because of this limitation.

### C API Changes (Prioritized for 1.6)

Adding a new thread_safe flag for MXCreateCachedOpEx. When set to true this should create a thread_safe cached op instead of a cached op.



Add similar thread_safe flag flags to Invoke and Free to invoke thread safe cached op versions instead of the default versions. 



#### Please see the PoC here for details:

1. Thread Safe Cached Op Code : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/src/imperative/cached_op_threadsafe.h , https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/src/imperative/cached_op_threadsafe.cc
2. Example Code for invoking Cached Op inference from multiple threads : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/cpp-package/example/multithreading_engine_push_cached_op.cpp 



#### Use Cases Tested:

1. Create cached op with a single op (Convolution) from main thread. Spawn additional threads and invoke cached op from each thread.
2. Create cached op with a full model (resnet-18) from main thread. Spawn additional threads and invoke cached op from each thread.

### CPP Frontend Changes (Priority for 1.6)

1. Add a singleton SymbolBlock (ThreadSafe version) with an imports API like in python, targeted for Inference.
2. Params will be loaded using ndarray module.
3. Initially only one context is supported but this can be extended to multi context.
4. Forward call will invoke CachedOp passing the input ndarrays and param ndarrays.
5. Initially sparse storage types won’t be supported and casting won’t be supported.
6. Will be added to the contrib API.

@access2rohit will be helping me with the CPP API changes.

### Python Frontend Changes (Lower Priority, Post 1.6)

1. Add a SymbolBlock (threadsafe version, singleton) inheriting the SymbolBlock with imports and forward API. 
2. Here is a PoC: https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/python/mxnet/gluon/contrib/block.py  and an example of how to call it : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/test_symbolblock_cached_op_ts.py
3. The PoC is currently not functioning and hangs randomly. This could be because of WaitForVar and WaitForAll thread safety issues and/or the cross device copy thread safety issues and/or issues with usage of python thread local. This requires some more investigation.

# Existing Issues

1. dmlc-core ThreadLocalStore issue[[2]](https://github.com/dmlc/dmlc-core/issues/571) . Reverting back to MX_THREAD_LOCAL fixes the issue but need to explore additional downsides of reverting back. (HIGH PRIORITY FOR 1.6) : Addressed in (https://github.com/apache/incubator-mxnet/pull/16526)
2. WaitForVar and WaitForAll are not thread safe. (HIGH PRIORITY FOR 1.6). [[3]](https://github.com/apache/incubator-mxnet/issues/16434)
3. Python API Issues mentioned above. (LOWER PRIORITY, POST 1.6).

# Expected Benefits

One big benefit is being able to run inference on the same model with shared params from multiple threads. Current approach is to use multiprocessing library and import mxnet in each process. This saves a lot of memory footprint and improves the throughput for inference on a single machine. To obtain some numbers I wrote a multiprocessing script in python to load model and run inference from multiple processes. 

Please see here for the python script : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/test_symbolblock_cached_op_ts.py
This runs out of memory with 12 parallel inferences. 

When running the same model inference on CPP, please see example here : https://github.com/anirudh2290/mxnet/tree/multithreaded_inference_poc/cpp-package/example/multithreading_engine_push_cached_op_full_model.cpp



This is able to run more than 960 parallel inferences though there is an increased latency with higher number of parallel inferences.


# Model Coverage

|Models Tested|MKLDNN|CUDNN|NO-CUDNN|
| --- | --- | --- | --- |
| resnet-18 | Yes | Yes | Yes |

This is a work in progress list and more models will be added to this list.

# What will not be supported for 1.6 ?

Since, this is a new interface where many things can go wrong, we are starting small here and will incrementally add support. Lot of these features may just work but requires some effort with verification and won't be feasible for 1.6.

1. Only operators tested with the existing model coverage are supported. Other operators (stateful operators, custom operators) not supported.
2. Only dense storage types supported currently.
3. Multi GPU inference not supported currently.
4. Instantiating multiple instances of SymbolBlockThreadsafe is not supported. Can run parallel inference only on one model per process.
5. dynamic shapes not supported.
6. static_alloc and static_shape not supported.
7. Bulking of ops is not supported.
8. This is only for inference use cases, backward pass/training use cases not supported.
9. graph rewrites with subgraph api currently not supported.
10. Python Frontend Changes


# References 

1. https://github.com/apache/incubator-mxnet/issues/3946
2. https://github.com/dmlc/dmlc-core/issues/571
3. https://github.com/apache/incubator-mxnet/issues/16434
",Feature request RFC Thread Safety,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended label(s): Feature', ""Great proposal!\r\n\r\nFew questions from my end:\r\n\r\n1. Will the new C-API functions be threadsafe in general? Speak, I can invoke them at any point in time from any thread without the need of a lock, sticky-thread or a thread hierarchy? (I'm thinking of the thread-safety being done on the backend level)\r\n2. Will this also support the GPU use-case? Speak, the parameters are only copied into GPU memory once in the same fashion as you're describing for the CPU?\r\n3. Do you think there's a path forward to make all inference-related C-APIs threadsafe instead of splitting off another execution branch?"", ""Thanks @marcoabreu ! \r\n\r\n> Will the new C-API functions be threadsafe in general? Speak, I can invoke them at any point in time from any thread without the need of a lock, sticky-thread or a thread hierarchy? (I'm thinking of the thread-safety being done on the backend level)\r\n\r\nThe issue I found with C API thread safety especially with the cached op use case was the ThreadLocalStore. If we fix this issue then C APIs related to CreateCachedOp and InvokeCachedOp should be threadsafe.\r\n\r\n>  Will this also support the GPU use-case? Speak, the parameters are only copied into GPU memory once in the same fashion as you're describing for the CPU?\r\n\r\nThis should still support the single GPU use-case for 1.6. Multi GPU inference use case requires more verification at the cached op level .\r\n\r\n> Do you think there's a path forward to make all inference-related C-APIs threadsafe instead of splitting off another execution branch?\r\n\r\nI don't think we have such a strict split between inference and training APIs at the C API level. For example for gluon cached op we call InvokeCachedOp for both training and Inference.\r\n\r\nBut if I rephrase your question to:\r\nWill I be able to do multi threaded inference from every frontend API which I can use to do inference today ?  \r\nRight now, I am targeting only gluon since most users have been directed towards gluon. The other ways are using module, symbolic and using C Predict API. To support these two frontend APIs requires the graph executor to be thread safe.  This would definitely be a great add for MXNet since it would ensure that they can do multi-threaded inference from any of these APIs in MXNet, but not something I have planned for currently."", '@mxnet-label-bot , add [Feature]', 'Hi @anirudh2290, what is the status of this proposal? When do you think changes will be ready?', ""@ptrendx I am trying to open a PR by Friday. On the status : the two prereqs issues https://github.com/dmlc/dmlc-core/pull/573 and https://github.com/apache/incubator-mxnet/issues/16434 have been better understood and fixed/worked around. I have made C API and backend changes and currently still testing it. \r\n\r\nBecause of time and resource constraints I won't be able to add the CPP frontend changes (which has been mentioned in this PR as targeted for 1.6) in this proposal but only C API changes, backend changes and tests/verification."", ""@anirudh2290 Just see this RFC. Let me share what I've done in multithreaded infererce, I think it's the only viable way now in mxnet.\r\n\r\nI've deployed many models with scala API, and run them in multiple threads. The whole system has run smoothly in production environment for more than 2 months.\r\n\r\nThe backend of inference is graph executor, which is created for each thread with shared model parameters. The executors can be dynamically reshaped in each thread independently according to the shape of the data input.\r\n\r\nLike what's mentioned above, the dependency engine is not thread safe, so if you run it in threaded engine, dead lock and core dump will happen. Therefore, naive engine is the only option left. Without the dependency scheduling, any write dependency on model parameters is likely to be executed simultaneously and mess the internal data. If mkldnn is used to accelerate inference, you will get non-deterministic results per inference because mxnet stealthily reorder the data in ndarray (write dependency involved) for mkldnn operators. I've used a temporary method to address this issue which is not suitable for an official PR.\r\n\r\nMultithreaded inference should be used with caution. Sharing model parameters can reduce the memory footprint in your program, but a lot of memory usage is consumed by global resources (temporary workspace, random number generator, ...) or op cache for mkldnn which are stored in static thread_local variables. So **thread number** is the most important factor for memory footprint, any thread involving mxnet operation, be it any trivial imperative invoking of operators, will incur memory overhead by creating its own set of thread_local variables. I've spent so much time tracking down memory leak and the best solution is to limit thread number.\r\n\r\nA new method to do multithreaded inference by threaded engine is much welcomed here. It will solve the above issues automatically and ensure result correctness by enforcing dependency checking."", ""Thanks for the thoughtful and valuable comments @arcadiaphy.\r\n\r\n> I've deployed many models with scala API, and run them in multiple threads. The whole system has run smoothly in production environment for more than 2 months.\r\n\r\n> The backend of inference is graph executor, which is created for each thread with shared model parameters. The executors can be dynamically reshaped in each thread independently according to the shape of the data input.\r\n\r\nYes, if I am not mistaken this is very similar to how the C Predict API supports multi threaded inference today.\r\n\r\n> Like what's mentioned above, the dependency engine is not thread safe, so if you run it in threaded engine, dead lock and core dump will happen. Therefore, naive engine is the only option left. Without the dependency scheduling, any write dependency on model parameters is likely to be executed simultaneously and mess the internal data. If mkldnn is used to accelerate inference, you will get non-deterministic results per inference because mxnet stealthily reorder the data in ndarray (write dependency involved) for mkldnn operators. I've used a temporary method to address this issue which is not suitable for an official PR.\r\n\r\nThis is a very useful point. In my proposal, I was concentrating mostly on ThreadedEngine and not NaiveEngine. Though, recently I added tests for NaiveEngine in my PR and everything seemed to be working fine. Till now I have not been able to reproduce the correctness issue that you mention with MKLDNN (hidden write) and NaiveEngine, but it could be because the Reorder doesnt happen in the spawned thread. Here is my test: https://github.com/apache/incubator-mxnet/pull/16654/files#diff-1335fbaf3930b1438d9be18edb07a1a6R1384 . Not sure, if something changed with MKLDNN 1.0 or my test doesnt catch that use case, will dig more into this. \r\n\r\n\r\n> Multithreaded inference should be used with caution. Sharing model parameters can reduce the memory footprint in your program, but a lot of memory usage is consumed by global resources (temporary workspace, random number generator, ...) or op cache for mkldnn which are stored in static thread_local variables. So thread number is the most important factor for memory footprint, any thread involving mxnet operation, be it any trivial imperative invoking of operators, will incur memory overhead by creating its own set of thread_local variables. I've spent so much time tracking down memory leak and the best solution is to limit thread number.\r\n\r\n> A new method to do multithreaded inference by threaded engine is much welcomed here. It will solve the above issues automatically and ensure result correctness by enforcing dependency checking.\r\n\r\nYes, the earlier approach which has one graph executor per thread, may have a lot of memory consumption for global resources. Sharing the cached op will alleviate the pain. As you know, we still have a lot of customers using graph executor as the backend. Would be a great add, if you are interested to contribute towards making graph executor also thread safe for inference use cases."", '@anirudh2290 hi, I use mutithreading C++ API and find that the change between NDArrayHandle* to NDArray cost too much time(about 50ms). My prvious pred time about the model just cost 20-30ms. Is it normal?', 'though there exsists async, it really cost too much that against my will to use multithread', 'cc @josephevans @Zha0q1 ', 'I think is there any method can be replaced with data output, like vector<mx_float>.', 'ok, I have found float* format output width method MxPred... works.']","['\r\n./build/cpp-package/example/multithreading_engine_push_mxnet_op 2\r\n', '\r\npython3 test_cached_op_ts_check.py\r\n', '\r\n# Usage\r\n./build/cpp-package/example/multithreading_engine_push_cached_op <num_threads> <context> <thread_safe>\r\n\r\n# Example\r\n./build/cpp-package/example/multithreading_engine_push_cached_op 20 cpu 0 // uses cached op available in master\r\n', '\r\n  /*!\r\n   * \\brief create cached operator\r\n   */\r\n  MXNET_DLL int MXCreateCachedOpEx(SymbolHandle handle,\r\n                                   int num_flags,\r\n                                   const char** keys,\r\n                                   const char** vals,\r\n                                   CachedOpHandle *out,\r\n                                   bool thread_safe = false);\r\n', ""\r\n  /*!\r\n   * \\brief invoke a cached op\r\n   * \\param handle the handle to the cached op\r\n   * \\param num_inputs number of input NDArrays\r\n   * \\param inputs input NDArrays\r\n   * \\param num_outputs number of output NDArrays\r\n   * \\param outputs output NDArrays\r\n   * \\param out_stypes output ndarrays' stypes\r\n   * \\param thread_safe whether to invoke thread safe version of cached op.\r\n   * \\return 0 when success, -1 when failure happens\r\n   */\r\n    \r\n      \r\n  MXNET_DLL int MXInvokeCachedOpEx(CachedOpHandle handle,\r\n                                   int num_inputs,\r\n                                   NDArrayHandle *inputs,\r\n                                   int *num_outputs,\r\n                                   NDArrayHandle **outputs,\r\n                                   const int** out_stypes,\r\n                                   bool thread_safe = false);\r\n\r\n    \r\n                                   \r\n  /*!\r\n   * \\brief free cached operator\r\n   */\r\n  MXNET_DLL int MXFreeCachedOp(CachedOpHandle handle, bool thread_safe = false);\r\n"", '\r\n# Usage\r\n./build/cpp-package/example/multithreading_engine_push_cached_op <num_threads> <context> <thread_safe>\r\n\r\n# Example\r\n./build/cpp-package/example/multithreading_engine_push_cached_op 20 cpu 1\r\n', '\r\n# Usage \r\n./build/cpp-package/example/multithreading_engine_push_cached_op_full_model <num_threads> <context>\r\n\r\n# Example\r\n./build/cpp-package/example/multithreading_engine_push_cached_op_full_model 20 cpu\r\n']",[],0,0
69,incubator-mxnet,7445,open,Using cuDNN for CTC Loss,"@piiswrong, @szha: Now that cuDNN 7 supports CTC loss, perhaps we should discard the current GPU implementation in contrib.ctc_loss (adapted from the WarpCTC implementation) and only use cuDNN for GPU? The main reasons:
1) it requires maintenance effort to ensure the GPU implementation works on new GPU architectures, requiring careful updating of dependencies (like modern gpu). 
2) Users are still reporting problems with memset issues when using the WarpCTC plugin (#6121)

I don't think the maintenance effort is worthwhile if almost every single user training with CUDA will have cuDNN.

What are your thoughts?

",Operator Roadmap,"[""Thanks for raising this, @sbodenstein. I'm working on using the cudnn7 implementation of CTC for GPU."", '@szha: do you agree that we should remove the WarpCTC CUDA implementation?', ""@sbodenstein I agree. There is only one catch. It seems that the current WarpCTC supports variable-length inputs whereas cudnn7 only has the intention to support it. To elaborate, the current cudnn7 CTC API for getting workspace size looks like this:\r\n```\r\ncudnnStatus_t CUDNNWINAPI cudnnGetCTCLossWorkspaceSize(\r\n                                cudnnHandle_t                       handle,\r\n                                const cudnnTensorDescriptor_t       probsDesc,       /* Tensor descriptor for probabilities, the dimensions are T,N,A (T is the timing steps, N is the mini batch size, A is the alphabet size) */\r\n                                const cudnnTensorDescriptor_t       gradientsDesc,   /* Tensor descriptor for gradients, the dimensions are T,N,A. To compute costs only, set it to NULL */\r\n                                const int                          * labels,         /* labels, in CPU memory */\r\n                                const int                          * labelLengths,   /* the length of each label, in CPU memory */\r\n                                const int                          * inputLengths,   /* the lengths of timing steps in each batch, in CPU memory */\r\n                                cudnnCTCLossAlgo_t                  algo,            /* algorithm selected, supported now 0 and 1 */\r\n                                cudnnCTCLossDescriptor_t            ctcLossDesc,\r\n                                size_t                             *sizeInBytes );   /* pointer to the returned workspace size */\r\n```\r\nHowever, if I give any `*inputLengths` that is different from T, it throws an `CUDNN_STATUS_BAD_PARAM` error. Reading the doc, it has a note saying that this error is thrown if:\r\n```\r\n‣ The inputLengths do not agree with the first dimension of probsDesc.\r\n```\r\n...so my guess is that this argument is left there so that variable input lengths will be supported going forward, because asking for a list of Ts doesn't make much sense otherwise.\r\n\r\nBack to whether we should remove the WarpCTC implementation, I think we need to first clarify with cudnn team on when the `*inputLengths` can support variable input lengths, and remove the WarpCTC GPU implementation when that becomes available."", 'Ah, that is annoying! One other limitation I noticed: `CUDNN_STATUS_BAD_PARAM` is also thrown when \r\n```\r\nThe labelLengths is greater than 256.\r\n```\r\nwhilst WarpCTC:\r\n```\r\nThe CUDA implementation supports a maximum label length of 639 (timesteps are unlimited).\r\n', 'Good catch. Let me reflect this in the PR as well.', 'so, the ctc of cudnn7 supports neither variable lengths inputs nor longer labellengths than 256.', '@szha: one annoying thing about you adding cuDNN support: if you build against cuDNN (which you always usually want to do), you automatically have to use the cuDNN WarpCTC implementation, which you might not want if you want to support variable length inputs. ', 'Current implementation still includes the WarpCTC implementation in the GPU version and only enables cudnn version when all input requirements are met, since the cudnn version is strictly more limited.', 'Unfortunately I have to turn cudnn CTC off because of the API design. I have requested API changes to nv people and hopefully we could incorporate that once they change the API.', '> only enables cudnn version when all input requirements are met, since the cudnn version is strictly more limited.\r\n\r\n@szha: why was that not enough? Why do you need to completely turn it off?', ""The input length note being supported means that there's no way for me to enforce consistency between CPU and GPU implementation. cudnn version also doesn't reset the padding area gradients to zero, which can cause instability in training. It's too much of a risk to leave it be."", '@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', 'cudnn integration for ctc requires action from cudnn team in improving the API.']",[],[],0,0
70,incubator-mxnet,9937,open,fatal error: cblas.h: No such file or directory,"My system is Ubuntu 16.04. 
when I run code 

I got the error 


g++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -O3 -I/home/duoduo/github/mxnet/mshadow/ -I/home/duoduo/github/mxnet/dmlc-core/include -fPIC -I/home/duoduo/github/mxnet/nnvm/include -Iinclude -funroll-loops -Wno-unused-variable -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/local/include/opencv -I/usr/local/include -fopenmp -DMSHADOW_USE_CUDNN=1  -I/home/duoduo/github/mxnet/cub -DMXNET_USE_NVRTC=0 -MMD -c src/operator/nn/softmax.cc -o build/src/operator/nn/softmax.o
g++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -O3 -I/home/duoduo/github/mxnet/mshadow/ -I/home/duoduo/github/mxnet/dmlc-core/include -fPIC -I/home/duoduo/github/mxnet/nnvm/include -Iinclude -funroll-loops -Wno-unused-variable -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/local/include/opencv -I/usr/local/include -fopenmp -DMSHADOW_USE_CUDNN=1  -I/home/duoduo/github/mxnet/cub -DMXNET_USE_NVRTC=0 -MMD -c src/operator/mkl/mkl_memory.cc -o build/src/operator/mkl/mkl_memory.o
g++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -O3 -I/home/duoduo/github/mxnet/mshadow/ -I/home/duoduo/github/mxnet/dmlc-core/include -fPIC -I/home/duoduo/github/mxnet/nnvm/include -Iinclude -funroll-loops -Wno-unused-variable -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/local/include/opencv -I/usr/local/include -fopenmp -DMSHADOW_USE_CUDNN=1  -I/home/duoduo/github/mxnet/cub -DMXNET_USE_NVRTC=0 -MMD -c src/operator/tensor/elemwise_binary_broadcast_op_basic.cc -o build/src/operator/tensor/elemwise_binary_broadcast_op_basic.o
g++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -O3 -I/home/duoduo/github/mxnet/mshadow/ -I/home/duoduo/github/mxnet/dmlc-core/include -fPIC -I/home/duoduo/github/mxnet/nnvm/include -Iinclude -funroll-loops -Wno-unused-variable -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/local/include/opencv -I/usr/local/include -fopenmp -DMSHADOW_USE_CUDNN=1  -I/home/duoduo/github/mxnet/cub -DMXNET_USE_NVRTC=0 -MMD -c src/operator/tensor/elemwise_binary_op_extended.cc -o build/src/operator/tensor/elemwise_binary_op_extended.o
In file included from /home/duoduo/github/mxnet/mshadow/mshadow/tensor.h:16:0,
                 from include/mxnet/base.h:13,
                 from src/operator/nn/./../mxnet_op.h:10,
                 from src/operator/nn/./softmax-inl.h:11,
                 from src/operator/nn/softmax.cc:6:
/home/duoduo/github/mxnet/mshadow/mshadow/./base.h:136:23: fatal error: cblas.h: No such file or directory
compilation terminated.
Makefile:207: recipe for target 'build/src/operator/nn/softmax.o' failed
make: *** [build/src/operator/nn/softmax.o] Error 1
make: *** Waiting for unfinished jobs....
In file included from /home/duoduo/github/mxnet/mshadow/mshadow/tensor.h:16:0,
                 from include/mxnet/./base.h:13,
                 from include/mxnet/operator.h:19,
                 from src/operator/mkl/../operator_common.h:13,
                 from src/operator/mkl/mkl_memory.cc:22:
/home/duoduo/github/mxnet/mshadow/mshadow/./base.h:136:23: fatal error: cblas.h: No such file or directory
compilation terminated.
Makefile:207: recipe for target 'build/src/operator/mkl/mkl_memory.o' failed
make: *** [build/src/operator/mkl/mkl_memory.o] Error 1
In file included from /home/duoduo/github/mxnet/mshadow/mshadow/tensor.h:16:0,
                 from include/mxnet/./base.h:13,
                 from include/mxnet/operator_util.h:24,
                 from src/operator/tensor/./elemwise_unary_op.h:9,
                 from src/operator/tensor/elemwise_binary_broadcast_op_basic.cc:6:
/home/duoduo/github/mxnet/mshadow/mshadow/./base.h:136:23: fatal error: cblas.h: No such file or directory
compilation terminated.
Makefile:207: recipe for target 'build/src/operator/tensor/elemwise_binary_broadcast_op_basic.o' failed
make: *** [build/src/operator/tensor/elemwise_binary_broadcast_op_basic.o] Error 1
In file included from /home/duoduo/github/mxnet/mshadow/mshadow/tensor.h:16:0,
                 from include/mxnet/./base.h:13,
                 from include/mxnet/operator_util.h:24,
                 from src/operator/tensor/./elemwise_unary_op.h:9,
                 from src/operator/tensor/elemwise_binary_op_extended.cc:6:
/home/duoduo/github/mxnet/mshadow/mshadow/./base.h:136:23: fatal error: cblas.h: No such file or directory
compilation terminated.
Makefile:207: recipe for target 'build/src/operator/tensor/elemwise_binary_op_extended.o' failed
make: *** [build/src/operator/tensor/elemwise_binary_op_extended.o] Error 1


how can I solve this problem",Build Installation,"['You need to install openblas. Please follow the steps here for building from source.\r\nhttp://mxnet.incubator.apache.org/install/index.html\r\nTry this \r\n`sudo apt-get install libopenblas-dev`.\r\n', 'good issue!', '@zhengduoru Did installing openblas help resolve your issue ? \r\nIf it did resolve your issue, please feel free to close the issue :) ', '@mxnet-label-bot [Pending Requester Info]']",[],['make -j4  USE_OPENCV=1 USE_BLAS=openblas USE_CUDA=1 USE_CUDA_PATH=/usr/local/cuda USE_CUDNN=1'],0,0
71,incubator-mxnet,13743,open,Flaky test in windows GPU CI,"In the windows-GPU stage of the CI, different  tests fail.

 fails on commit  but passes after updating README
https://github.com/apache/incubator-mxnet/pull/13595
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Fwindows-gpu/detail/PR-13595/9/pipeline


http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Fwindows-gpu/detail/PR-13681/37/pipeline

Seems to only occur on windows GPU build.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
(Brief description of the problem in no more than 2 sentences.)

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.
",CI Flaky Test,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: CI, Test, Flaky', '@mxnet-label-bot  add [CI, Test, Flaky]', 'Another test which failed on Windows GPU : \r\n```test_operator_gpu.test_multinomial_generator```\r\n\r\nThe failure is here on Jenkins : http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Fwindows-gpu/detail/PR-13678/24/pipeline \r\n\r\nLike @azai91 mentioned, the failure happens on Windows GPU only and is flaky in nature.']",[],"['test_random', 'test_random.test_exponential_generator', '6a293fc', 'test_random.test_uniform_generator', '', '\r\nWhat to do:\r\n1. Download the diagnosis script from https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/diagnose.py\r\n2. Run the script using ', ' and paste its output here.\r\n\r\n', '', 'java -version', 'mvn -version', 'scala -version', 'sessionInfo()', 'git rev-parse HEAD']",0,0
72,incubator-mxnet,11843,open,No CI for tools/coreml package,"## Description
The mxnet-to-coreml package under tools/coreml does not have CI and new releases that breaks this package directly affects its customers. (See issue [10349](https://github.com/apache/incubator-mxnet/issues/10349)). We should add tests of this package to our CI system.

## Environment info (Required)



Package used (Python/R/Scala/Julia):
Python

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
g++

MXNet commit hash:
e4134c8270c1b944278b1e0331313074b1d97cc0",CI Converter CoreML Test,"['@sandeep-krishnamurthy Please help to label this issue _CI_', '@apeforest are there tests that can be tested on CI?', '#11841 ', '@nswamy I have created another [issue](https://github.com/apache/incubator-mxnet/issues/11841) to update/add tests for that package. ', '@pracheer ', 'Created a [JIRA](https://issues.apache.org/jira/browse/MXNET-708) ticket to track this issue. I will work on this task with help from @marcoabreu ', 'I believe this PR : https://github.com/apache/incubator-mxnet/pull/11952 will also track this issue. ']","[""\r\n----------Python Info----------\r\n('Version      :', '2.7.15')\r\n('Compiler     :', 'GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)')\r\n('Build        :', ('default', 'May  1 2018 16:44:37'))\r\n('Arch         :', ('64bit', ''))\r\n------------Pip Info-----------\r\n('Version      :', '10.0.1')\r\n('Directory    :', '/Users/lnyuan/.virtualenvs/mxnet2/lib/python2.7/site-packages/pip')\r\n----------MXNet Info-----------\r\n('Version      :', '1.3.0')\r\n('Directory    :', '/Users/lnyuan/work/incubator-mxnet/python/mxnet')\r\nHashtag not found. Not installed from pre-built package.\r\n""]",[],0,0
73,incubator-mxnet,14484,open,Odd behaviour with 'device' kvstore and CUDA illegal memory access errors,"## Description
Training the FCN model from gluon-cv over 2 GPUs I encounter different but perhaps related issues depending on which kind of kvstore I use ('local' and 'device'). (I don't think this is a gluon-cv issue.) Test script included.

## Environment info (Required)


Package used (Python/R/Scala/Julia):
Python

## Error Message:
### If kvstore is 'local':

### If kvstore is 'device':
There is no error, the process hangs when trying to push to the kvstore in . The example script below includes some debug code to narrow down where the process hangs.

Note: the specific layer it stops on varies.

## Minimum reproducible example

## Steps to reproduce
1. Run the above script, setting the kvstore type to either  or .

## What have you tried to solve it?
1. Disabling gc at beginning of epoch and re-enabling at end, seemed to work in one similar-seeming issue, but made no difference for me.

Note: I still get the same result when not using a sub-classed version of gluon.Trainer.
",Gluon KVStore Python,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Cuda, Bug', ""Thank you for submitting the issue! I'm labeling it so the MXNet community members can help resolve it.\r\n\r\n@mxnet-label-bot add [Gluon, Python, KVStore]""]","[""\r\n----------Python Info----------\r\nVersion      : 3.5.6\r\nCompiler     : GCC 7.3.0\r\nBuild        : ('default', 'Aug 26 2018 21:41:56')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 8.1.2\r\nDirectory    : /opt/conda/lib/python3.5/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.3.1\r\nDirectory    : /opt/conda/lib/python3.5/site-packages/mxnet\r\nCommit Hash   : 19c501680183237d52a862e6ae1dc4ddc296305b\r\n----------System Info----------\r\nPlatform     : Linux-4.15.0-46-generic-x86_64-with-debian-stretch-sid\r\nsystem       : Linux\r\nnode         : axl1\r\nrelease      : 4.15.0-46-generic\r\nversion      : #49~16.04.1-Ubuntu SMP Tue Feb 12 17:45:24 UTC 2019\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                4\r\nOn-line CPU(s) list:   0-3\r\nThread(s) per core:    1\r\nCore(s) per socket:    4\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             AuthenticAMD\r\nCPU family:            23\r\nModel:                 17\r\nModel name:            AMD Ryzen 3 2200G with Radeon Vega Graphics\r\nStepping:              0\r\nCPU MHz:               1458.994\r\nCPU max MHz:           3500.0000\r\nCPU min MHz:           1600.0000\r\nBogoMIPS:              6986.85\r\nVirtualization:        AMD-V\r\nHypervisor vendor:     vertical\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             64K\r\nL2 cache:              512K\r\nL3 cache:              4096K\r\nNUMA node0 CPU(s):     0-3\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx hw_pstate sme ssbd ibpb vmmcall fsgsbase bmi1 avx2 smep bmi2 rdseed adx smap clflushopt sha_ni xsaveopt xsavec xgetbv1 xsaves clzero irperf xsaveerptr arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif overflow_recov succor smca\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.1691 sec, LOAD: 0.6659 sec.\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0070 sec, LOAD: 1.3928 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0083 sec, LOAD: 0.8829 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.8895 sec, LOAD: 0.7720 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0078 sec, LOAD: 0.9719 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0093 sec, LOAD: 0.0760 sec.\r\n"", '\r\nepoch 0\r\n[01:09:18] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n-------- autograd.backward(loss)\r\n---------- trainer.step(batch_size)\r\nTraceback (most recent call last):\r\n  File ""train.py"", line 131, in <module>\r\n    predTop = predTop.reshape((-1,)).astype(\'uint8\').asnumpy()\r\n  File ""/opt/conda/lib/python3.5/site-packages/mxnet/ndarray/ndarray.py"", line 1972, in asnumpy\r\n    ctypes.c_size_t(data.size)))\r\n  File ""/opt/conda/lib/python3.5/site-packages/mxnet/base.py"", line 251, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [01:09:26] /home/travis/build/dmlc/mxnet-distro/mxnet-build/3rdparty/mshadow/mshadow/./stream_gpu-inl.h:62: Check failed: e == cudaSuccess CUDA: an illegal memory access was encountered\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x381822) [0x7fbe7f130822]\r\n[bt] (1) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x381e08) [0x7fbe7f130e08]\r\n[bt] (2) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2f3e198) [0x7fbe81ced198]\r\n[bt] (3) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2faf1ea) [0x7fbe81d5e1ea]\r\n[bt] (4) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2f15123) [0x7fbe81cc4123]\r\n[bt] (5) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2f1d334) [0x7fbe81ccc334]\r\n[bt] (6) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2f213db) [0x7fbe81cd03db]\r\n[bt] (7) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2f215fe) [0x7fbe81cd05fe]\r\n[bt] (8) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2f1d9fb) [0x7fbe81ccc9fb]\r\n[bt] (9) /opt/conda/bin/../lib/libstdc++.so.6(+0xb8678) [0x7fbe6a362678]\r\n', '\r\nepoch 0\r\n[01:21:38] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n-------- autograd.backward(loss)\r\n---------- trainer.step(batch_size)\r\nkvs 2 <mxnet.kvstore.KVStore object at 0x7f1e6f85f940>\r\na\r\na2\r\nb 0 fcn0_resnetv1s_conv0_weight\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 1 fcn0_resnetv1s_syncbatchnorm0_gamma\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 2 fcn0_resnetv1s_syncbatchnorm0_beta\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 3 fcn0_resnetv1s_syncbatchnorm0_running_mean\r\nh\r\nb 4 fcn0_resnetv1s_syncbatchnorm0_running_var\r\nh\r\nb 5 fcn0_resnetv1s_conv1_weight\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 6 fcn0_resnetv1s_syncbatchnorm1_gamma\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 7 fcn0_resnetv1s_syncbatchnorm1_beta\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 8 fcn0_resnetv1s_syncbatchnorm1_running_mean\r\nh\r\nb 9 fcn0_resnetv1s_syncbatchnorm1_running_var\r\nh\r\nb 10 fcn0_resnetv1s_conv2_weight\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 11 fcn0_resnetv1s_syncbatchnorm2_gamma\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 12 fcn0_resnetv1s_syncbatchnorm2_beta\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 13 fcn0_resnetv1s_syncbatchnorm2_running_mean\r\nh\r\nb 14 fcn0_resnetv1s_syncbatchnorm2_running_var\r\nh\r\nb 15 fcn0_resnetv1s_layers1_conv0_weight\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 16 fcn0_resnetv1s_layers1_syncbatchnorm0_gamma\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 17 fcn0_resnetv1s_layers1_syncbatchnorm0_beta\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 18 fcn0_resnetv1s_layers1_syncbatchnorm0_running_mean\r\nh\r\nb 19 fcn0_resnetv1s_layers1_syncbatchnorm0_running_var\r\nh\r\nb 20 fcn0_resnetv1s_layers1_conv1_weight\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 21 fcn0_resnetv1s_layers1_syncbatchnorm1_gamma\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 22 fcn0_resnetv1s_layers1_syncbatchnorm1_beta\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 23 fcn0_resnetv1s_layers1_syncbatchnorm1_running_mean\r\nh\r\nb 24 fcn0_resnetv1s_layers1_syncbatchnorm1_running_var\r\nh\r\nb 25 fcn0_resnetv1s_layers1_conv2_weight\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 26 fcn0_resnetv1s_layers1_syncbatchnorm2_gamma\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 27 fcn0_resnetv1s_layers1_syncbatchnorm2_beta\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 28 fcn0_resnetv1s_layers1_syncbatchnorm2_running_mean\r\nh\r\nb 29 fcn0_resnetv1s_layers1_syncbatchnorm2_running_var\r\nh\r\nb 30 fcn0_resnetv1s_down1_conv0_weight\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 31 fcn0_resnetv1s_down1_syncbatchnorm0_gamma\r\nc\r\nc2\r\n[...hangs here. The python process then refuses to exit regardless of which kill signal I send to it. The docker container also refuses to stop. I have to restart the machine at this point.]\r\n', '\r\nimport sys, math\r\nimport numpy as np\r\nimport mxnet as mx\r\nfrom mxnet import gluon, autograd, metric\r\nimport gluoncv\r\nfrom gluoncv.utils.parallel import DataParallelModel, DataParallelCriterion\r\n\r\nfrom gluoncv.model_zoo import get_model\r\nfrom gluoncv.loss import *\r\nfrom gluoncv.model_zoo.segbase import *\r\nfrom mxnet.gluon.data import dataset\r\nfrom gluoncv.utils import LRScheduler\r\n  \r\n\r\nclass DummyDataSet(dataset.Dataset):\r\n    def __init__(self, crop_size):\r\n      self.data = []\r\n      for i in range(5):\r\n          d = mx.ndarray.ones((3, crop_size, crop_size))\r\n          l = mx.ndarray.ones((crop_size, crop_size))\r\n          r = (d, l)\r\n          self.data.append(r)\r\n        \r\n    @property\r\n    def num_class(self):\r\n      return 5\r\n    \r\n    def __len__(self):\r\n        return len(self.data)\r\n    \r\n    def __getitem__(self, index):\r\n      return self.data[index]\r\n\r\n  \r\n  \r\nclass Trainer(gluon.Trainer):\r\n    def step(self, batch_size, ignore_stale_grad=False):\r\n        if not self._kv_initialized:\r\n            print(""kvs %d %s"" % (len(self._contexts), str(self._kvstore_params[\'kvstore\'])))\r\n            self._init_kvstore()\r\n        if self._params_to_init:\r\n            self._init_params()\r\n        self._optimizer.rescale_grad = self._scale / batch_size\r\n        self._allreduce_grads()\r\n        self._update(ignore_stale_grad)\r\n        \r\n     \r\n    def _allreduce_grads(self):\r\n        print(""a"")\r\n        if self._kvstore:\r\n            print(""a2"")\r\n            for i, param in enumerate(self._params):\r\n                print(""b %d %s"" % (i, param.name))\r\n                if param.grad_req != \'null\':\r\n                    print(""c"")\r\n                    \r\n                    plg = param.list_grad()\r\n                    \r\n                    print(""c2"")\r\n                    \r\n                    self._kvstore.push(i, plg, priority=-i)\r\n                    \r\n                    print(""d"")\r\n                    if not self._update_on_kvstore:\r\n                        print(""e"")\r\n                        self._kvstore.pull(i, param.list_grad(), priority=-i, ignore_sparse=self._distributed)\r\n                        print(""f"")\r\n                    print(""g"")\r\n                print(""h"")\r\n            print(""i"")\r\n        print(""j"")\r\n\r\n\r\n\r\nif __name__ == ""__main__"":\r\n    input_size = 480\r\n    \r\n    dataset_train = DummyDataSet(input_size)\r\n    data_loader = gluon.data.DataLoader(dataset_train, 2, shuffle=True, last_batch=\'rollover\', num_workers=4)\r\n    \r\n    net = get_segmentation_model(model=\'fcn\', dataset=\'pascal_aug\',\r\n                                backbone=\'resnet50\', norm_layer=mx.gluon.contrib.nn.basic_layers.SyncBatchNorm,\r\n                                norm_kwargs={\'num_devices\': 2}, aux=True,\r\n                                crop_size=input_size)\r\n    net.cast(\'float32\')\r\n    \r\n    exec_contexts = [ mx.gpu(0), mx.gpu(1) ]\r\n    \r\n    net = DataParallelModel(net, exec_contexts)\r\n\r\n    criterion = MixSoftmaxCrossEntropyLoss(True, aux_weight=0.5)\r\n    criterion = DataParallelCriterion(criterion, exec_contexts, True)\r\n\r\n    lr_scheduler = LRScheduler(mode=\'poly\', baselr=0.001,\r\n                            niters=len(dataset_train), \r\n                            nepochs=30)\r\n    optimizer_params = {\'lr_scheduler\': lr_scheduler,\r\n                        \'wd\':0.0001,\r\n                        \'momentum\': 0.9}\r\n    \r\n    kv = mx.kv.create(\'device\')\r\n    \r\n    trainer = Trainer(net.module.collect_params(), \'sgd\', optimizer_params, kvstore = kv)\r\n    \r\n    batch_size = 4\r\n    \r\n    for epoch in range(0, 30):\r\n        print (""epoch"", epoch)\r\n        for i, (data, label) in enumerate(data_loader):\r\n            lr_scheduler.update(i, epoch)\r\n            \r\n            with autograd.record(True):\r\n                pred = net(data)\r\n                #pred = upsize_parallel_output(pred)\r\n                loss = criterion(pred, label)\r\n                mx.nd.waitall()\r\n                print (""-------- autograd.backward(loss)"")\r\n                autograd.backward(loss)\r\n            print (""---------- trainer.step(batch_size)"")\r\n            trainer.step(batch_size)\r\n            \r\n            # DataParallelModel output is a tuple of tuples of NDArrays.\r\n            pred = [ p[0] for p in pred ]\r\n            pred = mx.ndarray.concat(*pred)\r\n            predTop = mx.nd.argmax(pred, 1)\r\n            \r\n            predNP = predTop.reshape((-1,)).astype(\'uint8\').asnumpy()\r\n\r\n']","['gluon.Trainer._allreduce_grads()', 'local', 'device']",0,0
74,incubator-mxnet,14981,open,[CI][NightlyTestsForBinaries] Test Large Tensor: GPU Failing,"## Description

Test Large Tensor: GPU step is failing with:



see http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/NightlyTestsForBinaries/detail/master/312/pipeline/144 for the full log
",Test,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Test, CI', '@mxnet-label-bot add [test]\r\n@apeforest ', 'fixed in latest run, we can close this now: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/NightlyTestsForBinaries/detail/master/320/pipeline', ""actually, we can't close it yet, this test was fixed but went back to failing after https://github.com/apache/incubator-mxnet/pull/15059. Similar OOM issue in https://github.com/apache/incubator-mxnet/issues/14980\r\n"", 'Currently, both CPU and GPU tests have been disabled due to the same memory issue. Had a discussion with @access2rohit and @apeforest,  we can try a few things:\r\n1. change to P3 instances  here https://github.com/apache/incubator-mxnet/blob/master/tests/nightly/JenkinsfileForBinaries#L82\r\n2. further increase shared memory to 50G\r\n3. stop running large tensor test parallelly with other tests.\r\n\r\nWe are having problems testing the above solutions on CI machines that have multiple jobs running in parallel.', 'failed with 200G shared memory on P3.2x and failed, we need another approach for testing large tensor.']","['\r\n======================================================================\r\nERROR: test_large_array.test_ndarray_random_randint\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File ""/usr/local/lib/python3.5/dist-packages/nose/case.py"", line 198, in runTest\r\n    self.test(*self.arg)\r\n  File ""/work/mxnet/tests/python/unittest/common.py"", line 177, in test_new\r\n    orig_test(*args, **kwargs)\r\n  File ""/work/mxnet/tests/nightly/test_large_array.py"", line 70, in test_ndarray_random_randint\r\n    assert a.__gt__(low) & a.__lt__(high)\r\n  File ""/work/mxnet/python/mxnet/ndarray/ndarray.py"", line 336, in __gt__\r\n    return greater(self, other)\r\n  File ""/work/mxnet/python/mxnet/ndarray/ndarray.py"", line 3376, in greater\r\n    _internal._lesser_scalar)\r\n  File ""/work/mxnet/python/mxnet/ndarray/ndarray.py"", line 2704, in _ufunc_helper\r\n    return fn_array(lhs, rhs)\r\n  File ""<string>"", line 46, in broadcast_greater\r\n  File ""/work/mxnet/python/mxnet/_ctypes/ndarray.py"", line 92, in _imperative_invoke\r\n    ctypes.byref(out_stypes)))\r\n  File ""/work/mxnet/python/mxnet/base.py"", line 254, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [06:39:26] /work/mxnet/src/io/../operator/elemwise_op_common.h:135: Check failed: assign(&dattr, vec.at(i)): Incompatible attr in node  at 1-th input: expected int32, got int64\r\nStack trace:\r\n  [bt] (0) /work/mxnet/python/mxnet/../../build/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x3c) [0x7fa0e59e8b3c]\r\n  [bt] (1) /work/mxnet/python/mxnet/../../build/libmxnet.so(bool mxnet::op::ElemwiseAttr<int, &mxnet::op::type_is_none, &mxnet::op::type_assign, true, &mxnet::op::type_string[abi:cxx11], -1l, -1l>(nnvm::NodeAttrs const&, std::vector<int, std::allocator<int> >*, std::vector<int, std::allocator<int> >*, int const&)::{lambda(std::vector<int, std::allocator<int> > const&, unsigned long, char const*)#1}::operator()(std::vector<int, std::allocator<int> > const&, unsigned long, char const*) const+0x62d) [0x7fa0e8c6866d]\r\n  [bt] (2) /work/mxnet/python/mxnet/../../build/libmxnet.so(bool mxnet::op::ElemwiseAttr<int, &mxnet::op::type_is_none, &mxnet::op::type_assign, true, &mxnet::op::type_string[abi:cxx11], -1l, -1l>(nnvm::NodeAttrs const&, std::vector<int, std::allocator<int> >*, std::vector<int, std::allocator<int> >*, int const&)+0x2f3) [0x7fa0e8f963a3]\r\n  [bt] (3) /work/mxnet/python/mxnet/../../build/libmxnet.so(bool mxnet::op::ElemwiseType<2l, 1l>(nnvm::NodeAttrs const&, std::vector<int, std::allocator<int> >*, std::vector<int, std::allocator<int> >*)+0x34d) [0x7fa0e8f968ed]\r\n  [bt] (4) /work/mxnet/python/mxnet/../../build/libmxnet.so(std::_Function_handler<bool (nnvm::NodeAttrs const&, std::vector<int, std::allocator<int> >*, std::vector<int, std::allocator<int> >*), bool (*)(nnvm::NodeAttrs const&, std::vector<int, std::allocator<int> >*, std::vector<int, std::allocator<int> >*)>::_M_invoke(std::_Any_data const&, nnvm::NodeAttrs const&, std::vector<int, std::allocator<int> >*&&, std::vector<int, std::allocator<int> >*&&)+0x1d) [0x7fa0e8bb909d]\r\n  [bt] (5) /work/mxnet/python/mxnet/../../build/libmxnet.so(mxnet::imperative::SetShapeType(mxnet::Context const&, nnvm::NodeAttrs const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, mxnet::DispatchMode*)+0x6a5) [0x7fa0e8c28e35]\r\n  [bt] (6) /work/mxnet/python/mxnet/../../build/libmxnet.so(mxnet::Imperative::Invoke(mxnet::Context const&, nnvm::NodeAttrs const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&)+0x10b) [0x7fa0e8c0f52b]\r\n  [bt] (7) /work/mxnet/python/mxnet/../../build/libmxnet.so(MXImperativeInvokeImpl(void*, int, void**, int*, void***, int, char const**, char const**)+0x1c9) [0x7fa0e8a8a479]\r\n  [bt] (8) /work/mxnet/python/mxnet/../../build/libmxnet.so(MXImperativeInvokeEx+0x8f) [0x7fa0e8a8a97f]\r\n\r\n\r\n-------------------- >> begin captured logging << --------------------\r\ntests.python.unittest.common: INFO: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=2073509752 to reproduce.\r\n--------------------- >> end captured logging << ---------------------\r\n']",[],0,0
75,incubator-mxnet,4105,closed,[R] Data augmentation with basic MNIST example,"I want to create a custom iterator in R. As an initial example I will use the MNIST data. 

What I would like to do is an iterator that gets as input the raw data, that would be a matrix of 60000 examples times 784 which is each image expanded in a vector:
 
and whose output, in every iteration, would be a matrix of :

 
The only operation that I have to do inside the iterator is the following:

 
I don´t know if there is a way to reimplement the operator  or  in R. I know that that can be done in python and C++, but not sure how to do it in R. 

The interface should be something like:

 

Any help appreciated :) @piiswrong @thirdwing 
",R,"['@miguelgfierro This can be done as a reference class in R. I give a very prototype below.\r\n\r\n```r\r\ncus_iter <-setRefClass(""Custom.Iter"", fields = ""x"")\r\ncus_iter$methods(iter.next = function() {return(TRUE)})\r\n\r\niter <- cus_iter$new(x = 123)\r\niter$iter.next()\r\n```', '@thirdwing what you are suggesting is to implement a reference class from scratch that copies the behavior of the C++ iterator class?\r\n\r\nI want to reimplement the method `value` in `mx.io.arrayiter`. So what you are suggesting is to do:\r\n\r\n```R\r\ncus_iter <-setRefClass(""Custom.Iter"", fields = c(""data"", ""label"",""batch.size"", ""shuffle""))\r\ncus_iter$methods(iter.next = function() {\r\n#code here\r\n})\r\ncus_iter$methods(value = function() {\r\n#code here\r\n})\r\n```\r\nCould this class be used as an input to `mx.model.FeedForward.create`?\r\n\r\nIdeally what I would like is to inhereit from a `MXArrayDataIter` and reimplement only the method `value`. If I create an instance of `mx.io.arrayiter`, it has everything that I want but I don\'t know how to modify the `value`.\r\n```R\r\narray.iter.mx <- mx.io.arrayiter(data = train.x, label = train.y, batch.size = 100, shuffle = TRUE)\r\nis(array.iter.mx)\r\n[1] ""Rcpp_MXArrayDataIter"" ""C++Object""           \r\n[3] ""envRefClass""          "".environment""        \r\n[5] ""refClass""             ""environment""         \r\n[7] ""refObject""\r\nmxnet:::is.MXDataIter(array.iter.mx)\r\n[1] TRUE\r\n```\r\nIn python you can create a custom iterator if you inhereit from `mx.io.DataIter` and reimplement  `provide_data(), provide_label(), next()`. How can this be done in R? \r\n\r\n\r\n', 'I think you can try something like below:\r\n\r\n```r\r\n> setRefClass(""Custom.Iter"", contains = ""Rcpp_MXArrayDataIter"")\r\n> \r\n> cus_iter <-setRefClass(""Custom.Iter"", contains = ""Rcpp_MXArrayDataIter"")\r\n> cus_iter$methods(`iter.next` = function() {return(TRUE)})\r\n> \r\n> cus_iter\r\nGenerator for class ""Custom.Iter"":\r\n\r\nNo fields defined\r\n\r\nClass Methods: \r\n     ""iter.next#Rcpp_MXArrayDataIter"", ""import"", "".objectParent"", \r\n     ""usingMethods"", ""show"", ""getClass"", ""untrace"", ""export"", "".objectPackage"", \r\n     ""callSuper"", ""copy"", ""initFields"", ""getRefClass"", ""trace"", ""field"", \r\n     ""iter.next"", ""num.pad"", ""reset"", ""value"", ""finalize"", ""initialize""\r\n\r\nReference Superclasses: \r\n     ""Rcpp_MXArrayDataIter"", ""envRefClass""\r\n\r\n> \r\n> it <- cus_iter$new()\r\n> \r\n> it$iter.next()\r\n[1] TRUE\r\n```', ""The problem with that is that it's not taking the methods from the c++ class. The class has `value, reset`. We are  just creating `iter.next()` that every time is called it returns `TRUE` but it is not counting the number of batches. And it won't return a batch of values..."", '@miguelgfierro I might try to find some time to give a more complete example.\r\n\r\nThis is still doable through a reference class. We only need to provide a RC `iter`.', '@thirdwing look, this could be a solution to overload the CSVIter using MNIST data in csv format:\r\n\r\n```R\r\nCustomCSVIter <- setRefClass(""CustomCSVIter"",\r\n                             fields=c(""iter"", ""data.csv"", ""data.shape"", ""batch.size"", ""shuffle""),\r\n                             methods=list(\r\n                               initialize=function(iter, data.csv, data.shape, batch.size, shuffle){\r\n                                 feature_len <- data.shape*data.shape + 1\r\n                                 csv_iter <- mx.io.CSVIter(data.csv=data.csv, data.shape=c(feature_len), batch.size=batch.size)\r\n                                 .self$iter <- csv_iter \r\n                                 .self\r\n                               },\r\n                               inter.next=function(){\r\n                                 .self$iter$iter.next()\r\n                               },\r\n                               value=function(){\r\n                                 .self$iter$value()\r\n                                 # modify the value here\r\n                               }\r\n                             )\r\n)\r\ncc <- CustomCSVIter$new(iter = NULL, data.csv = train_file, data.shape = 28, \r\n                        batch.size = 2, shuffle = FALSE)  \r\ncc$inter.next()\r\ncc_value <- cc$value()\r\n```\r\nI\'ll try to do an example to show this and do a PR. Thanks buddy!!!\r\n', 'This should work.When sending the PR, please send to the nnvm branch. Thank you.']","['R\r\ndim(train.x)\r\n[1] 59999   784\r\n', 'R\r\ndim(train.x)\r\n[1]  28  28   1 100\r\n', 'R\r\ndim(train.x) <- c(28, 28, 1, ncol(train.x))\r\n', 'R\r\ncustom.iter <- function(X, y, batch.size, is.train){\r\n#my magical transformation...???...???\r\nreturn(Xiter)\r\n}\r\n\r\n#data definition\r\ndim(train.x)\r\n[1] 59999   784\r\n\r\n#Iterator instantiation\r\nXiter <- custom.iter(train.x, train.y, 100, TRUE)\r\nXiter$iter.next()\r\n[1] TRUE\r\ndata <- Xiter$value()$data\r\ndim(data)\r\n[1]  28  28   1 100\r\n']","['28x28x1xbatch_size', 'iter.next()', 'value()']",0,0
76,incubator-mxnet,10101,closed,gluon feature request: proper registration/initialization of layers inside a list (container) for custom (Hybrid)Blocks,"Dear all, it would be very useful if one could add NN layers of a gluon custom model inside a list, similar to , something like: 


I can think of many use cases, but one important one is indexing for neuroevolution problems, i.e. using a variable architecture of a specified set of layers. 

Thank you very much for the great work you put into gluon/mxnet. ",,"['how do you intend to use `layers_list` in your example? it is possible to use Sequential/HybridSequential just as containers without using its forward functionality.', ""Hi @szha, thank you for your reply. I've done so in simpler architectures as you describe but now I want to try something more advanced. \r\n\r\nThe basic idea is that one can have a set of layers that live in a list, ```layers_list```. Then one can form a sparse connectivity matrix, ```Sij``` where each row corresponds to the connections of ```layer_i``` to ```layer_j```. The connectivity matrix will be an individual inside an evolutionary algorithm. The architecture of the network is defined by ```Sij```. For example, a simple Sequential module, where one stacks 4 layers \r\n\r\n```Python\r\nnet = Sequential()\r\nfor i in range(3):\r\n    net.add(Dense(5))\r\n```\r\ncan be represented with the following connectivity matrix: \r\n```Python\r\n   | 1   2   3   4\r\n------------------- \r\n1  | 0  1   0   0\r\n2  | 0  0   1   0\r\n3  | 0  0   0   1 \r\n4  | 0  0   0   0 \r\n ```\r\nStarting from row, ```layer_1``` connects to ```layer_2```, ```layer_2``` to ```layer_3``` and so on. Layer 4 has no connectivy( last layer). But if we want more advanced topology of the network (like ```layer_1``` connecting with ```layer_2``` and ```layer_3```)\r\n```Python\r\n   | 1   2   3   4\r\n------------------- \r\n1  | 0  1   1   0\r\n2  | 0  0   1   0\r\n3  | 0  0   0   1 \r\n4  | 0  0   0   0 \r\n ```\r\nthe ```Sequential``` breaks down. It is possible again to formulate it with Sequential but I think it lacks the flexibility of indexing.  \r\n\r\nNow assuming one has the layers in a container (a list in this example, I can think of dictionary usage as well), ```layers_list```, and ```Sij``` is a sparse matrix, one can formulate a ```forward``` function (design prototype, not the true solution, [here](https://stackoverflow.com/questions/4319014/iterating-through-a-scipy-sparse-vector-or-matrix) is an example of iterating over sparse matrix): \r\n\r\n```Python \r\ndef hybrid_forward(self, F, input):\r\n    out = self.first_layer(input)\r\n    cx = Sij.tocoo()    \r\n    # This for loop iterates over non zero elements. \r\n    for i,j,_ in itertools.izip(cx.row, cx.col, cx.data):\r\n        out = self.layer_list[j](self.layer_list[i](out))\r\n        out = F.relu(out)\r\n    return out\r\n``` \r\n\r\nThe basic idea is to create a DAG on the fly, using lists and a connectivity matrix is the first way that comes into my mind of implemeting this (I may be wrong, am pretty sure there are perhaps better ways of doing so, but I don't know any). I think this functionality, in combination with the flexibility of gluon imperative style, can help a lot of people play with variable architectures. \r\n"", '```python\r\nIn [1]: import mxnet as mx\r\n\r\nIn [2]: net = mx.gluon.model_zoo.vision.alexnet()\r\n\r\nIn [3]: net\r\nOut[3]:\r\nAlexNet(\r\n  (features): HybridSequential(\r\n    (0): Conv2D(None -> 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\r\n    (1): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(0, 0), ceil_mode=False)\r\n    (2): Conv2D(None -> 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\r\n    (3): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(0, 0), ceil_mode=False)\r\n    (4): Conv2D(None -> 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (5): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (6): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n    (7): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(0, 0), ceil_mode=False)\r\n    (8): Flatten\r\n    (9): Dense(None -> 4096, Activation(relu))\r\n    (10): Dropout(p = 0.5, axes=())\r\n    (11): Dense(None -> 4096, Activation(relu))\r\n    (12): Dropout(p = 0.5, axes=())\r\n  )\r\n  (output): Dense(None -> 1000, linear)\r\n)\r\n\r\nIn [4]: net.features\r\nOut[4]:\r\nHybridSequential(\r\n  (0): Conv2D(None -> 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\r\n  (1): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(0, 0), ceil_mode=False)\r\n  (2): Conv2D(None -> 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\r\n  (3): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(0, 0), ceil_mode=False)\r\n  (4): Conv2D(None -> 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n  (5): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n  (6): Conv2D(None -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n  (7): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(0, 0), ceil_mode=False)\r\n  (8): Flatten\r\n  (9): Dense(None -> 4096, Activation(relu))\r\n  (10): Dropout(p = 0.5, axes=())\r\n  (11): Dense(None -> 4096, Activation(relu))\r\n  (12): Dropout(p = 0.5, axes=())\r\n)\r\n\r\nIn [5]: net.features[3]\r\nOut[5]: MaxPool2D(size=(3, 3), stride=(2, 2), padding=(0, 0), ceil_mode=False)\r\n```', 'Refer to https://github.com/apache/incubator-mxnet/issues/9264 .', '@feevos Currently the `HybridSequential` and `Sequential` have the same functionality as `ModuleList`. Thus we previously decide to not add an additional `ModuleList`. We can bring it to the table again.', ""Hi @szha  and @sxjscience thank you very much for your reply. So if I understand correctly, (Hybrid)Sequential can also be used as a container of the various layers and indexed just like a list **so I can use the contained layers in any _order_ I want** (without the stacked sequential forward functionality). If I understand correctly, I can use something like:\r\n\r\n```Python\r\nclass CustomNet(HybridBlock):\r\n\r\n    def __init__(self,**kwards):\r\n        HybridBlock.__init__(self,**kwards)\r\n\r\n        with self.name_scope():\r\n            self.net = HybridSequential()\r\n            # Add some convolution operators\r\n            for i in range(3):\r\n                net.add(Conv2D(....))\r\n\r\n    # Change the order of the layers in the self.net. \r\n    # This is not equivalent to self.net(input)\r\n    def hybrid_forward(self,F, input):\r\n        out = self.net[2]( input)\r\n        out = self.net[0] (out) \r\n        out = self.net[1] (out) \r\n\r\n       return out\r\n```\r\nif my understanding is correct then yes, there is no need for something similar to ModuleList. I haven't seen anything like what you just described in the documentation (it would be nice to add it in the gluon [book](http://gluon.mxnet.io/) and API). \r\n\r\nThank you very much! \r\n"", ""Good point on making the feature known. cc'd @zackchase, @astonzhang, @mli "", ""This solution is kind of weird.  Sequential feels like it ought to be composed of things that can feed into one another.  But if you are just using it as a list, the shapes might not even be right for that.\r\n\r\nI admit it isn't a high priority, but just for sugar it might be nice to implement a separate blocklist class.""]","['torch.nn.ModuleList', 'Python\r\n\r\nclass CustomNet(HybridBlock):\r\n\r\n    def __init__(self,**kwards):\r\n        HybridBlock.__init__(self,**kwards)\r\n        with self.name_scope():\r\n           layers_list = []\r\n           for i in range(5):\r\n               layers_list += [gluon.nn.Conv2D( SomeArguments )]\r\n\r\n\r\n    def hybrid_forward(self,F,_x):\r\n         # Some manipulation of layers_list elements\r\n         out = ... \r\n \r\n        return out\r\n']",[],0,0
77,incubator-mxnet,6918,closed,mxnet R 3.4 installation for CentOS release 6.9 (Final),"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: CentOS release 6.9 (Final)

Compiler: gcc version 4.9.2 20150212 (Red Hat 4.9.2-6) (GCC)

Package used (Python/R/Scala/Julia): R

MXNet version: 0.10

Or if installed from source: 

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide 3.4

R :
> sessionInfo(package=NULL)
R version 3.4.0 (2017-04-21)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: CentOS release 6.9 (Final)

Matrix products: default
BLAS: /usr/lib64/R/lib/libRblas.so
LAPACK: /usr/lib64/R/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] drat_0.1.2     compiler_3.4.0 tools_3.4.0


## Error Message:
Please paste the full error message, including stack trace.
Warning message:
package ‘mxnet’ is not available (for R version 3.4.0)

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. From R console I entered the following commands:
install.packages(""drat"", repos=""https://cran.rstudio.com"")
drat:::addRepo(""dmlc"")
install.packages(""mxnet"")
2.
3.

## What have you tried to solve it?

1. Attempted to install from source and received the following error message when running the make rpkg command:

mkdir -p R-package/inst
mkdir -p R-package/inst/libs
cp -rf lib/libmxnet.so R-package/inst/libs
mkdir -p R-package/inst/include
cp -rf include/* R-package/inst/include
cp -rf dmlc-core/include/* R-package/inst/include/
cp -rf nnvm/include/* R-package/inst/include
echo ""import(Rcpp)"" > R-package/NAMESPACE
echo ""import(methods)"" >> R-package/NAMESPACE
R CMD INSTALL R-package
make[1]: Entering directory all'.
make[1]: Leaving directory `/root/mxnet/R-package/src'
No man pages found in package  ‘mxnet’
Error: package or namespace load failed for ‘mxnet’:
 .onLoad failed in loadNamespace() for 'mxnet', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object '/usr/lib64/R/library/mxnet/libs/libmxnet.so':
  libopenblas.so.0: cannot open shared object file: No such file or directory
Error: loading failed
Execution halted

2.
3.
",Installation R,"['As we said, the `drat` repo is for Windows and OSX users. On Linux, you need to compile from source.\r\n\r\nFrom your error log:\r\n> libopenblas.so.0: cannot open shared object file: No such file or directory\r\n\r\nI think you need to check your openblas installaton.']",[],"['git rev-parse HEAD', 'sessionInfo()', ""/root/mxnet/R-package/src'\r\nmake[1]: Nothing to be done for ""]",0,0
78,incubator-mxnet,7272,closed,jenkins/incubator-mxnet pipeline is broken on the master,"https://builds.apache.org/blue/organizations/jenkins/incubator-mxnet/detail/master/83/pipeline/

output:
> [amalgamation] Running shell script
> + tests/ci_build/ci_build.sh cpu make -C amalgamation/ USE_BLAS=openblas MIN=1
> WORKSPACE: /home/jenkins/jenkins-slave/workspace/amalgamation
> CI_DOCKER_EXTRA_PARAMS: 
> COMMAND: make -C amalgamation/ USE_BLAS=openblas MIN=1
> CONTAINER_TYPE: cpu
> BUILD_TAG: jenkins-incubator-mxnet-master-83
> NODE_NAME: mxnet3
> DOCKER CONTAINER NAME: mx-ci.cpu
> PRE_COMMAND: tests/ci_build/with_the_same_user
> 
> Building container (mx-ci.cpu)...
> Sending build context to Docker daemon 59.39 kB
> 
> Step 1/9 : FROM ubuntu:14.04
>  ---> 4a2820e686c4
> Step 2/9 : COPY install/ubuntu_install_core.sh /install/
>  ---> Using cache
>  ---> a2648bbfb7e4
> Step 3/9 : RUN /install/ubuntu_install_core.sh
>  ---> Using cache
>  ---> bd54bb963df0
> Step 4/9 : COPY install/ubuntu_install_python.sh /install/
>  ---> Using cache
>  ---> b79f713d5145
> Step 5/9 : RUN /install/ubuntu_install_python.sh
>  ---> Using cache
>  ---> 570842ae2af2
> Step 6/9 : COPY install/ubuntu_install_scala.sh /install/
>  ---> Using cache
>  ---> 6f8e5f2011ba
> Step 7/9 : RUN /install/ubuntu_install_scala.sh
>  ---> Using cache
>  ---> e2b49cb08c67
> Step 8/9 : COPY install/ubuntu_install_r.sh /install/
>  ---> Using cache
>  ---> f5f990f7f4ac
> Step 9/9 : RUN /install/ubuntu_install_r.sh
>  ---> Using cache
>  ---> d795cd130ad6
> Successfully built d795cd130ad6
> Running 'make -C amalgamation/ USE_BLAS=openblas MIN=1' inside mx-ci.cpu...
> Adding group /workspace/amalgamation'
> g++ -std=c++11 -Wno-unknown-pragmas -Wall -DMSHADOW_USE_CBLAS=0 -DDISABLE_OPENMP=1 -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DDMLC_LOG_STACK_TRACE=0 -DMSHADOW_FORCE_STREAM -DMXNET_USE_OPENCV=0 -DMXNET_PREDICT_ONLY=1 -fPIC -o mxnet_predict-all.o -c mxnet_predict-all.cc
> mxnet_predict-all.cc:42:37: fatal error: io/threaded_input_split.h: No such file or directory
>  #include <io/threaded_input_split.h>
>                                      ^
> compilation terminated.
> make: Leaving directory `/workspace/amalgamation'
> make: *** [mxnet_predict-all.o] Error 1",,['I was not able to reproduce it by running manually.'],[],"[""jenkins' (GID 1001) ...\r\n> Done.\r\n> make: Entering directory ""]",0,0
79,incubator-mxnet,3622,closed,How to use the parameters in im2rec.py?,"I have some problems when I use the ""--exts"" in parametes of im2rec.py.
It's right if I use the default value,but It's error if I use it like --exts=['.jpg','.jpeg'].
Why?
",,"[""I have find reason from im2rec.py.\ncgroup.add_argument('--exts', type=list,default=['.jpeg', '.jpg'],\n                        help='list of acceptable image extensions.')\nchange to\ncgroup.add_argument('--exts', type=list, action='append',default=['.jpeg', '.jpg'],\n                        help='list of acceptable image extensions.')\nOK!\n\nmodified im2rec.py\nhttps://github.com/sunshineInmoon/mxnet/blob/master/tools/im2rec.py\n"", 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
80,incubator-mxnet,1049,closed,mean.img error ,"I occur an error when using:
mean.img = as.array(mx.nd.load(""Inception/mean_224.nd"")[[""mean_img""]])

Error in mx.nd.load(""Inception/mean_224.nd"")[[""mean_img""]] : 
  object of type 'externalptr' is not subsettable

How could I fix it?
",,"['[[""mean_img""]] - > [""mean_img""]\n']",[],[],0,0
81,incubator-mxnet,8983,closed,python-howto-debug_conv doesn't work?,"
## Description
I debug conv as  but it will not stop at breakpoint.


## Environment info (Required)
OS: Ubuntu 16.04 xenial

## Build info (Required if built from source)
gcc
mxnet 1.0.0 cpu 

Build config:
DEBUG=1
CUDA=0
CUDNN=0
CUDA_PATH=NONE
make -j$(nproc)

## Error Message:
➜  ~ gdb --args python debug_conv.py
GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1
Copyright (C) 2016 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type ""show copying""
and ""show warranty"" for details.
This GDB was configured as ""x86_64-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
<http://www.gnu.org/software/gdb/documentation/>.
For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...
Reading symbols from python...done.
(gdb) b incubator-mxnet/src/operator/convolution_v1-inl.h:130
No source file named incubator-mxnet/src/operator/convolution_v1-inl.h.
Make breakpoint pending on future shared library load? (y or [n]) n
(gdb) run
Starting program: /home/hl/anaconda2/bin/python debug_conv.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7fffe57a4700 (LWP 12340)]
[New Thread 0x7fffe4fa3700 (LWP 12341)]
[New Thread 0x7fffe47a2700 (LWP 12342)]
[New Thread 0x7fffe3fa1700 (LWP 12343)]
[New Thread 0x7fffe37a0700 (LWP 12344)]
[Thread 0x7fffe37a0700 (LWP 12344) exited]
[Thread 0x7fffe3fa1700 (LWP 12343) exited]
[Thread 0x7fffe47a2700 (LWP 12342) exited]
[Thread 0x7fffe4fa3700 (LWP 12341) exited]
[New Thread 0x7fffe47a2700 (LWP 12345)]
[New Thread 0x7fffe37a0700 (LWP 12346)]
[New Thread 0x7fffe4fa3700 (LWP 12347)]
[New Thread 0x7fffe3fa1700 (LWP 12348)]
/home/hl/anaconda2/lib/python2.7/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead
  import OpenSSL.SSL
[11:18:59] src/engine/engine.cc:55: MXNet start using engine: NaiveEngine
[[[[-0.00020103  0.00926307  0.00926307  0.00926307  0.00431658]
   [ 0.0041606   0.01661832  0.01661832  0.01661832  0.02024863]
   [ 0.0041606   0.01661832  0.01661832  0.01661832  0.02024863]
   [ 0.0041606   0.01661832  0.01661832  0.01661832  0.02024863]
   [ 0.00537269  0.01894068  0.01894068  0.01894068  0.02670578]]]]
[Thread 0x7fffe3fa1700 (LWP 12348) exited]
[Thread 0x7fffe4fa3700 (LWP 12347) exited]
[Thread 0x7fffe47a2700 (LWP 12345) exited]
[Thread 0x7fffe57a4700 (LWP 12340) exited]
[Thread 0x7ffff7fcb700 (LWP 12334) exited]
[Inferior 1 (process 12334) exited normally]
(gdb) b incubator-mxnet/src/operator/convolution_v1-inl.h:130
Breakpoint 1 at 0x7ffff0b8a90f: incubator-mxnet/src/operator/convolution_v1-inl.h:130. (3 locations)
(gdb) run
Starting program: /home/hl/anaconda2/bin/python debug_conv.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7fffe57a4700 (LWP 12354)]
[New Thread 0x7fffe4fa3700 (LWP 12355)]
[New Thread 0x7fffe47a2700 (LWP 12356)]
[New Thread 0x7fffe3fa1700 (LWP 12357)]
[New Thread 0x7fffe37a0700 (LWP 12358)]
[Thread 0x7fffe37a0700 (LWP 12358) exited]
[Thread 0x7fffe3fa1700 (LWP 12357) exited]
[Thread 0x7fffe47a2700 (LWP 12356) exited]
[Thread 0x7fffe4fa3700 (LWP 12355) exited]
[New Thread 0x7fffe47a2700 (LWP 12359)]
........................

",,"[""It doesn't call convolution in `src/operator/convolution_v1-inl.h` but `src/operator/nn/convolution.h`.""]",[],['python-howto/READMD.md'],0,0
82,incubator-mxnet,11703,closed,test_loss.test_triplet_loss has fixed seed that can mask flakiness,"The unit test in title have been using fixed seed to mask flakiness. Suggested action:
1. Evaluate whether the test is flaky without fixed seed. If not, remove seed. Else move to 2
2. If test is flaky, determine whether it's an actual uncaught edge case. If so, fix the operator. Else move to 3
3. If numerical instability is inevitable, adjust tolerance level appropriately.
",Flaky Test,"['Thanks for filing this issue. We will investigate this Flaky test', '@szha Related fix is merged, should be good to close.', '@sandeep-krishnamurthy Related PR is merged, should be good to close.']",[],[],0,0
83,incubator-mxnet,6810,closed,'NoneType' object has no attribute 'data',"I am using mxnet to do transfer learning with python code, and encounters error. I checked the data batch generated by my dataiter, it seems to be ok. Here is the error:  

---
Traceback (most recent call last):
  File ""/Users/nali/PycharmProjects/mxnet-ir/test.py"", line 104, in <module>
    test_train()
  File ""/Users/nali/PycharmProjects/mxnet-ir/test.py"", line 100, in test_train
    epoch_end_callback=mx.callback.do_checkpoint(""models/ir-blur""))
  File ""/Library/Python/2.7/site-packages/mxnet/model.py"", line 826, in fit
    sym_gen=self.sym_gen)
  File ""/Library/Python/2.7/site-packages/mxnet/model.py"", line 237, in _train_multi_device
    executor_manager.load_data_batch(data_batch)
  File ""/Library/Python/2.7/site-packages/mxnet/executor_manager.py"", line 412, in load_data_batch
    self.curr_execgrp.load_data_batch(data_batch)
  File ""/Library/Python/2.7/site-packages/mxnet/executor_manager.py"", line 259, in load_data_batch
    _load_data(data_batch, self.data_arrays)
  File ""/Library/Python/2.7/site-packages/mxnet/executor_manager.py"", line 95, in _load_data
    _load_general(batch.data, targets)
AttributeError: 'NoneType' object has no attribute 'data'
  
---
Here is the code:

    optimizer = mx.optimizer.SGD(momentum=0.99)  # lr_scheduler=lr_scheduler)
    model = mx.model.FeedForward(
        allow_extra_params=True,
        ctx=dev,
        symbol=network,
        num_epoch=200,
        learning_rate=0.1*1e-2,
        wd=0.0001,
        initializer=mx.init.Load(""./ResNet/resnet-18-0000.params"", default_init=mx.init.Xavier(rnd_type=""gaussian"", factor_type=""in"", magnitude=2)),
        optimizer=optimizer)
    model.fit(X=train_set,
              eval_metric=Auc(),
              kvstore='local_allreduce_device',
              batch_end_callback=mx.callback.Speedometer(batch_size, 10),
              epoch_end_callback=mx.callback.do_checkpoint(""models/ir-blur""))",,"[""I debug the code and find that the error occurs when i run iter on my train data.\r\nHere is the simplified code:\r\n\r\ntrain_set = DataIter(...)\r\nfor batch in train_set:\r\n       print len(batch)\r\n\r\nAn error will tell me the batch is a 'NoneType' object and has no len().\r\nMy DataIter is customerized following the link: http://mxnet.io/tutorials/basic/data.html\r\n\r\nI don't know why this happens."", 'The next() function in my data iter is wrong.']",[],[],0,0
84,incubator-mxnet,15658,closed,profile_symbolic flag not working in profiler,"We use  to control the profiler's behaviors, i.e. what to profile.
 and  are two parameters to control whether to profile operators called in the two modes respectively. However, it seems currently  is not functioning correctly.

In the screenshot below, we have a simple scrip that has  in symbolic mode and  in imperative mode.  and  are both set to  and we do see both events in .

![Screen Shot 2019-07-25 at 10 55 47 AM](https://user-images.githubusercontent.com/16669457/61897220-78376080-aecb-11e9-82dd-68cff9b83c6d.png)

However, if we set  and  to . The  event is gone, but we still have the  event, which is not the expected behavior.

![Screen Shot 2019-07-25 at 10 56 16 AM](https://user-images.githubusercontent.com/16669457/61897214-753c7000-aecb-11e9-89a6-e876b0b6ccb3.png)

MXNet version: from 1.4 to 1.6 (last night build) (I only tested as far as 1.4)
Python version: 2&3
",Bug Profiler,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Bug', '@mxnet-label-bot  add [Profiler, Bug]', 'I looked into the code. It seemed like even though `profile_symbolic` was defined, it was never used anywhere. @anirudh2290 do you know about this?']",[],"['profiler.set_config()', 'profile_symbolic', 'profile_imperative', 'profiler_symbolic', 'plus_scalar', 'minus_scalar', 'profile_symbolic', 'profile_imperative', 'True', 'profiler.dumps()', 'profile_symbolic', 'profile_imperative', 'False', 'minus_sclar', 'plus_scalar']",0,0
85,incubator-mxnet,8016,closed,mxnet installation GPU validation issue/error,"Hi. I ran into an mxnet installation GPU validation issue on the Nvidia TX1 (Ubuntu 16.04). I built mxnet from source according to the Device Jetson TX2 GPU directions at:
[https://mxnet.incubator.apache.org/get_started/install.html#validate-mxnet-installation](url)

The CPU validation code works just fine, but the GPU errors (see attached log file):

>>> import mxnet as mx
>>> a = mx.nd.ones((2, 3), mx.gpu())
>>> b = a * 2 + 1
>>> b.asnumpy()
array([[ 3.,  3.,  3.],
       [ 3.,  3.,  3.]], dtype=float32)


For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
Ubuntu 16.04

Compiler:
g++ (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609

Package used (Python/R/Scala/Julia):

MXNet version:
mxnet===0.11.1

Or if installed from source:
git clone https://github.com/dmlc/mxnet.git --recursive

MXNet commit hash ():
ebf1bf9d3a6cef335a5b2c2a37175e9e91f5b546

If you are using python package, please provide
pip (9.0.1)

Python version and distribution:
Python 2.7.12 (default, Nov 19 2016, 06:48:10) 

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.
>>> [19:27:21] /home/nvidia/mxnet/dmlc-core/include/dmlc/./logging.h:308: [19:27:21] /home/nvidia/mxnet/mshadow/mshadow/././././cuda/tensor_gpu-inl.cuh:110: Check failed: err == cudaSuccess (8 vs. 0) Name: MapPlanKernel ErrStr:invalid device function
(see attached log file)

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.
>>> import mxnet as mx
>>> a = mx.nd.ones((2, 3), mx.gpu())
>>> b = a * 2 + 1
>>> b.asnumpy()
array([[ 3.,  3.,  3.],
       [ 3.,  3.,  3.]], dtype=float32

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.
2.
3.

## What have you tried to solve it?

1. reinstalled
2.
3.

[mxnet-out.log](https://github.com/apache/incubator-mxnet/files/1327872/mxnet-out.log)
",Installation,"['@arank Do you know if anything on Jetson could cause this?', "" this is giving a CUDA error so it is probably isn't finding your CUDA install or the version of CUDA you installed and mxnet expects is off. Did you go through the Jetpac setup to get the CUDA/CUDNN drivers onto the machine? What version of CUDA/CUDNN do you have?"", ""I've tested that this works as expected with recent builds.  As mentioned previously it was likely an environment issue.  @kaisark Please let us know if this is still causing you problems."", '@sandeep-krishnamurthy @eric-haibin-lin  Could one of you please close this issue?']",[],"['git rev-parse HEAD', 'sessionInfo()']",0,0
86,incubator-mxnet,3395,closed,Checked failed: cuudnnConvolutionForward,"Hi All MXNET users:

Recently I downloaded the latest MXNET. I tried to train ILSVRC2012 data with MXNET, but I could not train with alexnet and inception-bn network.
If I use inception-bn network, 
../../tools/launch.py -H hosts -n 2 --launcher ssh python train_imagenet.py --network inception-bn --gpus 0,1,2,3 --batch-size 144 --num-epochs 1 --lr 0.05 --lr-factor 0.94 --data-shape 256 --data-dir ../../data/ilsvrc12/ --kv-store dist_sync

it has the following error:
[10:45:00] /cm/shared/scratch/rengan/DL/mxnet/dmlc-core/include/dmlc/logging.h:235: [10:45:00] src/operator/./cudnn_convolution-inl.h:113: Check failed: (cudnnConvolutionForward(s->dnn_handle_, &alpha, in_desc_, data_ptr + data_offset_ \* g, filter_desc_, wmat_ptr + weight_offset_ \* g, conv_desc_, algo_, workspace.dptr_, forward_workspace_byte_, &beta, out_desc_, out_ptr + out_offset_ \* g)) == (CUDNN_STATUS_SUCCESS)

[10:45:00] /cm/shared/scratch/rengan/DL/mxnet/dmlc-core/include/dmlc/logging.h:235: [10:45:00] src/engine/./threaded_engine.h:306: [10:45:00] src/operator/./cudnn_convolution-inl.h:113: Check failed: (cudnnConvolutionForward(s->dnn_handle_, &alpha, in_desc_, data_ptr + data_offset_ \* g, filter_desc_, wmat_ptr + weight_offset_ \* g, conv_desc_, algo_, workspace.dptr_, forward_workspace_byte_, &beta, out_desc_, out_ptr + out_offset_ \* g)) == (CUDNN_STATUS_SUCCESS)

An fatal error occurred in asynchronous engine operation. If you do not know what caused this error, you can try set environment variable MXNET_ENGINE_TYPE to NaiveEngine and run with debugger (i.e. gdb). This will force all operations to be synchronous and backtrace will give you the series of calls that lead to this error. Remember to set MXNET_ENGINE_TYPE back to empty after debugging.

The alexnet has the same error as inception-bn.

Does anyone know why I got these errors? Thanks.

Regards,
Rengan
",,['This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!'],[],[],0,0
87,incubator-mxnet,15376,closed,beta website doesn't render html tags for images,"## Description

When trying to fix https://github.com/mli/new-docs/pull/123
I found that html code that should render fine in a markdown file, doesn't get converted when building the site. However, video html codes worked fine.
There's no warning or error. It just skips those lines of code.

Seems like a bug with the new site's build.

Refer to this commit to see the difference of what was there before that didn't work, compared to was did work. https://github.com/mli/new-docs/pull/123/commits/58b88f83b91c31f2fa31a5810f9563ed581a498c",Bug,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Doc']",[],[],0,0
88,incubator-mxnet,3647,closed,Question on SequenceMask OP,"http://mxnet.io/api/python/symbol.html#mxnet.symbol.SequenceMask

It said 

>  If sequence_length is false, then each example in the batch is assumed to have the max sequence length, and this operator becomes the identity operator.

First I think the sequence_length parameter here mentioned should be use_sequence_length.

Then this document means this op works only if I set use_sequence_length is true, otherwise it's just an identity OP. 
Therefore why do we need this parameter? Why it shouldn't be true by default?
",,"[""Good question: you are correct, by default, its the identity op. The reason for this strange looking design: it brings consistency with the other sequence ops (`SequenceLast` and `SequenceReverse`) which often just want to be used without specifying sequence lengths. \n\nHonestly, I'm leaning towards requiring sequence length the default behaviour for all these ops. Not sure if its too late to change the behaviour.\n"", 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
89,incubator-mxnet,14712,closed,Conv3DTranspose not work in Ubuntu.,"This is my code

But report a cudnn bug, I also tried nvidia-docker (official) also not work too.
",Bug CUDA Gluon,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Bug', 'Also, I tried to reduce/model size is not work too.', '@mxnet-label-bot add [gluon, bug, cuda]', 'windows could run the same code but Ubuntu can’t.', '@PistonY What GPU do you have? Can you share the nvidia-smi outputs?', 'I use GTX 1070 with CUDA10.\r\n```\r\nNVIDIA-SMI 410.48                 Driver Version: 410.48                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 1070    Off  | 00000000:01:00.0  On |                  N/A |\r\n|  0%   49C    P8    10W / 180W |    787MiB /  8116MiB |      0%      Default |\r\n```\r\nHave you tested it on Ubuntu? My workmate also has this issue.', 'What is the version of CUDNN?\r\nIt works on Ubuntu 16.04, CUDA 8.0, CUDNN 7.3.0, TITAN X.', '@wkcn   \r\nCUDNN 7.0.5, CUDA 9.0, Ubuntu 16.04  \r\n```\r\nerror:\r\nmxnet.base.MXNetError: [10:55:33] src/operator/nn/./cudnn/cudnn_deconvolution-inl.h:849: Failed to find any forward deconvolution algorithm with workspace size of 536870912 bytes, please consider reducing batch/model size or increasing the workspace size\r\n```', 'works on Ubuntu 16.04, CUDA 10.1, CUDNN 7, mxnet 1.3.1', 'minimum cuDNN version required to support CUDA 10 is 7.3.1\r\n@PistonY can you please check your cuDNN version?\r\n\r\nAlso, could you please tell us how you installed MXNet?', 'Duplicate of #13135 ', 'Closing it in favor of #13135 Please reopen if you see the issue is different.']","['python\r\nimport mxnet\r\nfrom mxnet import nd\r\nfrom mxnet.gluon import nn\r\n\r\nab = nd.random.normal(shape=(1, 64, 4, 4, 4),ctx=mx.gpu())\r\nfra = nn.Conv3DTranspose(channels=32, kernel_size=3, padding=1)\r\n\r\nfra.initialize(ctx=mx.gpu())\r\nprint(fra(ab))\r\n', '\r\n[18:24:26] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\nTraceback (most recent call last):\r\n  File ""/home/piston/PycharmProjects/iqiyi-cvic/match/test.py"", line 11, in <module>\r\n    print(fra(ab))\r\n  File ""/home/piston/.conda/envs/mxnet/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py"", line 193, in __repr__\r\n    return \'\\n%s\\n<%s %s @%s>\' % (str(self.asnumpy()),\r\n  File ""/home/piston/.conda/envs/mxnet/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py"", line 1992, in asnumpy\r\n    ctypes.c_size_t(data.size)))\r\n  File ""/home/piston/.conda/envs/mxnet/lib/python3.7/site-packages/mxnet/base.py"", line 252, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [18:24:26] src/operator/nn/./cudnn/cudnn_deconvolution-inl.h:867: Failed to find any forward deconvolution algorithm with workspace size of 536870912 bytes, please consider reducing batch/model size or increasing the workspace size\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /home/piston/.conda/envs/mxnet/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x4271f2) [0x7fc48762f1f2]\r\n[bt] (1) /home/piston/.conda/envs/mxnet/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x4277d8) [0x7fc48762f7d8]\r\n[bt] (2) /home/piston/.conda/envs/mxnet/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x3f79c82) [0x7fc48b181c82]\r\n[bt] (3) /home/piston/.conda/envs/mxnet/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x3f7e0b1) [0x7fc48b1860b1]\r\n[bt] (4) /home/piston/.conda/envs/mxnet/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x3f6f2e2) [0x7fc48b1772e2]\r\n[bt] (5) /home/piston/.conda/envs/mxnet/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x3f6f707) [0x7fc48b177707]\r\n[bt] (6) /home/piston/.conda/envs/mxnet/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x3f7079d) [0x7fc48b17879d]\r\n[bt] (7) /home/piston/.conda/envs/mxnet/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x3f716d3) [0x7fc48b1796d3]\r\n[bt] (8) /home/piston/.conda/envs/mxnet/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x3f772ae) [0x7fc48b17f2ae]\r\n[bt] (9) /home/piston/.conda/envs/mxnet/lib/python3.7/site-packages/mxnet/libmxnet.so(mxnet::imperative::PushFCompute(std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)> const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<unsigned int, std::allocator<unsigned int> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&)::{lambda(mxnet::RunContext)#1}::operator()(mxnet::RunContext) const+0x36d) [0x7fc48a44db9d]\r\n\r\n']",[],0,0
90,incubator-mxnet,3814,closed,installation error for scala package,"I try to install mxnet for scala-package following the installation guide. After building the shared library, then execute the command: make scalapkg.
But I got an error: 
Failed to execute goal net.alchim31.maven:scala-maven-plugin:3.2.2:compile (default) on project mxnet-init_2.11: Execution default of goal net.alchim31.maven:scala-maven-plugin:3.2.2:compile failed. CompileFailed
Anybody knows how to solove it?  Thank you so much.",,['This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!'],[],[],0,0
91,incubator-mxnet,7415,closed,Caffe-converter convert_model.py fail,"Hi, tried converting a caffe model.
The convert_symbol ran successfully, but the convert_model crashed.
I know the model works fine on caffe. I don't know any details about the model.

## Environment info
Operating System:
Ubuntu 16.04

Package used (Python/R/Scala/Julia):
Python

MXNet commit hash ():
89e3ee3ea7c223db8c65ddd8c94c6e787d7c52df
If you are using python package, please provide

Python version and distribution:
python 2.7

## Error Message:
Please paste the full error message, including stack trace.

converting layer fc6, wmat shape = (22440, 512)fc6_bias not found in arg_shape_dic.
        skipping layer softmaxloss1 of type SoftmaxWithLoss
        skipping layer center_loss_1 of type CenterLoss
Traceback (most recent call last):
  File ""convert_model.py"", line 220, in <module>
    main()
  File ""convert_model.py"", line 216, in main
    convert_model(args.prototxt, args.caffemodel, args.save_model_name)
  File ""convert_model.py"", line 198, in convert_model
    assert len(layer_blobs) == 0
AssertionError

## Steps to reproduce

1. run tools/caffe_converter$ python convert_model.py proto caffemodel filename

",,"['This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!\nAlso, do please check out our [forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) for general ""how-to"" questions.']",[],['git rev-parse HEAD'],0,0
92,incubator-mxnet,11700,closed,test_loss.test_sample_weight_loss has fixed seed that can mask flakiness,"The unit test in title have been using fixed seed to mask flakiness. Suggested action:
1. Evaluate whether the test is flaky without fixed seed. If not, remove seed. Else move to 2
2. If test is flaky, determine whether it's an actual uncaught edge case. If so, fix the operator. Else move to 3
3. If numerical instability is inevitable, adjust tolerance level appropriately.
",Flaky Test,"['Thanks for filing this issue. We will investigate this Flaky test', 'Ran it on a EC2 GPU instance for 25K runs, with random seeds, all of them pass. I guess we can enable random seeds, the test does not seem flaky.', '@sandeep-krishnamurthy Related PR is merged, should be good to close.']",[],[],0,0
93,incubator-mxnet,12949,closed,text contrib module docs errors,"## Description
Sphinx is throwing errors on the  and  modules.

## Error

",Doc,"['@mxnet-label-bot add [doc]', '@mxnet-label-bot [good first issue]', '@mxnet-label-bot [Good First Issue]']",['\r\n/home/ubuntu/incubator-mxnet/python/mxnet/contrib/text/embedding.py:docstring of mxnet.contrib.text.embedding.GloVe:40: SEVERE: Unexpected section title.\r\n\r\nProperties\r\n----------\r\n/home/ubuntu/incubator-mxnet/python/mxnet/contrib/text/embedding.py:docstring of mxnet.contrib.text.embedding.FastText:54: SEVERE: Unexpected section title.\r\n\r\nProperties\r\n----------\r\n/home/ubuntu/incubator-mxnet/python/mxnet/contrib/text/embedding.py:docstring of mxnet.contrib.text.embedding.CustomEmbedding:31: SEVERE: Unexpected section title.\r\n\r\nProperties\r\n----------\r\n/home/ubuntu/incubator-mxnet/python/mxnet/contrib/text/embedding.py:docstring of mxnet.contrib.text.embedding.CompositeEmbedding:18: SEVERE: Unexpected section title.\r\n\r\nProperties\r\n----------\r\n/home/ubuntu/incubator-mxnet/python/mxnet/contrib/text/vocab.py:docstring of mxnet.contrib.text.vocab.Vocabulary:34: SEVERE: Unexpected section title.\r\n'],"['contrib.text.embedding', 'contrib.text.vocab']",0,0
94,incubator-mxnet,14437,closed,compile error ,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
I did the following:

git clone --recursive https://github.com/apache/incubator-mxnet.git
cd incubator-mxnet
make -j4



## Error Message:
![image](https://user-images.githubusercontent.com/48436808/54449650-98bb1580-4789-11e9-8eda-33ad937ee9ec.png)

Can someone  tell me how to solve this issue.",Build,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Build', 'Please install cmake', 'Thank you\r\nI instaledl cmake,and got the following error:\r\n![image](https://user-images.githubusercontent.com/48436808/54470280-f37f5c00-47df-11e9-9560-47b40c7f9ce1.png)\r\n\r\n', 'Seems BLAS is missing. You need install either openblas or mkl and set USE_BLAS=openblas or mkl respectively in the make line.', 'BTW, you can follow this document to build MXNet from source: https://mxnet.incubator.apache.org/versions/master/install/ubuntu_setup.html#build-mxnet-from-source', '@yongfang1995  It looks like you have finished the compilation successfully. I will close the issue now. Feel free to reopen if you still have problem on it.']",[],[],0,0
95,incubator-mxnet,12087,closed,Python list as a gluon Dataset,"
This causes an error in the recent master.

The code has worked in some days ago. I guess #11370 brokes it. According to the API doc, any types with  and  can be used as a Dataset. #11370 is temporal but I think it would be a good idea to avoid breaking existing code. @zhreshold ",Bug Gluon,"['@mxnet-label-bot could you please add [gluon, bug] to this label?']","['python\r\ndata = mx.gluon.data.DataLoader([([1,2], 0), ([3, 4], 1)], batch_size=1, num_workers=2) \r\nfor d, l in data:\r\n    pass\r\n', '\r\nTraceback (most recent call last):\r\n  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 258, in _bootstrap\r\n    self.run()\r\n  File ""/usr/lib/python3.6/multiprocessing/process.py"", line 93, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File ""/usr/lib/python3.6/site-packages/mxnet-1.3.0-py3.6.egg/mxnet/gluon/data/dataloader.py"", line 154, in worker_loop\r\n    dataset._fork()\r\nAttributeError: \'list\' object has no attribute \'_fork\'\r\n']","['__getitem__', '__len__']",0,0
96,incubator-mxnet,16560,closed,It is easy to crash MXNet when tensor goes larger,"## Description
When I use large tensor, it is easy to crash the MXNet kernel.
Using following python code to reproduce:


The error looks like an int32 overflow on shape.size.
Any easy way to fix this out? The only way I found out is to compile MXNet with USE_INT64_TENSOR_SIZE = ON, which is slower than the default one.

## Environment info (Required)
mxnet 1.5.1 (pip3 install)

Package used (Python/R/Scala/Julia):
Python

## Error Message:
",Bug,"['@mxnet-label-bot Add [Bug, Large Tensor Support]', 'cc @access2rohit ', 'We should raise an error message in the C++ side when we are going to create a large NDArray.', 'Yes it is being tracked here #16570 ', 'Is this resolved now that #16570 is merged?', '@lanking520 assign @ChaiBapchya ', ""We can close this ticket. As the solution is to build with large tensor as the issue author pointed it out. An error message is already raised as part of #16570 if large array is created when large tensor support isn't enabled.""]","['\r\n>>> import mxnet.ndarray as nd\r\n\r\n>>> a = nd.random.randn(4, 256, 1, 100, 100)\r\n>>> b = nd.broadcast_axis(a, axis=2, size=256)\r\n>>> b.size\r\n2621440000\r\n>>> b.asnumpy()\r\nCRASH HERE\r\n', '\r\nTraceback (most recent call last):\r\n  File ""<stdin>"", line 1, in <module>\r\n  File ""/usr/local/lib/python3.5/dist-packages/mxnet/ndarray/ndarray.py"", line 1996, in asnumpy\r\n    ctypes.c_size_t(data.size)))\r\n  File ""/usr/local/lib/python3.5/dist-packages/mxnet/base.py"", line 253, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [07:26:09] include/mxnet/././tensor_blob.h:290: Check failed: this->shape_.Size() == static_cast<size_t>(shape.Size()) (2621440000 vs. 18446744072036024320) : TBlob.get_with_shape: new and old shape do not match total elements\r\n']",[],0,0
97,incubator-mxnet,15194,closed,How do I get the smoothest installation experience in R (GPU version)?,"Assume, I'm a total idiot (indeed, I feel like one, at least like a bloody beginner...)

This whole neural net installation for GPU is a total nightmare. I came here after failing to get tensorflow to run. Seems like it's the same disaster with MXNet. People, it's awesome that these tools are free to use for a hobbyist like me, but not everybody is a professional developer! I will keep learning of course, but this hurdle is just too high at the moment.

This is my whole installation Routine:

Windows 10 Version 10.0.18362.145 64bit (clean install)
R-3.6.0 -> uninstalled and installed R-3.5.2 later
R-Studio 1.2.1335
Rtools35
Nvidia Display Driver 26.21.14.3086 (GTX 1060 3GB)
cuda_9.0.176_win10 -> update to 9.0.176.1 -> 9.0.176.2 -> 9.0.176.3 (
cudnn-9.0-windows10-x64-v7.1.zip -> unzip cudnn64_7.dll to C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\bin
Anaconda3-2019.03-Windows-x86_64 -> downgrade to Anaconda3-5.2.0-Windows-x86_64 after problems with tensorflow -> re-upgrade back later to Anaconda3-2019.03-Windows-x86_64

In R-Studio, I called:

Calling  i get this:

> Error: package or namespace load failed for ‘mxnet’:
>  .onLoad failed in loadNamespace() for 'mxnet', details:
>   call: inDL(x, as.logical(local), as.logical(now), ...)
>   error: unable to load shared object 'D:/Benutzer/MyName/Documents/R/win-library/3.5/mxnet/libs/x64/libmxnet.dll':
>   LoadLibrary failure:  Die angegebene Prozedur wurde nicht gefunden. (German for ""the specified procedure wasn't found"")
> 

Is there any older version that a dumb end user like me can get running by just copying and pasting some lines of R code in the R terminal and execute these?",Installation R,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Installation', 'Fixed with `devtools::install_github(""rstudio/reticulate"")`']","['\r\ncran <- getOption(""repos"")\r\ncran[""dmlc""] <- ""https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/GPU/cu90""\r\noptions(repos = cran)\r\ninstall.packages(""mxnet"")\r\n']","[""library('mxnet') ""]",0,0
98,incubator-mxnet,1325,closed,Compiling MxNet with GPU support in R,"I'm having some trouble compiling the mxnet package in R with GPU support enabled on an Ubuntu machine in an AWS instance. Like many others before, I get the error 



when I run any GPU algorithms in R. However, I know for sure that I have installed CUDA correctly and I compiled mxnet with the settings  



in the config.mk file (which sits in mxnet root) with no compilation errors as well as recompiled the R package with 



Is there something else that I'm missing here?
",R,"['My suggestion is `make clean_all;make`. Pay attention to if `nvcc` is actually used.\n\nLet me know if you still meet some errors.\n', 'Thanks! This seems to have worked. Before I was only using `make clean` instead of `make clean_all`.\n']","[' R\nsrc/storage/storage.cc:44: Please compile with CUDA enabled\n', ' bash\nUSE_CUDA=1\nUSE_CUDA_PATH=/usr/local/cuda\n', ' R\nsudo R CMD INSTALL mxnet_0.5.tar.gz\n']",[],0,0
99,incubator-mxnet,1272,closed,Max Pooling Index,"Is there any way that we could get the position of max pooling operations. For example, [[1,2], [3,4]] to [4], we could get [[0, 0], [0, 1]], thanks
",,"[""pooling doesn't maintain a map. It use == check to determine source in backward.\n""]",[],[],0,0
100,incubator-mxnet,10694,closed,Importing an ONNX model (from model zoo) to MXNet errors out,"## Description
Importing an ONNX model to MXNet errors out.
Model: [FER+ Emotion Recognition](https://github.com/onnx/models/tree/master/emotion_ferplus)
This may be an issue with the ONNX model itself, but it is on the ONNX model zoo so I assume it is tested regularly.

To reproduce:
- Download the ONNX model listed above into the working directory, add signature.json and synset.txt
- Use new MXNet ONNX contrib API to import ONNX model into MXNet

Expected result: emotion-detection sym and params are returned
Actual result: errors out

## Environment info (Required)


File ""/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/import_model.py"", line 53, in import_model
    sym, arg_params, aux_params = graph.from_onnx(model_proto.graph)
  File ""/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/import_onnx.py"", line 114, in from_onnx
    mxnet_sym = self._convert_operator(node_name, op_name, onnx_attr, inputs)
  File ""/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/import_onnx.py"", line 58, in _convert_operator
    op_name, new_attrs, inputs = convert_map[op_name](attrs, inputs, self)
  File ""/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/op_translations.py"", line 216, in conv
    new_attrs = translation_utils._fix_channels('Convolution', new_attrs, inputs, cls)
  File ""/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/translation_utils.py"", line 172, in _fix_channels
    raise ValueError(""Unable to get channels/units attr from onnx graph."")
ValueError: Unable to get channels/units attr from onnx graph.
`
",Bug ONNX,"['@anirudhacharya @spidyDev @Roshrini ', 'These are the tests running on onnx CI with the latest master - https://github.com/onnx/onnx/blob/master/onnx/backend/test/case/model/__init__.py#L39. \r\n\r\nONNX v1.1 which we are using for our tests has one less than the list. This error is occurring while translating the convolution operator, and it would seem the translator is unable to find the channel information in the ONNX graph. But have to take a closer look. \r\n\r\nFollowing two models have been added since the v1.1 release -\r\n - [emotion_ferplus](https://github.com/onnx/models/commits/master/emotion_ferplus)\r\n - [tiny yolo](https://github.com/onnx/models/commits/master/tiny_yolov2)', '[FER+ Emotion Recognition](https://github.com/onnx/models/tree/master/emotion_ferplus) is using legacy attribute for convolution , **auto_pad**, which we do not support.\r\n\r\n**auto_pad : string**\r\n    auto_pad must be either SAME_UPPER, SAME_LOWER or VALID. Where SAME_UPPER or SAME_LOWER mean pad the input so that the output size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding. **DEPRECATION NOTE: auto_pad is only intended to support legacy uses, and for framework authors, one is explicitly encouraged to use explicit padding specified in the pads attribute.**', 'Thanks @spidyDev.\r\nClosing.', '@spidyDev can you create an issue [onnx-models repo](https://github.com/onnx/models/issues ) saying that the repo contains models with deprecated operators?\r\n\r\nBecause the repository README says that ""any implementation of ONNX needs to support these models out of the box"".']","[""\r\n----------Python Info----------\r\nVersion      : 3.6.4\r\nCompiler     : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)\r\nBuild        : ('default', 'Jan 16 2018 12:04:33')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 10.0.1\r\nDirectory    : /Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.2.0\r\nDirectory    : /Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet\r\nCommit Hash   : 7989782cca64db5469d31713e65d21c8e043bbc0\r\n----------System Info----------\r\nPlatform     : Darwin-16.7.0-x86_64-i386-64bit\r\nsystem       : Darwin\r\nnode         : 8c8590170440.ant.amazon.com\r\nrelease      : 16.7.0\r\nversion      : Darwin Kernel Version 16.7.0: Tue Jan 30 11:27:06 PST 2018; root:xnu-3789.73.11~1/RELEASE_X86_64\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : i386\r\nb'machdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT PREFETCHW RDTSCP TSCI'\r\nb'machdep.cpu.leaf7_features: SMEP ERMS RDWRFSGS TSC_THREAD_OFFSET BMI1 HLE AVX2 BMI2 INVPCID RTM SMAP RDSEED ADX IPT SGX FPU_CSDS MPX CLFSOPT'\r\nb'machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C'\r\nb'machdep.cpu.brand_string: Intel(R) Core(TM) i7-7660U CPU @ 2.50GHz'\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0187 sec, LOAD: 0.6492 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0438 sec, LOAD: 0.1820 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0206 sec, LOAD: 1.0483 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0231 sec, LOAD: 0.1971 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0180 sec, LOAD: 0.3810 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0190 sec, LOAD: 0.1072 sec."", '\r\n\r\n## Error Message:\r\n']",[''],0,0
101,incubator-mxnet,14022,closed,Segmentation fault during inference with quantization,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
I got ""Segmentation fault: 11"" error when I ran the following command,

""python imagenet_inference.py --symbol-file=./model/imagenet1k-inception-bn-quantized-5batches-naive-symbol.json --param-file=./model/imagenet1k-inception-bn-quantized-0000.params --rgb-mean=123.68,116.779,103.939 --num-skipped-batches=50 --batch-size=64 --num-inference-batches=500 --dataset=./data/val_256_q90.rec --ctx=cpu  --data-nthreads=1""

Please note: the model was quantized using ""imagenet_gen_qsym.py"" instead of ""imagenet_gen_qsym_mkldnn.py""

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
I am using Python

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)
INFO:logger:batch size = 64 for inference
INFO:logger:rgb_mean = 123.68,116.779,103.939   
INFO:logger:rgb_std = 1,1,1
INFO:logger:label_name = softmax_label
INFO:logger:Input data shape = (3, 224, 224)
INFO:logger:Dataset for inference: ./data/val_256_q90.rec
[14:01:27] src/io/iter_image_recordio_2.cc:170: ImageRecordIOParser2: ./data/val_256_q90.rec, use 1 threads for decoding..
INFO:logger:Loading symbol from file /work/projects/qat/incubator-mxnet-master/example/quantization/./model/imagenet1k-inception-
bn-quantized-5batches-naive-symbol.json
INFO:logger:Loading params from file /work/projects/qat/incubator-mxnet-master/example/quantization/./model/imagenet1k-inception-
bn-quantized-0000.params
INFO:logger:Skipping the first 50 batches
INFO:logger:Running model ./model/imagenet1k-inception-bn-quantized-5batches-naive-symbol.json for inference
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_conv
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_pooling
[14:01:34] src/executor/attach_op_execs_pass.cc:335: Neither FCompute nor FComputeEx registered _contrib_quantized_fully_connected

Segmentation fault: 11

Stack trace returned 10 entries:
[bt] (0) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x381822) [0x7fa65e7af822]
[bt] (1) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x368d87e) [0x7fa661abb87e]
[bt] (2) /lib/x86_64-linux-gnu/libc.so.6(+0x3ef20) [0x7fa6c57fbf20]
[bt] (3) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x2f3bcbe) [0x7fa661369cbe]
[bt] (4) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x2f3c661) [0x7fa66136a661]
[bt] (5) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x2f5c3d6) [0x7fa66138a3d6]
[bt] (6) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x2f63574) [0x7fa661391574]
[bt] (7) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(+0x2f63c64) [0x7fa661391c64]
[bt] (8) /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet/libmxnet.so(MXExecutorSimpleBind+0x2260) [0x7fa6612ed940]
[bt] (9) /work/anaconda3/envs/py3/lib/python3.7/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7fa6c3f63ec0]
## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

https://github.com/apache/incubator-mxnet/tree/master/example/quantization

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. python imagenet_gen_qsym.py --model=imagenet1k-inception-bn --num-calib-batches=5 --calib-mode=naive 
(Note: This command worked fine)
2. python imagenet_inference.py --symbol-file=./model/imagenet1k-inception-bn-quantized-5batches-naive-symbol.json --param-file=./model/imagenet1k-inception-bn-quantized-0000.params --rgb-mean=123.68,116.779,103.939 --num-skipped-batches=50 --batch-size=64 --num-inference-batches=500 --dataset=./data/val_256_q90.rec --ctx=cpu  --data-nthreads=1 
(Note: This command stopped and returned error)

## What have you tried to solve it?

1.
2.
",Quantization,"[""@nuslq log indicates that there's no implementation for quantized convolution. MXNet quantization flow only works for either CUDA or MKLDNN build. As you are using MXNet without CUDA, so I assume you want to run with CPU. You can try MXNet with MKLDNN and use imagenet_gen_qsym_mkldnn.py instead."", 'Thanks @ZhennanQin :)\r\n\r\n@nuslq you can refer https://github.com/apache/incubator-mxnet/tree/master/example/quantization#1\r\nFeel free to ping us for any question ', 'closing this for now. please feel free to comment/reopen if you come across this issue again']",[],"['', '\r\nWhat to do:\r\n1. Download the diagnosis script from https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/diagnose.py\r\n2. Run the script using ', "" and paste its output here.\r\n\r\nArchitecture:        x86_64\r\nCPU op-mode(s):      32-bit, 64-bit\r\nByte Order:          Little Endian\r\nCPU(s):              24\r\nOn-line CPU(s) list: 0-23\r\nThread(s) per core:  2\r\nCore(s) per socket:  6\r\nSocket(s):           2\r\nNUMA node(s):        2\r\nVendor ID:           GenuineIntel\r\nCPU family:          6\r\nModel:               45\r\nModel name:          Intel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz\r\nStepping:            7\r\nCPU MHz:             1197.129\r\nCPU max MHz:         2500.0000\r\nCPU min MHz:         1200.0000\r\nBogoMIPS:            3990.41\r\nVirtualization:      VT-x\r\nL1d cache:           32K\r\nL1i cache:           32K\r\nL2 cache:            256K\r\nL3 cache:            15360K\r\nNUMA node0 CPU(s):   0-5,12-17\r\nNUMA node1 CPU(s):   6-11,18-23\r\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx lahf_lm epb pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid xsaveopt dtherm ida arat pln pts flush_l1d\r\n----------Python Info----------\r\nVersion      : 3.7.2\r\nCompiler     : GCC 7.3.0\r\nBuild        : ('default', 'Dec 29 2018 06:19:36')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 18.1\r\nDirectory    : /work/anaconda3/envs/py3/lib/python3.7/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.3.1\r\nDirectory    : /work/anaconda3/envs/py3/lib/python3.7/site-packages/mxnet\r\nCommit Hash   : 19c501680183237d52a862e6ae1dc4ddc296305b\r\n----------System Info----------\r\nPlatform     : Linux-4.15.0-43-generic-x86_64-with-debian-buster-sid\r\nsystem       : Linux\r\nnode         : u698118817fd358.ant.amazon.com\r\nrelease      : 4.15.0-43-generic\r\nversion      : #46-Ubuntu SMP Thu Dec 6 14:45:28 UTC 2018\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0088 sec, LOAD: 0.6208 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0081 sec, LOAD: 0.0679 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0082 sec, LOAD: 0.1198 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0079 sec, LOAD: 0.1090 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0082 sec, LOAD: 0.1756 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0080 sec, LOAD: 0.0468 sec.\r\n\r\n"", '', 'java -version', 'mvn -version', 'scala -version', 'sessionInfo()', 'git rev-parse HEAD']",0,0
102,incubator-mxnet,4697,closed,[Scala] Symbol is not serializable,"## Environment info
Operating System: debian testing

Compiler: 

Package used (Python/R/Scala/Julia): Scala 2.11, Spark 2.0.1

MXNet version: 

Or if installed from source:  from master 2017-01-16

MXNet commit hash ():


## Error Message:
2017-01-17 16:20:38,890 ERROR executor.Executor (Logging.scala:logError(91)) - Exception in task 0.0 in stage 1.0 (TID 1)
java.io.NotSerializableException: ml.dmlc.mxnet.Symbol
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1184)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at ml.dmlc.mxnet.JavaSerializer.serialize(Serializer.scala:48)
	at ml.dmlc.mxnet.KVStore.setOptimizer(KVStore.scala:187)
	at ml.dmlc.mxnet.Model$$anonfun$trainMultiDevice$4.apply(Model.scala:259)
	at ml.dmlc.mxnet.Model$$anonfun$trainMultiDevice$4.apply(Model.scala:259)
	at scala.Option.foreach(Option.scala:257)
	at ml.dmlc.mxnet.Model$.trainMultiDevice(Model.scala:259)
	at ml.dmlc.mxnet.FeedForward.fit(FeedForward.scala:347)
	at ml.dmlc.mxnet.FeedForward.fit(FeedForward.scala:286)
	at ml.dmlc.mxnet.FeedForward.fit(FeedForward.scala:294)
	at ml.dmlc.mxnet.FeedForward.fit(FeedForward.scala:300)
	at ml.dmlc.mxnet.spark.MXNet$$anonfun$1.apply(MXNet.scala:168)
	at ml.dmlc.mxnet.spark.MXNet$$anonfun$1.apply(MXNet.scala:127)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:332)
	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:330)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:935)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

## Minimum reproducible example

## Steps to reproduce
run  example

## What have you tried to solve it?
it seems that the commit [[Scala] Bucketing API Support](https://github.com/dmlc/mxnet/commit/4d9ac5b77d3a5ad7b34d69f972386b9ae36d68c6) which adds  to  causes the problem. 
1. since symbol is not used right now, just remove it from  temporarily
2. or convert symbol to json in 
",,"[""I didn't test the spark task when I built the bucketing api. Sorry for that. \r\nSeems that we can solve it by modifying the implementation of `ml.dmlc.mxnet.Serializer`."", '@javelinjs Did you solve it? I still have the problem with the latest source code.\r\n', '@yxzf I also got the same issue. For now, if you want to run the example, you can remove symbol code from ml.dmlc.mxnet.Optimizer temporarily and it will work fine.', ""@Roshrini @yxzf \r\nYou can mark symbol as transient to solve this problem ( i.e., ` @transient protected var symbol: Symbol = null` in line 53) , which means don't Serializer/Derializer this variable. Then, everything goes on well.\r\n\r\nThanks to @huafengw . :+1: "", 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],"['git rev-parse HEAD', 'mxnet/scala-package/spark/bin/run-mnist-example.sh', 'Symbol', 'Optimizer', 'Optimizer', 'Optimizer']",0,0
103,incubator-mxnet,9279,closed,should gluon use the sublinear memory,"I set export MXNET_BACKWARD_DO_MIRROR=1 while use gluon 
Does this environment work in gluon?
Thanks a lot
",,"[""It doesn't work in Gluon yet"", 'Related: #6644', '@sandeep-krishnamurthy  Please close this issue, as the query was answered.']",[],[],0,0
104,incubator-mxnet,887,closed,Latest pull (today Dec 9) fails to build on mac,"Dear All,

I pulled the code again today and fail to build (I have successfully built it before). This is the error I get:

pkg-config --cflags opencvpkg-config --cflags opencvpkg-config --cflags opencv
",,"['try update submodule by git submodule update\n', '@winstywang A lot of people seems to stumble on this. Is there a way to force always update submodule?\n', 'Yep, that works. Thank you. \n']",[],"['', '\ng++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -I/System/Library/Frameworks/Accelerate.framework/Versions/Current/Frameworks/vecLib.framework/Versions/Current/Headers/ -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1 ', ' -DMSHADOW_USE_CUDNN=1  -c src/operator/swapaxis.cc -o build/operator/swapaxis.o\ng++ -std=c++0x -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -I/System/Library/Frameworks/Accelerate.framework/Versions/Current/Frameworks/vecLib.framework/Versions/Current/Headers/ -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1 ', ' -DMSHADOW_USE_CUDNN=1  -MM -MT build/operator/upsampling.o src/operator/upsampling.cc >build/operator/upsampling.d\ng++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -I/System/Library/Frameworks/Accelerate.framework/Versions/Current/Frameworks/vecLib.framework/Versions/Current/Headers/ -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1 ', "" -DMSHADOW_USE_CUDNN=1  -c src/operator/upsampling.cc -o build/operator/upsampling.o\nIn file included from src/operator/upsampling.cc:9:\nsrc/operator/./upsampling-inl.h:77:63: error: use of undeclared identifier 'upsampling_nearest'\n        Assign(slice<1>(out, begin, end), req[up_enum::kOut], upsampling_nearest(data, scale));\n                                                              ^\nsrc/operator/./operator_common.h:36:18: note: expanded from macro 'Assign'\n        (out) = (exp);                  \\\n                 ^\nsrc/operator/./upsampling-inl.h:56:12: note: in instantiation of member function 'mxnet::op::UpSamplingNearestOp<mshadow::cpu>::Forward'\n      requested here\n  explicit UpSamplingNearestOp(UpSamplingParam p) {\n           ^\nsrc/operator/upsampling.cc:16:16: note: in instantiation of member function\n      'mxnet::op::UpSamplingNearestOp<mshadow::cpu>::UpSamplingNearestOp' requested here\n    return new UpSamplingNearestOp<cpu>(param);\n               ^\nIn file included from src/operator/upsampling.cc:9:\nsrc/operator/./upsampling-inl.h:77:63: error: use of undeclared identifier 'upsampling_nearest'\n        Assign(slice<1>(out, begin, end), req[up_enum::kOut], upsampling_nearest(data, scale));\n                                                              ^\nsrc/operator/./operator_common.h:39:19: note: expanded from macro 'Assign'\n        (out) += (exp);                 \\\n                  ^\n2 errors generated.\nmake: *** [build/operator/upsampling.o] Error 1\n"", '']",0,0
105,incubator-mxnet,7386,closed,How could I define function for GPU only?,"I need  to define a function in .h file for GPU version only, then implenent it in .cu file, 
declaration in .h:

implement in .cu file:

the problem is I am force to declare the same function for CPU version and implement it, or it will compile failed
I just need the function for GPU, How could I get ride of this problem?
 ",,[],"['\r\n void channelwise_Forward(mshadow::Stream<cpu> *stream,\r\n                          const std::vector<TBlob> &in_data,\r\n                          const std::vector<TBlob> &out_data);\r\n  void channelwise_Backward_input(mshadow::Stream<cpu> *stream,\r\n                          const std::vector<TBlob> &in_data,\r\n                          const std::vector<TBlob> &in_grad,\r\n                          const std::vector<TBlob> &out_grad);  \r\n  void channelwise_Backward_filter(mshadow::Stream<cpu> *stream,\r\n                          const std::vector<TBlob> &in_data,\r\n                          const std::vector<TBlob> &in_grad,\r\n                          const std::vector<TBlob> &out_grad);                         \r\n\r\n#if MXNET_USE_CUDA\r\n  void channelwise_Forward(mshadow::Stream<gpu> *stream,\r\n                          const std::vector<TBlob> &in_data,\r\n                          const std::vector<TBlob> &out_data);\r\n  void channelwise_Backward_input(mshadow::Stream<gpu> *stream,\r\n                          const std::vector<TBlob> &in_data,\r\n                          const std::vector<TBlob> &in_grad,\r\n                          const std::vector<TBlob> &out_grad);  \r\n  void channelwise_Backward_filter(mshadow::Stream<gpu> *stream,\r\n                          const std::vector<TBlob> &in_data,\r\n                          const std::vector<TBlob> &in_grad,\r\n                          const std::vector<TBlob> &out_grad); \r\n', '\r\nvoid ConvolutionOp<xpu, DType>::channelwise_Forward(mshadow::Stream<gpu> *stream,\r\n                          const std::vector<TBlob> &in_data,\r\n                          const std::vector<TBlob> &out_data) {\r\n  using namespace mxnet_op;\r\n .....\r\n}\r\n']",[],0,0
106,incubator-mxnet,3146,closed,Does mxnet has the ready-made spp operation?,"I want to construct a network which need the spatial pyramid pooling (spp: spatial pyramid pooling in deep convolutional network for visual recognition) operation. Does mxnet has the ready-made spp operation?
",,[],[],[],0,0
107,incubator-mxnet,5093,closed,Linker error when building mlp.cpp with VS2015,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: Windows 10 64 bit

Compiler: VS2015 C++

Package used (Python/R/Scala/Julia): ----

MXNet version: Latest nightly Windows build 20170221, CUDA 8.0.61, cudnn 8.0v5.1

Or if installed from source:

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.
mlp.obj : error LNK2001: unresolved external symbol __imp_MXOptimizerFree
mlp.obj : error LNK2001: unresolved external symbol __imp_MXOptimizerFindCreator
mlp.obj : error LNK2001: unresolved external symbol __imp_MXOptimizerUpdate
error LNK2001: unresolved external symbol __imp_MXOptimizerCreateOptimizer

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. Just compiled the mlp.cpp sample in a C++ VS2015 solution. This worked in an earlier install from MXNet but based on a version from MxNet.cpp with cudnnv3.1, CUDA 7.5 and VS2013. (entire MXNet version in a separate folder structure).
2.
3.

## What have you tried to solve it?

1. Tried to find where the symbols that cannot be linked are defined. Can't find those in the source code on Github.
2. Googled for a solution
3.
",,"['I have the same problem but the MxnetTestApp can pass. I compared the full command of two project. They looks same. My code only include <mxnet-cpp/MxNetCpp.h>. I try to write CMakeLists or add `#progma command(lib,\'libmxnet.lib\')` but the link error remain occured.\r\nAnd my link error is:\r\n~~~\r\nmnist.obj : error LNK2019: unresolved external symbol __imp__MXGetLastError\r\n...\r\n~~~\r\nand my link command is\r\n~~~\r\n/OUT:""E:\\test\\mnist\\Debug\\mnist.exe"" /MANIFEST /NXCOMPAT /PDB:""E:/test/mnist/Debug/mnist.pdb"" /DYNAMICBASE ""kernel32.lib"" ""user32.lib"" ""gdi32.lib"" ""winspool.lib"" ""shell32.lib"" ""ole32.lib"" ""oleaut32.lib"" ""uuid.lib"" ""comdlg32.lib"" ""advapi32.lib"" ""D:\\DevLib\\mxnet\\lib\\libmxnet.lib"" /IMPLIB:""E:/test/mnist/Debug/mnist.lib"" /DEBUG /MACHINE:X86 /SAFESEH /INCREMENTAL /PGD:""E:\\test\\mnist\\Debug\\mnist.pgd"" /SUBSYSTEM:CONSOLE /MANIFESTUAC:""level=\'asInvoker\' uiAccess=\'false\'"" /ManifestFile:""mnist.dir\\Debug\\mnist.exe.intermediate.manifest"" /ERRORREPORT:PROMPT /NOLOGO /LIBPATH:""D:\\Program Files (x86)\\Visual Leak Detector\\lib\\Win32"" /TLBID:1 \r\n~~~\r\nDoes I copy the MxnetTestApp proj to my work place and change it to work?', 'Hi, I have solved the problem. I have built the latest release of MxNet toegther. I cloned the code for the C++ API through a link on the MxNet website. These two or not compatible! You need to download/clone the latest version of the C++ API from Github. For the rest the procedure for installing etc. remains the same. Basically only the header files are different between the 2 c++ API versions.', 'I have solved my problem too. My project base on WIN32 platform. But when I used x64 compiler ""Visual Studio 14 Win64"" this project compiled successfully. I use the nighty build version without gpu for code test.']",[],"['git rev-parse HEAD', 'sessionInfo()']",0,0
108,incubator-mxnet,9357,closed,can group2ctx be used in multi-machine model parallel situation?,"I have figured out how to split a layer into 8 gpus by using group2ctx which is a very great feature. I wonder if group2ctx can support to split a layer into multi-machines (eg. 16 gpus on two machine) by doing some easy modifications?

Thanks. @tqchen @piiswrong @mli ",,"['No model parallel across multi-machines is not supported as of now.', '@quietsmile going forward please file questions like this in [discuss.mxnet.io](https://discuss.mxnet.io). GitHub issues are for reporting bugs, feature requests, performance issues, etc.\r\n\r\n@sandeep-krishnamurthy kindly asking to label as ""Question"" and close.']",[],[],0,0
109,incubator-mxnet,5037,closed,Loading multiple files for training ,"Hi,
I am attempting to load multiple ARK files for training, but I noticed that the numpy.dataIter only takes a single numpy feature matrix and single numpy label vector, is it possible to load multiple data sets??
I couldn't figure this out so I then attempted to concantataneted all my ARK files and created a single numpy matrix and vector for both features and matrix and ended up with this error even though the shapes are the same:

include/mxnet/./tensor_blob.h:742: Check failed: (this->shape_.Size()) == (shape.Size()) TBlob.get_with_shape: new and old shape do not match total elements
Traceback (most recent call last):
  File ""am.py"", line 52, in <module>
    train = mx.io.NDArrayIter(featureMat, label=targetMat, batch_size=100)
  File ""/usr/local/lib/python2.7/site-packages/mxnet-0.7.0-py2.7.egg/mxnet/io.py"", line 420, in __init__
    self.data = _init_data(data, allow_empty=False, default_name='data')
  File ""/usr/local/lib/python2.7/site-packages/mxnet-0.7.0-py2.7.egg/mxnet/io.py"", line 391, in _init_data
    ""should be NDArray or numpy.ndarray"")
TypeError: Invalid type '<type 'numpy.ndarray'>' for data, should be NDArray or numpy.ndarray

The shapes are the same though:
(39673722, 340) : featureMat
(39673722,) : targetVec
",,"['it support multiple data source\r\nyou can use NDArrayIter', 'I tried that but I seemed to get this error:\r\nmxnet.base.MXNetError: [19:23:40] src/symbol/symbol.cc:155: Symbol.InferShapeKeyword argument name _0_data not found.\r\nCandidate arguments:\r\n\t[0]data\r\n\t[1]affine_hidden_fc1_weight\r\n\t[2]affine_hidden_fc1_bias\r\n\t[3]affine_hidden_fc2_weight\r\n\t[4]affine_hidden_fc2_bias\r\n\t[5]affine_hidden_fc3_weight\r\n\t[6]affine_hidden_fc3_bias\r\n\t[7]affine_hidden_fc4_weight\r\n\t[8]affine_hidden_fc4_bias\r\n\t[9]affine_output_weight\r\n\t[10]affine_output_bias\r\n\t[11]softmax_label', ""Actually I don't think I gave an accurate description of what I meant by multiple np.arrays:\r\nI want to send a series numpy arrays into an AM that are all used for the same training AM. It's like a for-loop of series of numpy arrays (features & targets) into the AM model for training, where each feature&target will have (x, 340) and (x,) size so my AM model shouldn’t be compromised in any way and x will vary in each numpy array that is being passed.\r\n\r\nFor each (feature,target) in file:\r\n  pass in (feature,target) into AM model for training\r\n\r\nNote that feature,target have (x,340) and (x,) size so AM model itself shouldn't be compromised"", '```\r\nmxnet.base.MXNetError: [19:23:40] src/symbol/symbol.cc:155: Symbol.InferShapeKeyword argument name _0_data not found.\r\n```\r\ndo you have a source data named ""_0_data""\r\n\r\nIn the other hand, i understand that the length of input in your \'AM\' model is variable, but every the length of every column about numpy type is same. So you need to a variable data structure to support your input.  \r\n', 'Okay, so I looked into it a bit more and this is what makes things really weird is that the training works if I send in a smaller matrix. So anything with size below:\r\nfeature: (12594176, 340)\r\ntarget(12594176,) \r\nwill work but anything above that will give the same error:\r\ninclude/mxnet/./tensor_blob.h:742: Check failed: (this->shape_.Size()) == (shape.Size()) TBlob.get_with_shape: new and old shape do not match total elements\r\nTraceback (most recent call last):\r\nFile ""am.py"", line 52, in \r\ntrain = mx.io.NDArrayIter(featureMat, label=targetMat, batch_size=100)\r\nFile ""/usr/local/lib/python2.7/site-packages/mxnet-0.7.0-py2.7.egg/mxnet/io.py"", line 420, in init\r\nself.data = _init_data(data, allow_empty=False, default_name=\'data\')\r\nFile ""/usr/local/lib/python2.7/site-packages/mxnet-0.7.0-py2.7.egg/mxnet/io.py"", line 391, in _init_data\r\n""should be NDArray or numpy.ndarray"")\r\nTypeError: Invalid type \'<type \'numpy.ndarray\'>\' for data, should be NDArray or numpy.ndarray\r\n\r\nIs there a max cap on how much the arrayIterator can hold? \r\n', ""Looks like a bug in mxnet. \r\nmethod MXNDArraySyncCopyFromCPU() seems to crash.\r\nCan recreate this bug via:\r\nimport mxnet as mx\r\nimport numpy as np\r\n\r\nfinal_feature= np.zeros((14401306,340))\r\nfinal_target = np.zeros((14401306))\r\ntrain = mx.io.NDArrayIter(final_feature, label=final_target, batch_size=100)\r\n\r\nthe method it fails is int MXNDArraySyncCopyFromCPU(NDArrayHandle handle,\r\n                             const void *data,\r\n                             size_t size) \r\nin file c_api.cc\r\nI have a feeling there must be some type of data overflow, and the copy doesn't seem to work on c++ side. \r\n"", 'Create a seperate issue for this. ']",[],[],0,0
110,incubator-mxnet,7560,closed,Creating a layer-by-layer network,"[MyData2.zip](https://github.com/apache/incubator-mxnet/files/1242794/MyData2.zip)

Hi, I have a model of a layer that I would like to train, to then use both weights and Bias as a parameter to create a new layer:

DataNeurona<- read.csv(""D:/DATOS_PROYECTO/MyData2.csv"",sep = "","", header = T)



DataNeurona<-as.matrix(DataNeurona)
#Duplico la ultima fila para luego hacer el test con ella:
DataNeurona<-rbind(DataNeurona,DataNeurona[length(DataNeurona[,1]),])

NumTest<-2
train.ind<-c(41:(length(DataNeurona[,1])-NumTest))
train.x<-DataNeurona[train.ind,-(length(DataNeurona[1,]))]
train.y<-DataNeurona[train.ind,length(DataNeurona[1,])]
test.x<-DataNeurona[-c(1:41,train.ind),-length(DataNeurona[1,])]
test.y<-DataNeurona[-c(1:41,train.ind),length(DataNeurona[1,])]

data <- mx.symbol.Variable(""data"")
#w = mx.symbol.Variable('myweight')

fc1<-mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=50, weights(ww))
act1<-mx.symbol.Activation(fc1,name=""sigmoid1"",act_type=""sigmoid"")

fc2<-mx.symbol.FullyConnected(act1,name=""fc2"",num_hidden=1)
lro=mx.symbol.LinearRegressionOutput(data=fc2, grad.scale=1)
mx.set.seed(0)
train_iter = mx.io.arrayiter(data = t(train.x), label = t(train.y))
model <- mx.model.FeedForward.create(symbol= lro, 
                                     X=train_iter, 
                                     ctx=mx.cpu(2),     
                                     num.round=50,
                                     #optimizer = 
                                     initialize=mx.init.uniform(0.7),
                                     array.batch.size=3,
                                     learning.rate=0.01, 
                                     momentum=0.9,  
                                     eval.metric=mx.metric.mse)


My problem is that I can not find the way to create the layer later with the weights as parameter, 
I have tried with:

1
model$arg.params$fc1_weight
fc1<-mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=25, weights(model$arg.params$fc1_weight))
2


model$arg.params$fc1_weight
fc1<-mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=25, weights=model$arg.params$fc1_weight, bias=model$arg.params$fc1_bias)
3
model$arg.params$fc1_weight
fc1<-mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=25, weights=model$arg.params[[fc1_weight]], bias=model$arg.params[[fc1_bias]])
4
model.extract(model, ""weights"")

## ## ### **

**
And I do not quite understand what I do wrong ....
Greeting
",,"['@thirdwing could you help take a look at this issue? ', '\r\nHOla, this I have not been able to create it as such, what I did was create the layers in a general way and put the parameters on the code .... so it served me, thank you']",[],[],0,0
111,incubator-mxnet,890,closed,[error] Check failed: (param_.workspace) >= (required_size) ,"An fatal error occurred in asynchronous engine operation. If you do not know what caused this error, you can try set environment variable MXNET_ENGINE_TYPEto NaiveEngine and run with debugger (i.e. gdb). This will force all operations to be synchronous and backtrace will give you the series of calls that lead to this error. Remember to set MXNET_ENGINE_TYPE back to empty after debugging.
terminate called after throwing an instance of 'dmlc::Error'
  what():  [15:04:06] src/engine/./threaded_engine.h:295: [15:04:06] src/operator/./convolution-inl.h:258: Check failed: (param_.workspace) >= (required_size) 
Minimum workspace size: 666989568 Bytes
Given: 536870912 Bytes
",,"[""GPU k40m\n12G memory\nwhen this error ocur, just use  4786MiB memory\n\nwhat's the problem \n"", 'This is a known bug and it will be fixed after https://github.com/dmlc/mxnet/pull/873 is merged\n@tqchen this is the cudnn algorithm bug I talked about\n', '@piiswrong @tqchen  #873  work\n']",[],[],0,0
112,incubator-mxnet,4223,closed,how to print values of a tensor？,"i want to print some values of specified locations of a tensor in forward or backward op， is there some function to call or how to implement this function？
",,"['Would you like to print the value of some ndarray? ', ' no ，i want to print some values of a Tensor in forward or backward operation of\r\n a operator in .cpp or .cu @kevinthesun ', '@achao2013 Could you put your code snippets?', ""Tensor<gpu, 4, DType> tmp_gwmat=mshadow::NewTensor(gwmat.shape_,DType(0),true,s);\r\ntmp_gwmat=tmp_gwmat*mshadow::expr::F<mshadow_op::trunc>(wmat);\r\nAssign(gwmat, req[conv::kWeight], tmp_gwmat);\r\n\r\nit's a code snippet in my cudnn_convolution-inl.h\r\nAs shown above，i want to see the middle result of tmp_gwmat and gwmat @zihaolucky "", 'You can print value like this\r\n```\r\nTensor<cpu, 4> cpu_gwmat=mshadow::NewTensor<cpu, 4>(gwmat.shape_,DType(0),true,s);\r\nCopy(cpu_gwmat, tmp_gwmat,s);\r\ncout<<cpu_gwmat.dptr_[0];\r\n```', 'the type of s is stream \\< gpu\\>, can it be used directly to construct tensor fron cpu? @feiyulv  @zihaolucky ', ""just discard s, that's ok ,thx @feiyulv "", '@achao2013:\r\n\r\nCan you pls help me in printing  the value of some tensors in the Forward operation of convolution-inl.h .\r\n\r\nHere is the code snippet  in convolution-inl.h\r\n\r\n    Tensor<xpu, 3, DType> weight_3d = in_data[conv::kWeight].get_with_shape<xpu, 3, DType>(\r\n      Shape3(group_, M, K), s);\r\n    Tensor<xpu, 3, DType> col_buffer_3d = col_buffer.get_with_shape<xpu, 3, DType>(\r\n      Shape3(group_, K, N), s);\r\n    Tensor<xpu, 4, DType> output_4d = out_data[conv::kOut].get_with_shape<xpu, 4, DType>(\r\n      Shape4(num_, group_, M, N), s);\r\n\r\nCan i use the Copy function as suggested above. The definition of Copy function?']",[],[],0,0
113,incubator-mxnet,8821,closed,"I can not find the module called ""get_data"" for mxnet 0.12","I use mxnet 0.12 with python2.7 ,win10. For example:
https://github.com/apache/incubator-mxnet/blob/b5648a43955f7d05c0e53c1ab61a58bd402b4416/example/multi-task/example_multi_task.py
I want to test how to use multi label accuracy with this example, but got error:  ""ImportError: No module named get_data""  
I googled, found that this module is a relevant one related to mnist example, but I couldn't find it anymore. 

So could someone fix it, or provided the module?",,"['@szha could you fix the import error? ', ""The path is correct with the assumption that you're running the example with `examples/multi-task/` folder as the current working directory."", '@szha .At present, I just copy the code from example_multi_task.py to a new .py.  Does that mean I have to download the whole mxnet folder, then go through examples/multi-task/  to test? Anyway, I would give it a try soon.', ""@dbsxdbsx I see. I was assuming that user has the complete directory when running the examples. You can download the get_data.py file from [here](https://github.com/apache/incubator-mxnet/blob/master/tests/python/common/get_data.py) if you don't want to download the whole repo for 0.12."", '@szha Many thanks, it is worked now.']",[],[],0,0
114,incubator-mxnet,9993,closed,cmake cannot build mxnet,"Hi,
sorry,there are some problems with cmake

command I use
$git clone --recursive https://github.com/apache/incubator-mxnet.git
$cd incubator-mxnet/
$mkdir build/Release && cd build/Release
$cmake ../../
$make -j8


- cmake ../../ output log

-- The C compiler identification is GNU 5.4.0
-- The CXX compiler identification is GNU 5.4.0
-- Check for working C compiler: /usr/bin/cc
-- Check for working C compiler: /usr/bin/cc -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Detecting C compile features
-- Detecting C compile features - done
-- Check for working CXX compiler: /usr/bin/c++
-- Check for working CXX compiler: /usr/bin/c++ -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- CMake version '3.5.1' using generator 'Unix Makefiles'
-- Performing Test SUPPORT_CXX11
-- Performing Test SUPPORT_CXX11 - Success
-- Performing Test SUPPORT_CXX0X
-- Performing Test SUPPORT_CXX0X - Success
-- Performing Test SUPPORT_MSSE2
-- Performing Test SUPPORT_MSSE2 - Success
-- CMAKE_BUILD_TYPE is unset, defaulting to Release
-- Detecting Intel(R) MKL: trying mklml_intel
-- Detecting Intel(R) MKL: trying mklml
-- Detecting Intel(R) MKL: trying mkl_rt
CMake Warning at 3rdparty/mkldnn/cmake/MKL.cmake:177 (message):
  Intel(R) MKL not found.  Some performance features may not be available.
  Please run scripts/prepare_mkl.sh to download a minimal set of libraries or
  get a full version from https://software.intel.com/en-us/intel-mkl
Call Stack (most recent call first):
  3rdparty/mkldnn/cmake/OpenMP.cmake:24 (include)
  3rdparty/mkldnn/CMakeLists.txt:57 (include)


-- Try OpenMP C flag = [-fopenmp]
-- Performing Test OpenMP_FLAG_DETECTED
-- Performing Test OpenMP_FLAG_DETECTED - Success
-- Try OpenMP CXX flag = [-fopenmp]
-- Performing Test OpenMP_FLAG_DETECTED
-- Performing Test OpenMP_FLAG_DETECTED - Success
-- Found OpenMP: -fopenmp
-- Could NOT find Doxygen (missing:  DOXYGEN_EXECUTABLE)
-- VTune profiling environment is unset
-- Looking for pthread.h
-- Looking for pthread.h - found
-- Looking for pthread_create
-- Looking for pthread_create - found
-- Found Threads: TRUE
-- Found CUDA: /usr/local/cuda-8.0 (found version ""8.0"")
-- Found OpenBLAS libraries: /usr/lib/libopenblas.so
-- Found OpenBLAS include: /usr/include
-- CUDA detected: 8.0
-- Found cuDNN (include: /usr/local/cuda-8.0/include, library: /usr/local/cuda-8.0/lib64/libcudnn.so)
-- Running GPU architecture autodetection
-- Found CUDA arch 5.2 5.2 5.2 5.2
-- Added CUDA NVCC flags for: sm_52
-- Could NOT find Gperftools (missing:  GPERFTOOLS_LIBRARIES GPERFTOOLS_INCLUDE_DIR)
-- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1"")
-- Could NOT find Jemalloc (missing:  JEMALLOC_LIBRARY JEMALLOC_INCLUDE_DIR)
--  OpenCV_LIBS=opencv_core;opencv_highgui;opencv_imgproc;opencv_imgcodecs
-- OpenCV found (/usr/local/share/OpenCV)
-- Performing Test LIBOMP_HAVE_STD_CPP11_FLAG
-- Performing Test LIBOMP_HAVE_STD_CPP11_FLAG - Success
-- Performing Test LIBOMP_HAVE_FNO_EXCEPTIONS_FLAG
-- Performing Test LIBOMP_HAVE_FNO_EXCEPTIONS_FLAG - Success
-- Performing Test LIBOMP_HAVE_FNO_RTTI_FLAG
-- Performing Test LIBOMP_HAVE_FNO_RTTI_FLAG - Success
-- Performing Test LIBOMP_HAVE_X_CPP_FLAG
-- Performing Test LIBOMP_HAVE_X_CPP_FLAG - Success
-- Performing Test LIBOMP_HAVE_WERROR_FLAG
-- Performing Test LIBOMP_HAVE_WERROR_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_FUNCTION_FLAG
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_FUNCTION_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_LOCAL_TYPEDEF_FLAG
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_LOCAL_TYPEDEF_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_VALUE_FLAG
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_VALUE_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_VARIABLE_FLAG
-- Performing Test LIBOMP_HAVE_WNO_UNUSED_VARIABLE_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_SWITCH_FLAG
-- Performing Test LIBOMP_HAVE_WNO_SWITCH_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_COVERED_SWITCH_DEFAULT_FLAG
-- Performing Test LIBOMP_HAVE_WNO_COVERED_SWITCH_DEFAULT_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_DEPRECATED_REGISTER_FLAG
-- Performing Test LIBOMP_HAVE_WNO_DEPRECATED_REGISTER_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_SIGN_COMPARE_FLAG
-- Performing Test LIBOMP_HAVE_WNO_SIGN_COMPARE_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_GNU_ANONYMOUS_STRUCT_FLAG
-- Performing Test LIBOMP_HAVE_WNO_GNU_ANONYMOUS_STRUCT_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_UNKNOWN_PRAGMAS_FLAG
-- Performing Test LIBOMP_HAVE_WNO_UNKNOWN_PRAGMAS_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_MISSING_FIELD_INITIALIZERS_FLAG
-- Performing Test LIBOMP_HAVE_WNO_MISSING_FIELD_INITIALIZERS_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_MISSING_BRACES_FLAG
-- Performing Test LIBOMP_HAVE_WNO_MISSING_BRACES_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_COMMENT_FLAG
-- Performing Test LIBOMP_HAVE_WNO_COMMENT_FLAG - Success
-- Performing Test LIBOMP_HAVE_WNO_SELF_ASSIGN_FLAG
-- Performing Test LIBOMP_HAVE_WNO_SELF_ASSIGN_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_VLA_EXTENSION_FLAG
-- Performing Test LIBOMP_HAVE_WNO_VLA_EXTENSION_FLAG - Failed
-- Performing Test LIBOMP_HAVE_WNO_FORMAT_PEDANTIC_FLAG
-- Performing Test LIBOMP_HAVE_WNO_FORMAT_PEDANTIC_FLAG - Failed
-- Performing Test LIBOMP_HAVE_MSSE2_FLAG
-- Performing Test LIBOMP_HAVE_MSSE2_FLAG - Success
-- Performing Test LIBOMP_HAVE_FTLS_MODEL_FLAG
-- Performing Test LIBOMP_HAVE_FTLS_MODEL_FLAG - Success
-- Performing Test LIBOMP_HAVE_MMIC_FLAG
-- Performing Test LIBOMP_HAVE_MMIC_FLAG - Failed
-- Performing Test LIBOMP_HAVE_M32_FLAG
-- Performing Test LIBOMP_HAVE_M32_FLAG - Failed
-- Performing Test LIBOMP_HAVE_X_FLAG
-- Performing Test LIBOMP_HAVE_X_FLAG - Success
-- Performing Test LIBOMP_HAVE_WARN_SHARED_TEXTREL_FLAG
-- Performing Test LIBOMP_HAVE_WARN_SHARED_TEXTREL_FLAG - Success
-- Performing Test LIBOMP_HAVE_AS_NEEDED_FLAG
-- Performing Test LIBOMP_HAVE_AS_NEEDED_FLAG - Success
-- Performing Test LIBOMP_HAVE_VERSION_SCRIPT_FLAG
-- Performing Test LIBOMP_HAVE_VERSION_SCRIPT_FLAG - Success
-- Performing Test LIBOMP_HAVE_STATIC_LIBGCC_FLAG
-- Performing Test LIBOMP_HAVE_STATIC_LIBGCC_FLAG - Success
-- Performing Test LIBOMP_HAVE_Z_NOEXECSTACK_FLAG
-- Performing Test LIBOMP_HAVE_Z_NOEXECSTACK_FLAG - Success
-- Performing Test LIBOMP_HAVE_FINI_FLAG
-- Performing Test LIBOMP_HAVE_FINI_FLAG - Success
-- Found Perl: /usr/bin/perl (found version ""5.22.1"")
-- Performing Test LIBOMP_HAVE_VERSION_SYMBOLS
-- Performing Test LIBOMP_HAVE_VERSION_SYMBOLS - Success
-- Performing Test LIBOMP_HAVE___BUILTIN_FRAME_ADDRESS
-- Performing Test LIBOMP_HAVE___BUILTIN_FRAME_ADDRESS - Success
-- Performing Test LIBOMP_HAVE_WEAK_ATTRIBUTE
-- Performing Test LIBOMP_HAVE_WEAK_ATTRIBUTE - Success
-- Looking for include files windows.h, psapi.h
-- Looking for include files windows.h, psapi.h - not found
-- Looking for EnumProcessModules in psapi
-- Looking for EnumProcessModules in psapi - not found
-- LIBOMP: Operating System     -- Linux
-- LIBOMP: Target Architecture  -- x86_64
-- LIBOMP: Build Type           -- Release
-- LIBOMP: OpenMP Version       -- 50
-- LIBOMP: Library Kind         -- SHARED
-- LIBOMP: Library Type         -- normal
-- LIBOMP: Fortran Modules      -- FALSE
-- LIBOMP: Build                -- 20140926
-- LIBOMP: Use Stats-gathering  -- FALSE
-- LIBOMP: Use Debugger-support -- FALSE
-- LIBOMP: Use ITT notify       -- TRUE
-- LIBOMP: Use OMPT-support     -- FALSE
-- LIBOMP: Use Adaptive locks   -- TRUE
-- LIBOMP: Use quad precision   -- TRUE
-- LIBOMP: Use TSAN-support     -- FALSE
-- LIBOMP: Use Hwloc library    -- FALSE
-- Found PythonInterp: /usr/bin/python (found version ""2.7.12"")
-- Looking for sqrt in m
-- Looking for sqrt in m - found
-- Looking for __atomic_load_1
-- Looking for __atomic_load_1 - not found
-- Looking for __atomic_load_1 in atomic
-- Looking for __atomic_load_1 in atomic - found
-- LIBOMP: Cannot find llvm-lit.
-- LIBOMP: Please put llvm-lit in your PATH, set LIBOMP_LLVM_LIT_EXECUTABLE to its full path or point OPENMP_LLVM_TOOLS_DIR to its directory
CMake Warning at 3rdparty/openmp/runtime/cmake/LibompUtils.cmake:21 (message):
  LIBOMP: The check-libomp target will not be available!
Call Stack (most recent call first):
  3rdparty/openmp/runtime/test/CMakeLists.txt:62 (libomp_warning_say)


-- Could NOT find Jemalloc (missing:  JEMALLOC_LIBRARY JEMALLOC_INCLUDE_DIR)
-- Found GTest: gtest
-- Found cuDNN (include: /usr/local/cuda-8.0/include, library: /usr/local/cuda-8.0/lib64/libcudnn.so)
You have called ADD_LIBRARY for library mxnet without any source files. This typically indicates a problem with your CMakeLists.txt file
-- Configuring done
-- Generating done
-- Build files have been written to: /home/jacky4323/TEST_bmxnet/incubator-mxnet/build/Release

- make -j8 error

[ 56%] Linking CXX executable benchdnn
[ 57%] Linking CXX executable test_convolution_forward_u8s8s32
[ 57%] Built target benchdnn
[ 57%] Built target test_convolution_forward_u8s8s32
[ 57%] Linking CXX executable test_convolution_relu_forward_f32
[ 57%] Built target test_convolution_relu_forward_f32
CMakeFiles/Makefile2:139: recipe for target 'CMakeFiles/mxnet_static.dir/all' failed
make[1]: *** [CMakeFiles/mxnet_static.dir/all] Error 2
Makefile:138: recipe for target 'all' failed
make: *** [all] Error 2
",Bug Build MKL,"['I was able to reproduce.', 'The exact error is:\r\n\r\n```\r\nIn file included from /home/piotr/devel/mxnet_build/src/operator/nn/dropout.cu:27:0:\r\n/home/piotr/devel/mxnet_build/src/operator/nn/./dropout-inl.h:44:31: fatal error: mkl_vml_functions.h: No such file or directory\r\ncompilation terminated.\r\nCMake Error at cuda_compile_generated_dropout.cu.o.cmake:207 (message):\r\n  Error generating\r\n  /home/piotr/devel/mxnet_build/build/CMakeFiles/cuda_compile.dir/src/operator/nn/./cuda_compile_generated_dropout.cu.o\r\n\r\n\r\n\r\n```', ""@marcoabreu @cjolivier01  as we spoke with Marco in person, I don't think we should compile with MKL by default if we don't even know if there's MKL available.\r\n\r\nAs a workaround, you can call cmake as:\r\n\r\n```\r\ncmake -DUSE_MKL_IF_AVAILABLE=OFF ..\r\n\r\n```"", ""The logic in CMakeLists.txt is bad, having mkldnn as is part of 3rdparty doesn't mean that you have MKL which is not open source."", 'How come that CMake properly detects that MKL is not present\r\n```\r\n-- Detecting Intel(R) MKL: trying mklml_intel\r\n-- Detecting Intel(R) MKL: trying mklml\r\n-- Detecting Intel(R) MKL: trying mkl_rt\r\nCMake Warning at 3rdparty/mkldnn/cmake/MKL.cmake:177 (message):\r\nIntel(R) MKL not found. Some performance features may not be available.\r\nPlease run scripts/prepare_mkl.sh to download a minimal set of libraries or\r\nget a full version from https://software.intel.com/en-us/intel-mkl\r\nCall Stack (most recent call first):\r\n3rdparty/mkldnn/cmake/OpenMP.cmake:24 (include)\r\n3rdparty/mkldnn/CMakeLists.txt:57 (include)\r\n```\r\nbut still tries to use it?', 'I am not sure what was changed for the enormous mkldnn PR, but ""USE_MKL_IF_AVAILABLE"" means use it if it is found (real MKL or MKLML), otherwise don\'t.\r\n', 'closed on accident', ""Well, it's clear from the logic in the CMake file what the problem is. I can fix it, but honestly I would like to test the build system better or be more careful. I invested already a lot of time on maintaining the build system and I'm not happy to see this random breaks."", 'Another problem right now is what we discussed previously with @cjolivier01 :\r\n\r\nWhen I build in CLion:\r\n\r\n```\r\nCMake Error at CMakeLists.txt:51 (project):\r\n  No CMAKE_CUDA_COMPILER could be found.\r\n\r\n  Tell CMake where to find the compiler by setting either the environment\r\n  variable ""CUDACXX"" or the CMake cache entry CMAKE_CUDA_COMPILER to the full\r\n  path to the compiler, or to the compiler name if it is in the PATH.\r\n\r\n```\r\nI use \r\nUSE_OLDCMAKECUDA as a workaround, but I would prefer this to work out of the box. \r\nFrom CMAKE docs I don\'t see why generators are supposed to work with Unix Makefiles:\r\n\r\nhttps://cmake.org/cmake/help/latest/variable/CMAKE_GENERATOR_TOOLSET.html\r\n\r\nI never got a propper answer to this.\r\n', '@jacky4323  your issue should be the same with https://github.com/apache/incubator-mxnet/issues/10072, would you try to patch the related PR(https://github.com/apache/incubator-mxnet/pull/10075) in https://github.com/apache/incubator-mxnet/issues/10072 and see if the issue is gone?', '@marcoabreu @szha This issue has been fixed in #10075.  Could you help close this one?', '> How come that CMake properly detects that MKL is not present\r\n> \r\n> ```\r\n> -- Detecting Intel(R) MKL: trying mklml_intel\r\n> -- Detecting Intel(R) MKL: trying mklml\r\n> -- Detecting Intel(R) MKL: trying mkl_rt\r\n> CMake Warning at 3rdparty/mkldnn/cmake/MKL.cmake:177 (message):\r\n> Intel(R) MKL not found. Some performance features may not be available.\r\n> Please run scripts/prepare_mkl.sh to download a minimal set of libraries or\r\n> get a full version from https://software.intel.com/en-us/intel-mkl\r\n> Call Stack (most recent call first):\r\n> 3rdparty/mkldnn/cmake/OpenMP.cmake:24 (include)\r\n> 3rdparty/mkldnn/CMakeLists.txt:57 (include)\r\n> ```\r\n> but still tries to use it?\r\n\r\nBut I have already installed mkl in anaconda and I cmake in anaconda. Why this error again?']",[],[],0,0
115,incubator-mxnet,10279,closed,Failing test_operator_gpu.test_sparse_quadratic_function and test_flip,"

http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/546/pipeline

https://issues.apache.org/jira/browse/MXNET-237",Breaking Test,['Fixed by https://github.com/apache/incubator-mxnet/pull/10259 '],"['\r\ntest_operator_gpu.test_sparse_quadratic_function ... [INFO] Setting test np/mx/python random seeds, use MXNET_TEST_SEED=1862592620 to reproduce.\r\n\r\nERROR\r\n\r\ntest_operator_gpu.test_flip ... [INFO] Setting test np/mx/python random seeds, use MXNET_TEST_SEED=170826886 to reproduce.\r\n\r\nERROR\r\n\r\ntest_operator_gpu.test_stn ... [00:04:00] src/operator/tensor/./.././../common/../operator/mxnet_op.h:576: Check failed: (err) == (cudaSuccess) Name: mxnet_generic_kernel ErrStr:invalid configuration argument\r\n\r\n/work/runtime_functions.sh: line 391:     7 Aborted                 (core dumped) nosetests-2.7 --verbose tests/python/gpu\r\n\r\nbuild.py: 2018-03-27 00:04:01,588 Running of command in container failed: nvidia-docker run --rm -v /home/jenkins_slave/workspace/ut-python2-gpu:/work/mxnet -v /home/jenkins_slave/workspace/ut-python2-gpu/build:/work/build -u 1001:1001 mxnet/build.ubuntu_gpu /work/runtime_functions.sh unittest_ubuntu_python2_gpu\r\n\r\nbuild.py: 2018-03-27 00:04:01,589 You can try to get into the container by using the following command: nvidia-docker run --rm -v /home/jenkins_slave/workspace/ut-python2-gpu:/work/mxnet -v /home/jenkins_slave/workspace/ut-python2-gpu/build:/work/build -u 1001:1001 -ti --entrypoint bash mxnet/build.ubuntu_gpu /work/runtime_functions.sh unittest_ubuntu_python2_gpu\r\n\r\nTraceback (most recent call last):\r\n\r\n  File ""ci/build.py"", line 179, in <module>\r\n\r\n    sys.exit(main())\r\n\r\n  File ""ci/build.py"", line 159, in main\r\n\r\n    container_run(platform, docker_binary, command)\r\n\r\n  File ""ci/build.py"", line 110, in container_run\r\n\r\n    raise subprocess.CalledProcessError(ret, cmd)\r\n\r\nsubprocess.CalledProcessError: Command \'nvidia-docker run --rm -v /home/jenkins_slave/workspace/ut-python2-gpu:/work/mxnet -v /home/jenkins_slave/workspace/ut-python2-gpu/build:/work/build -u 1001:1001 mxnet/build.ubuntu_gpu /work/runtime_functions.sh unittest_ubuntu_python2_gpu\' returned non-zero exit status 134\r\n\r\nscript returned exit code 1\r\n']",[],0,0
116,incubator-mxnet,4155,closed," An error occured when I complie mxnet in VS2013, could you tell me how to fix it ","2>  symbol.cc
2>     正在创建库 G:/OpenSource/mxnet/build/Release/libmxnet.lib 和对象 G:/OpenSource/mxnet/build/Release/libmxnet.exp
2>  正在生成代码
2>g:\opensource\mxnet\src\engine\threaded_engine.cc(298): fatal error C1001: 编译器中发生内部错误。
2>  (编译器文件“f:\dd\vctools\compiler\utc\src\p2\ehexcept.c”，第 956 行)
2>   要解决此问题，请尝试简化或更改上面所列位置附近的程序。
2>  请选择 Visual C++
2>  “帮助”菜单上的“技术支持”命令，或打开技术支持帮助文件来获得详细信息。
2>LINK : fatal error LNK1257: 代码生成失败
",,"['Have you tried to install mxnet with prebuilt package?http://mxnet.io/get_started/setup.html#installing-the-prebuilt-package-on-windows', '@kevinthesun thank you , it works', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
117,incubator-mxnet,14844,closed,ci/build.py failed to build MXNet for Android_armv7,"## Description
Tried to build Android_armv7 using ci/build.py and failed.
I runned 
And the error showed as follows:


## Environment info (Required)
OS: Ubuntu 18.04 64bit LTS
MXNet: 1.3.1
Python: 3.6
GPU: NVIDIA GTX1060 6G
CPU: i7-8750H (16G memory)


## What have you tried to solve it?

1. Changed mxnetci dockcross address in 
Previously it is 
Now it is 
2. Set  argument in  to 'mxnetcipinned'
3. Created  and restarted the docker service

4. Used proxy(shadowsocks + proxychains4). BUt it seems that it has nothing to do with my network connection?

## Complete building log


I am wondering if there is anyone who can reproduce this error, or there is just something wrong in my network connection (e.g. GFW)?",Build Edge devices,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: CI, Build', '@larroy Could you please take a look?', ""seems like a network issue?  Works for me:\r\n\r\n```\r\nlc.a /usr/arm-linux-androideabi/lib/libopenblas.a && :\r\nbuild.py: 2019-04-30 19:33:06,432Z INFO Waiting for status of container 38451c89318e for 600 s.\r\nbuild.py: 2019-04-30 19:33:07,522Z INFO Container exit status: {'Error': None, 'StatusCode': 0}\r\nbuild.py: 2019-04-30 19:33:07,522Z INFO Container exited with success 👍\r\nbuild.py: 2019-04-30 19:33:07,522Z INFO Stopping container: 38451c89318e\r\nbuild.py: 2019-04-30 19:33:07,523Z INFO Removing container: 38451c89318e\r\n\r\nreal    7m7.247s\r\nuser    0m0.506s\r\nsys     0m0.254s\r\npiotr@ip-172-31-63-171:0:~/mxnet_other (master)+$ time ci/build.py -p android_armv7\r\n\r\n\r\nIm at a386644f2cd2a7b8ef553c518a9558e11923b834  in master\r\n```"", '@larroy\r\nThank you. After adding `RUN sed -i ""s/jessie/stretch/g"" /etc/apt/sources.list` it works. I think it is indeed a network issue.', '1. Tried to build Android_armv7 using ci/build.py and sucess. ndk17, api 24\r\n2.  Use Android Studio. \r\nAndroid.mk, \r\ninclude $(CLEAR_VARS)\r\nLOCAL_MODULE := mxnet_inference          \r\nLOCAL_SRC_FILES := $(LOCAL_PATH)/libs/libmxnet.so\r\nLOCAL_EXPORT_C_INCLUDES := $(LOCAL_PATH)/include/mxnet        \r\ninclude $(PREBUILT_SHARED_LIBRARY) \r\n...\r\nLOCAL_SHARED_LIBRARIES += mxnet_inference\r\ninclude $(BUILD_SHARED_LIBRARY)           \r\n\r\nApplication.mk\r\nAPP_ABI := armeabi-v7a\r\nAPP_PLATFORM := android-24\r\nAPP_STL := c++_static\r\nNDK_TOOLCHAIN_VERSION := clang\r\nAPP_BUILD_SCRIPT := Android.mk\r\n\r\nbuild.gradle\r\nandroid {\r\n    compileSdkVersion 29\r\n    buildToolsVersion ""29.0.2""\r\n    defaultConfig {\r\n        applicationId ""com.tistory.webnautes.useopencvwithndk_build""\r\n        minSdkVersion 21\r\n        targetSdkVersion 25\r\n        versionCode 1\r\n        versionName ""1.0""\r\n        testInstrumentationRunner ""androidx.test.runner.AndroidJUnitRunner""\r\n\r\n       // ndk {\r\n       //     abiFilters ""armeabi-v7a""\r\n       // }\r\n    }\r\n\r\n    buildTypes {\r\n        release {\r\n            minifyEnabled false\r\n            proguardFiles getDefaultProguardFile(\'proguard-android-optimize.txt\'), \'proguard-rules.pro\'\r\n        }\r\n    }\r\n    externalNativeBuild {\r\n        ndkBuild {\r\n            path \'src/main/jni/Android.mk\'\r\n        }\r\n   }\r\n\r\n    packagingOptions {\r\n       // pickFirst \'lib/arm64-v8a/*\'\r\n        pickFirst \'lib/armeabi-v7a/*\'\r\n       // pickFirst \'lib/x86/*\'\r\n       // pickFirst \'lib/x86_64/*\'\r\n    }\r\n}\r\n\r\nerror showed as follows:\r\n#==================\r\nE/AndroidRuntime: FATAL EXCEPTION: main\r\n    Process: com.tistory.webnautes.useopencvwithndk_build, PID: 12657\r\n    java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol ""__aeabi_memcpy4"" referenced by ""/data/app/com.tistory.webnautes.useopencvwithndk_build-2/lib/arm/libmxnet.so""...\r\n        at java.lang.Runtime.loadLibrary(Runtime.java:372)\r\n        at java.lang.System.loadLibrary(System.java:1076)\r\n        at com.tistory.webnautes.useopencvwithndk_build.MainActivity.<clinit>(MainActivity.java:48)\r\n        at java.lang.Class.newInstance(Native Method)\r\n        at android.app.Instrumentation.newActivity(Instrumentation.java:1095)\r\n        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:3083)\r\n        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3349)\r\n        at android.app.ActivityThread.access$1100(ActivityThread.java:221)\r\n        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1794)\r\n        at android.os.Handler.dispatchMessage(Handler.java:102)\r\n        at android.os.Looper.loop(Looper.java:158)\r\n        at android.app.ActivityThread.main(ActivityThread.java:7224)\r\n        at java.lang.reflect.Method.invoke(Native Method)\r\n        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1230)\r\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1120)\r\nI/Process: Sending signal. PID: 12657 SIG: 9\r\n#=======================================\r\nHow to fix that? Thank you.', '@bykim555 which version of MXNet are you building. Please open a new discussion thread. Thanks']","[""\r\nW: Failed to fetch http://cdn-fastly.deb.debian.org/debian/dists/jessie-updates/InRelease  Unable to find expected entry 'main/binary-amd64/Packages' in Release file (Wrong sources.list entry or malformed file)\r\n\r\nW: Failed to fetch http://ftp.debian.org/debian/dists/jessie-backports/main/binary-amd64/Packages  404  Not Found\r\n\r\nE: Some index files failed to download. They have been ignored, or old ones used instead.\r\n"", '\r\n{\r\n""registry-mirrors"": [""https://registry.docker-cn.com""]\r\n}\r\n', '\r\njinmengrao@jinmengrao-OMEN-by-HP-Laptop-15-dc0xxx:~/gitRepo/apache-mxnet-src-1.3.1-incubating/ci$ sudo ./build.py -p android_armv7\r\nbuild.py: 2019-04-30 15:43:50,514 Building container tagged \'mxnetcipinned/build.android_armv7\' with docker\r\nbuild.py: 2019-04-30 15:43:50,514 1 out of 1 tries to build the docker image.\r\nbuild.py: 2019-04-30 15:43:50,514 Running command: \'docker build -f docker/Dockerfile.build.android_armv7 --build-arg USER_ID=0 --build-arg GROUP_ID=0 --cache-from mxnetcipinned/build.android_armv7 -t mxnetcipinned/build.android_armv7 docker\'\r\nSending build context to Docker daemon  156.2kB\r\nStep 1/34 : FROM mxnetcipinned/dockcross-base:11262018\r\n ---> 94f0363cdb71\r\nStep 2/34 : MAINTAINER Pedro Larroy ""pllarroy@amazon.com""\r\n ---> Running in 6d2c98f8d584\r\nRemoving intermediate container 6d2c98f8d584\r\n ---> cab83d01644a\r\nStep 3/34 : RUN apt-get update && apt-get install -y   unzip\r\n ---> Running in 234473d03ea3\r\nIgn http://ftp.debian.org jessie-backports InRelease\r\nIgn http://cdn-fastly.deb.debian.org jessie InRelease\r\nIgn http://ftp.debian.org jessie-backports Release.gpg\r\nIgn http://ftp.debian.org jessie-backports Release\r\nErr http://ftp.debian.org jessie-backports/main amd64 Packages\r\n  \r\nGet:1 http://cdn-fastly.deb.debian.org jessie-updates InRelease [7340 B]\r\nGet:2 http://cdn-fastly.deb.debian.org jessie/updates InRelease [44.9 kB]\r\nErr http://ftp.debian.org jessie-backports/main amd64 Packages\r\n  \r\nErr http://ftp.debian.org jessie-backports/main amd64 Packages\r\n  \r\nErr http://ftp.debian.org jessie-backports/main amd64 Packages\r\n  \r\nErr http://ftp.debian.org jessie-backports/main amd64 Packages\r\n  404  Not Found\r\nHit http://cdn-fastly.deb.debian.org jessie Release.gpg\r\nHit http://cdn-fastly.deb.debian.org jessie Release\r\nGet:3 http://cdn-fastly.deb.debian.org jessie/updates/main amd64 Packages [829 kB]\r\n\r\n\r\n\r\nGet:4 http://cdn-fastly.deb.debian.org jessie/main amd64 Packages [9098 kB]\r\nGet:5 http://cdn-fastly.deb.debian.org jessie/contrib amd64 Packages [59.2 kB]\r\nGet:6 http://cdn-fastly.deb.debian.org jessie/non-free amd64 Packages [101 kB]\r\nFetched 10.1 MB in 9min 38s (17.5 kB/s)\r\nW: Failed to fetch http://cdn-fastly.deb.debian.org/debian/dists/jessie-updates/InRelease  Unable to find expected entry \'main/binary-amd64/Packages\' in Release file (Wrong sources.list entry or malformed file)\r\n\r\nW: Failed to fetch http://ftp.debian.org/debian/dists/jessie-backports/main/binary-amd64/Packages  404  Not Found\r\n\r\nE: Some index files failed to download. They have been ignored, or old ones used instead.\r\nThe command \'/bin/sh -c apt-get update && apt-get install -y   unzip\' returned a non-zero code: 100\r\nbuild.py: 2019-04-30 15:53:35,677 Failed to build docker image\r\n--- Logging error ---\r\nTraceback (most recent call last):\r\n  File ""/usr/lib/python3.6/logging/__init__.py"", line 994, in emit\r\n    msg = self.format(record)\r\n  File ""/usr/lib/python3.6/logging/__init__.py"", line 840, in format\r\n    return fmt.format(record)\r\n  File ""/usr/lib/python3.6/logging/__init__.py"", line 577, in format\r\n    record.message = record.getMessage()\r\n  File ""/usr/lib/python3.6/logging/__init__.py"", line 338, in getMessage\r\n    msg = msg % self.args\r\nTypeError: not all arguments converted during string formatting\r\nCall stack:\r\n  File ""./build.py"", line 394, in <module>\r\n    sys.exit(main())\r\n  File ""./build.py"", line 315, in main\r\n    build_docker(platform, docker_binary, registry=args.docker_registry, num_retries=num_docker_build_retires)\r\n  File ""./build.py"", line 118, in build_docker\r\n    logging.exception(\'Exception during build of docker image\', saved_exception)\r\nMessage: \'Exception during build of docker image\'\r\nArguments: (CalledProcessError(100, [\'docker\', \'build\', \'-f\', \'docker/Dockerfile.build.android_armv7\', \'--build-arg\', \'USER_ID=0\', \'--build-arg\', \'GROUP_ID=0\', \'--cache-from\', \'mxnetcipinned/build.android_armv7\', \'-t\', \'mxnetcipinned/build.android_armv7\', \'docker\']),)\r\nbuild.py: 2019-04-30 15:53:35,678 Failed to build the docker image, aborting...\r\n\r\n']","['sudo ./build.py -p android_armv7', 'Dockerfile.build.android_armv7', 'FROM mxnetci/dockcross-linux-base:08212018', 'FROM mxnetcipinned/dockcross-base:11262018', '--docker-registry', 'ci/build.py', '/etc/docter/daemon.json']",0,0
118,incubator-mxnet,9823,closed,RCNN example fails for using latest mxnet,"I am using mxnet with CUDA9 + CUDNN7 and distributed training enabled. However, when I re-run the rcnn code in the example, I got the following error:

Traceback (most recent call last):
  File ""train_end2end.py"", line 199, in <module>
    main()
  File ""train_end2end.py"", line 196, in main
    lr=args.lr, lr_step=args.lr_step)
  File ""train_end2end.py"", line 158, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File ""/----/libs/incubator-mxnet/python/mxnet/module/base_module.py"", line 496, in fit
    self.update_metric(eval_metric, data_batch.label)
  File ""/----/mx-rcnn/rcnn/core/module.py"", line 227, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File ""/----/libs/incubator-mxnet/python/mxnet/module/module.py"", line 749, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File ""/----/libs/incubator-mxnet/python/mxnet/module/executor_group.py"", line 616, in update_metric
    eval_metric.update_dict(labels_, preds)
  File ""/----/libs/incubator-mxnet/python/mxnet/metric.py"", line 280, in update_dict
    metric.update_dict(labels, preds)
  File ""/----/libs/incubator-mxnet/python/mxnet/metric.py"", line 108, in update_dict
    self.update(label, pred)
  File ""/----/mx-rcnn/rcnn/core/metric.py"", line 51, in update
    pred_label = mx.ndarray.argmax_channel(pred).asnumpy().astype('int32')
  File ""/----/libs/incubator-mxnet/python/mxnet/ndarray/ndarray.py"", line 1801, in asnumpy
    ctypes.c_size_t(data.size)))
  File ""/----/libs/incubator-mxnet/python/mxnet/base.py"", line 148, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [17:08:44] src/operator/nn/./cudnn/cudnn_softmax_activation-inl.h:154: Check failed: e == CUDNN_STATUS_SUCCESS (3 vs. 0) cuDNN: CUDNN_STATUS_BAD_PARAM

Stack trace returned 10 entries:
[bt] (0) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(dmlc::StackTrace()+0x3d) [0x2adc0c3395cd]
[bt] (1) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x18) [0x2adc0c339a58]
[bt] (2) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::op::CuDNNSoftmaxActivationOp::Backward(mxnet::OpContext const&, mxnet::TBlob const&, mxnet::TBlob const&, mxnet::OpReqType const&, mxnet::TBlob const&)+0x10b9) [0x2adc0f5c7669]
[bt] (3) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(void mxnet::op::SoftmaxActivationGradCompute<mshadow::gpu>(nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)+0xd4c) [0x2adc0f5c2eac]
[bt] (4) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::exec::FComputeExecutor::Run(mxnet::RunContext, bool)+0x50) [0x2adc0ec4cc40]
[bt] (5) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(+0x3284653) [0x2adc0ec54653]
[bt] (6)/----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::engine::ThreadedEngine::ExecuteOprBlock(mxnet::RunContext, mxnet::engine::OprBlock*)+0x2c4) [0x2adc0ec2fcd4]
[bt] (7) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(void mxnet::engine::ThreadedEnginePerDevice::GPUWorker<(dmlc::ConcurrentQueueType)0>(mxnet::Context, bool, mxnet::engine::ThreadedEnginePerDevice::ThreadWorkerBlock<(dmlc::ConcurrentQueueType)0>*, std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent> const&)+0x103) [0x2adc0ec34253]
[bt] (8) /----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler<void (std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent>), mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::{lambda()#3}::operator()() const::{lambda(std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent>)#1}>::_M_invoke(std::_Any_data const&, std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent>)+0x3e) [0x2adc0ec3448e]
[bt] (9)/----/libs/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(std::thread::_Impl<std::_Bind_simple<std::function<void (std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent>)> (std::shared_ptr<mxnet::engine::ThreadPool::SimpleEvent>)> >::_M_run()+0x3b) [0x2adc0ec2e36b]


Can anyone help me with it? Thanks very much!",Bug Example Operator,"['I somehow found a solution to this. Since I observed that this issue is caused by cudnn_softmax_activation function, both disabling cudnn and dropping the cudnn implementation of softmax will solve the problem. This mainly happens when using asnumpy() function for softmax results. Maybe someone can help check the real problem out and fix it. Thanks!', ""I encountered this problem in RCNN too. I've tested with cuda 8.0 and cudnn6.0.2/cudnn7.1.2, both of them are failed today. However, It can run seccussfully on mxnet version two month ago.\r\nI think there may be a bug within mxnet backend."", ""@marcoabreu It's not only the bug in RCNN, but also in mx.sym.SoftmaxOutput or mx.sym.SoftmaxActivation when their result are using in metric such as ```pred.asnumpy()```.\r\nIt may occur in multi-gpu case.\r\nSo I suggest that reopen this issue util it's solved."", ""It's solved when I roll back to mxnet v1.1.0."", 'Thanks a lot for providing more detail! This indeed sounds like quite a serious issue. Just to clarify, does this only happen on a multi-gpu or on a distributed training environment?\r\n\r\n@szha @rahul003 could check this please?', '    pred_label = mx.ndarray.argmax_channel(pred).asnumpy().astype(\'int32\')\r\n  File ""/home/ABCDEFG/dev/incubator-mxnet/python/mxnet/ndarray/ndarray.py"", line 1826, in asnumpy\r\n    ctypes.c_size_t(data.size)))\r\n  File ""/home/ABCDEFG/dev/incubator-mxnet/python/mxnet/base.py"", line 149, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [11:18:51] src/operator/nn/./cudnn/cudnn_softmax_activation-inl.h:154: Check failed: e == CUDNN_STATUS_SUCCESS (3 vs. 0) cuDNN: CUDNN_STATUS_BAD_PARAM\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /home/ABCDEFG/dev/incubator-mxnet/lib/libmxnet.so(dmlc::StackTrace[abi:cxx11]()+0x5b) [0x7f3943b0efab]\r\n[bt] (1) /home/ABCDEFG/dev/incubator-mxnet/lib/libmxnet.so(mxnet::op::CuDNNSoftmaxActivationOp::Backward(mxnet::OpContext const&, mxnet::TBlob const&, mxnet::TBlob const&, mxnet::OpReqType const&, mxnet::TBlob const&)+0x1bf5) [0x7f3947f52885]\r\n[bt] (2) /home/ABCDEFG/dev/incubator-mxnet/lib/libmxnet.so(void mxnet::op::SoftmaxActivationGradCompute<mshadow::gpu>(nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)+0x1e1b) [0x7f3947f4dd8b]\r\n[bt] (3) /home/ABCDEFG/dev/incubator-mxnet/lib/libmxnet.so(mxnet::exec::FComputeExecutor::Run(mxnet::RunContext, bool)+0x50) [0x7f39462912d0]\r\n[bt] (4) /home/ABCDEFG/dev/incubator-mxnet/lib/libmxnet.so(+0x330c7f8) [0x7f39462587f8]\r\n[bt] (5) /home/ABCDEFG/dev/incubator-mxnet/lib/libmxnet.so(mxnet::engine::ThreadedEngine::ExecuteOprBlock(mxnet::RunContext, mxnet::engine::OprBlock*)+0x8e5) [0x7f394689d2c5]\r\n[bt] (6) /home/ABCDEFG/dev/incubator-mxnet/lib/libmxnet.so(void mxnet::engine::ThreadedEnginePerDevice::GPUWorker<(dmlc::ConcurrentQueueType)0>(mxnet::Context, bool, mxnet::engine::ThreadedEnginePerDevice::ThreadWorkerBlock<(dmlc::ConcurrentQueueType)0>*, std::shared_ptr<dmlc::ManualEvent> const&)+0xeb) [0x7f39468b2e4b]\r\n[bt] (7) /home/ABCDEFG/dev/incubator-mxnet/lib/libmxnet.so(std::_Function_handler<void (std::shared_ptr<dmlc::ManualEvent>), mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::{lambda()#3}::operator()() const::{lambda(std::shared_ptr<dmlc::ManualEvent>)#1}>::_M_invoke(std::_Any_data const&, std::shared_ptr<dmlc::ManualEvent>&&)+0x4e) [0x7f39468b30ae]\r\n[bt] (8) /home/ABCDEFG/dev/incubator-mxnet/lib/libmxnet.so(std::thread::_Impl<std::_Bind_simple<std::function<void (std::shared_ptr<dmlc::ManualEvent>)> (std::shared_ptr<dmlc::ManualEvent>)> >::_M_run()+0x4a) [0x7f39468acf5a]\r\n[bt] (9) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80) [0x7f3975ab5c80]', '@marcoabreu It also happened on single GPU by chance.', 'I\'m sure that the problem is caused by this line.\r\nhttps://github.com/apache/incubator-mxnet/blob/7c28089749287f42ea8f41abd1358e6dbac54187/example/rcnn/rcnn/symbol/symbol_resnet.py#L187\r\nWhen I changed the line to\r\n```\r\nrpn_cls_prob = mx.symbol.softmax(data=rpn_cls_score_reshape, axis=1, name=""rpn_cls_prob"")\r\n```\r\nThe problem is solved. So I\'m sure the mx.symbol.SoftmaxActivation operator(which depend on CUDNN, on the other hand, the mx.symbol.softmax operator is native implementation) has some bug after #9677 . @zheng-da ', ' It happened on single GPU by chance in my machine with mxnet 1.2.0.', ""It seems the reason is that CUDNN call fails.\r\n\r\nWhen the compile options includes USE_CUDNN=1, the softmax activation operator uses CUDNNSoftmax.\r\n\r\nAnd the convolution operator prints the log: \r\nsrc/operator/nn/convolution.cu:140: This convolution is not supported by cudnn, MXNET convolution is applied. The old CUDNN doesn't support dilated conv.\r\n\r\nSoftmax Operator dosen't use CUDNN, so it doesn't cause any error.\r\n\r\nSolution:\r\n1.compile MXNet with latest CUDNN\r\n2.Replace mx.sym.SoftmaxActivation(cudnn) with mx.sym.Softmax(pure CUDA) if CUDNN didn't support SoftmaxActivation."", 'I had the same problem. I have just installed mxnet gpu support version 1.1.0\r\nBefore i had mxnet-cu80 1.2.0.\r\n\r\nand It worked.', '@Ram124 The latest MXNet has fixed the bug.\r\nhttps://github.com/apache/incubator-mxnet/pull/10918', '@wkcn . Oh cool. i will check that..\r\n\r\nI have my custom dataset in pascal format.\r\nwhat changes needs to be done to get started with training.\r\nI have 2 classes( pedestrian + bicycle). i need to classify them on single image..\r\nI have changed pascal.py by changing class names and numbers.\r\n\r\nIs there anything else that i need to change?\r\n\r\nAnybody done training on own dataset. Please help me out.\r\n ', '@Ram124 \r\nYou also need to change num_classes in [config.py](https://github.com/apache/incubator-mxnet/blob/master/example/rcnn/rcnn/config.py).', '@wkcn \r\nI should make it 3 right? with background.\r\nconfig.NUM_CLASSES = 21\r\n\r\nAnd where should i specify my datset??\r\ni have my dataset in \r\n./data/my_own_data/\r\nAnnotations\r\nImagesets\r\nImages\r\n\r\nIn which files should i give this path??\r\nso that it can read my custom data\r\n\r\n', 'The num_classes includes background, so 3 is right.\r\nFor the dataset path, you could check config.py, pascal_voc.py and pascal_voc_eval.py ', '@wkcn \r\nThank you.\r\nwhen i run demo.py. I am getting something like this.\r\nWhat is this??\r\n\r\n(mxnet_p27) ubuntu@ip-172-31-10-202:~/mx-rcnn-1$ python demo.py --prefix model/vgg16 --epoch 0 --image myimage.jpg --gpu 0 --vis\r\nTraceback (most recent call last):\r\n  File ""demo.py"", line 143, in <module>\r\n    main()\r\n  File ""demo.py"", line 138, in main\r\n    predictor = get_net(symbol, args.prefix, args.epoch, ctx)\r\n  File ""demo.py"", line 49, in get_net\r\n    assert k in arg_params, k + \' not initialized\'\r\nAssertionError: rpn_conv_3x3_weight not initialized\r\n\r\n', 'It seems that you read a pretrained model rather than detection model.\r\nThere is no rpn_conv parameter.', 'I solved that problem. Thank You fro that.\r\n\r\nI am trying to train on my own dataset. \r\nI have changed Number of classes in config.py\r\n\r\nI have modified pascal.py (changed Class names, i have only 2 classes + 1 background)\r\n\r\nBut now getting this error..What is the problem @wkcn \r\n\r\n\r\nINFO:root:voc_radar_train append flipped images to roidb\r\nTraceback (most recent call last):\r\n  File ""train_end2end.py"", line 178, in <module>\r\n    main()\r\n  File ""train_end2end.py"", line 175, in main\r\n    lr=args.lr, lr_step=args.lr_step)\r\n  File ""train_end2end.py"", line 39, in train_net\r\n    for image_set in image_sets]\r\n  File ""/home/ubuntu/mx-rcnn-1/rcnn/utils/load_data.py"", line 13, in load_gt_roidb\r\n    roidb = imdb.append_flipped_images(roidb)\r\n  File ""/home/ubuntu/mx-rcnn-1/rcnn/dataset/imdb.py"", line 168, in append_flipped_images\r\n    assert (boxes[:, 2] >= boxes[:, 0]).all()\r\nAssertionError\r\n\r\n\r\n', 'It seems the dataset is wrong.\r\nThe boxes xmin, ymin, xmax, ymax should be started with 1.', 'matlab is starting with 1', 'Yaa  I corrected it.\r\n\r\nNow i m getting this error after 1 epoch. How to solve this? Is it related to mxnet version?\r\n\r\nTraceback (most recent call last):\r\n  File ""train_end2end.py"", line 178, in <module>\r\n    main()\r\n  File ""train_end2end.py"", line 175, in main\r\n    lr=args.lr, lr_step=args.lr_step)\r\n  File ""train_end2end.py"", line 137, in train_net\r\n    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)\r\n  File ""/home/ubuntu/anaconda3/envs/mxnet_p27/lib/python2.7/site-packages/mxnet/module/base_module.py"", line 517, in fit\r\n    self.set_params(arg_params, aux_params)\r\n  File ""/home/ubuntu/anaconda3/envs/mxnet_p27/lib/python2.7/site-packages/mxnet/module/base_module.py"", line 652, in set_params\r\n    allow_extra=allow_extra)\r\nTypeError: init_params() got an unexpected keyword argument \'allow_extra\'\r\n\r\n', '@wkcn @chinakook @ysfalo @ijkguo I have a question regarding batch size. Can we use batch size of more than 1 in mxnet-rcnn training??\r\nBecause i have a large dataset of 15000 images. \r\nif i do training on them , the speed : 2.35 sample/sec.\r\nit takes almost  4 hours per epoch.\r\nis there anyother way i could increase the speed??\r\n\r\nAny help is really appreciated.', ""So the original issue has been fixed in https://github.com/apache/incubator-mxnet/pull/10918.\r\n\r\nAs to unexpected kwarg 'allow_extra' and multi-batch size training, they are solved in https://github.com/apache/incubator-mxnet/pull/11373."", '@Ram124 If you regard batch_size, please use [SNIPER](https://github.com/mahyarnajibi/SNIPER). It can be trained with large batch_size.', ""Closing this after merging #11373, feel free to ping me to reopen it it's not fixed.""]",[],[],0,0
119,incubator-mxnet,8898,closed,PReLU in gluon,"    class PReLU(gluon.HybridBlock):
        def __init__(self, *args):
            super(PReLU, self).__init__(*args)
            with self.name_scope():
                self.alpha = self.params.get('alpha', shape=(1,), init=mx.init.Zero())
                self.act = gluon.nn.Activation(activation='relu')

        def hybrid_forward(self, F, x, *args, **kwargs):
            pos = self.act(x)
            neg = F.negative(self.alpha.data()) * self.act(F.negative(x))
            return pos + neg

This custom block only works for non-hybridized models (error below), but would be nice to see this as a default activation option, something similar to this: ""gluon.nn.Activation(activation='prelu')"" - Is this in the plans going forward?

    AssertionError: Argument data must be Symbol instances, but got 
    [ 0.]
    <NDArray 1 @cpu(0)>
",,"[""```\r\nclass PReLU(gluon.HybridBlock):\r\n    def __init__(self, *args):\r\n        super(PReLU, self).__init__(*args)\r\n        with self.name_scope():\r\n            self.alpha = self.params.get('alpha', shape=(1,), init=mx.init.Zero())\r\n            self.act = gluon.nn.Activation(activation='relu')\r\n\r\n    def hybrid_forward(self, F, x, alpha):\r\n        pos = self.act(x)\r\n        neg = F.negative(alpha) * self.act(F.negative(x))\r\n        return pos + neg\r\n```\r\n\r\nThis is how hybrid block works"", 'Regardless of `self.alpha.data()`, that still doesn\'t work with hybridizing. Even calling `prelu.hybridize()` before `prelu.initialize()` causes the same problem (errors below). Are there any plans in the future to release a \'prelu\' standard activation function; something like `gluon.nn.Activation(\'prelu\')` in the future? \r\n    \r\n    In [17]: mx.__version__\r\n    Out[17]: \'0.12.1\'\r\n\r\n    In [18]: prelu = PReLU()\r\n\r\n    In [19]: prelu.initialize()\r\n\r\n    In [20]: prelu.hybridize()\r\n\r\n    In [21]: test = mx.nd.array(np.random.randn(1,3,256,256))\r\n\r\n    In [22]: out = prelu(test)\r\n    [13:35:49] /Users/travis/build/dmlc/mxnet-distro/mxnet-build/dmlc-core/include/dmlc/logging.h:308: [13:35:49] src/operator/nn/../tensor/../elemwise_op_common.h:122: Check failed: assign(&dattr, (*vec)[i]) Incompatible attr in node prelu2__mul0 at 1-th input: expected (1,), got (1,3,256,256)\r\n\r\n    Stack trace returned 10 entries:\r\n    [bt] (0) 0   libmxnet.so                         0x000000010d904805 _ZN4dmlc15LogMessageFatalD2Ev + 37\r\n    [bt] (1) 1   libmxnet.so                         0x000000010d902399 _ZN4dmlc15LogMessageFatalD1Ev + 9\r\n    [bt] (2) 2   libmxnet.so                         0x000000010d9c32b2 _ZZN5mxnet2op12ElemwiseAttrIN4nnvm6TShapeEXadL_ZNS0_13shape_is_noneERKS3_EEXadL_ZNS0_12shape_assignEPS3_S5_EELb1EXadL_ZNS0_12shape_stringES5_EELin1ELin1EEEbRKNS2_9NodeAttrsEPNSt3__16vectorIT_NSA_9allocatorISC_EEEESG_RKSC_ENKUlPNSB_IS3_NSD_IS3_EEEEmPKcE_clESL_mSN_ + 610\r\n    [bt] (3) 3   libmxnet.so                         0x000000010d9c2ef1 _ZN5mxnet2op12ElemwiseAttrIN4nnvm6TShapeEXadL_ZNS0_13shape_is_noneERKS3_EEXadL_ZNS0_12shape_assignEPS3_S5_EELb1EXadL_ZNS0_12shape_stringES5_EELin1ELin1EEEbRKNS2_9NodeAttrsEPNSt3__16vectorIT_NSA_9allocatorISC_EEEESG_RKSC_ + 241\r\n    [bt] (4) 4   libmxnet.so                         0x000000010d9bfb83 _ZN5mxnet2op13ElemwiseShapeILi2ELi1EEEbRKN4nnvm9NodeAttrsEPNSt3__16vectorINS2_6TShapeENS6_9allocatorIS8_EEEESC_ + 259\r\n    [bt] (5) 5   libmxnet.so                         0x000000010e8823a2 _ZZN5mxnet4exec9InferAttrIN4nnvm6TShapeENSt3__18functionIFbRKNS2_9NodeAttrsEPNS4_6vectorIS3_NS4_9allocatorIS3_EEEESD_EEEZNS0_10InferShapeEONS2_5GraphEOSC_RKNS4_12basic_stringIcNS4_11char_traitsIcEENSA_IcEEEEE3$_0DnEESG_SH_T_PKcST_ST_ST_ST_T1_T2_bST_NS_12DispatchModeEENKUljbE_clEjb + 2770\r\n    [bt] (6) 6   libmxnet.so                         0x000000010e879a9e _ZN5mxnet4exec10InferShapeEON4nnvm5GraphEONSt3__16vectorINS1_6TShapeENS4_9allocatorIS6_EEEERKNS4_12basic_stringIcNS4_11char_traitsIcEENS7_IcEEEE + 4798\r\n    [bt] (7) 7   libmxnet.so                         0x000000010e88ecc4 _ZN5mxnet10imperative18CheckAndInferShapeEPN4nnvm5GraphEONSt3__16vectorINS1_6TShapeENS4_9allocatorIS6_EEEEbNS4_4pairIjjEESC_ + 1796\r\n    [bt] (8) 8   libmxnet.so                         0x000000010e88d945 _ZN5mxnet10Imperative8CachedOp15GetForwardGraphEbRKNSt3__16vectorIPNS_7NDArrayENS2_9allocatorIS5_EEEE + 1157\r\n    [bt] (9) 9   libmxnet.so                         0x000000010e8937c2 _ZN5mxnet10Imperative8CachedOp7ForwardERKNSt3__16vectorIPNS_7NDArrayENS2_9allocatorIS5_EEEESA_ + 98\r\n\r\n    ---------------------------------------------------------------------------\r\n    MXNetError                                Traceback (most recent call last)\r\n    <ipython-input-22-61e322b35fd0> in <module>()\r\n    ----> 1 out = prelu(test)\r\n\r\n    /Users/krzum/anaconda3/lib/python3.6/site-packages/mxnet/gluon/block.py in __call__(self, *args)\r\n        288     def __call__(self, *args):\r\n        289         """"""Calls forward. Only accepts positional arguments.""""""\r\n    --> 290         return self.forward(*args)\r\n        291 \r\n        292     def forward(self, *args):\r\n\r\n    /Users/krzum/anaconda3/lib/python3.6/site-packages/mxnet/gluon/block.py in forward(self, x, *args)\r\n        464             with x.context as ctx:\r\n        465                 if self._active:\r\n    --> 466                     return self._call_cached_op(x, *args)\r\n        467                 try:\r\n        468                     params = {i: j.data(ctx) for i, j in self._reg_params.items()}\r\n\r\n    /Users/krzum/anaconda3/lib/python3.6/site-packages/mxnet/gluon/block.py in _call_cached_op(self, *args)\r\n        392         for i, j in self._in_idx:\r\n        393             cargs[i] = args[j]\r\n    --> 394         out = self._cached_op(*cargs)\r\n        395         if isinstance(out, NDArray):\r\n        396             out = [out]\r\n\r\n    /Users/krzum/anaconda3/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py in __call__(self, *args, **kwargs)\r\n        144             ctypes.byref(num_output),\r\n        145             ctypes.byref(output_vars),\r\n    --> 146             ctypes.byref(out_stypes)))\r\n        147 \r\n        148         if original_output is not None:\r\n\r\n    /Users/krzum/anaconda3/lib/python3.6/site-packages/mxnet/base.py in check_call(ret)\r\n        144     """"""\r\n        145     if ret != 0:\r\n    --> 146         raise MXNetError(py_str(_LIB.MXGetLastError()))\r\n        147 \r\n        148 if sys.version_info[0] < 3:\r\n\r\n    MXNetError: Error in operator prelu2__mul0: [13:35:49] src/operator/nn/../tensor/../elemwise_op_common.h:122: Check failed: assign(&dattr, (*vec)[i]) Incompatible attr in node prelu2__mul0 at 1-th input: expected (1,), got (1,3,256,256)\r\n\r\n    Stack trace returned 10 entries:\r\n    [bt] (0) 0   libmxnet.so                         0x000000010d904805 _ZN4dmlc15LogMessageFatalD2Ev + 37\r\n    [bt] (1) 1   libmxnet.so                         0x000000010d902399 _ZN4dmlc15LogMessageFatalD1Ev + 9\r\n    [bt] (2) 2   libmxnet.so                         0x000000010d9c32b2 _ZZN5mxnet2op12ElemwiseAttrIN4nnvm6TShapeEXadL_ZNS0_13shape_is_noneERKS3_EEXadL_ZNS0_12shape_assignEPS3_S5_EELb1EXadL_ZNS0_12shape_stringES5_EELin1ELin1EEEbRKNS2_9NodeAttrsEPNSt3__16vectorIT_NSA_9allocatorISC_EEEESG_RKSC_ENKUlPNSB_IS3_NSD_IS3_EEEEmPKcE_clESL_mSN_ + 610\r\n    [bt] (3) 3   libmxnet.so                         0x000000010d9c2ef1 _ZN5mxnet2op12ElemwiseAttrIN4nnvm6TShapeEXadL_ZNS0_13shape_is_noneERKS3_EEXadL_ZNS0_12shape_assignEPS3_S5_EELb1EXadL_ZNS0_12shape_stringES5_EELin1ELin1EEEbRKNS2_9NodeAttrsEPNSt3__16vectorIT_NSA_9allocatorISC_EEEESG_RKSC_ + 241\r\n    [bt] (4) 4   libmxnet.so                         0x000000010d9bfb83 _ZN5mxnet2op13ElemwiseShapeILi2ELi1EEEbRKN4nnvm9NodeAttrsEPNSt3__16vectorINS2_6TShapeENS6_9allocatorIS8_EEEESC_ + 259\r\n    [bt] (5) 5   libmxnet.so                         0x000000010e8823a2 _ZZN5mxnet4exec9InferAttrIN4nnvm6TShapeENSt3__18functionIFbRKNS2_9NodeAttrsEPNS4_6vectorIS3_NS4_9allocatorIS3_EEEESD_EEEZNS0_10InferShapeEONS2_5GraphEOSC_RKNS4_12basic_stringIcNS4_11char_traitsIcEENSA_IcEEEEE3$_0DnEESG_SH_T_PKcST_ST_ST_ST_T1_T2_bST_NS_12DispatchModeEENKUljbE_clEjb + 2770\r\n    [bt] (6) 6   libmxnet.so                         0x000000010e879a9e _ZN5mxnet4exec10InferShapeEON4nnvm5GraphEONSt3__16vectorINS1_6TShapeENS4_9allocatorIS6_EEEERKNS4_12basic_stringIcNS4_11char_traitsIcEENS7_IcEEEE + 4798\r\n    [bt] (7) 7   libmxnet.so                         0x000000010e88ecc4 _ZN5mxnet10imperative18CheckAndInferShapeEPN4nnvm5GraphEONSt3__16vectorINS1_6TShapeENS4_9allocatorIS6_EEEEbNS4_4pairIjjEESC_ + 1796\r\n    [bt] (8) 8   libmxnet.so                         0x000000010e88d945 _ZN5mxnet10Imperative8CachedOp15GetForwardGraphEbRKNSt3__16vectorIPNS_7NDArrayENS2_9allocatorIS5_EEEE + 1157\r\n    [bt] (9) 9   libmxnet.so                         0x000000010e8937c2 _ZN5mxnet10Imperative8CachedOp7ForwardERKNSt3__16vectorIPNS_7NDArrayENS2_9allocatorIS5_EEEESA_ + 98\r\n\r\n\r\n    In [23]: prelu = PReLU()\r\n\r\n    In [24]: prelu.initialize()\r\n\r\n    In [25]: out = prelu(test)', ""`alpha` just needs to be broadcasted to multiply with `self.act(F.negative(x))`, so just use `broadcast_mul` instead of `*`. So modifying @piiswrong's code we have:\r\n\r\n```\r\nclass PReLU(gluon.HybridBlock):\r\n    def __init__(self, *args):\r\n        super(PReLU, self).__init__(*args)\r\n        with self.name_scope():\r\n            self.alpha = self.params.get('alpha', shape=(1,), init=mx.init.Zero())\r\n            self.act = gluon.nn.Activation(activation='relu')\r\n\r\n    def hybrid_forward(self, F, x, alpha):\r\n        pos = self.act(x)\r\n        neg = F.broadcast_mul(F.negative(alpha), self.act(F.negative(x)))\r\n        return pos + neg\r\n```"", '@KayneWest Has this issue been fixed for you? \r\n', 'Please add the labels ""Gluon"" and ""Question""', '@mbaijal, It’s been fixed. ', 'Thanks']",[],[],0,0
120,incubator-mxnet,9117,closed,argsort produces an ndarray which cannot be used for indexing an ndarray,"The following snippet 


gives



I think that argsort result should be ready to be used as index for matrices with no further conversion.
Please also note that argsort returns an NDAarray of floats and not of ints as one would expect for indexes.
",,"['What version of MXNet are you using? Works fine for me in version 1.0.0.\r\n\r\n```\r\n$ pip list | grep mxnet\r\nmxnet (1.0.0.post1)\r\n$ python\r\nPython 3.6.3 (default, Oct  4 2017, 06:09:15) \r\n[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.37)] on darwin\r\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\r\n>>> from mxnet import nd\r\n>>> import numpy as np\r\n>>> X = nd.random_normal(shape=(10, 10))\r\n>>> np.all(nd.argsort(X, axis=1).asnumpy().astype(int) == np.argsort(X.asnumpy(), axis=1))\r\nTrue\r\n>>> np.all(X[nd.argsort(X, axis=1)].asnumpy() == X.asnumpy()[np.argsort(X.asnumpy(), axis=1)])\r\nTrue\r\n```', ""@aidan-plenert-macdonald Try the code I posted above, it won't work. You can use neither an numpy array or a NDArray as index of NDArray.\r\n\r\n In particular\r\n```X = nd.random_normal(shape=(10, 10))```\r\n```X[nd.argsort(X,axis=1)] = 0``` -> **ValueError: NDArray does not support slicing with key**\r\n```X[nd.argsort(X,axis=1).astype(int)] = 0``` -> **ValueError: NDArray does not support slicing with key**\r\n```X.asnumpy()[nd.argsort(X,axis=1).asnumpy()] = 0``` -> **IndexError: arrays used as indices must be of integer (or boolean) type**\r\n```X.asnumpy()[nd.argsort(X,axis=1).astype(int).asnumpy()] = 0``` -> **Ok**\r\n\r\n\r\nBTW,\r\n```\r\n>>> mx.__version__\r\n'0.12.1'\r\n```"", 'It works for me.\r\n\r\n```\r\n>>> from mxnet import nd\r\n>>> X = nd.random_normal(shape=(10, 10))\r\n>>> X[nd.argsort(X,axis=1)] = 0\r\n>>> X\r\n\r\n[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\r\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\r\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\r\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\r\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\r\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\r\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\r\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\r\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\r\n [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\r\n<NDArray 10x10 @cpu(0)>\r\n```\r\n\r\nTry upgrading your versions,\r\n```\r\n$ pip list | grep ""numpy\\|mxnet""\r\nmxnet (1.0.0.post1)\r\nnumpy (1.13.3)\r\n```', 'Yes, it works with mxnet 1.0.0.\r\nThank you.']","[' X[nd.argsort(X,axis=1)] = 0 ', ""\r\nValueError: NDArray does not support slicing with key \r\n[[  1.   2.   4. ...,  45.  14.  22.]\r\n [  0.   1.   2. ...,  46.   5.  22.]\r\n [  0.   1.   7. ...,   5.   4.  46.]\r\n ..., \r\n [  1.   4.   7. ...,  26.   9.   6.]\r\n [  0.   1.   2. ...,  36.  45.  22.]\r\n [  0.   1.   5. ...,  20.  13.  14.]]\r\n<NDArray 64x50 @cpu(0)> of type <class 'mxnet.ndarray.ndarray.NDArray'>.\r\n""]",[],0,0
121,incubator-mxnet,1102,closed,Segmentation fault when loading a saved numpy-op model,"I create a new layer with python refered to the example [numpy_softmax.py](https://github.com/dmlc/mxnet/blob/master/example/numpy-ops/numpy_softmax.py.
The fit process is good. But when I tried to load the model from json file there is a segmentation fault. I have known it is caused by the serialization and deserialization of the native python object. What can I do to make sure I can load the model correctly?
",,"['This is expected behavior. You cannot load a numpyop. Instead, you can recreate the symbol and the model, then init the parameters by loading with with mx.initializer.Load\n']",[],[],0,0
122,incubator-mxnet,3568,closed,slowness with new code,"I know this is vague question, but I recently pulled the latest code and all of my models runs half as fast or worse now during training with the same code. My last version came from early March. I was wondering if something about training has been changed which could explain why this happened. I'm using convolutional, pooling, batch normalization, and dense layers with ReLU activations. Thanks!
",,"['multi-gpu or one gpu?\n', 'Both. Multi-gpu will still provide a speedup compared to single GPU though.\n', ""just try `kv-store='device'` when using multi-gpu\n"", 'try set the cudnn_tune=kOff in convolution operator\n', 'Using the two above suggestions sped up my code back to the original amount. Thank you!']",[],[],0,0
123,incubator-mxnet,3723,closed,Does mxnet provide Model Average for distributed training?,"Now I would like to train the example code _train_cifar10_resnet.py_ with two local workers, is there any existed model average implementation I can directly use? (For example, CNTK has this kind of feature)
Or should I write the corresponding update rules for the kv-store?

Thanks a lot!",,"['what model averaging?\ntry kv-store=dist_sync?\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
124,incubator-mxnet,2018,closed,example about doing OCR use CNN+RNN,"I see some papers about doing OCR without segmentation using CNN and LSTM.

Does mxnet support such work?
",,"[""I don't think we have an example for this. But you can definitely do it with mxnet. The speech and RNN examples are good references\n"", 'Thanks!\n', '@xlvector \nHave you succeeded in achieving CNN + LSTM + CTC code?\nor just achieve example warpctc?\nrecently I am studying cnn + lstm + ctc joint-training, but I have met some problem, did you make it successfully?\n', 'You can see examples under /examples/warpctc/\n', ""```\n        This example does not use cnn to extract features as lstm's input，so when the captcha have rotate or some change it wont recognize success，do u plan to add cnn to this example？\n        在2016年07月20日 15:17，Xiang Liang 写道:You can see examples under /examples/warpctc/\n```\n\n—You are receiving this because you commented.Reply to this email directly, view it on GitHub, or mute the thread.\n"", '@sinmaystar @xlvector Do you gays make some progress with cnn+rnn+ctc?', 'example/warpctc  @sosong   You need to use an old version of warpctc from https://github.com/baidu-research/warp-ctc with version 5bfb46e83bcb338a09fbf875cb0b02bc39746b36', '@xlvector Does warp-ctc plugin support bucketing? I implemented cnn-bi_lstm-ctc with buckets in order to fit variable input image length, but I find it all the outputs of final layer remain same during training, however it will converge if I resized all images to fixed length and only use one bucket.\r\nSo I guess warp-ctc may not be compatible with bucketing.']",[],[],0,0
125,incubator-mxnet,16996,closed,mx.io.NDArrayIter cant pad when size is large,"## Description
When input data is smaller than batch size, sometime it errors out with:


## To Reproduce


Using a batch size of 20 succeeds, but larger sizes fail. 

### Steps to reproduce
This is using the 1.6.0 branch
",Bug,[],"['\r\nTraceback (most recent call last):\r\n  File ""test.py"", line 7, in <module>\r\n    for batch in dataiter:\r\n  File ""/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/io/io.py"", line 230, in __next__\r\n    return self.next()\r\n  File ""/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/io/io.py"", line 682, in next\r\n    data = self.getdata()\r\n  File ""/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/io/io.py"", line 764, in getdata\r\n    return self._batchify(self.data)\r\n  File ""/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/io/io.py"", line 751, in _batchify\r\n    second_data = self._getdata(data_source, end=pad)\r\n  File ""/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/io/io.py"", line 707, in _getdata\r\n    ]]) for x in data_source\r\n  File ""/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/io/io.py"", line 707, in <listcomp>\r\n    ]]) for x in data_source\r\n  File ""/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py"", line 705, in __getitem__\r\n    return self._slice(key.start, key.stop)\r\n  File ""/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py"", line 1338, in _slice\r\n    start, stop, _ = _get_index_range(start, stop, self.shape[0])\r\n  File ""/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py"", line 3080, in _get_index_range\r\n    raise IndexError(\'Slicing stop %d exceeds limit of %d\' % (stop, length))\r\nIndexError: Slicing stop 190 exceeds limit of 10\r\n', ""\r\nimport numpy as np\r\nimport mxnet as mx\r\n\r\ndata = np.arange(40).reshape((10,2,2))\r\ndataiter = mx.io.NDArrayIter(data=data, batch_size=200, last_batch_handle='pad')\r\nfor batch in dataiter:\r\n     print(batch.data[0].asnumpy().shape)\r\n""]",[],0,0
126,incubator-mxnet,7826,closed,Enable the test_CSVIter which fails intermittently on windows,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: Windows

Compiler:

Package used (Python/R/Scala/Julia): Python

MXNet version: master

Or if installed from source:

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. nosetests tests/python/unittest/test_io.py
2.
3.

## What have you tried to solve it?

1.
2.
3.
",Bug Flaky Windows,"['Running the test on windwos environment fails with following \r\n- System \r\n\r\n  - Provider \r\n\r\n   [ Name]  Application Error \r\n \r\n  - EventID 1000 \r\n\r\n   [ Qualifiers]  0 \r\n \r\n   Level 2 \r\n \r\n   Task 100 \r\n \r\n   Keywords 0x80000000000000 \r\n \r\n  - TimeCreated \r\n\r\n   [ SystemTime]  2017-09-11T22:20:04.170823700Z \r\n \r\n   EventRecordID 4672 \r\n \r\n   Channel Application \r\n \r\n   Computer EC2AMAZ-SQL8POR \r\n \r\n   Security \r\n \r\n\r\n- EventData \r\n\r\n   python.exe \r\n   3.6.1150.1013 \r\n   58d320d0 \r\n   libmxnet.dll \r\n   0.0.0.0 \r\n   59b6bc76 \r\n   c0000005 \r\n   0000000000dd7f28 \r\n   5d8 \r\n   01d32b4c1b20cf09 \r\n   C:\\Anaconda3\\envs\\py3\\python.exe \r\n   c:\\Users\\jenkins\\Downloads\\workspace\\ut-python-cpu\\pkg_vc14_cpu\\build\\libmxnet.dll \r\n   04ddb8ec-73c8-4452-ab18-cf25f7ce2ddc \r\n    \r\n    \r\n\r\n\r\n- EventData \r\n\r\n   python.exe \r\n   3.6.1150.1013 \r\n   58d320d0 \r\n   libmxnet.dll \r\n   0.0.0.0 \r\n   59b6bc76 \r\n   c0000005 \r\n   0000000000dd7f28 \r\n   5d8 \r\n   01d32b4c1b20cf09 \r\n   C:\\Anaconda3\\envs\\py3\\python.exe \r\n   c:\\Users\\jenkins\\Downloads\\workspace\\ut-python-cpu\\pkg_vc14_cpu\\build\\libmxnet.dll \r\n   04ddb8ec-73c8-4452-ab18-cf25f7ce2ddc \r\n    \r\n    \r\n\r\n   3.6.1150.1013 \r\n   58d320d0 \r\n   libmxnet.dll \r\n   0.0.0.0 \r\n   59b6bc76 \r\n   c0000005 \r\n   0000000000dd7f28 \r\n   5d8 \r\n   01d32b4c1b20cf09 \r\n   C:\\Anaconda3\\envs\\py3\\python.exe \r\n   c:\\Users\\jenkins\\Downloads\\workspace\\ut-python-cpu\\pkg_vc14_cpu\\build\\libmxnet.dll \r\n   04ddb8ec-73c8-4452-ab18-cf25f7ce2ddc \r\n', 'Step to reproduce the issue. just run this test on g2.2x or g2.8x ec2 windows instance. ', '@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', '@szha this is already fixed in #10533.', 'The fundamental cause was in dmlc-core, and fixed in https://github.com/dmlc/dmlc-core/pull/381', 'I have run this test on Windows built from the latest MXNet source and could not reproduce the error. ', 'thanks @haojin2 for the fix, @apeforest for confirming the fix.']",[],"['git rev-parse HEAD', 'sessionInfo()']",0,0
127,incubator-mxnet,1801,closed,Customise control towards the gradient flow,"Dear all,
Just as the title indicats that I would like to customise the flow of the gradients.
For example,


when updating the parameters, I want to update  only according to the gradient from  while ignoring .
I notice that this might be done via utilising  array, but can anyone give me a specific instruction? Any level will be acceptable for me (python or c++).

Thanks in advance.
",,"['use operator BlockGrad.\n\n```\ntensor_2 = mx.sym.BlockGrad(tensor_0)\n```\n', '@tqchen This works. Thank you very much for your suggestion. \nTwo remaining question: \nI notice that `req` array is always `kWriteTo`. How can I modify it?\nAnd will mxnet add both the gradients from `tensor_1` and `tensor_2` as a default behaviour if I do not use `BlockGrad`?\n', 'Yes\n', 'grads in branches will be automatically added up, so there is no need to do this manually\n', '@tqchen Thank you again. Close for now.\n']",[],"['tensor_0 -> tensor_1', 'tensor_0 -> tensor_2', 'tensor_0', 'tensor_1', 'tensor_2', 'req']",0,0
128,incubator-mxnet,902,closed,how to initialize the weights,"I want to init the fc layer weights alone , how to do ?
",,"['You can pass pre-initialized weight into  Feedforward as in \n\nhttps://github.com/dmlc/mxnet/blob/master/python/mxnet/model.py#L479\n\nThe Feedforward is a thin wrapper of  NDArray and initialization happens here https://github.com/dmlc/mxnet/blob/master/python/mxnet/model.py#L540 You can do arbitrary operations you like to initialize the ndarrays like in this function. Either by reusing initializer class, or do your own initialization\n', 'this issue help a lot\n', 'Hi @qiaohaijun, I am extremely new to mxnet, could you please shed some more light regarding the solution. May I know what exact changes do I need to make, to change weight initialization method of one particular layers, along with changing its mean and std, like we do in Caffe\n`weight_filler { type: ""gaussian"" mean: 0.0 std: 0.01 }`\n\nThanks,\nGaurav\n', 'Hi @gaush123 , I wondered if your problem has solved. Could you please shall your solution with me?\n', ""No, I didn't exactly solve this issue. \n"", '@gaush123 @MissFishLi Check out the initializers: http://mxnet.readthedocs.io/en/latest/packages/python/model.html#module-mxnet.initializer. Probably the `Load` or `Mixed` will suit your needs.\n']",[],[],0,0
129,incubator-mxnet,3198,closed,Check list for more operators,"Lacking of operators is the major disadvantage of MXNet comparing to other frameworks. The current multidimensional array interface follows the  convention. See this [tutorial](http://nbviewer.jupyter.org/github/dmlc/mxnet-notebooks/blob/master/python/basic/ndarray.ipynb) for a quick overview. 

Now we are going to add the rest numpy operators into MXNet, and also fix the existing operators if their are different to the according ones in numpy.

I grabbed numpy's routines from [this page](https://docs.scipy.org/doc/numpy/reference/routines.html). The comparison to MXNet's operators will be listed in a few following issues. 

For an operator, there are 4 states 
- **v** : already done, and it is consistent to numpy
- **p** : partially done. the part should be fixed is on the comments
- **x** : not exists, need to add into mxnet
- **=** : not exists, but will not support in a short time
- **?** : not sure whether x or =, leave for discussion
  We will use separate issues to track each operator category. The schedule is
- [ ] survey the current status, and which operators should be added or fixed.
- [ ] examples codes to implement new operators
- [ ] assign jobs to contributors 

Also some related tasks:
- better operator documents
- better unittest 
- improve neural network related operators 
",Call for Contribution,['close on stale issue'],[],['numpy.ndarray'],0,0
130,incubator-mxnet,3915,closed,auto_module_index.js doesn't work properly,"Some changes made in API pages, for example, changing the link content of left sidebar, makes auto_module_index.js failed. Now some entries such as ""Symbol Creation API Reference"" has no child level any more. ",,"['try bisecting?', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
131,incubator-mxnet,2727,closed,about using the im2rec.py,"@tmatas 
I am not sure about using the im2rec.py,
 for example, the file 'im2rec.py' in the folder 'D:/test' and the two class of trainning images(for two classification) in the folders 'D:/test/train1' and 'D:/test/train2', respectively, and the image file is jpeg format.
as for as the example, how to create the rec file for  mx.io.ImageRecordIter with  im2rec.py?  
thanks for your help very much.
",,"['From https://github.com/phunterlau/kaggle_statefarm/tree/master/inception , you can find a complete example for (1) creating the image list; (2) creating rec files; (3) training using mxnet.\n\nThe training set is from https://www.kaggle.com/c/state-farm-distracted-driver-detection .I hope this helps.\n', ""for the two steps of creating REC file, it is OK, but now, 'make_list.py'  is deleted, and just 'im2rec.py' is used for creating REC file, as for as this one step of creating REC file is concerned, how to use  'im2rec.py' ?\nthanks for your help.\n"", 'This is using the `im2rec.cc`, `im2rec.py` is similar.\n\nhttps://github.com/phunterlau/kaggle_statefarm/blob/master/inception/gen_rec_bin.sh#L10\n', ""Deleted make_list.py, fixed a typo in im2rec.py by tmatas · Pull Request #2463 · dmlc/mxnet https://github.com/dmlc/mxnet/pull/2463\n\nso I cannot download ' make_list.py' and use it now, what can I do?\nthanks for your help.\n"", 'you can find a older version of make_list.py here [https://github.com/imistyrain/mxnet-mr/blob/master/make_list.py](https://github.com/imistyrain/mxnet-mr/blob/master/make_list.py)\n', 'thanks.\n']",[],[],0,0
132,incubator-mxnet,13441,closed,[Clojure] Add Spec Validations for the Random namespace,"It would be nice to add some spec validations to the random namespace https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/org/apache/clojure_mxnet/random.clj

So that if a user calls a function with the incorrect arguments, it will guide them to the correct form.

Using the  function as in https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/org/apache/clojure_mxnet/module.clj#L186 and the correct specs would be a great addition to the project.

Addition of unit tests to test a failing case of the spec that an exception is thrown would be great too :)
",Clojure good first issue,['Thanks @hellonico !'],[],['util/validate'],0,0
133,incubator-mxnet,14895,closed,[DOC] Build from source link for ubuntu is broken,"On this page: https://github.com/apache/incubator-mxnet/blob/master/docs/install/build_from_source.md

If click the ubuntu hyperlink, it is broken:
https://github.com/apache/incubator-mxnet/blob/master/docs/install/ubuntu_setup.html
",Bug Doc pr-awaiting-merge,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Build', 'Looking into this, this seems to be true for all the links. since we convert our md docs to html for the docs website, looks like html links are hardcoded']",[],[],0,0
134,incubator-mxnet,6912,closed,I'm sorry that i cant find the tools?,"where the tools in your project?
",,[],[],[],0,0
135,incubator-mxnet,12030,closed,What happen when I group two same model together and train it?,"For example:

My code is something like above. Both resnet 50 is initialized by the same initializer. However, the outputs of these two softmax are different in the begining, Something likes 27.x vs 21.x

It is very strange I think.",Python,"['Thanks for trying it out.\u2028For how-to and usability questions, please use MXNet discuss forum -\xa0https://discuss.mxnet.io/\xa0to involve wider community.\u2028We want to use Github issues mainly for bugs and feature request. Feel free to reopen if closed in error.\r\n\r\n@sandeep-krishnamurthy\xa0Can you add labels: Question, Python and close this issue?\r\n']","[""\r\nsoftmax1 = resnet_50()\r\nsoftmax2 = resnet_50()\r\nout = mx.sym.Group([softmax1, softmax2])\r\nmodel = mx.module.Module(symbol=out, context=ctx, data_names=['data1', 'data2'], label_names=['softmax_label1','softmax_label2'])\r\ntrain_dataiter = get_dataiter() #will produce the DataBatch with [('data1',[N, 3, 224,224]), ('data2',[N,3,224,224])] and the data and label of data1 and data2 are totally the same.\r\n\r\nmodel.fit(train_dataiter, ......)\r\n""]",[],0,0
136,incubator-mxnet,16932,open,Detect unsupported usage of Gluon Hybridization,"## Description
Sometimes users may expect Gluon hybridization to magically do things it currently cannot do.
An example is https://github.com/apache/incubator-mxnet/issues/16926, where the user expects  control flow to be incorporated into the hybridized graph.

Instead of silently ignoring the control flow and picking the branch that was selected during the first call to the hybrid network, we should error out or warn the user.",Feature request Gluon,"['I think, that the bigger issue here is not that hybridization doesn\'t account for user defined conditions/branching, but that there is no way (?) to obtain information about the current execution mode after hybridization.\r\n\r\nIf I understood you correctly, detecting ""unsupported"" usage for hybridization in Gluon would require introspecting user code inside `hybrid_forward`, which is not possible/reasonable IMO.\r\n\r\nWhat do you think about adding `mxnet.sym.is_training()` and `mxnet.nd.is_training()`? They should return a Symbol/Ndarray respectively, instead of a python bool. That way we could use `F.contrib.cond(F.is_training(), ...)` to emulate the desired behaviour.\r\n\r\nThe current solution of ""just create 2 models"" is simply atrocious.', 'The proposed solution will help for the case of #16926. Do you want to work on it?\r\n\r\nUsing `F.contrib.cond` could (need to confirm with @junrushao1994 ) currently make your model run slower as certain optimizations taken by MXNet are currently not supported with dynamic control flow in the computational graph. \r\n\r\nDetecting ""unsupported"" usage for hybridization is non-trivial / may require restrictions on the programming model, but would improve the user-experience.']",[],['if autograd.is_training()'],0,0
137,incubator-mxnet,15482,closed,mx2onnx error  about  batchnorm,"## Description
 I use mx2onnx onnx_mxnet.export_model to transfer mxnet symbol to onnx . But the moving_mean&moving_var param of Batchnorm is not in the params. So the 

## Environment info (Required)



Package used (Python/R/Scala/Julia):
(I'm usining Python)

## Build info (Required if built from source)

Compiler (gcc):

MXNet commit hash:
(da4b2a82511df)

Build config:


ifndef CC
export CC = gcc
endif
ifndef CXX
export CXX = g++
endif
ifndef NVCC
export NVCC = nvcc
endif

# whether compile with options for MXNet developer
DEV = 0

# whether compile with debug
DEBUG = 0

# whether to turn on segfault signal handler to log the stack trace
USE_SIGNAL_HANDLER =

# the additional link flags you want to add
ADD_LDFLAGS =

# the additional compile flags you want to add
ADD_CFLAGS =

#---------------------------------------------
# matrix computation libraries for CPU/GPU
#---------------------------------------------

# whether use CUDA during compile
USE_CUDA = 1

# add the path to CUDA library to link and compile flag
# if you have already add them to environment variable, leave it as NONE
USE_CUDA_PATH = /usr/local/cuda
#USE_CUDA_PATH = NONE

# whether to enable CUDA runtime compilation
ENABLE_CUDA_RTC = 1

# whether use CuDNN R3 library
USE_CUDNN = 1

# whether to use NVTX when profiling
USE_NVTX = 0

#whether to use NCCL library
USE_NCCL = 0
#add the path to NCCL library
USE_NCCL_PATH = NONE

# whether use opencv during compilation
# you can disable it, however, you will not able to use
# imbin iterator
USE_OPENCV = 1
# Add OpenCV include path, in which the directory  exists
USE_OPENCV_INC_PATH = NONE
# Add OpenCV shared library path, in which the shared library exists
USE_OPENCV_LIB_PATH = NONE

#whether use libjpeg-turbo for image decode without OpenCV wrapper
USE_LIBJPEG_TURBO = 0
#add the path to libjpeg-turbo library
USE_LIBJPEG_TURBO_PATH = NONE

# use openmp for parallelization
USE_OPENMP = 1

# whether use MKL-DNN library: 0 = disabled, 1 = enabled
# if USE_MKLDNN is not defined, MKL-DNN will be enabled by default on x86 Linux.
# you can disable it explicity with USE_MKLDNN = 0
USE_MKLDNN = 0

# whether use NNPACK library
USE_NNPACK = 0

# choose the version of blas you want to use
# can be: mkl, blas, atlas, openblas
# in default use atlas for linux while apple for osx
UNAME_S := $(shell uname -s)
ifeq ($(UNAME_S), Darwin)
USE_BLAS = apple
else
USE_BLAS = atlas
endif

# whether use lapack during compilation
# only effective when compiled with blas versions openblas/apple/atlas/mkl
USE_LAPACK = 1

# path to lapack library in case of a non-standard installation
USE_LAPACK_PATH =

# add path to intel library, you may need it for MKL, if you did not add the path
# to environment variable
USE_INTEL_PATH = NONE

# If use MKL only for BLAS, choose static link automatically to allow python wrapper
ifeq ($(USE_BLAS), mkl)
USE_STATIC_MKL = 1
else
USE_STATIC_MKL = NONE
endif

#----------------------------
# Settings for power and arm arch
#----------------------------
ARCH := $(shell uname -a)
ifneq (,$(filter $(ARCH), armv6l armv7l powerpc64le ppc64le aarch64))
	USE_SSE=0
	USE_F16C=0
else
	USE_SSE=1
endif

#----------------------------
# F16C instruction support for faster arithmetic of fp16 on CPU
#----------------------------
# For distributed training with fp16, this helps even if training on GPUs
# If left empty, checks CPU support and turns it on.
# For cross compilation, please check support for F16C on target device and turn off if necessary.
USE_F16C =

#----------------------------
# distributed computing
#----------------------------

# whether or not to enable multi-machine supporting
USE_DIST_KVSTORE = 0

# whether or not allow to read and write HDFS directly. If yes, then hadoop is
# required
USE_HDFS = 0

# path to libjvm.so. required if USE_HDFS=1
LIBJVM=$(JAVA_HOME)/jre/lib/amd64/server

# whether or not allow to read and write AWS S3 directly. If yes, then
# libcurl4-openssl-dev is required, it can be installed on Ubuntu by
# sudo apt-get install -y libcurl4-openssl-dev
USE_S3 = 0

#----------------------------
# performance settings
#----------------------------
# Use operator tuning
USE_OPERATOR_TUNING = 1

# Use gperftools if found
# Disable because of #8968
USE_GPERFTOOLS = 0

# path to gperftools (tcmalloc) library in case of a non-standard installation
USE_GPERFTOOLS_PATH =

# Link gperftools statically
USE_GPERFTOOLS_STATIC =

# Use JEMalloc if found, and not using gperftools
USE_JEMALLOC = 1

# path to jemalloc library in case of a non-standard installation
USE_JEMALLOC_PATH =

# Link jemalloc statically
USE_JEMALLOC_STATIC =

#----------------------------
# additional operators
#----------------------------

# path to folders containing projects specific operators that you don't want to put in src/operators
EXTRA_OPERATORS =

#----------------------------
# other features
#----------------------------

# Create C++ interface package
USE_CPP_PACKAGE = 0

# Use int64_t type to represent the total number of elements in a tensor
# This will cause performance degradation reported in issue #14496
# Set to 1 for large tensor with tensor size greater than INT32_MAX i.e. 2147483647
# Note: the size of each dimension is still bounded by INT32_MAX
USE_INT64_TENSOR_SIZE = 0

# Python executable. Needed for cython target
PYTHON = python

#----------------------------
# plugins
#----------------------------

# whether to use caffe integration. This requires installing caffe.
# You also need to add CAFFE_PATH/build/lib to your LD_LIBRARY_PATH
# CAFFE_PATH = $(HOME)/caffe
# MXNET_PLUGINS += plugin/caffe/caffe.mk


#WARPCTC_PATH = $(HOME)/warp-ctc
WARPCTC_PATH = /home/deep/warp-ctc
MXNET_PLUGINS += plugin/warpctc/warpctc.mk

# whether to use sframe integration. This requires build sframe
# git@github.com:dato-code/SFrame.git
# SFRAME_PATH = $(HOME)/SFrame
# MXNET_PLUGINS += plugin/sframe/plugin.mk

## Error Message:
INFO:root:Converting idx: 0, op: null, name: data
INFO:root:Converting idx: 1, op: null, name: first-3x3-conv-conv2d_weight
INFO:root:Converting idx: 2, op: Convolution, name: first-3x3-conv-conv2d
INFO:root:Converting idx: 3, op: null, name: first-3x3-conv-batchnorm_gamma
INFO:root:Converting idx: 4, op: null, name: first-3x3-conv-batchnorm_beta
INFO:root:Converting idx: 5, op: null, name: first-3x3-conv-batchnorm_moving_mean
Traceback (most recent call last):
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 484, in <module>
    tune_and_evaluate(tuning_option)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 436, in tune_and_evaluate
    net, params, input_shape, _ = get_network(network, batch_size=1)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 93, in get_network
    return get_network_lpr_mb2(name,batch_size)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 143, in get_network_lpr_mb2
    test_onnx()
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 135, in test_onnx
    converted_model_path = onnx_mxnet.export_model(mx_sym, args, [input_shape], np.float32, onnx_file, True)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_model.py"", line 87, in export_model
    verbose=verbose)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_onnx.py"", line 256, in create_onnx_graph_proto
    idx=idx
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_onnx.py"", line 92, in convert_layer
    return convert_func(node, **kwargs)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/_op_translations.py"", line 170, in convert_weights_and_inputs
    np_arr = weights[name]
KeyError: 'first-3x3-conv-batchnorm_moving_mean'
Error in sys.excepthook:
Traceback (most recent call last):
  File ""/usr/lib/python3/dist-packages/apport_python_hook.py"", line 63, in apport_excepthook
    from apport.fileutils import likely_packaged, get_recent_crashes
  File ""/usr/lib/python3/dist-packages/apport/__init__.py"", line 5, in <module>
    from apport.report import Report
  File ""/usr/lib/python3/dist-packages/apport/report.py"", line 30, in <module>
    import apport.fileutils
  File ""/usr/lib/python3/dist-packages/apport/fileutils.py"", line 23, in <module>
    from apport.packaging_impl import impl as packaging
  File ""/usr/lib/python3/dist-packages/apport/packaging_impl.py"", line 23, in <module>
    import apt
  File ""/usr/lib/python3/dist-packages/apt/__init__.py"", line 23, in <module>
    import apt_pkg
ModuleNotFoundError: No module named 'apt_pkg'

Original exception was:
Traceback (most recent call last):
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 484, in <module>
    tune_and_evaluate(tuning_option)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 436, in tune_and_evaluate
    net, params, input_shape, _ = get_network(network, batch_size=1)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 93, in get_network
    return get_network_lpr_mb2(name,batch_size)
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 143, in get_network_lpr_mb2
    test_onnx()
  File ""/home/deep/workssd/arm/tvm_app/tune_relay_mobile_gpu.py"", line 135, in test_onnx
    converted_model_path = onnx_mxnet.export_model(mx_sym, args, [input_shape], np.float32, onnx_file, True)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_model.py"", line 87, in export_model
    verbose=verbose)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_onnx.py"", line 256, in create_onnx_graph_proto
    idx=idx
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/export_onnx.py"", line 92, in convert_layer
    return convert_func(node, **kwargs)
  File ""/home/deep/workssd/mxnet/incubator-mxnet/python/mxnet/contrib/onnx/mx2onnx/_op_translations.py"", line 170, in convert_weights_and_inputs
    np_arr = weights[name]
KeyError: 'first-3x3-conv-batchnorm_moving_mean'

## Minimum reproducible example


## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.python3 tran2onnx.py
2.

## What have you tried to solve it?

1.By debugging ,the moving_mean&moving_var  of batchnorm is not in params ,so the converter treat it as input which is not real.
2. There should be code to process the moving_mean&moving_var  of batchnorm indepently.
",,"['  sorry, the moving_mean&moving_var is in auxs. ']","[""\r\n----------Python Info----------\r\nVersion      : 3.6.8\r\nCompiler     : GCC 5.4.0 20160609\r\nBuild        : ('default', 'May  7 2019 14:58:50')\r\nArch         : ('64bit', 'ELF')\r\n------------Pip Info-----------\r\nVersion      : 19.1.1\r\nDirectory    : /usr/local/lib/python3.6/dist-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.5.0\r\nDirectory    : /home/deep/workssd/mxnet/incubator-mxnet/python/mxnet\r\nHashtag not found. Not installed from pre-built package.\r\n----------System Info----------\r\nPlatform     : Linux-4.4.0-148-generic-x86_64-with-Ubuntu-16.04-xenial\r\nsystem       : Linux\r\nnode         : MS-7817\r\nrelease      : 4.4.0-148-generic\r\nversion      : #174-Ubuntu SMP Tue May 7 12:20:14 UTC 2019\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                4\r\nOn-line CPU(s) list:   0-3\r\nThread(s) per core:    1\r\nCore(s) per socket:    4\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 60\r\nModel name:            Intel(R) Core(TM) i5-4590 CPU @ 3.30GHz\r\nStepping:              3\r\nCPU MHz:               3657.070\r\nCPU max MHz:           3700.0000\r\nCPU min MHz:           800.0000\r\nBogoMIPS:              6600.45\r\nVirtualization:        VT-x\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              6144K\r\nNUMA node0 CPU(s):     0-3\r\n\r\n\r\n""]","['opencv2', ""batch_size =  1\r\n    input_shape = (batch_size, 3, 512, 512)\r\n    output_shape = (batch_size, 65520,14)\r\n\r\n\r\n    mx_sym, args,auxs = mx.model.load_checkpoint('./model/ssd_mobilenetv2_512', 18)\r\n    mx_sym = get_symbol('mobilenetv2',512, num_classes=1,nms_thresh=0.5, force_nms=True, nms_topk=400)\r\n\r\n    onnx_file = './mxnet_exported_resnet18.onnx'\r\n    converted_model_path = onnx_mxnet.export_model(mx_sym, args, [input_shape], np.float32, onnx_file, True)""]",0,0
138,incubator-mxnet,6736,closed,DataParallelExecutorGroup: layout handling for symbols,"When  in a call to  of a ,  will try to concatenate the outputs from the different devices along the major axis.

The major axis is computed based on  in the initializer of .

What is the recommended way to set the  of a symbol? Simply pass  when constructing the symbol? Can the attribute be set automatically during module binding?

Setting  is necessary, as it is otherwise , leading to  trying to concatenate along  which will fail if the batch size is not divisible by the number of devices and the symbol outputs a shape (1, batch_size_per_device, X).

I.e. in case of 3 devices and batch size 128, concatenating  along  will fail.",,"['In most times, the default layout for DataDesc is \'NCHW\' or \'NTC\'. And, if the `layout` given to `get_batch_axis` is null, it will return 0 which is just the default batch axis. If your layout is not `N...`, set the layout attribute into op by yourself. Also, `concat` can concatenate those tensors different on the batch axis.\r\n```\r\ndef get_batch_axis(layout):\r\n        """"""Get the dimension that corresponds to the batch size.\r\n\r\n        When data parallelism is used, the data will be automatically split and\r\n        concatenated along the batch-size dimension. Axis can be -1, which means\r\n        the whole array will be copied for each data-parallelism device.\r\n\r\n        Parameters\r\n        ----------\r\n        layout : str\r\n            layout string. For example, ""NCHW"".\r\n\r\n        Returns\r\n        -------\r\n        int\r\n            An axis indicating the batch_size dimension.\r\n        """"""\r\n        if layout is None:\r\n            return 0\r\n        return layout.find(\'N\')\r\n```\r\n\r\n```\r\ndef concatenate(arrays, axis=0, always_copy=True):\r\n    """"""DEPRECATED, use ``concat`` instead\r\n\r\n    Parameters\r\n    ----------\r\n    arrays : list of `NDArray`\r\n        Arrays to be concatenate. They must have identical shape except\r\n        the first dimension. They also must have the same data type.\r\n    axis : int\r\n        The axis along which to concatenate.\r\n    always_copy : bool\r\n        Default `True`. When not `True`, if the arrays only contain one\r\n        `NDArray`, that element will be returned directly, avoid copying.\r\n\r\n    Returns\r\n    -------\r\n    NDArray\r\n        An `NDArray` that lives on the same context as `arrays[0].context`.\r\n    """"""\r\n    assert isinstance(arrays, list)\r\n    assert len(arrays) > 0\r\n    assert isinstance(arrays[0], NDArray)\r\n\r\n    if not always_copy and len(arrays) == 1:\r\n        return arrays[0]\r\n\r\n    shape_axis = arrays[0].shape[axis]\r\n    shape_rest1 = arrays[0].shape[0:axis]\r\n    shape_rest2 = arrays[0].shape[axis+1:]\r\n    dtype = arrays[0].dtype\r\n    for arr in arrays[1:]:\r\n        shape_axis += arr.shape[axis]\r\n        assert shape_rest1 == arr.shape[0:axis]\r\n        assert shape_rest2 == arr.shape[axis+1:]\r\n        assert dtype == arr.dtype\r\n    ret_shape = shape_rest1 + (shape_axis,) + shape_rest2\r\n    ret = empty(ret_shape, ctx=arrays[0].context, dtype=dtype)\r\n\r\n    idx = 0\r\n    begin = [0 for _ in ret_shape]\r\n    end = list(ret_shape)\r\n    for arr in arrays:\r\n        if axis == 0:\r\n            ret[idx:idx+arr.shape[0]] = arr\r\n        else:\r\n            begin[axis] = idx\r\n            end[axis] = idx+arr.shape[axis]\r\n            # pylint: disable=no-member,protected-access\r\n            _internal._crop_assign(ret, arr, out=ret,\r\n                                   begin=tuple(begin),\r\n                                   end=tuple(end))\r\n            # pylint: enable=no-member,protected-access\r\n        idx += arr.shape[axis]\r\n\r\n    return ret\r\n```', ""> If your layout is not N..., set the layout attribute into op by yourself. \r\n\r\nWhat do you have in mind to set the layout attribute?\r\n\r\nConcretely my use case is about state-outputs from RNN. I.e. the states returned by `unroll`.\r\n\r\nI have shortly tried to set `attr={'__layout__': layout}` when creating the symbols, by adapting [rnn_cell.py](https://github.com/dmlc/mxnet/blob/master/python/mxnet/rnn/rnn_cell.py#L387). My code currently uses the workaround to set `merge_multi_context=False`."", 'If you are using \'FucedRNNCell\', the shape for `states` may not be swapped but the `outputs` do. You can ensure that because I\'m not absolutely sure. However, all `__layout__` attribute of rnn cell have been set. It should works for `[DataDesc.get_batch_axis(self.symbol[name].attr(\'__layout__\')) for name in self.output_names]`. \r\n```\r\ndef unroll(self, length, inputs, begin_state=None, layout=\'NTC\', merge_outputs=None):\r\n        self.reset()\r\n\r\n        inputs, axis = _normalize_sequence(length, inputs, layout, True)\r\n        if axis == 1:\r\n            warnings.warn(""NTC layout detected. Consider using ""\r\n                          ""TNC for FusedRNNCell for faster speed"")\r\n            inputs = symbol.swapaxes(inputs, dim1=0, dim2=1)\r\n        else:\r\n            assert axis == 0, ""Unsupported layout %s""%layout\r\n        if begin_state is None:\r\n            begin_state = self.begin_state()\r\n\r\n        states = begin_state\r\n        if self._mode == \'lstm\':\r\n            states = {\'state\': states[0], \'state_cell\': states[1]} # pylint: disable=redefined-variable-type\r\n        else:\r\n            states = {\'state\': states[0]}\r\n\r\n        rnn = symbol.RNN(data=inputs, parameters=self._parameter,\r\n                         state_size=self._num_hidden, num_layers=self._num_layers,\r\n                         bidirectional=self._bidirectional, p=self._dropout,\r\n                         state_outputs=self._get_next_state,\r\n                         mode=self._mode, name=self._prefix+\'rnn\',\r\n                         **states)\r\n\r\n        if not self._get_next_state:\r\n            outputs, states = rnn, []\r\n        elif self._mode == \'lstm\':\r\n            outputs, states = rnn[0], [rnn[1], rnn[2]]\r\n        else:\r\n            outputs, states = rnn[0], [rnn[1]]\r\n\r\n        if axis == 1:\r\n            outputs = symbol.swapaxes(outputs, dim1=0, dim2=1)\r\n\r\n        outputs, _ = _normalize_sequence(length, outputs, layout, merge_outputs)\r\n\r\n        return outputs, states\r\n```\r\n\r\n```\r\ndef state_info(self):\r\n        b = self._bidirectional + 1\r\n        n = (self._mode == \'lstm\') + 1\r\n        return [{\'shape\': (b*self._num_layers, 0, self._num_hidden), \'__layout__\': \'LNC\'}\r\n                for _ in range(n)]\r\n```', ""For FusedRNNCell (with BlockGrad on states) I get shapes `(1, 43, X), (1, 43, X), (1, 42, X)` for the states when specifying batchsize 128 on 3 devices.\r\nCurrently `_merge_multi_context` will try to concatenate these 3 ndarrays along `dim=0`, which is not possible. That's why, as far as I understand, at some point the layout attribute of the state symbols should be set. Perhaps this should be done by `mx.sym.RNN`?"", ""```\r\nrnn = symbol.RNN(data=inputs, parameters=self._parameter,\r\n                         state_size=self._num_hidden, num_layers=self._num_layers,\r\n                         bidirectional=self._bidirectional, p=self._dropout,\r\n                         state_outputs=self._get_next_state,\r\n                         mode=self._mode, name=self._prefix+'rnn',\r\n                         **states)\r\n```\r\nYes. It just set the `__layout__` for the beginning `states` but `rnn`.  Just set attribute `__layout__` for `rnn` again may be simple.  However, this is just a temporary solution."", 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],"['merge_multi_context=True', 'get_outputs', 'DataParallelExecutorGroup', '_merge_multi_context', ""[DataDesc.get_batch_axis(self.symbol[name].attr('__layout__')) for name in self.output_names]"", 'DataParallelExecutorGroup', ""attr('__layout__')"", ""attr={'__layout__': layout}"", ""attr('__layout__')"", 'None', '_merge_multi_context', 'dim=0', '(1, 43), (1, 43), (1, 42)', 'dim=0']",0,0
139,incubator-mxnet,1246,closed,[torch backend] does torch backend as efficient  as original mxnet's op?,"I find the mxnet add torch support, so I have such question.

@piiswrong 
",,"[""Torch doesn't allow memory optimization. Otherwise the speed should be similar. I haven't done testing though\n""]",[],[],0,0
140,incubator-mxnet,9853,closed,Flaky test_operator.test_binary_op,"http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/397/pipeline



",Bug Flaky Operator Test,"[""This hasn't broken in like a year to my knowledge."", 'is that an mkl build?', 'No, on Windows we only run OpenBLAS.\n', ""It seems https://github.com/apache/incubator-mxnet/issues/9853 fails in the same test. It's strange how this fails."", ""Wasn't elemwise_add changed to use mkl?\r\nbtw, was it verified that mkl is faster for all shapes and types?  I saw it allocates memory, which seems like it might be slow."", ""I don't think we have the tools to measure performance on that scale yet. As far as I know, this is in the works. Since there's still some time until 1.2, we can definitely gather these numbers."", ""Well even if it was changed to use MKL, this would not apply here since we're running on OpenBLAS, right?"", ""@cjolivier01 in both cases (https://github.com/apache/incubator-mxnet/issues/9853 and https://github.com/apache/incubator-mxnet/issues/9844), the tests fail in test_bmod. It shouldn't have invoked elemwise_add "", ""i don’t know what is invoked in the process of calling test_bmod(). could\nbe that elemwise_add() isn’t called, or is called before and corrupts\nmemory, or maybe has nothing to do with elemwise_add.\n\nhowever, we seem to have a lot of tests that are suddenly failing... any\nideas?\n\nOn Thu, Feb 22, 2018 at 3:38 PM Da Zheng <notifications@github.com> wrote:\n\n> @cjolivier01 <https://github.com/cjolivier01> in both cases (#9853\n> <https://github.com/apache/incubator-mxnet/issues/9853> and #9844\n> <https://github.com/apache/incubator-mxnet/issues/9844>), the tests fail\n> in test_bmod. It shouldn't have invoked elemwise_add\n>\n> —\n> You are receiving this because you were mentioned.\n>\n>\n> Reply to this email directly, view it on GitHub\n> <https://github.com/apache/incubator-mxnet/issues/9853#issuecomment-367860345>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AKts_fYOpzaNXyAWlk7woscdV0Pz1w4Iks5tXfqHgaJpZM4SOaWO>\n> .\n>\n"", ""I don't have a clue right now. so far we see failures in random generators and binary operators. it's weird why it fails in these simple operators that are seemingly irrelevant to MKLDNN operators."", 'https://github.com/apache/incubator-mxnet/issues/9844', 'I think the cause of this is that operator mod is using doubles to make the computation, while the test is forcing float32, also the modulo operator for floating point seems to give different results in GPU vs CPU. Why is fmod in cuda giving different results?\r\n\r\nAccording to table 7  here https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#introduction-cuda-dynamic-parallelism\r\n\r\nthere should be no differences in fmod.\r\n\r\nhttps://github.com/apache/incubator-mxnet/blob/master/tests/python/unittest/test_operator.py#L1511\r\nhttps://github.com/apache/incubator-mxnet/blob/master/src/operator/mshadow_op.h#L402\r\n\r\n>>> np.double(1.68) % np.double(1.30123)\r\n0.37876999999999983\r\n>>> np.float32(1.68) % np.float32(1.30123)\r\n0.37877\r\n\r\n', 'I tried to increase the tolerance, but I found out one failure where the difference is much bigger than expected 0.28679015 . I think we should look deeper into this\r\n\r\n[-116.15162] <-input\r\n<NDArray 1 @gpu(0)>\r\n[-115.8648288] <- gradient\r\n[0.28679015] <- diff\r\n[0.8396868] <- a \r\n[0.0020733]  <- b\r\nFAIL', 'reproducible 100% with export MXNET_TEST_SEED=1688524483\r\n\r\nnosetests-3.4 -s -v test_operator_gpu.py:test_binary_op\r\n\r\n```\r\ndiff --git a/tests/python/unittest/test_operator.py b/tests/python/unittest/test_operator.py\r\nindex 5d38222..04e880c 100644\r\n--- a/tests/python/unittest/test_operator.py\r\n+++ b/tests/python/unittest/test_operator.py\r\n@@ -1429,6 +1429,16 @@ def check_binary_op_backward(symbol, baseline, gen_data, rtol=1e-3, atol=1e-5):\r\n         y.forward(is_train=True)\r\n         y.backward([mx.nd.array(out)])\r\n         assert_allclose(y_1.asnumpy(), x_1, rtol=rtol, atol=atol)\r\n+        z = np.abs(y_2.asnumpy() - x_2)\r\n+        w = np.where(z>atol)\r\n+        if w[0].size > 0:\r\n+            print(""d[0].shape: {} d[1].shape: {} baseline_grad2.shape: {}"".format(d[0].shape, d[1].shape, baseline_grad2.shape))\r\n+            print(w)\r\n+            print(y_2[w])\r\n+            print(x_2[w])\r\n+            print(z[w])\r\n+            print(d[0][w])\r\n+            print(d[1][w])\r\n```', ""I have likely found the root cause of this problem, just so we don't duplicate resources on this one."", 'seed 1060292419']","['\r\n======================================================================\r\n\r\nFAIL: test_operator.test_binary_op\r\n\r\n----------------------------------------------------------------------\r\n\r\nTraceback (most recent call last):\r\n\r\n  File ""C:\\Anaconda3\\envs\\py3\\lib\\site-packages\\nose\\case.py"", line 197, in runTest\r\n\r\n    self.test(*self.arg)\r\n\r\n  File ""C:\\jenkins_slave\\workspace\\ut-python-gpu@2\\tests\\python\\unittest\\common.py"", line 155, in test_new\r\n\r\n    orig_test(*args, **kwargs)\r\n\r\n  File ""C:\\jenkins_slave\\workspace\\ut-python-gpu@2\\tests\\python\\unittest\\test_operator.py"", line 1377, in test_binary_op\r\n\r\n    test_bmod(a, b)\r\n\r\n  File ""C:\\jenkins_slave\\workspace\\ut-python-gpu@2\\tests\\python\\unittest\\test_operator.py"", line 1353, in test_bmod\r\n\r\n    lambda g_out, a, b: (g_out, - g_out * (np.float32(a) // np.float32(b))), gen_binary_data)\r\n\r\n  File ""C:\\jenkins_slave\\workspace\\ut-python-gpu@2\\tests\\python\\unittest\\test_operator.py"", line 1319, in check_binary_op_backward\r\n\r\n    assert_allclose(y_2.asnumpy(), x_2, rtol=rtol, atol=atol)\r\n\r\n  File ""C:\\Anaconda3\\envs\\py3\\lib\\site-packages\\numpy\\testing\\utils.py"", line 1411, in assert_allclose\r\n\r\n    verbose=verbose, header=header, equal_nan=equal_nan)\r\n\r\n  File ""C:\\Anaconda3\\envs\\py3\\lib\\site-packages\\numpy\\testing\\utils.py"", line 796, in assert_array_compare\r\n\r\n    raise AssertionError(msg)\r\n\r\nAssertionError: \r\n\r\nNot equal to tolerance rtol=0.001, atol=1e-05\r\n\r\n\r\n\r\n(mismatch 0.5555555555555571%)\r\n\r\n x: array([[[[ -3.451749e-01,  -0.000000e+00,  -0.000000e+00,  -6.440228e-01],\r\n\r\n         [ -0.000000e+00,  -1.070805e+01,  -5.140794e-01,  -6.652636e-01],\r\n\r\n         [ -2.817436e-01,  -0.000000e+00,  -0.000000e+00,  -4.327150e+00]],...\r\n\r\n y: array([[[[ -3.451749e-01,  -0.000000e+00,  -0.000000e+00,  -6.440228e-01],\r\n\r\n         [ -0.000000e+00,  -1.070805e+01,  -5.140794e-01,  -6.652636e-01],\r\n\r\n         [ -2.817437e-01,  -0.000000e+00,  -0.000000e+00,  -4.327150e+00]],...\r\n\r\n-------------------- >> begin captured logging << --------------------\r\n\r\ncommon: INFO: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=94585786 to reproduce.\r\n\r\n--------------------- >> end captured logging << ---------------------\r\n']",[],0,0
141,incubator-mxnet,9044,closed,[scala] run_gan_mnist.sh fails,"# Description
Was able to built libmxnet.so, and successfully build the Scala package, but run_gan_mnist.sh fails.

## Environment info (Required)
I had to change diagnose.py:113 to except IOError as e: since FileNotFoundError is only on Python 3.


Package used (Python/R/Scala/Julia):
Scala

For Scala user, please provide:
1. Java version: ()

2. Maven version: ()


## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):


MXNet commit hash:
2700ddbbeef212879802f7f0c0812192ec5c2b77

Build config:


## Error Message:


## Minimum reproducible example
https://github.com/apache/incubator-mxnet/blob/master/scala-package/examples/scripts/run_gan_mnist.sh

## Steps to reproduce
1. make -j4
2. make scalapkg

3. make scalatest

4. make scalainstall

5. get the mnist data

6. update run_gan_mnist.sh to be cpu

7. bash run_gan_mnist.sh -1 ../../data ../../tmp


## What have you tried to solve it?

1. Check the links in libmxnet.so are there:

2. Check the built openblas from https://github.com/xianyi/OpenBLAS, but that doesn't seem to be the issue since the cblas function is there:
 
3. Looked at other possibly related issues, like #2184, which was closed and placed in the TODO in #3084 by @javelinjs but that was closed without having been resolved.",Bug Installation Scala,['#11547 should fix this.'],"[""\r\n----------Python Info----------\r\n('Version      :', '2.7.13')\r\n('Compiler     :', 'GCC 4.4.7 20120313 (Red Hat 4.4.7-18)')\r\n('Build        :', ('default', 'Aug 11 2017 20:36:55'))\r\n('Arch         :', ('64bit', 'ELF'))\r\n------------Pip Info-----------\r\n('Version      :', '9.0.1')\r\n('Directory    :', '/scratch/cahsin/pythondir27/lib/python2.7/site-packages/pip')\r\n----------MXNet Info-----------\r\n('Version      :', '1.0.0')\r\n('Directory    :', '/scratch/cahsin/repo/mxnet/python/mxnet')\r\nHashtag not found. Not installed from pre-built package.\r\n----------System Info----------\r\n('Platform     :', 'Linux-4.1.12-61.1.16.el6uek.x86_64-x86_64-with-redhat-6.9-Santiago')\r\n('system       :', 'Linux')\r\n('node         :', 'den02kge')\r\n('release      :', '4.1.12-61.1.16.el6uek.x86_64')\r\n('version      :', '#2 SMP Fri Oct 21 14:23:10 PDT 2016')\r\n----------Hardware Info----------\r\n('machine      :', 'x86_64')\r\n('processor    :', 'x86_64')\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                4\r\nOn-line CPU(s) list:   0-3\r\nThread(s) per core:    1\r\nCore(s) per socket:    4\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 63\r\nModel name:            Intel(R) Xeon(R) CPU E5-2699 v3 @ 2.30GHz\r\nStepping:              2\r\nCPU MHz:               2294.908\r\nBogoMIPS:              4589.81\r\nHypervisor vendor:     Xen\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              46080K\r\nNUMA node0 CPU(s):     0-3\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0050 sec, LOAD: 0.8736 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0001 sec, LOAD: 0.3412 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0000 sec, LOAD: 0.8275 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0012 sec, LOAD: 0.2533 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.1606 sec, LOAD: 0.3929 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.1115 sec, LOAD: 0.3883 sec.\r\n"", '\r\nbash-4.1$ java -version\r\njava version ""1.8.0_144""\r\nJava(TM) SE Runtime Environment (build 1.8.0_144-b01)\r\nJava HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\r\n', '\r\nbash-4.1$ mvn -version\r\nApache Maven 3.5.0 (ff8f5e7444045639af65f6095c62210b5713f426; 2017-04-03T15:39:06-04:00)\r\nMaven home: /scratch/cahsin/maven/apache-maven-3.5.0\r\nJava version: 1.8.0_144, vendor: Oracle Corporation\r\nJava home: /scratch/cahsin/java/jdk1.8.0_144/jre\r\nDefault locale: en_US, platform encoding: UTF-8\r\nOS name: ""linux"", version: ""4.1.12-61.1.16.el6uek.x86_64"", arch: ""amd64"", family: ""unix""\r\n', '\r\nbash-4.1$ gcc --version\r\ngcc (GCC) 4.8.2 20140120 (Red Hat 4.8.2-15)\r\nCopyright (C) 2013 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n', ""\r\n#-------------------------------------------------------------------------------\r\n#  Template configuration for compiling mxnet\r\n#\r\n#  If you want to change the configuration, please use the following\r\n#  steps. Assume you are on the root directory of mxnet. First copy the this\r\n#  file so that any local changes will be ignored by git\r\n#\r\n#  $ cp make/config.mk .\r\n#\r\n#  Next modify the according entries, and then compile by\r\n#\r\n#  $ make\r\n#\r\n#  or build in parallel with 8 threads\r\n#\r\n#  $ make -j8\r\n#-------------------------------------------------------------------------------\r\n\r\n#---------------------\r\n# choice of compiler\r\n#--------------------\r\n\r\nexport CC = gcc\r\nexport CXX = g++\r\nexport NVCC = nvcc\r\n\r\n# whether compile with options for MXNet developer\r\nDEV = 0\r\n\r\n# whether compile with debug\r\nDEBUG = 0\r\n\r\n# whether compile with profiler\r\nUSE_PROFILER =\r\n\r\n# whether to turn on signal handler (e.g. segfault logger)\r\nUSE_SIGNAL_HANDLER =\r\n\r\n# the additional link flags you want to add\r\nADD_LDFLAGS = -lopencv_core -lopencv_imgproc -L/scratch/cahsin/local/lib/ -lopenblas\r\n\r\n# the additional compile flags you want to add\r\n# where openblas .h files are\r\nADD_CFLAGS = -I/scratch/cahsin/local/include/ -I/scratch/cahsin/repo/OpenBLAS/\r\n\r\n#---------------------------------------------\r\n# matrix computation libraries for CPU/GPU\r\n#---------------------------------------------\r\n\r\n# whether use CUDA during compile\r\nUSE_CUDA = 0\r\n\r\n# add the path to CUDA library to link and compile flag\r\n# if you have already add them to environment variable, leave it as NONE\r\n# USE_CUDA_PATH = /usr/local/cuda\r\nUSE_CUDA_PATH = NONE\r\n\r\n# whether use CuDNN R3 library\r\nUSE_CUDNN = 0\r\n\r\n#whether to use NCCL library\r\nUSE_NCCL = 0\r\n#add the path to NCCL library\r\nUSE_NCCL_PATH = NONE\r\n\r\n# whether use opencv during compilation\r\n# you can disable it, however, you will not able to use\r\n# imbin iterator\r\nUSE_OPENCV = 1\r\n\r\n#whether use libjpeg-turbo for image decode without OpenCV wrapper\r\nUSE_LIBJPEG_TURBO = 0\r\n#add the path to libjpeg-turbo library\r\nUSE_LIBJPEG_TURBO_PATH = NONE\r\n\r\n# use openmp for parallelization\r\nUSE_OPENMP = 1\r\n\r\n# MKL ML Library for Intel CPU/Xeon Phi\r\n# Please refer to MKL_README.md for details\r\n\r\n# MKL ML Library folder, need to be root for /usr/local\r\n# Change to User Home directory for standard user\r\n# For USE_BLAS!=mkl only\r\nMKLML_ROOT=/usr/local\r\n\r\n# whether use MKL2017 library\r\nUSE_MKL2017 = 0\r\n\r\n# whether use MKL2017 experimental feature for high performance\r\n# Prerequisite USE_MKL2017=1\r\nUSE_MKL2017_EXPERIMENTAL = 0\r\n\r\n# whether use NNPACK library\r\nUSE_NNPACK = 0\r\n\r\n# choose the version of blas you want to use\r\n# can be: mkl, blas, atlas, openblas\r\n# in default use atlas for linux while apple for osx\r\nUNAME_S := $(shell uname -s)\r\nifeq ($(UNAME_S), Darwin)\r\nUSE_BLAS = apple\r\nelse\r\nUSE_BLAS = openblas \r\nendif\r\n\r\n# whether use lapack during compilation\r\n# only effective when compiled with blas versions openblas/apple/atlas/mkl\r\nUSE_LAPACK = 1\r\n\r\n# path to lapack library in case of a non-standard installation\r\nUSE_LAPACK_PATH =\r\n\r\n# by default, disable lapack when using MKL\r\n# switch on when there is a full installation of MKL available (not just MKL2017/MKL_ML)\r\nifeq ($(USE_BLAS), mkl)\r\nUSE_LAPACK = 0\r\nendif\r\n\r\n# add path to intel library, you may need it for MKL, if you did not add the path\r\n# to environment variable\r\nUSE_INTEL_PATH = NONE\r\n\r\n# If use MKL only for BLAS, choose static link automatically to allow python wrapper\r\nifeq ($(USE_MKL2017), 0)\r\nifeq ($(USE_BLAS), mkl)\r\nUSE_STATIC_MKL = 1\r\nendif\r\nelse\r\nUSE_STATIC_MKL = NONE\r\nendif\r\n\r\n#----------------------------\r\n# Settings for power and arm arch\r\n#----------------------------\r\nARCH := $(shell uname -a)\r\nifneq (,$(filter $(ARCH), armv6l armv7l powerpc64le ppc64le aarch64))\r\n\tUSE_SSE=0\r\nelse\r\n\tUSE_SSE=1\r\nendif\r\n\r\n#----------------------------\r\n# distributed computing\r\n#----------------------------\r\n\r\n# whether or not to enable multi-machine supporting\r\nUSE_DIST_KVSTORE = 0\r\n\r\n# whether or not allow to read and write HDFS directly. If yes, then hadoop is\r\n# required\r\nUSE_HDFS = 0\r\n\r\n# path to libjvm.so. required if USE_HDFS=1\r\nLIBJVM=$(JAVA_HOME)/jre/lib/amd64/server\r\n\r\n# whether or not allow to read and write AWS S3 directly. If yes, then\r\n# libcurl4-openssl-dev is required, it can be installed on Ubuntu by\r\n# sudo apt-get install -y libcurl4-openssl-dev\r\nUSE_S3 = 0\r\n\r\n#----------------------------\r\n# performance settings\r\n#----------------------------\r\n# Use operator tuning\r\nUSE_OPERATOR_TUNING = 1\r\n\r\n# Use gperftools if found\r\nUSE_GPERFTOOLS = 1\r\n\r\n# Use JEMalloc if found, and not using gperftools\r\nUSE_JEMALLOC = 1\r\n\r\n#----------------------------\r\n# additional operators\r\n#----------------------------\r\n\r\n# path to folders containing projects specific operators that you don't want to put in src/operators\r\nEXTRA_OPERATORS =\r\n\r\n#----------------------------\r\n# other features\r\n#----------------------------\r\n\r\n# Create C++ interface package\r\nUSE_CPP_PACKAGE = 1\r\n\r\n#----------------------------\r\n# plugins\r\n#----------------------------\r\n\r\n# whether to use caffe integration. This requires installing caffe.\r\n# You also need to add CAFFE_PATH/build/lib to your LD_LIBRARY_PATH\r\n# CAFFE_PATH = $(HOME)/caffe\r\n# MXNET_PLUGINS += plugin/caffe/caffe.mk\r\n\r\n# whether to use torch integration. This requires installing torch.\r\n# You also need to add TORCH_PATH/install/lib to your LD_LIBRARY_PATH\r\n# TORCH_PATH = $(HOME)/torch\r\n# MXNET_PLUGINS += plugin/torch/torch.mk\r\n\r\n# WARPCTC_PATH = $(HOME)/warp-ctc\r\n# MXNET_PLUGINS += plugin/warpctc/warpctc.mk\r\n\r\n# whether to use sframe integration. This requires build sframe\r\n# git@github.com:dato-code/SFrame.git\r\n# SFRAME_PATH = $(HOME)/SFrame\r\n# MXNET_PLUGINS += plugin/sframe/plugin.mk\r\n"", '\r\nbash-4.1$ bash run_gan_mnist.sh -1 ../../data ../../tmp\r\nSLF4J: Class path contains multiple SLF4J bindings.\r\nSLF4J: Found binding in [jar:file:/scratch/cahsin/repo/mxnet/scala-package/assembly/linux-x86_64-cpu/target/mxnet-full_2.11-linux-x86_64-cpu-1.0.0-SNAPSHOT.jar!/org/slf4j/impl/StaticLoggerBinder.class]\r\nSLF4J: Found binding in [jar:file:/scratch/cahsin/repo/mxnet/scala-package/examples/target/classes/lib/slf4j-log4j12-1.7.7.jar!/org/slf4j/impl/StaticLoggerBinder.class]\r\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\r\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\r\n2017-12-12 17:54:07,654 [main] [MXNetJVM] [INFO] - Try loading mxnet-scala from native path.\r\n2017-12-12 17:54:07,657 [main] [MXNetJVM] [INFO] - Try loading mxnet-scala-linux-x86_64-gpu from native path.\r\n2017-12-12 17:54:07,658 [main] [MXNetJVM] [INFO] - Try loading mxnet-scala-linux-x86_64-cpu from native path.\r\n2017-12-12 17:54:07,659 [main] [MXNetJVM] [WARN] - MXNet Scala native library not found in path. Copying native library from the archive. Consider installing the library somewhere in the path (for Windows: PATH, for Linux: LD_LIBRARY_PATH), or specifying by Java cmd option -Djava.library.path=[lib path].\r\n2017-12-12 17:54:07,697 [main] [ml.dmlc.mxnet.util.NativeLibraryLoader] [INFO] - Loading libmxnet-scala.so from /lib/native/ copying to mxnet-scala\r\n[17:54:10] src/io/iter_mnist.cc:113: MNISTIter: load 60000 images, shuffle=1, shape=[100,1,28,28]\r\njava: symbol lookup error: /tmp/mxnet1076674076824248309/mxnet-scala: undefined symbol: cblas_sgemm\r\n', '\r\nbash-4.1$ make scalapkg\r\nMakefile:224: WARNING: Significant performance increases can be achieved by installing and enabling gperftools or jemalloc development packages\r\n(cd /scratch/cahsin/repo/mxnet/scala-package; \\\r\n    mvn package -Plinux-x86_64-cpu -Dcxx=""g++"" \\\r\n      -Dcflags=""-DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -O3 -DNDEBUG=1 -I/scratch/cahsin/repo/mxnet/mshadow/ -I/scratch/cahsin/repo/mxnet/dmlc-core/include -fPIC -I/scratch/cahsin/repo/mxnet/nnvm/include -I/scratch/cahsin/repo/mxnet/dlpack/include -Iinclude -funroll-loops -Wno-unused-variable -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/scratch/cahsin/local/include/opencv -I/scratch/cahsin/local/include   -fopenmp -DMXNET_USE_OPERATOR_TUNING=1 -DMXNET_USE_LAPACK -I/scratch/cahsin/local/include/ -I/scratch/cahsin/repo/OpenBLAS/ -DMXNET_USE_NCCL=0 -DMXNET_USE_LIBJPEG_TURBO=0"" -Dldflags=""-pthread -lm -fopenmp -lrt -L/scratch/cahsin/local/lib -lopencv_calib3d -lopencv_contrib -lopencv_core -lopencv_features2d -lopencv_flann -lopencv_highgui -lopencv_imgproc -lopencv_legacy -lopencv_ml -lopencv_nonfree -lopencv_objdetect -lopencv_ocl -lopencv_photo -lopencv_stitching -lopencv_superres -lopencv_video -lopencv_videostab -lrt -lpthread -lm -ldl -lopencv_core -lopencv_imgproc -L/scratch/cahsin/local/lib/ -lopenblas"" \\\r\n      -Dcurrent_libdir=""/scratch/cahsin/repo/mxnet/lib"" \\\r\n      -Dlddeps=""/scratch/cahsin/repo/mxnet/dmlc-core/libdmlc.a /scratch/cahsin/repo/mxnet/nnvm/lib/libnnvm.a /scratch/cahsin/repo/mxnet/lib/libmxnet.a"")\r\n[INFO] Scanning for projects...\r\n[WARNING] \r\n[WARNING] Some problems were encountered while building the effective model for ml.dmlc.mxnet:mxnet-examples_2.11:jar:1.0.0-SNAPSHOT\r\n[WARNING] \'build.plugins.plugin.version\' for net.alchim31.maven:scala-maven-plugin is missing. @ ml.dmlc.mxnet:mxnet-examples_2.11:[unknown-version], /scratch/cahsin/repo/mxnet/scala-package/examples/pom.xml, line 106, column 15\r\n[WARNING] \r\n[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.\r\n[WARNING] \r\n[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.\r\n[WARNING] \r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Reactor Build Order:\r\n...\r\n...\r\n...\r\n...\r\n[INFO] --- maven-jar-plugin:3.0.2:jar (default-jar) @ mxnet-full_2.11-linux-x86_64-cpu ---\r\n[INFO] \r\n[INFO] --- maven-source-plugin:2.2.1:jar-no-fork (attach-sources) @ mxnet-full_2.11-linux-x86_64-cpu ---\r\n[INFO] No sources in project. Archive not created.\r\n[INFO] \r\n[INFO] --- maven-jar-plugin:3.0.2:jar (empty-javadoc-jar) @ mxnet-full_2.11-linux-x86_64-cpu ---\r\n[WARNING] JAR will be empty - no content was marked for inclusion!\r\n[INFO] \r\n[INFO] --- maven-assembly-plugin:2.5.5:single (default) @ mxnet-full_2.11-linux-x86_64-cpu ---\r\n[INFO] Reading assembly descriptor: src/main/assembly/assembly.xml\r\n[WARNING] Artifact: ml.dmlc.mxnet:mxnet-full_2.11-linux-x86_64-cpu:jar:1.0.0-SNAPSHOT references the same file as the assembly destination file. Moving it to a temporary location for inclusion.\r\n[INFO] Building jar: /scratch/cahsin/repo/mxnet/scala-package/assembly/linux-x86_64-cpu/target/mxnet-full_2.11-linux-x86_64-cpu-1.0.0-SNAPSHOT.jar\r\n[WARNING] Configuration options: \'appendAssemblyId\' is set to false, and \'classifier\' is missing.\r\nInstead of attaching the assembly file: /scratch/cahsin/repo/mxnet/scala-package/assembly/linux-x86_64-cpu/target/mxnet-full_2.11-linux-x86_64-cpu-1.0.0-SNAPSHOT.jar, it will become the file for main project artifact.\r\nNOTE: If multiple descriptors or descriptor-formats are provided for this project, the value of this file will be non-deterministic!\r\n[WARNING] Replacing pre-existing project main-artifact file: /scratch/cahsin/repo/mxnet/scala-package/assembly/linux-x86_64-cpu/target/archive-tmp/mxnet-full_2.11-linux-x86_64-cpu-1.0.0-SNAPSHOT.jar\r\nwith assembly file: /scratch/cahsin/repo/mxnet/scala-package/assembly/linux-x86_64-cpu/target/mxnet-full_2.11-linux-x86_64-cpu-1.0.0-SNAPSHOT.jar\r\n[INFO] \r\n[INFO] --- maven-javadoc-plugin:2.9.1:jar (attach-javadocs) @ mxnet-full_2.11-linux-x86_64-cpu ---\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Reactor Summary:\r\n[INFO] \r\n[INFO] MXNet Scala Package - Parent ....................... SUCCESS [  4.593 s]\r\n[INFO] MXNet Scala Package - Initializer .................. SUCCESS [  1.896 s]\r\n[INFO] MXNet Scala Package - Initializer Native Parent .... SUCCESS [  0.107 s]\r\n[INFO] MXNet Scala Package - Initializer Native Linux-x86_64 SUCCESS [  4.807 s]\r\n[INFO] MXNet Scala Package - Macros ....................... SUCCESS [  1.144 s]\r\n[INFO] MXNet Scala Package - Core ......................... SUCCESS [ 20.476 s]\r\n[INFO] MXNet Scala Package - Native Parent ................ SUCCESS [  0.128 s]\r\n[INFO] MXNet Scala Package - Native Linux-x86_64 CPU-only . SUCCESS [  3.077 s]\r\n[INFO] MXNet Scala Package - Examples ..................... SUCCESS [ 27.360 s]\r\n[INFO] MXNet Scala Package - Spark ML ..................... SUCCESS [ 10.935 s]\r\n[INFO] MXNet Scala Package - Full Parent .................. SUCCESS [  0.109 s]\r\n[INFO] MXNet Scala Package - Full Linux-x86_64 CPU-only ... SUCCESS [  9.293 s]\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD SUCCESS\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time: 01:25 min\r\n[INFO] Finished at: 2017-12-12T17:23:09-05:00\r\n[INFO] Final Memory: 154M/1173M\r\n', '\r\nbash-4.1$ make scalatest\r\nMakefile:224: WARNING: Significant performance increases can be achieved by installing and enabling gperftools or jemalloc development packages\r\n(cd /scratch/cahsin/repo/mxnet/scala-package; \\\r\n    mvn verify -Plinux-x86_64-cpu -Dcxx=""g++"" \\\r\n      -Dcflags=""-DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -O3 -DNDEBUG=1 -I/scratch/cahsin/repo/mxnet/mshadow/ -I/scratch/cahsin/repo/mxnet/dmlc-core/include -fPIC -I/scratch/cahsin/repo/mxnet/nnvm/include -I/scratch/cahsin/repo/mxnet/dlpack/include -Iinclude -funroll-loops -Wno-unused-variable -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/scratch/cahsin/local/include/opencv -I/scratch/cahsin/local/include   -fopenmp -DMXNET_USE_OPERATOR_TUNING=1 -DMXNET_USE_LAPACK -I/scratch/cahsin/local/include/ -I/scratch/cahsin/repo/OpenBLAS/ -DMXNET_USE_NCCL=0 -DMXNET_USE_LIBJPEG_TURBO=0"" -Dldflags=""-pthread -lm -fopenmp -lrt -L/scratch/cahsin/local/lib -lopencv_calib3d -lopencv_contrib -lopencv_core -lopencv_features2d -lopencv_flann -lopencv_highgui -lopencv_imgproc -lopencv_legacy -lopencv_ml -lopencv_nonfree -lopencv_objdetect -lopencv_ocl -lopencv_photo -lopencv_stitching -lopencv_superres -lopencv_video -lopencv_videostab -lrt -lpthread -lm -ldl -lopencv_core -lopencv_imgproc -L/scratch/cahsin/local/lib/ -lopenblas"" \\\r\n      -Dlddeps=""/scratch/cahsin/repo/mxnet/dmlc-core/libdmlc.a /scratch/cahsin/repo/mxnet/nnvm/lib/libnnvm.a /scratch/cahsin/repo/mxnet/lib/libmxnet.a"" )\r\n[INFO] Scanning for projects...\r\n[WARNING] \r\n[WARNING] Some problems were encountered while building the effective model for ml.dmlc.mxnet:mxnet-examples_2.11:jar:1.0.0-SNAPSHOT\r\n[WARNING] \'build.plugins.plugin.version\' for net.alchim31.maven:scala-maven-plugin is missing. @ ml.dmlc.mxnet:mxnet-examples_2.11:[unknown-version], /scratch/cahsin/repo/mxnet/scala-package/examples/pom.xml, line 106, column 15\r\n[WARNING] \r\n[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.\r\n[WARNING] \r\n[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.\r\n[WARNING] \r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Reactor Build Order:\r\n...\r\n...\r\n...\r\n...\r\n[INFO] \r\n[INFO] --- scalastyle-maven-plugin:0.8.0:check (default) @ mxnet-full_2.11-linux-x86_64-cpu ---\r\n[WARNING] sourceDirectory is not specified or does not exist value=/scratch/cahsin/repo/mxnet/scala-package/assembly/linux-x86_64-cpu/src/main/scala\r\n[WARNING] testSourceDirectory is not specified or does not exist value=/scratch/cahsin/repo/mxnet/scala-package/assembly/linux-x86_64-cpu/src/test/scala\r\nSaving to outputFile=/scratch/cahsin/repo/mxnet/scala-package/assembly/linux-x86_64-cpu/target/scalastyle-output.xml\r\nProcessed 0 file(s)\r\nFound 0 errors\r\nFound 0 warnings\r\nFound 0 infos\r\nFinished in 2 ms\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Reactor Summary:\r\n[INFO] \r\n[INFO] MXNet Scala Package - Parent ....................... SUCCESS [  6.316 s]\r\n[INFO] MXNet Scala Package - Initializer .................. SUCCESS [  3.302 s]\r\n[INFO] MXNet Scala Package - Initializer Native Parent .... SUCCESS [  1.033 s]\r\n[INFO] MXNet Scala Package - Initializer Native Linux-x86_64 SUCCESS [  6.798 s]\r\n[INFO] MXNet Scala Package - Macros ....................... SUCCESS [  2.462 s]\r\n[INFO] MXNet Scala Package - Core ......................... SUCCESS [01:27 min]\r\n[INFO] MXNet Scala Package - Native Parent ................ SUCCESS [  1.449 s]\r\n[INFO] MXNet Scala Package - Native Linux-x86_64 CPU-only . SUCCESS [  4.219 s]\r\n[INFO] MXNet Scala Package - Examples ..................... SUCCESS [ 36.493 s]\r\n[INFO] MXNet Scala Package - Spark ML ..................... SUCCESS [ 13.132 s]\r\n[INFO] MXNet Scala Package - Full Parent .................. SUCCESS [  0.963 s]\r\n[INFO] MXNet Scala Package - Full Linux-x86_64 CPU-only ... SUCCESS [  9.823 s]\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD SUCCESS\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time: 02:54 min\r\n[INFO] Finished at: 2017-12-12T17:44:15-05:00\r\n[INFO] Final Memory: 156M/1134M\r\n[INFO] ------------------------------------------------------------------------\r\n', '\r\nbash-4.1$ make scalainstall\r\nMakefile:224: WARNING: Significant performance increases can be achieved by installing and enabling gperftools or jemalloc development packages\r\n(cd /scratch/cahsin/repo/mxnet/scala-package; \\\r\n\t\tmvn install -Plinux-x86_64-cpu -DskipTests -Dcxx=""g++"" \\\r\n\t\t\t-Dcflags=""-DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -O3 -DNDEBUG=1 -I/scratch/cahsin/repo/mxnet/mshadow/ -I/scratch/cahsin/repo/mxnet/dmlc-core/include -fPIC -I/scratch/cahsin/repo/mxnet/nnvm/include -I/scratch/cahsin/repo/mxnet/dlpack/include -Iinclude -funroll-loops -Wno-unused-variable -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/scratch/cahsin/local/include/opencv -I/scratch/cahsin/local/include   -fopenmp -DMXNET_USE_OPERATOR_TUNING=1 -DMXNET_USE_LAPACK -I/scratch/cahsin/local/include/ -I/scratch/cahsin/repo/OpenBLAS/ -DMXNET_USE_NCCL=0 -DMXNET_USE_LIBJPEG_TURBO=0"" -Dldflags=""-pthread -lm -fopenmp -lrt -L/scratch/cahsin/local/lib -lopencv_calib3d -lopencv_contrib -lopencv_core -lopencv_features2d -lopencv_flann -lopencv_highgui -lopencv_imgproc -lopencv_legacy -lopencv_ml -lopencv_nonfree -lopencv_objdetect -lopencv_ocl -lopencv_photo -lopencv_stitching -lopencv_superres -lopencv_video -lopencv_videostab -lrt -lpthread -lm -ldl -lopencv_core -lopencv_imgproc -L/scratch/cahsin/local/lib/ -lopenblas"" \\\r\n\t\t\t-Dlddeps=""/scratch/cahsin/repo/mxnet/dmlc-core/libdmlc.a /scratch/cahsin/repo/mxnet/nnvm/lib/libnnvm.a /scratch/cahsin/repo/mxnet/lib/libmxnet.a"")\r\n[INFO] Scanning for projects...\r\n[WARNING] \r\n[WARNING] Some problems were encountered while building the effective model for ml.dmlc.mxnet:mxnet-examples_2.11:jar:1.0.0-SNAPSHOT\r\n[WARNING] \'build.plugins.plugin.version\' for net.alchim31.maven:scala-maven-plugin is missing. @ ml.dmlc.mxnet:mxnet-examples_2.11:[unknown-version], /scratch/cahsin/repo/mxnet/scala-package/examples/pom.xml, line 106, column 15\r\n[WARNING] \r\n[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.\r\n[WARNING] \r\n[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.\r\n[WARNING] \r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Reactor Build Order:\r\n...\r\n...\r\n...\r\n...\r\n[INFO] \r\n[INFO] --- scalastyle-maven-plugin:0.8.0:check (default) @ mxnet-full_2.11-linux-x86_64-cpu ---\r\n[WARNING] sourceDirectory is not specified or does not exist value=/scratch/cahsin/repo/mxnet/scala-package/assembly/linux-x86_64-cpu/src/main/scala\r\n[WARNING] testSourceDirectory is not specified or does not exist value=/scratch/cahsin/repo/mxnet/scala-package/assembly/linux-x86_64-cpu/src/test/scala\r\nSaving to outputFile=/scratch/cahsin/repo/mxnet/scala-package/assembly/linux-x86_64-cpu/target/scalastyle-output.xml\r\nProcessed 0 file(s)\r\nFound 0 errors\r\nFound 0 warnings\r\nFound 0 infos\r\nFinished in 1 ms\r\n[INFO] \r\n[INFO] --- maven-install-plugin:2.5.2:install (default-install) @ mxnet-full_2.11-linux-x86_64-cpu ---\r\n[INFO] Installing /scratch/cahsin/repo/mxnet/scala-package/assembly/linux-x86_64-cpu/target/mxnet-full_2.11-linux-x86_64-cpu-1.0.0-SNAPSHOT.jar to /home/cahsin/.m2/repository/ml/dmlc/mxnet/mxnet-full_2.11-linux-x86_64-cpu/1.0.0-SNAPSHOT/mxnet-full_2.11-linux-x86_64-cpu-1.0.0-SNAPSHOT.jar\r\n[INFO] Installing /scratch/cahsin/repo/mxnet/scala-package/assembly/linux-x86_64-cpu/pom.xml to /home/cahsin/.m2/repository/ml/dmlc/mxnet/mxnet-full_2.11-linux-x86_64-cpu/1.0.0-SNAPSHOT/mxnet-full_2.11-linux-x86_64-cpu-1.0.0-SNAPSHOT.pom\r\n[INFO] Installing /scratch/cahsin/repo/mxnet/scala-package/assembly/linux-x86_64-cpu/target/mxnet-full_2.11-linux-x86_64-cpu-1.0.0-SNAPSHOT-javadoc.jar to /home/cahsin/.m2/repository/ml/dmlc/mxnet/mxnet-full_2.11-linux-x86_64-cpu/1.0.0-SNAPSHOT/mxnet-full_2.11-linux-x86_64-cpu-1.0.0-SNAPSHOT-javadoc.jar\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Reactor Summary:\r\n[INFO] \r\n[INFO] MXNet Scala Package - Parent ....................... SUCCESS [  5.448 s]\r\n[INFO] MXNet Scala Package - Initializer .................. SUCCESS [  2.116 s]\r\n[INFO] MXNet Scala Package - Initializer Native Parent .... SUCCESS [  0.164 s]\r\n[INFO] MXNet Scala Package - Initializer Native Linux-x86_64 SUCCESS [  6.489 s]\r\n[INFO] MXNet Scala Package - Macros ....................... SUCCESS [  1.517 s]\r\n[INFO] MXNet Scala Package - Core ......................... SUCCESS [ 18.221 s]\r\n[INFO] MXNet Scala Package - Native Parent ................ SUCCESS [  0.182 s]\r\n[INFO] MXNet Scala Package - Native Linux-x86_64 CPU-only . SUCCESS [  3.736 s]\r\n[INFO] MXNet Scala Package - Examples ..................... SUCCESS [ 33.491 s]\r\n[INFO] MXNet Scala Package - Spark ML ..................... SUCCESS [ 11.440 s]\r\n[INFO] MXNet Scala Package - Full Parent .................. SUCCESS [  0.130 s]\r\n[INFO] MXNet Scala Package - Full Linux-x86_64 CPU-only ... SUCCESS [  9.548 s]\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] BUILD SUCCESS\r\n[INFO] ------------------------------------------------------------------------\r\n[INFO] Total time: 01:33 min\r\n[INFO] Finished at: 2017-12-12T17:50:14-05:00\r\n[INFO] Final Memory: 156M/1274M\r\n[INFO] ------------------------------------------------------------------------\r\n', '\r\nbash-4.1$ cd scala-package/\r\nbash-4.1$ core/scripts/get_mnist_data.sh\r\n', '\r\n#!/bin/bash\r\n\r\n# Licensed to the Apache Software Foundation (ASF) under one\r\n# or more contributor license agreements.  See the NOTICE file\r\n# distributed with this work for additional information\r\n# regarding copyright ownership.  The ASF licenses this file\r\n# to you under the Apache License, Version 2.0 (the\r\n# ""License""); you may not use this file except in compliance\r\n# with the License.  You may obtain a copy of the License at\r\n#\r\n#   http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing,\r\n# software distributed under the License is distributed on an\r\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\r\n# KIND, either express or implied.  See the License for the\r\n# specific language governing permissions and limitations\r\n# under the License.\r\n\r\n\r\nMXNET_ROOT=$(cd ""$(dirname $0)/../../..""; pwd)\r\nCLASS_PATH=$MXNET_ROOT/scala-package/assembly/linux-x86_64-cpu/target/*:$MXNET_ROOT/scala-package/examples/target/*:$MXNET_ROOT/scala-package/examples/target/classes/lib/*\r\n\r\n# which gpu card to use, -1 means cpu\r\nGPU=$1\r\n\r\n# the mnist data path\r\n# you can get the mnist data using the script core/scripts/get_mnist_data.sh\r\nMNIST_DATA_PATH=$2\r\n\r\n# the path to save the generated results\r\nOUTPUT_PATH=$3\r\n\r\njava -Xmx4G -cp $CLASS_PATH \\\r\n\tml.dmlc.mxnetexamples.gan.GanMnist \\\r\n\t--mnist-data-path $MNIST_DATA_PATH \\\r\n\t--gpu $GPU \\\r\n\t--output-path $OUTPUT_PATH\r\n', '\r\nbash-4.1$ bash run_gan_mnist.sh -1 ../../data ../../tmp\r\nSLF4J: Class path contains multiple SLF4J bindings.\r\nSLF4J: Found binding in [jar:file:/scratch/cahsin/repo/mxnet/scala-package/assembly/linux-x86_64-cpu/target/mxnet-full_2.11-linux-x86_64-cpu-1.0.0-SNAPSHOT.jar!/org/slf4j/impl/StaticLoggerBinder.class]\r\nSLF4J: Found binding in [jar:file:/scratch/cahsin/repo/mxnet/scala-package/examples/target/classes/lib/slf4j-log4j12-1.7.7.jar!/org/slf4j/impl/StaticLoggerBinder.class]\r\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\r\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\r\n2017-12-12 17:54:07,654 [main] [MXNetJVM] [INFO] - Try loading mxnet-scala from native path.\r\n2017-12-12 17:54:07,657 [main] [MXNetJVM] [INFO] - Try loading mxnet-scala-linux-x86_64-gpu from native path.\r\n2017-12-12 17:54:07,658 [main] [MXNetJVM] [INFO] - Try loading mxnet-scala-linux-x86_64-cpu from native path.\r\n2017-12-12 17:54:07,659 [main] [MXNetJVM] [WARN] - MXNet Scala native library not found in path. Copying native library from the archive. Consider installing the library somewhere in the path (for Windows: PATH, for Linux: LD_LIBRARY_PATH), or specifying by Java cmd option -Djava.library.path=[lib path].\r\n2017-12-12 17:54:07,697 [main] [ml.dmlc.mxnet.util.NativeLibraryLoader] [INFO] - Loading libmxnet-scala.so from /lib/native/ copying to mxnet-scala\r\n[17:54:10] src/io/iter_mnist.cc:113: MNISTIter: load 60000 images, shuffle=1, shape=[100,1,28,28]\r\njava: symbol lookup error: /tmp/mxnet1076674076824248309/mxnet-scala: undefined symbol: cblas_sgemm\r\n', '\r\nbash-4.1$  ldd lib/libmxnet.so | grep blas\r\n\tlibopenblas.so.0 => /scratch/cahsin/local/lib/libopenblas.so.0 (0x00007f86e2406000)\r\n', '\r\nbash-4.1$ nm /scratch/cahsin/local/lib/libopenblas.so.0 | grep cblas_sgemm\r\n0000000000090380 T cblas_sgemm\r\n']","['java -version', 'mvn -version']",0,0
142,incubator-mxnet,12839,closed,"[Clojure] Readme: ""Getting Started"" not entirely trivial to follow","I mentioned in #12822 that something in the README of the Clojure package was off and intended to fix it. However, now that I read the text in a bit more detail, I have some broader questions that might be good to discuss in advance before I come up with some random change.

The main issue with the current version is that as someone not familiar with the package architecture and just starting out with Clojure (that's me currently), you just follow instructions and don't really have a clue what you're doing. Some of the nagging questions while doing that were:

- If I want to use prebuilt jars, what *exactly* do I have to do?

  The fact that some of the instructions I need to follow are under *Cloning the repo and running from source* is rather confusing. I feel that instructions for ""From prebuilt jars"" and ""From source"" should be entirely separate.
  Maybe also good to know would be which possible scenarios there exist. If I should guess I would say (1) everything prebuilt jars, (2) all deps from prebuilt jars, but Clojure package from source, (3-infinity) all possible combinations of prebuilt jars and manual builds for deps, most notably the Scala package and MXNet core.

- Prebuilt jars of what?

  Certainly too much to mention, I guess, but the biggest ones, the Scala package and the base MXNet package would be worth mentioning.

- Where do the instructions end?

  I found it surprising to scroll past the examples to find a header *Build from MXNet Source*, because ""source"" was mentioned earlier already. Are those two things connected?
  One way to make it clear that there are two entirely separate sets of instructions (are there?) is to make headers **Method 1: Use prebuilt jars** and **Method 2: Build from source**.

- The prebuilt Scala package isn't working (#12822, workaround in place now). Can I build it from source but still use a prebuilt jar for MXNet core?

As I mentioned above, I'm not really familiar with the build infrastructure and the Clojure package architecture, so I wouldn't exactly know what to write as instructions. But equipped with some extra knowledge, I certainly could.",Clojure Doc Scala,"['Thanks @kohr-h for creating the issue. Feedback on the README and getting started is much appreciated and will make it easier for new folks to get started.\r\n\r\nWould you be interested in collaborating on this with me to make it better? I was thinking that I could take a crack at updating the README in a PR and then you could give feedback and review it to see if it makes sense and is clearer?', '@kohr-h Thanks a lot for your contribution to MXNet Clojure package. Really appreciated!\r\nApart from that, I would like to invite you to join our discussion. We have a small group of people working on Scala and Clojure there on Slack, please follow the step here: https://mxnet.incubator.apache.org/community/mxnet_channels.html\r\n\r\nI would like to introduce you the basic build procedure for MXNet Clojure package (based on my understanding) @gigasquid please correct me if there is something wrong\r\n\r\n1. MXNet backend build from source\r\n2. Make Scala package from source and install it in local system\r\n3. Make Clojure package from source based on the Scala package\r\n\r\n@mxnet-label-bot please add [clojure, scala, doc]', 'If you do get on the apache slack - we hang out in #mxnet and #mxnet-scala :)', ""> Would you be interested in collaborating on this with me to make it better?\r\n\r\nYeah sure, I'd be more than happy to contribute.\r\n\r\n\r\n\r\n> I was thinking that I could take a crack at updating the README in a PR and then you could give feedback and review it to see if it makes sense and is clearer?\r\n\r\nThat works for me. Probably it's the most efficient way to make quick improvements. But I certainly didn't intend to dump all the work on you @gigasquid 😉 \r\n\r\n\r\n\r\n> If you do get on the apache slack - we hang out in #mxnet and #mxnet-scala :)\r\n\r\nI'll tune in sometime tonight -- which will be afternoon for you I guess? I'm in the Amsterdam time zone."", 'Thanks @lanking520 for the explanation!', ""Great @kohr-h - I have some time for this carved out on Friday so I'll ping you then"", ""@kohr-h I have a first draft of it. Please feel free to provide feedback and/or PR's on my gigasquid fork"", ""Great, @gigasquid. I had a pretty busy weekend, but I'll have a look at the new version tonight."", 'I think this issue can be closed now that the PR was merged - Thanks @kohr-h ']",[],[],0,0
143,incubator-mxnet,7110,closed,[gluon] Using mxnet evaluation metrics in gluon,"I was wondering if it was already easy to use mxnet.metric as the loss function in place of defining my own or using the gluon loss. For instance, I would prefer to use the mx.metric perplexity. 

Currently, I am defining my own loss function which calls the perplexity class, but this seems like a feature that would be good to have in gluon.",,"['metric is in principle separate from loss. You can use all kinds of metrics to measure classification accuracy and you can use all kinds of loss to optimize classifier. They are not necessarily connected.', 'yup got it.\r\nThanks']",[],[],0,0
144,incubator-mxnet,9068,closed,How to use sym.contrib.ctc_loss instead of baidu WARPCTC,"win10, mxnet 0.12,python 2.7
For the official example WARPCTC, I am trying to use sym.contrib.ctc_loss instead of baidu WARPCTC, as I am with windows. So I modified . 
 
Noitice that  is what I modified. Then running ,  I get error said: 

I wonder how to fix it.",,"['label_lengths should be a vector of lengths for each of the samples.', ""@dbsxdbsx what's the status of this issue?"", 'Suggested Labels : ""python"", ""Windows"", ""HowTo""', 'Closing due to inactivity. @dbsxdbsx - Please reopen if issue still persist.']","['\r\ndef lstm_unroll(num_lstm_layer, seq_len,\r\n                num_hidden, num_label):\r\n    param_cells = []\r\n    last_states = []\r\n    for i in range(num_lstm_layer):\r\n        param_cells.append(LSTMParam(i2h_weight=mx.sym.Variable(""l%d_i2h_weight"" % i),\r\n                                     i2h_bias=mx.sym.Variable(""l%d_i2h_bias"" % i),\r\n                                     h2h_weight=mx.sym.Variable(""l%d_h2h_weight"" % i),\r\n                                     h2h_bias=mx.sym.Variable(""l%d_h2h_bias"" % i)))\r\n        state = LSTMState(c=mx.sym.Variable(""l%d_init_c"" % i),\r\n                          h=mx.sym.Variable(""l%d_init_h"" % i))\r\n        last_states.append(state)\r\n    assert(len(last_states) == num_lstm_layer)\r\n\r\n    # embeding layer\r\n    data = mx.sym.Variable(\'data\')\r\n    label = mx.sym.Variable(\'label\')\r\n    wordvec = mx.sym.SliceChannel(data=data, num_outputs=seq_len, squeeze_axis=1)\r\n\r\n    hidden_all = []\r\n    for seqidx in range(seq_len):\r\n        hidden = wordvec[seqidx]\r\n        for i in range(num_lstm_layer):\r\n            next_state = lstm(num_hidden, indata=hidden,\r\n                              prev_state=last_states[i],\r\n                              param=param_cells[i],\r\n                              seqidx=seqidx, layeridx=i)\r\n            hidden = next_state.h\r\n            last_states[i] = next_state\r\n        hidden_all.append(hidden)\r\n\r\n    hidden_concat = mx.sym.Concat(*hidden_all, dim=0)\r\n    pred = mx.sym.FullyConnected(data=hidden_concat, num_hidden=11)\r\n\r\n    label = mx.sym.Reshape(data=label, shape=(-1,))\r\n    label = mx.sym.Cast(data = label, dtype = \'int32\')\r\n    # sm = mx.sym.WarpCTC(data=pred, label=label, label_length = num_label, input_length = seq_len)\r\n    sm =mx.sym.contrib.ctc_loss(data=pred, label=label, label_lengths = num_label, data_lengths  = seq_len,use_data_lengths =True,use_label_lengths=True)\r\n    return sm\r\n']","['lstm.py', ' sm =mx.sym.contrib.ctc_loss(data=pred, label=label, label_lengths = num_label, data_lengths  = seq_len,use_data_lengths =True,use_label_lengths=True)', 'toy_ctc.py', 'AssertionError: Argument data_lengths must be Symbol instances, but got 80']",0,0
145,incubator-mxnet,7865,closed,How to load params with LoadToMap c++ api and set device contect to GPU?,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: Windows 10

Compiler: VS2015

Package used (Python/R/Scala/Julia):

MXNet version: 0.905

Or if installed from source:

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
The loaded NDArrays in the map (from LoadToMap) do not have the device context 'GPU'. 

## Minimum reproducible example
I use the following code to read params from file:
        m_params_map = NDArray::LoadToMap(fileNamePars);
	m_args_map.clear();
	m_auxs_map.clear();

	int pos = 0;
	for (auto it = m_params_map.begin(); it != m_params_map.end(); ++it)
	{
		const string key = it->first;
		NDArray val = it->second;
		if ((pos = key.find(""arg:"")) != string::npos)
			m_args_map[key.substr(4)] = val; 
		if ((pos = key.find(""aux:"")) != string::npos)
			m_auxs_map[key.substr(4)] = val;
	}
## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.
2.
3.

## What have you tried to solve it?

1.
2.
3.
",,"['Found following solution (maybe not very efficient):\r\n\r\n```\r\n   m_params_map = NDArray::LoadToMap(fileNamePars);\r\n   SplitParams();\r\n\r\n   void MxNetwork::SplitParams() \r\n   {\r\n   \tm_args_map.clear();\r\n   \tm_auxs_map.clear();\r\n   \r\n   \tint pos = 0;\r\n   \tfor (auto it = m_params_map.begin(); it != m_params_map.end(); ++it)\r\n   \t{\r\n   \t\tconst string key = it->first;\r\n   \t\tNDArray val = it->second;\r\n   \t\tShape shape = Shape(val.GetShape());\r\n   \t\tif ((pos = key.find(""arg:"")) != string::npos)\r\n   \t\t{\r\n   \t\t\tm_args_map[key.substr(4)] = NDArray(shape, Context::gpu(), false);\r\n   \t\t\tval.CopyTo(&m_args_map[key.substr(4)]);\r\n   \t\t}\r\n   \t\tif ((pos = key.find(""aux:"")) != string::npos)\r\n   \t\t{\r\n   \t\t\tm_auxs_map[key.substr(4)] = NDArray(shape, Context::gpu(), false);\r\n   \t\t\tval.CopyTo(&m_auxs_map[key.substr(4)]);\r\n   \t\t}\r\n  \t}\r\n   }\r\n```\r\nFor SimpleBind call (not documented in c++ examples):\r\n```\r\nSimpleBind(Context::gpu(), m_args_map, std::map<std::string, NDArray>(), std::map<std::string, OpReqType>(), m_auxs_map);\r\n```\r\n']",[],"['git rev-parse HEAD', 'sessionInfo()']",0,0
146,incubator-mxnet,14484,open,Odd behaviour with 'device' kvstore and CUDA illegal memory access errors,"## Description
Training the FCN model from gluon-cv over 2 GPUs I encounter different but perhaps related issues depending on which kind of kvstore I use ('local' and 'device'). (I don't think this is a gluon-cv issue.) Test script included.

## Environment info (Required)


Package used (Python/R/Scala/Julia):
Python

## Error Message:
### If kvstore is 'local':

### If kvstore is 'device':
There is no error, the process hangs when trying to push to the kvstore in . The example script below includes some debug code to narrow down where the process hangs.

Note: the specific layer it stops on varies.

## Minimum reproducible example

## Steps to reproduce
1. Run the above script, setting the kvstore type to either  or .

## What have you tried to solve it?
1. Disabling gc at beginning of epoch and re-enabling at end, seemed to work in one similar-seeming issue, but made no difference for me.

Note: I still get the same result when not using a sub-classed version of gluon.Trainer.
",Gluon KVStore Python,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Cuda, Bug', ""Thank you for submitting the issue! I'm labeling it so the MXNet community members can help resolve it.\r\n\r\n@mxnet-label-bot add [Gluon, Python, KVStore]""]","[""\r\n----------Python Info----------\r\nVersion      : 3.5.6\r\nCompiler     : GCC 7.3.0\r\nBuild        : ('default', 'Aug 26 2018 21:41:56')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 8.1.2\r\nDirectory    : /opt/conda/lib/python3.5/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.3.1\r\nDirectory    : /opt/conda/lib/python3.5/site-packages/mxnet\r\nCommit Hash   : 19c501680183237d52a862e6ae1dc4ddc296305b\r\n----------System Info----------\r\nPlatform     : Linux-4.15.0-46-generic-x86_64-with-debian-stretch-sid\r\nsystem       : Linux\r\nnode         : axl1\r\nrelease      : 4.15.0-46-generic\r\nversion      : #49~16.04.1-Ubuntu SMP Tue Feb 12 17:45:24 UTC 2019\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                4\r\nOn-line CPU(s) list:   0-3\r\nThread(s) per core:    1\r\nCore(s) per socket:    4\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             AuthenticAMD\r\nCPU family:            23\r\nModel:                 17\r\nModel name:            AMD Ryzen 3 2200G with Radeon Vega Graphics\r\nStepping:              0\r\nCPU MHz:               1458.994\r\nCPU max MHz:           3500.0000\r\nCPU min MHz:           1600.0000\r\nBogoMIPS:              6986.85\r\nVirtualization:        AMD-V\r\nHypervisor vendor:     vertical\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             64K\r\nL2 cache:              512K\r\nL3 cache:              4096K\r\nNUMA node0 CPU(s):     0-3\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx hw_pstate sme ssbd ibpb vmmcall fsgsbase bmi1 avx2 smep bmi2 rdseed adx smap clflushopt sha_ni xsaveopt xsavec xgetbv1 xsaves clzero irperf xsaveerptr arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif overflow_recov succor smca\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.1691 sec, LOAD: 0.6659 sec.\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0070 sec, LOAD: 1.3928 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0083 sec, LOAD: 0.8829 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.8895 sec, LOAD: 0.7720 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0078 sec, LOAD: 0.9719 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0093 sec, LOAD: 0.0760 sec.\r\n"", '\r\nepoch 0\r\n[01:09:18] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n-------- autograd.backward(loss)\r\n---------- trainer.step(batch_size)\r\nTraceback (most recent call last):\r\n  File ""train.py"", line 131, in <module>\r\n    predTop = predTop.reshape((-1,)).astype(\'uint8\').asnumpy()\r\n  File ""/opt/conda/lib/python3.5/site-packages/mxnet/ndarray/ndarray.py"", line 1972, in asnumpy\r\n    ctypes.c_size_t(data.size)))\r\n  File ""/opt/conda/lib/python3.5/site-packages/mxnet/base.py"", line 251, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [01:09:26] /home/travis/build/dmlc/mxnet-distro/mxnet-build/3rdparty/mshadow/mshadow/./stream_gpu-inl.h:62: Check failed: e == cudaSuccess CUDA: an illegal memory access was encountered\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x381822) [0x7fbe7f130822]\r\n[bt] (1) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x381e08) [0x7fbe7f130e08]\r\n[bt] (2) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2f3e198) [0x7fbe81ced198]\r\n[bt] (3) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2faf1ea) [0x7fbe81d5e1ea]\r\n[bt] (4) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2f15123) [0x7fbe81cc4123]\r\n[bt] (5) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2f1d334) [0x7fbe81ccc334]\r\n[bt] (6) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2f213db) [0x7fbe81cd03db]\r\n[bt] (7) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2f215fe) [0x7fbe81cd05fe]\r\n[bt] (8) /opt/conda/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2f1d9fb) [0x7fbe81ccc9fb]\r\n[bt] (9) /opt/conda/bin/../lib/libstdc++.so.6(+0xb8678) [0x7fbe6a362678]\r\n', '\r\nepoch 0\r\n[01:21:38] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n-------- autograd.backward(loss)\r\n---------- trainer.step(batch_size)\r\nkvs 2 <mxnet.kvstore.KVStore object at 0x7f1e6f85f940>\r\na\r\na2\r\nb 0 fcn0_resnetv1s_conv0_weight\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 1 fcn0_resnetv1s_syncbatchnorm0_gamma\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 2 fcn0_resnetv1s_syncbatchnorm0_beta\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 3 fcn0_resnetv1s_syncbatchnorm0_running_mean\r\nh\r\nb 4 fcn0_resnetv1s_syncbatchnorm0_running_var\r\nh\r\nb 5 fcn0_resnetv1s_conv1_weight\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 6 fcn0_resnetv1s_syncbatchnorm1_gamma\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 7 fcn0_resnetv1s_syncbatchnorm1_beta\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 8 fcn0_resnetv1s_syncbatchnorm1_running_mean\r\nh\r\nb 9 fcn0_resnetv1s_syncbatchnorm1_running_var\r\nh\r\nb 10 fcn0_resnetv1s_conv2_weight\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 11 fcn0_resnetv1s_syncbatchnorm2_gamma\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 12 fcn0_resnetv1s_syncbatchnorm2_beta\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 13 fcn0_resnetv1s_syncbatchnorm2_running_mean\r\nh\r\nb 14 fcn0_resnetv1s_syncbatchnorm2_running_var\r\nh\r\nb 15 fcn0_resnetv1s_layers1_conv0_weight\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 16 fcn0_resnetv1s_layers1_syncbatchnorm0_gamma\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 17 fcn0_resnetv1s_layers1_syncbatchnorm0_beta\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 18 fcn0_resnetv1s_layers1_syncbatchnorm0_running_mean\r\nh\r\nb 19 fcn0_resnetv1s_layers1_syncbatchnorm0_running_var\r\nh\r\nb 20 fcn0_resnetv1s_layers1_conv1_weight\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 21 fcn0_resnetv1s_layers1_syncbatchnorm1_gamma\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 22 fcn0_resnetv1s_layers1_syncbatchnorm1_beta\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 23 fcn0_resnetv1s_layers1_syncbatchnorm1_running_mean\r\nh\r\nb 24 fcn0_resnetv1s_layers1_syncbatchnorm1_running_var\r\nh\r\nb 25 fcn0_resnetv1s_layers1_conv2_weight\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 26 fcn0_resnetv1s_layers1_syncbatchnorm2_gamma\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 27 fcn0_resnetv1s_layers1_syncbatchnorm2_beta\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 28 fcn0_resnetv1s_layers1_syncbatchnorm2_running_mean\r\nh\r\nb 29 fcn0_resnetv1s_layers1_syncbatchnorm2_running_var\r\nh\r\nb 30 fcn0_resnetv1s_down1_conv0_weight\r\nc\r\nc2\r\nd\r\ng\r\nh\r\nb 31 fcn0_resnetv1s_down1_syncbatchnorm0_gamma\r\nc\r\nc2\r\n[...hangs here. The python process then refuses to exit regardless of which kill signal I send to it. The docker container also refuses to stop. I have to restart the machine at this point.]\r\n', '\r\nimport sys, math\r\nimport numpy as np\r\nimport mxnet as mx\r\nfrom mxnet import gluon, autograd, metric\r\nimport gluoncv\r\nfrom gluoncv.utils.parallel import DataParallelModel, DataParallelCriterion\r\n\r\nfrom gluoncv.model_zoo import get_model\r\nfrom gluoncv.loss import *\r\nfrom gluoncv.model_zoo.segbase import *\r\nfrom mxnet.gluon.data import dataset\r\nfrom gluoncv.utils import LRScheduler\r\n  \r\n\r\nclass DummyDataSet(dataset.Dataset):\r\n    def __init__(self, crop_size):\r\n      self.data = []\r\n      for i in range(5):\r\n          d = mx.ndarray.ones((3, crop_size, crop_size))\r\n          l = mx.ndarray.ones((crop_size, crop_size))\r\n          r = (d, l)\r\n          self.data.append(r)\r\n        \r\n    @property\r\n    def num_class(self):\r\n      return 5\r\n    \r\n    def __len__(self):\r\n        return len(self.data)\r\n    \r\n    def __getitem__(self, index):\r\n      return self.data[index]\r\n\r\n  \r\n  \r\nclass Trainer(gluon.Trainer):\r\n    def step(self, batch_size, ignore_stale_grad=False):\r\n        if not self._kv_initialized:\r\n            print(""kvs %d %s"" % (len(self._contexts), str(self._kvstore_params[\'kvstore\'])))\r\n            self._init_kvstore()\r\n        if self._params_to_init:\r\n            self._init_params()\r\n        self._optimizer.rescale_grad = self._scale / batch_size\r\n        self._allreduce_grads()\r\n        self._update(ignore_stale_grad)\r\n        \r\n     \r\n    def _allreduce_grads(self):\r\n        print(""a"")\r\n        if self._kvstore:\r\n            print(""a2"")\r\n            for i, param in enumerate(self._params):\r\n                print(""b %d %s"" % (i, param.name))\r\n                if param.grad_req != \'null\':\r\n                    print(""c"")\r\n                    \r\n                    plg = param.list_grad()\r\n                    \r\n                    print(""c2"")\r\n                    \r\n                    self._kvstore.push(i, plg, priority=-i)\r\n                    \r\n                    print(""d"")\r\n                    if not self._update_on_kvstore:\r\n                        print(""e"")\r\n                        self._kvstore.pull(i, param.list_grad(), priority=-i, ignore_sparse=self._distributed)\r\n                        print(""f"")\r\n                    print(""g"")\r\n                print(""h"")\r\n            print(""i"")\r\n        print(""j"")\r\n\r\n\r\n\r\nif __name__ == ""__main__"":\r\n    input_size = 480\r\n    \r\n    dataset_train = DummyDataSet(input_size)\r\n    data_loader = gluon.data.DataLoader(dataset_train, 2, shuffle=True, last_batch=\'rollover\', num_workers=4)\r\n    \r\n    net = get_segmentation_model(model=\'fcn\', dataset=\'pascal_aug\',\r\n                                backbone=\'resnet50\', norm_layer=mx.gluon.contrib.nn.basic_layers.SyncBatchNorm,\r\n                                norm_kwargs={\'num_devices\': 2}, aux=True,\r\n                                crop_size=input_size)\r\n    net.cast(\'float32\')\r\n    \r\n    exec_contexts = [ mx.gpu(0), mx.gpu(1) ]\r\n    \r\n    net = DataParallelModel(net, exec_contexts)\r\n\r\n    criterion = MixSoftmaxCrossEntropyLoss(True, aux_weight=0.5)\r\n    criterion = DataParallelCriterion(criterion, exec_contexts, True)\r\n\r\n    lr_scheduler = LRScheduler(mode=\'poly\', baselr=0.001,\r\n                            niters=len(dataset_train), \r\n                            nepochs=30)\r\n    optimizer_params = {\'lr_scheduler\': lr_scheduler,\r\n                        \'wd\':0.0001,\r\n                        \'momentum\': 0.9}\r\n    \r\n    kv = mx.kv.create(\'device\')\r\n    \r\n    trainer = Trainer(net.module.collect_params(), \'sgd\', optimizer_params, kvstore = kv)\r\n    \r\n    batch_size = 4\r\n    \r\n    for epoch in range(0, 30):\r\n        print (""epoch"", epoch)\r\n        for i, (data, label) in enumerate(data_loader):\r\n            lr_scheduler.update(i, epoch)\r\n            \r\n            with autograd.record(True):\r\n                pred = net(data)\r\n                #pred = upsize_parallel_output(pred)\r\n                loss = criterion(pred, label)\r\n                mx.nd.waitall()\r\n                print (""-------- autograd.backward(loss)"")\r\n                autograd.backward(loss)\r\n            print (""---------- trainer.step(batch_size)"")\r\n            trainer.step(batch_size)\r\n            \r\n            # DataParallelModel output is a tuple of tuples of NDArrays.\r\n            pred = [ p[0] for p in pred ]\r\n            pred = mx.ndarray.concat(*pred)\r\n            predTop = mx.nd.argmax(pred, 1)\r\n            \r\n            predNP = predTop.reshape((-1,)).astype(\'uint8\').asnumpy()\r\n\r\n']","['gluon.Trainer._allreduce_grads()', 'local', 'device']",0,0
147,incubator-mxnet,11120,closed,Address already in use during tutorial test,"http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-10656/7/pipeline/



Possibly related to hardcoding ports.",Disabled test Flaky Test,"['@ThomasDelteil ', ""I tracked this issue for a while, still not sure of why it is happening. My first guess was that the previous notebook run didn't clear the socket in time for the next run. \r\n\r\nI added a delay between each notebook run which should have been plenty of time for socket to be released.\r\n\r\nI'll do some more digging.\r\n\r\n@marcoabreu, how many containers are running per instance concurrently? only one right?"", 'They are running concurrently. We got up to 4 containers in parallel. Why should it matter whether a socket is released or not? First of all, networking is virtualized per container, so there should be no problem on that side. Second, we should not require a certain port but just use a random free one.', ""The ports are already random, but I don't know whether it checks for availability. I think the issue could be that the ports are not released and rarely but sometimes it happens to try to reuse the same random port. \r\n\r\nI have also seen a 'linger=1000', which could mean that the port might be still taken 1s after closing, so ugprading the delay between notebook to 1.1 from 0.5 could also solve the issue.\r\n\r\nI'll see if I can make the port deterministically different."", ""I'm not a fan of the delay in between notebooks anyways because it masks a problem. I'd propose that we now remove the delay entirely and track down all the issues coming from that. Otherwise, we're flaky and depend on timing."", ""the `linger` variable is hard coded in the `kernelapp.py`, if we don't want to use this technique then we need to assign deterministic ports that are different from each other and update the config file of the python notebook between runs."", ""I think that's what we should do. In general, this is required to prepare the path for parallel execution."", 'HI Marco,\r\n    For reproducing this issue I have to build docs within MXNet since it requires gan.ipynb file. Can you share the setup to reproduce it ', '@ThomasDelteil would you mind assisting here?', 'assigned to @reminisce. @access2rohit is working on this.', ""To reproduce the setup I suggest looking at the jenkins function for\ntutorial tests.\n\nI had put a fix in my last PR before removing them from CI, the issue might\nbe gone already. Can someone start a few hundred runs of the tutorial tests\nand see if it still happen? Note that they take ~25min so that could take a\nfew days.\n\nActually commenting out most tests except three very fast ones might be a\nbetter idea since it isn't related to a specific test, and as one simple\ntest runs in 2-3s with the jupyter kernel overhead. To know which one is\nfast check the tutorials, some do not much like the NDArray ones.\n\nMy current best guess is that the issue is related to the fact that the\nports used by jupiter internal mechanism are chosen randomly and that there\nis linger=1000 hard-coded in the jupiter code somewhere that keep it being\nused for 1sec. For every test there is ~1/10000 chance that the same port\nwill be reused (3 ports are picked between 1-100000), which makes it 1/300\nbecause we have 30 tests and 1/150 because we run on python2 and python3.\nThat seems roughly consistent with the number of reports we've had, about\nonce every 150 CI runs.\n\nThere is no easy way to set the ports to fixed deterministic value. My\nlatest fix added a non-ideal 1.1 sleep between tests. Let's see if that\nfixed it. The above explanation might be bogus too.\n\nI'm on my phone in a plane and can assist more from Friday onwards.\n\nThanks for looking into it @reminisce <https://github.com/reminisce> and\n@access2rohit <https://github.com/access2rohit>!\n\n\nOn Wed, Jun 27, 2018, 20:45 Anirudh Subramanian <notifications@github.com>\nwrote:\n\n> assigned to @reminisce <https://github.com/reminisce> @access2rohit\n> <https://github.com/access2rohit> is working on this.\n>\n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/apache/incubator-mxnet/issues/11120#issuecomment-400864919>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ADi001F-ydKxRBX2r1PYR-DJXVfJv14lks5uBBkDgaJpZM4UWPoF>\n> .\n>\n"", ""Just to be on the safe side: please try what Thomas suggested only locally\nand don't submit these jobs to CI. This test suite causes resource\nexhaustion on our CI and running so many in parallel would basically knock\noff our instances.\n\nThomas Delteil <notifications@github.com> schrieb am Do., 28. Juni 2018,\n11:29:\n\n> To reproduce the setup I suggest looking at the jenkins function for\n> tutorial tests.\n>\n> I had put a fix in my last PR before removing them from CI, the issue might\n> be gone already. Can someone start a few hundred runs of the tutorial tests\n> and see if it still happen? Note that they take ~25min so that could take a\n> few days.\n>\n> Actually commenting out most tests except three very fast ones might be a\n> better idea since it isn't related to a specific test, and as one simple\n> test runs in 2-3s with the jupyter kernel overhead. To know which one is\n> fast check the tutorials, some do not much like the NDArray ones.\n>\n> My current best guess is that the issue is related to the fact that the\n> ports used by jupiter internal mechanism are chosen randomly and that there\n> is linger=1000 hard-coded in the jupiter code somewhere that keep it being\n> used for 1sec. For every test there is ~1/10000 chance that the same port\n> will be reused (3 ports are picked between 1-100000), which makes it 1/300\n> because we have 30 tests and 1/150 because we run on python2 and python3.\n> That seems roughly consistent with the number of reports we've had, about\n> once every 150 CI runs.\n>\n> There is no easy way to set the ports to fixed deterministic value. My\n> latest fix added a non-ideal 1.1 sleep between tests. Let's see if that\n> fixed it. The above explanation might be bogus too.\n>\n> I'm on my phone in a plane and can assist more from Friday onwards.\n>\n> Thanks for looking into it @reminisce <https://github.com/reminisce> and\n> @access2rohit <https://github.com/access2rohit>!\n>\n>\n> On Wed, Jun 27, 2018, 20:45 Anirudh Subramanian <notifications@github.com>\n> wrote:\n>\n> > assigned to @reminisce <https://github.com/reminisce> @access2rohit\n> > <https://github.com/access2rohit> is working on this.\n> >\n> > —\n> > You are receiving this because you were mentioned.\n> > Reply to this email directly, view it on GitHub\n> > <\n> https://github.com/apache/incubator-mxnet/issues/11120#issuecomment-400864919\n> >,\n> > or mute the thread\n> > <\n> https://github.com/notifications/unsubscribe-auth/ADi001F-ydKxRBX2r1PYR-DJXVfJv14lks5uBBkDgaJpZM4UWPoF\n> >\n> > .\n> >\n>\n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/apache/incubator-mxnet/issues/11120#issuecomment-400972980>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ARxB60DSOdndKcaobWgfxBGzIAMRSv4Dks5uBKH-gaJpZM4UWPoF>\n> .\n>\n"", '@ThomasDelteil : Can you specify which ""jenkins functions for tutorial tests"" are you referring to in order to reproduce the tests ? ', 'They are defined here: https://github.com/apache/incubator-mxnet/blob/master/ci/docker/runtime_functions.sh#L580\r\n\r\nDisable was in https://github.com/apache/incubator-mxnet/pull/11170', ""@marcoabreu the suite was run 300 times and the address already in use wasn't triggered. Can we close this issue?"", '@marcoabreu The address in use issue not being triggered by running the suite couple hundred times. Should this issue be closed ? If not then can you shared the exact setup to reproduce it. I worked with @ThomasDelteil to get these tests to run and since they take time to complete a single run I ran it 300 times in order to reproduce it but it still succeeded.', ""Did you remove the thread.sleep you introduced to work around this error?\r\n\r\nThe environment is the regular CI pipeline. \r\n\r\nI'll leave it up to you, Thomas."", ""The sleep is still there and I think it is necessary. It doesn't bring much extra delay. 30s on a 30min test run, that 1.6% extra delay, which is acceptable.\r\n\r\nI would close it, thanks.\r\n"", 'The question is whether we are masking a problem with that sleep. It feels like fixing a race condition by adding a sleep.', 'there is a hardcoded 1000ms linger on the socket in the base code of Jupyter, which I believe is the root cause of the problem. \r\n\r\nWe can fork jupyter or monkey patch it but I think the better trade-off with performance and maintainability is the sleep.', 'Okay, that makes sense. Please note that even with the increased delay we sometimes experienced this error. \r\n\r\nFor reproducing, please run multiple instances of the tests in parallel to see if the error occurs.\r\n\r\nWe can easily increase the delay to more than a second if that fixes the problem.', ""To clarify: I had first put a 0.5s delay as a wild guess when we still had the error, I only then found out about the 1000ms socket linger, increased delay to 1.1s but the test was disabled already at that point. access2rohit tested that version and didn't reproduce the bug. "", ""Oh, I was under the impression that we disabled the test after adding the 1.1s delay because it was still failing and we didn't know why because it should have worked due to the 1s timeout."", 'See https://github.com/apache/incubator-mxnet/pull/11170/files', 'Great, thanks a lot for the link Thomas!\r\n\r\nCan we bring the tutorial tests into nightly and then close this issue? Currently, this issue serves as master ticket to mark the tests as disabled', ""Sure, it's in the works by @vishaalkapoor "", 'Happened again: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/NightlyTests_onBinaries/detail/NightlyTests_onBinaries/102/pipeline\r\n\r\n```\r\n+ nosetests-3.4 --with-xunit --xunit-file nosetests_straight_dope_python3_single_gpu.xml test_notebooks_single_gpu.py --nologcapture\r\n\r\n.......[01:16:58] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n\r\n.....[01:28:00] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n\r\n[01:28:00] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n\r\n.Traceback (most recent call last):\r\n\r\n  File ""/usr/lib/python3.5/runpy.py"", line 184, in _run_module_as_main\r\n\r\n    ""__main__"", mod_spec)\r\n\r\n  File ""/usr/lib/python3.5/runpy.py"", line 85, in _run_code\r\n\r\n    exec(code, run_globals)\r\n\r\n  File ""/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py"", line 16, in <module>\r\n\r\n    app.launch_new_instance()\r\n\r\n  File ""/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py"", line 657, in launch_instance\r\n\r\n    app.initialize(argv)\r\n\r\n  File ""<decorator-gen-123>"", line 2, in initialize\r\n\r\n  File ""/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py"", line 87, in catch_config_error\r\n\r\n    return method(app, *args, **kwargs)\r\n\r\n  File ""/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py"", line 456, in initialize\r\n\r\n    self.init_sockets()\r\n\r\n  File ""/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py"", line 238, in init_sockets\r\n\r\n    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\r\n\r\n  File ""/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py"", line 180, in _bind_socket\r\n\r\n    s.bind(""tcp://%s:%i"" % (self.ip, port))\r\n\r\n  File ""zmq/backend/cython/socket.pyx"", line 549, in zmq.backend.cython.socket.Socket.bind\r\n\r\n  File ""zmq/backend/cython/checkrc.pxd"", line 25, in zmq.backend.cython.checkrc._check_rc\r\n\r\nzmq.error.ZMQError: Address already in use\r\n\r\nERROR:root:Kernel died before replying to kernel_info\r\n\r\nF...........................[01:48:50] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n\r\n.\r\n\r\n======================================================================\r\n\r\nFAIL: test_generative_adversarial_networks (test_notebooks_single_gpu.StraightDopeSingleGpuTests)\r\n\r\n----------------------------------------------------------------------\r\n\r\nTraceback (most recent call last):\r\n\r\n  File ""/work/mxnet/tests/nightly/straight_dope/test_notebooks_single_gpu.py"", line 274, in test_generative_adversarial_networks\r\n\r\n    assert _test_notebook(\'chapter14_generative-adversarial-networks/conditional\')\r\n\r\nAssertionError\r\n\r\n\r\n\r\n----------------------------------------------------------------------\r\n\r\nRan 42 tests in 2291.515s\r\n\r\n\r\n\r\nFAILED (failures=1)\r\n\r\nbuild.py: 2018-08-03 01:49:31,003 Running of command in container failed (1):\r\n\r\nnvidia-docker\\\r\n\r\n\trun\\\r\n\r\n\t--rm\\\r\n\r\n\t-t\\\r\n\r\n\t--shm-size=500m\\\r\n\r\n\t-v\\\r\n\r\n\t/home/jenkins_slave/workspace/straight_dope-single_gpu:/work/mxnet\\\r\n\r\n\t-v\\\r\n\r\n\t/home/jenkins_slave/workspace/straight_dope-single_gpu/build:/work/build\\\r\n\r\n\t-v\\\r\n\r\n\t/tmp/ci_ccache:/work/ccache\\\r\n\r\n\t-u\\\r\n\r\n\t1001:1001\\\r\n\r\n\t-e\\\r\n\r\n\tCCACHE_MAXSIZE=500G\\\r\n\r\n\t-e\\\r\n\r\n\tCCACHE_TEMPDIR=/tmp/ccache\\\r\n\r\n\t-e\\\r\n\r\n\tCCACHE_DIR=/work/ccache\\\r\n\r\n\t-e\\\r\n\r\n\tCCACHE_LOGFILE=/tmp/ccache.log\\\r\n\r\n\tmxnetci/build.ubuntu_nightly_gpu\\\r\n\r\n\t/work/runtime_functions.sh\\\r\n\r\n\tnightly_straight_dope_python3_single_gpu_tests\r\n\r\n\r\n\r\nbuild.py: 2018-08-03 01:49:31,003 You can get into the container by adding the -i option\r\n\r\nTraceback (most recent call last):\r\n\r\n  File ""ci/build.py"", line 408, in <module>\r\n\r\n    sys.exit(main())\r\n\r\n  File ""ci/build.py"", line 337, in main\r\n\r\n    local_ccache_dir=args.ccache_dir, interactive=args.interactive)\r\n\r\n  File ""ci/build.py"", line 224, in container_run\r\n\r\n    raise subprocess.CalledProcessError(ret, cmd)\r\n\r\nsubprocess.CalledProcessError: Command \'nvidia-docker\\\r\n\r\n\trun\\\r\n\r\n\t--rm\\\r\n\r\n\t-t\\\r\n\r\n\t--shm-size=500m\\\r\n\r\n\t-v\\\r\n\r\n\t/home/jenkins_slave/workspace/straight_dope-single_gpu:/work/mxnet\\\r\n\r\n\t-v\\\r\n\r\n\t/home/jenkins_slave/workspace/straight_dope-single_gpu/build:/work/build\\\r\n\r\n\t-v\\\r\n\r\n\t/tmp/ci_ccache:/work/ccache\\\r\n\r\n\t-u\\\r\n\r\n\t1001:1001\\\r\n\r\n\t-e\\\r\n\r\n\tCCACHE_MAXSIZE=500G\\\r\n\r\n\t-e\\\r\n\r\n\tCCACHE_TEMPDIR=/tmp/ccache\\\r\n\r\n\t-e\\\r\n\r\n\tCCACHE_DIR=/work/ccache\\\r\n\r\n\t-e\\\r\n\r\n\tCCACHE_LOGFILE=/tmp/ccache.log\\\r\n\r\n\tmxnetci/build.ubuntu_nightly_gpu\\\r\n\r\n\t/work/runtime_functions.sh\\\r\n\r\n\tnightly_straight_dope_python3_single_gpu_tests\' returned non-zero exit status 1\r\n\r\nscript returned exit code 1\r\n```', ""Looks like the sleep(1.1) got removed as far as I can see.\r\nedit: it's not, investigating with Vishaal. It seems like we might have misdiagnosed this error, it happens consistently when a notebook crashes. \r\n\r\nOn Fri, Aug 3, 2018, 03:44 Marco de Abreu <notifications@github.com> wrote:\r\n\r\n> Happened again:\r\n> http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/NightlyTests_onBinaries/detail/NightlyTests_onBinaries/102/pipeline\r\n>\r\n> —\r\n> You are receiving this because you were mentioned.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/apache/incubator-mxnet/issues/11120#issuecomment-410216354>,\r\n> or mute the thread\r\n> <https://github.com/notifications/unsubscribe-auth/ADi000XEYmMEPAqZvOtRcgpBiLfzZgI_ks5uNCmNgaJpZM4UWPoF>\r\n> .\r\n>\r\n"", 'Notes:\r\n- The address already in use issue is resolved by this https://github.com/apache/incubator-mxnet/pull/12068 merged Aug 10.\r\n- The tutorial tests will be re-enabled in #13099 in review.\r\nOnce #13099 is merged this issue can be closed.', '#13099 is merged, please close. \r\nWhy did we not use mechanism describe in https://blog.github.com/2013-05-14-closing-issues-via-pull-requests/ i.e. add fixes #13099  in PR? Are people not aware of it?']","['\r\n+ nosetests-3.4 test_tutorials.py --nologcapture\r\n\r\n....[19:25:36] src/io/iter_image_recordio_2.cc:170: ImageRecordIOParser2: ./data/caltech.rec, use 4 threads for decoding..\r\n\r\n.......[19:27:51] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n\r\n.....[19:28:58] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n\r\n..[19:32:06] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n\r\n[19:37:22] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n\r\n....[19:39:25] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\n\r\n.[19:39:51] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\r\n\r\n[19:39:51] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\r\n\r\n.....[19:40:24] src/operator/././../common/utils.h:416: Optimizer with lazy_update = True detected. Be aware that lazy update with row_sparse gradient is different from standard update, and may lead to different empirical results. See https://mxnet.incubator.apache.org/api/python/optimization/optimization.html for more details.\r\n\r\n..[19:40:43] src/operator/././../common/utils.h:416: Optimizer with lazy_update = True detected. Be aware that lazy update with row_sparse gradient is different from standard update, and may lead to different empirical results. See https://mxnet.incubator.apache.org/api/python/optimization/optimization.html for more details.\r\n\r\n..Traceback (most recent call last):\r\n\r\n  File ""/usr/lib/python3.5/runpy.py"", line 184, in _run_module_as_main\r\n\r\n    ""__main__"", mod_spec)\r\n\r\n  File ""/usr/lib/python3.5/runpy.py"", line 85, in _run_code\r\n\r\n    exec(code, run_globals)\r\n\r\n  File ""/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py"", line 16, in <module>\r\n\r\n    app.launch_new_instance()\r\n\r\n  File ""/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py"", line 657, in launch_instance\r\n\r\n    app.initialize(argv)\r\n\r\n  File ""<decorator-gen-123>"", line 2, in initialize\r\n\r\n  File ""/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py"", line 87, in catch_config_error\r\n\r\n    return method(app, *args, **kwargs)\r\n\r\n  File ""/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py"", line 456, in initialize\r\n\r\n    self.init_sockets()\r\n\r\n  File ""/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py"", line 248, in init_sockets\r\n\r\n    self.control_port = self._bind_socket(self.control_socket, self.control_port)\r\n\r\n  File ""/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py"", line 180, in _bind_socket\r\n\r\n    s.bind(""tcp://%s:%i"" % (self.ip, port))\r\n\r\n  File ""zmq/backend/cython/socket.pyx"", line 547, in zmq.backend.cython.socket.Socket.bind\r\n\r\n  File ""zmq/backend/cython/checkrc.pxd"", line 25, in zmq.backend.cython.checkrc._check_rc\r\n\r\nzmq.error.ZMQError: Address already in use\r\n\r\nF..\r\n\r\n======================================================================\r\n\r\nFAIL: test_tutorials.test_unsupervised_learning_gan\r\n\r\n----------------------------------------------------------------------\r\n\r\nTraceback (most recent call last):\r\n\r\n  File ""/usr/local/lib/python3.5/dist-packages/nose/case.py"", line 198, in runTest\r\n\r\n    self.test(*self.arg)\r\n\r\n  File ""/work/mxnet/tests/tutorials/test_tutorials.py"", line 203, in test_unsupervised_learning_gan\r\n\r\n    assert _test_tutorial_nb(\'unsupervised_learning/gan\')\r\n\r\nAssertionError: \r\n\r\n-------------------- >> begin captured stdout << ---------------------\r\n\r\nKernel died before replying to kernel_info\r\n\r\n\r\n\r\n--------------------- >> end captured stdout << ----------------------\r\n\r\n\r\n\r\n----------------------------------------------------------------------\r\n\r\nRan 35 tests in 1024.216s\r\n\r\n\r\n\r\nFAILED (failures=1)\r\n\r\nbuild.py: 2018-05-31 19:41:38,780 Running of command in container failed (1): nvidia-docker run --rm -t --shm-size=3g -v /home/jenkins_slave/workspace/it-tutorials-py2:/work/mxnet -v /home/jenkins_slave/workspace/it-tutorials-py2/build:/work/build -u 1001:1001 mxnet/build.ubuntu_gpu /work/runtime_functions.sh tutorialtest_ubuntu_python2_gpu\r\n\r\nbuild.py: 2018-05-31 19:41:38,780 You can try to get into the container by using the following command: nvidia-docker run --rm -t --shm-size=3g -v /home/jenkins_slave/workspace/it-tutorials-py2:/work/mxnet -v /home/jenkins_slave/workspace/it-tutorials-py2/build:/work/build -u 1001:1001 -ti --entrypoint /bin/bash mxnet/build.ubuntu_gpu /work/runtime_functions.sh tutorialtest_ubuntu_python2_gpu\r\n\r\ninto container: False\r\n\r\nTraceback (most recent call last):\r\n\r\n  File ""ci/build.py"", line 307, in <module>\r\n\r\n    sys.exit(main())\r\n\r\n  File ""ci/build.py"", line 243, in main\r\n\r\n    container_run(platform, docker_binary, shared_memory_size, command)\r\n\r\n  File ""ci/build.py"", line 154, in container_run\r\n\r\n    raise subprocess.CalledProcessError(ret, cmd)\r\n\r\nsubprocess.CalledProcessError: Command \'nvidia-docker run --rm -t --shm-size=3g -v /home/jenkins_slave/workspace/it-tutorials-py2:/work/mxnet -v /home/jenkins_slave/workspace/it-tutorials-py2/build:/work/build -u 1001:1001 mxnet/build.ubuntu_gpu /work/runtime_functions.sh tutorialtest_ubuntu_python2_gpu\' returned non-zero exit status 1\r\n\r\nscript returned exit code 1\r\n']",[],0,0
148,incubator-mxnet,4841,closed,No module named bbox when running faster-cnn exampl,"trying to reproduce the faster-rcnn tutorial as in http://mxnet.io/tutorials/computer_vision/detection.html
running 
python train_alternate.py --gpus 0

yields this error:
Traceback (most recent call last):
  File ""train_alternate.py"", line 7, in <module>
    from rcnn.tools.train_rpn import train_rpn
  File ""/mnt/gelu/mxnet/example/rcnn/rcnn/tools/train_rpn.py"", line 7, in <module>
    from ..symbol import *
  File ""/mnt/gelu/mxnet/example/rcnn/rcnn/symbol/__init__.py"", line 1, in <module>
    from symbol_vgg import *
  File ""/mnt/gelu/mxnet/example/rcnn/rcnn/symbol/symbol_vgg.py"", line 2, in <module>
    import proposal
  File ""/mnt/gelu/mxnet/example/rcnn/rcnn/symbol/proposal.py"", line 11, in <module>
    from rcnn.processing.bbox_transform import bbox_pred, clip_boxes
  File ""/mnt/gelu/mxnet/example/rcnn/rcnn/processing/bbox_transform.py"", line 2, in <module>
    from ..cython.bbox import bbox_overlaps_cython
ImportError: No module named bbox

I've tried searching on bbox module but could not find it anywhere. My mxnet is compiled in ubuntu 16 with cuda and cdnn support",,"['Please follow the readme you need to compile extra operators', 'Thanks for the reply, ', 'Emm...Are you ok?\r\nI had the same problem.Could you please tell me how to deal with the things?\r\n\r\nLook this step:\r\n\r\nbash script/vgg_voc07.sh 0\r\n\r\nreply:\r\nTraceback (most recent call last):\r\n  File ""train_end2end.py"", line 8, in <module>\r\n    from rcnn.symbol import *\r\n  File ""F:\\mxnet\\example\\rcnn\\rcnn\\symbol\\__init__.py"", line 1, in <module>\r\n    from symbol_vgg import *\r\n  File ""F:\\mxnet\\example\\rcnn\\rcnn\\symbol\\symbol_vgg.py"", line 2, in <module>\r\n    import proposal\r\n  File ""F:\\mxnet\\example\\rcnn\\rcnn\\symbol\\proposal.py"", line 11, in <module>\r\n    from rcnn.processing.bbox_transform import bbox_pred, clip_boxes\r\n  File ""F:\\mxnet\\example\\rcnn\\rcnn\\processing\\bbox_transform.py"", line 2, in <module>\r\n    from ..cython.bbox import bbox_overlaps_cython\r\nImportError: No module named bbox\r\nTraceback (most recent call last):\r\n  File ""test.py"", line 4, in <module>\r\n    from rcnn.tools.test_rcnn import test_rcnn\r\n  File ""F:\\mxnet\\example\\rcnn\\rcnn\\tools\\test_rcnn.py"", line 6, in <module>\r\n    from ..symbol import *\r\n  File ""F:\\mxnet\\example\\rcnn\\rcnn\\symbol\\__init__.py"", line 1, in <module>\r\n    from symbol_vgg import *\r\n  File ""F:\\mxnet\\example\\rcnn\\rcnn\\symbol\\symbol_vgg.py"", line 2, in <module>\r\n    import proposal\r\n  File ""F:\\mxnet\\example\\rcnn\\rcnn\\symbol\\proposal.py"", line 11, in <module>\r\n    from rcnn.processing.bbox_transform import bbox_pred, clip_boxes\r\n  File ""F:\\mxnet\\example\\rcnn\\rcnn\\processing\\bbox_transform.py"", line 2, in <module>\r\n    from ..cython.bbox import bbox_overlaps_cython\r\nImportError: No module named bbox\r\n\r\nWhy closed the issue? @Gelu74 @piiswrong ', ""That's all right.\r\nI found ..cython.bbox.pyx and setup.py\r\nthen I open cmd and input `python setup.py install`\r\nget another error:\r\nEnvironmentError: The CUDA nvcc path could not be located in C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\bin\\nvcc\r\nbut I really don't have folder-nvcc,I have nvcc.exe and nvcc.profile\r\n\r\nwho knows where is the folder?"", 'I have met the same error with you.Have you solved this problem? @lightningsoon ', 'use linux to slove\n\n\n发自网易邮箱大师\nOn 03/02/2017 15:20, niluanwudidadi wrote:\n\nI have met the same error with you.Have you solved this problem? @lightningsoon\n\n—\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.']",[],[],0,0
149,incubator-mxnet,7491,closed,GPUDeviceStorage is not used? why?,"I found that GPUDeviceStorage is not used, however CPUDeviceStorage is used, why is that?",,"['Are you sure you compiled with CUDA support enabled? What is it that you are trying to do?', ""I didn't compile with CUDA, I'm reading the code, I see that when CUDA is used, it actually use GPUPooledStorageManager to do the allocation, on the other hand, CPUDeviceStorage is used no where.\r\n\r\nI'm just curious why CPUDeviceStorage is there, and not in use.\r\n\r\nI'm on the master branch."", 'Oh, ok. This is because CUDA allocations and deallocations are much more expensive (since they deal with pinned memory), especially with multiple GPUs per node. They also introduce stalls in the GPU pipeline, which is not something we want for maximum performance. That is why MXNet uses caching allocator (GPUPooledStorageManager) instead of a naive one.', '@szha please close']",[],[],0,0
150,incubator-mxnet,3517,closed,Can I train the faster_RCNN with multi-GPU with multi-machine ,"I found faster RCNN is supported in mxnet.  Can I train it on multi-GPU with multi-machine ?
",,"['yes, you can. i used it training with multi-gpus, but not test on multi-machine.\n', ""I just use python train_end2end.py --gpu 0,1,2,3 ,but the cost time more than use 2 gpu,I don't know the reason,should I change some paramrter? @tornadomeet "", 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!']",[],[],0,0
151,incubator-mxnet,3058,closed,how to output loss,"how to output loss \ accuray \ or others log info.
if have any  tutorial or demo?
I search fo a long time ,no harvest.
tks.
",,"['https://github.com/dmlc/mxnet/blob/master/example/image-classification/train_model.py#L82\n', '@neodooth tks ,   alse loss?  is  there  documents in detail?\n', ""I didn't find any docs. To print these in the log you need to supply corresponding metrics to `fit`. You can also take a look at https://github.com/dmlc/mxnet/blob/master/example/rcnn/rcnn/metric.py and https://github.com/dmlc/mxnet/blob/master/example/rcnn/tools/train_rpn.py#L78\n"", 'tks\n', ""mark. \r\nThere're a lot of invalid links."", '@neodooth \r\nI also want to output loss and speed information in the terminal when training my own data, but i cannot find and docs in the apache/incubator-mxnet repo. The links above are now invalid. Can you give me some advices?\r\n@xiaomaxiao have you solved your problem?', ""@LeonJWH \r\nHi, the links should be around the commit 83dc0b4d46383ef63b2731f12663aa947d96c2ad.\r\nhttps://github.com/apache/incubator-mxnet/blob/83dc0b4d46383ef63b2731f12663aa947d96c2ad/example/image-classification/train_model.py#L82\r\nhttps://github.com/apache/incubator-mxnet/blob/83dc0b4d46383ef63b2731f12663aa947d96c2ad/example/rcnn/rcnn/metric.py#L7\r\nhttps://github.com/apache/incubator-mxnet/blob/83dc0b4d46383ef63b2731f12663aa947d96c2ad/example/rcnn/tools/train_rpn.py#L78\r\n\r\nI haven't been using mxnet for quite a while and it looks like some major updates have taken place... but the ideas should still be the same, those metrics (for computing accuracy or loss) will be called when an iter is finished, and add some print there should do. I used to infer speed by reading the default logs and compute the intervals of the lines and iter numbers, but if you really want to print the speed, you might need to modify the code beneath the ```fit``` method; there must be a ```for``` or ```while``` somewhere to launch each iteration.\r\n\r\nThe metrics thing is from my experience of running the rcnn example, I don't know if it's the same if you're running something else."", '@neodooth \r\nI have solved my problem by set ""**eval_metric = \'ce\'**"" in **mod.fit**, to print cross entropy loss after each iter in the terminmal. According to **Evaluation Metric API**\r\n[http://mxnet.io/api/python/metric.html](url)\r\nThank you for your answer!']",[],[],0,0
152,incubator-mxnet,2171,closed,Symbol argmax API absence,"Hi,

I am trying to implement the sequence to sequence model using mxnet. It seems that there is no argmax API for mxnet symbol (http://mxnet.readthedocs.io/en/latest/packages/python/symbol.html). So how should I implement the decoder part when emitting a word after softmax? Any suggestions? 

Thanks.
",,"['`argmax` may not be needed for a sequence-to-sequence learning model. During training, we can use softmax + crossentropy to compute the loss. For testing, we can get the output of softmax activation and perform beam-search. \nAlso, to add an `argmax` operator, you can fill in the backward implementation of the current `argmax` https://github.com/dmlc/mxnet/blob/master/src/operator/broadcast_reduce_op-inl.h#L183 and register it as a symbol.\n', '@sxjscience Thanks for your comment. I will try it!\n']",[],[],0,0
153,incubator-mxnet,10217,closed,Building with OpenCV causes link errors,"## Description
Building with opencv and cmake causes link errors  on ubuntu
I installed opencv with 


## Environment info (Required)



Package used: N/A 

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): gcc
MXNet commit hash: 09281c76bc215823bc74b34f9ac65d906b741377

Build config:


## Error Message:


Link error
TIFFReadRGBAStrip@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFWriteEncodedStrip@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFWriteScanline@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFNumberOfStrips@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFReadEncodedTile@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFClose@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFOpen@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFSetField@LIBTIFF_4.0'
/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to TIFFSetErrorHandler@LIBTIFF_4.0'
collect2: error: ld returned 1 exit status
ninja: build stopped: subcommand failed.
`


## Minimum reproducible example
N/A
## Steps to reproduce
1. cmake -DCMAKE_BUILD_TYPE=Release -DUSE_GPERFTOOLS=OFF -DUSE_DIST_KVSTORE=ON -DUSE_SSE=ON -DUSE_MKLDNN=OFF .. 
",Build Pending Requester Info,"[""I could guess that:\r\n\r\n1. For some reason libtiff didn't get installed.\r\n\r\n```\r\nsudo apt install libtiff-dev\r\n```\r\n\r\n2. Googling gives the idea that a wrongly set LD_LIBRARY_PATH might be the issue.\r\n\r\n```\r\nexport LD_LIBRARY_PATH\r\n```\r\n\r\nhttps://github.com/BVLC/caffe/issues/4436\r\nhttps://github.com/slowmoVideo/slowmoVideo/issues/143"", '@rahul003 Did the above suggestion worked for you? \r\n@sandeep-krishnamurthy  Could you please tag the issue as Pending Requester Info and build', '@rahul003  Has the issue been resolved on your side? If so , requesting to close the issue', ""@rahul003 I tried @lebeg 's suggestions on the latest MXNet from master (commit hash : d43b7860819a0bd8f51025ad9d0df4981c25293a ) and was unable to reproduce this issue. I ran it on the same environment as the info provided by you.\r\n\r\n@sandeep-krishnamurthy Requesting this issue to be closed. \r\n\r\n@rahul003 Please feel free to re-open if closed in error.\r\nThanks!\r\n""]","[""\r\n----------Python Info----------\r\nVersion      : 3.6.3\r\nCompiler     : GCC 7.2.0\r\nBuild        : ('default', 'Oct 13 2017 12:02:49')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 9.0.1\r\nDirectory    : /home/ubuntu/anaconda3/lib/python3.6/site-packages/pip\r\n----------MXNet Info-----------\r\nNo MXNet installed.\r\n----------System Info----------\r\nPlatform     : Linux-4.4.0-1052-aws-x86_64-with-debian-stretch-sid\r\nsystem       : Linux\r\nnode         : ip-172-31-37-207\r\nrelease      : 4.4.0-1052-aws\r\nversion      : #61-Ubuntu SMP Mon Feb 12 23:05:58 UTC 2018\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                32\r\nOn-line CPU(s) list:   0-31\r\nThread(s) per core:    2\r\nCore(s) per socket:    16\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\nStepping:              1\r\nCPU MHz:               2699.894\r\nCPU max MHz:           3000.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              4600.10\r\nHypervisor vendor:     Xen\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              46080K\r\nNUMA node0 CPU(s):     0-31\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single retpoline kaiser fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0056 sec, LOAD: 0.3840 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0475 sec, LOAD: 0.0169 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0766 sec, LOAD: 0.5814 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0167 sec, LOAD: 0.2930 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0038 sec, LOAD: 0.0420 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0047 sec, LOAD: 0.0881 sec.\r\n"", ""\r\ncmake -DCMAKE_BUILD_TYPE=Release -DUSE_GPERFTOOLS=OFF -DUSE_DIST_KVSTORE=ON -DUSE_SSE=ON -DUSE_MKLDNN=OFF -GNinja .. && ninja\r\n-- CMake version '3.10.2' using generator 'Ninja'\r\n-- Could NOT find MKL (missing: MKL_INCLUDE_DIR MKL_RT_LIBRARY)\r\n--  MKL not found\r\n-- Could NOT find MKL (missing: MKL_INCLUDE_DIR MKL_RT_LIBRARY)\r\n-- Found OpenBLAS libraries: /usr/local/lib/libopenblas.so\r\n-- Found OpenBLAS include: /usr/local/include\r\n-- CUDA detected: 9.0\r\n-- Found cuDNN (include: /usr/local/cuda/include, library: /usr/local/cuda/lib64/libcudnn.so)\r\n-- Running GPU architecture autodetection\r\n-- Found CUDA arch 7.0 7.0 7.0 7.0\r\n-- Added CUDA NVCC flags for: sm_70\r\n-- Using JEMalloc malloc\r\n--  OpenCV_LIBS=opencv_core;opencv_highgui;opencv_imgproc;opencv_imgcodecs\r\n-- OpenCV found (/usr/local/share/OpenCV)\r\n-- Found OpenMP_C: -fopenmp\r\n-- Found OpenMP_CXX: -fopenmp\r\n-- LIBOMP: Operating System     -- Linux\r\n-- LIBOMP: Target Architecture  -- x86_64\r\n-- LIBOMP: Build Type           -- Release\r\n-- LIBOMP: OpenMP Version       -- 50\r\n-- LIBOMP: Library Kind         -- SHARED\r\n-- LIBOMP: Library Type         -- normal\r\n-- LIBOMP: Fortran Modules      -- FALSE\r\n-- LIBOMP: Build                -- 20140926\r\n-- LIBOMP: Use Stats-gathering  -- FALSE\r\n-- LIBOMP: Use Debugger-support -- FALSE\r\n-- LIBOMP: Use ITT notify       -- TRUE\r\n-- LIBOMP: Use OMPT-support     -- FALSE\r\n-- LIBOMP: Use Adaptive locks   -- TRUE\r\n-- LIBOMP: Use quad precision   -- TRUE\r\n-- LIBOMP: Use TSAN-support     -- FALSE\r\n-- LIBOMP: Use Hwloc library    -- FALSE\r\n-- Found cuDNN (include: /usr/local/cuda/include, library: /usr/local/cuda/lib64/libcudnn.so)\r\n-- Found OpenMP_C: -fopenmp\r\n-- Found OpenMP_CXX: -fopenmp\r\nYou have called ADD_LIBRARY for library mxnet without any source files. This typically indicates a problem with your CMakeLists.txt file\r\n-- Found PROTOBUF Compiler: /home/ubuntu/anaconda3/bin/protoc\r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /home/ubuntu/efs/fp16-dist/mxnet-char/build\r\n""]","['sudo apt-get install -y libopencv-dev', '', '\r\nLinking CXX executable tests/mxnet_unit_tests\r\nFAILED: : && /usr/lib/ccache/c++  -Wall -Wno-unknown-pragmas -fPIC -Wno-sign-compare -O3 -std=c++11 -fno-builtin-malloc -fno-builtin-calloc -fno-builtin-realloc -fno-builtin-free -fopenmp -std=c++0x -O3 -DNDEBUG  -rdynamic tests/CMakeFiles/mxnet_unit_tests.dir/cpp/engine/threaded_engine_test.cc.o tests/CMakeFiles/mxnet_unit_tests.dir/cpp/misc/memory_test.cc.o tests/CMakeFiles/mxnet_unit_tests.dir/cpp/operator/activation_perf.cc.o tests/CMakeFiles/mxnet_unit_tests.dir/cpp/operator/batchnorm_test.cc.o tests/CMakeFiles/mxnet_unit_tests.dir/cpp/operator/coreop_perf.cc.o tests/CMakeFiles/mxnet_unit_tests.dir/cpp/operator/dropout_perf.cc.o tests/CMakeFiles/mxnet_unit_tests.dir/cpp/operator/fully_conn_perf.cc.o tests/CMakeFiles/mxnet_unit_tests.dir/cpp/operator/krprod_test.cc.o tests/CMakeFiles/mxnet_unit_tests.dir/cpp/operator/mkldnn.cc.o tests/CMakeFiles/mxnet_unit_tests.dir/cpp/operator/runner/core_op_runner_test.cc.o tests/CMakeFiles/mxnet_unit_tests.dir/cpp/operator/slice_channel_perf.cc.o tests/CMakeFiles/mxnet_unit_tests.dir/cpp/operator/tune/operator_tune_test.cc.o tests/CMakeFiles/mxnet_unit_tests.dir/cpp/storage/storage_test.cc.o tests/CMakeFiles/mxnet_unit_tests.dir/cpp/test_main.cc.o  -o tests/mxnet_unit_tests -L/usr/local/cuda/lib64 -Wl,-rpath,/usr/local/cuda/lib64:/usr/local/lib:/home/ubuntu/efs/fp16-dist/mxnet-char/build/3rdparty/openmp/runtime/src:/home/ubuntu/anaconda3/lib 3rdparty/googletest/googletest/libgtest.a -Wl,--whole-archive libmxnet.a -Wl,--no-whole-archive dmlc-core/libdmlc.a /usr/local/lib/libopenblas.so /usr/local/cuda/lib64/libcudart.so /usr/local/cuda/lib64/libcurand.so /usr/local/cuda/lib64/libcublas.so /usr/local/cuda/lib64/libcublas_device.a /usr/local/cuda/lib64/libcudart.so /usr/local/cuda/lib64/libcurand.so /usr/local/cuda/lib64/libcublas.so /usr/local/cuda/lib64/libcublas_device.a /usr/local/cuda/lib64/libcudnn.so -lrt -ljemalloc /usr/local/lib/libopencv_highgui.so.3.2.0 3rdparty/openmp/runtime/src/libomp.so -lpthread -llapack -ljemalloc /usr/local/cuda/lib64/libcudnn.so -lcufft -lcusolver -lnvrtc -lcuda /home/ubuntu/anaconda3/lib/libprotobuf.so /home/ubuntu/anaconda3/lib/libzmq.so ps-lite/libpslite.a -lprotobuf /home/ubuntu/anaconda3/lib/libzmq.so ps-lite/libpslite.a -lprotobuf -lrt -lpthread -llapack -lcufft -lcusolver -lnvrtc -lcuda /home/ubuntu/anaconda3/lib/libprotobuf.so /home/ubuntu/anaconda3/lib/libzmq.so -lprotobuf /home/ubuntu/anaconda3/lib/libzmq.so -lprotobuf /usr/local/lib/libopencv_imgcodecs.so.3.2.0 /usr/local/lib/libopencv_imgproc.so.3.2.0 /usr/local/lib/libopencv_core.so.3.2.0 -ldl -Wl,-rpath-link,/usr/local/lib && :\r\n/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to ', ""TIFFReadDirectory@LIBTIFF_4.0'\r\n/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to "", ""TIFFIsTiled@LIBTIFF_4.0'\r\n/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to "", ""TIFFGetField@LIBTIFF_4.0'\r\n/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to "", ""TIFFScanlineSize@LIBTIFF_4.0'\r\n/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to "", ""TIFFReadRGBATile@LIBTIFF_4.0'\r\n/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to "", ""TIFFRGBAImageOK@LIBTIFF_4.0'\r\n/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to "", ""TIFFReadEncodedStrip@LIBTIFF_4.0'\r\n/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to "", ""TIFFSetWarningHandler@LIBTIFF_4.0'\r\n/usr/local/lib/libopencv_imgcodecs.so.3.2.0: undefined reference to "", '']",0,0
154,incubator-mxnet,14177,open,Insufficient documentation for .hybridize(),"Hi

I have been trying to optimize my models with hybridize and accidentally misspelled an argument to the method. I got the quite interesting message below (using a minimal example):


Although I find this message quite useful, I also found it quite surprising since [the documentation](https://mxnet.incubator.apache.org/versions/master/api/python/gluon/gluon.html?highlight=hybrid#mxnet.gluon.Block.hybridize) only mentions  and .

I am not sure what the effect of the other parameters are and when changing them is appropriate. I am hoping that someone could tell me and I suggest that the documentation be updated to describe the undocumented keyword arguments.",Python,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Doc', '@TobiasSkovgaardJepsen Thanks for raising this. \r\n\r\n@eric-haibin-lin @szha if you guys know anything with the info of HybridBlock', '@TobiasSkovgaardJepsen the document from the error message is the list of arguments for CachedOp, the underlying operator to make hybridization happen. CachedOp is not the same as hybridize, which indeed only has those documented arguments.', ""The problem is that hybridize didn't fail fast but instead returned the error message of CachedOp. The error message should be fixed.""]","['\r\n>>> from mxnet.gluon.nn import Dense\r\n>>> from mxnet.ndarray import ones\r\n>>> model = Dense(10)\r\n>>> X =ones((1, 10))\r\n>>> model.initialize()\r\n>>> model.hybridize(unsupported_keyword_argument=True))\r\n>>> model(X)\r\nTraceback (most recent call last):\r\n  File ""<stdin>"", line 1, in <module>\r\n  File ""/Users/tsj/.local/share/virtualenvs/rne-U4U7XVrs/lib/python3.6/site-packages/mxnet/gluon/block.py"", line 542, in __call__\r\n    out = self.forward(*args)\r\n  File ""/Users/tsj/.local/share/virtualenvs/rne-U4U7XVrs/lib/python3.6/site-packages/mxnet/gluon/block.py"", line 909, in forward\r\n    return self._call_cached_op(x, *args)\r\n  File ""/Users/tsj/.local/share/virtualenvs/rne-U4U7XVrs/lib/python3.6/site-packages/mxnet/gluon/block.py"", line 799, in _call_cached_op\r\n    self._build_cache(*args)\r\n  File ""/Users/tsj/.local/share/virtualenvs/rne-U4U7XVrs/lib/python3.6/site-packages/mxnet/gluon/block.py"", line 787, in _build_cache\r\n    self._cached_op = ndarray.CachedOp(out, flags)\r\n  File ""/Users/tsj/.local/share/virtualenvs/rne-U4U7XVrs/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py"", line 116, in __init__\r\n    ctypes.byref(self.handle)))\r\n  File ""/Users/tsj/.local/share/virtualenvs/rne-U4U7XVrs/lib/python3.6/site-packages/mxnet/base.py"", line 251, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: Cannot find argument \'erroneous_keyword_argument\', Possible Arguments:\r\n\r\n----------------\r\nstatic_alloc : boolean, optional, default=0\r\n    Statically allocate memory to improve speed. Memory usage may increase.\r\nstatic_shape : boolean, optional, default=0\r\n    Optimize for invariant input shapes between iterations. Must also set static_alloc to True. Change of input shapes is still allowed but slower.\r\ninline_limit : int (non-negative), optional, default=2\r\n    Maximum number of operators that can be inlined.\r\nforward_bulk_size : int (non-negative), optional, default=15\r\n    Segment size of bulk execution during forward pass.\r\nbackward_bulk_size : int (non-negative), optional, default=15\r\n    Segment size of bulk execution during backward pass.\r\ndata_indices : tuple of <int (non-negative)>, optional, default=[]\r\n    Position of argument variables.\r\nparam_indices : tuple of <int (non-negative)>, optional, default=[]\r\n    Position of parameters.\r\n']","['static_alloc', 'static_shape']",0,0
155,incubator-mxnet,14755,closed,"Build on Linux will fail if ""test"" option used","## Description
There is a build issue happened on MXNet github repo on Linux if using below command:
 make -j USE_OPENCV=1 USE_MKLDNN=1 USE_BLAS=mkl **_### test_**

The build is okay if ""test"" removed.

@TaoLv @pengzhao-intel 

## Environment info (Required)
GCC 4.8.5
CentOS 7.5


Package used (Python/R/Scala/Julia):
Python

## Build info (Required if built from source)
Compiler (gcc/clang/mingw/visual studio):
GCC4.8.5

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)


## What have you tried to solve it?
@zachgk 
The build issue is most likely introduced after commit https://github.com/apache/incubator-mxnet/commit/391a1be260eb75b437ebced6743647b8e9df7802
The commit https://github.com/apache/incubator-mxnet/commit/dc48cd2a5a6460171bf9b842453866e731e6ff7d seems changing the HEAD of 3rdpary/googletest to eb9225c, if I switch the 3rdpary/googletest to previous HEAD ec44c6c , then make -j USE_OPENCV=1 USE_MKLDNN=1 USE_BLAS=mkl test can succeed.

",Build,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Build', '@mxnet-label-bot add [build]', '@larroy Any ideas?', ""@juliusshufan Can you try a higher version of GCC? I think it's due to the new googletest is not compatible with GCC 4.8.5. "", 'Sure thing and will take a try. Just wondering, is the GCC 4.8.5 still the minimum requirements for MXNet?\r\n\r\n', 'Yes, I think the requirement for GCC is not changed. If the issue is confirmed, it will be a breaking issue for MXNet and should be fixed.\r\nHi @marcoabreu, is GCC 4.8.5 still in the CI validation set?', ""What is the error?\r\n\r\nFor me is MKL problem as I don't have mkl.\r\n\r\n\r\n```\r\nmake[1]: 'libdmlc.a' is up to date.  \r\nmake[1]: Leaving directory '/home/piotr/mxnet_master/3rdparty/dmlc-core'                                                      \r\nsparse_matrix.cc:4:10: fatal error: mkl_spblas.h: No such file or directory                                                   \r\n #include <mkl_spblas.h>    \r\n```"", 'This works for me\r\n```\r\nmake -j USE_OPENCV=1 USE_MKLDNN=1 USE_BLAS=open test | tee build.log\r\n```\r\n\r\n', '@mxnet-label-bot add [MKL]', '@mxnet-label-bot add [Build]\r\n\r\n', '@larroy Thanks for the follow-up, at my side, the compilation is successful with gcc6.3.1\r\non using make -j USE_OPENCV=1 USE_MKLDNN=1 USE_BLAS=openblas test\r\n\r\nBut it will fail on gcc 4.8.5/5.3.1, logs as below. seems it more like a GCC compatibility issue. If the GCC4.8.5 is still the minimum requirement for MXNet, could you please try with gcc 4/5. \r\n\r\nUSE_BLAS=open：\r\n#gcc5.3.1)\r\n    60 g++ -c -std=c++11 -Wall -O2 -Iinclude -fPIC -I../include -I../3rdparty/dlpack/include -I../3rdparty/HalideIR/src -I../topi/include -I/home/torch/workspace/sourc     e/incubator-mxnet/3rdparty/dmlc-core/include  -c src/pass/plan_memory.cc -o build/src/pass/plan_memory.o\r\n  61 In file included from 3rdparty/googletest/googletest/include/gtest/internal/gtest-internal.h:40:0,\r\n  62                  from 3rdparty/googletest/googletest/include/gtest/gtest.h:60,\r\n  63                  from 3rdparty/googletest/googletest//src/gtest-all.cc:38:\r\n  64 3rdparty/googletest/googletest/include/gtest/internal/gtest-port.h:830:12: error: ‘std::get’ has not been declared\r\n  65  using std::get;\r\n  66             ^\r\n  67 3rdparty/googletest/googletest/include/gtest/internal/gtest-port.h:831:12: error: ‘std::make_tuple’ has not been declared\r\n  68  using std::make_tuple;\r\n  69             ^\r\n  70 3rdparty/googletest/googletest/include/gtest/internal/gtest-port.h:832:12: error: ‘std::tuple’ has not been declared\r\n  71  using std::tuple;\r\n#gcc4.8.5)\r\n  42 /usr/include/c++/4.8.2/bits/c++0x_warning.h:32:2: error: #error This file requires compiler and library support for the ISO C++ 2011 standard. This support is c     urrently experimental, and must be enabled with the -std=c++11 or -std=gnu++11 compiler options.\r\n  43  #error This file requires compiler and library support for the \\\r\n  44   ^\r\n  45 ^M  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0In file included from 3rdparty/googletest/googletest/include/gtest/internal/gtes     t-internal.h:40:0,\r\n  46                  from 3rdparty/googletest/googletest/include/gtest/gtest.h:60,\r\n  47                  from 3rdparty/googletest/googletest//src/gtest-all.cc:38:\r\n  48 3rdparty/googletest/googletest/include/gtest/internal/gtest-port.h:830:12: error: ‘std::get’ has not been declared\r\n  49  using std::get;\r\n  50             ^\r\n  51 3rdparty/googletest/googletest/include/gtest/internal/gtest-port.h:831:12: error: ‘std::make_tuple’ has not been declared\r\n \r\nUSE_BLAS=openblas：\r\n#gcc5.3.1)\r\n  41 /opt/rh/devtoolset-4/root/usr/include/c++/5.3.1/bits/c++0x_warning.h:32:2: error: #error This file requires compiler and library support for the ISO C++ 2011 standard. This support must be enabled with the -std=c++11 or -std=gnu++11 compiler options.\r\n  42  #error This file requires compiler and library support \\\r\n  43   ^\r\n  44   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n  45                                  Dload  Upload   Total   Spent    Left  Speed\r\n  46 ^M  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0g++ -c -std=c++11 -Wall -O2 -Iinclude -fPIC -I../include -I../3rdparty/dlpack/in     clude -I../3rdparty/HalideIR/src -I../topi/include -I/home/torch/workspace/source/incubator-mxnet/3rdparty/dmlc-core/include  -c src/core/node.cc -o build/src/c     ore/node.o\r\n \r\n#gcc4.8.5)\r\n22 /usr/include/c++/4.8.2/bits/c++0x_warning.h:32:2: error: #error This file requires compiler and library support for the ISO C++ 2011 standard. This support is c     urrently experimental, and must be enabled with the -std=c++11 or -std=gnu++11 compiler options.\r\n  23  #error This file requires compiler and library support for the \\\r\n  24   ^\r\n  25 g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0  -msse2 -o recordio.o src/recordi     o.cc\r\n ', ""Can you print full compiler invocation? looks like std=c++11 is missing, so it can't find make_tuple. I think this is an easy Makefile fix."", '@larroy this line? https://github.com/apache/incubator-mxnet/blob/master/tests/cpp/unittest.mk#L39', '@TaoLv can you add -std=c++11  as in the lines below?', 'better to replace c++0x to c++11', '@mxnet-label-bot remove [MKL]', ""@szha seems to be issue with googletest and old GCC version - I'm not sure if it should be investigated more - with newer GCC version there is no issue - what do you think?"", ' GCC4.8.5 is no longer supported on the master branch. So I think we can close this issue.']","['\r\nWhat to do:\r\nrun  make -j USE_OPENCV=1 USE_MKLDNN=1 USE_BLAS=mkl **_### test_**, build MXNet from source.\r\n\r\n']",['git rev-parse HEAD'],0,0
156,incubator-mxnet,1712,closed,Train and Validation Metric Evaluation,"Hi,

I was just wondering how metrics are evaluated at the end of a training epoch and during validation afterwards. Is it the mean metric value per batch? 

If so, at least for validation wouldn't it be more robust to evaluate the metric based off of the prediction values off of the entire eval dataset? One example I can think of is for validation with a dataset that has sparse labels. In some batches, certain labels may not appear, breaking specific metric functions.

Thanks!
",,"['I am also curious about how the training accuracy  of each displayed batch, e.g. \nBatch [50]. speed: 594.15 samples/sec Train-accuracy=0.646563\nDoes this number indicates the accuracy of batch 50 or the average accuracy of last 50 batches?\n', 'Would it be possible to modify the online evaluation process to store batch predictions on the eval data and calculate the evaluation metric at the very end? This would solve the issue of imbalanced evaluation sets and provide a more robust validation measure.\n']",[],[],0,0
157,incubator-mxnet,14955,open,[Feature request]Calculate network calculations tools for Gluon.,"Now gluon has a  function for calculate total params for a network but don't have a tool for calculate network FLOPs(G).

Why need this?
 - Model FLOPs could straightly measure a network inference speed.
 - Research needed.
 - Some of ops are widely used in many networks like conv, pooling, fc, bn
, relu, softmax.
 - Some of ops are looping many times and have different shape of feature_maps outpus, it's hard to calculate them manually.

But it's hard for calculating all of ops and actually not necessary(Some discussions [here](https://discuss.gluon.ai/t/topic/10228/8)). So I partition them on demand.
 1. Widely used in many networks and most commonly used.[urgent]
    - Conv2d/3d
    - Maxpool2d/3d
    - Avgpool 2d/3d
    - GlobalAvgPool2d/3d
    - FC
    - Relu, LeakyReLU, PReLU, Tanh, Sigmoid
    - BN
    - Softmax
    - RNN(basic rnn is just matrix multiplication, more complicated I don't know, this may need add if anything misses.)
 2. Used somewhere but may not common.[not urgent]
    - Dropout
    - Conv1d, Maxpool1d, Avgpool1d
    - GlobalAvgPool1d
    - ConvTranspose1d/2d/3d (GAN may use this, but for now GAN don't care about FLOPs)
    - UpSampling bilinear/nearest
    - InstanceNorm, LayerNorm
    - L2Normalization
3. May only use once or little times in a model, their FLOPs may based on implement. Not hard to calculate manually.(May not to implement.)
     - ROIPooling
     - Atomic level operation(I didn't see anyone calculate them.)
 4. Need not to implement
    - Loss functions.

Additional interface should be added to make users  for manually defined Blocks.

Welcome to add if anything missing.
Welcome to suggest if anything wrong.",Feature request Profiler,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Gluon, Feature', 'The Gflops is related to what kind of implementation is used and whether other optimization skills are applied.\r\n\r\nFor example, the computation of direct, GEMM-based and Winograd convolution is really different. And if the convolution is fused with BN/Relu/Sum, the calculation is also changed.\r\n\r\nIf you only care about how much OPs (Add, Mul, FMA) in the network at the runtime, I suggest to get it by profiling tools in a short time :)\r\n\r\nAnyway, this is a good proposal for the analysis and I also like it. ', ""@sandeep-krishnamurthy 's proposal maybe can cover your request with further improvements.\r\nhttps://cwiki.apache.org/confluence/display/MXNET/MXNet+Operator+Benchmarks\r\n\r\n"", ""@pengzhao-intel I mean GFLOPs is not consider special further improvements.It's just standard calculated amount.\r\nFor example, a Conv2d flops should be defined as:\r\n```\r\nAssume that the input and output and kernel are square.\r\n\r\nO(conv2d-nobias) = K * K * Cin * M * M * Cout\r\n\r\nM = output feature map side length\r\nK = kernel size side length\r\nC(in/out) = Channels in/out\r\n```"", 'Thanks this will be very useful.\r\n\r\nCurrently, I am working on per operator profiling to capture forward time, backward time, max memory allocated in phase 1 of my work. And, these uses different input shapes and option for each operator. \r\n\r\nIntention of this work is - to catch any performance regression at operator level, ability identify hot computation paths in operator kernel for certain input shapes, and finally, derive insights like - In MXNet ArgMax is slower than Max operator for same operation.\r\n\r\nWill that give a proxy for what you are looking for? However, this proposal is more fine grained and will be useful for planning optimization work.\r\n', ""@sandeep-krishnamurthy It's pleasure this may help you, but I just want a static analysis as I reply to pengzhao-intel, that's not complicated as you do.\r\nThe static analysis could help you evaluate network computing in the most fair way. "", 'Anyone has an update on this ?\r\n']",[],"['summary', 'defined calculations themselves']",0,0
158,incubator-mxnet,9342,closed,I have a problem in the process of cross compiling,"issue:./include/dmlc/./optional.h:67:29: error: 'class dmlc::optional<int>' has no member named 'val'
     std::swap(val, other.val);
I should how to modify?",ARM Pending Requester Info,"['Did you update the submodule? `git submodule update --init --recursive`', 'I don‘t your meaning,I have downloaded all files of github. I want to create dynamic link library int the arm,but having a problem in the process of cross compiling. I should where to execute this order?\n\nAt 2018-01-08 12:06:12, ""Sheng Zha"" <notifications@github.com> wrote:\n\n\nDid you update the submodule? git submodule update --init --recursive\n\n—\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.', ""Sorry for the confusion. Given the compilation error, the most common cause is that some of the submodules are outdated, which is why I asked whether you updated the submodules. You didn't provide environment information such as that you're doing it on ARM, which is less common, so I didn't think it would be a code problem.\r\n\r\n@ZihengJiang would you provide some info on how to compile for ARM?"", 'You can also try to use our docker_multiarch containers: https://github.com/apache/incubator-mxnet/tree/master/docker_multiarch', '@sandeep-krishnamurthy\xa0Can you please add labels:\r\n- ARM\r\n- Pending Requester Info\r\n\r\nAlso, 30+ day old issue. Please close the issue due to inactivity and no response from the requester.\r\n\r\n@zhangguotai Please follow this [template](https://github.com/apache/incubator-mxnet/blob/master/.github/ISSUE_TEMPLATE.md) when you are creating an issue in future since this will help the community to identify the issue faster.\r\nIf done in error please feel free to re-open and comment.\r\n\r\nThanks!']",[],[],0,0
159,incubator-mxnet,945,closed,Some questions about multi label image classification in MXNet.,"Hi,
     I want to perform multi label image classification for my own dataset with mxnet. Here are some questions bother me.
- How to prepare the recordIO database or the index file?
  According to [Extension: Mutliple Labels for a Single Image](https://github.com/dmlc/mxnet/blob/a6b4baf9824bb3f0bfb8ec804d333913b3bbc0c8/doc/python/io.md) , the index file should have a fixed width of label field. What if my labels are not always the same width which is the common occasion. And will the labels of a single image be treated as a vector like (1,0,0,...,1,...0,...,1)? Or how can I prepare a binary vector label for the image data?
- What loss function should I assign to the training phase? Will the  deal with multi-label? Or should I implement a  like loss function?
- What evaluation criteria should I choose for the test or val phase? The accuracy metric is for single label.

Thanks!  
",,"['you can refer to this example https://github.com/dmlc/mxnet/pull/940\n', '@wangg12 did you figure out? Thanks a lot in advance.']",[],"['SoftmaxOutput', 'sum of squares']",0,0
160,incubator-mxnet,16424,closed,[Channel Shuffle / Hard Swish / Hard Sigmoid] running in MKL CPU backend failed,"## Description
I've trained a [NAS searched ShuffleNet related model](https://github.com/CanyonWind/MXNet-Single-Path-One-Shot-NAS), which contains some rare operators like Channel Shuffle, hard Swish, hard Sigmoid, etc.. It runs fine on both GPU and raw CPU backend but failed (val_acc = 0.0) on MKL CPU backend. 

## Environment info (Required)



## Background
This ShuffleNet related model has been built by:

| Layers | Ops
| :--------------------- | :-----: |
|Common ops                                | conv, BN, Activation('relu') |
|Concat                                          | concat |
|Shuffle Channel & Slice              | reshape-swapaxes-reshape-slice |
|Hard swish                                   | plusscalar-clip-divscalar-mul |
|Hard sigmoid                               | plusscalar-clip-divscalar |
|Global Average Pooling              | pool |

For how the Shuffle Channel is implemented: 

![alt text](https://github.com/CanyonWind/MXNet-Single-Path-One-Shot-NAS/blob/master/images/Channel_Shuffle_and_Split.png?raw=true)

## Error Message
The model was planned to be quantized by using MXNet 1.6.0 (master) [quantization tool](https://github.com/apache/incubator-mxnet/tree/master/example/quantization). The ""error"" occurs when trying to use **MKL backend** to run the raw model before quantization as well as the quantized model.

- Raw model: when using [imagenet_inference.py](https://github.com/CanyonWind/MXNet-Single-Path-One-Shot-NAS/blob/master/quantization/imagenet_inference.py) with MXNet CPU only (no MKL), it works fine


- Raw model: while using the same model and same [code](https://github.com/CanyonWind/MXNet-Single-Path-One-Shot-NAS/blob/master/quantization/imagenet_inference.py) but with MXNet-mkl, it **failed**:


- Quantized model:  interestingly, with MXNet-mkl, the quantization process works smoothly and generates a quantized model. But when using [imagenet_inference.py](https://github.com/CanyonWind/MXNet-Single-Path-One-Shot-NAS/blob/master/quantization/imagenet_inference.py) to verify the quantized model's performance, it **failed again** just like the raw model before quantization.


## Steps to reproduce:
1. Clone the code and the model has been put in there:

2. Reproduce MXNet CPU only **without MKL**:


3. Reproduce **MXNet-mkl** with failed validation accuracy:


",MKLDNN Quantization,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended label(s): Bug', 'Thank to report the issue @ZhennanQin  will take a look :)', 'This bug can be reproduced locally, and found the root cause. Internal patch is ready, need more time for verification. ', ""> This bug can be reproduced locally, and found the root cause. Internal patch is ready, need more time for verification.\r\n\r\nHi @ZhennanQin, thanks for the prompt response. I'm participating a competition and desperately need this tool to quantize. Could you please let me know whether there could be a quick fix / walk-around? "", ""@CanyonWind it's great to know you're using MXNet Quantization solution in your competition.\r\nCould you cite the MXNet and the related quantization solution in your further publication?"", ""Sure, I'm happy to do that. Could you please let me know which quantization method (paper) you are using in the MKL so that  I could cite it. Thanks\r\n\r\n"", 'Please cite the blog, https://medium.com/apache-mxnet/model-quantization-for-production-level-neural-network-inference-f54462ebba05\r\n\r\n', ""@CanyonWind https://github.com/apache/incubator-mxnet/pull/16455 is created to address the fp32 accuracy issue. With this patch, your command can provide below accuracy result:\r\n```\r\nINFO:logger:('accuracy', 0.771875)\r\nINFO:logger:('top_k_accuracy_5', 0.909375)\r\n```\r\nFor quantization, I've tried, but still got 0 acc due to some mkldnn correctness issue. We need to wait mkldnn team to fix that. This may take a few days or weeks. Sorry about that."", 'Reopen to wait for quantization fix ', '@pengzhao-intel Got it. Thanks\r\n\r\n@ZhennanQin Thanks for the help! I will give it a try. A quick question is that is this problem caused by reshaping? If I can find some way to avoid using it in the model, should the quantization work?', ""for quantization, it's not about reshape. there're some int8 convolutions produces wrong result, causing acc to 0. Currently the only workaround solution is skipping quantize those trouble convolution, I can help to identify those layers in your model when I have time."", 'Thank you very much for taking the time to help. I will try it too and let you know if there is any update.', '@ZhennanQin does MKLDNN 1.0 upgrade fix this problem?', 'With https://github.com/apache/incubator-mxnet/pull/16734 merged, the computation error is fixed. Then you can have a try for intel int8 solution. ', ""Hi @ZhennanQin, thanks a lot for your effort! \r\nI tried to verify the quantized model's performance with the nightly built release (`mxnet-mkl-1.6.0b20191107`, the merge commit was completed on 1106 so I assumed this release already contains the updated codes) on the Mac to get a quick result. \r\n\r\n```sh\r\ngit clone https://github.com/CanyonWind/Single-Path-One-Shot-NAS-MXNet.git\r\ncd Single-Path-One-Shot-NAS-MXNet\r\npython3 -m venv env\r\nsource env/bin/activate\r\npip install mxnet-mkl --pre\r\ncd quantization\r\n```\r\nI've tried the following:\r\nWith calib-mode: `none`\r\n```sh\r\n# quantize model\r\npython3 quantize_mkldnn.py --model=ShuffleNas_fixArch --num-calib-batches=5 --calib-mode=none\r\n# verify performance\r\npython3 imagenet_inference.py --symbol-file model/ShuffleNas_fixArch-quantized-symbol.json --param-file model/ShuffleNas_fixArch-quantized-0000.params --rgb-mean=123.68,116.779,103.939 --rgb-std=58.393,57.12,57.375 --num-skipped-batches=50 --batch-size=64 --num-inference-batches=5 --dataset=./data/val_256_q90.rec --ctx=cpu\r\n# accuracy: 0.009375\r\n```\r\nWith calib-mode: `naive`\r\n```sh\r\n# quantize model\r\npython quantize_mkldnn.py --model=ShuffleNas_fixArch --num-calib-batches=5 --calib-mode=naive\r\n# verify performance\r\npython3 imagenet_inference.py --symbol-file model/ShuffleNas_fixArch-quantized-5batches-naive-symbol.json --param-file model/ShuffleNas_fixArch-quantized-0000.params --rgb-mean=123.68,116.779,103.939 --rgb-std=58.393,57.12,57.375 --num-skipped-batches=50 --batch-size=64 --num-inference-batches=5 --dataset=./data/val_256_q90.rec --ctx=cpu\r\n# accuracy: 0.003125\r\n```\r\nWith calib-mode: `entropy`\r\n```sh\r\n# quantize model\r\npython3 quantize_mkldnn.py --model=ShuffleNas_fixArch --num-calib-batches=5 --calib-mode=entropy\r\n# verify performance\r\npython3 imagenet_inference.py --symbol-file model/ShuffleNas_fixArch-quantized-5batches-entropy-symbol.json --param-file model/ShuffleNas_fixArch-quantized-0000.params --rgb-mean=123.68,116.779,103.939 --rgb-std=58.393,57.12,57.375 --num-skipped-batches=50 --batch-size=64 --num-inference-batches=5 --dataset=./data/val_256_q90.rec --ctx=cpu\r\n# error was thrown when doing inference\r\n```\r\nCould you please guide me how did you verify the quantization accuracy or could you please try any of the above quantization procedure (it wouldn't take more than 10min to finish) at your convenience? \r\n\r\nThanks again for your generous help, I do appreciate it a lot!\r\n\r\n"", '@CanyonWind Below PR is created as a demo for CPU quantization.\r\nhttps://github.com/CanyonWind/Single-Path-One-Shot-NAS-MXNet/pull/12', ""I've tried the updates from the pull request, it works like a charm. Seems like the degraded quantization performance comes from the model precision itself and the large kernel dw conv. \r\n\r\nThough I still have some questions about why and how these factors influence the quantization performance, they are not related to this issue anymore. Hi @ZhennanQin, I might throw some educational questions on the pr thread after more experiments. If you got some time in the future, any quick answer would be appreciated and it might save a good amount time of mine\r\n\r\nThanks a lot for the help again @pengzhao-intel @ZhennanQin! "", ""> I've tried the updates from the pull request, it works like a charm. Seems like the degraded quantization performance comes from the model precision itself and the large kernel dw conv.\r\n> \r\n> Though I still have some questions about why and how these factors influence the quantization performance, they are not related to this issue anymore. Hi @ZhennanQin, I might throw some educational questions on the pr thread after more experiments. If you got some time in the future, any quick answer would be appreciated and it might save a good amount time of mine\r\n> \r\n> Thanks a lot for the help again @pengzhao-intel @ZhennanQin!\r\n\r\nSure. You can send the mail to me (patric.zhao@intel.com) and I will add Zhennan in the loop.\r\n"", 'That would be great, thanks!']","[""\r\n----------Python Info----------\r\nVersion      : 3.7.3\r\nCompiler     : Clang 10.0.1 (clang-1001.0.46.3)\r\nBuild        : ('default', 'Mar 27 2019 09:23:15')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 19.0.3\r\nDirectory    : /Users/yaoxi/projects/oneshot_nas/nasenv/lib/python3.7/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.6.0\r\nDirectory    : /Users/yaoxi/projects/oneshot_nas/nasenv/lib/python3.7/site-packages/mxnet\r\nCommit Hash   : 1d0d1e687fdf436896f8ca106c4915adfd29c8cb\r\nLibrary      : ['/Users/yaoxi/projects/oneshot_nas/nasenv/lib/python3.7/site-packages/mxnet/libmxnet.so']\r\nBuild features:\r\n✖ CUDA\r\n✖ CUDNN\r\n✖ NCCL\r\n✖ CUDA_RTC\r\n✖ TENSORRT\r\n✔ CPU_SSE\r\n✔ CPU_SSE2\r\n✔ CPU_SSE3\r\n✔ CPU_SSE4_1\r\n✔ CPU_SSE4_2\r\n✖ CPU_SSE4A\r\n✔ CPU_AVX\r\n✖ CPU_AVX2\r\n✖ OPENMP\r\n✖ SSE\r\n✖ F16C\r\n✖ JEMALLOC\r\n✖ BLAS_OPEN\r\n✖ BLAS_ATLAS\r\n✖ BLAS_MKL\r\n✔ BLAS_APPLE\r\n✔ LAPACK\r\n✔ MKLDNN\r\n✔ OPENCV\r\n✖ CAFFE\r\n✖ PROFILER\r\n✔ DIST_KVSTORE\r\n✖ CXX14\r\n✖ INT64_TENSOR_SIZE\r\n✔ SIGNAL_HANDLER\r\n✖ DEBUG\r\n✖ TVM_OP\r\n----------System Info----------\r\nPlatform     : Darwin-18.2.0-x86_64-i386-64bit\r\nsystem       : Darwin\r\nnode         : yaoxis-MacBook-Pro.local\r\nrelease      : 18.2.0\r\nversion      : Darwin Kernel Version 18.2.0: Thu Dec 20 20:46:53 PST 2018; root:xnu-4903.241.1~1/RELEASE_X86_64\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : i386\r\nb'machdep.cpu.brand_string: Intel(R) Core(TM) i5-8259U CPU @ 2.30GHz'\r\nb'machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C'\r\nb'machdep.cpu.leaf7_features: SMEP ERMS RDWRFSGS TSC_THREAD_OFFSET BMI1 AVX2 BMI2 INVPCID SMAP RDSEED ADX IPT SGX FPU_CSDS MPX CLFSOPT'\r\nb'machdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT PREFETCHW RDTSCP TSCI'\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0358 sec, LOAD: 0.6333 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0269 sec, LOAD: 0.1421 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0581 sec, LOAD: 0.2112 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0193 sec, LOAD: 0.1315 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0483 sec, LOAD: 0.6375 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0008 sec, LOAD: 0.2240 sec.\r\n----------Environment----------\r\n"", ""sh\r\nINFO:logger:('accuracy', 0.771875)\r\nINFO:logger:('top_k_accuracy_5', 0.909375)\r\n"", ""sh\r\nINFO:logger:('accuracy', 0.0)\r\nINFO:logger:('top_k_accuracy_5', 0.003125)\r\n"", ""\r\nINFO:logger:('accuracy', 0.0)\r\nINFO:logger:('top_k_accuracy_5', 0.003125)\r\n"", '\r\ngit clone https://github.com/CanyonWind/MXNet-Single-Path-One-Shot-NAS.git\r\n', ""sh\r\npip install mxnet --pre\r\ncd MXNet-Single-Path-One-Shot-NAS/quantization/\r\npython3 imagenet_inference.py --symbol-file model/ShuffleNas_fixArch-symbol.json --param-file model/ShuffleNas_fixArch-0000.params --rgb-mean=123.68,116.779,103.939 --rgb-std=58.393,57.12,57.375 --num-skipped-batches=50 --batch-size=64 --num-inference-batches=5 --dataset=./data/val_256_q90.rec --ctx=cpu\r\n\r\n...\r\n# output would be like:\r\nINFO:logger:('accuracy', 0.771875)\r\nINFO:logger:('top_k_accuracy_5', 0.909375)\r\n"", 'sh\r\n# clean the previous no mkl MXNet\r\npip uninstall mxnet\r\n', ""sh\r\npip install mxnet-mkl --pre\r\ncd MXNet-Single-Path-One-Shot-NAS/quantization/\r\npython3 imagenet_inference.py --symbol-file model/ShuffleNas_fixArch-symbol.json --param-file model/ShuffleNas_fixArch-0000.params --rgb-mean=123.68,116.779,103.939 --rgb-std=58.393,57.12,57.375 --num-skipped-batches=50 --batch-size=64 --num-inference-batches=5 --dataset=./data/val_256_q90.rec --ctx=cpu\r\n\r\n...\r\n# output would be like:\r\nINFO:logger:('accuracy', 0.0)\r\nINFO:logger:('top_k_accuracy_5', 0.003125)\r\n""]",[],0,0
161,incubator-mxnet,13592,open,Transpose with MXNET_BACKWARD_DO_MIRROR throws exception,"Consider the following (using MXNet release version 1.3.1 on OSX):

returns an array. However:

throws an exception:
 
It may be related to issue #8048.",Bug Environment Variables,"['@sbodenstein thanks for reporting this issue. I can reproduce it on `v1.3.1`. Could you please explain more on the reason you set this [flag](https://mxnet.incubator.apache.org/faq/env_var.html#memonger)?  @anirudh2290 @apeforest ', '@lanking520: we wanted to offer Mathematica users a memory-efficient training option for very large models. And ran into this during testing.', 'hi, I also encountered this problem. How did you solve it?']","[""\r\nimport mxnet as mx\r\nimport os\r\n\r\ndef f():\r\n    shape = (1,2,3,4)\r\n    sym = mx.sym.Variable('data', shape=shape)\r\n    sym = mx.sym.transpose(sym, axes=(0,3,1,2))\r\n    sym = mx.sym.transpose(sym, axes=(0,2,3,1))\r\n    exe = sym.simple_bind(ctx=mx.cpu())\r\n    output = exe.forward()[0]\r\n    exe.backward(output)\r\n    return exe.grad_arrays[0].asnumpy()\r\n\r\nf()\r\n"", '\r\nos.environ[""MXNET_BACKWARD_DO_MIRROR""] = ""1""\r\nf()\r\n', '\r\nTraceback (most recent call last):\r\n  File ""/Users/sebastianb/Documents/Wolfram_work/2018_October/test_mx.py"", line 20, in <module>\r\n    print(f())\r\n  File ""/Users/sebastianb/Documents/Wolfram_work/2018_October/test_mx.py"", line 16, in f\r\n    return exe.grad_arrays[0].asnumpy()\r\n  File ""/Users/sebastianb/git/mxnet_seb/python/mxnet/ndarray/ndarray.py"", line 1980, in asnumpy\r\n    ctypes.c_size_t(data.size)))\r\n  File ""/Users/sebastianb/git/mxnet_seb/python/mxnet/base.py"", line 252, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [15:20:11] src/operator/tensor/./matrix_op-inl.h:310: Check failed: req[0] == kWriteTo (0 vs. 1) Transpose does not support inplace\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) 0   libmxnet.so                         0x0000000118e327f5 dmlc::StackTrace() + 261\r\n[bt] (1) 1   libmxnet.so                         0x0000000118e325af dmlc::LogMessageFatal::~LogMessageFatal() + 47\r\n[bt] (2) 2   libmxnet.so                         0x000000011a1598d1 void mxnet::op::Transpose<mshadow::cpu>(nnvm::NodeAttrs const&, mxnet::OpContext const&, std::__1::vector<mxnet::TBlob, std::__1::allocator<mxnet::TBlob> > const&, std::__1::vector<mxnet::OpReqType, std::__1::allocator<mxnet::OpReqType> > const&, std::__1::vector<mxnet::TBlob, std::__1::allocator<mxnet::TBlob> > const&) + 257\r\n[bt] (3) 3   libmxnet.so                         0x000000011a3c8227 mxnet::exec::FComputeExecutor::Run(mxnet::RunContext, bool) + 87\r\n[bt] (4) 4   libmxnet.so                         0x000000011a3f54a4 std::__1::__function::__func<mxnet::exec::GraphExecutor::CreateCachedSegOpr(unsigned long, unsigned long)::$_7, std::__1::allocator<mxnet::exec::GraphExecutor::CreateCachedSegOpr(unsigned long, unsigned long)::$_7>, void (mxnet::RunContext, mxnet::engine::CallbackOnComplete)>::operator()(mxnet::RunContext&&, mxnet::engine::CallbackOnComplete&&) + 84\r\n[bt] (5) 5   libmxnet.so                         0x000000011a3b4da5 mxnet::engine::ThreadedEngine::ExecuteOprBlock(mxnet::RunContext, mxnet::engine::OprBlock*) + 533\r\n[bt] (6) 6   libmxnet.so                         0x000000011a3b8c71 void std::__1::__invoke_void_return_wrapper<void>::__call<mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::\'lambda\'()::operator()() const::\'lambda\'(std::__1::shared_ptr<dmlc::ManualEvent>)&, std::__1::shared_ptr<dmlc::ManualEvent> >(mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::\'lambda\'()::operator()() const::\'lambda\'(std::__1::shared_ptr<dmlc::ManualEvent>)&&&, std::__1::shared_ptr<dmlc::ManualEvent>&&) + 145\r\n[bt] (7) 7   libmxnet.so                         0x000000011a3b5de3 void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, std::__1::function<void (std::__1::shared_ptr<dmlc::ManualEvent>)>, std::__1::shared_ptr<dmlc::ManualEvent> > >(void*) + 83\r\n[bt] (8) 8   libsystem_pthread.dylib             0x00007fff59f13661 _pthread_body + 340\r\n[bt] (9) 9   libsystem_pthread.dylib             0x00007fff59f1350d _pthread_body + 0\r\n']",[],0,0
162,incubator-mxnet,13438,closed,libc getenv is not threadsafe,"## Description
getenv() calls in libc are not threadsafe according to:

https://rachelbythebay.com/w/2017/01/30/env/
and
https://github.com/xianyi/OpenBLAS/issues/716

There are indirect calls to dmlc::GetEnv() all across the mxnet codebase, here are a few:

https://github.com/apache/incubator-mxnet/blob/266de6bef4da5769431557288d41fab2a02e52ca/src/engine/threaded_engine_perdevice.cc#L79
or
https://github.com/apache/incubator-mxnet/blob/5a83b6b563211f430688e41eab4752c6de4ecf22/src/executor/graph_executor.cc#L1194

## Error Message:
/lib64/libc.so.6(+0x35250) [0x7fdc5b99b250]
/lib64/libc.so.6(getenv+0xad) [0x7fdc5b99e0cd]
/opt/amazon/lib/libmxnet.so(_ZN4dmlc6GetEnvIbEET_PKcS1_+0x1b) [0x7fdc4a1bedab]
/opt/amazon/lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor10InitOpSegsEv+0x1cb) [0x7fdc4a1b6e0b]
/opt/amazon/lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor15FinishInitGraphEN4nnvm6SymbolENS2_5GraphEPNS_8ExecutorERKSt13unordered_mapINS2_9NodeEntryENS_7NDArrayENS2_13NodeEntryHashENS2_14NodeEntryEqualESaISt4pairIKS8_S9_EEE+0x71b) [0x7fdc4a1b760b]
/opt/amazon/lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor4InitEN4nnvm6SymbolERKNS_7ContextERKSt3mapISsS4_St4lessISsESaISt4pairIKSsS4_EEERKSt6vectorIS4_SaIS4_EESL_SL_RKSt13unordered_mapISsNS2_6TShapeESt4hashISsESt8equal_toISsESaISA_ISB_SN_EEERKSM_ISsiSP_SR_SaISA_ISB_iEEES11_RKSH_INS_9OpReqType
ESaIS12_EERKSt13unordered_setISsSP_SR_SaISsEEPSH_INS_7NDArrayESaIS1C_EES1F_S1F_PSM_ISsS1C_SP_SR_SaISA_ISB_S1C_EEEPNS_8ExecutorERKSM_INS2_9NodeEntryES1C_NS2_13NodeEntryHashENS2_14NodeEntryEqualESaISA_IKS1M_S1C_EEE+0x75d) [0x7fdc4a1b958d]
/opt/amazon/lib/libmxnet.so(_ZN5mxnet8Executor10SimpleBindEN4nnvm6SymbolERKNS_7ContextERKSt3mapISsS3_St4lessISsESaISt4pairIKSsS3_EEERKSt6vectorIS3_SaIS3_EESK_SK_RKSt13unordered_mapISsNS1_6TShapeESt4hashISsESt8equal_toISsESaIS9_ISA_SM_EEERKSL_ISsiSO_SQ_SaIS9_ISA_iEEES10_RKSG_INS_9OpReqTypeESaI
S11_EERKSt13unordered_setISsSO_SQ_SaISsEEPSG_INS_7NDArrayESaIS1B_EES1E_S1E_PSL_ISsS1B_SO_SQ_SaIS9_ISA_S1B_EEEPS0_+0x1a6) [0x7fdc4a1b9f46]
/opt/amazon/lib/libmxnet.so(MXExecutorSimpleBind+0x1e38) [0x7fdc4a1031a8]
/opt/amazon/python2.7/lib/python2.7/lib-dynload/_ctypes.so(ffi_call_unix64+0x4c) [0x7fdc5af9b858]

## Minimum reproducible example
TODO

## Steps to reproduce
TODO
",Backend Bug,"['@samskalicky Thanks for identifying the thread safety issue', '@mxnet-label-bot add [Backend, Bug]', ""I found a set/get in MXNet for MXNET_CPU_WORKER_NTHREADS:\r\n![image](https://user-images.githubusercontent.com/1541993/49183630-34776180-f312-11e8-9df8-2a2295d77b43.png)\r\nSo if we're running multiple programs using MXNet on the same machine, its possible that one will be setting MXNET_CPU_WORKER_NTHREADS when the other is getting MXNET_CPU_WORKER_NTHREADS and since they both use the same libc, we're going to hit this issue."", 'FYI @KellenSunderland and @larroy ', ""@samskalicky I don't think the problem is running different processes, one process shouldn't affect the other in terms of environment and per separation of the process space. The problem is using getenv / setenv from the same process in different threads, as is the case from the code you linked."", 'Could you decode the stack trace via c++filt?', 'Looks like the evidence points to where we suspected, initialize.cc We should rework that code.', '```\r\n/lib64/libc.so.6(+0x35250) [0x7fdc5b99b250]\r\n/lib64/libc.so.6(getenv+0xad) [0x7fdc5b99e0cd]\r\n/opt/amazon/lib/libmxnet.so(ZN4dmlc6GetEnvIbEET_PKcS1+0x1b) [0x7fdc4a1bedab]\r\n/opt/amazon/lib/libmxnet.so(mxnet::exec::GraphExecutor::InitOpSegs()+0x1cb) [0x7fdc4a1b6e0b]\r\n/opt/amazon/lib/libmxnet.so(mxnet::exec::GraphExecutor::FinishInitGraph(nnvm::Symbol, nnvm::Graph, mxnet::Executor*, std::unordered_map<nnvm::NodeEntry, mxnet::NDArray, nnvm::NodeEntryHash, nnvm::NodeEntryEqual, std::allocator<std::pair<nnvm::NodeEntry const, mxnet::NDArray> > > const&)+0x71b) [0x7fdc4a1b760b]\r\n/opt/amazon/lib/libmxnet.so(mxnet::exec::GraphExecutor::Init(nnvm::Symbol, mxnet::Context const&, std::map<std::basic_string<char, std::char_traits<char>, std::allocator<char> >, mxnet::Context, std::less<std::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::basic_string<char, std::char_traits<char>, std::allocator<char> > const, mxnet::Context> > > const&, std::vector<mxnet::Context, std::allocator<mxnet::Context> > const&, std::vector<mxnet::Context, std::allocator<mxnet::Context> > const&, std::vector<mxnet::Context, std::allocator<mxnet::Context> > const&, std::unordered_map<std::basic_string<char, std::char_traits<char>, std::allocator<char> >, nnvm::TShape, std::hash<std::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::basic_string<char, std::char_traits<char>, std::allocator<char> > const, nnvm::TShape> > > const&, std::unordered_map<std::basic_string<char, std::char_traits<char>, std::allocator<char> >, int, std::hash<std::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> > > const&, std::unordered_map<std::basic_string<char, std::char_traits<char>, std::allocator<char> >, int, std::hash<std::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::basic_string<char, std::char_traits<char>, std::allocator<char> > const, int> > > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::unordered_set<std::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::hash<std::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> >*, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> >*, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> >*, std::unordered_map<std::basic_string<char, std::char_traits<char>, std::allocator<char> >, mxnet::NDArray, std::hash<std::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::basic_string<char, std::char_traits<char>, std::allocator<char> > const, mxnet::NDArray> > >*, mxnet::Executor*, std::unordered_map<nnvm::NodeEntry, mxnet::NDArray, nnvm::NodeEntryHash, nnvm::NodeEntryEqual, std::allocator<std::pair<nnvm::NodeEntry const, mxnet::NDArray> > > const&)+0x75d)\r\n[0x7fdc4a1b958d] /opt/amazon/lib/libmxnet.so(ZN5mxnet8Executor10SimpleBindEN4nnvm6SymbolERKNS_7ContextERKSt3mapISsS3_St4lessISsESaISt4pairIKSsS3_EEERKSt6vectorIS3_SaIS3_EESK_SK_RKSt13unordered_mapISsNS1_6TShapeESt4hashISsESt8equal_toISsESaIS9_ISA_SM_EEERKSL_ISsiSO_SQ_SaIS9_ISA_iEEES10_RKSG_INS_9OpReqTypeESaIS11_EERKSt13unordered_setISsSO_SQ_SaISsEEPSG_INS_7NDArrayESaIS1B_EES1E_S1E_PSL_ISsS1B_SO_SQ_SaIS9_ISA_S1B_EEEPS0+0x1a6) [0x7fdc4a1b9f46]\r\n/opt/amazon/lib/libmxnet.so(MXExecutorSimpleBind+0x1e38) [0x7fdc4a1031a8]\r\n/opt/amazon/python2.7/lib/python2.7/lib-dynload/_ctypes.so(ffi_call_unix64+0x4c) [0x7fdc5af9b858]\r\n```', ""What if we set a process wide mutex here: https://github.com/dmlc/dmlc-core/blob/600bc28bc476a1b7866cfe9f444c91b6d49760b7/include/dmlc/parameter.h#L1062\r\n\r\nand here: https://github.com/dmlc/dmlc-core/blob/600bc28bc476a1b7866cfe9f444c91b6d49760b7/include/dmlc/parameter.h#L1076\r\n\r\nShould fix the issue right?  No deadlocks? We'd have to make sure the mutex wasn't threadpool scoped as it's getting set in a new threadpool"", 'as you said, what about libraries like openmp which might access the environment variable without a lock?.  We could try monkey patching getenv with our own wrapper at link time or runtime. Best is not to use setenv after we have multiple threads running.', ""I don't think we need any mutex. We can just pass any config to the thread as data if we need. Definitely we shouldn't be using the environment to config workers."", 'In an attempt to reproduce the issue (assuming its coming from simultaneous processes initializing at the same time) I created a cpp engine unit test by modifying tests/cpp/engine/threaded_engine_test.cc and adding the following two functions:\r\n```\r\nvoid handler(int sig) {\r\n  void *array[10];\r\n  size_t size;\r\n\r\n  // get void*\'s for all entries on the stack                                                                                                                        \r\n  size = backtrace(array, 10);\r\n\r\n  // print out all the frames to stderr                                                                                                                              \r\n  fprintf(stderr, ""Error: signal %d:\\n"", sig);\r\n  backtrace_symbols_fd(array, size, STDERR_FILENO);\r\n  exit(1);\r\n}\r\n\r\nTEST(Engine, envsegfault) {\r\n  signal(SIGSEGV, handler);\r\n mxnet::Engine* engine = mxnet::engine::CreateThreadedEnginePerDevice();\r\n\r\n for (int i = 0; i < 10000; ++i) {\r\n   engine->Stop();\r\n   engine->Start();\r\n }\r\n}\r\n```\r\n\r\nThe handler attempts to capture the segfault and print the stack trace, and the envsegfault test creates a threaded engine object and repeatedly stops and starts it to trigger the SetEnv call in initialize.cc and GetEnv call in threaded_engine_perdevice.cc.\r\n\r\nThen I wrote this python script to run multiple independent processes doing this:\r\n\r\n```\r\nimport multiprocessing\r\nimport time\r\nimport os\r\n\r\ndef mxnet_worker():\r\n    for i in range(100):\r\n        ret = os.system(\'./mxnet_unit_tests  --gtest_filter=Engine.envsegfault\')\r\n        if ret != 0:\r\n            print(\'Failed@@@@@@@@@@@@@@@@\')\r\n            exit(2)\r\n\r\n\r\nread_process = [multiprocessing.Process(target=mxnet_worker) for i in range(10)]\r\nfor p in read_process:\r\n    p.daemon = True\r\n    p.start()\r\n\r\nfor p in read_process:\r\n    p.join()\r\n```\r\n\r\nI was able to trigger a segfault, but I hadnt added the handler yet to print the stack trace. I need to run again and try to reproduce again.', 'Do you think the multiple process have any impact? Env is not shared across processes.', ""process != thread.  In this case I think you mean thread.\r\n\r\nOther than that I agree with your analysis.\r\n\r\nI think we need to understand if not using this variable as in https://github.com/apache/incubator-mxnet/pull/13472  makes unwanted threads to be spawn inside the engine workers, because it might actually not be the case.\r\n\r\nDepending on that, we need to see if we need to use a different mechanism in the engine to control OMP threads, then run performance regression tests.\r\n\r\nAs you see from my PR, not changing the environment is functionally correct, but I don't know if it has performance impact because of the reason explained above."", ""I would suggest using an atomic counter in pthread_atfork that is incremented whenever we create a thread.  In this way see how many threads we are creating and printing it out and comparing two runs with, and without the variables that I removed to see if there's any difference, that would be a quick check."", 'Heres the relevant code from the version of libc (2.17) that was being used in the failure: \r\ngetenv.c: https://pastebin.com/gj4XZgdE \r\nsetenv.c: https://pastebin.com/NuTfDdDp\r\n\r\nIt looks like the issue is the __environ variable being iterated over in lines 15, 32, 55. This variable is defined in setenv.c:\r\n\r\n```\r\n#if !_LIBC\r\n# define __environ      environ\r\n# ifndef HAVE_ENVIRON_DECL\r\nextern char **environ;\r\n# endif\r\n#endif\r\n```\r\n\r\nSo there is this nasty global pointer to the environment. While setenv has a lock around changing the environment, theres no lock for getenv so (as mentioned in the block post linked in the description) :\r\n\r\n> ""this is a char**, so it\'s supposed to have a bunch of pointers to char* buffers, one for each var=val pairing. What if that region has been reused and now contains a bogus pointer into the weeds? Yep, segfault.""\r\n\r\nSo I think @KellenSunderland\'s suggestion of adding a lock/mutex in dmls parameter.h\'s GetEnv and SetEnv should prevent any failure due to MXNet\'s various threads accessing the environment simultaneously. Although without a reproducible test case we\'re unable to validate this. \r\n\r\nAnybody have any ideas for reproducing something similar to this code from the blog post with mxnet\'s engine tests so that we have a reproducible test case? \r\n\r\n```\r\n#include <stdio.h>\r\n#include <stdlib.h>\r\n#include <pthread.h>\r\n \r\nstatic void* worker(void* arg) {\r\n  for (;;) {\r\n    int i;\r\n    char var[256], *p = var;\r\n \r\n    for (i = 0; i < 8; ++i) {\r\n      *p++ = 65 + (random() % 26);\r\n    }\r\n \r\n    *p++ = \'\\0\';\r\n \r\n    setenv(var, ""test"", 1);\r\n  }\r\n \r\n  return NULL;\r\n}\r\n \r\nint main() {\r\n  pthread_t t;\r\n \r\n  printf(""start\\n"");\r\n  setenv(""foo"", ""bar"", 0);\r\n  pthread_create(&t, NULL, worker, 0);\r\n \r\n  for (;;) {\r\n    getenv(""foo"");\r\n  }\r\n \r\n  return 0;\r\n}\r\n```\r\n\r\nI tried simplifying the start_stop test https://github.com/apache/incubator-mxnet/blob/master/tests/cpp/engine/threaded_engine_test.cc#L124 for just the threaded_engine_perdevice and stop/started it a few hundred times and it didnt cause a segfault.\r\n\r\n', 'We should not use locking in the handlers in pthread_atfork, it will likely have negative impacts in terms of lock contention and performance and architecturally is not a good solution. We should find a solution using good architecture to pass the number of threads in the engine. threads get a data pointer where you can put configuration or pass any other data at creation time.', '@larroy We were already using locks inside the handlers. setenv uses a lock in libc around modifying the environment. This doesnt change anything. \r\n\r\nAre you suggesting that we dont use an EnvVar to pass the OMP_NUM_THREADS=1 to subsequent processes? What do you think the impact will be the other processes that are using MXNet using more threads?\r\n\r\nWas there a conscious decision to use an EnvVar to limit OMP_NUM_THREADS in subsequent processes?', 'The problem as provided in the article linked in this issue and related article here: https://rachelbythebay.com/w/2017/01/30/env/ is that if the main thread spawns another thread, which calls setenv and while we call setenv the process is forked, the mutex is currently in locked state in the child process and it will never be unlocked since there is no thread to release the lock which causes it to hang. \r\nThis can be replicated in MXNet in the following way. Pull the code from https://github.com/anirudh2290/mxnet/tree/setenv_issue and build it similar to the following:\r\n```\r\ncd build && cmake VERBOSE=1 -DUSE_CUDA=ON -DUSE_CUDNN=ON -DUSE_MKLDNN=ON -DUSE_OPENMP=ON -DUSE_OPENCV=OFF -DCMAKE_BUILD_TYPE=Debug -GNinja ..\r\n```\r\n\r\nRun the following script:\r\n\r\n```\r\n  import multiprocessing\r\n  import os\r\n  import sys\r\n  import mxnet as mx\r\n\r\n  def mxnet_worker():\r\n       print \'inside mxnet_worker\'\r\n\r\n  mx.base._LIB.MXStartBackgroundThread(mx.base.c_str(""dummy""))\r\n  read_process = [multiprocessing.Process(target=mxnet_worker) for i in range(8)]\r\n  for p in read_process:\r\n      p.daemon = True\r\n      p.start()\r\n      p.join()\r\n```\r\n\r\nNow run the script, you will be able to see the process hangs.\r\nWhen I attach gdb to the process I see the following:\r\n\r\n```\r\n#0  __lll_lock_wait_private () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:95\r\n#1  0x00007fc0fabab99c in __add_to_environ (name=0x7fc093a935fc ""MXNET_CPU_WORKER_NTHREADS"", value=0x7fffec2eff10 ""1"", combined=0x0,\r\n    replace=1) at setenv.c:133\r\n```\r\n\r\nwhich means it is stuck trying to acquire the lock: https://github.com/lattera/glibc/blob/master/stdlib/setenv.c#L133\r\n\r\nI checked the mxnet codebase to see if we are calling SetEnv anywhere else and we dont seem to be calling it anywhere except here. Also, pthread_at_fork statement calls `Engine::Get()->Stop()` which would mean that all engine threads are suspended. It is still possible that it could be called from other multithreaded code in MXNet iterators for example, but I couldnt find it and it is unlikely that we are not using dmlc::SetEnv but something else to set env vars for mxnet or dmlc-core code. I think it is more likely that the customer application spawned a thread, which called `SetEnv` at the same time pthread_at_fork was called which let to this behavior. ', ""Good analysis @anirudh2290 agree with it and makes sense. I would suggest we don't use environment for this and have a propper configuration object that we can pass when needed, or in the worst case, can be a singleton, what do you think?"", '@larroy Can you elaborate more on the singleton solution . For example even if its a singleton its still possible that we may fork during setenv call inside a thread and run across the same issue. Removing env variables and changing it to config would be a breaking change. I dont think we can do it before 2.0.\r\nMaybe we should understand more on the customer application and customer issue and come up with a set of guidelines when using multiprocessing with mxnet and document it for now.', '@anirudh2290 good one!\r\nI think this is problem in general. For this particular case we can try to use fork handlers:\r\npthread_at_fork(prepare, parent, child) \r\n\r\nin prepare method, we should try to set bogus env variable, which will unlock the lock and then child will get that lock in unlocked state. \r\nSomething like dmlc::setEnv(""Bogus"", ""Bogus"") here: https://github.com/apache/incubator-mxnet/blob/master/src/initialize.cc#L54\r\n', 'Thanks for the suggestion @Vikas89 . I think with your suggested change, it may be less likely to be encountered, but it is possible that mutex is in locked state in child process, if the thread calls setenv after the prepare step and before fork.', 'If there is only 2 places that too after fork where we setEnv(initialize.cc), why are we setting env ? Can we just keep these values in memory or in some file tied to this mxnet processID ?', 'I was able to run the user\'s test script and reproduce in GDB. Looks like its failing when calling getenv(""MXNET_EXEC_BULK_EXEC_INFERENCE""). This only seems to happen here:\r\n\r\nhttps://github.com/apache/incubator-mxnet/blob/5a83b6b563211f430688e41eab4752c6de4ecf22/src/executor/graph_executor.cc#L1186-L1209\r\n\r\nThis matches the original stack trace where we found it failing in GraphExecutor::InitOpSegs', ""So far, we've been able to verify that compiling mxnet without openmp does not trigger the segfault. This validates that the problem is between one thread in mxnet running openmp and another thread in mxnet calling getenv. \r\n\r\nThus the current workaround (to avoid the segfault) is to recompile mxnet without openmp. This will cause performance degredation for any operators that used to run using openmp (ie. those that are not using BLAS/LAPACK routines or MKLDNN). "", ""@Vikas89 and @anirudh2290 have discussed a couple of options for implementing a permanent solution:\r\n\r\n1. Moving all get/setenv calls to the beginning of mxnet initialization, before any openmp or any other dependent library is initialized. This would clearly prevent the problem by moving the getenv to before openmp runs. But then this may cause a breaking change with how developers are using mxnet to change its behavior using environment variables at runtime. If we only sample env vars at init time this will no longer work.\r\n\r\n2. We could write our own thread-safe getenv/setenv functions and implement them across mxnet and openmp (since we're compiling it from source when we build mxnet). This would eliminate the problem, but would be harder to maintain as we would have to constantly patch openmp\r\n\r\n3. We could create APIs to enable the behavior that users currently have when setting env vars, and with the change described in \\#1 have the same functionality albeit with a different use-model. \r\n\r\nNone of these seem like the best options, any other comments or thoughts?"", 'I think to arrive at the right solution need to understand more on the openmp behavior and why it calls the library initialize within an operator execution when an omp for loop is called. Need to also confirm if this happens only during forking but also outside forking and what specific openmp versions the customer has and if this can be reproduced on other openmp versions.', ""Good analysis.  Has anyone checked to see this problem is reproducible with all versions of OMP?  I'm wondering if another workaround that may not have a perf impact would be to use a different implementation than what is used by default."", ""Regarding option 1.  I actually think this is a good design, but several tests are currently relying on the fact that we can change behaviour via env var changes during runtime.  However, we could probably fix this be reinit'ing the library whenever we set an env var in a test.  I think we should avoid reading env vars at runtime in any case for performance reasons, so it makes sense to read these once at startup and not again after."", 'I would go for option 1.', ""Thanks @larroy @KellenSunderland @anirudh2290, just found out that the problem was due to using Intel OpenMP rather than the LLVM OpenMP submodule. Upon switching back to using LLVM OpenMP the problem did not occur. I think the problem is effectively avoided since we're not advocating for using Intel OpenMP. \r\n\r\n@TaoLv @pengzhao-intel any interest in seeing MXNet switch to Intel OpenMP and investigating this issue? Are there any perceived benefits?"", ""thanks @samskalicky It's a long thread, we need to warm up and understand the background :)  \r\n\r\n@TaoLv could you help take a look for the questions? "", '@samskalicky Can you explain more about how to use Intel OMP in MXNet and how to switch back to LLVM OMP? I think LLVM OMP is using the same runtime as Intel OMP.', ""@TaoLv according to this page: https://software.intel.com/en-us/forums/intel-c-compiler/topic/793552 they should be the same but may differ slightly as they have different release schedules. So this is a possibility that the functionality differs between a particular versions of LLVM/Intel OMP.\r\n\r\nAs for how to use it, I didnt do the building myself but I imagine that those who did simply modified the makefile to link against the Intel OMP binary rather than building the LLVM OMP submodule. Unfortunately I dont have step-by-step instructions for you. \r\n\r\nI was just hoping to see what your thoughts were on the current way MXNet is architected in regards to OMP and if what you thought could be improved (possibly by using Intel OMP). And if you had any interest in seeing MXNet switch to Intel OMP and what any benefits might be. Of course we'd still need to maintain a build without Intel OMP for other architectures."", '@samskalicky Yes. I would expect ICC + Intel OMP should have better performance and I know there is an effort ongoing for enabling them for MXNet. Currently MXNet cannot be successfully built with ICC.']",[],[],0,0
163,incubator-mxnet,3836,closed,"train faster-rcnn use two gpus, error occured like this","C:\WinPython\python-2.7.10.amd64\python.exe D:/MyCoding/DeepLearning/test_example/mxnet/example/rcnn/train_end2end.py --root_path H:\data\faster_rcnn --devkit_path H:\data\faster_rcnn\VOCdevkit --frequent 50 --kv_store local --prefix H:\data\faster_rcnn\model\faster-rcnn --pretrained H:\data\faster_rcnn\model\vgg16 --load-epoch 1
INFO:root:Namespace(devkit_path='H:\\data\\faster_rcnn\\VOCdevkit', factor_step=50000, frequent=50, gpu_ids='1,0', image_set='trainval', kv_store='local', load_epoch=1, lr=0.001, mom=0.9, monitor=False, no_flip=False, num_classes=21, num_epoch=10, prefix='H:\\data\\faster_rcnn\\model\\faster-rcnn', pretrained='H:\\data\\faster_rcnn\\model\\vgg16', resume=False, root_path='H:\\data\\faster_rcnn', test_image_set='test', wd=0.0005, work_load_list=None, year='2007')
INFO:root:########## TRAIN FASTER-RCNN WITH APPROXIMATE JOINT END2END #############
('providing maximum shape', [('data', (2, 3, 1000, 1000))], [('label', (1L, 34596L)), ('bbox_target', (1L, 36L, 62L, 62L)), ('bbox_inside_weight', (1L, 36L, 62L, 62L)), ('bbox_outside_weight', (1L, 36L, 62L, 62L)), ('gt_boxes', (2, 500))])
voc_2007_trainval gt roidb loaded from H:\data\faster_rcnn\cache\voc_2007_trainval_gt_roidb.pkl
append flipped images to roidb
prepare roidb
Traceback (most recent call last):
  File ""D:/MyCoding/DeepLearning/test_example/mxnet/example/rcnn/train_end2end.py"", line 178, in <module>
    args.work_load_list, args.resume, not args.no_flip, args.factor_step)
  File ""D:/MyCoding/DeepLearning/test_example/mxnet/example/rcnn/train_end2end.py"", line 125, in end2end_train
    arg_params=args, aux_params=auxs, begin_epoch=begin_epoch, num_epoch=num_epoch)
  File ""C:\WinPython\python-2.7.10.amd64\lib\site-packages\mxnet-0.7.0-py2.7.egg\mxnet\module\base_module.py"", line 338, in fit
    for_training=True, force_rebind=force_rebind)
  File ""D:\MyCoding\DeepLearning\test_example\mxnet\example\rcnn\rcnn\module.py"", line 137, in bind
    force_rebind=False, shared_module=None)
  File ""C:\WinPython\python-2.7.10.amd64\lib\site-packages\mxnet-0.7.0-py2.7.egg\mxnet\module\module.py"", line 282, in bind
    grad_req=grad_req, input_types=input_types)
  File ""C:\WinPython\python-2.7.10.amd64\lib\site-packages\mxnet-0.7.0-py2.7.egg\mxnet\module\executor_group.py"", line 170, in __init__
    self.label_layouts = self.decide_slices(label_shapes)
  File ""C:\WinPython\python-2.7.10.amd64\lib\site-packages\mxnet-0.7.0-py2.7.egg\mxnet\module\executor_group.py"", line 196, in decide_slices
    + (""%s has shape %s"" % (name, shape)))
AssertionError: all data must have the same batch size: batch_size = 2, but label has shape (1L, 34596L)

Process finished with exit code 1


training_end2end",,"['@precedenceguo \n', 'Updated:\r\nI may have used a wrong version before. Multi-gpus for e2e training seems ok.\r\n\r\nOriginal:\r\nYes, the e2e code in the example does not support multiple gpu training yet. We are working on that but you are welcome to contribute.', ""but i 'm always using multi-gpus for  e2e training.  @Trangle do you change the training symbol?\n"", '@tornadomeet symbol was original version, and i changed the max_label_shape list，it works in multi-gpu，but really slower than just one device\n', '@tornadomeet , I  encountered the same problem and had no change for the source code.  I want to kown how you run the program using mutil-GPUs.\n', '@hanshumin001 Maybe issues appear in some commits. I checked out the latest master and 2-gpu training works.\n', ""@precedenceguo I try the latest master, but e2e 2-gpu training can't work, AssertionError: all data must have the same batch size: batch_size = 2, but label has shape (1, 34596)"", 'tried again, still works. are we talking about the same https://github.com/dmlc/mxnet/tree/master/example/rcnn/train_end2end.py?', '@precedenceguo I copy your https://github.com/dmlc/mxnet/tree/master/example/rcnn/train_end2end.py, but still have the problem, i use the latest mxnet and i clone it today.', '@tornadomeet Hi, I remember I once saw ""AssertionError: all data must have the same batch size: batch_size = 2, but label has shape (1L, 34596L)"" but now I cannot reproduce this error as @Trangle or @KeyKy found in current mxnet. Now Trangle seems to have fixed it using ""max_label_shape"" but did not give details. Can you verify again?', 'i also fix by setting the batch size of ""max_label_shape"" to 2. I see the code and it seems that max_label_shape is used to decide slice.', ""OK I know how to reproduce the problem. Module API has changed since tornadomeet's pr several months ago. The fix is indeed to change the batch size of max_label_shape."", 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
164,incubator-mxnet,9520,open,Image augumention crash when set   MXNET_CPU_WORKER_NTHREADS bigger than 3,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
Image augumention crash when set   MXNET_CPU_WORKER_NTHREADS bigger than 3

## Environment info (Required)

----------Python Info----------
('Version      :', '2.7.6')
('Compiler     :', 'GCC 4.8.4')
('Build        :', ('default', 'Oct 26 2016 20:30:19'))
('Arch         :', ('64bit', 'ELF'))
------------Pip Info-----------
('Version      :', '9.0.1')
('Directory    :', '/usr/local/lib/python2.7/dist-packages/pip')
----------MXNet Info-----------
('Version      :', '0.12.1')
('Directory    :', '/usr/local/lib/python2.7/dist-packages/mxnet')
('Commit Hash   :', 'e0c7906693f0c79b0ce34a4d777c26a6bf1903c1')
----------System Info----------
('Platform     :', 'Linux-4.4.0-64-generic-x86_64-with-Ubuntu-14.04-trusty')
('system       :', 'Linux')
('node         :', 'meter')
('release      :', '4.4.0-64-generic')
('version      :', '#85~14.04.1-Ubuntu SMP Mon Feb 20 12:10:54 UTC 2017')
----------Hardware Info----------
('machine      :', 'x86_64')
('processor    :', 'x86_64')
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                8
On-line CPU(s) list:   0-7
Thread(s) per core:    2
Core(s) per socket:    4
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 94
Stepping:              3
CPU MHz:               4200.000
BogoMIPS:              8016.71
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              8192K
NUMA node0 CPU(s):     0-7
----------Network Test----------
Setting timeout: 10
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0072 sec, LOAD: 1.6354 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0060 sec, LOAD: 0.5680 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.1315 sec, LOAD: 0.9401 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.1766 sec, LOAD: 1.0127 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0067 sec, LOAD: 0.3688 sec.
Error open Gluon Tutorial(cn): https://zh.gluon.ai, <urlopen error [Errno 1] _ssl.c:510: error:14077410:SSL routines:SSL23_GET_SERVER_HELLO:sslv3 alert handshake failure>, DNS finished in 0.277799129486 sec.


Package used (Python/R/Scala/Julia):
Python 

## Error Message:
BLAS : Program is Terminated. Because you tried to allocate too many memory regions.

## Minimum reproducible example
`
",BLAS,"['@sandeep-krishnamurthy: Label ""BLAS"" ""Need Triaging""\r\n\r\n@yuantangliang: Are you still seeing this issue? Could you give more information on how to reproduce it. Especially ""Minimum reproducible example"" section. This helps in debugging it further. And have you started a discussion on discuss.mxnet.io . If yes, could you post that link here for any-one coming to this link? ', '@sandeep-krishnamurthy @vdantu  please refrain from manually adding ""Need Triage"" label while triaging. Thanks.']","['\r\ndefault_train_augument = {}\r\n\r\ndefault_train_augument[\'mean\'] = np.array([123.68, 116.28, 103.53])\r\ndefault_train_augument[\'rand_crop\'] = 1 # random crop 只会放大\r\ndefault_train_augument[\'rand_mirror\'] = 1\r\ndefault_train_augument[\'rand_pad\'] = 0.65 # pad 之后将图片变小\r\ndefault_train_augument[\'rand_gray\'] = 0.2\r\ndefault_train_augument[\'brightness\'] = 0.7#\r\ndefault_train_augument[\'contrast\'] = 0.7 # 是否清晰\r\ndefault_train_augument[\'saturation\'] = 0.7 #\r\ndefault_train_augument[\'pca_noise\'] = 0.7 #\r\ndefault_train_augument[\'hue\'] = 0.7 #\r\ndefault_train_augument[\'min_object_covered\'] = 0\r\ndefault_train_augument[\'aspect_ratio_range\'] =(0.8, 1.22)\r\ndefault_train_augument[\'area_range\'] =(0.3, 2.4)\r\ndefault_train_augument[\'min_eject_coverage\'] = 0.4 # 不符合条件的box将会被删除\r\n\r\nos.environ[""MXNET_CPU_WORKER_NTHREADS""] = ""%d"" % num_worker\r\n\r\ndef create_mx_det_iter():\r\n    file_name = os.path.join(RECORD_PERSON_ROOPATH, \'person_test.rec\')\r\n    id_file_name = os.path.join(RECORD_PERSON_ROOPATH, \'person_test.idx\')\r\n    iter1 = ImageDetIter(20,(3,480,640), path_imgrec=file_name, path_imgidx=id_file_name, **default_train_augument)\r\n    return iter1\r\n\r\ndef record_iterator_test_all(det_iter,batch_size=32):\r\n    import time\r\n    import mxnet as mx\r\n    mx.profiler\r\n    i = 0\r\n    det_iter.reset()\r\n    tic = time.time()\r\n    for batch in det_iter:\r\n        i+=1\r\n        print(batch_size * i / (time.time() - tic))\r\n\r\ndet_iter = create_mx_det_iter()\r\nrecord_iterator_test_all(det_iter,32)\r\n\r\n']",[],0,0
165,incubator-mxnet,13303,open,"mxnet-cpp package cross-compilation fails with OSError: ""wrong ELF class: ELFCLASS32""","## Description
mxnet-cpp package cross-compilation fails with OSError: ""wrong ELF class: ELFCLASS32""

## Environment info (Required)
Host system: Ubuntu 18.04.1 LTS  4.15.0-38-generic x86_64
Target system: ARM Cortex-A9 CPU


## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
arm-buildroot-linux-gnueabihf-gcc-7.3.0

MXNet commit hash:
85fefa8c7291b556057ae685a5883c3f6a175c18

Build config:
-DBUILD_CPP_EXAMPLES=OFF -DUSE_MKLDNN=OFF \
                -DTHREADS_PTHREAD_ARG=OFF -DUSE_OPENCV=OFF \
                -DUSE_OPENMP=OFF -DUSE_CUDA=OFF -DUSE_CUDNN=OFF \
                -DUSE_SSE=OFF -DUSE_CPP_PACKAGE=ON -DUSE_LIBJPEG_TURBO=OFF \
                -DENABLE_CUDA_RTC=OFF

## Error Message:
>>> mxnet 1.3.0 Building
....
[ 86%] Building C object CMakeFiles/mxnet.dir/dummy.c.o
[ 93%] Built target mxnet_unit_tests
[ 93%] Linking CXX shared library libmxnet.so
[ 93%] Built target mxnet
Scanning dependencies of target cpp_package_op_h
Running: OpWrapperGenerator.py
Traceback (most recent call last):
  File ""OpWrapperGenerator.py"", line 428, in <module>
    raise(e)
OSError: buildroot/output/build/mxnet-1.3.0/libmxnet.so: wrong ELF class: ELFCLASS32
cpp-package/CMakeFiles/cpp_package_op_h.dir/build.make:58: recipe for target 'cpp-package/CMakeFiles/cpp_package_op_h' failed
make[4]: *** [cpp-package/CMakeFiles/cpp_package_op_h] Error 1
CMakeFiles/Makefile2:541: recipe for target 'cpp-package/CMakeFiles/cpp_package_op_h.dir/all' failed
make[3]: *** [cpp-package/CMakeFiles/cpp_package_op_h.dir/all] Error 2

## Minimum reproducible example + Steps to reproduce
1. Configure Buildroot for target system

2. Add MxNet as a CMake Buildroot package:
MXNET_VERSION:=1.3.0
MXNET_SITE:=https://github.com/apache/incubator-mxnet.git
MXNET_SITE_METHOD = git
MXNET_GIT_SUBMODULES = YES
MXNET_INSTALL_STAGING = YES
MXNET_CONF_OPTS = -DBUILD_CPP_EXAMPLES=OFF -DUSE_MKLDNN=OFF \
                -DTHREADS_PTHREAD_ARG=OFF -DUSE_OPENCV=OFF \
                -DUSE_OPENMP=OFF -DUSE_CUDA=OFF -DUSE_CUDNN=OFF \
                -DUSE_SSE=OFF -DUSE_CPP_PACKAGE=ON -DUSE_LIBJPEG_TURBO=OFF \
                -DENABLE_CUDA_RTC=OFF
$(eval $(cmake-package))

3. Compile package

## What have you tried to solve it?

1. Checked OpWrapperGenerator.py source code. It tries to invoke Python of the *host* system (x86_64) and perform cdll.libmxnet = cdll.LoadLibrary(sys.argv[1]) for library built for *target*. Eventually host Python know nothing about ARM library format.
",ARM Build CMake,"[""@mxnet-label-bot add [Build, CMake, ARM]\r\n\r\nThank you for submitting the issue! I'm labeling it so the MXNet community members can help resolve it."", 'Yes, interesting issue. @leleamol \r\n\r\n@TeXniKK try to do the following as a workaround: \r\n\r\n* Do cmake configuration but for the host platform. It will generate the needed `op.h` file.\r\n* Remove the [following section](https://github.com/apache/incubator-mxnet/blob/master/cpp-package/CMakeLists.txt#L9-L17) from the CMakeLists.txt\r\n* Re-configure cmake for cross-compilation', '@lebeg , thanks for suggestion. I\'ve slightly modified it, because removal of whole section will cause dependency failure of several MXNet modules.\r\n\r\nThis patch helped as a workaround:\r\n\r\n```diff --git a/CMakeLists.txt b/CMakeLists.txt\r\nindex adff533..df8fa39 100644\r\n--- a/CMakeLists.txt\r\n+++ b/CMakeLists.txt\r\n@@ -299,6 +299,8 @@ include_directories(""3rdparty/tvm/include"")\r\n include_directories(""3rdparty/dmlc-core/include"")\r\n include_directories(""3rdparty/dlpack/include"")\r\n \r\n+install(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/3rdparty/nnvm/include/nnvm DESTINATION ${CMAKE_INSTALL_INCLUDEDI$\r\n+\r\n # commented out until PR goes through\r\n #if(EXISTS ${CMAKE_CURRENT_SOURCE_DIR}/3rdparty/dlpack)\r\n # add_subdirectory(3rdparty/dlpack)\r\ndiff --git a/cpp-package/CMakeLists.txt b/cpp-package/CMakeLists.txt\r\nindex f7fbc77..fbe8c86 100644\r\n--- a/cpp-package/CMakeLists.txt\r\n+++ b/cpp-package/CMakeLists.txt\r\n@@ -12,10 +12,12 @@ if(USE_CPP_PACKAGE)\r\n     MAIN_DEPENDENCY mxnet\r\n     DEPENDS mxnet ${CMAKE_CURRENT_SOURCE_DIR}/scripts/OpWrapperGenerator.py\r\n     COMMAND echo ""Running: OpWrapperGenerator.py""\r\n-    COMMAND python OpWrapperGenerator.py $<TARGET_FILE:mxnet>\r\n+#    COMMAND python OpWrapperGenerator.py $<TARGET_FILE:mxnet>\r\n     WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/scripts\r\n   )\r\n \r\n+  install(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/include/mxnet-cpp DESTINATION ${CMAKE_INSTALL_INCLUDEDIR})\r\n+\r\n   if(NOT DO_NOT_BUILD_EXAMPLES)\r\n     add_subdirectory(example)\r\n   endif()\r\ndiff --git a/cpp-package/include/mxnet-cpp/op.h b/cpp-package/include/mxnet-cpp/op.h\r\nnew file mode 100644\r\nindex 0000000..69409cd\r\n--- /dev/null\r\n+++ b/cpp-package/include/mxnet-cpp/op.h\r\n.... Copied code here.....\r\n```', ""I'm glad you nailed it."", '@lebeg yep, but still it will be nice to generate some permanent fix for it )']",['\r\nWhat to do:\r\n1. Configure Buildroot for target system\r\n\r\n2. Add MxNet as a CMake Buildroot package\r\n\r\n3. Compile package\r\n\r\n'],[],0,0
166,incubator-mxnet,6759,open,How to set MXNET_CPU_WORKER_NTHREADS in R,"	
How to set MXNET_CPU_WORKER_NTHREADS in R",R,"['You can set it just like other environmental variables.', 'I have set as Sys.setenv(MXNET_CPU_WORKER_NTHREADS = as.integer(1)) in the beginning of file and used ctx = mx.cpu() \r\n\r\nIt still takes all available COREs\r\n\r\nPlease guide how to use 6 out of 8 available core only', 'Hi,\r\nI have set as Sys.setenv(MXNET_CPU_WORKER_NTHREADS = as.integer(1)) in the beginning of file and used ctx = mx.cpu()\r\n\r\nIt still takes all available COREs\r\n\r\nPlease guide how to use 6 out of 8 available core only\r\n\r\nThank you\r\nShiv\r\n\r\nFrom: Qiang Kou (KK) [mailto:notifications@github.com]\r\nSent: Wednesday, June 21, 2017 2:09 AM\r\nTo: dmlc/mxnet <mxnet@noreply.github.com>\r\nCc: Shiv Onkar Deepak Kumar <Shiv_Kumar10@infosys.com>; Author <author@noreply.github.com>\r\nSubject: Re: [dmlc/mxnet] How to set MXNET_CPU_WORKER_NTHREADS in R (#6759)\r\n\r\n\r\nYou can set it just like other environmental variables.\r\n\r\n—\r\nYou are receiving this because you authored the thread.\r\nReply to this email directly, view it on GitHub<https://github.com/dmlc/mxnet/issues/6759#issuecomment-309884065>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AKntJT0KJfsgtfBHJYS8KJMaBKFzOCjPks5sGC3VgaJpZM4N_JW3>.\r\n', 'Can you tell me which operating system and BLAS library you are using?', 'The OS is Windows 8.1 (64 bit) and BLAS is default running on latest R version 3.4 . If detail of BLAS is required then please guide how and where to look for BLAS info', 'If you installed the prebuilt pkg provided by us, it should include openblas.\r\n\r\nYou can find how to change the number of threads in openblas from https://github.com/xianyi/OpenBLAS#set-the-number-of-threads-with-environment-variables', 'It would have helpful, is examples were given in R too.\r\n\r\nI set \r\nSys.setenv(OPENBLAS_NUM_THREADS = as.integer(1)) \r\nctx = mx.cpu()\r\n\r\nand still all COREs are utilised. Lokks like ""ctx = mx.cpu()"" overriding all setups']",[],[],0,0
167,incubator-mxnet,15138,open,Tutorial for developing advanced operators,"In the current tutorial for developing operators in mxnet, https://mxnet.incubator.apache.org/versions/master/faq/add_op_in_backend.html

But it didn't talk about FStatefulCompute and FStatefulComputeEx, which are useful for many CUDNN ops. We should add a section for these two interfaces, and when the states are kept persistent in cached_op. @zheng-da ",Doc,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Feature, Doc', ""Also the current documentation doesn't talk about temp space requests"", 'We should also mention FIgnoreInputs, FMutableInputs @haojin2 ', 'Also we should mention dynamic shape ops like @junrushao1994 did in  https://github.com/apache/incubator-mxnet/pull/13283 ']",[],[],0,0
168,incubator-mxnet,15919,open,Trainer.set_learning_rate is broken when distributed kvstore is used,"https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/gluon/trainer.py#L265-L275
When update_on_kvstore=True, Trainer.set_learning_rate does not modify the learning rate on the remote parameter server",Gluon KVStore Python,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Bug']",[],[],0,0
169,incubator-mxnet,16508,open,Distributed Training using MXNet with Horovod,"https://github.com/apache/incubator-mxnet/tree/master/example/distributed_training-horovod
the examples as follow:

$ mpirun -np 8 \
    -H server1:4,server2:4 \
    -bind-to none -map-by slot \
    -x NCCL_DEBUG=INFO \
    -mca pml ob1 -mca btl ^openib
    python train.py

this train.py means one of the (gluon_mnist.py、module_mnist.py、resnet50_imagenet.py) ?
can i use gluon_mnist.py instead of train.py?",Distributed Example,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended label(s): Example', 'Is there any examples that can be run directly? This page is too simple to write. I hope you can write some details in detail.', '@apeforest @yuxihu ', ""@gentelyang while you're waiting for a response, I'd like to share a full-fledged example in GluonNLP for BERT-pretraining with horovod. You can find it in [this page](http://gluon-nlp.mxnet.io/model_zoo/bert/index.html#run-pre-training)""]",[],[],0,0
170,incubator-mxnet,13439,open,[Test Failure] R: CPU,"Build failure error in http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/2038/pipeline

",CI Flaky R Test,"['@Chancebair Thank you for reporting the build failure. ', '@mxnet-label-bot  add [Build]', '@mxnet-label-bot add [build]', '@anirudhacharya @ankkhedia ', 'this is not a build failure. it is a flaky test failure', '@anirudhacharya - please elaborate why you think\r\n""}, ""could not find function \\""mx.ctx.default\\"""", quote(mx.ctx.default())) at R-package/tests/testthat/test_img_seg.R:157"" is a flaky test?\r\n', '@srochel Still investigating the root cause, but it is a test failure because it failed in the `make rpkgtest` step which is run after the `make rpkg`( which builds the package) is run successfully. And it is flaky because it is not consistently reproducible. \r\n\r\nBut unlike most flaky tests it does not seem to be a precision issue with output values, but I still need to root cause why the interpreter is not able to find the function `mx.ctx.default`. \r\n\r\nWhen I tried to replicate I was able to successfully run the `test_img_seg.R`( the test that is erroring out in the above issue) test locally and since this failure there have also been successful runs on the CI - http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-13467/2/pipeline', '@mxnet-label-bot update [flaky, test, r]', '@mxnet-label-bot add [CI]\r\n\r\n', ""@anirudhacharya R GPU failed in unix-gpu for unrelated PR #17542 \r\n\r\nhttp://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-17542/10/pipeline/\r\n\r\n```\r\nR-package/Makefile:32: recipe for target 'rpkgtest' failed\r\n```\r\nNot sure exactly which test failed. Any idea? Looks like flaky coz other unix-gpu builds seem to have gone fine.""]","['\r\n** testing if installed package can be loaded\r\n* DONE (mxnet)\r\n+ make rpkgtest R_LIBS=/tmp/r-site-library\r\nRscript -e \'require(testthat);res<-test_dir(""R-package/tests/testthat"");if(!testthat:::all_passed(res)){stop(""Test failures"", call. = FALSE)}\'\r\nLoading required package: testthat\r\nv | OK F W S | Context\r\ntrying URL \'https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/data/ISBI.zip\'\r\nContent type \'application/zip\' length 25275513 bytes (24.1 MB)\r\n==================================================\r\ndownloaded 24.1 MB\r\n\r\n\r\n/ |  0       | Image segmentation\r\n- |  0 1     | Image segmentation\r\nx |  0 1     | Image segmentation [2.5 s]\r\n--------------------------------------------------------------------------------\r\ntest_img_seg.R:157: error: UNET\r\ncould not find function ""mx.ctx.default""\r\n1: .handleSimpleError(function (e) \r\n   {\r\n       handled <<- TRUE\r\n       test_error <<- e\r\n       options(expressions = expressions_opt_new)\r\n       on.exit(options(expressions = expressions_opt), add = TRUE)\r\n       e$expectation_calls <- frame_calls(11, 2)\r\n       test_error <<- e\r\n       register_expectation(e)\r\n       e$handled <- TRUE\r\n       test_error <<- e\r\n   }, ""could not find function \\""mx.ctx.default\\"""", quote(mx.ctx.default())) at R-package/tests/testthat/test_img_seg.R:157\r\n']",[],0,0
171,incubator-mxnet,14203,open,[Bug]Cannot compile mxnet on windows,"os : win10 64bits
compiler : vc2015 64 bits
cuda : cuda92
commit hash: bada8a1961f0da7f01cd9e61d03f280c48083f1b

Bug 1 : openMP required int in for loop

line 515, line 580, line 607 of mxnet_op.h should change to



line 729 of utils.h should change to



line 315, 203, 218, 252 of broad_cast_reduce_inl.h

line 430 of indexing_op.cc

Bug 2 : std::min cannot find overload version

line 340, line 463 of convolution_v1-inl.h should change to 



Bug 3 : C1002 link time code generation

Finding a way to fix it, [this link](https://social.msdn.microsoft.com/Forums/sqlserver/en-US/d2c4bb60-e558-4dc6-a0ba-47611d45bc86/c1002-compiler-is-out-of-heap-space-in-pass-2?forum=vcgeneral) suggest 

""Link Time Code Generation"" should be set to ""Profile Guided Optimization - Optimization (/LTCG:PGOptimize)"" instead of being blank.

Bug 4 : Uncheck ""BUILD_CPP_EXAMPLES"" from cmake-gui, but the cpp examples still include in the project files.",Bug Build Pending Requester Info Windows,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Build', 'The project, always show me the error codes c10002\r\n\r\neven I select \r\n**Linker->Optimization->Link time code generation->""Profile Guided Optimization - Optimization (/LTCG:PGOptimize)""**\r\n\r\nAlways stuck at the function ""RspRspOp"" of elemwise_binary_op-inl.h\r\n\r\nps : Could this issue be solved before next version(version after 1.3.1) release?', '@stereomatchingkiss This issue has been fixed totally by #14877.\r\nYou could try in latest master branch.', '@mxnet-label-bot add [Pending Requester Info]']",[],"['for (int i = 0; i < static_cast<int>(N); ++i)', 'for (int i = 0; i < static_cast<int>(size); ++i) ', 'std::min<index_t>(....)']",0,0
172,incubator-mxnet,6874,open,"mx.symbol.softmax_cross_entropy() raises error ""Not enough argument to call operator softmax_cross_entropy""","## Environment info
Operating System:
This error was raised on Ubuntu 14.04, Windows 10 and Mac OS X El Capitan(10.11.6)

Compiler:
gcc / Visual Studio 2013 / clang-omp

Package used:
Python

MXNet version:
0.10.1(installed from source)

Python version and distribution:
2.7.6(installed by apt-get) for Ubuntu.
2.7.12(from python.org) for Windows and Mac OS.

## Error Message:
(on Mac OS)


## Minimum reproducible example
(this code runs fine on MXNet 0.9.5, but not on 0.10.1)


## Steps to reproduce
Just run the python code above.
",Operator,"['This can be fixed by this PR: https://github.com/dmlc/mxnet/pull/6766', 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!', 'I am using mxnet-cu80 (0.11.0rc3), the issue is reproducible with the same example code.', 'This error is still reproducible!', 'This error is still reproducible on 1.3.0.', 'This is still an issue. \r\n\r\nSteps to reproduce on mxnet 1.3.1.\r\n```python\r\ndata = mx.sym.Variable(""data"")\r\nsymbol = mx.syml.Variable(""label"")\r\n# fails below\r\nce = mx.sym.softmax_cross_entropy(name=""ce"", data=data, label=label)\r\n```']","['\r\n[00:31:44] /Users/Seal/mxnet/dmlc-core/include/dmlc/logging.h:304: [00:31:44] src/core/symbolic.cc:295: Not enough argument to call operator softmax_cross_entropy\r\n\r\nStack trace returned 5 entries:\r\n[bt] (0) 0   libmxnet.so                         0x0000000103289da5 _ZN4dmlc15LogMessageFatalD2Ev + 37\r\n[bt] (1) 1   libmxnet.so                         0x0000000104a46cf9 _ZN4nnvm6Symbol7ComposeERKN4dmlc10array_viewIPKS0_EERKNSt3__113unordered_mapINS8_12basic_stringIcNS8_11char_traitsIcEENS8_9allocatorIcEEEES4_NS8_4hashISF_EENS8_8equal_toISF_EENSD_INS8_4pairIKSF_S4_EEEEEERSL_ + 8121\r\n[bt] (2) 2   libmxnet.so                         0x0000000104a39911 NNSymbolCompose + 1345\r\n[bt] (3) 3   _ctypes.so                          0x0000000100780417 ffi_call_unix64 + 79\r\n[bt] (4) 4   ???                                 0x00007fff5fbfe6f0 0x0 + 140734799800048\r\n\r\nTraceback (most recent call last):\r\n  File ""sm_ce_test.py"", line 9, in <module>\r\n    ce = mx.symbol.softmax_cross_entropy(data=data, label=label, name=""sm"")\r\n  File ""<string>"", line 22, in softmax_cross_entropy\r\n  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/mxnet-0.10.1-py2.7.egg/mxnet/_ctypes/symbol.py"", line 120, in _symbol_creator\r\n    s._compose(name=name, **kwargs)\r\n  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/mxnet-0.10.1-py2.7.egg/mxnet/symbol.py"", line 449, in _compose\r\n    self.handle, name, num_args, keys, args))\r\n  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/mxnet-0.10.1-py2.7.egg/mxnet/base.py"", line 85, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [00:31:44] src/core/symbolic.cc:295: Not enough argument to call operator softmax_cross_entropy\r\n\r\nStack trace returned 5 entries:\r\n[bt] (0) 0   libmxnet.so                         0x0000000103289da5 _ZN4dmlc15LogMessageFatalD2Ev + 37\r\n[bt] (1) 1   libmxnet.so                         0x0000000104a46cf9 _ZN4nnvm6Symbol7ComposeERKN4dmlc10array_viewIPKS0_EERKNSt3__113unordered_mapINS8_12basic_stringIcNS8_11char_traitsIcEENS8_9allocatorIcEEEES4_NS8_4hashISF_EENS8_8equal_toISF_EENSD_INS8_4pairIKSF_S4_EEEEEERSL_ + 8121\r\n[bt] (2) 2   libmxnet.so                         0x0000000104a39911 NNSymbolCompose + 1345\r\n[bt] (3) 3   _ctypes.so                          0x0000000100780417 ffi_call_unix64 + 79\r\n[bt] (4) 4   ???                                 0x00007fff5fbfe6f0 0x0 + 140734799800048\r\n', '\r\nimport mxnet as mx\r\n\r\nctx = mx.gpu(0)\r\ndata = mx.symbol.Variable(""data"")\r\nlabel = mx.symbol.Variable(""label"")\r\ndata_nd = mx.nd.array([[1,2,3],[2,3,4]],ctx)\r\nlabel_nd = mx.nd.array([1,2],ctx)\r\n\r\nce = mx.symbol.softmax_cross_entropy(data=data, label=label, name=""sm"")\r\nexe = ce.bind(ctx=ctx, args={""data"":data_nd, ""label"":label_nd})\r\nexe.forward()\r\n']",[],0,0
173,incubator-mxnet,16960,open,large numpy array to mxnet ndarray conversion,"## Description
Conversion fails on large matrices.

### Error Message
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/ndarray/utils.py"", line 146, in array
    return _array(source_array, ctx=ctx, dtype=dtype)
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py"", line 2505, in array
    arr[:] = source_array
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py"", line 449, in __setitem__
    self._set_nd_basic_indexing(key, value)
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py"", line 715, in _set_nd_basic_indexing
    self._sync_copyfrom(value)
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py"", line 881, in _sync_copyfrom
    ctypes.c_size_t(source_array.size)))
  File ""/home/ec2-user/.local/lib/python3.6/site-packages/mxnet/base.py"", line 253, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [19:09:04] src/ndarray/ndarray_function.cc:51: Check failed: size == to->Size() (-294967296 vs. 4000000000) : copying size mismatch, from: 18446744072529682432 bytes, to: 16000000000 bytes.
Stack trace:
  [bt] (0) /home/ec2-user/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2795cb) [0x7efff4d2c5cb]
  [bt] (1) /home/ec2-user/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x259399b) [0x7efff704699b]
  [bt] (2) /home/ec2-user/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::NDArray::SyncCopyFromCPU(void const*, unsigned long) const+0x284) [0x7efff6fe5934]
  [bt] (3) /home/ec2-user/.local/lib/python3.6/site-packages/mxnet/libmxnet.so(MXNDArraySyncCopyFromCPU+0x2b) [0x7efff6d8ebcb]
  [bt] (4) /usr/lib64/libffi.so.6(ffi_call_unix64+0x4c) [0x7f0059bbacec]
  [bt] (5) /usr/lib64/libffi.so.6(ffi_call+0x1f5) [0x7f0059bba615]
  [bt] (6) /usr/lib64/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2a0) [0x7f0059dcd290]
  [bt] (7) /usr/lib64/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x9586) [0x7f0059dc6586]
  [bt] (8) /usr/lib64/libpython3.6m.so.1.0(_PyObject_FastCallDict+0x90) [0x7f0061bce7e0]


### Steps to reproduce
T= nd.array(np.random.randn(5000000,800))
(Paste the commands you ran that produced the error.)

## What have you tried to solve it?

1. workaround: If you convert in smaller chunks and concatenate the ndarray to create the final mxnet



",Bug,"['Looks like 5M > 2^32, i.e. you have more elements than a single int32 can represent.\r\n\r\nThis PR adds support for int64 number of elements: https://github.com/apache/incubator-mxnet/pull/14570\r\n\r\nBut it does it via a build-time flag USE_INT64_TENSOR_SIZE, which defaults to false.\r\n\r\nLooks like you need to build a custom version of MXNet with this flag turned on: USE_INT64_TENSOR_SIZE', '@apeforest assign @access2rohit ', '@drmasud  can you paste the output of \r\n```\r\npython -c ""from mxnet.runtime import Features; print(Features())""\r\n```', 'Here it is:\r\n\r\n[✖ CUDA, ✖ CUDNN, ✖ NCCL, ✖ CUDA_RTC, ✖ TENSORRT, ✔ CPU_SSE, ✔ CPU_SSE2, ✔ CPU_SSE3, ✔ CPU_SSE4_1, ✔ CPU_SSE4_2, ✖ CPU_SSE4A, ✔ CPU_AVX, ✖ CPU_AVX2, ✖ OPENMP, ✖ SSE, ✔ F16C, ✖ JEMALLOC, ✖ BLAS_OPEN, ✖ BLAS_ATLAS, ✖ BLAS_MKL, ✖ BLAS_APPLE, ✔ LAPACK, ✖ MKLDNN, ✔ OPENCV, ✖ CAFFE, ✖ PROFILER, ✔ DIST_KVSTORE, ✖ CXX14, ✖ INT64_TENSOR_SIZE, ✔ SIGNAL_HANDLER, ✖ DEBUG]', '@drivanov in your make file add this at the bottom\r\n```\r\nUSE_INT64_TENSOR_SIZE = 1\r\n```\r\nand build again.\r\n\r\nLet us know if that works or not.']",[],[],0,0
174,incubator-mxnet,13199,open,Namescope is None when hybridize in multi-threading environment. AttributeError: 'NoneType' object has no attribute '__exit__',"## Description
(Brief description of the problem in no more than 2 sentences.)

## Environment info (Required)



Package used (Python/R/Scala/Julia):
(I'm using Python)

## Error Message:


## Minimum reproducible example


## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

Forward once before starting the thread.
",Bug Gluon Thread Safety,"['The latest version of mxnet also have this bug.', '@mxnet-label-bot add [Gluon, Thread Safety, Bug]\r\n', '@kohillyang  \r\nThanks for submitting the issue. I have added the labels so that community members can provide the help.', ""I'm facing the same problem. Has this issue been fixed?"", 'mxnet in general is not thread safe. You can accomplish the above using multiprocessing.\r\n\r\n```python\r\nimport multiprocessing as mp\r\nimport gluoncv\r\nimport mxnet as mx\r\n\r\nnet = gluoncv.model_zoo.resnet18_v1b(pretrained=True)\r\nnet.hybridize()\r\n\r\ndef worker(module, input, outputs):\r\n    outnd = module(input)  # type: mx.nd.NDArray\r\n    outnd.wait_to_read()\r\n    outputs.put(outnd)\r\n\r\nps = []\r\noutputs = mp.Queue(5) \r\nfor i in range(3):\r\n    input1 = mx.random.randn(1, 3, 368, 368)\r\n    p = mp.Process(target=worker, args=(net, input1, outputs))\r\n    ps.append(p)\r\n\r\nfor p in ps:\r\n    p.start()\r\nfor p in ps:\r\n    p.join()\r\n\r\nwhile not outputs.empty():\r\n    print(outputs.get().shape)  \r\n```', 'But unlike pytorch, it is not possible to optimize the network if using Process instead. I found a inconvenient way to solve it is to inference once before pushing it into sub-threads. ', ""@kohillyang \r\n\r\nIn my opinion, supporting multi-threading in Python will drop the performance, because we need to add locks to keep thread-safety.\r\n\r\nI think it's better to use multi-process in Python, which has GIL and create a fake multi-threading. We could pass NDArray object through Pipe, e.g. [Gluon DataLoader](https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/gluon/data/dataloader.py#L98)\r\n\r\nCould you please provide some projects which use multi-threading to optimize a network? We may support multi-threading in Python if it is necessary. Thank you!\r\n\r\nI submited a PR just now, which may support multi-theading environment for Gluon.\r\nhttps://github.com/apache/incubator-mxnet/pull/14344\r\nBTW, in the testing case in this issue, `outputs = [None for _ in range(len(ctx_list))] `"", '@wkcn, Glad to see this issue is going to be resolved.\r\nOne case threading is needed is that when some operators are written by numpy, especially when the batch size is small, which is common in object detection. Using multi-threading can get a speed improvement of about 15% according to my test on 8x P40\r\n\r\nAnyway, At least according to my test, mxnet has already supported the multi-threading training,  for example, <https://github.com/dmlc/gluon-cv/blob/master/gluoncv/utils/parallel.py>, and <https://github.com/dmlc/gluon-cv/blob/master/scripts/segmentation/train.py> uses `parallel.py` to speed training up. There maybe no extra works need to be done.', '@kohillyang Thank you!\r\nIn Object Detection, do you mean that the proposal and proposal_target layers are custom operators, written by numpy, and using multi-threading to execute these NumPy operators parallelly can accelerate them？', 'Yes. Another case is that if some codes is written by Block rather than HybridBlock if some codes can hardly be packaged into a single Operator and asnumpy is called (sometimes because dynamic shape inference is almost impossible.).  In this case if more than one gpu are used and not using mult-threading, the network can not easily be paralleled. \r\n\r\nSince dynamic network is becoming more and more popular, I think supporting multi-threading is needed. ', '@kohillyang Hi! Could you please provide an example code to show how to run the operator written by numpy in parallel? Thanks!', 'I see. There is only one thread to execute Custom Operator.\r\nDid you modify `src/operator/custom/custom-inl.h` to support multi-threading?', ""I didn't modify src/operator/custom/custom-inl.h, but there can be more than one thread to excucte custom Operator. I mean, considering there are only one network, it has each individual copy on each GPU, so I think they can be treated several independent networks when forwarding. And if we have n GPUs, we execute n threads, one thread per one GPU,  to inference and back-propagate these networks. Then there should be n threads to execute the custom Operator. As the GIL is freed when CPP codes are executed, and to the best of my knowns, there is no lock in mxnet in this case to force Custom Operator to be executed in only one thread, using multi-threading can speed these operators up.\r\n\r\nBut I'm not sure whether mxnet forces only one thread to execute Custom Operator."", '@kohillyang \r\nI submitted a PR to support multi-threading for Custom Operator \r\nhttps://github.com/apache/incubator-mxnet/pull/14363, but I do not know how did you accelerate it without modifying custom-inl.h\r\nCould you upload your code? Did you use Python multi-threading to implement it?', '@wkcn\r\nI have to admit that I was wrong. I have tried to write a small test case and I found it is absolutely impossible to run a same CustomOp in different threads. More worse, I found my program sometimes cashes if multi-threading is used.\r\n\r\nHere is my test codes:\r\n\r\n```python\r\nimport os\r\n# os.environ[""MXNET_ENGINE_TYPE""]=""NaiveEngine""\r\nimport mxnet as mx\r\nimport time\r\nimport threading\r\nimport numpy as np\r\nimport cv2\r\nimport os\r\n\r\n\r\ncv2.setNumThreads(1)  # Sometimes we need this to avoid deadlock, especially in multi-processing environments.\r\n\r\n\r\nclass TestOP(mx.operator.CustomOp):\r\n    def __init__(self, *args, **kwargs):\r\n        super(TestOP, self).__init__(*args, **kwargs)\r\n        print(""init"")\r\n\r\n    def forward(self, is_train, req, in_data, out_data, aux):\r\n        try:\r\n            x = in_data[0].asnumpy()\r\n            print(""ss"")\r\n            x = np.ones(shape=(1024, 1024, 300))\r\n            x_resized = cv2.resize(x, (0, 0), fx=0.5, fy=0.5)\r\n            x_resized_sum = x_resized.sum()\r\n            print(\'ee\', x_resized_sum)\r\n        except Exception as e:\r\n            print(e)\r\n\r\n@mx.operator.register(""test_op"")\r\nclass TestOPProp(mx.operator.CustomOpProp):\r\n    def __init__(self):\r\n        super(TestOPProp, self).__init__()\r\n\r\n    def list_arguments(self):\r\n        return [\'x\']\r\n\r\n    def list_outputs(self):\r\n        return [\'y\']\r\n\r\n    def infer_shape(self, in_shape):\r\n        return in_shape, in_shape\r\n\r\n    def create_operator(self, ctx, shapes, dtypes):\r\n        return TestOP()\r\n\r\n\r\nctx_list = [mx.gpu(x) for x in [0, 1, 2, 3]]\r\nx_list = [mx.nd.ones(shape=(1, 2), ctx=c) for c in ctx_list]\r\n\r\ndata = mx.sym.var(name=""data"")\r\ny = mx.sym.Custom(data, op_type=""test_op"")\r\ny = mx.sym.identity(y, name=""identity"")\r\nsym_block = mx.gluon.SymbolBlock(outputs=y, inputs=data)\r\nsym_block.collect_params().reset_ctx(ctx_list)\r\n\r\n\r\ndef forward(x, ctx):\r\n    # print(""enter"", x)\r\n    re = sym_block(x)\r\n    re.wait_to_read()\r\n    # print(""exit"")\r\n    return re\r\n\r\n\r\n# for x, c in zip(x_list, ctx_list):\r\n#     forward(x, c)\r\n# mx.nd.waitall()\r\nthreads = []\r\nfor x, c in zip(x_list, ctx_list):\r\n    t = threading.Thread(target=forward, args=(x, c))\r\n    t.daemon = True\r\n    t.start()\r\n#\r\nfor t in threads:\r\n    t.join()\r\nmx.nd.waitall()\r\n```\r\n\r\nIt cashes without any Exception and outputs.\r\n\r\n', 'if line `print(""enter"", x)` is not committed, it does not crash but the cpu usage is less than 100%, and the outputs are in order so I am sure that there is only one thread to execute CustomOP. ', 'Thanks for your report! I will check it.\r\nI have closed the previous PR, since I found that it is too complex to support multi-threading. The issue is still considered.\r\nThere are some bugs when running MXNet on multi-threading or multi-process, e.g. \r\nhttps://github.com/apache/incubator-mxnet/issues/14396\r\n\r\n']","[""\r\n----------Python Info----------\r\n('Version      :', '2.7.15')\r\n('Compiler     :', 'GCC 7.2.0')\r\n('Build        :', ('default', 'May  1 2018 23:32:55'))\r\n('Arch         :', ('64bit', ''))\r\n------------Pip Info-----------\r\n('Version      :', '18.1')\r\n('Directory    :', '/home/kohill/anaconda2/lib/python2.7/site-packages/pip')\r\n----------MXNet Info-----------\r\n('Version      :', '1.3.0')\r\n('Directory    :', '/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet')\r\n('Commit Hash   :', 'b3be92f4a48bce62a5a8424271871c2f81c8f7f1')\r\n----------System Info----------\r\n('Platform     :', 'Linux-4.15.0-36-generic-x86_64-with-debian-stretch-sid')\r\n('system       :', 'Linux')\r\n('node         :', 'heils-server')\r\n('release      :', '4.15.0-36-generic')\r\n('version      :', '#39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018')\r\n----------Hardware Info----------\r\n('machine      :', 'x86_64')\r\n('processor    :', 'x86_64')\r\nArchitecture:          x86_64\r\nCPU \\u8fd0\\u884c\\u6a21\\u5f0f\\uff1a    32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                40\r\nOn-line CPU(s) list:   0-39\r\n\\u6bcf\\u4e2a\\u6838\\u7684\\u7ebf\\u7a0b\\u6570\\uff1a2\r\n\\u6bcf\\u4e2a\\u5ea7\\u7684\\u6838\\u6570\\uff1a  10\r\nSocket(s):             2\r\nNUMA \\u8282\\u70b9\\uff1a         2\r\n\\u5382\\u5546 ID\\uff1a           GenuineIntel\r\nCPU \\u7cfb\\u5217\\uff1a          6\r\n\\u578b\\u53f7\\uff1a              63\r\nModel name:            Intel(R) Xeon(R) CPU E5-2650 v3 @ 2.30GHz\r\n\\u6b65\\u8fdb\\uff1a              2\r\nCPU MHz\\uff1a             1197.546\r\nCPU max MHz:           3000.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              4591.39\r\n\\u865a\\u62df\\u5316\\uff1a           VT-x\r\nL1d \\u7f13\\u5b58\\uff1a          32K\r\nL1i \\u7f13\\u5b58\\uff1a          32K\r\nL2 \\u7f13\\u5b58\\uff1a           256K\r\nL3 \\u7f13\\u5b58\\uff1a           25600K\r\nNUMA node0 CPU(s):     0-9,20-29\r\nNUMA node1 CPU(s):     10-19,30-39\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm cpuid_fault epb invpcid_single pti intel_ppin ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts flush_l1d\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0046 sec, LOAD: 0.8261 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0039 sec, LOAD: 3.3043 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.3213 sec, LOAD: 1.9182 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0029 sec, LOAD: 0.6460 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0032 sec, LOAD: 1.9723 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.5289 sec, LOAD: 1.0473 sec.\r\n\r\n\r\n"", '\r\n/home/kohill/anaconda2/bin/python /home/kohill/Desktop/mx-detection/bug_example.py\r\nModel file is not found. Downloading.\r\nDownloading /home/kohill/.mxnet/models/resnet18_v1b-2d9d980c.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet18_v1b-2d9d980c.zip...\r\n42433KB [00:46, 909.00KB/s]                            \r\n/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py:421: UserWarning: load_params is deprecated. Please use load_parameters.\r\n  warnings.warn(""load_params is deprecated. Please use load_parameters."")\r\nException in thread Thread-5:\r\nTraceback (most recent call last):\r\n  File ""/home/kohill/anaconda2/lib/python2.7/threading.py"", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File ""/home/kohill/anaconda2/lib/python2.7/threading.py"", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File ""/home/kohill/Desktop/mx-detection/bug_example.py"", line 10, in worker\r\n    outnd = module(inputs)  # type: mx.nd.NDArray\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 541, in __call__\r\n    out = self.forward(*args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 908, in forward\r\n    return self._call_cached_op(x, *args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 798, in _call_cached_op\r\n    self._build_cache(*args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 750, in _build_cache\r\n    data, out = self._get_graph(*args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 742, in _get_graph\r\n    out = self.hybrid_forward(symbol, *grouped_inputs, **params)  # pylint: disable=no-value-for-parameter\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 85, in __exit__\r\n    self._name_scope.__exit__(ptype, value, trace)\r\nAttributeError: \'NoneType\' object has no attribute \'__exit__\'\r\n\r\nException in thread Thread-3:\r\nTraceback (most recent call last):\r\n  File ""/home/kohill/anaconda2/lib/python2.7/threading.py"", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File ""/home/kohill/anaconda2/lib/python2.7/threading.py"", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File ""/home/kohill/Desktop/mx-detection/bug_example.py"", line 10, in worker\r\n    outnd = module(inputs)  # type: mx.nd.NDArray\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 541, in __call__\r\n    out = self.forward(*args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 908, in forward\r\n    return self._call_cached_op(x, *args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 798, in _call_cached_op\r\n    self._build_cache(*args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 750, in _build_cache\r\n    data, out = self._get_graph(*args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 742, in _get_graph\r\n    out = self.hybrid_forward(symbol, *grouped_inputs, **params)  # pylint: disable=no-value-for-parameter\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 85, in __exit__\r\n    self._name_scope.__exit__(ptype, value, trace)\r\nAttributeError: \'NoneType\' object has no attribute \'__exit__\'\r\n\r\nException in thread Thread-4:\r\nTraceback (most recent call last):\r\n  File ""/home/kohill/anaconda2/lib/python2.7/threading.py"", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File ""/home/kohill/anaconda2/lib/python2.7/threading.py"", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File ""/home/kohill/Desktop/mx-detection/bug_example.py"", line 10, in worker\r\n    outnd = module(inputs)  # type: mx.nd.NDArray\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 541, in __call__\r\n    out = self.forward(*args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 908, in forward\r\n    return self._call_cached_op(x, *args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 798, in _call_cached_op\r\n    self._build_cache(*args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 750, in _build_cache\r\n    data, out = self._get_graph(*args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 742, in _get_graph\r\n    out = self.hybrid_forward(symbol, *grouped_inputs, **params)  # pylint: disable=no-value-for-parameter\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/gluoncv/model_zoo/resnetv1b.py"", line 235, in hybrid_forward\r\n    x = self.conv1(x)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 541, in __call__\r\n    out = self.forward(*args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 925, in forward\r\n    return self.hybrid_forward(symbol, x, *args, **params)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 85, in __exit__\r\n    self._name_scope.__exit__(ptype, value, trace)\r\nAttributeError: \'NoneType\' object has no attribute \'__exit__\'\r\n\r\nException in thread Thread-2:\r\nTraceback (most recent call last):\r\n  File ""/home/kohill/anaconda2/lib/python2.7/threading.py"", line 801, in __bootstrap_inner\r\n    self.run()\r\n  File ""/home/kohill/anaconda2/lib/python2.7/threading.py"", line 754, in run\r\n    self.__target(*self.__args, **self.__kwargs)\r\n  File ""/home/kohill/Desktop/mx-detection/bug_example.py"", line 10, in worker\r\n    outnd = module(inputs)  # type: mx.nd.NDArray\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 541, in __call__\r\n    out = self.forward(*args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 908, in forward\r\n    return self._call_cached_op(x, *args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 798, in _call_cached_op\r\n    self._build_cache(*args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 750, in _build_cache\r\n    data, out = self._get_graph(*args)\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 742, in _get_graph\r\n    out = self.hybrid_forward(symbol, *grouped_inputs, **params)  # pylint: disable=no-value-for-parameter\r\n  File ""/home/kohill/anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 85, in __exit__\r\n    self._name_scope.__exit__(ptype, value, trace)\r\nAttributeError: \'NoneType\' object has no attribute \'__exit__\'\r\n\r\n\r\nProcess finished with exit code 0\r\n\r\n', 'python\r\nimport gluoncv\r\nimport threading\r\nimport mxnet as mx\r\nnet = gluoncv.model_zoo.resnet18_v1b(pretrained=True)\r\nnet.hybridize()\r\nctx_list = [mx.gpu(x) for x in [0,1,2,3]]\r\n\r\n\r\ndef worker(module, inputs, i, lock,  outputs):\r\n    outnd = module(inputs)  # type: mx.nd.NDArray\r\n    outnd.wait_to_read()\r\n    with lock:\r\n        outputs[i] = outnd\r\n\r\n\r\nthreads = []\r\noutputs = []\r\nlock = threading.Lock()\r\nfor i in range(len(ctx_list)):\r\n    thread = threading.Thread(target=worker, args=(net, mx.random.randn(1, 3, 368, 368), i, lock, outputs))\r\n    threads.append(thread)\r\n\r\nfor thread in threads:\r\n    thread.start()\r\nfor thread in threads:\r\n    thread.join()\r\n\r\n']",[],0,0
175,incubator-mxnet,9381,open,(Flaky?) perl test failure ,"I'm looking at the build status for each commit on MXNet master and noticed that perl test failed once a few weeks ago. Was this already fixed? @sergeykolychev 


http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/74/pipeline ",Flaky Test,"['```\r\nFailed test at t/test_loss.t line 233.\r\nLooks like you failed 1 test of 24.\r\n```', ""Was not aware of this, I'll fix this asap."", 'Should be fixed by https://github.com/apache/incubator-mxnet/pull/9414', 'Hey @sergeykolychev , this is still occuring: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-11358/19/pipeline/744', ""@marcoabreu I'll add static seed to these tests in the PR that I have open right now. Thanks."", ""Would it be possible to track the issue down? Our experience showed that setting a fixed seed often masks an actual bug in our implementation. I'd appreciate it very much if you wouldn't mind :)"", ""@marcoabreu I've take a look, but these particular tests do need a pre-set seed.\r\nThese tests are essentially a set of network trainings and expect a specific loss value for any random initialization is probably asking too much. I am fairly sure there's no bug in perl implementation that causes this. "", 'ok, thanks for looking into it!', '@sergeykolychev thanks for the explanation. Would be great if you can follow up with the static seed to ensure the test is not flaky. Thanks!', 'http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-cpu/detail/PR-13819/4/pipeline/235/\r\nAdd one datapoint', 'Another data point for PR #15953 - http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-\r\nvalidation%2Funix-gpu/detail/PR-15953/7/pipeline/\r\n', ""@ChaiBapchya Thank you for the report, I'll take a look.""]","['\r\nTest Summary Report\r\n\r\n-------------------\r\n\r\nt/test_loss.t             (Wstat: 256 Tests: 24 Failed: 1)\r\n\r\n  Failed test:  21\r\n\r\n  Non-zero exit status: 1\r\n\r\nFiles=27, Tests=6721, 123 wallclock secs ( 0.77 usr  0.24 sys + 348.20 cusr 744.50 csys = 1093.71 CPU)\r\n\r\n']",[],0,0
176,incubator-mxnet,16214,open,test_sync_batchnorm failure on p3.8xlarge,"test_sync_batchnorm behaves differently when there are different number of gpu devices on the machine. It fails on p3.8xlarge but when num_devices are 1 or 2, the test passes.

",CI Test,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended label(s): Test']",['\r\nnosetests3 -v tests/python/gpu/test_gluon_gpu.py:test_sync_batchnorm\r\n'],[],0,0
177,incubator-mxnet,14681,open,suggestion: a different random dataloader,"Currently, the best(?) way to load huge dataset in mxnet is implement a dataloader. However, this need the ability to easily random access the ""i-th"" example, becauce ""__index__"" need to be overwrite.

Huge data(too huge to save on disk) usually stored in remote side (example hdfs) with several small datapart. Each datapart which can be easily load in to memory contains maybe millions of examples. So random access is difficult because this need the ability of random access different datapart and the datapart were saved in hdfs.

I think a good Dataloader for this situation is:
 1. First random choose a datapart
 2. Shuffle the small datapart
 3. train

 
",Feature request,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Feature', '@gramce thank you for your feature request\r\n\r\n@mxnet-label-bot add [Feature Request]', 'The sampler of dataloader maybe useful.']",[],[],0,0
178,incubator-mxnet,15112,open,[Feature Request] Make mxnet be available to published by PyInstaller,"**PyInstaller** bundles a Python application and all its dependencies into a single package. It support Windows/Linux and Mac OS. We can publish our app rapidly on these platforms by PyInstaller.
However, mxnet cannot be packaged as a dependency. So I think we should make MXNet to be compatible with PyInstaller.
P.S:  and  can be directly packaged with PyInstaller. I've tested on Windows.",Feature request,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Feature', '@mxnet-label-bot add [feature request]']","['Ten*flow', 'Pyt*ch']",[],0,0
179,incubator-mxnet,13838,open,[OSX] Brew install opencv breaks master,"Brew has updated opencv so that when you do  you get opencv4 which is not compatible with current master.

All of the current install docs for OSX say to use  as a prereq - so this will impact new users trying out MXNet.

It is particularly problematic because there is no way to brew install the 3.4 version - details are here https://github.com/Homebrew/homebrew-core/issues/35869

There is currently a PR in the works to address the compatibility with opencv 4.0 
https://github.com/apache/incubator-mxnet/pull/13559. This issue is to raise the awareness that it is impacting the project now.",Build OSX OpenCV,"['@mxnet-label-bot add [Build, OpenCV]', 'There is now a opencv@3 available :)\r\n\r\n```\r\n$ brew search opencv\r\n==> Formulae\r\nopencv ✔               opencv@2 ✔             opencv@3\r\n```']",[],"['brew install opencv', 'brew install opencv']",0,0
180,incubator-mxnet,14366,open,Flaky test test_with_random_seed,"Appeared in https://github.com/apache/incubator-mxnet/pull/14321 
See logs at
- http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Fcentos-gpu/detail/PR-14321/6/pipeline 
- http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-14321/5/pipeline 
",Flaky Test,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Test, Flaky', '@mxnet-label-bot Update [Flaky, Test]']","['\r\ntest_operator_gpu.test_with_random_seed ... [INFO] Setting test np/mx/python random seeds, use MXNET_TEST_SEED=745702041 to reproduce.\r\n\r\nERROR\r\n']",[],0,0
181,incubator-mxnet,9436,open,Support boolean outputs for topk operator,"## Description
Output from topk operator is positional 0s and 1s. It would be more standard with Numpy NDArray and other DL framework, if the return values are Boolean (True / False).

Similarly, since MXNet NDArray wants to be closer to behavior of Numpy NDArray operations, it would be good to support Boolean types as output for conditional operators.

This functionality will also help Apache MXNet backend for Keras2",Feature request Keras,[],[],[],0,0
182,incubator-mxnet,17033,open,AttributeError: 'NoneType' object has no attribute 'MXNDArrayFree',"## Description
(A clear and concise description of what the bug is.)

Hello, i am using Cython to generate dynamic library files of mxnet project. But if i run my project through these dymanic library files, the problem AttributeError: 'NoneType' object has no attribute 'MXNDArrayFree' sometimes occurs, exactly the problem does not always come up.  It is strange that the problem comes up after all my code was executed.

Cython version 0.29.14
python version 3.5.2
mxnet version 1.5.1.post0

### Error Message
(Paste the complete error message, including stack trace.)

Exception ignored in: <object repr() failed>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/_ctypes/ndarray.py"", line 51, in __del__
AttributeError: 'NoneType' object has no attribute 'MXNDArrayFree'
Exception ignored in: <object repr() failed>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/_ctypes/ndarray.py"", line 51, in __del__
AttributeError: 'NoneType' object has no attribute 'MXNDArrayFree'
Exception ignored in: <object repr() failed>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/mxnet/_ctypes/ndarray.py"", line 51, in __del__
AttributeError: 'NoneType' object has no attribute 'MXNDArrayFree'

## To Reproduce
(If you developed your own code, please provide a short script that reproduces the error. For existing examples, please provide link.)

### Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.

## Environment

We recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:

",Bug Pending Requester Info,['@hnuhchen Thanks for submitting the issue. Is it possible to post a minimal reproducible example? That will help us solve the problem.'],['\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n\r\n# paste outputs here\r\n'],[],0,0
183,incubator-mxnet,12062,open,DMLC_PS_ROOT_URI using hostname failed in distributed training,"
## Description
DMLC_PS_ROOT_URI is ip or hostname , but when use the hostname instead of ip , it reports ""bind failed"" in the src/van.cc

## Environment info (Required)



Package used (Python/R/Scala/Julia):
python


## Build info (Required if built from source)

gcc

MXNet commit hash:
3df9bf802021d5aa67c609c6736acee94aaf3a48

Build config:
the same as doc https://mxnet.apache.org/install/index.html?platform=Linux&language=Python&processor=CPU

## Error Message:
(Paste the complete error message, including stack trace.)

[17:46:11] /home/tusimple/incubator-mxnet/dmlc-core/include/dmlc/./logging.h:308: [17:46:11] src/van.cc:76: Check failed: (my_node_.port) != (-1) bind failed

Stack trace returned 10 entries:
[bt] (0) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f1a283f624c]
[bt] (1) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps3Van5StartEv+0x91f) [0x7f1a2af45b8f]
[bt] (2) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps6ZMQVan5StartEv+0x4a) [0x7f1a2af504fa]
[bt] (3) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps10Postoffice5StartEPKcb+0x1e9) [0x7f1a2af42119]
[bt] (4) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN5mxnet7kvstore11KVStoreDist9RunServerERKSt8functionIFviRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE+0x1c5) [0x7f1a2aee1c35]
[bt] (5) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(MXKVStoreRunServer+0x4b) [0x7f1a2ae629db]
[bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f1a41450e40]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x2eb) [0x7f1a414508ab]
[bt] (8) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48f) [0x7f1a416603df]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x11d82) [0x7f1a41664d82]

Traceback (most recent call last):
  File ""train_mnist.py"", line 25, in <module>
    from common import find_mxnet, fit
  File ""/home/tusimple/incubator-mxnet/example/image-classification/common/find_mxnet.py"", line 20, in <module>
    import mxnet as mx
  File ""/home/tusimple/incubator-mxnet/example/image-classification/mxnet/__init__.py"", line 56, in <module>
    from . import kvstore_server
  File ""/home/tusimple/incubator-mxnet/example/image-classification/mxnet/kvstore_server.py"", line 85, in <module>
    _init_kvstore_server_module()
  File ""/home/tusimple/incubator-mxnet/example/image-classification/mxnet/kvstore_server.py"", line 82, in _init_kvstore_server_module
    server.run()
  File ""/home/tusimple/incubator-mxnet/example/image-classification/mxnet/kvstore_server.py"", line 73, in run
    check_call(_LIB.MXKVStoreRunServer(self.handle, _ctrl_proto(self._controller()), None))
  File ""/home/tusimple/incubator-mxnet/example/image-classification/mxnet/base.py"", line 146, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [17:46:11] src/van.cc:76: Check failed: (my_node_.port) != (-1) bind failed

Stack trace returned 10 entries:
[bt] (0) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f1a283f624c]
[bt] (1) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps3Van5StartEv+0x91f) [0x7f1a2af45b8f]
[bt] (2) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps6ZMQVan5StartEv+0x4a) [0x7f1a2af504fa]
[bt] (3) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN2ps10Postoffice5StartEPKcb+0x1e9) [0x7f1a2af42119]
[bt] (4) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(_ZN5mxnet7kvstore11KVStoreDist9RunServerERKSt8functionIFviRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEE+0x1c5) [0x7f1a2aee1c35]
[bt] (5) /home/tusimple/incubator-mxnet/example/image-classification/mxnet/libmxnet.so(MXKVStoreRunServer+0x4b) [0x7f1a2ae629db]
[bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f1a41450e40]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x2eb) [0x7f1a414508ab]
[bt] (8) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48f) [0x7f1a416603df]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x11d82) [0x7f1a41664d82]

## Minimum reproducible example
1 scheduler 1 server 1 worker

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.export DMLC_PS_ROOT_URI=tusimple-System-Product-Name; export DMLC_ROLE=scheduler; export DMLC_PS_ROOT_PORT=9001; export DMLC_NUM_WORKER=1; export DMLC_NUM_SERVER=1;
2.python train_mnist.py

## What have you tried to solve it?

1.i replaced the DMLC_PS_ROOT_URI with ip and it works well
",Backend Distributed,"['@mxnet-label-bot could you please add [Backend] here?', 'I think this is actually an issue of zmq, used in ps-lite. Zmq can only take ip address to find network interface. Using hostname will fail. \r\nPlease take a look at the discussion here:\r\nhttps://stackoverflow.com/questions/6024003/why-doesnt-zeromq-work-on-localhost', 'thanks!', '@mxnet-label-bot add[Distributed]']","[""\r\n----------Python Info----------\r\n('Version      :', '2.7.12')\r\n('Compiler     :', 'GCC 5.4.0 20160609')\r\n('Build        :', ('default', 'Dec  4 2017 14:50:18'))\r\n('Arch         :', ('64bit', 'ELF'))\r\n------------Pip Info-----------\r\n('Version      :', '10.0.1')\r\n('Directory    :', '/usr/local/lib/python2.7/dist-packages/pip')\r\n----------MXNet Info-----------\r\n('Version      :', '1.0.0')\r\n('Directory    :', '/home/tusimple/incubator-mxnet/python/mxnet')\r\nHashtag not found. Not installed from pre-built package.\r\n----------System Info----------\r\n('Platform     :', 'Linux-4.4.0-130-generic-x86_64-with-Ubuntu-16.04-xenial')\r\n('system       :', 'Linux')\r\n('node         :', 'tusimple-System-Product-Name')\r\n('release      :', '4.4.0-130-generic')\r\n('version      :', '#156-Ubuntu SMP Thu Jun 14 08:53:28 UTC 2018')\r\n----------Hardware Info----------\r\n('machine      :', 'x86_64')\r\n('processor    :', 'x86_64')\r\nArchitecture:          x86_64\r\nCPU 运行模式：    32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                8\r\nOn-line CPU(s) list:   0-7\r\n每个核的线程数：2\r\n每个座的核数：  4\r\nSocket(s):             1\r\nNUMA 节点：         1\r\n厂商 ID：           GenuineIntel\r\nCPU 系列：          6\r\n型号：              94\r\nModel name:            Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz\r\n步进：              3\r\nCPU MHz：             4200.156\r\nCPU max MHz:           4200.0000\r\nCPU min MHz:           800.0000\r\nBogoMIPS:              8015.57\r\n虚拟化：           VT-x\r\nL1d 缓存：          32K\r\nL1i 缓存：          32K\r\nL2 缓存：           256K\r\nL3 缓存：           8192K\r\nNUMA node0 CPU(s):     0-7\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt ibrs ibpb stibp kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0007 sec, LOAD: 1.5099 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.2137 sec, LOAD: 3.8772 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.2147 sec, LOAD: 1.0284 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0100 sec, LOAD: 0.7743 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0097 sec, LOAD: 2.1807 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0098 sec, LOAD: 1.6313 sec.\r\n\r\n""]",[],0,0
184,incubator-mxnet,7080,open,simple_bind elemwise_add with group2ctx fails,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: AWS Deep Learning AMI

Package used (Python/R/Scala/Julia): python

Or if installed from source:

MXNet commit hash ():  8c81ee48c197dd66276fa8d4008cbad0dcd2c8fb

If you are using python package, please provide 

Python version and distribution: python 2.7


## Error Message:
Please paste the full error message, including stack trace.



## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. run the following code:


## What have you tried to solve it?

1. This is due to the recent change of using (src/operator/elemwise_op_common.h) for  backward pass which reduces the number of copies. This however, failed to copy the gradient across devices. It could probably solved by registering  attribute for inplace updates. 
",Bug,"[""This seems tricky :-(... I don't think we have information of device placement during graph construction and that's when we choose to do CloneGradient method. @piiswrong Any ideas how to work around that? Is there a device placement pass in NNVM that we could use for making a copy node (or any pass that knows about devices)?"", ""@eric-haibin-lin you are right, I just verified the perl test is failing on the master branch as well and it's likely related to this issue. I'll be removing this perl test from the master branch via another pull request until the issue is fixed. You can go ahead with merging my pull for your sparse branch. "", '@sergeykolychev thanks!', '@ptrendx are you referring to the place_device pass? \r\nhttps://github.com/dmlc/nnvm/blob/master/src/pass/place_device.cc', '@eric-haibin-lin requesting an update on this bug, has this been resolved?', '@vrakesh No. The example is already posted above and you should be able to reproduce it. ']","['\r\n.[22:46:08] /home/ubuntu/upstream-gpu/dmlc-core/include/dmlc/logging.h:304: [22:46:08] src/executor/graph_executor.cc:340: Check failed: device[nid] == devid (0 vs. 1) device of sam\r\ne output not equal to each other\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /home/ubuntu/upstream-gpu/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f0bf44d8abc]\r\n[bt] (1) /home/ubuntu/upstream-gpu/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet4exec13AssignContextEN4nnvm5GraphERKNS_7ContextERKSt3mapISsS3_St4lessISsESaISt4pairIKSsS3_EEERKSt6vect\r\norIS3_SaIS3_EESK_SK_mm+0x12df) [0x7f0bf51fd25f]\r\n[bt] (2) /home/ubuntu/upstream-gpu/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor9InitGraphEN4nnvm6SymbolERKNS_7ContextERKSt3mapISsS4_St4lessISsESaISt4pairIKSsS4_E\r\nEERKSt6vectorIS4_SaIS4_EESL_SL_RKSH_INS_9OpReqTypeESaISM_EE+0xaf) [0x7f0bf5206f4f]\r\n[bt] (3) /home/ubuntu/upstream-gpu/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor4InitEN4nnvm6SymbolERKNS_7ContextERKSt3mapISsS4_St4lessISsESaISt4pairIKSsS4_EEERK$\r\nt6vectorIS4_SaIS4_EESL_SL_RKSt13unordered_mapISsNS2_6TShapeESt4hashISsESt8equal_toISsESaISA_ISB_SN_EEERKSM_ISsiSP_SR_SaISA_ISB_iEEERKSH_INS_9OpReqTypeESaIS12_EERKSt13unordered_setI$\r\nsSP_SR_SaISsEEPSH_INS_7NDArrayESaIS1C_EES1F_S1F_PSM_ISsS1C_SP_SR_SaISA_ISB_S1C_EEEPNS_8ExecutorERKSM_INS2_9NodeEntryES1C_NS2_13NodeEntryHashENS2_14NodeEntryEqualESaISA_IKS1M_S1C_EE$\r\n+0xa0) [0x7f0bf5208c30]\r\n[bt] (4) /home/ubuntu/upstream-gpu/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet8Executor10SimpleBindEN4nnvm6SymbolERKNS_7ContextERKSt3mapISsS3_St4lessISsESaISt4pairIKSsS3_EEERKSt6v$\r\nctorIS3_SaIS3_EESK_SK_RKSt13unordered_mapISsNS1_6TShapeESt4hashISsESt8equal_toISsESaIS9_ISA_SM_EEERKSL_ISsiSO_SQ_SaIS9_ISA_iEEERKSG_INS_9OpReqTypeESaIS11_EERKSt13unordered_setISsSO$\r\nSQ_SaISsEEPSG_INS_7NDArrayESaIS1B_EES1E_S1E_PSL_ISsS1B_SO_SQ_SaIS9_ISA_S1B_EEEPS0_+0x194) [0x7f0bf5209934]\r\n[bt] (5) /home/ubuntu/upstream-gpu/python/mxnet/../../lib/libmxnet.so(MXExecutorSimpleBind+0x2221) [0x7f0bf5198991]\r\n[bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f0c080caadc]\r\n[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f0c080ca40c]\r\n[bt] (8) /usr/lib/python3.4/lib-dynload/_ctypes.cpython-34m-x86_64-linux-gnu.so(_ctypes_callproc+0x21d) [0x7f0c082dc12d]\r\n[bt] (9) /usr/lib/python3.4/lib-dynload/_ctypes.cpython-34m-x86_64-linux-gnu.so(+0xf6a3) [0x7f0c082dc6a3]\r\n', ""\r\n    with mx.AttrScope(ctx_group='stage1'):\r\n        lhs = mx.symbol.Variable('lhs')\r\n        rhs = mx.symbol.Variable('rhs')\r\n        plus  = mx.symbol.elemwise_add(lhs, rhs, name='plus')\r\n\r\n    set_stage1 = set(plus.list_arguments())\r\n    with mx.AttrScope(ctx_group='stage2'):\r\n        softmax  = mx.symbol.SoftmaxOutput(data = plus, name = 'softmax')\r\n\r\n    set_stage2 = set(softmax.list_arguments()) - set_stage1\r\n\r\n    group2ctx = {\r\n        'stage1' : mx.cpu(1),\r\n        'stage2' : mx.cpu(2)\r\n    }\r\n    texec = softmax.simple_bind(mx.cpu(0), group2ctx=group2ctx, lhs=(1,200), rhs=(1,200))\r\n""]","['git rev-parse HEAD', 'CloneGradient', 'elemwise_add', 'inplace_identity']",0,0
185,incubator-mxnet,10968,open,[Discussion][NDArray]Discuss about NDArray::Save and NDArray::Load,"    There seems to be some mistakes in NDArray::Save(dmlc::Stream *strm) (File: ndarray.cc, Line: 1587~1651) and NDArray::Load(dmlc::Stream *strm) (File:ndarray.cc, Line: 1700~1781). 
    This issue may cause a CUDA: invalid device ordinal with following two steps:
        1. Save a ndarray on gpu(1) in a machine with two gpu card;
        2. Load the ndarray in another machine with only one gpu card the program.

    I find the problem is that in function NDArray::Save the context of ndarray will be saved into stream  and in function   NDArray::Load the data loaded into memory will be converted to the context saved by  NDArray::Save. Why the context is saved in NDArray::Save? To improve portability of saved params, I think it's better to remove these operations to avoid load ndarray in specific device while initializing. ",Discussion NDArray,['@sandeep-krishnamurthy Could you please tag this issue as Discussion and NDArray'],[],[],0,0
186,incubator-mxnet,16319,open,[python docs] multiple broken cross links in tutorials,"## Description

Sphinx builds of the Python API docs have the following warning(s):


## How to reproduce
You can run into the problem following these steps.

1. Run a ""lite"" binary build.


2. Run the Python API docs build:
",Website,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended label(s): Doc']","[""\r\n/work/mxnet/docs/python_docs/python/build/tutorials/getting-started/crash-course/5-predict.ipynb:72: WARNING: File not found: 'tutorials/getting-started/crash-course/train.md'\r\n/work/mxnet/docs/python_docs/python/build/tutorials/getting-started/crash-course/6-use_gpus.ipynb:214: WARNING: File not found: 'tutorials/getting-started/crash-course/predict.md'\r\n/work/mxnet/docs/python_docs/python/build/tutorials/packages/gluon/loss/custom-loss.ipynb:70: WARNING: File not found: '/api/python/docs/api/gluon/_autogen/mxnet.gluon.loss.L1Loss.html'\r\n/work/mxnet/docs/python_docs/python/build/tutorials/packages/gluon/loss/custom-loss.ipynb:70: WARNING: File not found: '/api/python/docs/api/gluon/_autogen/mxnet.gluon.loss.L2Loss.html'\r\n/work/mxnet/docs/python_docs/python/build/tutorials/packages/gluon/loss/custom-loss.ipynb:71: WARNING: File not found: '/api/python/docs/api/gluon/_autogen/mxnet.gluon.loss.SigmoidBinaryCrossEntropyLoss.html'\r\n/work/mxnet/docs/python_docs/python/build/tutorials/packages/gluon/loss/custom-loss.ipynb:71: WARNING: File not found: '/api/python/docs/api/gluon/_autogen/mxnet.gluon.loss.SoftmaxBinaryCrossEntropyLoss.html'\r\n/work/mxnet/docs/python_docs/python/build/tutorials/packages/gluon/loss/custom-loss.ipynb:72: WARNING: File not found: '/api/python/docs/api/gluon/_autogen/mxnet.gluon.loss.HingeLoss.html'\r\n/work/mxnet/docs/python_docs/python/build/tutorials/packages/gluon/loss/custom-loss.ipynb:269: WARNING: image file not readable: tutorials/packages/gluon/loss/images/inuktitut_1.png\r\n/work/mxnet/docs/python_docs/python/build/tutorials/packages/gluon/loss/custom-loss.ipynb:372: WARNING: image file not readable: tutorials/packages/gluon/loss/images/inuktitut_2.png\r\n/work/mxnet/docs/python_docs/python/build/tutorials/packages/gluon/loss/loss.ipynb:70: WARNING: File not found: '/api/python/docs/api/gluon/_autogen/mxnet.gluon.loss.L1Loss.html'\r\n/work/mxnet/docs/python_docs/python/build/tutorials/packages/gluon/loss/loss.ipynb:70: WARNING: File not found: '/api/python/docs/api/gluon/_autogen/mxnet.gluon.loss.L2Loss.html'\r\n/work/mxnet/docs/python_docs/python/build/tutorials/packages/gluon/loss/loss.ipynb:71: WARNING: File not found: '/api/python/docs/api/gluon/_autogen/mxnet.gluon.loss.SigmoidBinaryCrossEntropyLoss.html'\r\n/work/mxnet/docs/python_docs/python/build/tutorials/packages/gluon/loss/loss.ipynb:71: WARNING: File not found: '/api/python/docs/api/gluon/_autogen/mxnet.gluon.loss.SoftmaxBinaryCrossEntropyLoss.html'\r\n/work/mxnet/docs/python_docs/python/build/tutorials/packages/gluon/loss/loss.ipynb:72: WARNING: File not found: '/api/python/docs/api/gluon/_autogen/mxnet.gluon.loss.HingeLoss.html'\r\n"", '\r\nci/build.py --docker-registry mxnetci --platform ubuntu_cpu_lite /work/runtime_functions.sh build_ubuntu_cpu_docs\r\n', '\r\nci/build.py --docker-registry mxnetci --platform ubuntu_cpu_python /work/runtime_functions.sh build_python_docs\r\n']",[],0,0
187,incubator-mxnet,16187,open,symbol.contrib.cond does not support custom operator execution,"## Description
symbol.contrib.cond operator does not support custom operator execution.

## Environment info (Required)




I'm using Pyton

## Build info (Required if built from source)
N/A

## Error Message:


## Minimum reproducible example


## Steps to reproduce
Run code above

## What have you tried to solve it?

1. Replace custom operator with no-operator (or built-in operator) - works (see comment in hybrid_forward

I suspect it has something to do with custom operators being executed imperatively (?)
Might be related to #12154 , #11641 and #16182 .

*I'm not sure that the custom operator implementation is not missing something, I attached an example with simple identity custom operator (which doesn't work).",Backend Bug,"['Was this ever resolved or was a work around ever found? ', ""You can consider trying https://github.com/apache/incubator-mxnet/tree/83797400128d41910d87e957131f29fd466f4777/example/extensions/lib_custom_op instead of the Python-level custom operator. But I'm not sure if it has been tested with conditional operator yet."", 'Heres the full stack trace from the given example on v1.8 MX:\r\n```\r\n#0  0x00007fffdee8748d in std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > mxnet::op::custom::List<(CustomOpPropCallbacks)1>(nnvm::NodeAttrs const&) () from /home/ubuntu/18_fixes/python/mxnet/../../lib/libmxnet.so\r\n#1  0x00007fffdee77bd8 in mxnet::op::custom::AttrParser(nnvm::NodeAttrs*) ()\r\n   from /home/ubuntu/18_fixes/python/mxnet/../../lib/libmxnet.so\r\n#2  0x00007fffe54d8a32 in nnvm::Symbol::CreateFunctor(nnvm::Op const*, std::unordered_map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > >) ()\r\n   from /home/ubuntu/18_fixes/python/mxnet/../../lib/libmxnet.so\r\n#3  0x00007fffe3c492d1 in MXSymbolCreateAtomicSymbol () from /home/ubuntu/18_fixes/python/mxnet/../../lib/libmxnet.so\r\n#4  0x00007ffff6607ec0 in ffi_call_unix64 () from /home/ubuntu/anaconda3/lib/python3.6/lib-dynload/../../libffi.so.6\r\n#5  0x00007ffff660787d in ffi_call () from /home/ubuntu/anaconda3/lib/python3.6/lib-dynload/../../libffi.so.6\r\n#6  0x00007ffff681cdae in _ctypes_callproc ()\r\n   from /home/ubuntu/anaconda3/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so\r\n#7  0x00007ffff681d7e5 in PyCFuncPtr_call ()\r\n```\r\nIts failing in the MXNet Python Custom Op, but on the C++ side here: https://github.com/apache/incubator-mxnet/blob/v1.x/src/operator/custom/custom.cc#L106 after it calls back into Python here: https://github.com/apache/incubator-mxnet/blob/v1.x/python/mxnet/operator.py#L733', 'Simple fix seems to be adding `**kwargs` to the `IdentityOPProp` constructor like:\r\n```\r\n@mx.operator.register(""identityop"")\r\nclass IdentityOPProp(mx.operator.CustomOpProp):\r\n    def __init__(self, **kwargs):\r\n        super(IdentityOPProp, self).__init__(True)\r\n        print(\'IdentityOPProp: %s\' % kwargs)\r\n```\r\nNow it works and prints:\r\n```\r\nIdentityOPProp: {\'__subgraph_name__\': \'cond_else0\'}\r\n\r\n[[3.]]\r\n<NDArray 1x1 @cpu(0)>\r\n\r\n[[3.]]\r\n<NDArray 1x1 @cpu(0)>\r\n```\r\nSo the question is, how/why is `__subgraph_name__` getting added to this op\'s attributes?', ""That does look like the issue we're having. I'll try that workaround. Thanks!""]","[""\r\n----------Python Info----------\r\nVersion      : 3.7.4\r\nCompiler     : Clang 10.0.1 (clang-1001.0.46.4)\r\nBuild        : ('default', 'Jul  9 2019 18:13:23')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 19.0.3\r\nDirectory    : /Users/XX/PycharmProjects/XX/venv/lib/python3.7/site-packages/pip-19.0.3-py3.7.egg/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.5.0\r\nDirectory    : /Users/XX/PycharmProjects/XX/venv/lib/python3.7/site-packages/mxnet\r\nCommit Hash   : 75a9e187d00a8b7ebc71412a02ed0e3ae489d91f\r\nLibrary      : ['/Users/XX/PycharmProjects/XX/venv/lib/python3.7/site-packages/mxnet/libmxnet.so']\r\nBuild features:\r\n✖ CUDA\r\n✖ CUDNN\r\n✖ NCCL\r\n✖ CUDA_RTC\r\n✖ TENSORRT\r\n✔ CPU_SSE\r\n✔ CPU_SSE2\r\n✔ CPU_SSE3\r\n✔ CPU_SSE4_1\r\n✔ CPU_SSE4_2\r\n✖ CPU_SSE4A\r\n✔ CPU_AVX\r\n✖ CPU_AVX2\r\n✖ OPENMP\r\n✖ SSE\r\n✖ F16C\r\n✖ JEMALLOC\r\n✖ BLAS_OPEN\r\n✖ BLAS_ATLAS\r\n✖ BLAS_MKL\r\n✖ BLAS_APPLE\r\n✔ LAPACK\r\n✖ MKLDNN\r\n✔ OPENCV\r\n✖ CAFFE\r\n✖ PROFILER\r\n✔ DIST_KVSTORE\r\n✖ CXX14\r\n✖ INT64_TENSOR_SIZE\r\n✔ SIGNAL_HANDLER\r\n✖ DEBUG\r\n----------System Info----------\r\nPlatform     : Darwin-18.7.0-x86_64-i386-64bit\r\nsystem       : Darwin\r\nnode         : XXX\r\nrelease      : 18.7.0\r\nversion      : Darwin Kernel Version 18.7.0: Tue Aug 20 16:57:14 PDT 2019; root:xnu-4903.271.2~2/RELEASE_X86_64\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : i386\r\nb'machdep.cpu.brand_string: Intel(R) Core(TM) i7-7660U CPU @ 2.50GHz'\r\nb'machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C'\r\nb'machdep.cpu.leaf7_features: RDWRFSGS TSC_THREAD_OFFSET SGX BMI1 HLE AVX2 SMEP BMI2 ERMS INVPCID RTM FPU_CSDS MPX RDSEED ADX SMAP CLFSOPT IPT MDCLEAR TSXFA IBRS STIBP L1DF SSBD'\r\nb'machdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT PREFETCHW RDTSCP TSCI'\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0137 sec, LOAD: 0.5112 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0180 sec, LOAD: 0.4525 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0198 sec, LOAD: 0.8612 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0233 sec, LOAD: 0.1894 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0120 sec, LOAD: 0.3173 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0105 sec, LOAD: 0.0961 sec.\r\n----------Environment----------\r\n\r\n"", '\r\nTraceback (most recent call last):\r\n  File ""_ctypes/callbacks.c"", line 232, in \'calling callback function\'\r\n  File ""/Users/XX/PycharmProjects/XX/venv/lib/python3.7/site-packages/mxnet/operator.py"", line 718, in creator\r\n    op_prop = prop_cls(**kwargs)\r\nTypeError: __init__() got an unexpected keyword argument \'__subgraph_name__\'\r\n\r\nSegmentation fault: 11\r\n\r\nStack trace:\r\n  [bt] (0) 1   libmxnet.so                         0x000000011705c2b0 mxnet::Storage::Get() + 4880\r\n  [bt] (1) 2   libsystem_platform.dylib            0x00007fff57f9eb5d _sigtramp + 29\r\n  [bt] (2) 3   Python                              0x000000010dcd7194 _PyMethodDef_RawFastCallDict + 591\r\n  [bt] (3) 4   libmxnet.so                         0x0000000115698206 mxnet::NDArray::set_aux_shape(unsigned long, mxnet::TShape const&) const + 177878\r\n  [bt] (4) 5   libmxnet.so                         0x00000001174c6fee NNSymbolCompose + 89646\r\n  [bt] (5) 6   libmxnet.so                         0x00000001168eb3d6 MXSymbolCreateAtomicSymbol + 4086\r\n  [bt] (6) 7   _ctypes.cpython-37m-darwin.so       0x000000010e1c636f ffi_call_unix64 + 79\r\n  [bt] (7) 8   ???                                 0x00007ffee1f469d0 0x0 + 140732689312208\r\n', '\r\nimport mxnet as mx\r\nfrom mxnet import nd, autograd, gluon\r\n\r\n\r\nclass IdentityOP(mx.operator.CustomOp):\r\n    def forward(self, is_train, req, in_data, out_data, aux):\r\n        self.assign(out_data[0], req[0], in_data[0])\r\n\r\n    def backward(self, req, out_grad, in_data, out_data, in_grad, aux):\r\n        self.assign(in_grad[0], req[0], out_grad[0])\r\n\r\n\r\n@mx.operator.register(""identityop"")\r\nclass IdentityOPProp(mx.operator.CustomOpProp):\r\n    def __init__(self):\r\n        super(IdentityOPProp, self).__init__(True)\r\n\r\n    def create_operator(self, ctx, in_shapes, in_dtypes):\r\n        return IdentityOP()\r\n\r\n\r\nclass MLP(gluon.HybridBlock):\r\n    def __init__(self, **kwargs):\r\n        super(MLP, self).__init__(**kwargs)\r\n        with self.name_scope():\r\n            self.dense1 = gluon.nn.Dense(1, in_units=1)\r\n\r\n    def hybrid_forward(self, F, x):\r\n        # Not working:\r\n        cond_out = F.contrib.cond(F.ones(1) == F.ones(1), lambda: self.dense1(x), lambda: mx.symbol.Custom(data=x, name=\'identityop\', op_type=\'identityop\'))\r\n        # Working:\r\n        # cond_out = F.contrib.cond(F.ones(1) == F.ones(1), lambda: self.dense1(x), lambda: x)\r\n        return cond_out\r\n\r\nmodel_ctx = mx.cpu()\r\nnet = MLP()\r\nnet.hybridize()\r\nnet.collect_params().initialize(mx.init.Constant([1]), ctx=model_ctx)\r\ndata = nd.ones((3,1))\r\nwith mx.autograd.record():\r\n    out = net(data.as_in_context(model_ctx))\r\nout.backward()\r\nprint(net.dense1.weight.grad())\r\nwith mx.autograd.record():\r\n    out = net(data.as_in_context(model_ctx))\r\nout.backward()\r\nprint(net.dense1.weight.grad())\r\n']","['', '']",0,0
188,incubator-mxnet,16333,open,mxnet docker gives different inference output,"## Description
When using official mxnet docker image on cloud server and without docker on a local server, the inference result is different. The input is exactly the same.

## Environment info (Required)
docker on cloud server: cuda9.0, cuda drive 418 (host machine), mxnet 1.4.0
local server: cuda9.0, cuda drive 396, mxnet 1.3.0",Docker,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended label(s): Performance', 'After downgrading the mxnet version in the docker to 1.3.0, the inference result are exactly the same. But why?']",[],[],0,0
189,incubator-mxnet,7933,open,CoreML conversion with finetuned model ,"I have successfully converted the squeezenet and resnet50 models from the examples to CoreML using mxnet-to-coreml. However, when converting a model after fine-tuning using my own data, the predictions are seemingly random. The model is fine-tuned using finetune.py from the examples. The model performs well prior to conversion to CoreML. After conversion to CoreML, the model predicts the same probabilities regardless of the image. The pre-trained model I'm using for fine-tuning is the imagenet11k-places resnet50 model.

I've tried:

1. subtracting channel biases as is performed during fine-tuning. (--pre-processing-arguments='{""image_input_names"":""data"",""red_bias"":123.68,""blue_bias"":103.939,""green_bias"":116.779}')

2. subtracting channel biases and scaling 1/255  (--pre-processing-arguments='{""image_input_names"":""data"",""red_bias"":123.68,""blue_bias"":103.939,""green_bias"":116.779, ""image_scale"":0.00392156862}')

3. subtracting scaled channel biases because I was unsure about when coreml performed the scaling  (--pre-processing-arguments='{""image_input_names"":[""data""],""red_bias"":0.485019,""blue_bias"":0.407603,""green_bias"":0.457956, ""image_scale"":0.00392156862}')

4. not scaling or biasing channels

Has anyone successfully converted a model after fine-tuning using a different data set? Any ideas would be greatly appreciated. I'm fairly certain there's something simple that I'm overlooking... 

I've also examined the converted model using Model_pb2 to make sure the preprocessing flags are being respected, and they appear to be:

print(model.neuralNetworkClassifier.preprocessing)

[featureName: ""data""
scaler {
  channelScale: 0.00380000006407
  blueBias: 103.939
  greenBias: 116.779
  redBias: 123.68
}
]

here's the entire cmd line: 

mxnet_coreml_converter.py --model-prefix='imagenet11k-places-resnet-50' --epoch=47 --input-shape='{""data"":""3,224,224""}' --mode=classifier --class-labels myclass_labels.txt --output-file=""mxnetimagenet11kplaces50resnet.mlmodel""  --pre-processing-arguments='{""image_input_names"":""data"",""red_bias"":123.68,""blue_bias"":103.939,""green_bias"":116.779, ""image_scale"":0.00392156862}'

",Bug Converter CoreML,"['@pracheer ', 'still hitting this issue - any guidance? ', ""Hi @loweew \r\n\r\nCan you provide more details about your fine-tuned model? For instance, what command you used in order to fine-tune? I'm assuming when you say you used fine-tune.py you used [this](https://github.com/apache/incubator-mxnet/blob/master/example/image-classification/fine-tune.py).\r\n\r\nAlso, will it be possible to share your fine-tuned model?\r\n\r\nAlso, while we are at this, are you fine-tuning this model: http://data.mxnet.io/models/imagenet-11k-place365-ch/ (resnet-50) so that I can try reproducing this at my end?"", ""python fine-tune.py --pretrained-model imagenet11k-place365ch-resnet-50 --data-train train.rec  --data-val val.rec --batch-size 360 --num-classes 227 --num-examples 115000 --data-nthreads 24 --lr 0.001 --lr-factor 0.1 --lr-step-epochs 30,60,90 --mom 0.9 --wd 0.0001 --disp-batches 500 --top-k 5 --max-random-h 30 --max-random-s 30 --max-random-aspect-ratio 0.30 --max-random-rotate-angle 90 --max-random-shear-ratio 0.15 --max-random-scale 2 --num-epochs 150  --gpus '0,1,2,3,4,5,6,7' --model-prefix ./imagenet11k-places-resnet-50\r\n\r\nUnfortunately, I cannot provide the model. I would imagine fine-tuning on any data set for a few epochs where number of classes != 1000 should be sufficient to repro the issue, but I haven't yet done that. "", 'any update here? do you need me to provide a model for you to move forward?', '@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', 'Sorry for the delay, @loweew. A model would be great!', '@loweew are you still seeing this issue? please share the model for further debug if the issue still occurs', 'Hi @loweew, I tried to reproduce this issue on this model: http://data.mxnet.io/models/imagenet-11k-place365-ch/ (resnet-50) I was not able to reproduce it. Your exact model and scripts would have helped to debug the issue you are facing further. For now, I am closing it as I cannot reproduce. Please feel free to reopen if closed in error or if you still encounter this issue. :) Thanks!', '1. The right way to do pre-processing is bgrConverter(image) * scale + bias，so for example, if your params are \'{""is_bgr"":True,""red_bias"":-128,""blue_bias"":-128,""green_bias"":-128,""image_scale"":0.0078125,""image_input_names"":""data""}\' , you are doing: image * 1/128.0 + (-128). If you set is_bgr = False, you need to change the order for bias, which means you need to give the real red bias to blue_bias, the same as blue bias to red_bias.\r\n\r\n2. mxnet_coreml_converter.py --model-prefix=\'squeezenet_v1.1\' --epoch=0 --input-shape=\'{""data"":""3,224,224""}\' --pre-processing-arguments=\'{""red_bias"":127,""blue_bias"":117,""green_bias"":103,""image_input_names"":""data""}\' --output-file=""squeezenet_v11.mlmodel""\r\nI find that if you use this command, the transform params are not worked, which means all the params are zeros now(is_bgr, bias and scale). You need change the source code of coremltools: \r\nset_pre_processing_parameters() fuction in coremltools/models/neural_network/builder.py: \r\n        if not isinstance(is_bgr, dict):\r\n            #is_bgr = dict.fromkeys(image_input_names, is_bgr)\r\n            is_bgr = dict.fromkeys([image_input_names], is_bgr)\r\n        if not isinstance(red_bias, dict):\r\n            #red_bias = dict.fromkeys(image_input_names, red_bias)\r\n            red_bias = dict.fromkeys([image_input_names], red_bias)\r\n        if not isinstance(blue_bias, dict):\r\n            #blue_bias = dict.fromkeys(image_input_names, blue_bias)\r\n            blue_bias = dict.fromkeys([image_input_names], blue_bias)\r\n        if not isinstance(green_bias, dict):\r\n            #green_bias = dict.fromkeys(image_input_names, green_bias)\r\n            green_bias = dict.fromkeys([image_input_names], green_bias)\r\n        if not isinstance(gray_bias, dict):\r\n            #gray_bias = dict.fromkeys(image_input_names, gray_bias)\r\n            gray_bias = dict.fromkeys([image_input_names], gray_bias)\r\n        if not isinstance(image_scale, dict):\r\n            #image_scale = dict.fromkeys(image_input_names, image_scale)\r\n            image_scale = dict.fromkeys([image_input_names], image_scale)\r\nAll you need to do is add [], otherwise the dict may not be right, and then the transform is all zero. And by the way the bias is need to be negtive if you mean: image - bias.\r\n\r\n']",[],[],0,0
190,incubator-mxnet,16188,open,symbol.contrib.cond does not support some built-in operators,"## Description
symbol.contrib.cond operator does not support the build-in operators round, floor and ceil (and probably some more).

## Environment info (Required)


I'm using Pyton

## Build info (Required if built from source)
N/A

## Error Message:


## Minimum reproducible example


## Steps to reproduce

1. Run the code above. hybrid_forward has few lines with comment if it's working or not (uncomment lines to see more examples)

## What have you tried to solve it?
N/A

Might be related to #12154 , #11641 , #16182 and #16187 . I keep those issues separate because I'm not sure the cause is the same.
",Backend Bug Operator,"['@yzhliu Hey I saw MXTVMBridge in the stack trace, what is that used for?', 'Hi, it also happens in MXNET1.4.1:\r\n\r\n\r\n## Output:\r\n```\r\n1.4.1\r\nTraceback (most recent call last):\r\n  File ""/Users/XX/PycharmProjects/XX/playground.py"", line 40, in <module>\r\n    out.backward()\r\n  File ""/Users/XX/PycharmProjects/XX/venv/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py"", line 2200, in backward\r\n    ctypes.c_void_p(0)))\r\n  File ""/Users/XX/PycharmProjects/XX/venv/lib/python3.7/site-packages/mxnet/base.py"", line 252, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: Error in operator node_1_backward: Error in operator mlp0__cond0_backward: [18:04:48] src/imperative/cached_op.cc:1250: Check failed: in_attrs->size() == bwd_input_eid.size() (3 vs. 2) \r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) 0   libmxnet.so                         0x00000001097f0c90 std::__1::__tree<std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, mxnet::NDArrayFunctionReg*>, std::__1::__map_value_compare<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, mxnet::NDArrayFunctionReg*>, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, mxnet::NDArrayFunctionReg*> > >::destroy(std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, mxnet::NDArrayFunctionReg*>, void*>*) + 2736\r\n[bt] (1) 1   libmxnet.so                         0x00000001097f0a3f std::__1::__tree<std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, mxnet::NDArrayFunctionReg*>, std::__1::__map_value_compare<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, mxnet::NDArrayFunctionReg*>, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, true>, std::__1::allocator<std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, mxnet::NDArrayFunctionReg*> > >::destroy(std::__1::__tree_node<std::__1::__value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, mxnet::NDArrayFunctionReg*>, void*>*) + 2143\r\n[bt] (2) 2   libmxnet.so                         0x000000010ae74537 mxnet::CachedOpBackward(mxnet::OpStatePtr const&, mxnet::OpContext const&, std::__1::vector<mxnet::NDArray, std::__1::allocator<mxnet::NDArray> > const&, std::__1::vector<mxnet::OpReqType, std::__1::allocator<mxnet::OpReqType> > const&, std::__1::vector<mxnet::NDArray, std::__1::allocator<mxnet::NDArray> > const&) + 9319\r\n[bt] (3) 3   libmxnet.so                         0x000000010b02c302 void mxnet::op::extract_by_loc<mxnet::NDArray>(std::__1::vector<mxnet::NDArray, std::__1::allocator<mxnet::NDArray> > const&, nnvm::Tuple<long long>, std::__1::vector<mxnet::NDArray, std::__1::allocator<mxnet::NDArray> >*) + 12514\r\n[bt] (4) 4   libmxnet.so                         0x000000010b0239e5 MXTVMBridge + 174165\r\n[bt] (5) 5   libmxnet.so                         0x000000010ae4b91e std::__1::__tree<std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::__map_value_compare<unsigned long, std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::less<unsigned long>, true>, std::__1::allocator<std::__1::__value_type<unsigned long, mxnet::NDArray> > >::erase(std::__1::__tree_const_iterator<std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::__tree_node<std::__1::__value_type<unsigned long, mxnet::NDArray>, void*>*, long>) + 5454\r\n[bt] (6) 6   libmxnet.so                         0x000000010ae59556 std::__1::__tree<std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::__map_value_compare<unsigned long, std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::less<unsigned long>, true>, std::__1::allocator<std::__1::__value_type<unsigned long, mxnet::NDArray> > >::erase(std::__1::__tree_const_iterator<std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::__tree_node<std::__1::__value_type<unsigned long, mxnet::NDArray>, void*>*, long>) + 61830\r\n[bt] (7) 7   libmxnet.so                         0x000000010ae518ea std::__1::__tree<std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::__map_value_compare<unsigned long, std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::less<unsigned long>, true>, std::__1::allocator<std::__1::__value_type<unsigned long, mxnet::NDArray> > >::erase(std::__1::__tree_const_iterator<std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::__tree_node<std::__1::__value_type<unsigned long, mxnet::NDArray>, void*>*, long>) + 29978\r\n[bt] (8) 8   libmxnet.so                         0x000000010ae63462 mxnet::CachedOp::SetForwardGraph(mxnet::CachedOp::GraphInfo*, bool, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&) + 15634\r\n[bt] (9) 9   libmxnet.so                         0x000000010ae73e38 mxnet::CachedOpBackward(mxnet::OpStatePtr const&, mxnet::OpContext const&, std::__1::vector<mxnet::NDArray, std::__1::allocator<mxnet::NDArray> > const&, std::__1::vector<mxnet::OpReqType, std::__1::allocator<mxnet::OpReqType> > const&, std::__1::vector<mxnet::NDArray, std::__1::allocator<mxnet::NDArray> > const&) + 7528\r\n\r\n\r\n```\r\n\r\n## ENV INFO:\r\n```\r\n----------Python Info----------\r\nVersion      : 3.7.4\r\nCompiler     : Clang 10.0.1 (clang-1001.0.46.4)\r\nBuild        : (\'default\', \'Jul  9 2019 18:13:23\')\r\nArch         : (\'64bit\', \'\')\r\n------------Pip Info-----------\r\nVersion      : 19.0.3\r\nDirectory    : /Users/XX/PycharmProjects/XX/venv/lib/python3.7/site-packages/pip-19.0.3-py3.7.egg/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.4.1\r\nDirectory    : /Users/XX/PycharmProjects/XX/venv/lib/python3.7/site-packages/mxnet\r\nCommit Hash   : 1a7199691f5cbc6012bb53eecbf884bed5ae6590\r\nLibrary      : [\'/Users/XX/PycharmProjects/XX/venv/lib/python3.7/site-packages/mxnet/libmxnet.so\']\r\nBuild features:\r\nNo runtime build feature info available\r\n----------System Info----------\r\nPlatform     : Darwin-18.7.0-x86_64-i386-64bit\r\nsystem       : Darwin\r\nnode         : XX\r\nrelease      : 18.7.0\r\nversion      : Darwin Kernel Version 18.7.0: Tue Aug 20 16:57:14 PDT 2019; root:xnu-4903.271.2~2/RELEASE_X86_64\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : i386\r\nb\'machdep.cpu.brand_string: Intel(R) Core(TM) i7-7660U CPU @ 2.50GHz\'\r\nb\'machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C\'\r\nb\'machdep.cpu.leaf7_features: RDWRFSGS TSC_THREAD_OFFSET SGX BMI1 HLE AVX2 SMEP BMI2 ERMS INVPCID RTM FPU_CSDS MPX RDSEED ADX SMAP CLFSOPT IPT MDCLEAR TSXFA IBRS STIBP L1DF SSBD\'\r\nb\'machdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT PREFETCHW RDTSCP TSCI\'\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0256 sec, LOAD: 0.6952 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0332 sec, LOAD: 0.0961 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0194 sec, LOAD: 0.5617 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0714 sec, LOAD: 0.4392 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0125 sec, LOAD: 0.2901 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0159 sec, LOAD: 0.0748 sec.\r\n----------Environment----------\r\n\r\n```', 'We confirm that we can reproduce this bug', 'A minimal example would be:\r\n\r\n```python\r\nimport mxnet as mx\r\nfrom mxnet import nd, autograd, gluon\r\n\r\nclass MLP(gluon.HybridBlock):\r\n    def __init__(self, **kwargs):\r\n        super(MLP, self).__init__(**kwargs)\r\n        with self.name_scope():\r\n            self.dense1 = gluon.nn.Dense(1, in_units=1)\r\n\r\n    def hybrid_forward(self, F, x):\r\n        cond_out = F.contrib.cond(F.ones(1) == F.ones(1), lambda: self.dense1(x), lambda: F.round(x))\r\n        return cond_out\r\n```\r\n', 'A workaround would be:\r\n\r\n```python\r\nimport mxnet as mx\r\nfrom mxnet import nd, autograd, gluon\r\n\r\nclass MLP(gluon.HybridBlock):\r\n    def __init__(self, **kwargs):\r\n        super(MLP, self).__init__(**kwargs)\r\n        with self.name_scope():\r\n            self.dense1 = gluon.nn.Dense(1, in_units=1)\r\n\r\n    def hybrid_forward(self, F, x, zero):\r\n        # `zero` is an ndarray that contains only zero, so `round(x) + relu(zero)` is always `round(x)`\r\n        cond_out = F.contrib.cond(F.ones(1) == F.ones(1), lambda: self.dense1(x), lambda: F.round(x) + F.relu(zero))\r\n        return cond_out\r\n```', 'Just digged a while with @zheng-da.\r\n\r\nThis bug should be related to inconsistency between operator implementation (F.round does not require original input when doing backward) and cached op (in which there are pieces of code that assume original input exists). We have a workaround in the post above that forces the input to exist, but this is definitely a bug somewhere unrelated to control flow operator itself. Could someone help us with the fix?']","[""\r\n----------Python Info----------\r\nVersion      : 3.7.4\r\nCompiler     : Clang 10.0.1 (clang-1001.0.46.4)\r\nBuild        : ('default', 'Jul  9 2019 18:13:23')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 19.0.3\r\nDirectory    : /Users/XX/PycharmProjects/XX/venv/lib/python3.7/site-packages/pip-19.0.3-py3.7.egg/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.5.0\r\nDirectory    : /Users/XX/PycharmProjects/XX/venv/lib/python3.7/site-packages/mxnet\r\nCommit Hash   : 75a9e187d00a8b7ebc71412a02ed0e3ae489d91f\r\nLibrary      : ['/Users/XX/PycharmProjects/XX/venv/lib/python3.7/site-packages/mxnet/libmxnet.so']\r\nBuild features:\r\n✖ CUDA\r\n✖ CUDNN\r\n✖ NCCL\r\n✖ CUDA_RTC\r\n✖ TENSORRT\r\n✔ CPU_SSE\r\n✔ CPU_SSE2\r\n✔ CPU_SSE3\r\n✔ CPU_SSE4_1\r\n✔ CPU_SSE4_2\r\n✖ CPU_SSE4A\r\n✔ CPU_AVX\r\n✖ CPU_AVX2\r\n✖ OPENMP\r\n✖ SSE\r\n✖ F16C\r\n✖ JEMALLOC\r\n✖ BLAS_OPEN\r\n✖ BLAS_ATLAS\r\n✖ BLAS_MKL\r\n✖ BLAS_APPLE\r\n✔ LAPACK\r\n✖ MKLDNN\r\n✔ OPENCV\r\n✖ CAFFE\r\n✖ PROFILER\r\n✔ DIST_KVSTORE\r\n✖ CXX14\r\n✖ INT64_TENSOR_SIZE\r\n✔ SIGNAL_HANDLER\r\n✖ DEBUG\r\n----------System Info----------\r\nPlatform     : Darwin-18.7.0-x86_64-i386-64bit\r\nsystem       : Darwin\r\nnode         : XXX\r\nrelease      : 18.7.0\r\nversion      : Darwin Kernel Version 18.7.0: Tue Aug 20 16:57:14 PDT 2019; root:xnu-4903.271.2~2/RELEASE_X86_64\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : i386\r\nb'machdep.cpu.brand_string: Intel(R) Core(TM) i7-7660U CPU @ 2.50GHz'\r\nb'machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C'\r\nb'machdep.cpu.leaf7_features: RDWRFSGS TSC_THREAD_OFFSET SGX BMI1 HLE AVX2 SMEP BMI2 ERMS INVPCID RTM FPU_CSDS MPX RDSEED ADX SMAP CLFSOPT IPT MDCLEAR TSXFA IBRS STIBP L1DF SSBD'\r\nb'machdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT PREFETCHW RDTSCP TSCI'\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0137 sec, LOAD: 0.5112 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0180 sec, LOAD: 0.4525 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0198 sec, LOAD: 0.8612 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0233 sec, LOAD: 0.1894 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0120 sec, LOAD: 0.3173 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0105 sec, LOAD: 0.0961 sec.\r\n----------Environment----------\r\n\r\n"", '\r\nTraceback (most recent call last):\r\n  File ""/Users/XX/PycharmProjects/XX/playground.py"", line 39, in <module>\r\n    out.backward()\r\n  File ""/Users/XX/PycharmProjects/XX/venv/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py"", line 2216, in backward\r\n    ctypes.c_void_p(0)))\r\n  File ""/Users/XX/PycharmProjects/XX/venv/lib/python3.7/site-packages/mxnet/base.py"", line 253, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: Error in operator node_1_backward: Error in operator mlp0__cond0_backward: [12:15:35] src/imperative/cached_op.cc:1322: Check failed: in_attrs->size() == bwd_input_eid.size() (3 vs. 2) : \r\nStack trace:\r\n  [bt] (0) 1   libmxnet.so                         0x00000001143d3929 mxnet::op::NDArrayOpProp::~NDArrayOpProp() + 4473\r\n  [bt] (1) 2   libmxnet.so                         0x0000000115939ccf mxnet::CachedOpBackward(mxnet::OpStatePtr const&, mxnet::OpContext const&, std::__1::vector<mxnet::NDArray, std::__1::allocator<mxnet::NDArray> > const&, std::__1::vector<mxnet::OpReqType, std::__1::allocator<mxnet::OpReqType> > const&, std::__1::vector<mxnet::NDArray, std::__1::allocator<mxnet::NDArray> > const&) + 9439\r\n  [bt] (2) 3   libmxnet.so                         0x0000000115ae40e2 void mxnet::op::extract_by_loc<mxnet::NDArray>(std::__1::vector<mxnet::NDArray, std::__1::allocator<mxnet::NDArray> > const&, mxnet::Tuple<long long>, std::__1::vector<mxnet::NDArray, std::__1::allocator<mxnet::NDArray> >*) + 3586\r\n  [bt] (3) 4   libmxnet.so                         0x0000000115ae0ad5 MXTVMBridge + 168405\r\n  [bt] (4) 5   libmxnet.so                         0x000000011591166e std::__1::__tree<std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::__map_value_compare<unsigned long, std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::less<unsigned long>, true>, std::__1::allocator<std::__1::__value_type<unsigned long, mxnet::NDArray> > >::erase(std::__1::__tree_const_iterator<std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::__tree_node<std::__1::__value_type<unsigned long, mxnet::NDArray>, void*>*, long>) + 6094\r\n  [bt] (5) 6   libmxnet.so                         0x000000011591ecb6 std::__1::__tree<std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::__map_value_compare<unsigned long, std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::less<unsigned long>, true>, std::__1::allocator<std::__1::__value_type<unsigned long, mxnet::NDArray> > >::erase(std::__1::__tree_const_iterator<std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::__tree_node<std::__1::__value_type<unsigned long, mxnet::NDArray>, void*>*, long>) + 60950\r\n  [bt] (6) 7   libmxnet.so                         0x000000011591763a std::__1::__tree<std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::__map_value_compare<unsigned long, std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::less<unsigned long>, true>, std::__1::allocator<std::__1::__value_type<unsigned long, mxnet::NDArray> > >::erase(std::__1::__tree_const_iterator<std::__1::__value_type<unsigned long, mxnet::NDArray>, std::__1::__tree_node<std::__1::__value_type<unsigned long, mxnet::NDArray>, void*>*, long>) + 30618\r\n  [bt] (7) 8   libmxnet.so                         0x0000000115929432 mxnet::CachedOp::SetForwardGraph(mxnet::CachedOp::GraphInfo*, bool, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&) + 12402\r\n  [bt] (8) 9   libmxnet.so                         0x00000001159395ab mxnet::CachedOpBackward(mxnet::OpStatePtr const&, mxnet::OpContext const&, std::__1::vector<mxnet::NDArray, std::__1::allocator<mxnet::NDArray> > const&, std::__1::vector<mxnet::OpReqType, std::__1::allocator<mxnet::OpReqType> > const&, std::__1::vector<mxnet::NDArray, std::__1::allocator<mxnet::NDArray> > const&) + 7611\r\n\r\n\r\n', '\r\nimport mxnet as mx\r\nfrom mxnet import nd, autograd, gluon\r\n\r\n\r\nclass MLP(gluon.HybridBlock):\r\n    def __init__(self, **kwargs):\r\n        super(MLP, self).__init__(**kwargs)\r\n        with self.name_scope():\r\n            self.dense1 = gluon.nn.Dense(1, in_units=1)\r\n\r\n    def hybrid_forward(self, F, x):\r\n        # Not working:\r\n        cond_out = F.contrib.cond(F.ones(1) == F.ones(1), lambda: self.dense1(x), lambda: F.round(x))\r\n        # cond_out = F.contrib.cond(F.ones(1) != F.ones(1), lambda: self.dense1(x), lambda: F.round(x))\r\n        # cond_out = F.contrib.cond(F.ones(1) != F.ones(1), lambda: self.dense1(x), lambda: F.floor(x))\r\n        # cond_out = F.contrib.cond(F.ones(1) == F.ones(1), lambda: self.dense1(x), lambda: F.floor(x))\r\n        # cond_out = F.contrib.cond(F.ones(1) != F.ones(1), lambda: self.dense1(x), lambda: F.ceil(x))\r\n        # cond_out = F.contrib.cond(F.ones(1) == F.ones(1), lambda: self.dense1(x), lambda: F.ceil(x))\r\n\r\n        # Working:\r\n        # cond_out = F.contrib.cond(F.ones(1) != F.ones(1), lambda: self.dense1(x), lambda: F.relu(x))\r\n        # cond_out = F.contrib.cond(F.ones(1) == F.ones(1), lambda: self.dense1(x), lambda: F.relu(x))\r\n        # cond_out = F.round(x)\r\n        # cond_out = F.floor(x)\r\n        # cond_out = F.ceil(x)\r\n        # cond_out = F.contrib.cond(F.ones(1) == F.ones(1), lambda: self.dense1(x), lambda: F.sign(x))\r\n        # cond_out = F.contrib.cond(F.ones(1) != F.ones(1), lambda: self.dense1(x), lambda: F.sign(x))\r\n\r\n        cond_out = F.broadcast_mul(cond_out, self.dense1(x))\r\n        return cond_out\r\n\r\nmodel_ctx = mx.cpu()\r\nnet = MLP()\r\nnet.hybridize()\r\nnet.collect_params().initialize(mx.init.Constant([1]), ctx=model_ctx)\r\ndata = nd.ones((3,1)) * 1.7\r\nwith mx.autograd.record():\r\n    out = net(data.as_in_context(model_ctx))\r\nout.backward()\r\nprint(net.dense1.weight.grad())\r\nwith mx.autograd.record():\r\n    out = net(data.as_in_context(model_ctx))\r\nout.backward()\r\nprint(net.dense1.weight.grad())\r\n']","['', '', '', '', '', '', '', '']",0,0
191,incubator-mxnet,12126,open,[Feature Request] Utility API for querying GPU memory,"Platform independent API (without using nvidia-smi) for querying GPU memory.
C implementation is provided by @sbodenstein  in this PR - https://github.com/apache/incubator-mxnet/pull/12083#pullrequestreview-145347358
",Feature request Python,"['I would also suggest to extend the C implementation to support wider GPU info. More precisely I suggest to add number of GPUs available into output of this method. And then, wrap it all up and expose via Python API.']",[],[],0,0
192,incubator-mxnet,16674,open,Garbage ctx.dev_mask seen in Clojure CPU Integration CI run,"## Description
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-cpu/detail/PR-16671/2/pipeline


### Error Message

# To Reproduce
(If you developed your own code, please provide a short script that reproduces the error. For existing examples, please provide link.)

### Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.

## Environment

We recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:

",Bug Clojure,"['@DickJC123 can this be closed now that #16671 is merged?\r\n@zachgk assign @DickJC123 ', 'any solution?. got the same error\r\n\r\napache-mxnet-src-1.7.0-incubating/src/engine/threaded_engine_perdevice.cc:131: Check failed: ctx.dev_mask() == Context::kGPU (1373401408 vs. 2) : \r\n']","['\r\n  what():  [23:30:23] src/engine/threaded_engine_perdevice.cc:131: Check failed: ctx.dev_mask() == Context::kGPU (1140850888 vs. 2) : \r\n', ""\r\nterminate called after throwing an instance of 'dmlc::Error'\r\n\r\nwhat():  [23:30:23] src/engine/threaded_engine_perdevice.cc:131: Check failed: ctx.dev_mask() == Context::kGPU (1140850888 vs. 2) : \r\n\r\nStack trace:\r\n\r\n[bt] (0) /tmp/mxnet6219749271079940772/mxnet-scala(dmlc::LogMessageFatal::~LogMessageFatal()+0x32) [0x7fc43f08c972]\r\n[bt] (1) /tmp/mxnet6219749271079940772/libmxnet.so(mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)+0x280) [0x7fc3173d2950]\r\n[bt] (2) /tmp/mxnet6219749271079940772/libmxnet.so(mxnet::engine::ThreadedEngine::Push(mxnet::engine::Opr*, mxnet::Context, int, bool)+0x41b) [0x7fc3173c006b]\r\n[bt] (3) /tmp/mxnet6219749271079940772/libmxnet.so(mxnet::engine::ThreadedEngine::PushAsync(std::function<void (mxnet::RunContext, mxnet::engine::CallbackOnComplete)>, mxnet::Context, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, mxnet::FnProperty, int, char const*, bool)+0xd8) [0x7fc3173bcaf8]\r\n[bt] (4) /tmp/mxnet6219749271079940772/libmxnet.so(mxnet::engine::ThreadedEngine::BulkFlush()+0x481) [0x7fc3173bbb31]\r\n[bt] (5) /tmp/mxnet6219749271079940772/libmxnet.so(mxnet::engine::ThreadedEngine::Push(mxnet::engine::Opr*, mxnet::Context, int, bool)+0x42) [0x7fc3173bfc92]\r\n[bt] (6) /tmp/mxnet6219749271079940772/libmxnet.so(mxnet::engine::ThreadedEngine::PushAsync(std::function<void (mxnet::RunContext, mxnet::engine::CallbackOnComplete)>, mxnet::Context, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, mxnet::FnProperty, int, char const*, bool)+0xd8) [0x7fc3173bcaf8]\r\n[bt] (7) /tmp/mxnet6219749271079940772/libmxnet.so(mxnet::engine::ThreadedEngine::BulkFlush()+0x481) [0x7fc3173bbb31]\r\n[bt] (8) /tmp/mxnet6219749271079940772/libmxnet.so(mxnet::engine::ThreadedEngine::Push(mxnet::engine::Opr*, mxnet::Context, int, bool)+0x42) [0x7fc3173bfc92]\r\n\r\nTests failed.\r\n"", '\r\ncurl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\r\n\r\n# paste outputs here\r\n']",[],0,0
193,incubator-mxnet,10549,open,scala-package 1.1.0 build instruction Windows VS2015,"## Description
I'd like to build mxnet for Scala on Windows from source. I can build libmxnet.dll successfully, but there are no instructions how to build scala-package on Windows. [Instruction page](https://mxnet.incubator.apache.org/install/windows_setup.html#install-the-mxnet-package-for-scala)
refers to make only.

Could you provide instructions relevant for windows or mxnet-scala.dll?

## Environment info (Required)

Windows 10.
mxnet 1.1.0


## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
Visual Studio 14 2015 Win64

MXNet commit hash: ""07a83a0325a3d782513a04f47d711710972cb144""

Build config:
mxnet_option(USE_CPP_PACKAGE      ""Build C++ Package"" ON)

## Steps to reproduce
1. Build libmxnet.dll
2. Try to build scala-package??

## What have you tried to solve it?

1. I tried to compile dll from files in 
scala-package\native\src
but failed to resolve all dependencies correctly
",Call for Contribution Installation Scala Windows,"['@nswamy Could you please add labels-\r\nScala, Windows, Installation', 'any update here.', 'Unfortunately, Scala is not supported on Windows for now. We are prioritize Windows support for Scala this month as many users requested that. Will try to provide support that as soon as possible. However, there is still more time needed for a stable release.', 'Please add the label for Call for Contribution.', '#8075', ""@evanthomas we'll be tracking this issue here and update here when we have Windows support added."", ""The JavaCPP Presets for MXNet now bundle the Scala API and they work on Windows too:\r\nhttps://github.com/bytedeco/javacpp-presets/tree/master/mxnet\r\nWhat I ended up doing is generating the missing files that we can't generate with CMake on Windows using the Makefiles on Linux, and that's pretty much it. I think those files should be checked in the source code repository as it would help with this issue. Anyway, to give the current presets a try, run `mvn install` in the directory for MXNet or use the prebuilt binaries from Maven Central."", ""@saudet That's amazing! We are planning to officially support MXNet very soon from `1.4.x` and later version. Will you be interested in doing that? Currently we greatly optimized the building process and it should be very straight-forward to do so."", ""@lanking520 The presets use their own build system for Java classes to unify how they are packaged and loaded w.r.t. other native libraries such as OpenCV, so I'm not sure if any of it could be reused here. Could you take a look and let me know?\r\n\r\nAnyway, there isn't a lot that needs to be changed for the build system in MXNet to work as well. It's basically just making sure everything can be built with CMake and then it looks like Windows would pretty much work."", ""Awesome, thank you @saudet ! We'd be happy to assist you to get this ported into mainline. Please feel free to open a thread on dev@ as well :)"", ""@marcoabreu It's more than just about MXNet on Mac or Windows though. It also about CUDA/cuDNN, OpenCV, MKL/MKL-DNN, Caffe, Deeplearning4j, TensorFlow, and (eventually) PyTorch, and how they interact. For details, read http://bytedeco.org/news/2019/01/11/importance-of-a-distribution/. How are the builds of MXNet for Java/Scala currently deployed to support CUDA, OpenCV, and MKL on Linux, Mac, and Windows? They don't seem to be available..."", '@smpawlowski You may be interested in our publish pipeline: https://github.com/apache/incubator-mxnet/tree/master/ci/publish. We do a static-link on most of the dependencies and that will also include MKLDNN very soon. We require users to set up their own CUDA path.', ""@lanking520 For MKL-DNN, you'll be bundling MKLML which is ~30 MB, probably doubling the size of the artifacts, but what if the user wants to use the full version of MKL in their application? What about the features that require OpenCV, etc? Someone has to manage these dependencies. If MXNet does everything by themselves, it would prevent using these and other native libraries that conflict with the statically linked versions..."", ""@smpawlowski https://github.com/apache/incubator-mxnet/tree/master/tools/dependencies we have a set of libraries static-linked including OpenCV. We are keeping the up-to-date and aviod influencing the users' environment"", ""@lanking520 How can Java/Scala users access the functions from the statically linked version? If they can't, they will try to use another version that will most likely conflict, especially if GPU support is enabled."", ""> @lanking520 How can Java/Scala users access the functions from the statically linked version? If they can't, they will try to use another version that will most likely conflict, especially if GPU support is enabled.\r\n\r\nRecently we enable the Scala-Java users load `libmxnet.so` directly, this library contains all we need for the dependencies. We no longer require users to dynamic link them. However, we only do this for the nightly-snapshot and official versions from `1.4.x` and above. https://repository.apache.org/#nexus-search;gav~org.apache.mxnet\r\n\r\nApart from that, will you be interested in joining our Slack channel? We can discuss there. \r\nhttp://mxnet.incubator.apache.org/versions/master/community/contribute.html#slack"", ""@lanking520 I don't see in your documentation where it explains how users can call from Java/Scala the functions of OpenCV that are in `libmxnet.so`. In any case, I'm trying to explain that this isn't just about builds for Mac or Windows. This is also about, at least, CUDA, MKL, and OpenCV: They are not just dependencies that can be buried in MXNet. I would like to expand the discussion, but is this something you think people on dev@ (as per @marcoabreu) or on Slack would be interested in?"", ""I think this is a great discussion point. These are powerful libraries that don't only serve mxnet but also other use cases. Changing the build system to allow access to them could potentially help especially in environments with restricted space requirements. Also, that way, people don't have to figure out the dependency clojure twice (once by us for mxnet and once by the user for their pipeline).""]",[],[],0,0
194,incubator-mxnet,12683,open,tests still pulling data from data.dmlc.ml and are randomly failing,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
Unit tests pulling data from data.dmlc.ml and randomly failing
## Environment info (Required)
Jenkins:
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/1676/pipeline 
",CI Test,"['@mxnet-label-bot [CI, Test]', '@mxnet-label-bot [Good First Issue]']",[],[],0,0
195,incubator-mxnet,13100,open,Hybridization generates superfluous backward ops that may induce storage fallbacks ,"## Description
Hybridizing creates superfluous backward ops in some conditions. This is bad, as these ops may consequently trigger a storage fallback. In the example below, no gradient for  is requested. Still  is generated and consequently a storage fallback occurs.
Note that this example works without storage fallback in the imperative and symbolic API (for imperative, just remove hybridize. For symbolic, see https://github.com/apache/incubator-mxnet/blob/master/example/sparse/factorization_machine/model.py#L39 )

## Environment info (Required)
mxnet
floatnp.floatingnp.float64 == np.dtype(float).type

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. Run above code example. Note the storage fallback that occurs.
2. Remove the  line. Note that the storage fallback disappears.

",Operator,"['Also note that adding `F.dot(F.BlockGrad(csr.square()), rsp)` will avoid the storage fallback on CPU.\r\nOn GPU, adding F.BlockGrad will induce the following error message:\r\n\r\n```\r\n\r\n[07:42:34] src/engine/engine.cc:55: MXNet start using engine: NaiveEngine\r\nTraceback (most recent call last):\r\n  File ""bug.py"", line 17, in <module>\r\n    l = net(csr, rsp)\r\n  File ""/home/ubuntu/mxnet/python/mxnet/gluon/block.py"", line 542, in __call__\r\n    out = self.forward(*args)\r\n  File ""/home/ubuntu/mxnet/python/mxnet/gluon/block.py"", line 909, in forward\r\n    return self._call_cached_op(x, *args)\r\n  File ""/home/ubuntu/mxnet/python/mxnet/gluon/block.py"", line 815, in _call_cached_op\r\n    out = self._cached_op(*cargs)\r\n  File ""/home/ubuntu/mxnet/python/mxnet/_ctypes/ndarray.py"", line 150, in __call__\r\n    ctypes.byref(out_stypes)))\r\n  File ""/home/ubuntu/mxnet/python/mxnet/base.py"", line 253, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [07:42:38] src/operator/tensor/././cast_storage-inl.cuh:606: Check failed: ctx.requested.size() > 0 (0 vs. 0)\r\n```', '@mxnet-label-bot [Good first issue, operator]', 'I don\'t think it\'s a trivial task for a beginner, as it involves sparse ops and hybridization. Removing ""good first issue"" label. ']","['\r\n\r\nPackage used: Python\r\n\r\n## Error Message:\r\n', '\r\n\r\n## Minimum reproducible example\r\n']","['csr', 'operator = _backward_square', '', ""\r\n----------Python Info----------\r\nVersion      : 3.6.6\r\nCompiler     : GCC 8.2.0\r\nBuild        : ('default', 'Oct 13 2018 05:47:55')\r\nArch         : ('64bit', 'ELF')\r\n------------Pip Info-----------\r\nVersion      : 10.0.0.dev0\r\nDirectory    : /home/leonard/software/pip/src/pip\r\n----------MXNet Info-----------\r\n/home/leonard/.local/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from "", ' to ', ' is deprecated. In future, it will be treated as ', "".\r\n  from ._conv import register_converters as _register_converters\r\nVersion      : 1.3.1\r\nDirectory    : /home/leonard/.local/lib64/python3.6/site-packages/mxnet\r\nCommit Hash   : 0bea50ec201d19cf393a2dce37d9a6b1625be144\r\n----------System Info----------\r\nPlatform     : Linux-4.19.0-gentoo-x86_64-Intel-R-_Core-TM-_i7-7500U_CPU_@_2.70GHz-with-gentoo-2.4.1\r\nsystem       : Linux\r\nnode         : leonard-xps13\r\nrelease      : 4.19.0-gentoo\r\nversion      : #4 SMP Sun Oct 28 09:21:38 UTC 2018\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz\r\nArchitecture:        x86_64\r\nCPU op-mode(s):      32-bit, 64-bit\r\nByte Order:          Little Endian\r\nCPU(s):              4\r\nOn-line CPU(s) list: 0-3\r\nThread(s) per core:  2\r\nCore(s) per socket:  2\r\nSocket(s):           1\r\nVendor ID:           GenuineIntel\r\nCPU family:          6\r\nModel:               142\r\nModel name:          Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz\r\nStepping:            9\r\nCPU MHz:             3499.226\r\nCPU max MHz:         3500.0000\r\nCPU min MHz:         400.0000\r\nBogoMIPS:            5808.00\r\nVirtualization:      VT-x\r\nL1d cache:           32K\r\nL1i cache:           32K\r\nL2 cache:            256K\r\nL3 cache:            4096K\r\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp flush_l1d\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0133 sec, LOAD: 1.3410 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.1139 sec, LOAD: 0.2640 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.2299 sec, LOAD: 0.8850 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0157 sec, LOAD: 1.0251 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0164 sec, LOAD: 1.1068 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0497 sec, LOAD: 2.2623 sec.\r\n\r\n\r\n[07:31:15] src/operator/tensor/././../../common/utils.h:450:\r\nStorage type fallback detected:\r\noperator = _backward_square\r\ninput storage types = [default, csr, ]\r\noutput storage types = [default, ]\r\nparams = {}\r\ncontext.dev_mask = cpu\r\nThe operator with default storage type will be dispatched for execution. You're seeing this warning message because the operator above is unable to process the given ndarrays with specified storage types, context and parameter. Temporary dense ndarrays are generated in order to execute the operator. This does not affect the correctness of the programme. You can set environment variable MXNET_STORAGE_FALLBACK_LOG_VERBOSE to 0 to suppress this warning.\r\n[[0. 0.]\r\n [0. 0.]]\r\n\r\nimport mxnet as mx\r\n\r\ndns = mx.nd.array([[0, 0], [1, 2], [0, 0], [3, 4], [0, 0]])\r\nrsp = dns.tostype('row_sparse')\r\ncsr = mx.nd.sparse.csr_matrix(mx.nd.zeros(shape=(2, 5)))\r\n\r\n\r\nclass Net(mx.gluon.HybridBlock):\r\n    def hybrid_forward(self, F, csr, rsp):\r\n        csr = csr.square()\r\n        return F.dot(csr.square(), rsp)\r\n\r\n\r\nrsp.attach_grad()\r\nnet = Net()\r\nnet.hybridize()\r\nwith mx.autograd.record():\r\n    l = net(csr, rsp)\r\nl.backward()\r\nprint(l.asnumpy())\r\n"", '', '.hybridize()']",0,0
196,incubator-mxnet,11255,open,P100 + MXNet is slow,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
I have installed the **Anaconda3 and installed the mxnet-cu90** by pip but the training speed is very slow

and I find that ,the data reading speed is much slow , when reading image data and decoding the binary data by imdecode , **the GPU usage is below 30%**, I guess that, the speed bottleneck of the speed is data reading.

multi-gpu and single gpu are the same slow 
## Environment info (Required)
Ubuntu16.04
P100


python diagnose.py

Package used (Python/R/Scala/Julia):
I'm using Anaconda3 python3.6
MXNet 1.2.0

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)
pip install mxnet-cu90
## Error Message:
(Paste the complete error message, including stack trace.)
No error, but the speed is slow, GPU usage is low
![default](https://user-images.githubusercontent.com/12196464/41327683-f5f6506e-6ef6-11e8-9650-cd2add427809.png)

traiing is slow
![default](https://user-images.githubusercontent.com/12196464/41327726-1cb087f6-6ef7-11e8-86dd-42978e275253.png)


## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.Training with mxnet and P100
2.

## What have you tried to solve it?

1. installed python3, python2, pytthon2 encoutered the same problem
2.
",Performance,"['did you use multiple worker for data loader?\r\n', 'Thanks for submitting this issue - @Erdos001 \r\nThis community is mainly for reporting bugs/requesting new features. To further discuss about the performance - I would recommend taking a look at the open discussion forum - https://discuss.mxnet.io\r\n@sandeep-krishnamurthy could you add label ""Performance"" to this?']",[],"['', '\r\nWhat to do:\r\n1. Download the diagnosis script from https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/diagnose.py\r\n2. Run the script using ', ' and paste its output here.\r\n\r\n', '', 'java -version', 'mvn -version', 'scala -version', 'sessionInfo()', 'git rev-parse HEAD']",0,0
197,incubator-mxnet,13853,open,Error while running the mxnet spark examples and test cases,"Opening issue on behalf of @adwivedi on the discussion forum (https://discuss.mxnet.io/t/error-while-running-the-mxnet-spark-examples-and-test-cases/2720).

### Quotes from the thread...

I am trying to run the mxnet in distributed mode using spark as implemented here : https://github.com/apache/incubator-mxnet/tree/master/scala-package/spark

but I am not able to run the examples and/or tests.

The commented tests in the file : https://github.com/apache/incubator-mxnet/blob/master/scala-package/spark/src/test/scala/org/apache/mxnet/spark/MXNetGeneralSuite.scala keep running into the following error. I get the same error when I try to run the examples in the repo.



I have seen this error generally when there’s a mismatch between the scala versions in the api, but in this case I am using the using the pom file that’s in the project and not including any external libraries.
I have also looked at the pom file but I’ve not found any lib that might have a mismatch in this case, all the libraries in pom are 2.11 version

I am building it from source, running it with this vm parameter : -



to let it find the native library.",Scala,"['@lanking520', '@mxnet-label-bot add [Scala]', 'Thanks for @thomelane raising it here. Add a bunch of Scala guru here:\r\n@piyushghai @zachgk @andrewfayres @CodingCat \r\nPlease take a look at this issue. I also think it is a good time now to fix the flaky test on the disabled tests and allow Spark run in the CI.', '@adwivedi , Your issue for running the examples should be resolved by this PR : https://github.com/apache/incubator-mxnet/pull/13849 and https://github.com/apache/incubator-mxnet/pull/13891.  These fixes are now merged into master. \r\nThere were recent changes to the Maven POM files due to which the examples were temporarily not running. They should be back to normal now. Let me know if you still face issues with running your examples. \r\n\r\nAnd yes. the java library path that you are setting is the correct one. ', ""@piyushghai The error still persists. You can reproduce it by un-commenting the  test = `run spark with MLP` with it's related methods in the file `org/apache/mxnet/spark/MXNetGeneralSuite.scala`\r\n\r\nAlso, the latest version in master doesn't respect the `-Djava.library.path` or `LD_LIBRARY_PATH_VARIABLES` and only picks up the native files from the jar (which doesn't seem to have these files). So to test this  I am running a hacked version to make the libraries get picked up from the path (incubator-mxnet/scala-package/native/osx-x86_64-cpu/target) I hard code in `NativeLibraryLoader.scala`"", ""@piyushghai The path of the jars are still incorrect / incomplete. I've fixed this in this pull request, here : https://github.com/apache/incubator-mxnet/pull/14020\r\n\r\nHowever there's still one problem, with the latest changes. The mxnet shared library fails to build when `USE_DIST_KVSTORE = 1` because of a the following error : \r\n\r\n```\r\nchecking whether the C compiler works... no\r\nconfigure: error: in `/path_to_mxnet/incubator-mxnet/3rdparty/ps-lite/protobuf-2.5.0':\r\nconfigure: error: C compiler cannot create executables\r\nSee `config.log' for more details\r\nmake[1]: *** [/path_to_mxnet/incubator-mxnet/deps/include/google/protobuf/message.h] Error 77\r\nmake: *** [PSLITE] Error 2\r\n```"", ""@aashudwivedi Thanks for making the fix to the calsspath problem for the Spark issue. \r\n\r\nCan you point me to the specific build instructions you followed to build the mxnet shared library ? \r\nAlso what's the instance type on which you're building it ? "", ""Here's what I did to build the libmxnet.so from source : \r\n``` \r\ngit clone --recursive https://github.com/apache/incubator-mxnet.git \r\ncd incubator-mxnet\r\nmake clean && make -j$(nproc) USE_BLAS=openblas USE_CUDA=1 USE_CUDA_PATH=/usr/local/cuda-9.0 USE_CUDNN=1 USE_DIST_KVSTORE=1\r\n```\r\nHere's the instance info on which I built mxnet: \r\n```\r\n('Version      :', '2.7.12')\r\n('Compiler     :', 'GCC 5.4.0 20160609')\r\n('Build        :', ('default', 'Nov 12 2018 14:36:49'))\r\n('Arch         :', ('64bit', 'ELF'))\r\n------------Pip Info-----------\r\n('Version      :', '18.1')\r\n('Directory    :', '/usr/local/lib/python2.7/dist-packages/pip')\r\n----------MXNet Info-----------\r\n('Version      :', '1.5.0')\r\n('Directory    :', '/home/ubuntu/.local/lib/python2.7/site-packages/mxnet')\r\n('Commit Hash   :', 'da5242b732de39ad47d8ecee582f261ba5935fa9')\r\n----------System Info----------\r\n('Platform     :', 'Linux-4.4.0-1074-aws-x86_64-with-Ubuntu-16.04-xenial')\r\n('system       :', 'Linux')\r\n('node         :', 'ip-172-31-78-46')\r\n('release      :', '4.4.0-1074-aws')\r\n('version      :', '#84-Ubuntu SMP Thu Dec 6 08:57:58 UTC 2018')\r\n----------Hardware Info----------\r\n('machine      :', 'x86_64')\r\n('processor    :', 'x86_64')\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                64\r\nOn-line CPU(s) list:   0-63\r\nThread(s) per core:    2\r\nCore(s) per socket:    16\r\nSocket(s):             2\r\nNUMA node(s):          2\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\nStepping:              1\r\nCPU MHz:               1227.804\r\nCPU max MHz:           3000.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              4600.14\r\nHypervisor vendor:     Xen\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              46080K\r\nNUMA node0 CPU(s):     0-15,32-47\r\nNUMA node1 CPU(s):     16-31,48-63\r\n```\r\n"", '@piyushghai \r\n\r\nI am building it on macOS High Sierra 10.13.6.\r\nHere\'s what I do to build the libmxnet.so. I have followed  the instructions from http://mxnet.incubator.apache.org/versions/master/install/osx_setup.html#build-the-shared-library\r\n\r\n```\r\n    git clone --recursive https://github.com/apache/incubator-mxnet ~/mxnet\r\n    cd ~/mxnet\r\n    cp make/osx.mk ./config.mk\r\n    echo ""USE_BLAS = openblas"" >> ./config.mk\r\n    echo ""ADD_CFLAGS += -I/usr/local/opt/openblas/include"" >> ./config.mk\r\n    echo ""ADD_LDFLAGS += -L/usr/local/opt/openblas/lib"" >> ./config.mk\r\n    echo ""ADD_LDFLAGS += -L/usr/local/lib/graphviz/"" >> ./config.mk\r\n    echo ""USE_DIST_KVSTORE=1"" >> ./config.mk\r\n    make -j$(sysctl -n hw.ncpu)\r\n```\r\nHere\'s the instance info : \r\n```\r\n----------Python Info----------\r\n(\'Version      :\', \'2.7.15\')\r\n(\'Compiler     :\', \'GCC 4.2.1 Compatible Apple LLVM 10.0.0 (clang-1000.11.45.2)\')\r\n(\'Build        :\', (\'default\', \'Oct  2 2018 11:47:18\'))\r\n(\'Arch         :\', (\'64bit\', \'\'))\r\n------------Pip Info-----------\r\n(\'Version      :\', \'18.0\')\r\n(\'Directory    :\', \'/usr/local/lib/python2.7/site-packages/pip\')\r\n----------MXNet Info-----------\r\nNo MXNet installed.\r\n----------System Info----------\r\n(\'Platform     :\', \'Darwin-17.7.0-x86_64-i386-64bit\')\r\n(\'system       :\', \'Darwin\')\r\n(\'node         :\', \'ashutdwi-mac\')\r\n(\'release      :\', \'17.7.0\')\r\n(\'version      :\', \'Darwin Kernel Version 17.7.0: Wed Oct 10 23:06:14 PDT 2018; root:xnu-4570.71.13~1/RELEASE_X86_64\')\r\n----------Hardware Info----------\r\n(\'machine      :\', \'x86_64\')\r\n(\'processor    :\', \'i386\')\r\nmachdep.cpu.brand_string: Intel(R) Core(TM) i7-4770HQ CPU @ 2.20GHz\r\nmachdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C\r\nmachdep.cpu.leaf7_features: SMEP ERMS RDWRFSGS TSC_THREAD_OFFSET BMI1 AVX2 BMI2 INVPCID FPU_CSDS\r\nmachdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT RDTSCP TSCI\r\n```\r\nHere are the details of xcode: \r\n```\r\nXcode 10.1\r\nBuild version 10B61\r\n```\r\nI\'ve also attached the config.log from `3rdparty/ps-lite/protobuf-2.5.0` dir here [config.log](https://github.com/apache/incubator-mxnet/files/2809313/config.log)', 'cannot reproduce the same issue with High Sierra. Here is the list of dependencies I installed:\r\n\r\n`xcode command-line tool 10`\r\n```\r\nbrew install openssl automake pkg-config nasm\r\n```\r\n\r\n```\r\nApple LLVM version 10.0.0 (clang-1000.10.44.4)\r\nTarget: x86_64-apple-darwin17.7.0\r\nThread model: posix\r\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\r\n```', '@aashudwivedi Any luck with these above steps ? ', '@piyushghai unfortunately I still have the same problem and I am not sure what other information I should provide you to be able to reproduce this.', ""From the previous message:\r\n```\r\nchecking whether the C compiler works... no\r\nconfigure: error: in `/path_to_mxnet/incubator-mxnet/3rdparty/ps-lite/protobuf-2.5.0':\r\nconfigure: error: C compiler cannot create executables\r\n```\r\n\r\nHave checked your C compiler `clang --version`? It seemed the problems appeared to be some compiler issues. Try `make clean` and `make -j` again""]","['\r\nError: A JNI error has occurred, please check your installation and try again\r\nException in thread ""main"" java.lang.NoClassDefFoundError: scala/collection/Seq\r\n\tat java.lang.Class.getDeclaredMethods0(Native Method)\r\n\tat java.lang.Class.privateGetDeclaredMethods(Class.java:2701)\r\n\tat java.lang.Class.privateGetMethodRecursive(Class.java:3048)\r\n\tat java.lang.Class.getMethod0(Class.java:3018)\r\n\tat java.lang.Class.getMethod(Class.java:1784)\r\n\tat sun.launcher.LauncherHelper.validateMainClass(LauncherHelper.java:544)\r\n\tat sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:526)\r\nCaused by: java.lang.ClassNotFoundException: scala.collection.Seq\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\t... 7 more\r\nException in thread ""Thread-21"" java.lang.IllegalArgumentException: requirement failed: Failed to start ps scheduler process with exit code 1\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.mxnet.spark.MXNet.org$apache$mxnet$spark$MXNet$$startPSSchedulerInner$1(MXNet.scala:159)\r\n\tat org.apache.mxnet.spark.MXNet$$anonfun$startPSScheduler$1.apply(MXNet.scala:162)\r\n\tat org.apache.mxnet.spark.MXNet$$anonfun$startPSScheduler$1.apply(MXNet.scala:162)\r\n\tat org.apache.mxnet.spark.MXNet$MXNetControllingThread.run(MXNet.scala:38)\r\nError: A JNI error has occurred, please check your installation and try again\r\nException in thread ""main"" java.lang.NoClassDefFoundError: scala/collection/Seq\r\n\tat java.lang.Class.getDeclaredMethods0(Native Method)\r\n\tat java.lang.Class.privateGetDeclaredMethods(Class.java:2701)\r\n\tat java.lang.Class.privateGetMethodRecursive(Class.java:3048)\r\n\tat java.lang.Class.getMethod0(Class.java:3018)\r\n\tat java.lang.Class.getMethod(Class.java:1784)\r\n\tat sun.launcher.LauncherHelper.validateMainClass(LauncherHelper.java:544)\r\n\tat sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:526)\r\nCaused by: java.lang.ClassNotFoundException: scala.collection.Seq\r\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:381)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:424)\r\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)\r\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:357)\r\n\t... 7 more\r\n', '\r\nDjava.library.path=/path_to_mxnet_source/incubator-mxnet/scala-package/native/osx-x86_64-cpu/target\r\n']",[],0,0
198,incubator-mxnet,9763,open,Too many header files need to be included when using C++ api,"Hi everyone, I am working on a C++ project which needs to use mxnet for CNN inference. I set  and compiled mxnet source code myself.

In my C++ program, I only include  at first but got errors like below:


It is caused by [](https://github.com/apache/incubator-mxnet/blob/master/cpp-package/include/mxnet-cpp/base.h#L31) which includes  and  inside it.

Thus, I have to add a lot more dirs to avoid the similar errors:


Just want to ask if it is possible to make the mxnet C++ api easier to use?

For instance, the mxnet cpp package folder only contains:
* : all header files necessary for C++ development;
* : all libraries necessary for C++ development (i.e. libmxnet.so);",Build C++ Feature request,"['@marcoabreu should we have a different tag for CPP_PACKAGE? I have seen a bunch of issues for the CPP_package  and it would be nice if we could group them together with a label.', 'Good idea, please mention me in the other ones so I can label them accordingly', 'There is discussion started by MXNet community to address this issue. Please chime in to provide your inputs and possibly contribute. \r\n\r\nhttps://lists.apache.org/thread.html/b8e655ab756db258efb1a5483b1643dbdc8fc0bfc12ce1cb8f1c2837@%3Cdev.mxnet.apache.org%3E', ""error:\r\n../../include/mxnet-cpp/optimizer.hpp:37:26: fatal error: mxnet-cpp/op.h: No such file or directory\r\n\r\nBut I can't find any files named op.h in mxnet-cpp, is this a bug?"", '@meanmee  I met the same problam like you .Have you solved it? ', '@nicklhy  Hi , I have the same problem like you, but I do not understand “Thus, I have to add a lot more dirs to avoid the similar errors:” . I mean where to add these infomation ,I still confused about it . ', '@yuyijie1995 you can check the make/cmake files in the examples, something like [this](https://github.com/apache/incubator-mxnet/blob/da5242b732de39ad47d8ecee582f261ba5935fa9/cpp-package/example/Makefile#L31).', 'Thanks a lot\n\n\n\n\n| |\n俞依杰\n|\n|\n邮箱：13588280094@163.com\n|\n\n签名由 网易邮箱大师 定制\n\nOn 01/28/2019 11:30, nicklhy wrote:\n\n@yuyijie1995 you can check the make/cmake files in the examples, something like this.\n\n—\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.', '> @meanmee I met the same problam like you .Have you solved it?\r\n\r\nNope, There is no need to use c++ API on my project till now.', 'Facing same issue.']","['\r\n/path/to/incubator-mxnet/cpp-package/include/mxnet-cpp/base.h:31:25: fatal error: mxnet/c_api.h: No such file or directory\r\n', '\r\n#include ""mxnet/c_api.h""\r\n#include ""nnvm/c_api.h""\r\n', '\r\nINCLUDE_DIRECTORIES(\r\n    /path/to/incubator-mxnet/cpp-package/include\r\n    /path/to/incubator-mxnet/include\r\n    /path/to/incubator-mxnet/nnvm/include\r\n    /path/to/incubator-mxnet/dmlc-core/include\r\n    )\r\n']","['USE_CPP_PACKAGE = 1', 'cpp-package/include/mxnet-cpp/MxNetCpp.h', 'cpp-package/include/mxnet-cpp/base.h', 'mxnet/c_api.h', 'nnvm/c_api.h', 'include', 'lib']",0,0
199,incubator-mxnet,15165,open, Cannot open include file: 'cub/cub.cuh': No such file or directory,Looks like that file cannot be found when building the latest trunk,Installation Pending Requester Info,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Installation', 'I suspect that you did not clone the third party modules? Try\r\n\r\n```\r\ngit submodule update --init --recursive\r\n```\r\n\r\nand build again.', '@mxnet-label-bot add [Installation, Pending Requester Info]']",[],[],0,0
200,incubator-mxnet,10668,open,[feature request] Jenkins build restartable from comments in the PR,"I used to use a plugin like this to restart builds using a keyword trigger like . Could be handy.

@marcoabreu 

plugin: https://plugins.jenkins.io/github-pr-comment-build",CI Feature request,"[""Looks good, I'll definitely look into this""]",[],['rebuild'],0,0
201,incubator-mxnet,16793,open,[Numpy] [WIP] [RFC] Sample_n op for DeepNumpy,"## Description
Current design of DeepNumpy's random module follows native numpy in terms of the interpretation of the parameter .
More specifically,  indicates the final output size of the sampling operation. Parameter tensors, if narrower or smaller than , will be automatically broadcast to the output's shape.
However, this mechanism makes I.I.D sampling little bit tricky, for example:

Problem would arise in symbolic model, as the shape of  and  cannot be obtained in the frontend.

## Solution

The following  function could resolve this issue. (modified from: https://github.com/apache/incubator-mxnet/blob/master/src/operator/numpy/random/dist_common.h#L143)



Notice that the  function could stay the same.

The modified sampling method is now able to produce the following result:


",Feature request Numpy RFC,[],"['\r\nloc = loc_net(x)\r\nscale = scale_net(x)\r\nN = 10\r\n# Generate N samples from the network-parameterized gaussian\r\nnp.random.normal(loc, scale, (N,) + loc.shape)\r\n', '\r\ntemplate <typename DistParam>\r\ninline bool TwoparamsDistOpConcatShape(const nnvm::NodeAttrs &attrs,\r\n                                 std::vector<TShape> *in_attrs,\r\n                                 std::vector<TShape> *out_attrs) {\r\n  const DistParam &param = nnvm::get<DistParam>(attrs.parsed);\r\n  mxnet::TShape &low = (*in_attrs)[0];\r\n  mxnet::TShape &high = (*in_attrs)[1];\r\n  mxnet::TShape out(std::max(low.ndim(), high.ndim()), -1);\r\n  if (in_attrs->size() == 2U) {\r\n      // Both params from ndarray.\r\n      InferBroadcastShape(low, high, &out);\r\n    } else if (in_attrs->size() == 1U) {\r\n      // One param from ndarray.\r\n      out = in_attrs->at(0);\r\n    } else if (in_attrs->size() == 0) {\r\n      // Two scalar case.\r\n      out = TShape(0, -1);\r\n    }\r\n  if (param.size.has_value()) {\r\n    // Size declared.\r\n    std::vector<dim_t> oshape_vec;\r\n    const mxnet::Tuple<int> &size = param.size.value();\r\n    for (int i = 0; i < size.ndim(); ++i) {\r\n      oshape_vec.emplace_back(size[i]);\r\n    }\r\n    for (int i = 0; i < out.ndim(); ++i) {\r\n      oshape_vec.emplace_back(out[i]);\r\n    }\r\n    SHAPE_ASSIGN_CHECK(*out_attrs, 0, TShape(oshape_vec));\r\n    for (size_t input_idx = 0; input_idx < in_attrs->size(); input_idx++) {\r\n      CheckBroadcastable((*in_attrs)[input_idx], (*out_attrs)[0]);\r\n    }\r\n  } else {\r\n    SHAPE_ASSIGN_CHECK(*out_attrs, 0, out);\r\n  }\r\n  return out_attrs->at(0).ndim() != 0U;\r\n}\r\n', '\r\n>>> loc = np.zeros((3,3))\r\n>>> scale = np.ones((4,3,3))\r\n>>> npx.random.normal_N(loc, scale, (2,)).shape\r\n(2, 4, 3, 3)\r\n']","['size', 'size', 'size', 'loc', 'scale', 'InferShape', 'FCompute']",0,0
202,incubator-mxnet,12894,open,Training crash SSD with LeakyReLU(rrelu),"## Description
Training SSD networks with LeakyReLU (rrelu) activation causes the training to crash. I have tried different networks and vgg16_reduced.py as well. It always crashes

## Environment info (Required)

Package used (Python/R/Scala/Julia):
Python


## Build info (Required if built from source)
Compiler (gcc/clang/mingw/visual studio):
gcc

MXNet commit hash:
74638105f5480349cf57cda40a37475d626dbf41

Build config:
make -j4 USE_OPENCV=1 USE_BLAS=openblas USE_CUDA=1 USE_CUDA_PATH=/usr/local/cuda USE_CUDNN=1

## Error Message:


## Minimum reproducible example
In vgg16_reduced.py in example/ssd/symbol, make the following changes as shown below.

Replacing LeakyReLU with activations at other positions also causes the training to crash

## Steps to reproduce
python train.py --gpus 0,1 --batch-size 32 --pretrained '' 

## What have you tried to solve it?
I have had to replace LeakyReLU(rrelu) with other activations to get around this issue.
",Bug Operator,"['@rayjs thanks for reporting this issue and glad to see you have a workaround for it. Looks like this one is a bug in the operator. But just in case, could you please make sure that you are using this operator correctly by referring to this [documentation](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.LeakyReLU).\r\nSome of the args should be set or they go with default values.\r\n\r\n@mxnet-label-bot please add [python, operator]', '@lanking520 For` rrelu `the default parameters work so I am certain about the correct usage. `leaky` `act_type` works from what I have found but `rrelu` causes the training to crash. I have not checked the other `act_type` options in `LeakyReLU` other than these two', '@mxnet-label-bot please add [bug]', '@mxnet-label-bot [bug]', 'Same as #14447\r\n@mxnet-label-bot add [bug]']","[""\r\n----------Python Info----------\r\n('Version      :', '2.7.12')\r\n('Compiler     :', 'GCC 5.4.0 20160609')\r\n('Build        :', ('default', 'Dec  4 2017 14:50:18'))\r\n('Arch         :', ('64bit', 'ELF'))\r\n------------Pip Info-----------\r\n('Version      :', '18.1')\r\n('Directory    :', '/usr/local/lib/python2.7/dist-packages/pip')\r\n----------MXNet Info-----------\r\n('Version      :', '1.3.1')\r\n('Directory    :', '/home/xx/Documents/extern_libs/incubator-mxnet/python/mxnet')\r\nHashtag not found. Not installed from pre-built package.\r\n----------System Info----------\r\n('Platform     :', 'Linux-4.4.0-137-generic-x86_64-with-Ubuntu-16.04-xenial')\r\n('system       :', 'Linux')\r\n('node         :', 'et2')\r\n('release      :', '4.4.0-137-generic')\r\n('version      :', '#163-Ubuntu SMP Mon Sep 24 13:14:43 UTC 2018')\r\n----------Hardware Info----------\r\n('machine      :', 'x86_64')\r\n('processor    :', 'x86_64')\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                4\r\nOn-line CPU(s) list:   0-3\r\nThread(s) per core:    1\r\nCore(s) per socket:    4\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 94\r\nModel name:            Intel(R) Core(TM) i5-6500 CPU @ 3.20GHz\r\nStepping:              3\r\nCPU MHz:               3377.625\r\nCPU max MHz:           3600.0000\r\nCPU min MHz:           800.0000\r\nBogoMIPS:              6383.90\r\nVirtualization:        VT-x\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              6144K\r\nNUMA node0 CPU(s):     0-3\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch invpcid_single intel_pt ssbd ibrs ibpb stibp kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp flush_l1d\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.1568 sec, LOAD: 1.4836 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.1446 sec, LOAD: 2.0502 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.1938 sec,LOAD: 1.3499 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.1528 sec, LOAD: 0.1908 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.2012 sec, LOAD: 0.0508 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.3913 sec, LOAD: 0.8876 sec.\r\n"", '\r\n[16:24:25] src/io/iter_image_det_recordio.cc:283: ImageDetRecordIOParser: /home/xx/Documents/extern_libs/incubator-mxnet/example/ssd/data/train.rec, use 3 threads for decoding..\r\n[16:24:26] src/io/iter_image_det_recordio.cc:340: ImageDetRecordIOParser: /home/xx/Documents/extern_libs/incubator-mxnet/example/ssd/data/train.rec, label padding width: 350\r\n[16:24:26] src/io/iter_image_det_recordio.cc:283: ImageDetRecordIOParser: /home/xx/Documents/extern_libs/incubator-mxnet/example/ssd/data/val.rec, use 3 threads for decoding..\r\n[16:24:26] src/io/iter_image_det_recordio.cc:340: ImageDetRecordIOParser: /home/xx/Documents/extern_libs/incubator-mxnet/example/ssd/data/val.rec, label padding width: 350\r\n[<Symbol relu4_3>, <Symbol relu7>, <Symbol multi_feat_2_conv_3x3_relu>, <Symbol multi_feat_3_conv_3x3_relu>, <Symbol multi_feat_4_conv_3x3_relu>, <Symbol multi_feat_5_conv_3x3_relu>]\r\n<Symbol relu4_3>\r\n<Symbol relu7>\r\n<Symbol multi_feat_2_conv_3x3_relu>\r\n<Symbol multi_feat_3_conv_3x3_relu>\r\n<Symbol multi_feat_4_conv_3x3_relu>\r\n<Symbol multi_feat_5_conv_3x3_relu>\r\nINFO:root:Experimental: start training from scratch with (gpu(0),gpu(1))\r\n[16:24:32] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\nTraceback (most recent call last):\r\n  File ""train.py"", line 156, in <module>\r\n    voc07_metric=args.use_voc07_metric)\r\n  File ""/home/xx/Documents/extern_libs/incubator-mxnet/example/ssd/train/train_net.py"", line 301, in train_net\r\n    monitor=monitor)\r\n  File ""/home/xx/Documents/extern_libs/incubator-mxnet/python/mxnet/module/base_module.py"", line 539, in fit\r\n    self.update_metric(eval_metric, data_batch.label)\r\n  File ""/home/xx/Documents/extern_libs/incubator-mxnet/python/mxnet/module/module.py"", line 773, in update_metric\r\n    self._exec_group.update_metric(eval_metric, labels, pre_sliced)\r\n  File ""/home/xx/Documents/extern_libs/incubator-mxnet/python/mxnet/module/executor_group.py"", line 639, in update_metric\r\n    eval_metric.update_dict(labels_, preds)\r\n  File ""/home/xx/Documents/extern_libs/incubator-mxnet/python/mxnet/metric.py"", line 132, in update_dict\r\n    self.update(label, pred)\r\n  File ""/home/xx/Documents/extern_libs/incubator-mxnet/example/ssd/train/metric.py"", line 48, in update\r\n    cls_prob = preds[0].asnumpy()\r\n  File ""/home/xx/Documents/extern_libs/incubator-mxnet/python/mxnet/ndarray/ndarray.py"", line 1980, in asnumpy\r\n    ctypes.c_size_t(data.size)))\r\n  File ""/home/xx/Documents/extern_libs/incubator-mxnet/python/mxnet/base.py"", line 252, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [16:24:32] include/mxnet/././resource.h:155: Check failed: req.type == ResourceRequest::kTempSpace (42955292 vs. 1)\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /home/xx/Documents/extern_libs/incubator-mxnet//lib/libmxnet.so(dmlc::StackTrace[abi:cxx11]()+0x5b) [0x7f98868b8fdb]\r\n[bt] (1) /home/xx/Documents/extern_libs/incubator-mxnet//lib/libmxnet.so(mshadow::Tensor<mshadow::gpu, 1, unsigned int> mxnet::Resource::get_space_typed<mshadow::gpu, 1, unsigned int>(mshadow::Shape<1>, mshadow::Stream<mshadow::gpu>*) const+0x6c5) [0x7f9889b02f35]\r\n[bt] (2) /home/xx/Documents/extern_libs/incubator-mxnet//lib/libmxnet.so(mxnet::op::LeakyReLUOp<mshadow::gpu, float>::Forward(mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)+0x5bc) [0x7f988b936e0c]\r\n[bt] (3) /home/xx/Documents/extern_libs/incubator-mxnet//lib/libmxnet.so(mxnet::op::OperatorState::Forward(mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)+0x363) [0x7f98892bdbc3]\r\n[bt] (4) /home/xx/Documents/extern_libs/incubator-mxnet//lib/libmxnet.so(mxnet::exec::StatefulComputeExecutor::Run(mxnet::RunContext, bool)+0x59) [0x7f9889a0c829]\r\n[bt] (5) /home/xx/Documents/extern_libs/incubator-mxnet//lib/libmxnet.so(+0x3e29526) [0x7f98899d7526]\r\n[bt] (6) /home/xx/Documents/extern_libs/incubator-mxnet//lib/libmxnet.so(mxnet::engine::ThreadedEngine::ExecuteOprBlock(mxnet::RunContext, mxnet::engine::OprBlock*)+0x8f5) [0x7f9889926045]\r\n[bt] (7) /home/xx/Documents/extern_libs/incubator-mxnet//lib/libmxnet.so(void mxnet::engine::ThreadedEnginePerDevice::GPUWorker<(dmlc::ConcurrentQueueType)0>(mxnet::Context, bool, mxnet::engine::ThreadedEnginePerDevice::ThreadWorkerBlock<(dmlc::ConcurrentQueueType)0>*, std::shared_ptr<dmlc::ManualEvent> const&)+0xeb) [0x7f988993c78b]\r\n[bt] (8) /home/xx/Documents/extern_libs/incubator-mxnet//lib/libmxnet.so(std::_Function_handler<void (std::shared_ptr<dmlc::ManualEvent>), mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::{lambda()#4}::operator()() const::{lambda(std::shared_ptr<dmlc::ManualEvent>)#1}>::_M_invoke(std::_Any_data const&, std::shared_ptr<dmlc::ManualEvent>&&)+0x4e) [0x7f988993c9fe]\r\n[bt] (9) /home/xx/Documents/extern_libs/incubator-mxnet//lib/libmxnet.so(std::thread::_Impl<std::_Bind_simple<std::function<void (std::shared_ptr<dmlc::ManualEvent>)> (std::shared_ptr<dmlc::ManualEvent>)> >::_M_run()+0x4a) [0x7f988992563a]\r\n', '    relu1_1 = mx.symbol.LeakyReLU(data=conv1_1, act_type=""rrelu"", name=""relu1_1"")']",[],0,0
203,incubator-mxnet,9574,open,Large host memory usage when using GPU with mobilenets,"## Description
Running mobilenet

## Environment info (Required)



## Build info (Required if built from source)
clang
MXNet commit hash:

20253d5ce821ac012e2483b5dfb15bb5b7202f6d (Update test_gluon_model_zoo.py (#9539))

## Minimum reproducible example
### run_mobilenet.py


## Steps to reproduce


## What have you tried to solve it?

1. We will try to run Massif to see where the memory is going",Performance,['Seems the allocation happen inside libcuda\r\n![image_class_massif](https://user-images.githubusercontent.com/928489/35446019-b7e7a17e-02b3-11e8-9504-04e37ef139a8.jpg)\r\n![image_class_massif_gpu](https://user-images.githubusercontent.com/928489/35446020-b8027e40-02b3-11e8-97d5-b5a92c49e779.jpg)\r\n'],"[""\r\n----------Python Info----------\r\nVersion      : 3.6.2\r\nCompiler     : GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.42)\r\nBuild        : ('default', 'Jul 17 2017 16:44:45')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 9.0.1\r\nDirectory    : /Users/pllarroy/devel/mxnet/mxnet/mxnet_py3/lib/python3.6/site-packages/pip\r\n----------MXNet Info-----------\r\nobjc[26349]: Class CaptureDelegate is implemented in both /usr/local/Cellar/opencv/3.3.0_3/lib/libopencv_videoio.3.3.dylib (0x1128c35d8) and /Users/pllarroy/devel/mxnet/mxnet/mxnet_py3/lib/python3.6/site-packages/cv2/cv2.cpython-36m-darwin.so (0x128f66030). One of the two will be used. Which one is undefined.\r\nVersion      : 1.0.1\r\nDirectory    : /Users/pllarroy/devel/mxnet/mxnet/python/mxnet\r\nHashtag not found. Not installed from pre-built package.\r\n----------System Info----------\r\nPlatform     : Darwin-16.7.0-x86_64-i386-64bit\r\nsystem       : Darwin\r\nnode         : 186590d670bd.ant.amazon.com\r\nrelease      : 16.7.0\r\nversion      : Darwin Kernel Version 16.7.0: Thu Jan 11 22:59:40 PST 2018; root:xnu-3789.73.8~1/RELEASE_X86_64\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : i386\r\nb'machdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT PREFETCHW RDTSCP TSCI'\r\nb'machdep.cpu.leaf7_features: SMEP ERMS RDWRFSGS TSC_THREAD_OFFSET BMI1 AVX2 BMI2 INVPCID SMAP RDSEED ADX IPT FPU_CSDS'\r\nb'machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C'\r\nb'machdep.cpu.brand_string: Intel(R) Core(TM) i7-5557U CPU @ 3.10GHz'\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0427 sec, LOAD: 0.8934 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0383 sec, LOAD: 0.1173 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0396 sec, LOAD: 0.8027 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0500 sec, LOAD: 0.3847 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0010 sec, LOAD: 0.1996 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0408 sec, LOAD: 0.3463 sec.\r\n"", '\r\n#!/usr/bin/env python3\r\n# -*- coding: utf-8 -*-\r\n\'\'\'\r\nprofile mxnet cpu memory consumption when loading a super-thin network.\r\nrequires https://pypi.python.org/pypi/memory_profiler\r\n\'\'\'\r\n\r\nimport mxnet as mx\r\nfrom collections import namedtuple\r\nimport numpy as np\r\nimport cv2\r\nBatch = namedtuple(\'Batch\', [\'data\'])\r\nfrom scipy.misc import imread\r\n\r\n\r\ndef get_mobilenet():\r\n  \'\'\'\r\n  function to get the pre-trained mobilenet1.0 from gluon\'s model zoo\r\n  \'\'\'\r\n  from mxnet.gluon.model_zoo import vision\r\n  mobilenet  = vision.mobilenet1_0(pretrained=True)\r\n  image = mx.nd.zeros((1,3,512,512))\r\n  mobilenet.hybridize()\r\n  mobilenet.forward(image)\r\n  mobilenet.export(""mobilenet1.0"")\r\n\r\nN = 2048\r\n@profile\r\ndef my_func():\r\n    sym, arg_params, aux_params = mx.model.load_checkpoint(\'mobilenet1.0\', 0)\r\n    #mod = mx.mod.Module(symbol=sym, context=mx.gpu(), label_names=None)\r\n    mod = mx.mod.Module(symbol=sym, context=mx.cpu(), label_names=None)\r\n    mod.bind(for_training=False, data_shapes=[(\'data\', (1,3,N,N))], label_shapes=mod._label_shapes)\r\n    mod.set_params(arg_params, aux_params, allow_missing=False)\r\n    img = imread(\'dachshund.jpg\')\r\n    img = cv2.resize(img, (512, 512))\r\n    img = np.swapaxes(img, 0, 2)\r\n    img = np.swapaxes(img, 1, 2)\r\n    img = img[np.newaxis, :]\r\n    mod.forward(Batch([mx.nd.array(img)]))\r\n    prob = mod.get_outputs()[0].asnumpy()\r\n    prob = np.squeeze(prob)\r\n    a = np.argsort(prob)[::-1]\r\n    print(a[-10::])\r\n\r\n#run with: python -m memory_profiler run_mobilenet.py\r\n\r\nif __name__ == \'__main__\':\r\n    get_mobilenet()\r\n    my_func()\r\n\r\n\r\n# example output:\r\n# ../e/mobilenet_memory_profiling.txt\r\n#[745 752 307  58 968 751  74 127 947 685]\r\n#Filename: run_mobilenet.py\r\n\r\n#Line #    Mem usage    Increment   Line Contents\r\n#================================================\r\n#     8  148.652 MiB  148.652 MiB   @profile\r\n#     9                             def my_func():\r\n#    10  165.703 MiB   17.051 MiB       sym, arg_params, aux_params = mx.model.load_checkpoint(\'mobilenet1.0\', 0)\r\n#    11  165.711 MiB    0.008 MiB       mod = mx.mod.Module(symbol=sym, context=mx.gpu(), label_names=None)\r\n#    12 1334.297 MiB 1168.586 MiB       mod.bind(for_training=False, data_shapes=[(\'data\', (1,3,512,512))], label_shapes=mod._label_shapes)\r\n#    13 1338.840 MiB    4.543 MiB       mod.set_params(arg_params, aux_params, allow_missing=False)\r\n#    14 1340.129 MiB    1.289 MiB       img = imread(\'dachshund.jpg\')\r\n#    15 1344.844 MiB    4.715 MiB       img = cv2.resize(img, (512, 512))\r\n#    16 1344.844 MiB    0.000 MiB       img = np.swapaxes(img, 0, 2)\r\n#    17 1344.844 MiB    0.000 MiB       img = np.swapaxes(img, 1, 2)\r\n#    18 1344.844 MiB    0.000 MiB       img = img[np.newaxis, :]\r\n#    19                             #img = np.random.rand(1,3,512,512)\r\n#    20 1346.281 MiB    1.438 MiB       mod.forward(Batch([mx.nd.array(img)]))\r\n#    21 1346.344 MiB    0.062 MiB       prob = mod.get_outputs()[0].asnumpy()\r\n#    22 1346.344 MiB    0.000 MiB       prob = np.squeeze(prob)\r\n#    23 1346.402 MiB    0.059 MiB       a = np.argsort(prob)[::-1]\r\n#    24 1346.418 MiB    0.016 MiB       print(a[-10::])\r\n\r\n', '\r\npip install memory_profiler\r\npip install opencv-python\r\npip install scipy\r\npip install Pillow\r\nwget -O dachshund.jpg https://upload.wikimedia.org/wikipedia/commons/b/b9/Dachshund_brown_puppy.jpg\r\npython -m memory_profiler ./run_mobilenet.py\r\n']",[],0,0
204,incubator-mxnet,10207,open,mxnet.ndarray.khatri_rao needs GPU version,"## Description
1. khatri_rao was prematurely added to mx.nd/mx.sym namespace instead of contrib namespace which happened in https://github.com/apache/incubator-mxnet/pull/7781/files#r176510540.
2. khatri_rao doesn't have GPU version.

Given that this PR was merged last year, this feature has made its way into releases already. To resolve, we need to do one of the following:
1. mark the released op as deprecated and move it back to contrib in the next major version.
2. move forward: a) one more pass of vetting on the API design (cc @piiswrong), and then 2) implement the GPU version.

cc @cswiercz ",API change Operator,"['Also bringing in @jli05 ', 'Maybe this is for another thread: we need a strategy for an intermediate-level pure, complete tensor algebra library — an equivalent of Eigen in tensorflow. This library/module alone would *solely* provide algebra routines. Higher-level developers define ops.\r\n\r\nOtherwise it’s always half-baked thing for such ops — part of the code would try to be generic self-consciously, the rest would follow the templates and define the op.\r\n\r\nIt’s the moment we make a clean design in this regard if we want a complete/powerful tensor algebra inside mxnet I believe.', ""@piiswrong @cswiercz did you get a chance to sync? What's the conclusion?""]",[],[],0,0
205,incubator-mxnet,5677,open,Constant Initializer only works on keys ending with weight,"The Constant initializer only overrides the _init_weight method. Consequently, there is no good way to use existing initializers to initialize the values for bias terms, which always are set to zero.

Example code


The same is true for Uniform, and Normal, and while an argument could be made that *typically* when Uniform and Normal are used, biases are set to zero, this current design results in very unexpected behavior. If I apply a Constant, Uniform, or Normal, initializer to a variable, my expectation is that it will actually initialize the variable in that way! Only through digging into the source code is it apparent that this expectation is violated and even if it was made more apparent in the documentation, I don't think that's the right design anyway. The functions should work as you would expect from their name. If someone wants to treat bias terms uniquely, they should use a Mixed initializer to explicitly state that difference. Or, if initing bias to zero is common enough, allow that mode with a flag in the constructor of these initializers, so it's still explicit, but simpler than using Mixed.

For more complex initialization strategies, it makes sense that it's variable dependent.",Feature request Python Symbol,"['This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!', 'I  also met ... @tqchen @piiswrong @mli ', '@jmacglashan    Do you have any new findings？', '@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', 'Hello @jmacglashan - Thanks for submitting this issue. Can this be closed?', 'Why should it be closed @kalyc ?', ""@kalyc The behavior I originally described remains the same at least as of version 1.1. So I don't think this issue has been resolved. It could be debated that the mxnet team wants the behavior to be this way and can overrule me and close it for that reason, but I still find the behavior misleading and don't think it should be this way. I also haven't heard an argument for why it should be this way.""]","[""\r\ndata = mx.sym.var('data')\r\nout = mx.sym.FullyConnected(data, num_hidden=3, name='out')\r\nex = out.simple_bind(mx.cpu(), data=(1, 3))\r\ninit = mx.initializer.Constant(1)\r\ninit(mx.initializer.InitDesc('out_bias'), ex.arg_dict['out_bias'])\r\nprint(ex.arg_dict['out_bias'].asnumpy())\r\n""]",[],0,0
206,incubator-mxnet,16868,open,[Numpy] Infrastructure for implementing constraint check,"## Description

Checking the validity of parameters is crucial many operators, especially in distribution related Ops. (see references for the implementations of torch and tensorflow)

I implement an operator called , which takes a boolean tensor and an error message as input and then checks if all the elements are true, if not, raises exception with given message. It will return a scalar tensor  if none of the elements is false.

However, this Op fails in symbolic mode, as the output of this Op is neither returned to users nor used as the input for other Ops, causing the engine to completely ignore the check Op. In short, exception is not raised.

@leezu provides a workaround like this:

This approach works well, exception got thrown out as expected.

However, this method is not convenient when the  is buried in function called inside the hybrid_forward, e.g:

In such case, it becomes quite difficult to manually turn the  tensor into a return value.

--------------

Another solution could be the  op in control flow, which unfortunately, seems to be out of maintenance.

I believe, the simplest way is to have some kinds of mechanism that force MXNet to evaluate a particular OP.

I'm open to other solutions . (It would be great to implement this feature using only the existing infrastructure)

## References
- https://pytorch.org/docs/stable/_modules/torch/distributions/constraints.html#Constraint
- https://github.com/tensorflow/probability/blob/84cdabcdea19ce20d044fb7809b5742b953c9688/tensorflow_probability/python/internal/assert_util.py",Feature request,"['@sxjscience Any suggestions?', '@xidulu suggest we can add https://www.tensorflow.org/api_docs/python/tf/control_dependencies']","['\r\nclass WrapperHybridBlock(HybridBlock):\r\n  def __init__(self):\r\n    super(WrapperHybridBlock, self).__init__()\r\n\r\n  def __call__(self, *args):\r\n    tmp = super(WrapperHybridBlock, self).__call__(args)\r\n    tmp[-1].wait_to_read()\r\n    return tmp[:-1] if len(tmp) > 2 else tmp[0]\r\n\r\nclass foo(WrapperHybridBlock):\r\n  def __init__(self):\r\n    super(foo, self).__init__()\r\n\r\n  def hybrid_forward(self, F, arg):\r\n    low = arg[0]\r\n    high = arg[1]\r\n    flag = F.npx.constraint_check(high > low, ""error!"")\r\n    actual_output = F.np.random.uniform(low, high)\r\n    return (actual_output, flag)\r\n\r\ntest_foo = foo()\r\nlow = np.ones((4,4))\r\nhigh = np.ones((4,4)) - 2\r\ntest_foo.hybridize()\r\nprint(test_foo(low, high))\r\n', '\r\ndef func1(F, args):\r\n    F.npx.constraint_check(args)\r\n    return F.npx.other_func(args)\r\n\r\ndef func2(F, args):\r\n    t = func1(F, args)\r\n    return F.npx.other_func(t)\r\n\r\ndef hybrid_forward(self, F, args);\r\n    return func2(F, args)\r\n']","['npx.constraint_check', 'array(True)', 'constraint_check', 'flag', 'cond']",0,0
207,incubator-mxnet,14916,open,"Failed to convert pytorch networks with ""torch.view()"" to mxnet with ONNX","Hi, there!
It seems that the current mxnet could not convert basic CNN models like alexnet, resnet from pytorch simply because the shape in ONNX is defined as a Tensor rather than attribute (which is mentioned [here](https://github.com/apache/incubator-mxnet/issues/13395#issuecomment-443304545)).

Are there any specific plans of solving this problem ?

Notice that the error could even occur when it is not a dynamic reshape. A simple script to produce is like below

Error message is

",ONNX,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: ONNX, Bug', '@mxnet-label-bot  add [ONNX]\r\n\r\n@nicklhy Thanks for reporting this, we will look into this issue', 'After a deeper look at the source code. I noticed the convert function for ""reshape"" tries to read the ""shape"" values from the graph params dict at [python/mxnet/contrib/onnx/onnx2mx/_op_translations.py#L462](https://github.com/apache/incubator-mxnet/blob/2e03e9ff07b4c34cd165071aeb785db14b965ade/python/mxnet/contrib/onnx/onnx2mx/_op_translations.py#L462).\r\n\r\n```\r\nreshape_shape = list(proto_obj._params[inputs[1].name].asnumpy())\r\n```\r\n\r\nHowever, the ""shape"" tensor in ONNX has never been read and saved in that params dict. I managed to solve this problem by adding two lines listed below in [python/mxnet/contrib/onnx/onnx2mx/import_onnx.py](https://github.com/nicklhy/incubator-mxnet/commit/ed9651f4b087ed9e34fd1718302a5737ea3a1864) when performing the operator conversion\r\n```\r\nif op_name == \'Constant\':\r\n    self._params[mxnet_sym.name] = self._parse_array(node.attribute[0].t)\r\n```\r\nBTW, this may not work in the dynamic reshape case.', '@nicklhy  is this fix being pushed to the repo?', '@ahmed-shariff No, the above fix has not been pushed to the official repo yet.']","['python\r\nimport torch\r\nimport torch.nn as nn\r\nimport mxnet as mx\r\nfrom mxnet.contrib import onnx as onnx_mxnet\r\n\r\n\r\nclass A(nn.Module):\r\n    def __init__(self):\r\n        super(A, self).__init__()\r\n        pass\r\n\r\n    def forward(self, x):\r\n        return x.view(-1, 2)\r\n\r\n\r\nif __name__ == ""__main__"":\r\n    net = A()\r\n    x = torch.randn(1, 3, 224, 224)\r\n    torch.onnx.export(net, x, \'test_view.onnx\', verbose=True)\r\n    sym, arg_params, aux_params = onnx_mxnet.import_model(\'test_view.onnx\')\r\n', '\r\n$ test_view_bug.py\r\ngraph(%0 : Float(1, 3, 224, 224)) {\r\n  %1 : Tensor = onnx::Constant[value=-1  2 [ CPULongType{2} ]](), scope: A\r\n  %2 : Float(75264, 2) = onnx::Reshape(%0, %1), scope: A\r\n  return (%2);\r\n}\r\n\r\nTraceback (most recent call last):\r\n  File ""test_view_bug.py"", line 23, in <module>\r\n    sym, arg_params, aux_params = onnx_mxnet.import_model(\'test_view.onnx\')\r\n  File ""/home/lhy/Documents/Lib/incubator-mxnet/python/mxnet/contrib/onnx/onnx2mx/import_model.py"", line 59, in import_model\r\n    sym, arg_params, aux_params = graph.from_onnx(model_proto.graph)\r\n  File ""/home/lhy/Documents/Lib/incubator-mxnet/python/mxnet/contrib/onnx/onnx2mx/import_onnx.py"", line 116, in from_onnx\r\n    mxnet_sym = self._convert_operator(node_name, op_name, onnx_attr, inputs)\r\n  File ""/home/lhy/Documents/Lib/incubator-mxnet/python/mxnet/contrib/onnx/onnx2mx/import_onnx.py"", line 62, in _convert_operator\r\n    op_name, new_attrs, inputs = convert_map[op_name](attrs, inputs, self)\r\n  File ""/home/lhy/Documents/Lib/incubator-mxnet/python/mxnet/contrib/onnx/onnx2mx/_op_translations.py"", line 462, in reshape\r\n    reshape_shape = list(proto_obj._params[inputs[1].name].asnumpy())\r\nKeyError: \'identity0\'\r\n']",[],0,0
208,incubator-mxnet,12736,open,"Running build.py to generate .whl for Jetson, no LAPACK lib found","## Description

liblapack not found when trying to build mxnet wheel from ci/build.py for the jetson framework on a host computer. Installed wheel on Jetson to see what would happen and lapack supported functions returned errors, did not build correctly, as expected. 

## Environment info (Required)
Running the build.py on Ubuntu 16.04 (more info below)
Docker version 18.06.1-ce 

What to do:
1. Download the diagnosis script from https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/diagnose.py
2. Run the script using  and paste its output here. 

$ sudo python diagnose.py 
----------Python Info----------
('Version      :', '2.7.12')
('Compiler     :', 'GCC 5.4.0 20160609')
('Build        :', ('default', 'Dec  4 2017 14:50:18'))
('Arch         :', ('64bit', 'ELF'))
------------Pip Info-----------
('Version      :', '18.0')
('Directory    :', '/usr/local/lib/python2.7/dist-packages/pip')
----------MXNet Info-----------
No MXNet installed.
----------System Info----------
('Platform     :', 'Linux-4.15.0-34-generic-x86_64-with-Ubuntu-16.04-xenial')
('system       :', 'Linux')
('node         :', 'cfa-System-Product-Name')
('release      :', '4.15.0-34-generic')
('version      :', '#37~16.04.1-Ubuntu SMP Tue Aug 28 10:44:06 UTC 2018')
----------Hardware Info----------
('machine      :', 'x86_64')
('processor    :', 'x86_64')
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                8
On-line CPU(s) list:   0-7
Thread(s) per core:    2
Core(s) per socket:    4
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 158
Model name:            Intel(R) Core(TM) i7-7700K CPU @ 4.20GHz
Stepping:              9
CPU MHz:               4297.817
CPU max MHz:           4500.0000
CPU min MHz:           800.0000
BogoMIPS:              8400.00
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              8192K
NUMA node0 CPU(s):     0-7
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp flush_l1d
----------Network Test----------
Setting timeout: 10
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0063 sec, LOAD: 0.4813 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0086 sec, LOAD: 0.3699 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.1589 sec, LOAD: 0.9135 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0258 sec, LOAD: 0.0875 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0778 sec, LOAD: 0.6933 sec.
Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.1163 sec, LOAD: 0.6141 sec.


Package used (Python/R/Scala/Julia):
Python 2 (Listed above)


## Build info (Required if built from source)
Cloned the repository 10/3/2018

MXNet commit hash:
bcd24f85457821f9c0ce17d60e545a252a87a5ae

Build config:
Standard config.mk, copied from the crosscompile.jetson.mk

## Error Message: (Including some of preceding output)
build.py: 2018-10-04 13:04:06,562 Executing the equivalent of:
docker \
	run \
	--cap-add \
	SYS_PTRACE \
	--rm \
	--shm-size=500m \
	-v \
	/home/cfa/mxnet-1.3:/work/mxnet \
	-v \
	/home/cfa/mxnet-1.3/build:/work/build \
	-v \
	/tmp/ci_ccache:/work/ccache \
	-u \
	0:0 \
	-e \
	CCACHE_MAXSIZE=500G \
	-e \
	CCACHE_TEMPDIR=/tmp/ccache \
	-e \
	CCACHE_DIR=/work/ccache \
	-e \
	CCACHE_LOGFILE=/tmp/ccache.log \
	-ti \
	mxnetci/build.jetson \
	/work/mxnet/ci/docker/runtime_functions.sh \
	build_jetson

build.py: 2018-10-04 13:04:07,016 Started container: f3dad0aa9232
+ NOSE_COVERAGE_ARGUMENTS='--with-coverage --cover-inclusive --cover-xml --cover-branches --cover-package=mxnet'
+ set +x
+ pushd .
/work/mxnet /work/mxnet
+ cp make/crosscompile.jetson.mk ./config.mk
++ nproc
+ make -j8
Makefile:180: ""USE_LAPACK disabled because libraries were not found""


## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce

1. cloned the repo to mxnet-1.3
2. $ cd mxnet-1.3
3. $ sudo time ci/build.py -p jetson


## What have you tried to solve it?

1. Tried symbolically linking the liblapack.so and liblapack.a files to the main mxnet-1.3 folder on my host computer, tried hard copying as well.

How do I enable lapack for the ci/build.py method to make the .whl file to install on a Jetson TX2?
",ARM Build,"['@rev-KevinBenham Thank you for reporting the issue.\r\n\r\n@mxnet-label-bot [Build, ARM]']",[],['python diagnose.py'],0,0
209,incubator-mxnet,14349,open,installed mxnet using pip install mxnet==1.3.1. Using numpy 1.14.3. But the import mxnet fails,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
(Brief description of the problem in no more than 2 sentences.)
installed mxnet using pip install mxnet==1.3.1. Using numpy 1.14.3. But the import mxnet fails
with module not found


## Environment info (Required)
pip freeze has
mxnet==1.3.1
numpy==1.14.3

-

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...) : Python

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

 import mxnet as mx
  File ""C:\Users\achatterjee\AppData\Local\Programs\Python\Python36\lib\site-packages\mxnet\__init__.py"", line 24, in <module>
    from .context import Context, current_context, cpu, gpu, cpu_pinned
  File ""C:\Users\achatterjee\AppData\Local\Programs\Python\Python36\lib\site-packages\mxnet\context.py"", line 24, in <module>
    from .base import classproperty, with_metaclass, _MXClassPropertyMetaClass
  File ""C:\Users\achatterjee\AppData\Local\Programs\Python\Python36\lib\site-packages\mxnet\base.py"", line 213, in <module>
    _LIB = _load_lib()
  File ""C:\Users\achatterjee\AppData\Local\Programs\Python\Python36\lib\site-packages\mxnet\base.py"", line 204, in _load_lib
    lib = ctypes.CDLL(lib_path[0], ctypes.RTLD_LOCAL)
  File ""C:\Users\achatterjee\AppData\Local\Programs\Python\Python36\lib\ctypes\__init__.py"", line 348, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 126] The specified module could not be found


## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. import mxnet as mx
2.

## What have you tried to solve it?

1.
2.
",Installation,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Installation', '@aChatterjee13 , we now have MXNet v1.4 as well on PyPi. \r\nIs there any specific reason you are using v1.3.1 ? \r\n\r\nAlso, can you check the output of : \r\n\r\n``` pip show mxnet ``` \r\n\r\nThis will tell you the path where MXNet is installed. To me it looks like a path issue. \r\n\r\n@mxnet-label-bot Add [Installation]', 'v1.3.1 was already in the application. I even tried with the latest version. Was getting the same error.\r\n\r\npip show mxnet\r\nName: mxnet\r\nVersion: 1.3.1\r\nSummary: MXNet is an ultra-scalable deep learning framework. This version uses openblas.\r\nHome-page: https://github.com/apache/incubator-mxnet\r\nAuthor: UNKNOWN\r\nAuthor-email: UNKNOWN\r\nLicense: Apache 2.0\r\nLocation: c:\\users\\achatterjee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\r\nRequires: numpy, requests, graphviz\r\nRequired-by:', 'You can try to reinstall numpy again with pip from the **ORIGIN SOURCE**(i.e. not mirrors)', 'I tried to import mxnet in my local python promt which gives me the above error. But on my anaconda environment, the issue is not reproducible. Was working fine on the anaconda environment.\r\nManually compared the dependencies, in both the environments it is the same\r\n\r\ngraphviz<0.9.0,>=0.8.1 \r\nrequests<2.19.0,>=2.18.4\r\nnumpy<1.15.0,>=1.8.2\r\nchardet<3.1.0,>=3.0.2\r\nidna<2.7,>=2.5\r\nurllib3<1.23,>=1.21.1\r\ncertifi>=2017.4.17\r\n\r\nDoes anyone feel its due to some installation issues and any workarounds for this please', ""I don't think it's a dependency issue. It's most likely because pip install mxnet is installing the wheel file into the anaconda's environment, rather than the system's python env."", '> v1.3.1 was already in the application. I even tried with the latest version. Was getting the same error.\r\n> \r\n> pip show mxnet\r\n> Name: mxnet\r\n> Version: 1.3.1\r\n> Summary: MXNet is an ultra-scalable deep learning framework. This version uses openblas.\r\n> Home-page: https://github.com/apache/incubator-mxnet\r\n> Author: UNKNOWN\r\n> Author-email: UNKNOWN\r\n> License: Apache 2.0\r\n> Location: c:\\users\\achatterjee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\r\n> Requires: numpy, requests, graphviz\r\n> Required-by:\r\n\r\n**Do you see any issue with the path for this?**', '> > v1.3.1 was already in the application. I even tried with the latest version. Was getting the same error.\r\n> > pip show mxnet\r\n> > Name: mxnet\r\n> > Version: 1.3.1\r\n> > Summary: MXNet is an ultra-scalable deep learning framework. This version uses openblas.\r\n> > Home-page: https://github.com/apache/incubator-mxnet\r\n> > Author: UNKNOWN\r\n> > Author-email: UNKNOWN\r\n> > License: Apache 2.0\r\n> > Location: c:\\users\\achatterjee\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\r\n> > Requires: numpy, requests, graphviz\r\n> > Required-by:\r\n> \r\n> **Do you see any issue with the path for this?**\r\n\r\nNot with this path though.', 'Can you try and see what does ```which python``` output ? ', 'Python prompt:\r\n\r\nC:\\Users\\achatterjee\\Desktop>python --version\r\nPython 3.6.5\r\n\r\nC:\\Users\\achatterjee\\Desktop>where python\r\nC:\\Users\\achatterjee\\AppData\\Local\\Programs\\Python\\Python36\\python.exe\r\n\r\nAnaconda prompt:\r\n(base) C:\\Users\\achatterjee>where python\r\nC:\\Users\\achatterjee\\AppData\\Local\\Continuum\\anaconda3\\python.exe\r\nC:\\Users\\achatterjee\\AppData\\Local\\Programs\\Python\\Python36\\python.exe\r\n\r\n(base) C:\\Users\\achatterjee>python --version\r\nPython 3.6.5 :: Anaconda, Inc.\r\n', '@aChatterjee13  It can happened in a way that pip does not linked to the python you used. Recommended to create a conda environment or pip environment to install and run mxnet. Please let me know if you are facing any problems by doing so.']",[],"['', '\r\nWhat to do:\r\n1. Download the diagnosis script from https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/diagnose.py\r\n2. Run the script using ', "" and paste its output here.\r\n---------Python Info----------\r\nVersion      : 3.6.5\r\nCompiler     : MSC v.1900 64 bit (AMD64)\r\nBuild        : ('v3.6.5:f59c0932b4', 'Mar 28 2018 17:00:18')\r\nArch         : ('64bit', 'WindowsPE')\r\n------------Pip Info-----------\r\nVersion      : 19.0.3\r\nDirectory    : C:\\Users\\achatterjee\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pip\r\n----------MXNet Info-----------\r\nHashtag not found. Not installed from pre-built package.\r\n----------System Info----------\r\nPlatform     : Windows-10-10.0.17134-SP0\r\nsystem       : Windows\r\nnode         : ############\r\nrelease      : 10\r\nversion      : 10.0.17134\r\n----------Hardware Info----------\r\nmachine      : AMD64\r\nprocessor    : Intel64 Family 6 Model 142 Stepping 9, GenuineIntel\r\nName\r\nIntel(R) Core(TM) i5-7300U CPU @ 2.60GHz\r\n\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0410 sec, LOAD: 2.8368 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0261 sec, LOAD: 0.1988 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0280 sec, LOAD: 1.6875 sec.\r\nError open FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:833)>, DNS finished in 0.02769947052001953 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0334 sec, LOAD: 1.4759 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0000 sec, LOAD: 0.2348 sec.\r\n\r\n"", '', 'java -version', 'mvn -version', 'scala -version', 'sessionInfo()', 'git rev-parse HEAD']",0,0
210,incubator-mxnet,9755,open,Feature request: move NDArrayiter to Core API,"The Core API's [IO](https://github.com/apache/incubator-mxnet/tree/master/src/io) isn't being updated to incude [NDArrayIter](https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/io.py#L544), which forces developers for the other languages to write equivalants. If  were in the Core API like , , , etc, then it would be called by all languages through each language's MXDataIter wrapper. 

 was first introduced as [NumpyIter](https://github.com/apache/incubator-mxnet/blob/f6327ecf86d8a169ec1277c1e7809ed14f89b0c0/python/mxnet/io.py#L83) by @sneakerkg in 2015, but evolved into a general numeric vector iterator that is useful in languages other than Python, such as in R, which defined but doesn't implement an [R NDArrayIter](https://github.com/apache/incubator-mxnet/blob/master/R-package/src/io.h#L92) as seen in the comments:

It would make more sense to have  in the Core, so it can be called by [R's MXDataIter wrapper](https://github.com/apache/incubator-mxnet/blob/master/R-package/src/io.h#L53). Then it could also be accessed by [Scala's MXDataIter wrapper](https://github.com/apache/incubator-mxnet/blob/master/scala-package/core/src/main/scala/ml/dmlc/mxnet/io//MXDataIter.scala). But instead, they had to code and test their own [Scala NDArrayIter](https://github.com/apache/incubator-mxnet/blob/master/scala-package/core/src/main/scala/ml/dmlc/mxnet/io/NDArrayIter.scala). The C++ API doesn’t even mention  and only has the [C++ MXDataIter wrapper](https://github.com/apache/incubator-mxnet/blob/master/cpp-package/include/mxnet-cpp/io.h). ",Backend Call for Contribution Feature request,"['You make a good point. Is this just legacy code waiting to be fixed or is there any strong reason for not doing this ? @piiswrong', '@piiswrong I want this feature enough to actually implement it, but would like guidance on how to do so. How would this impact the Python code?', 'This seems to be related to MXNet backend, not C++ API. This request seems to suggest to refactor Python API, extract NDArrayIter implementation from it and move it into MXNet engine itself so that all language APIs could access it and don\'t need to reimplement like it currently is in Python.\r\n\r\n@nswamy, could you please update labels of this issue: remove ""C++"" and add ""Backend""? Thanks!', 'Can I take this up ?', '@saisiddhant12 thanks for offering to help. @zhreshold recently worked on moving the python dataloader to the backend and can suggest on how to proceed.']","['\r\n/*!\r\n * \\brief data iterator that takes a NumericVector\r\n *  Shuffles it and iterate over its content.\r\n *  TODO(KK, tq) implement this when have time.\r\n *  c.f. python/io.py:NDArrayIter\r\n */\r\n']","['NDArrayIter', 'CSVIter', 'ImageRecordIter', 'MNISTIter', 'NDArrayiter', 'NDArrayIter', 'NDArrayIter']",0,0
211,incubator-mxnet,16656,open,"When I use different size inference, self.reshape()  Error in `/usr/bin/python': free(): invalid pointer: 0x00007f9a484890a0","NFO: 56358:  2019-10-28 08:26:33: main_crack_segmentation.py:382 * segmentation crack...
/usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/module/base_module.py:66: UserWarning: Data provided by label_shapes don't match names specified by label_names ([] vs. ['softmax_label'])
  warnings.warn(msg)
*** Error in `/usr/bin/python': free(): invalid pointer: 0x00007f9a484890a0 ***
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f9a764bc7e5]
/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f9a764c537a]
/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f9a764c953c]
/usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/libmxnet.so(MXExecutorReshape+0x1de7)[0x7f99c3a2d5e7]
/usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c)[0x7f9a0cfcfe40]
/usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x2eb)[0x7f9a0cfcf8ab]
/usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48f)[0x7f9a0d1df3df]
/usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x11d82)[0x7f9a0d1e3d82]
/usr/bin/python(PyEval_EvalFrameEx+0x578d)[0x4c166d]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python[0x4d57a3]
/usr/bin/python(PyObject_Call+0x3e)[0x4a587e]
/usr/bin/python(PyEval_EvalFrameEx+0x263e)[0x4be51e]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]
/usr/bin/python(PyEval_EvalFrameEx+0x553f)[0x4c141f]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]
/usr/bin/python(PyEval_EvalFrameEx+0x553f)[0x4c141f]
/usr/bin/python(PyEval_EvalFrameEx+0x553f)[0x4c141f]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python[0x4eb69f]
/usr/bin/python(PyRun_FileExFlags+0x82)[0x4e58f2]
/usr/bin/python[0x54aae7]
/usr/bin/python(PyEval_EvalFrameEx+0x5f3e)[0x4c1e1e]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python(PyEval_EvalFrameEx+0x58e6)[0x4c17c6]
/usr/bin/python(PyEval_EvalFrameEx+0x553f)[0x4c141f]
/usr/bin/python(PyEval_EvalCodeEx+0x306)[0x4b9b66]
/usr/bin/python[0x4eb69f]
/usr/bin/python(PyRun_FileExFlags+0x82)[0x4e58f2]
/usr/bin/python(PyRun_SimpleFileExFlags+0x186)[0x4e41a6]
/usr/bin/python(Py_Main+0x54e)[0x4938ce]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7f9a76465830]
/usr/bin/python(_start+0x29)[0x493299]
======= Memory map: ========
00400000-006de000 r-xp 00000000 08:21 62529595                           /usr/bin/python2.7
008dd000-008de000 r--p 002dd000 08:21 62529595                           /usr/bin/python2.7
008de000-00955000 rw-p 002de000 08:21 62529595                           /usr/bin/python2.7
00955000-00978000 rw-p 00000000 00:00 0 
00fae000-2d86a000 rw-p 00000000 00:00 0                                  [heap]
200000000-200200000 rw-s 00000000 00:06 815                              /dev/nvidiactl
200200000-200400000 ---p 00000000 00:00 0 
200400000-200404000 rw-s 00000000 00:06 815                              /dev/nvidiactl
200404000-200600000 ---p 00000000 00:00 0 
200600000-200a00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
200a00000-201800000 ---p 00000000 00:00 0 
201800000-201804000 rw-s 00000000 00:06 815                              /dev/nvidiactl
201804000-201a00000 ---p 00000000 00:00 0 
201a00000-201e00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
201e00000-202c00000 ---p 00000000 00:00 0 
202c00000-202c04000 rw-s 00000000 00:06 815                              /dev/nvidiactl
202c04000-202e00000 ---p 00000000 00:00 0 
202e00000-203200000 rw-s 00000000 00:06 815                              /dev/nvidiactl
203200000-204000000 ---p 00000000 00:00 0 
204000000-204004000 rw-s 00000000 00:06 815                              /dev/nvidiactl
204004000-204200000 ---p 00000000 00:00 0 
204200000-204600000 rw-s 00000000 00:06 815                              /dev/nvidiactl
204600000-205400000 ---p 00000000 00:00 0 
205400000-205404000 rw-s 00000000 00:06 815                              /dev/nvidiactl
205404000-205600000 ---p 00000000 00:00 0 
205600000-205a00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
205a00000-206800000 ---p 00000000 00:00 0 
206800000-206804000 rw-s 00000000 00:06 815                              /dev/nvidiactl
206804000-206a00000 ---p 00000000 00:00 0 
206a00000-206e00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
206e00000-207c00000 ---p 00000000 00:00 0 
207c00000-207c04000 rw-s 00000000 00:06 815                              /dev/nvidiactl
207c04000-207e00000 ---p 00000000 00:00 0 
207e00000-208200000 rw-s 00000000 00:06 815                              /dev/nvidiactl
208200000-209000000 ---p 00000000 00:00 0 
209000000-209004000 rw-s 00000000 00:06 815                              /dev/nvidiactl
209004000-209200000 ---p 00000000 00:00 0 
209200000-209600000 rw-s 00000000 00:06 815                              /dev/nvidiactl
209600000-20a400000 ---p 00000000 00:00 0 
20a400000-20a404000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20a404000-20a600000 ---p 00000000 00:00 0 
20a600000-20aa00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20aa00000-20aa04000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20aa04000-20ac00000 ---p 00000000 00:00 0 
20ac00000-20b000000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20b000000-20b004000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20b004000-20b200000 ---p 00000000 00:00 0 
20b200000-20b600000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20b600000-20b604000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20b604000-20b800000 ---p 00000000 00:00 0 
20b800000-20bc00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20bc00000-20bc04000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20bc04000-20be00000 ---p 00000000 00:00 0 
20be00000-20c200000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20c200000-20c204000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20c204000-20c400000 ---p 00000000 00:00 0 
20c400000-20c800000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20c800000-20c804000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20c804000-20ca00000 ---p 00000000 00:00 0 
20ca00000-20ce00000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20ce00000-20ce04000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20ce04000-20d000000 ---p 00000000 00:00 0 
20d000000-20d400000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20d400000-20d600000 ---p 00000000 00:00 0 
20d600000-20d800000 rw-s 00000000 00:06 815                              /dev/nvidiactl
20d800000-c00200000 ---p 00000000 00:00 0 
10000000000-10b04000000 ---p 00000000 00:00 0 
7f9823829000-7f9834000000 rw-p 00000000 00:00 0 
7f9834000000-7f9834022000 rw-p 00000000 00:00 0 
7f9834022000-7f9838000000 ---p 00000000 00:00 0 
7f9838000000-7f983a08a000 rw-p 00000000 00:00 0 
7f983a08a000-7f983c000000 ---p 00000000 00:00 0 
7f983c000000-7f983c022000 rw-p 00000000 00:00 0 
7f983c022000-7f9840000000 ---p 00000000 00:00 0 
7f9842807000-7f9849009000 rw-p 00000000 00:00 0 
7f984d7fe000-7f9854000000 rw-p 00000000 00:00 0 
7f9854000000-7f98569b9000 rw-p 00000000 00:00 0 
7f98569b9000-7f9858000000 ---p 00000000 00:00 0 
7f985c000000-7f985db22000 rw-p 00000000 00:00 0 
7f985db22000-7f9860000000 ---p 00000000 00:00 0 
7f9864000000-7f9866f05000 rw-p 00000000 00:00 0 
7f9866f05000-7f9868000000 ---p 00000000 00:00 0 
7f9868000000-7f986be05000 rw-p 00000000 00:00 0 
7f986be05000-7f986c000000 ---p 00000000 00:00 0 
7f986c000000-7f986ff25000 rw-p 00000000 00:00 0 
7f986ff25000-7f9870000000 ---p 00000000 00:00 0 
7f9870200000-7f9870800000 ---p 00000000 00:00 0 
7f98709fd000-7f98709fe000 ---p 00000000 00:00 0 
7f98709fe000-7f98711fe000 rw-p 00000000 00:00 0 
7f98711fe000-7f98711ff000 ---p 00000000 00:00 0 
7f98711ff000-7f98719ff000 rw-p 00000000 00:00 0 
7f98721fd000-7f98721fe000 ---p 00000000 00:00 0 
7f98721fe000-7f98729fe000 rw-p 00000000 00:00 0 
7f98729fe000-7f98729ff000 ---p 00000000 00:00 0 
7f98729ff000-7f98731ff000 rw-p 00000000 00:00 0 
7f98731ff000-7f9873200000 ---p 00000000 00:00 0 
7f9873200000-7f9873a00000 rw-p 00000000 00:00 0 
7f9873a00000-7f9874000000 ---p 00000000 00:00 0 
7f9874000000-7f9877da7000 rw-p 00000000 00:00 0 
7f9877da7000-7f9878000000 ---p 00000000 00:00 0 
7f9878200000-7f9878400000 ---p 00000000 00:00 0 
7f98785ff000-7f9878600000 ---p 00000000 00:00 0 
7f9878600000-7f9878e00000 rw-p 00000000 00:00 0 
7f9878e00000-7f9894000000 ---p 00000000 00:00 0 
7f9894000000-7f9898091000 rw-p 00000000 00:00 0 
7f9898091000-7f989c000000 ---p 00000000 00:00 0 
7f989c000000-7f989ffff000 rw-p 00000000 00:00 0 
7f989ffff000-7f98a0000000 ---p 00000000 00:00 0 
7f98a0000000-7f98a3f49000 rw-p 00000000 00:00 0 
7f98a3f49000-7f98a4000000 ---p 00000000 00:00 0 
7f98a4000000-7f98a7fce000 rw-p 00000000 00:00 0 
7f98a7fce000-7f98a8000000 ---p 00000000 00:00 0 
7f98a8000000-7f98abfee000 rw-p 00000000 00:00 0 
7f98abfee000-7f98ac000000 ---p 00000000 00:00 0 
7f98ac000000-7f98aff87000 rw-p 00000000 00:00 0 
7f98aff87000-7f98b0000000 ---p 00000000 00:00 0 
7f98b0000000-7f98b4000000 rw-p 00000000 00:00 0 
7f98b4000000-7f98b7efc000 rw-p 00000000 00:00 0 
7f98b7efc000-7f98b8000000 ---p 00000000 00:00 0 
7f98b8000000-7f98bc000000 rw-p 00000000 00:00 0 
7f98bc000000-7f98bd0a3000 rw-p 00000000 00:00 0 
7f98bd0a3000-7f98c0000000 ---p 00000000 00:00 0 
7f98c0000000-7f98c4000000 rw-p 00000000 00:00 0 
7f98c4000000-7f98c7ffe000 rw-p 00000000 00:00 0 
7f98c7ffe000-7f98c8000000 ---p 00000000 00:00 0 
7f98c8000000-7f98cbffd000 rw-p 00000000 00:00 0 
7f98cbffd000-7f98cc000000 ---p 00000000 00:00 0 
7f98cc000000-7f98d0000000 rw-p 00000000 00:00 0 
7f98d0000000-7f98d8000000 ---p 00000000 00:00 0 
7f98d8000000-7f98d8021000 rw-p 00000000 00:00 0 
7f98d8021000-7f98dc000000 ---p 00000000 00:00 0 
7f98dc200000-7f98e0000000 ---p 00000000 00:00 0 
7f98e0000000-7f98e0021000 rw-p 00000000 00:00 0 
7f98e0021000-7f98e4000000 ---p 00000000 00:00 0 
7f98e4200000-7f98e4e00000 ---p 00000000 00:00 0 
7f98e4ffe000-7f98eaffe000 ---p 00000000 00:00 0 
7f98eaffe000-7f98f4000000 rw-p 00000000 00:00 0 
7f98f4000000-7f98f4022000 rw-p 00000000 00:00 0 
7f98f4022000-7f98f8000000 ---p 00000000 00:00 0 
7f98f8000000-7f98f8022000 rw-p 00000000 00:00 0 
7f98f8022000-7f98fc000000 ---p 00000000 00:00 0 
7f98fc000000-7f98fc022000 rw-p 00000000 00:00 0 
7f98fc022000-7f9900000000 ---p 00000000 00:00 0 
7f9900200000-7f9900800000 ---p 00000000 00:00 0 
7f99009fc000-7f9904000000 rw-p 00000000 00:00 0 
7f9904000000-7f9904022000 rw-p 00000000 00:00 0 
7f9904022000-7f9908000000 ---p 00000000 00:00 0 
7f9908248000-7f9909d4b000 rw-p 00000000 00:00 0 
7f9909d4b000-7f9909d54000 r-xp 00000000 08:21 62787974                   /usr/lib/python2.7/lib-dynload/bz2.x86_64-linux-gnu.so
7f9909d54000-7f9909f53000 ---p 00009000 08:21 62787974                   /usr/lib/python2.7/lib-dynload/bz2.x86_64-linux-gnu.so
7f9909f53000-7f9909f54000 r--p 00008000 08:21 62787974                   /usr/lib/python2.7/lib-dynload/bz2.x86_64-linux-gnu.so
7f9909f54000-7f9909f56000 rw-p 00009000 08:21 62787974                   /usr/lib/python2.7/lib-dynload/bz2.x86_64-linux-gnu.so
7f9909f56000-7f9909f57000 ---p 00000000 00:00 0 
7f9909f57000-7f990a757000 rw-p 00000000 00:00 0 
7f990a757000-7f990a767000 r-xp 00000000 08:21 2233737                    /usr/lib/python2.7/dist-packages/h5py/h5l.x86_64-linux-gnu.so
7f990a767000-7f990a966000 ---p 00010000 08:21 2233737                    /usr/lib/python2.7/dist-packages/h5py/h5l.x86_64-linux-gnu.so
7f990a966000-7f990a967000 r--p 0000f000 08:21 2233737                    /usr/lib/python2.7/dist-packages/h5py/h5l.x86_64-linux-gnu.so
7f990a967000-7f990a96a000 rw-p 00010000 08:21 2233737                    /usr/lib/python2.7/dist-packages/h5py/h5l.x86_64-linux-gnu.so
7f990a96a000-7f990a97b000 r-xp 00000000 08:21 2233672                    /usr/lib/python2.7/dist-packages/h5py/h5o.x86_64-linux-gnu.so
7f990a97b000-7f990ab7a000 ---p 00011000 08:21 2233672                    /usr/lib/python2.7/dist-packages/h5py/h5o.x86_64-linux-gnu.so
7f990ab7a000-7f990ab7b000 r--p 00010000 08:21 2233672                    /usr/lib/python2.7/dist-packages/h5py/h5o.x86_64-linux-gnu.so
7f990ab7b000-7f990ab7e000 rw-p 00011000 08:21 2233672                    /usr/lib/python2.7/dist-packages/h5py/h5o.x86_64-linux-gnu.so
7f990ab7e000-7f990ab7f000 rw-p 00000000 00:00 0 
7f990ab7f000-7f990ab83000 r-xp 00000000 08:21 2233671                    /usr/lib/python2.7/dist-packages/h5py/h5fd.x86_64-linux-gnu.so
7f990ab83000-7f990ad82000 ---p 00004000 08:21 2233671                    /usr/lib/python2.7/dist-packages/h5py/h5fd.x86_64-linux-gnu.so
7f990ad82000-7f990ad83000 r--p 00003000 08:21 2233671                    /usr/lib/python2.7/dist-packages/h5py/h5fd.x86_64-linux-gnu.so
7f990ad83000-7f990ad84000 rw-p 00004000 08:21 2233671                    /usr/lib/python2.7/dist-packages/h5py/h5fd.x86_64-linux-gnu.so
7f990ad84000-7f990ad8f000 r-xp 00000000 08:21 2233717                    /usr/lib/python2.7/dist-packages/h5py/h5i.x86_64-linux-gnu.so
7f990ad8f000-7f990af8e000 ---p 0000b000 08:21 2233717                    /usr/lib/python2.7/dist-packages/h5py/h5i.x86_64-linux-gnu.so
7f990af8e000-7f990af8f000 r--p 0000a000 08:21 2233717                    /usr/lib/python2.7/dist-packages/h5py/h5i.x86_64-linux-gnu.so
7f990af8f000-7f990af91000 rw-p 0000b000 08:21 2233717                    /usr/lib/python2.7/dist-packages/h5py/h5i.x86_64-linux-gnu.so
7f990af91000-7f990afa7000 r-xp 00000000 08:21 2233684                    /usr/lib/python2.7/dist-packages/h5py/h5g.x86_64-linux-gnu.so
7f990afa7000-7f990b1a6000 ---p 00016000 08:21 2233684                    /usr/lib/python2.7/dist-packages/h5py/h5g.x86_64-linux-gnu.so
7f990b1a6000-7f990b1a7000 r--p 00015000 08:21 2233684                    /usr/lib/python2.7/dist-packages/h5py/h5g.x86_64-linux-gnu.so
7f990b1a7000-7f990b1aa000 rw-p 00016000 08:21 2233684                    /usr/lib/python2.7/dist-packages/h5py/h5g.x86_64-linux-gnu.so
7f990b1aa000-7f990b1bf000 r-xp 00000000 08:21 2233735                    /usr/lib/python2.7/dist-packages/h5py/h5f.x86_64-linux-gnu.so
7f990b1bf000-7f990b3be000 ---p 00015000 08:21 2233735                    /usr/lib/python2.7/dist-packages/h5py/h5f.x86_64-linux-gnu.so
7f990b3be000-7f990b3bf000 r--p 00014000 08:21 2233735                    /usr/lib/python2.7/dist-packages/h5py/h5f.x86_64-linux-gnu.so
7f990b3bf000-7f990b3c2000 rw-p 00015000 08:21 2233735                    /usr/lib/python2.7/dist-packages/h5py/h5f.x86_64-linux-gnu.so
7f990b3c2000-7f990b3c3000 rw-p 00000000 00:00 0 
7f990b3c3000-7f990b3d0000 r-xp 00000000 08:21 2233673                    /usr/lib/python2.7/dist-packages/h5py/h5ds.x86_64-linux-gnu.so
7f990b3d0000-7f990b5cf000 ---p 0000d000 08:21 2233673                    /usr/lib/python2.7/dist-packages/h5py/h5ds.x86_64-linux-gnu.so
7f990b5cf000-7f990b5d0000 r--p 0000c000 08:21 2233673                    /usr/lib/python2.7/dist-packages/h5py/h5ds.x86_64-linux-gnu.so
7f990b5d0000-7f990b5d2000 rw-p 0000d000 08:21 2233673                    /usr/lib/python2.7/dist-packages/h5py/h5ds.x86_64-linux-gnu.so
7f990b5d2000-7f990b5e6000 r-xp 00000000 08:21 2233716                    /usr/lib/python2.7/dist-packages/h5py/h5d.x86_64-linux-gnu.so
7f990b5e6000-7f990b7e5000 ---p 00014000 08:21 2233716                    /usr/lib/python2.7/dist-packages/h5py/h5d.x86_64-linux-gnu.so
7f990b7e5000-7f990b7e6000 r--p 00013000 08:21 2233716                    /usr/lib/python2.7/dist-packages/h5py/h5d.x86_64-linux-gnu.so
7f990b7e6000-7f990b7e9000 rw-p 00014000 08:21 2233716                    /usr/lib/python2.7/dist-packages/h5py/h5d.x86_64-linux-gnu.so
7f990b7e9000-7f990b7f0000 r-xp 00000000 08:21 2233682                    /usr/lib/python2.7/dist-packages/h5py/_proxy.x86_64-linux-gnu.so
7f990b7f0000-7f990b9ef000 ---p 00007000 08:21 2233682                    /usr/lib/python2.7/dist-packages/h5py/_proxy.x86_64-linux-gnu.so
7f990b9ef000-7f990b9f0000 r--p 00006000 08:21 2233682                    /usr/lib/python2.7/dist-packages/h5py/_proxy.x86_64-linux-gnu.so
7f990b9f0000-7f990b9f1000 rw-p 00007000 08:21 2233682                    /usr/lib/python2.7/dist-packages/h5py/_proxy.x86_64-linux-gnu.so
7f990b9f1000-7f990b9fc000 r-xp 00000000 08:21 2233676                    /usr/lib/python2.7/dist-packages/h5py/h5ac.x86_64-linux-gnu.so
7f990b9fc000-7f990bbfb000 ---p 0000b000 08:21 2233676                    /usr/lib/python2.7/dist-packages/h5py/h5ac.x86_64-linux-gnu.so
7f990bbfb000-7f990bbfc000 r--p 0000a000 08:21 2233676                    /usr/lib/python2.7/dist-packages/h5py/h5ac.x86_64-linux-gnu.so
7f990bbfc000-7f990bbfd000 rw-p 0000b000 08:21 2233676                    /usr/lib/python2.7/dist-packages/h5py/h5ac.x86_64-linux-gnu.so
7f990bbfd000-7f990bc25000 r-xp 00000000 08:21 2233678                    /usr/lib/python2.7/dist-packages/h5py/h5p.x86_64-linux-gnu.so
7f990bc25000-7f990be25000 ---p 00028000 08:21 2233678                    /usr/lib/python2.7/dist-packages/h5py/h5p.x86_64-linux-gnu.so
7f990be25000-7f990be26000 r--p 00028000 08:21 2233678                    /usr/lib/python2.7/dist-packages/h5py/h5p.x86_64-linux-gnu.so
7f990be26000-7f990be2e000 rw-p 00029000 08:21 2233678                    /usr/lib/python2.7/dist-packages/h5py/h5p.x86_64-linux-gnu.so
7f990be2e000-7f990be2f000 rw-p 00000000 00:00 0 
7f990be2f000-7f990be43000 r-xp 00000000 08:21 2233718                    /usr/lib/python2.7/dist-packages/h5py/h5s.x86_64-linux-gnu.so
7f990be43000-7f990c042000 ---p 00014000 08:21 2233718                    /usr/lib/python2.7/dist-packages/h5py/h5s.x86_64-linux-gnu.so
7f990c042000-7f990c043000 r--p 00013000 08:21 2233718                    /usr/lib/python2.7/dist-packages/h5py/h5s.x86_64-linux-gnu.so
7f990c043000-7f990c046000 rw-p 00014000 08:21 2233718                    /usr/lib/python2.7/dist-packages/h5py/h5s.x86_64-linux-gnu.so
7f990c046000-7f990c047000 rw-p 00000000 00:00 0 
7f990c047000-7f990c05c000 r-xp 00000000 08:21 2233681                    /usr/lib/python2.7/dist-packages/h5py/h5a.x86_64-linux-gnu.so
7f990c05c000-7f990c25c000 ---p 00015000 08:21 2233681                    /usr/lib/python2.7/dist-packages/h5py/h5a.x86_64-linux-gnu.so
7f990c25c000-7f990c25d000 r--p 00015000 08:21 2233681                    /usr/lib/python2.7/dist-packages/h5py/h5a.x86_64-linux-gnu.so
7f990c25d000-7f990c260000 rw-p 00016000 08:21 2233681                    /usr/lib/python2.7/dist-packages/h5py/h5a.x86_64-linux-gnu.so
7f990c260000-7f990c267000 r-xp 00000000 08:21 2233721                    /usr/lib/python2.7/dist-packages/h5py/h5z.x86_64-linux-gnu.so
7f990c267000-7f990c466000 ---p 00007000 08:21 2233721                    /usr/lib/python2.7/dist-packages/h5py/h5z.x86_64-linux-gnu.so
7f990c466000-7f990c467000 r--p 00006000 08:21 2233721                    /usr/lib/python2.7/dist-packages/h5py/h5z.x86_64-linux-gnu.so
7f990c467000-7f990c468000 rw-p 00007000 08:21 2233721                    /usr/lib/python2.7/dist-packages/h5py/h5z.x86_64-linux-gnu.so
7f990c468000-7f990c469000 rw-p 00000000 00:00 0 
7f990c469000-7f990c47a000 r-xp 00000000 08:21 2233675                    /usr/lib/python2.7/dist-packages/h5py/h5.x86_64-linux-gnu.so
7f990c47a000-7f990c679000 ---p 00011000 08:21 2233675                    /usr/lib/python2.7/dist-packages/h5py/h5.x86_64-linux-gnu.so
7f990c679000-7f990c67a000 r--p 00010000 08:21 2233675                    /usr/lib/python2.7/dist-packages/h5py/h5.x86_64-linux-gnu.so
7f990c67a000-7f990c67c000 rw-p 00011000 08:21 2233675                    /usr/lib/python2.7/dist-packages/h5py/h5.x86_64-linux-gnu.so
7f990c67c000-7f990c67d000 rw-p 00000000 00:00 0 
7f990c67d000-7f990c686000 r-xp 00000000 08:21 2233720                    /usr/lib/python2.7/dist-packages/h5py/utils.x86_64-linux-gnu.so
7f990c686000-7f990c885000 ---p 00009000 08:21 2233720                    /usr/lib/python2.7/dist-packages/h5py/utils.x86_64-linux-gnu.so
7f990c885000-7f990c886000 r--p 00008000 08:21 2233720                    /usr/lib/python2.7/dist-packages/h5py/utils.x86_64-linux-gnu.so
7f990c886000-7f990c887000 rw-p 00009000 08:21 2233720                    /usr/lib/python2.7/dist-packages/h5py/utils.x86_64-linux-gnu.so
7f990c887000-7f990c8cb000 r-xp 00000000 08:21 2233734                    /usr/lib/python2.7/dist-packages/h5py/h5t.x86_64-linux-gnu.so
7f990c8cb000-7f990caca000 ---p 00044000 08:21 2233734                    /usr/lib/python2.7/dist-packages/h5py/h5t.x86_64-linux-gnu.so
7f990caca000-7f990cacb000 r--p 00043000 08:21 2233734                    /usr/lib/python2.7/dist-packages/h5py/h5t.x86_64-linux-gnu.so
7f990cacb000-7f990cad5000 rw-p 00044000 08:21 2233734                    /usr/lib/python2.7/dist-packages/h5py/h5t.x86_64-linux-gnu.so
7f990cad5000-7f990caf3000 r-xp 00000000 08:21 1053210                    /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so.10.0.2
7f990caf3000-7f990ccf2000 ---p 0001e000 08:21 1053210                    /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so.10.0.2
7f990ccf2000-7f990ccf3000 r--p 0001d000 08:21 1053210                    /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so.10.0.2
7f990ccf3000-7f990ccf4000 rw-p 0001e000 08:21 1053210                    /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so.10.0.2
7f990ccf4000-7f990ccf5000 rw-p 00000000 00:00 0 
7f990ccf5000-7f990cd1c000 r-xp 00000000 08:21 2233674                    /usr/lib/python2.7/dist-packages/h5py/defs.x86_64-linux-gnu.so
7f990cd1c000-7f990cf1c000 ---p 00027000 08:21 2233674                    /usr/lib/python2.7/dist-packages/h5py/defs.x86_64-linux-gnu.so
7f990cf1c000-7f990cf1d000 r--p 00027000 08:21 2233674                    /usr/lib/python2.7/dist-packages/h5py/defs.x86_64-linux-gnu.so
7f990cf1d000-7f990cf1f000 rw-p 00028000 08:21 2233674                    /usr/lib/python2.7/dist-packages/h5py/defs.x86_64-linux-gnu.so
7f990cf1f000-7f990cf35000 r-xp 00000000 08:21 2233736                    /usr/lib/python2.7/dist-packages/h5py/_objects.x86_64-linux-gnu.so
7f990cf35000-7f990d134000 ---p 00016000 08:21 2233736                    /usr/lib/python2.7/dist-packages/h5py/_objects.x86_64-linux-gnu.so
7f990d134000-7f990d135000 r--p 00015000 08:21 2233736                    /usr/lib/python2.7/dist-packages/h5py/_objects.x86_64-linux-gnu.so
7f990d135000-7f990d138000 rw-p 00016000 08:21 2233736                    /usr/lib/python2.7/dist-packages/h5py/_objects.x86_64-linux-gnu.so
7f990d138000-7f990d142000 r-xp 00000000 08:21 2233715                    /usr/lib/python2.7/dist-packages/h5py/h5r.x86_64-linux-gnu.so
7f990d142000-7f990d341000 ---p 0000a000 08:21 2233715                    /usr/lib/python2.7/dist-packages/h5py/h5r.x86_64-linux-gnu.so
7f990d341000-7f990d342000 r--p 00009000 08:21 2233715                    /usr/lib/python2.7/dist-packages/h5py/h5r.x86_64-linux-gnu.so
7f990d342000-7f990d344000 rw-p 0000a000 08:21 2233715                    /usr/lib/python2.7/dist-packages/h5py/h5r.x86_64-linux-gnu.so
7f990d344000-7f990d351000 r-xp 00000000 08:21 2233683                    /usr/lib/python2.7/dist-packages/h5py/_conv.x86_64-linux-gnu.so
7f990d351000-7f990d550000 ---p 0000d000 08:21 2233683                    /usr/lib/python2.7/dist-packages/h5py/_conv.x86_64-linux-gnu.so
7f990d550000-7f990d551000 r--p 0000c000 08:21 2233683                    /usr/lib/python2.7/dist-packages/h5py/_conv.x86_64-linux-gnu.so
7f990d551000-7f990d552000 rw-p 0000d000 08:21 2233683                    /usr/lib/python2.7/dist-packages/h5py/_conv.x86_64-linux-gnu.so
7f990d552000-7f990d559000 r-xp 00000000 08:21 1053203                    /usr/lib/x86_64-linux-gnu/libaec.so.0.0.3
7f990d559000-7f990d758000 ---p 00007000 08:21 1053203                    /usr/lib/x86_64-linux-gnu/libaec.so.0.0.3
7f990d758000-7f990d759000 r--p 00006000 08:21 1053203                    /usr/lib/x86_64-linux-gnu/libaec.so.0.0.3
7f990d759000-7f990d75a000 rw-p 00007000 08:21 1053203                    /usr/lib/x86_64-linux-gnu/libaec.so.0.0.3
7f990d75a000-7f990d75c000 r-xp 00000000 08:21 1053205                    /usr/lib/x86_64-linux-gnu/libsz.so.2.0.1
7f990d75c000-7f990d95b000 ---p 00002000 08:21 1053205                    /usr/lib/x86_64-linux-gnu/libsz.so.2.0.1
7f990d95b000-7f990d95c000 r--p 00001000 08:21 1053205                    /usr/lib/x86_64-linux-gnu/libsz.so.2.0.1
7f990d95c000-7f990d95d000 rw-p 00002000 08:21 1053205                    /usr/lib/x86_64-linux-gnu/libsz.so.2.0.1
7f990d95d000-7f990dbf1000 r-xp 00000000 08:21 1053208                    /usr/lib/x86_64-linux-gnu/libhdf5_serial.so.10.1.0
7f990dbf1000-7f990ddf0000 ---p 00294000 08:21 1053208                    /usr/lib/x86_64-linux-gnu/libhdf5_serial.so.10.1.0
7f990ddf0000-7f990ddf5000 r--p 00293000 08:21 1053208                    /usr/lib/x86_64-linux-gnu/libhdf5_serial.so.10.1.0
7f990ddf5000-7f990ddfa000 rw-p 00298000 08:21 1053208                    /usr/lib/x86_64-linux-gnu/libhdf5_serial.so.10.1.0
7f990ddfa000-7f990ddfb000 rw-p 00000000 00:00 0 
7f990ddfb000-7f990de03000 r-xp 00000000 08:21 2233738                    /usr/lib/python2.7/dist-packages/h5py/_errors.x86_64-linux-gnu.so
7f990de03000-7f990e002000 ---p 00008000 08:21 2233738                    /usr/lib/python2.7/dist-packages/h5py/_errors.x86_64-linux-gnu.so
7f990e002000-7f990e003000 r--p 00007000 08:21 2233738                    /usr/lib/python2.7/dist-packages/h5py/_errors.x86_64-linux-gnu.so
7f990e003000-7f990e004000 rw-p 00008000 08:21 2233738                    /usr/lib/python2.7/dist-packages/h5py/_errors.x86_64-linux-gnu.so
7f990e004000-7f993a004000 rw-p 00000000 00:00 0 
7f993a004000-7f993a005000 ---p 00000000 00:00 0 
7f993a005000-7f993a805000 rw-p 00000000 00:00 0 
7f993a805000-7f993a806000 ---p 00000000 00:00 0 
7f993a806000-7f993b006000 rw-p 00000000 00:00 0 
7f993b006000-7f993b007000 ---p 00000000 00:00 0 
7f993b007000-7f993b807000 rw-p 00000000 00:00 0 
7f993b807000-7f993b808000 ---p 00000000 00:00 0 
7f993b808000-7f993c008000 rw-p 00000000 00:00 0 
7f993c400000-7f993c600000 ---p 00000000 00:00 0 
7f993c60a000-7f993f80b000 rw-p 00000000 00:00 0 
7f993fc00000-7f993fe00000 ---p 00000000 00:00 0 
7f993fe00000-7f9940000000 rw-s 00000000 00:05 206094999                  /dev/zero (deleted)
7f994000c000-7f994200c000 rw-p 00000000 00:00 0 
7f9942400000-7f9942600000 ---p 00000000 00:00 0 
7f994260d000-7f994580f000 rw-p 00000000 00:00 0 
7f9945c00000-7f9946000000 ---p 00000000 00:00 0 
7f9946010000-7f9948010000 rw-p 00000000 00:00 0 
7f9948216000-7f994f81b000 rw-p 00000000 00:00 0 
7f994fc00000-7f994fe00000 rw-s 00000000 00:05 206094998                  /dev/zero (deleted)
7f994fe00000-7f9950000000 ---p 00000000 00:00 0 
7f995001c000-7f995601c000 rw-p 00000000 00:00 0 
7f995601c000-7f995601d000 ---p 00000000 00:00 0 
7f995601d000-7f995881d000 rw-p 00000000 00:00 0 
7f995881d000-7f995881e000 ---p 00000000 00:00 0 
7f995881e000-7f995f01e000 rw-p 00000000 00:00 0 
7f995f400000-7f995f600000 ---p 00000000 00:00 0 
7f995f71f000-7f9962020000 rw-p 00000000 00:00 0 
7f9962400000-7f9962800000 ---p 00000000 00:00 0 
7f9962821000-7f9964821000 rw-p 00000000 00:00 0 
7f9964c00000-7f9965000000 ---p 00000000 00:00 0 
7f9965022000-7f9967022000 rw-p 00000000 00:00 0 
7f9967400000-7f9967800000 ---p 00000000 00:00 0 
7f9967823000-7f9969823000 rw-p 00000000 00:00 0 
7f9969c00000-7f9969ed6000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9969ed6000-7f996a000000 ---p 00000000 00:00 0 
7f996a024000-7f996c024000 rw-p 00000000 00:00 0 
7f996c400000-7f996c600000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f996c600000-7f996c800000 rw-s 00000000 00:05 206139044                  /dev/zero (deleted)
7f996c825000-7f996e825000 rw-p 00000000 00:00 0 
7f996ec00000-7f996ee00000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f996ee00000-7f996f000000 rw-s 00000000 00:05 206139043                  /dev/zero (deleted)
7f996f026000-7f9971026000 rw-p 00000000 00:00 0 
7f9971026000-7f9971027000 ---p 00000000 00:00 0 
7f9971027000-7f9973827000 rw-p 00000000 00:00 0 
7f9973c00000-7f9973e00000 ---p 00000000 00:00 0 
7f9973e29000-7f997902a000 rw-p 00000000 00:00 0 
7f997902d000-7f997d02e000 rw-p 00000000 00:00 0 
7f997d02e000-7f997d02f000 ---p 00000000 00:00 0 
7f997d02f000-7f997f82f000 rw-p 00000000 00:00 0 
7f997f82f000-7f997f830000 ---p 00000000 00:00 0 
7f997f830000-7f9984030000 rw-p 00000000 00:00 0 
7f9984400000-7f9984600000 ---p 00000000 00:00 0 
7f9984731000-7f9987032000 rw-p 00000000 00:00 0 
7f9987171000-7f998c034000 rw-p 00000000 00:00 0 
7f998c0b2000-7f9996038000 rw-p 00000000 00:00 0 
7f9996038000-7f99978ee000 r-xp 00000000 08:21 62790680                   /usr/lib/x86_64-linux-gnu/libicudata.so.55.1
7f99978ee000-7f9997aed000 ---p 018b6000 08:21 62790680                   /usr/lib/x86_64-linux-gnu/libicudata.so.55.1
7f9997aed000-7f9997aee000 r--p 018b5000 08:21 62790680                   /usr/lib/x86_64-linux-gnu/libicudata.so.55.1
7f9997aee000-7f9997aef000 rw-p 018b6000 08:21 62790680                   /usr/lib/x86_64-linux-gnu/libicudata.so.55.1
7f9997aef000-7f9997af2000 r-xp 00000000 08:21 45488001                   /lib/x86_64-linux-gnu/libkeyutils.so.1.5
7f9997af2000-7f9997cf1000 ---p 00003000 08:21 45488001                   /lib/x86_64-linux-gnu/libkeyutils.so.1.5
7f9997cf1000-7f9997cf2000 r--p 00002000 08:21 45488001                   /lib/x86_64-linux-gnu/libkeyutils.so.1.5
7f9997cf2000-7f9997cf3000 rw-p 00003000 08:21 45488001                   /lib/x86_64-linux-gnu/libkeyutils.so.1.5
7f9997cf3000-7f9997e72000 r-xp 00000000 08:21 62790694                   /usr/lib/x86_64-linux-gnu/libicuuc.so.55.1
7f9997e72000-7f9998072000 ---p 0017f000 08:21 62790694                   /usr/lib/x86_64-linux-gnu/libicuuc.so.55.1
7f9998072000-7f9998082000 r--p 0017f000 08:21 62790694                   /usr/lib/x86_64-linux-gnu/libicuuc.so.55.1
7f9998082000-7f9998083000 rw-p 0018f000 08:21 62790694                   /usr/lib/x86_64-linux-gnu/libicuuc.so.55.1
7f9998083000-7f9998087000 rw-p 00000000 00:00 0 
7f9998087000-7f9998091000 r-xp 00000000 08:21 45746719                   /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1
7f9998091000-7f9998290000 ---p 0000a000 08:21 45746719                   /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1
7f9998290000-7f9998291000 r--p 00009000 08:21 45746719                   /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1
7f9998291000-7f9998292000 rw-p 0000a000 08:21 45746719                   /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1
7f9998292000-7f9998295000 r-xp 00000000 08:21 38015890                   /lib/x86_64-linux-gnu/libcom_err.so.2.1
7f9998295000-7f9998494000 ---p 00003000 08:21 38015890                   /lib/x86_64-linux-gnu/libcom_err.so.2.1
7f9998494000-7f9998495000 r--p 00002000 08:21 38015890                   /lib/x86_64-linux-gnu/libcom_err.so.2.1
7f9998495000-7f9998496000 rw-p 00003000 08:21 38015890                   /lib/x86_64-linux-gnu/libcom_err.so.2.1
7f9998496000-7f99984c2000 r-xp 00000000 08:21 45746713                   /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1
7f99984c2000-7f99986c1000 ---p 0002c000 08:21 45746713                   /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1
7f99986c1000-7f99986c3000 r--p 0002b000 08:21 45746713                   /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1
7f99986c3000-7f99986c4000 rw-p 0002d000 08:21 45746713                   /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1
7f99986c4000-7f99986c5000 rw-p 00000000 00:00 0 
7f99986c5000-7f9998788000 r-xp 00000000 08:21 45746717                   /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3
7f9998788000-7f9998988000 ---p 000c3000 08:21 45746717                   /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3
7f9998988000-7f9998995000 r--p 000c3000 08:21 45746717                   /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3
7f9998995000-7f9998997000 rw-p 000d0000 08:21 45746717                   /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3
7f9998997000-7f99989a9000 r-xp 00000000 08:21 38015908                   /lib/x86_64-linux-gnu/libgpg-error.so.0.17.0
7f99989a9000-7f9998ba9000 ---p 00012000 08:21 38015908                   /lib/x86_64-linux-gnu/libgpg-error.so.0.17.0
7f9998ba9000-7f9998baa000 r--p 00012000 08:21 38015908                   /lib/x86_64-linux-gnu/libgpg-error.so.0.17.0
7f9998baa000-7f9998bab000 rw-p 00013000 08:21 38015908                   /lib/x86_64-linux-gnu/libgpg-error.so.0.17.0
7f9998bab000-7f9998bcc000 r-xp 00000000 08:21 53355465                   /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0
7f9998bcc000-7f9998dcb000 ---p 00021000 08:21 53355465                   /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0
7f9998dcb000-7f9998dcc000 r--p 00020000 08:21 53355465                   /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0
7f9998dcc000-7f9998dcd000 rw-p 00021000 08:21 53355465                   /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0
7f9998dcd000-7f9998dd3000 r-xp 00000000 08:21 62790576                   /usr/lib/x86_64-linux-gnu/libdatrie.so.1.3.3
7f9998dd3000-7f9998fd3000 ---p 00006000 08:21 62790576                   /usr/lib/x86_64-linux-gnu/libdatrie.so.1.3.3
7f9998fd3000-7f9998fd4000 r--p 00006000 08:21 62790576                   /usr/lib/x86_64-linux-gnu/libdatrie.so.1.3.3
7f9998fd4000-7f9998fd5000 rw-p 00007000 08:21 62790576                   /usr/lib/x86_64-linux-gnu/libdatrie.so.1.3.3
7f9998fd5000-7f9998ff9000 r-xp 00000000 08:21 62790651                   /usr/lib/x86_64-linux-gnu/libgraphite2.so.3.0.1
7f9998ff9000-7f99991f8000 ---p 00024000 08:21 62790651                   /usr/lib/x86_64-linux-gnu/libgraphite2.so.3.0.1
7f99991f8000-7f99991fa000 r--p 00023000 08:21 62790651                   /usr/lib/x86_64-linux-gnu/libgraphite2.so.3.0.1
7f99991fa000-7f99991fb000 rw-p 00025000 08:21 62790651                   /usr/lib/x86_64-linux-gnu/libgraphite2.so.3.0.1
7f99991fb000-7f999920c000 r-xp 00000000 08:21 45746737                   /usr/lib/x86_64-linux-gnu/libtasn1.so.6.5.1
7f999920c000-7f999940c000 ---p 00011000 08:21 45746737                   /usr/lib/x86_64-linux-gnu/libtasn1.so.6.5.1
7f999940c000-7f999940d000 r--p 00011000 08:21 45746737                   /usr/lib/x86_64-linux-gnu/libtasn1.so.6.5.1
7f999940d000-7f999940e000 rw-p 00012000 08:21 45746737                   /usr/lib/x86_64-linux-gnu/libtasn1.so.6.5.1
7f999940e000-7f999943f000 r-xp 00000000 08:21 45746711                   /usr/lib/x86_64-linux-gnu/libidn.so.11.6.15
7f999943f000-7f999963f000 ---p 00031000 08:21 45746711                   /usr/lib/x86_64-linux-gnu/libidn.so.11.6.15
7f999963f000-7f9999640000 r--p 00031000 08:21 45746711                   /usr/lib/x86_64-linux-gnu/libidn.so.11.6.15
7f9999640000-7f9999641000 rw-p 00032000 08:21 45746711                   /usr/lib/x86_64-linux-gnu/libidn.so.11.6.15
7f9999641000-7f999969a000 r-xp 00000000 08:21 45746728                   /usr/lib/x86_64-linux-gnu/libp11-kit.so.0.1.0
7f999969a000-7f9999899000 ---p 00059000 08:21 45746728                   /usr/lib/x86_64-linux-gnu/libp11-kit.so.0.1.0
7f9999899000-7f99998a3000 r--p 00058000 08:21 45746728                   /usr/lib/x86_64-linux-gnu/libp11-kit.so.0.1.0
7f99998a3000-7f99998a5000 rw-p 00062000 08:21 45746728                   /usr/lib/x86_64-linux-gnu/libp11-kit.so.0.1.0
7f99998a5000-7f9999a56000 r-xp 00000000 08:21 62790962                   /usr/lib/x86_64-linux-gnu/libxml2.so.2.9.3
7f9999a56000-7f9999c55000 ---p 001b1000 08:21 62790962                   /usr/lib/x86_64-linux-gnu/libxml2.so.2.9.3
7f9999c55000-7f9999c5d000 r--p 001b0000 08:21 62790962                   /usr/lib/x86_64-linux-gnu/libxml2.so.2.9.3
7f9999c5d000-7f9999c5f000 rw-p 001b8000 08:21 62790962                   /usr/lib/x86_64-linux-gnu/libxml2.so.2.9.3
7f9999c5f000-7f9999c60000 rw-p 00000000 00:00 0 
7f9999c60000-7f9999cdf000 r-xp 00000000 08:21 45746693                   /usr/lib/x86_64-linux-gnu/libgmp.so.10.3.0
7f9999cdf000-7f9999ede000 ---p 0007f000 08:21 45746693                   /usr/lib/x86_64-linux-gnu/libgmp.so.10.3.0
7f9999ede000-7f9999edf000 r--p 0007e000 08:21 45746693                   /usr/lib/x86_64-linux-gnu/libgmp.so.10.3.0
7f9999edf000-7f9999ee0000 rw-p 0007f000 08:21 45746693                   /usr/lib/x86_64-linux-gnu/libgmp.so.10.3.0
7f9999ee0000-7f9999f14000 r-xp 00000000 08:21 45746726                   /usr/lib/x86_64-linux-gnu/libnettle.so.6.2
7f9999f14000-7f999a113000 ---p 00034000 08:21 45746726                   /usr/lib/x86_64-linux-gnu/libnettle.so.6.2
7f999a113000-7f999a115000 r--p 00033000 08:21 45746726                   /usr/lib/x86_64-linux-gnu/libnettle.so.6.2
7f999a115000-7f999a116000 rw-p 00035000 08:21 45746726                   /usr/lib/x86_64-linux-gnu/libnettle.so.6.2
7f999a116000-7f999a148000 r-xp 00000000 08:21 45746707                   /usr/lib/x86_64-linux-gnu/libhogweed.so.4.2
7f999a148000-7f999a347000 ---p 00032000 08:21 45746707                   /usr/lib/x86_64-linux-gnu/libhogweed.so.4.2
7f999a347000-7f999a348000 r--p 00031000 08:21 45746707                   /usr/lib/x86_64-linux-gnu/libhogweed.so.4.2
7f999a348000-7f999a349000 rw-p 00032000 08:21 45746707                   /usr/lib/x86_64-linux-gnu/libhogweed.so.4.2
7f999a349000-7f999a390000 r-xp 00000000 08:21 45746699                   /usr/lib/x86_64-linux-gnu/libgssapi_krb5.so.2.2
7f999a390000-7f999a58f000 ---p 00047000 08:21 45746699                   /usr/lib/x86_64-linux-gnu/libgssapi_krb5.so.2.2
7f999a58f000-7f999a591000 r--p 00046000 08:21 45746699                   /usr/lib/x86_64-linux-gnu/libgssapi_krb5.so.2.2
7f999a591000-7f999a593000 rw-p 00048000 08:21 45746699                   /usr/lib/x86_64-linux-gnu/libgssapi_krb5.so.2.2
7f999a593000-7f999a66a000 r-xp 00000000 08:21 38015906                   /lib/x86_64-linux-gnu/libgcrypt.so.20.0.5
7f999a66a000-7f999a86a000 ---p 000d7000 08:21 38015906                   /lib/x86_64-linux-gnu/libgcrypt.so.20.0.5
7f999a86a000-7f999a86b000 r--p 000d7000 08:21 38015906                   /lib/x86_64-linux-gnu/libgcrypt.so.20.0.5
7f999a86b000-7f999a873000 rw-p 000d8000 08:21 38015906                   /lib/x86_64-linux-gnu/libgcrypt.so.20.0.5
7f999a873000-7f999a874000 rw-p 00000000 00:00 0 
7f999a874000-7f999a8ef000 r-xp 00000000 08:21 62790799                   /usr/lib/x86_64-linux-gnu/liborc-0.4.so.0.25.0
7f999a8ef000-7f999aaee000 ---p 0007b000 08:21 62790799                   /usr/lib/x86_64-linux-gnu/liborc-0.4.so.0.25.0
7f999aaee000-7f999aaf0000 r--p 0007a000 08:21 62790799                   /usr/lib/x86_64-linux-gnu/liborc-0.4.so.0.25.0
7f999aaf0000-7f999aaf4000 rw-p 0007c000 08:21 62790799                   /usr/lib/x86_64-linux-gnu/liborc-0.4.so.0.25.0
7f999aaf4000-7f999aafb000 r-xp 00000000 08:21 62790719                   /usr/lib/x86_64-linux-gnu/libogg.so.0.8.2
7f999aafb000-7f999acfb000 ---p 00007000 08:21 62790719                   /usr/lib/x86_64-linux-gnu/libogg.so.0.8.2
7f999acfb000-7f999acfc000 r--p 00007000 08:21 62790719                   /usr/lib/x86_64-linux-gnu/libogg.so.0.8.2
7f999acfc000-7f999acfd000 rw-p 00008000 08:21 62790719                   /usr/lib/x86_64-linux-gnu/libogg.so.0.8.2
7f999acfd000-7f999ad07000 r-xp 00000000 08:21 62790717                   /usr/lib/x86_64-linux-gnu/libnuma.so.1.0.0
7f999ad07000-7f999af06000 ---p 0000a000 08:21 62790717                   /usr/lib/x86_64-linux-gnu/libnuma.so.1.0.0
7f999af06000-7f999af07000 r--p 00009000 08:21 62790717                   /usr/lib/x86_64-linux-gnu/libnuma.so.1.0.0
7f999af07000-7f999af08000 rw-p 0000a000 08:21 62790717                   /usr/lib/x86_64-linux-gnu/libnuma.so.1.0.0
7f999af08000-7f999af36000 r-xp 00000000 08:21 62790869                   /usr/lib/x86_64-linux-gnu/libsoxr.so.0.1.1
7f999af36000-7f999b135000 ---p 0002e000 08:21 62790869                   /usr/lib/x86_64-linux-gnu/libsoxr.so.0.1.1
7f999b135000-7f999b137000 r--p 0002d000 08:21 62790869                   /usr/lib/x86_64-linux-gnu/libsoxr.so.0.1.1
7f999b137000-7f999b138000 rw-p 0002f000 08:21 62790869                   /usr/lib/x86_64-linux-gnu/libsoxr.so.0.1.1
7f999b138000-7f999b16d000 rw-p 00000000 00:00 0 
7f999b16d000-7f999b192000 r-xp 00000000 08:21 62790920                   /usr/lib/x86_64-linux-gnu/libv4lconvert.so.0.0.0
7f999b192000-7f999b392000 ---p 00025000 08:21 62790920                   /usr/lib/x86_64-linux-gnu/libv4lconvert.so.0.0.0
7f999b392000-7f999b394000 r--p 00025000 08:21 62790920                   /usr/lib/x86_64-linux-gnu/libv4lconvert.so.0.0.0
7f999b394000-7f999b395000 rw-p 00027000 08:21 62790920                   /usr/lib/x86_64-linux-gnu/libv4lconvert.so.0.0.0
7f999b395000-7f999b3e7000 rw-p 00000000 00:00 0 
7f999b3e7000-7f999b449000 r-xp 00000000 08:21 62790530                   /usr/lib/x86_64-linux-gnu/libXt.so.6.0.0
7f999b449000-7f999b649000 ---p 00062000 08:21 62790530                   /usr/lib/x86_64-linux-gnu/libXt.so.6.0.0
7f999b649000-7f999b64a000 r--p 00062000 08:21 62790530                   /usr/lib/x86_64-linux-gnu/libXt.so.6.0.0
7f999b64a000-7f999b64f000 rw-p 00063000 08:21 62790530                   /usr/lib/x86_64-linux-gnu/libXt.so.6.0.0
7f999b64f000-7f999b650000 rw-p 00000000 00:00 0 
7f999b650000-7f999b658000 r-xp 00000000 08:21 62790892                   /usr/lib/x86_64-linux-gnu/libthai.so.0.2.4
7f999b658000-7f999b857000 ---p 00008000 08:21 62790892                   /usr/lib/x86_64-linux-gnu/libthai.so.0.2.4
7f999b857000-7f999b858000 r--p 00007000 08:21 62790892                   /usr/lib/x86_64-linux-gnu/libthai.so.0.2.4
7f999b858000-7f999b859000 rw-p 00008000 08:21 62790892                   /usr/lib/x86_64-linux-gnu/libthai.so.0.2.4
7f999b859000-7f999b8b5000 r-xp 00000000 08:21 62790678                   /usr/lib/x86_64-linux-gnu/libharfbuzz.so.0.10000.1
7f999b8b5000-7f999bab5000 ---p 0005c000 08:21 62790678                   /usr/lib/x86_64-linux-gnu/libharfbuzz.so.0.10000.1
7f999bab5000-7f999bab6000 r--p 0005c000 08:21 62790678                   /usr/lib/x86_64-linux-gnu/libharfbuzz.so.0.10000.1
7f999bab6000-7f999bab7000 rw-p 0005d000 08:21 62790678                   /usr/lib/x86_64-linux-gnu/libharfbuzz.so.0.10000.1
7f999bab7000-7f999bace000 r-xp 00000000 08:21 38015955                   /lib/x86_64-linux-gnu/libresolv-2.23.so
7f999bace000-7f999bcce000 ---p 00017000 08:21 38015955                   /lib/x86_64-linux-gnu/libresolv-2.23.so
7f999bcce000-7f999bccf000 r--p 00017000 08:21 38015955                   /lib/x86_64-linux-gnu/libresolv-2.23.so
7f999bccf000-7f999bcd0000 rw-p 00018000 08:21 38015955                   /lib/x86_64-linux-gnu/libresolv-2.23.so
7f999bcd0000-7f999bcd2000 rw-p 00000000 00:00 0 
7f999bcd2000-7f999bcf1000 r-xp 00000000 08:21 38015961                   /lib/x86_64-linux-gnu/libselinux.so.1
7f999bcf1000-7f999bef0000 ---p 0001f000 08:21 38015961                   /lib/x86_64-linux-gnu/libselinux.so.1
7f999bef0000-7f999bef1000 r--p 0001e000 08:21 38015961                   /lib/x86_64-linux-gnu/libselinux.so.1
7f999bef1000-7f999bef2000 rw-p 0001f000 08:21 38015961                   /lib/x86_64-linux-gnu/libselinux.so.1
7f999bef2000-7f999bef4000 rw-p 00000000 00:00 0 
7f999bef4000-7f999befc000 r-xp 00000000 08:21 62790950                   /usr/lib/x86_64-linux-gnu/libxcb-render.so.0.0.0
7f999befc000-7f999c0fc000 ---p 00008000 08:21 62790950                   /usr/lib/x86_64-linux-gnu/libxcb-render.so.0.0.0
7f999c0fc000-7f999c0fd000 r--p 00008000 08:21 62790950                   /usr/lib/x86_64-linux-gnu/libxcb-render.so.0.0.0
7f999c0fd000-7f999c0fe000 rw-p 00009000 08:21 62790950                   /usr/lib/x86_64-linux-gnu/libxcb-render.so.0.0.0
7f999c0fe000-7f99a3f2c000 r-xp 00000000 08:21 50074698                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcufft.so.9.0.176
7f99a3f2c000-7f99a412c000 ---p 07e2e000 08:21 50074698                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcufft.so.9.0.176
7f99a412c000-7f99a413b000 rw-p 07e2e000 08:21 50074698                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcufft.so.9.0.176
7f99a413b000-7f99a419f000 rw-p 00000000 00:00 0 
7f99a419f000-7f99b77d1000 r-xp 00000000 08:21 54406239                   /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.0
7f99b77d1000-7f99b79d1000 ---p 13632000 08:21 54406239                   /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.0
7f99b79d1000-7f99b7a4c000 rw-p 13632000 08:21 54406239                   /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.0
7f99b7a4c000-7f99b7ade000 rw-p 00000000 00:00 0 
7f99b7ade000-7f99bc48d000 r-xp 00000000 08:21 50074704                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcusolver.so.9.0.176
7f99bc48d000-7f99bc68d000 ---p 049af000 08:21 50074704                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcusolver.so.9.0.176
7f99bc68d000-7f99bc6c7000 rw-p 049af000 08:21 50074704                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcusolver.so.9.0.176
7f99bc6c7000-7f99bc6d9000 rw-p 00000000 00:00 0 
7f99bc6d9000-7f99beb62000 r-xp 00000000 08:21 50074702                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcurand.so.9.0.176
7f99beb62000-7f99bed61000 ---p 02489000 08:21 50074702                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcurand.so.9.0.176
7f99bed61000-7f99c0133000 rw-p 02488000 08:21 50074702                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcurand.so.9.0.176
7f99c0133000-7f99c063d000 rw-p 00000000 00:00 0 
7f99c063d000-7f99d02b3000 r-xp 00000000 08:21 63967275                   /usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/libmxnet.so
7f99d02b3000-7f99d04b3000 ---p 0fc76000 08:21 63967275                   /usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/libmxnet.so
7f99d04b3000-7f99d04ed000 r--p 0fc76000 08:21 63967275                   /usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/libmxnet.so
7f99d04ed000-7f99d0511000 rw-p 0fcb0000 08:21 63967275                   /usr/local/lib/python2.7/dist-packages/mxnet-1.3.0-py2.7.egg/mxnet/libmxnet.so
7f99d0511000-7f99d1029000 rw-p 00000000 00:00 0 
7f99d1029000-7f99d102e000 r-xp 00000000 08:21 62790496                   /usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0
7f99d102e000-7f99d122d000 ---p 00005000 08:21 62790496                   /usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0
7f99d122d000-7f99d122e000 r--p 00004000 08:21 62790496                   /usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0
7f99d122e000-7f99d122f000 rw-p 00005000 08:21 62790496                   /usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0
7f99d122f000-7f99d1231000 r-xp 00000000 08:21 62790477                   /usr/lib/x86_64-linux-gnu/libXau.so.6.0.0
7f99d1231000-7f99d1431000 ---p 00002000 08:21 62790477                   /usr/lib/x86_64-linux-gnu/libXau.so.6.0.0
7f99d1431000-7f99d1432000 r--p 00002000 08:21 62790477                   /usr/lib/x86_64-linux-gnu/libXau.so.6.0.0
7f99d1432000-7f99d1433000 rw-p 00003000 08:21 62790477                   /usr/lib/x86_64-linux-gnu/libXau.so.6.0.0
7f99d1433000-7f99d1454000 r-xp 00000000 08:21 62790960                   /usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0
7f99d1454000-7f99d1653000 ---p 00021000 08:21 62790960                   /usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0
7f99d1653000-7f99d1654000 r--p 00020000 08:21 62790960                   /usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0
7f99d1654000-7f99d1655000 rw-p 00021000 08:21 62790960                   /usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0
7f99d1655000-7f99d1659000 r-xp 00000000 08:21 38015980                   /lib/x86_64-linux-gnu/libuuid.so.1.3.0
7f99d1659000-7f99d1858000 ---p 00004000 08:21 38015980                   /lib/x86_64-linux-gnu/libuuid.so.1.3.0
7f99d1858000-7f99d1859000 r--p 00003000 08:21 38015980                   /lib/x86_64-linux-gnu/libuuid.so.1.3.0
7f99d1859000-7f99d185a000 rw-p 00004000 08:21 38015980                   /lib/x86_64-linux-gnu/libuuid.so.1.3.0
7f99d185a000-7f99d18c8000 r-xp 00000000 08:21 38015948                   /lib/x86_64-linux-gnu/libpcre.so.3.13.2
7f99d18c8000-7f99d1ac8000 ---p 0006e000 08:21 38015948                   /lib/x86_64-linux-gnu/libpcre.so.3.13.2
7f99d1ac8000-7f99d1ac9000 r--p 0006e000 08:21 38015948                   /lib/x86_64-linux-gnu/libpcre.so.3.13.2
7f99d1ac9000-7f99d1aca000 rw-p 0006f000 08:21 38015948                   /lib/x86_64-linux-gnu/libpcre.so.3.13.2
7f99d1aca000-7f99d1bff000 r-xp 00000000 08:21 62790473                   /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0
7f99d1bff000-7f99d1dff000 ---p 00135000 08:21 62790473                   /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0
7f99d1dff000-7f99d1e00000 r--p 00135000 08:21 62790473                   /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0
7f99d1e00000-7f99d1e04000 rw-p 00136000 08:21 62790473                   /usr/lib/x86_64-linux-gnu/libX11.so.6.3.0
7f99d1e04000-7f99d1e15000 r-xp 00000000 08:21 62790500                   /usr/lib/x86_64-linux-gnu/libXext.so.6.4.0
7f99d1e15000-7f99d2014000 ---p 00011000 08:21 62790500                   /usr/lib/x86_64-linux-gnu/libXext.so.6.4.0
7f99d2014000-7f99d2015000 r--p 00010000 08:21 62790500                   /usr/lib/x86_64-linux-gnu/libXext.so.6.4.0
7f99d2015000-7f99d2016000 rw-p 00011000 08:21 62790500                   /usr/lib/x86_64-linux-gnu/libXext.so.6.4.0
7f99d2016000-7f99d201f000 r-xp 00000000 08:21 62790528                   /usr/lib/x86_64-linux-gnu/libXrender.so.1.3.0
7f99d201f000-7f99d221e000 ---p 00009000 08:21 62790528                   /usr/lib/x86_64-linux-gnu/libXrender.so.1.3.0
7f99d221e000-7f99d221f000 r--p 00008000 08:21 62790528                   /usr/lib/x86_64-linux-gnu/libXrender.so.1.3.0
7f99d221f000-7f99d2220000 rw-p 00009000 08:21 62790528                   /usr/lib/x86_64-linux-gnu/libXrender.so.1.3.0
7f99d2220000-7f99d2236000 r-xp 00000000 08:21 62790441                   /usr/lib/x86_64-linux-gnu/libICE.so.6.3.0
7f99d2236000-7f99d2435000 ---p 00016000 08:21 62790441                   /usr/lib/x86_64-linux-gnu/libICE.so.6.3.0
7f99d2435000-7f99d2436000 r--p 00015000 08:21 62790441                   /usr/lib/x86_64-linux-gnu/libICE.so.6.3.0
7f99d2436000-7f99d2437000 rw-p 00016000 08:21 62790441                   /usr/lib/x86_64-linux-gnu/libICE.so.6.3.0
7f99d2437000-7f99d243a000 rw-p 00000000 00:00 0 
7f99d243a000-7f99d2441000 r-xp 00000000 08:21 62790467                   /usr/lib/x86_64-linux-gnu/libSM.so.6.0.1
7f99d2441000-7f99d2640000 ---p 00007000 08:21 62790467                   /usr/lib/x86_64-linux-gnu/libSM.so.6.0.1
7f99d2640000-7f99d2641000 r--p 00006000 08:21 62790467                   /usr/lib/x86_64-linux-gnu/libSM.so.6.0.1
7f99d2641000-7f99d2642000 rw-p 00007000 08:21 62790467                   /usr/lib/x86_64-linux-gnu/libSM.so.6.0.1
7f99d2642000-7f99d2751000 r-xp 00000000 08:21 62529459                   /lib/x86_64-linux-gnu/libglib-2.0.so.0.4800.2
7f99d2751000-7f99d2950000 ---p 0010f000 08:21 62529459                   /lib/x86_64-linux-gnu/libglib-2.0.so.0.4800.2
7f99d2950000-7f99d2951000 r--p 0010e000 08:21 62529459                   /lib/x86_64-linux-gnu/libglib-2.0.so.0.4800.2
7f99d2951000-7f99d2952000 rw-p 0010f000 08:21 62529459                   /lib/x86_64-linux-gnu/libglib-2.0.so.0.4800.2
7f99d2952000-7f99d2953000 rw-p 00000000 00:00 0 
7f99d2953000-7f99d2954000 r-xp 00000000 08:21 62790657                   /usr/lib/x86_64-linux-gnu/libgthread-2.0.so.0.4800.2
7f99d2954000-7f99d2b53000 ---p 00001000 08:21 62790657                   /usr/lib/x86_64-linux-gnu/libgthread-2.0.so.0.4800.2
7f99d2b53000-7f99d2b54000 r--p 00000000 08:21 62790657                   /usr/lib/x86_64-linux-gnu/libgthread-2.0.so.0.4800.2
7f99d2b54000-7f99d2b55000 rw-p 00001000 08:21 62790657                   /usr/lib/x86_64-linux-gnu/libgthread-2.0.so.0.4800.2
7f99d2b55000-7f99d2e4e000 r-xp 00000000 08:21 1447102                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libvpx-8459aeef.so.6.0.0
7f99d2e4e000-7f99d304e000 ---p 002f9000 08:21 1447102                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libvpx-8459aeef.so.6.0.0
7f99d304e000-7f99d3051000 rw-p 002f9000 08:21 1447102                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libvpx-8459aeef.so.6.0.0
7f99d3051000-7f99d3058000 rw-p 00000000 00:00 0 
7f99d3058000-7f99d3059000 rw-p 0032c000 08:21 1447102                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libvpx-8459aeef.so.6.0.0
7f99d3059000-7f99d3073000 r-xp 00000000 08:21 1447098                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswresample-a49c020a.so.3.4.100
7f99d3073000-7f99d3273000 ---p 0001a000 08:21 1447098                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswresample-a49c020a.so.3.4.100
7f99d3273000-7f99d3275000 rw-p 0001a000 08:21 1447098                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswresample-a49c020a.so.3.4.100
7f99d3275000-7f99d3277000 rw-p 0001d000 08:21 1447098                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswresample-a49c020a.so.3.4.100
7f99d3277000-7f99d328d000 r-xp 00000000 08:21 38015904                   /lib/x86_64-linux-gnu/libgcc_s.so.1
7f99d328d000-7f99d348c000 ---p 00016000 08:21 38015904                   /lib/x86_64-linux-gnu/libgcc_s.so.1
7f99d348c000-7f99d348d000 rw-p 00015000 08:21 38015904                   /lib/x86_64-linux-gnu/libgcc_s.so.1
7f99d348d000-7f99d35ff000 r-xp 00000000 08:21 38274693                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7f99d35ff000-7f99d37ff000 ---p 00172000 08:21 38274693                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7f99d37ff000-7f99d3809000 r--p 00172000 08:21 38274693                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7f99d3809000-7f99d380b000 rw-p 0017c000 08:21 38274693                   /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21
7f99d380b000-7f99d380f000 rw-p 00000000 00:00 0 
7f99d380f000-7f99d3b0b000 r-xp 00000000 08:21 1447094                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtCore-3dbacd8a.so.4.8.7
7f99d3b0b000-7f99d3b1b000 ---p 002fc000 08:21 1447094                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtCore-3dbacd8a.so.4.8.7
7f99d3b1b000-7f99d3b47000 rw-p 0030c000 08:21 1447094                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtCore-3dbacd8a.so.4.8.7
7f99d3b47000-7f99d3d0a000 ---p 00338000 08:21 1447094                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtCore-3dbacd8a.so.4.8.7
7f99d3d0a000-7f99d3d1a000 rw-p 002fb000 08:21 1447094                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtCore-3dbacd8a.so.4.8.7
7f99d3d1a000-7f99d3d1b000 rw-p 00000000 00:00 0 
7f99d3d1b000-7f99d4823000 r-xp 00000000 08:21 1447095                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtGui-6d0f14dd.so.4.8.7
7f99d4823000-7f99d4a23000 ---p 00b08000 08:21 1447095                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtGui-6d0f14dd.so.4.8.7
7f99d4a23000-7f99d4a7c000 rw-p 00b08000 08:21 1447095                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtGui-6d0f14dd.so.4.8.7
7f99d4a7c000-7f99d4a7e000 rw-p 00000000 00:00 0 
7f99d4a7e000-7f99d4bac000 rw-p 00b61000 08:21 1447095                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtGui-6d0f14dd.so.4.8.7
7f99d4bac000-7f99d57cb000 r-xp 00000000 08:21 1447096                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavcodec-874f3d51.so.58.47.106
7f99d57cb000-7f99d59cb000 ---p 00c1f000 08:21 1447096                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavcodec-874f3d51.so.58.47.106
7f99d59cb000-7f99d5a2a000 rw-p 00c1f000 08:21 1447096                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavcodec-874f3d51.so.58.47.106
7f99d5a2a000-7f99d6208000 rw-p 00000000 00:00 0 
7f99d6208000-7f99d6218000 rw-p 00c7f000 08:21 1447096                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavcodec-874f3d51.so.58.47.106
7f99d6218000-7f99d7c28000 r-xp 00000000 08:21 1447070                    /usr/local/lib/python2.7/dist-packages/cv2/cv2.so
7f99d7c28000-7f99d7e28000 ---p 01a10000 08:21 1447070                    /usr/local/lib/python2.7/dist-packages/cv2/cv2.so
7f99d7e28000-7f99d7ec1000 rw-p 01a10000 08:21 1447070                    /usr/local/lib/python2.7/dist-packages/cv2/cv2.so
7f99d7ec1000-7f99d7f7f000 rw-p 00000000 00:00 0 
7f99d7f7f000-7f99d8000000 rw-p 01aaa000 08:21 1447070                    /usr/local/lib/python2.7/dist-packages/cv2/cv2.so
7f99d8000000-7f99d8021000 rw-p 00000000 00:00 0 
7f99d8021000-7f99dc000000 ---p 00000000 00:00 0 
7f99dc000000-7f99dc021000 rw-p 00000000 00:00 0 
7f99dc021000-7f99e0000000 ---p 00000000 00:00 0 
7f99e0000000-7f99e0021000 rw-p 00000000 00:00 0 
7f99e0021000-7f99e4000000 ---p 00000000 00:00 0 
7f99e414c000-7f99e4153000 r-xp 00000000 08:21 38015957                   /lib/x86_64-linux-gnu/librt-2.23.so
7f99e4153000-7f99e4352000 ---p 00007000 08:21 38015957                   /lib/x86_64-linux-gnu/librt-2.23.so
7f99e4352000-7f99e4353000 r--p 00006000 08:21 38015957                   /lib/x86_64-linux-gnu/librt-2.23.so
7f99e4353000-7f99e4354000 rw-p 00007000 08:21 38015957                   /lib/x86_64-linux-gnu/librt-2.23.so
7f99e4354000-7f99e4378000 r-xp 00000000 08:21 1447097                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7
7f99e4378000-7f99e4578000 ---p 00024000 08:21 1447097                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7
7f99e4578000-7f99e4581000 rw-p 00024000 08:21 1447097                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7
7f99e4581000-7f99e4601000 r-xp 00000000 08:21 1447093                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswscale-4e6f4703.so.5.4.100
7f99e4601000-7f99e4800000 ---p 00080000 08:21 1447093                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswscale-4e6f4703.so.5.4.100
7f99e4800000-7f99e4802000 rw-p 0007f000 08:21 1447093                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswscale-4e6f4703.so.5.4.100
7f99e4802000-7f99e480a000 rw-p 00000000 00:00 0 
7f99e480a000-7f99e480c000 rw-p 00082000 08:21 1447093                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libswscale-4e6f4703.so.5.4.100
7f99e480c000-7f99e4869000 r-xp 00000000 08:21 1447100                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavutil-473e9eb1.so.56.26.100
7f99e4869000-7f99e4a69000 ---p 0005d000 08:21 1447100                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavutil-473e9eb1.so.56.26.100
7f99e4a69000-7f99e4a74000 rw-p 0005d000 08:21 1447100                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavutil-473e9eb1.so.56.26.100
7f99e4a74000-7f99e4a83000 rw-p 00000000 00:00 0 
7f99e4a83000-7f99e4a87000 rw-p 00069000 08:21 1447100                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavutil-473e9eb1.so.56.26.100
7f99e4a87000-7f99e4ca4000 r-xp 00000000 08:21 1447101                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavformat-fb41c63f.so.58.26.101
7f99e4ca4000-7f99e4ea4000 ---p 0021d000 08:21 1447101                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavformat-fb41c63f.so.58.26.101
7f99e4ea4000-7f99e4ee4000 rw-p 0021d000 08:21 1447101                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libavformat-fb41c63f.so.58.26.101
7f99e4ee4000-7f99e4ef8000 r-xp 00000000 08:21 1447099                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3
7f99e4ef8000-7f99e50f7000 ---p 00014000 08:21 1447099                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3
7f99e50f7000-7f99e50f8000 rw-p 00013000 08:21 1447099                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3
7f99e50f8000-7f99e50f9000 rw-p 00015000 08:21 1447099                    /usr/local/lib/python2.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3
7f99e50f9000-7f99e50fa000 ---p 00000000 00:00 0 
7f99e50fa000-7f99e58fa000 rw-p 00000000 00:00 0 
7f99e58fa000-7f99e58fb000 ---p 00000000 00:00 0 
7f99e58fb000-7f99e60fb000 rw-p 00000000 00:00 0 
7f99e60fb000-7f99e60fc000 ---p 00000000 00:00 0 
7f99e60fc000-7f99e68fc000 rw-p 00000000 00:00 0 
7f99e68fc000-7f99e6900000 r-xp 00000000 08:21 62787987                   /usr/lib/python2.7/lib-dynload/termios.x86_64-linux-gnu.so
7f99e6900000-7f99e6aff000 ---p 00004000 08:21 62787987                   /usr/lib/python2.7/lib-dynload/termios.x86_64-linux-gnu.so
7f99e6aff000-7f99e6b00000 r--p 00003000 08:21 62787987                   /usr/lib/python2.7/lib-dynload/termios.x86_64-linux-gnu.so
7f99e6b00000-7f99e6b02000 rw-p 00004000 08:21 62787987                   /usr/lib/python2.7/lib-dynload/termios.x86_64-linux-gnu.so
7f99e6b02000-7f99e6b82000 rw-p 00000000 00:00 0 
7f99e6c02000-7f99e6dc2000 rw-p 00000000 00:00 0 
7f99e6dc2000-7f99e6de8000 r-xp 00000000 08:21 62529457                   /lib/x86_64-linux-gnu/libexpat.so.1.6.0
7f99e6de8000-7f99e6fe8000 ---p 00026000 08:21 62529457                   /lib/x86_64-linux-gnu/libexpat.so.1.6.0
7f99e6fe8000-7f99e6fea000 r--p 00026000 08:21 62529457                   /lib/x86_64-linux-gnu/libexpat.so.1.6.0
7f99e6fea000-7f99e6feb000 rw-p 00028000 08:21 62529457                   /lib/x86_64-linux-gnu/libexpat.so.1.6.0
7f99e6feb000-7f99e6ffa000 r-xp 00000000 08:21 62787984                   /usr/lib/python2.7/lib-dynload/pyexpat.x86_64-linux-gnu.so
7f99e6ffa000-7f99e71f9000 ---p 0000f000 08:21 62787984                   /usr/lib/python2.7/lib-dynload/pyexpat.x86_64-linux-gnu.so
7f99e71f9000-7f99e71fa000 r--p 0000e000 08:21 62787984                   /usr/lib/python2.7/lib-dynload/pyexpat.x86_64-linux-gnu.so
7f99e71fa000-7f99e71fc000 rw-p 0000f000 08:21 62787984                   /usr/lib/python2.7/lib-dynload/pyexpat.x86_64-linux-gnu.so
7f99e71fc000-7f99e727c000 rw-p 00000000 00:00 0 
7f99e727c000-7f99e73fc000 rw-p 00000000 00:00 0 
7f99e73fc000-7f99e7408000 r-xp 00000000 08:21 62787966                   /usr/lib/python2.7/lib-dynload/_json.x86_64-linux-gnu.so
7f99e7408000-7f99e7607000 ---p 0000c000 08:21 62787966                   /usr/lib/python2.7/lib-dynload/_json.x86_64-linux-gnu.so
7f99e7607000-7f99e7608000 r--p 0000b000 08:21 62787966                   /usr/lib/python2.7/lib-dynload/_json.x86_64-linux-gnu.so
7f99e7608000-7f99e7609000 rw-p 0000c000 08:21 62787966                   /usr/lib/python2.7/lib-dynload/_json.x86_64-linux-gnu.so
7f99e7609000-7f99e7689000 rw-p 00000000 00:00 0 
7f99e7689000-7f99e76e7000 r-xp 00000000 08:21 45488002                   /lib/x86_64-linux-gnu/libssl.so.1.0.0
7f99e76e7000-7f99e78e7000 ---p 0005e000 08:21 45488002                   /lib/x86_64-linux-gnu/libssl.so.1.0.0
7f99e78e7000-7f99e78eb000 r--p 0005e000 08:21 45488002                   /lib/x86_64-linux-gnu/libssl.so.1.0.0
7f99e78eb000-7f99e78f2000 rw-p 00062000 08:21 45488002                   /lib/x86_64-linux-gnu/libssl.so.1.0.0
7f99e78f2000-7f99e7907000 r-xp 00000000 08:21 62787971                   /usr/lib/python2.7/lib-dynload/_ssl.x86_64-linux-gnu.so
7f99e7907000-7f99e7b06000 ---p 00015000 08:21 62787971                   /usr/lib/python2.7/lib-dynload/_ssl.x86_64-linux-gnu.so
7f99e7b06000-7f99e7b07000 r--p 00014000 08:21 62787971                   /usr/lib/python2.7/lib-dynload/_ssl.x86_64-linux-gnu.so
7f99e7b07000-7f99e7b0b000 rw-p 00015000 08:21 62787971                   /usr/lib/python2.7/lib-dynload/_ssl.x86_64-linux-gnu.so
7f99e7b0b000-7f99e7ccb000 rw-p 00000000 00:00 0 
7f99e7ccc000-7f99e7d0c000 rw-p 00000000 00:00 0 
7f99e7d0c000-7f99e7d10000 r-xp 00000000 08:21 1442706                    /usr/local/lib/python2.7/dist-packages/_posixsubprocess32.so
7f99e7d10000-7f99e7f0f000 ---p 00004000 08:21 1442706                    /usr/local/lib/python2.7/dist-packages/_posixsubprocess32.so
7f99e7f0f000-7f99e7f10000 r--p 00003000 08:21 1442706                    /usr/local/lib/python2.7/dist-packages/_posixsubprocess32.so
7f99e7f10000-7f99e7f11000 rw-p 00004000 08:21 1442706                    /usr/local/lib/python2.7/dist-packages/_posixsubprocess32.so
7f99e7f11000-7f99e8051000 rw-p 00000000 00:00 0 
7f99e8051000-7f99e8102000 r-xp 00000000 08:21 3018979                    /usr/local/lib/python2.7/dist-packages/numpy/random/mtrand.so
7f99e8102000-7f99e8301000 ---p 000b1000 08:21 3018979                    /usr/local/lib/python2.7/dist-packages/numpy/random/mtrand.so
7f99e8301000-7f99e8326000 rw-p 000b0000 08:21 3018979                    /usr/local/lib/python2.7/dist-packages/numpy/random/mtrand.so
7f99e8326000-7f99e8368000 rw-p 00000000 00:00 0 
7f99e8368000-7f99e8371000 r-xp 00000000 08:21 3019001                    /usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.so
7f99e8371000-7f99e8571000 ---p 00009000 08:21 3019001                    /usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.so
7f99e8571000-7f99e8572000 rw-p 00009000 08:21 3019001                    /usr/local/lib/python2.7/dist-packages/numpy/fft/fftpack_lite.so
7f99e8572000-7f99e85f2000 rw-p 00000000 00:00 0 
7f99e85f2000-7f99e85f3000 r-xp 00000000 08:21 62787978                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
7f99e85f3000-7f99e87f2000 ---p 00001000 08:21 62787978                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
7f99e87f2000-7f99e87f3000 r--p 00000000 08:21 62787978                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
7f99e87f3000-7f99e87f4000 rw-p 00001000 08:21 62787978                   /usr/lib/python2.7/lib-dynload/future_builtins.x86_64-linux-gnu.so
7f99e87f4000-7f99e8874000 rw-p 00000000 00:00 0 
7f99e8874000-7f99e889f000 r-xp 00000000 08:21 3018415                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.so
7f99e889f000-7f99e8a9e000 ---p 0002b000 08:21 3018415                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.so
7f99e8a9e000-7f99e8aa0000 rw-p 0002a000 08:21 3018415                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.so
7f99e8aa0000-7f99e8aa3000 rw-p 000d2000 08:21 3018415                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.so
7f99e8aa3000-7f99e8aa7000 r-xp 00000000 08:21 3018416                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.so
7f99e8aa7000-7f99e8ca7000 ---p 00004000 08:21 3018416                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.so
7f99e8ca7000-7f99e8ca8000 rw-p 00004000 08:21 3018416                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.so
7f99e8ca8000-7f99e8caa000 rw-p 00019000 08:21 3018416                    /usr/local/lib/python2.7/dist-packages/numpy/linalg/lapack_lite.so
7f99e8caa000-7f99e8cea000 rw-p 00000000 00:00 0 
7f99e8cea000-7f99e8d09000 r-xp 00000000 08:21 3018453                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_tests.so
7f99e8d09000-7f99e8f08000 ---p 0001f000 08:21 3018453                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_tests.so
7f99e8f08000-7f99e8f0a000 rw-p 0001e000 08:21 3018453                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_tests.so
7f99e8f0a000-7f9a0cfca000 rw-p 00000000 00:00 0 
7f9a0cfca000-7f9a0cfd1000 r-xp 00000000 08:21 45746691                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4
7f9a0cfd1000-7f9a0d1d0000 ---p 00007000 08:21 45746691                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4
7f9a0d1d0000-7f9a0d1d1000 r--p 00006000 08:21 45746691                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4
7f9a0d1d1000-7f9a0d1d2000 rw-p 00007000 08:21 45746691                   /usr/lib/x86_64-linux-gnu/libffi.so.6.0.4
7f9a0d1d2000-7f9a0d1f0000 r-xp 00000000 08:21 62787959                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
7f9a0d1f0000-7f9a0d3ef000 ---p 0001e000 08:21 62787959                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
7f9a0d3ef000-7f9a0d3f0000 r--p 0001d000 08:21 62787959                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
7f9a0d3f0000-7f9a0d3f4000 rw-p 0001e000 08:21 62787959                   /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so
7f9a0d3f4000-7f9a0d434000 rw-p 00000000 00:00 0 
7f9a0d434000-7f9a0d435000 ---p 00000000 00:00 0 
7f9a0d435000-7f9a0dc35000 rw-p 00000000 00:00 0 
7f9a0de25000-7f9a0e4a8000 rw-p 00000000 00:00 0 
7f9a0e4a8000-7f9a0e4ac000 r-xp 00000000 08:21 1447721                    /usr/local/lib/python2.7/dist-packages/_scandir.so
7f9a0e4ac000-7f9a0e6ab000 ---p 00004000 08:21 1447721                    /usr/local/lib/python2.7/dist-packages/_scandir.so
7f9a0e6ab000-7f9a0e6ac000 r--p 00003000 08:21 1447721                    /usr/local/lib/python2.7/dist-packages/_scandir.so
7f9a0e6ac000-7f9a0e6ad000 rw-p 00004000 08:21 1447721                    /usr/local/lib/python2.7/dist-packages/_scandir.so
7f9a0e6ad000-7f9a0e6df000 r-xp 00000000 08:21 2232259                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/liblzma-6cd627ed.so.5.2.4
7f9a0e6df000-7f9a0e8df000 ---p 00032000 08:21 2232259                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/liblzma-6cd627ed.so.5.2.4
7f9a0e8df000-7f9a0e8e0000 rw-p 00032000 08:21 2232259                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/liblzma-6cd627ed.so.5.2.4
7f9a0e8e0000-7f9a0e8e1000 rw-p 00034000 08:21 2232259                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/liblzma-6cd627ed.so.5.2.4
7f9a0e8e1000-7f9a0e970000 r-xp 00000000 08:21 2232258                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libtiff-8267adfe.so.5.4.0
7f9a0e970000-7f9a0eb70000 ---p 0008f000 08:21 2232258                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libtiff-8267adfe.so.5.4.0
7f9a0eb70000-7f9a0eb74000 rw-p 0008f000 08:21 2232258                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libtiff-8267adfe.so.5.4.0
7f9a0eb74000-7f9a0eb7c000 rw-p 00094000 08:21 2232258                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libtiff-8267adfe.so.5.4.0
7f9a0eb7c000-7f9a0ebc3000 r-xp 00000000 08:21 2232261                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libopenjp2-e366d6b0.so.2.1.0
7f9a0ebc3000-7f9a0edc3000 ---p 00047000 08:21 2232261                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libopenjp2-e366d6b0.so.2.1.0
7f9a0edc3000-7f9a0edc5000 rw-p 00047000 08:21 2232261                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libopenjp2-e366d6b0.so.2.1.0
7f9a0edc5000-7f9a0edc7000 rw-p 0004a000 08:21 2232261                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libopenjp2-e366d6b0.so.2.1.0
7f9a0edc7000-7f9a0ee18000 r-xp 00000000 08:21 2232256                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libjpeg-3fe7dfc0.so.9.3.0
7f9a0ee18000-7f9a0f018000 ---p 00051000 08:21 2232256                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libjpeg-3fe7dfc0.so.9.3.0
7f9a0f018000-7f9a0f019000 rw-p 00051000 08:21 2232256                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libjpeg-3fe7dfc0.so.9.3.0
7f9a0f019000-7f9a0f01b000 rw-p 00053000 08:21 2232256                    /usr/local/lib/python2.7/dist-packages/PIL/.libs/libjpeg-3fe7dfc0.so.9.3.0
7f9a0f01b000-7f9a0f099000 r-xp 00000000 08:21 2232104                    /usr/local/lib/python2.7/dist-packages/PIL/_imaging.so
7f9a0f099000-7f9a0f299000 ---p 0007e000 08:21 2232104                    /usr/local/lib/python2.7/dist-packages/PIL/_imaging.so
7f9a0f299000-7f9a0f2af000 rw-p 0007e000 08:21 2232104                    /usr/local/lib/python2.7/dist-packages/PIL/_imaging.so
7f9a0f2af000-7f9a0f2b5000 r-xp 00000000 08:21 62787969                   /usr/lib/python2.7/lib-dynload/_multiprocessing.x86_64-linux-gnu.so
7f9a0f2b5000-7f9a0f4b4000 ---p 00006000 08:21 62787969                   /usr/lib/python2.7/lib-dynload/_multiprocessing.x86_64-linux-gnu.so
7f9a0f4b4000-7f9a0f4b5000 r--p 00005000 08:21 62787969                   /usr/lib/python2.7/lib-dynload/_multiprocessing.x86_64-linux-gnu.so
7f9a0f4b5000-7f9a0f4b6000 rw-p 00006000 08:21 62787969                   /usr/lib/python2.7/lib-dynload/_multiprocessing.x86_64-linux-gnu.so
7f9a0f4b6000-7f9a0f4b8000 r-xp 00000000 08:21 62790954                   /usr/lib/x86_64-linux-gnu/libxcb-shm.so.0.0.0
7f9a0f4b8000-7f9a0f6b8000 ---p 00002000 08:21 62790954                   /usr/lib/x86_64-linux-gnu/libxcb-shm.so.0.0.0
7f9a0f6b8000-7f9a0f6b9000 r--p 00002000 08:21 62790954                   /usr/lib/x86_64-linux-gnu/libxcb-shm.so.0.0.0
7f9a0f6b9000-7f9a0f6ba000 rw-p 00003000 08:21 62790954                   /usr/lib/x86_64-linux-gnu/libxcb-shm.so.0.0.0
7f9a0f6ba000-7f9a0f759000 r-xp 00000000 08:21 62790841                   /usr/lib/x86_64-linux-gnu/libpixman-1.so.0.33.6
7f9a0f759000-7f9a0f959000 ---p 0009f000 08:21 62790841                   /usr/lib/x86_64-linux-gnu/libpixman-1.so.0.33.6
7f9a0f959000-7f9a0f961000 r--p 0009f000 08:21 62790841                   /usr/lib/x86_64-linux-gnu/libpixman-1.so.0.33.6
7f9a0f961000-7f9a0f962000 rw-p 000a7000 08:21 62790841                   /usr/lib/x86_64-linux-gnu/libpixman-1.so.0.33.6
7f9a0f962000-7f9a0fa06000 r-xp 00000000 08:21 62790611                   /usr/lib/x86_64-linux-gnu/libfreetype.so.6.12.1
7f9a0fa06000-7f9a0fc05000 ---p 000a4000 08:21 62790611                   /usr/lib/x86_64-linux-gnu/libfreetype.so.6.12.1
7f9a0fc05000-7f9a0fc0b000 r--p 000a3000 08:21 62790611                   /usr/lib/x86_64-linux-gnu/libfreetype.so.6.12.1
7f9a0fc0b000-7f9a0fc0c000 rw-p 000a9000 08:21 62790611                   /usr/lib/x86_64-linux-gnu/libfreetype.so.6.12.1
7f9a0fc0c000-7f9a0fc1b000 r-xp 00000000 08:21 38015882                   /lib/x86_64-linux-gnu/libbz2.so.1.0.4
7f9a0fc1b000-7f9a0fe1a000 ---p 0000f000 08:21 38015882                   /lib/x86_64-linux-gnu/libbz2.so.1.0.4
7f9a0fe1a000-7f9a0fe1b000 r--p 0000e000 08:21 38015882                   /lib/x86_64-linux-gnu/libbz2.so.1.0.4
7f9a0fe1b000-7f9a0fe1c000 rw-p 0000f000 08:21 38015882                   /lib/x86_64-linux-gnu/libbz2.so.1.0.4
7f9a0fe1c000-7f9a0ff3f000 r-xp 00000000 08:21 45746695                   /usr/lib/x86_64-linux-gnu/libgnutls.so.30.6.2
7f9a0ff3f000-7f9a1013e000 ---p 00123000 08:21 45746695                   /usr/lib/x86_64-linux-gnu/libgnutls.so.30.6.2
7f9a1013e000-7f9a10149000 r--p 00122000 08:21 45746695                   /usr/lib/x86_64-linux-gnu/libgnutls.so.30.6.2
7f9a10149000-7f9a1014b000 rw-p 0012d000 08:21 45746695                   /usr/lib/x86_64-linux-gnu/libgnutls.so.30.6.2
7f9a1014b000-7f9a1014c000 rw-p 00000000 00:00 0 
7f9a1014c000-7f9a10193000 r-xp 00000000 08:21 62790559                   /usr/lib/x86_64-linux-gnu/libbluray.so.1.9.2
7f9a10193000-7f9a10392000 ---p 00047000 08:21 62790559                   /usr/lib/x86_64-linux-gnu/libbluray.so.1.9.2
7f9a10392000-7f9a10394000 r--p 00046000 08:21 62790559                   /usr/lib/x86_64-linux-gnu/libbluray.so.1.9.2
7f9a10394000-7f9a10395000 rw-p 00048000 08:21 62790559                   /usr/lib/x86_64-linux-gnu/libbluray.so.1.9.2
7f9a10395000-7f9a103df000 r-xp 00000000 08:21 62790639                   /usr/lib/x86_64-linux-gnu/libgme.so.0.6.0
7f9a103df000-7f9a105df000 ---p 0004a000 08:21 62790639                   /usr/lib/x86_64-linux-gnu/libgme.so.0.6.0
7f9a105df000-7f9a105e2000 r--p 0004a000 08:21 62790639                   /usr/lib/x86_64-linux-gnu/libgme.so.0.6.0
7f9a105e2000-7f9a105e3000 rw-p 0004d000 08:21 62790639                   /usr/lib/x86_64-linux-gnu/libgme.so.0.6.0
7f9a105e3000-7f9a1062d000 r-xp 00000000 08:21 62790711                   /usr/lib/x86_64-linux-gnu/libmodplug.so.1.0.0
7f9a1062d000-7f9a1082d000 ---p 0004a000 08:21 62790711                   /usr/lib/x86_64-linux-gnu/libmodplug.so.1.0.0
7f9a1082d000-7f9a1082e000 r--p 0004a000 08:21 62790711                   /usr/lib/x86_64-linux-gnu/libmodplug.so.1.0.0
7f9a1082e000-7f9a1082f000 rw-p 0004b000 08:21 62790711                   /usr/lib/x86_64-linux-gnu/libmodplug.so.1.0.0
7f9a1082f000-7f9a1096e000 rw-p 00000000 00:00 0 
7f9a1096e000-7f9a10989000 r-xp 00000000 08:21 45746731                   /usr/lib/x86_64-linux-gnu/librtmp.so.1
7f9a10989000-7f9a10b88000 ---p 0001b000 08:21 45746731                   /usr/lib/x86_64-linux-gnu/librtmp.so.1
7f9a10b88000-7f9a10b89000 r--p 0001a000 08:21 45746731                   /usr/lib/x86_64-linux-gnu/librtmp.so.1
7f9a10b89000-7f9a10b8a000 rw-p 0001b000 08:21 45746731                   /usr/lib/x86_64-linux-gnu/librtmp.so.1
7f9a10b8a000-7f9a10bd2000 r-xp 00000000 08:21 62790873                   /usr/lib/x86_64-linux-gnu/libssh-gcrypt.so.4.4.1
7f9a10bd2000-7f9a10dd1000 ---p 00048000 08:21 62790873                   /usr/lib/x86_64-linux-gnu/libssh-gcrypt.so.4.4.1
7f9a10dd1000-7f9a10dd2000 r--p 00047000 08:21 62790873                   /usr/lib/x86_64-linux-gnu/libssh-gcrypt.so.4.4.1
7f9a10dd2000-7f9a10dd3000 rw-p 00048000 08:21 62790873                   /usr/lib/x86_64-linux-gnu/libssh-gcrypt.so.4.4.1
7f9a10dd3000-7f9a10ded000 r-xp 00000000 08:21 62790573                   /usr/lib/x86_64-linux-gnu/libcrystalhd.so.3.6
7f9a10ded000-7f9a10fec000 ---p 0001a000 08:21 62790573                   /usr/lib/x86_64-linux-gnu/libcrystalhd.so.3.6
7f9a10fec000-7f9a10fed000 r--p 00019000 08:21 62790573                   /usr/lib/x86_64-linux-gnu/libcrystalhd.so.3.6
7f9a10fed000-7f9a10fee000 rw-p 0001a000 08:21 62790573                   /usr/lib/x86_64-linux-gnu/libcrystalhd.so.3.6
7f9a10fee000-7f9a10ffb000 r-xp 00000000 08:21 62790653                   /usr/lib/x86_64-linux-gnu/libgsm.so.1.0.12
7f9a10ffb000-7f9a111fa000 ---p 0000d000 08:21 62790653                   /usr/lib/x86_64-linux-gnu/libgsm.so.1.0.12
7f9a111fa000-7f9a111fb000 r--p 0000c000 08:21 62790653                   /usr/lib/x86_64-linux-gnu/libgsm.so.1.0.12
7f9a111fb000-7f9a111fc000 rw-p 0000d000 08:21 62790653                   /usr/lib/x86_64-linux-gnu/libgsm.so.1.0.12
7f9a111fc000-7f9a11241000 r-xp 00000000 08:21 62790713                   /usr/lib/x86_64-linux-gnu/libmp3lame.so.0.0.0
7f9a11241000-7f9a11441000 ---p 00045000 08:21 62790713                   /usr/lib/x86_64-linux-gnu/libmp3lame.so.0.0.0
7f9a11441000-7f9a11442000 r--p 00045000 08:21 62790713                   /usr/lib/x86_64-linux-gnu/libmp3lame.so.0.0.0
7f9a11442000-7f9a11443000 rw-p 00046000 08:21 62790713                   /usr/lib/x86_64-linux-gnu/libmp3lame.so.0.0.0
7f9a11443000-7f9a11471000 rw-p 00000000 00:00 0 
7f9a11471000-7f9a11493000 r-xp 00000000 08:21 62790792                   /usr/lib/x86_64-linux-gnu/libopenjpeg.so.1.5.2
7f9a11493000-7f9a11692000 ---p 00022000 08:21 62790792                   /usr/lib/x86_64-linux-gnu/libopenjpeg.so.1.5.2
7f9a11692000-7f9a11693000 r--p 00021000 08:21 62790792                   /usr/lib/x86_64-linux-gnu/libopenjpeg.so.1.5.2
7f9a11693000-7f9a11694000 rw-p 00022000 08:21 62790792                   /usr/lib/x86_64-linux-gnu/libopenjpeg.so.1.5.2
7f9a11694000-7f9a116dd000 r-xp 00000000 08:21 62790797                   /usr/lib/x86_64-linux-gnu/libopus.so.0.5.2
7f9a116dd000-7f9a118dc000 ---p 00049000 08:21 62790797                   /usr/lib/x86_64-linux-gnu/libopus.so.0.5.2
7f9a118dc000-7f9a118dd000 r--p 00048000 08:21 62790797                   /usr/lib/x86_64-linux-gnu/libopus.so.0.5.2
7f9a118dd000-7f9a118de000 rw-p 00049000 08:21 62790797                   /usr/lib/x86_64-linux-gnu/libopus.so.0.5.2
7f9a118de000-7f9a119af000 r-xp 00000000 08:21 62790861                   /usr/lib/x86_64-linux-gnu/libschroedinger-1.0.so.0.11.0
7f9a119af000-7f9a11baf000 ---p 000d1000 08:21 62790861                   /usr/lib/x86_64-linux-gnu/libschroedinger-1.0.so.0.11.0
7f9a11baf000-7f9a11bb1000 r--p 000d1000 08:21 62790861                   /usr/lib/x86_64-linux-gnu/libschroedinger-1.0.so.0.11.0
7f9a11bb1000-7f9a11bb2000 rw-p 000d3000 08:21 62790861                   /usr/lib/x86_64-linux-gnu/libschroedinger-1.0.so.0.11.0
7f9a11bb2000-7f9a11bb3000 rw-p 00000000 00:00 0 
7f9a11bb3000-7f9a11bbf000 r-xp 00000000 08:21 62790865                   /usr/lib/x86_64-linux-gnu/libshine.so.3.0.1
7f9a11bbf000-7f9a11dbe000 ---p 0000c000 08:21 62790865                   /usr/lib/x86_64-linux-gnu/libshine.so.3.0.1
7f9a11dbe000-7f9a11dbf000 r--p 0000b000 08:21 62790865                   /usr/lib/x86_64-linux-gnu/libshine.so.3.0.1
7f9a11dbf000-7f9a11dc0000 rw-p 0000c000 08:21 62790865                   /usr/lib/x86_64-linux-gnu/libshine.so.3.0.1
7f9a11dc0000-7f9a11dc7000 r-xp 00000000 08:21 62790867                   /usr/lib/x86_64-linux-gnu/libsnappy.so.1.3.0
7f9a11dc7000-7f9a11fc6000 ---p 00007000 08:21 62790867                   /usr/lib/x86_64-linux-gnu/libsnappy.so.1.3.0
7f9a11fc6000-7f9a11fc7000 r--p 00006000 08:21 62790867                   /usr/lib/x86_64-linux-gnu/libsnappy.so.1.3.0
7f9a11fc7000-7f9a11fc8000 rw-p 00007000 08:21 62790867                   /usr/lib/x86_64-linux-gnu/libsnappy.so.1.3.0
7f9a11fc8000-7f9a159f9000 r-xp 00000000 08:21 50074696                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcublas.so.9.0.480
7f9a159f9000-7f9a15bf9000 ---p 03a31000 08:21 50074696                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcublas.so.9.0.480
7f9a15bf9000-7f9a15c35000 rw-p 03a31000 08:21 50074696                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcublas.so.9.0.480
7f9a15c35000-7f9a17c45000 rw-p 00000000 00:00 0 
7f9a17dd4000-7f9a17deb000 r-xp 00000000 08:21 62790871                   /usr/lib/x86_64-linux-gnu/libspeex.so.1.5.0
7f9a17deb000-7f9a17feb000 ---p 00017000 08:21 62790871                   /usr/lib/x86_64-linux-gnu/libspeex.so.1.5.0
7f9a17feb000-7f9a17fec000 r--p 00017000 08:21 62790871                   /usr/lib/x86_64-linux-gnu/libspeex.so.1.5.0
7f9a17fec000-7f9a17fed000 rw-p 00018000 08:21 62790871                   /usr/lib/x86_64-linux-gnu/libspeex.so.1.5.0
7f9a17fed000-7f9a18006000 r-xp 00000000 08:21 62790896                   /usr/lib/x86_64-linux-gnu/libtheoradec.so.1.1.4
7f9a18006000-7f9a18205000 ---p 00019000 08:21 62790896                   /usr/lib/x86_64-linux-gnu/libtheoradec.so.1.1.4
7f9a18205000-7f9a18206000 r--p 00018000 08:21 62790896                   /usr/lib/x86_64-linux-gnu/libtheoradec.so.1.1.4
7f9a18206000-7f9a18207000 rw-p 00019000 08:21 62790896                   /usr/lib/x86_64-linux-gnu/libtheoradec.so.1.1.4
7f9a18207000-7f9a18245000 r-xp 00000000 08:21 62790898                   /usr/lib/x86_64-linux-gnu/libtheoraenc.so.1.1.2
7f9a18245000-7f9a18444000 ---p 0003e000 08:21 62790898                   /usr/lib/x86_64-linux-gnu/libtheoraenc.so.1.1.2
7f9a18444000-7f9a18445000 r--p 0003d000 08:21 62790898                   /usr/lib/x86_64-linux-gnu/libtheoraenc.so.1.1.2
7f9a18445000-7f9a18446000 rw-p 0003e000 08:21 62790898                   /usr/lib/x86_64-linux-gnu/libtheoraenc.so.1.1.2
7f9a18446000-7f9a3a446000 rw-p 00000000 00:00 0 
7f9a3a550000-7f9a3a56e000 r-xp 00000000 08:21 62790909                   /usr/lib/x86_64-linux-gnu/libtwolame.so.0.0.0
7f9a3a56e000-7f9a3a76d000 ---p 0001e000 08:21 62790909                   /usr/lib/x86_64-linux-gnu/libtwolame.so.0.0.0
7f9a3a76d000-7f9a3a76e000 r--p 0001d000 08:21 62790909                   /usr/lib/x86_64-linux-gnu/libtwolame.so.0.0.0
7f9a3a76e000-7f9a3a76f000 rw-p 0001e000 08:21 62790909                   /usr/lib/x86_64-linux-gnu/libtwolame.so.0.0.0
7f9a3a76f000-7f9a3a773000 rw-p 00000000 00:00 0 
7f9a3a773000-7f9a3a79d000 r-xp 00000000 08:21 62790927                   /usr/lib/x86_64-linux-gnu/libvorbis.so.0.4.8
7f9a3a79d000-7f9a3a99c000 ---p 0002a000 08:21 62790927                   /usr/lib/x86_64-linux-gnu/libvorbis.so.0.4.8
7f9a3a99c000-7f9a3a99d000 r--p 00029000 08:21 62790927                   /usr/lib/x86_64-linux-gnu/libvorbis.so.0.4.8
7f9a3a99d000-7f9a3a99e000 rw-p 0002a000 08:21 62790927                   /usr/lib/x86_64-linux-gnu/libvorbis.so.0.4.8
7f9a3a99e000-7f9a3aa2b000 r-xp 00000000 08:21 62790929                   /usr/lib/x86_64-linux-gnu/libvorbisenc.so.2.0.11
7f9a3aa2b000-7f9a3ac2a000 ---p 0008d000 08:21 62790929                   /usr/lib/x86_64-linux-gnu/libvorbisenc.so.2.0.11
7f9a3ac2a000-7f9a3ac46000 r--p 0008c000 08:21 62790929                   /usr/lib/x86_64-linux-gnu/libvorbisenc.so.2.0.11
7f9a3ac46000-7f9a3ac47000 rw-p 000a8000 08:21 62790929                   /usr/lib/x86_64-linux-gnu/libvorbisenc.so.2.0.11
7f9a3ac47000-7f9a3ec47000 rw-p 00000000 00:00 0 
7f9a3edfb000-7f9a3f01a000 r-xp 00000000 08:21 62790932                   /usr/lib/x86_64-linux-gnu/libvpx.so.3.0.0
7f9a3f01a000-7f9a3f219000 ---p 0021f000 08:21 62790932                   /usr/lib/x86_64-linux-gnu/libvpx.so.3.0.0
7f9a3f219000-7f9a3f21b000 r--p 0021e000 08:21 62790932                   /usr/lib/x86_64-linux-gnu/libvpx.so.3.0.0
7f9a3f21b000-7f9a3f21c000 rw-p 00220000 08:21 62790932                   /usr/lib/x86_64-linux-gnu/libvpx.so.3.0.0
7f9a3f21c000-7f9a3f21f000 rw-p 00000000 00:00 0 
7f9a3f21f000-7f9a3f247000 r-xp 00000000 08:21 62790934                   /usr/lib/x86_64-linux-gnu/libwavpack.so.1.1.7
7f9a3f247000-7f9a3f446000 ---p 00028000 08:21 62790934                   /usr/lib/x86_64-linux-gnu/libwavpack.so.1.1.7
7f9a3f446000-7f9a3f447000 r--p 00027000 08:21 62790934                   /usr/lib/x86_64-linux-gnu/libwavpack.so.1.1.7
7f9a3f447000-7f9a3f448000 rw-p 00028000 08:21 62790934                   /usr/lib/x86_64-linux-gnu/libwavpack.so.1.1.7
7f9a3f448000-7f9a41448000 rw-p 00000000 00:00 0 
7f9a4148d000-7f9a414e6000 r-xp 00000000 08:21 62790936                   /usr/lib/x86_64-linux-gnu/libwebp.so.5.0.4
7f9a414e6000-7f9a416e6000 ---p 00059000 08:21 62790936                   /usr/lib/x86_64-linux-gnu/libwebp.so.5.0.4
7f9a416e6000-7f9a416e7000 r--p 00059000 08:21 62790936                   /usr/lib/x86_64-linux-gnu/libwebp.so.5.0.4
7f9a416e7000-7f9a416e9000 rw-p 0005a000 08:21 62790936                   /usr/lib/x86_64-linux-gnu/libwebp.so.5.0.4
7f9a416e9000-7f9a41811000 r-xp 00000000 08:21 62790937                   /usr/lib/x86_64-linux-gnu/libx264.so.148
7f9a41811000-7f9a41a10000 ---p 00128000 08:21 62790937                   /usr/lib/x86_64-linux-gnu/libx264.so.148
7f9a41a10000-7f9a41a11000 r--p 00127000 08:21 62790937                   /usr/lib/x86_64-linux-gnu/libx264.so.148
7f9a41a11000-7f9a41a12000 rw-p 00128000 08:21 62790937                   /usr/lib/x86_64-linux-gnu/libx264.so.148
7f9a41a12000-7f9a41a8d000 rw-p 00000000 00:00 0 
7f9a41a8d000-7f9a4249a000 r-xp 00000000 08:21 62790938                   /usr/lib/x86_64-linux-gnu/libx265.so.79
7f9a4249a000-7f9a42699000 ---p 00a0d000 08:21 62790938                   /usr/lib/x86_64-linux-gnu/libx265.so.79
7f9a42699000-7f9a4269c000 r--p 00a0c000 08:21 62790938                   /usr/lib/x86_64-linux-gnu/libx265.so.79
7f9a4269c000-7f9a4269f000 rw-p 00a0f000 08:21 62790938                   /usr/lib/x86_64-linux-gnu/libx265.so.79
7f9a4269f000-7f9a426ac000 rw-p 00000000 00:00 0 
7f9a426ac000-7f9a4274d000 r-xp 00000000 08:21 62790966                   /usr/lib/x86_64-linux-gnu/libxvidcore.so.4.3
7f9a4274d000-7f9a4294c000 ---p 000a1000 08:21 62790966                   /usr/lib/x86_64-linux-gnu/libxvidcore.so.4.3
7f9a4294c000-7f9a4294d000 r--p 000a0000 08:21 62790966                   /usr/lib/x86_64-linux-gnu/libxvidcore.so.4.3
7f9a4294d000-7f9a42957000 rw-p 000a1000 08:21 62790966                   /usr/lib/x86_64-linux-gnu/libxvidcore.so.4.3
7f9a42957000-7f9a429c0000 rw-p 00000000 00:00 0 
7f9a429c0000-7f9a42a37000 r-xp 00000000 08:21 62790972                   /usr/lib/x86_64-linux-gnu/libzvbi.so.0.13.2
7f9a42a37000-7f9a42c36000 ---p 00077000 08:21 62790972                   /usr/lib/x86_64-linux-gnu/libzvbi.so.0.13.2
7f9a42c36000-7f9a42c3f000 r--p 00076000 08:21 62790972                   /usr/lib/x86_64-linux-gnu/libzvbi.so.0.13.2
7f9a42c3f000-7f9a42c4b000 rw-p 0007f000 08:21 62790972                   /usr/lib/x86_64-linux-gnu/libzvbi.so.0.13.2
7f9a42c4b000-7f9a44c4b000 rw-p 00000000 00:00 0 
7f9a44d20000-7f9a44d3b000 r-xp 00000000 08:21 62790925                   /usr/lib/x86_64-linux-gnu/libva.so.1.3900.0
7f9a44d3b000-7f9a44f3a000 ---p 0001b000 08:21 62790925                   /usr/lib/x86_64-linux-gnu/libva.so.1.3900.0
7f9a44f3a000-7f9a44f3b000 r--p 0001a000 08:21 62790925                   /usr/lib/x86_64-linux-gnu/libva.so.1.3900.0
7f9a44f3b000-7f9a44f3c000 rw-p 0001b000 08:21 62790925                   /usr/lib/x86_64-linux-gnu/libva.so.1.3900.0
7f9a44f3c000-7f9a44f56000 r-xp 00000000 08:21 62790879                   /usr/lib/x86_64-linux-gnu/libswresample-ffmpeg.so.1.2.101
7f9a44f56000-7f9a45156000 ---p 0001a000 08:21 62790879                   /usr/lib/x86_64-linux-gnu/libswresample-ffmpeg.so.1.2.101
7f9a45156000-7f9a45158000 r--p 0001a000 08:21 62790879                   /usr/lib/x86_64-linux-gnu/libswresample-ffmpeg.so.1.2.101
7f9a45158000-7f9a45159000 rw-p 0001c000 08:21 62790879                   /usr/lib/x86_64-linux-gnu/libswresample-ffmpeg.so.1.2.101
7f9a45159000-7f9a45162000 r-xp 00000000 08:21 62790918                   /usr/lib/x86_64-linux-gnu/libv4l2.so.0.0.0
7f9a45162000-7f9a45361000 ---p 00009000 08:21 62790918                   /usr/lib/x86_64-linux-gnu/libv4l2.so.0.0.0
7f9a45361000-7f9a45362000 r--p 00008000 08:21 62790918                   /usr/lib/x86_64-linux-gnu/libv4l2.so.0.0.0
7f9a45362000-7f9a45367000 rw-p 00009000 08:21 62790918                   /usr/lib/x86_64-linux-gnu/libv4l2.so.0.0.0
7f9a45367000-7f9a4537e000 r-xp 00000000 08:21 62529465                   /lib/x86_64-linux-gnu/libusb-1.0.so.0.1.0
7f9a4537e000-7f9a4557d000 ---p 00017000 08:21 62529465                   /lib/x86_64-linux-gnu/libusb-1.0.so.0.1.0
7f9a4557d000-7f9a4557e000 r--p 00016000 08:21 62529465                   /lib/x86_64-linux-gnu/libusb-1.0.so.0.1.0
7f9a4557e000-7f9a4557f000 rw-p 00017000 08:21 62529465                   /lib/x86_64-linux-gnu/libusb-1.0.so.0.1.0
7f9a4557f000-7f9a4558c000 r-xp 00000000 08:21 62790859                   /usr/lib/x86_64-linux-gnu/libraw1394.so.11.1.0
7f9a4558c000-7f9a4578c000 ---p 0000d000 08:21 62790859                   /usr/lib/x86_64-linux-gnu/libraw1394.so.11.1.0
7f9a4578c000-7f9a4578d000 r--p 0000d000 08:21 62790859                   /usr/lib/x86_64-linux-gnu/libraw1394.so.11.1.0
7f9a4578d000-7f9a4578e000 rw-p 0000e000 08:21 62790859                   /usr/lib/x86_64-linux-gnu/libraw1394.so.11.1.0
7f9a4578e000-7f9a457ac000 r-xp 00000000 08:21 62790815                   /usr/lib/x86_64-linux-gnu/libpangox-1.0.so.0.0.0
7f9a457ac000-7f9a459ac000 ---p 0001e000 08:21 62790815                   /usr/lib/x86_64-linux-gnu/libpangox-1.0.so.0.0.0
7f9a459ac000-7f9a459ad000 r--p 0001e000 08:21 62790815                   /usr/lib/x86_64-linux-gnu/libpangox-1.0.so.0.0.0
7f9a459ad000-7f9a459ae000 rw-p 0001f000 08:21 62790815                   /usr/lib/x86_64-linux-gnu/libpangox-1.0.so.0.0.0
7f9a459ae000-7f9a459c6000 r-xp 00000000 08:21 62790518                   /usr/lib/x86_64-linux-gnu/libXmu.so.6.2.0
7f9a459c6000-7f9a45bc5000 ---p 00018000 08:21 62790518                   /usr/lib/x86_64-linux-gnu/libXmu.so.6.2.0
7f9a45bc5000-7f9a45bc6000 r--p 00017000 08:21 62790518                   /usr/lib/x86_64-linux-gnu/libXmu.so.6.2.0
7f9a45bc6000-7f9a45bc7000 rw-p 00018000 08:21 62790518                   /usr/lib/x86_64-linux-gnu/libXmu.so.6.2.0
7f9a45bc7000-7f9a45c34000 r-xp 00000000 08:21 62790434                   /usr/lib/x86_64-linux-gnu/libGLU.so.1.3.1
7f9a45c34000-7f9a45e34000 ---p 0006d000 08:21 62790434                   /usr/lib/x86_64-linux-gnu/libGLU.so.1.3.1
7f9a45e34000-7f9a45e35000 r--p 0006d000 08:21 62790434                   /usr/lib/x86_64-linux-gnu/libGLU.so.1.3.1
7f9a45e35000-7f9a45e36000 rw-p 0006e000 08:21 62790434                   /usr/lib/x86_64-linux-gnu/libGLU.so.1.3.1
7f9a45e36000-7f9a45e38000 r-xp 00000000 08:21 62790484                   /usr/lib/x86_64-linux-gnu/libXcomposite.so.1.0.0
7f9a45e38000-7f9a46037000 ---p 00002000 08:21 62790484                   /usr/lib/x86_64-linux-gnu/libXcomposite.so.1.0.0
7f9a46037000-7f9a46038000 r--p 00001000 08:21 62790484                   /usr/lib/x86_64-linux-gnu/libXcomposite.so.1.0.0
7f9a46038000-7f9a46039000 rw-p 00002000 08:21 62790484                   /usr/lib/x86_64-linux-gnu/libXcomposite.so.1.0.0
7f9a46039000-7f9a46042000 r-xp 00000000 08:21 62790488                   /usr/lib/x86_64-linux-gnu/libXcursor.so.1.0.2
7f9a46042000-7f9a46241000 ---p 00009000 08:21 62790488                   /usr/lib/x86_64-linux-gnu/libXcursor.so.1.0.2
7f9a46241000-7f9a46242000 r--p 00008000 08:21 62790488                   /usr/lib/x86_64-linux-gnu/libXcursor.so.1.0.2
7f9a46242000-7f9a46243000 rw-p 00009000 08:21 62790488                   /usr/lib/x86_64-linux-gnu/libXcursor.so.1.0.2
7f9a46243000-7f9a4624d000 r-xp 00000000 08:21 62790524                   /usr/lib/x86_64-linux-gnu/libXrandr.so.2.2.0
7f9a4624d000-7f9a4644c000 ---p 0000a000 08:21 62790524                   /usr/lib/x86_64-linux-gnu/libXrandr.so.2.2.0
7f9a4644c000-7f9a4644d000 r--p 00009000 08:21 62790524                   /usr/lib/x86_64-linux-gnu/libXrandr.so.2.2.0
7f9a4644d000-7f9a4644e000 rw-p 0000a000 08:21 62790524                   /usr/lib/x86_64-linux-gnu/libXrandr.so.2.2.0
7f9a4644e000-7f9a4844e000 rw-p 00000000 00:00 0 
7f9a48485000-7f9a48626000 rw-p 00000000 00:00 0 
7f9a48626000-7f9a48635000 r-xp 00000000 08:21 62790512                   /usr/lib/x86_64-linux-gnu/libXi.so.6.1.0
7f9a48635000-7f9a48834000 ---p 0000f000 08:21 62790512                   /usr/lib/x86_64-linux-gnu/libXi.so.6.1.0
7f9a48834000-7f9a48835000 r--p 0000e000 08:21 62790512                   /usr/lib/x86_64-linux-gnu/libXi.so.6.1.0
7f9a48835000-7f9a48836000 rw-p 0000f000 08:21 62790512                   /usr/lib/x86_64-linux-gnu/libXi.so.6.1.0
7f9a48836000-7f9a48838000 r-xp 00000000 08:21 62790516                   /usr/lib/x86_64-linux-gnu/libXinerama.so.1.0.0
7f9a48838000-7f9a48a37000 ---p 00002000 08:21 62790516                   /usr/lib/x86_64-linux-gnu/libXinerama.so.1.0.0
7f9a48a37000-7f9a48a38000 r--p 00001000 08:21 62790516                   /usr/lib/x86_64-linux-gnu/libXinerama.so.1.0.0
7f9a48a38000-7f9a48a39000 rw-p 00002000 08:21 62790516                   /usr/lib/x86_64-linux-gnu/libXinerama.so.1.0.0
7f9a48a39000-7f9a48a76000 r-xp 00000000 08:21 62790606                   /usr/lib/x86_64-linux-gnu/libfontconfig.so.1.9.0
7f9a48a76000-7f9a48c75000 ---p 0003d000 08:21 62790606                   /usr/lib/x86_64-linux-gnu/libfontconfig.so.1.9.0
7f9a48c75000-7f9a48c77000 r--p 0003c000 08:21 62790606                   /usr/lib/x86_64-linux-gnu/libfontconfig.so.1.9.0
7f9a48c77000-7f9a48c7c000 rw-p 0003e000 08:21 62790606                   /usr/lib/x86_64-linux-gnu/libfontconfig.so.1.9.0
7f9a48c7c000-7f9a48cc5000 r-xp 00000000 08:21 62790805                   /usr/lib/x86_64-linux-gnu/libpango-1.0.so.0.3800.1
7f9a48cc5000-7f9a48ec5000 ---p 00049000 08:21 62790805                   /usr/lib/x86_64-linux-gnu/libpango-1.0.so.0.3800.1
7f9a48ec5000-7f9a48ec7000 r--p 00049000 08:21 62790805                   /usr/lib/x86_64-linux-gnu/libpango-1.0.so.0.3800.1
7f9a48ec7000-7f9a48ec8000 rw-p 0004b000 08:21 62790805                   /usr/lib/x86_64-linux-gnu/libpango-1.0.so.0.3800.1
7f9a48ec8000-7f9a48edc000 r-xp 00000000 08:21 62790813                   /usr/lib/x86_64-linux-gnu/libpangoft2-1.0.so.0.3800.1
7f9a48edc000-7f9a490dc000 ---p 00014000 08:21 62790813                   /usr/lib/x86_64-linux-gnu/libpangoft2-1.0.so.0.3800.1
7f9a490dc000-7f9a490dd000 r--p 00014000 08:21 62790813                   /usr/lib/x86_64-linux-gnu/libpangoft2-1.0.so.0.3800.1
7f9a490dd000-7f9a490de000 rw-p 00015000 08:21 62790813                   /usr/lib/x86_64-linux-gnu/libpangoft2-1.0.so.0.3800.1
7f9a490de000-7f9a4925e000 r-xp 00000000 08:21 62790631                   /usr/lib/x86_64-linux-gnu/libgio-2.0.so.0.4800.2
7f9a4925e000-7f9a4945e000 ---p 00180000 08:21 62790631                   /usr/lib/x86_64-linux-gnu/libgio-2.0.so.0.4800.2
7f9a4945e000-7f9a49462000 r--p 00180000 08:21 62790631                   /usr/lib/x86_64-linux-gnu/libgio-2.0.so.0.4800.2
7f9a49462000-7f9a49464000 rw-p 00184000 08:21 62790631                   /usr/lib/x86_64-linux-gnu/libgio-2.0.so.0.4800.2
7f9a49464000-7f9a49466000 rw-p 00000000 00:00 0 
7f9a49466000-7f9a49487000 r-xp 00000000 08:21 62790620                   /usr/lib/x86_64-linux-gnu/libgdk_pixbuf-2.0.so.0.3200.2
7f9a49487000-7f9a49686000 ---p 00021000 08:21 62790620                   /usr/lib/x86_64-linux-gnu/libgdk_pixbuf-2.0.so.0.3200.2
7f9a49686000-7f9a49687000 r--p 00020000 08:21 62790620                   /usr/lib/x86_64-linux-gnu/libgdk_pixbuf-2.0.so.0.3200.2
7f9a49687000-7f9a49688000 rw-p 00021000 08:21 62790620                   /usr/lib/x86_64-linux-gnu/libgdk_pixbuf-2.0.so.0.3200.2
7f9a49688000-7f9a49796000 r-xp 00000000 08:21 62790571                   /usr/lib/x86_64-linux-gnu/libcairo.so.2.11400.6
7f9a49796000-7f9a49996000 ---p 0010e000 08:21 62790571                   /usr/lib/x86_64-linux-gnu/libcairo.so.2.11400.6
7f9a49996000-7f9a49999000 r--p 0010e000 08:21 62790571                   /usr/lib/x86_64-linux-gnu/libcairo.so.2.11400.6
7f9a49999000-7f9a4999a000 rw-p 00111000 08:21 62790571                   /usr/lib/x86_64-linux-gnu/libcairo.so.2.11400.6
7f9a4999a000-7f9a4999c000 rw-p 00000000 00:00 0 
7f9a4999c000-7f9a499be000 r-xp 00000000 08:21 62790535                   /usr/lib/x86_64-linux-gnu/libatk-1.0.so.0.21809.1
7f9a499be000-7f9a49bbd000 ---p 00022000 08:21 62790535                   /usr/lib/x86_64-linux-gnu/libatk-1.0.so.0.21809.1
7f9a49bbd000-7f9a49bc0000 r--p 00021000 08:21 62790535                   /usr/lib/x86_64-linux-gnu/libatk-1.0.so.0.21809.1
7f9a49bc0000-7f9a49bc1000 rw-p 00024000 08:21 62790535                   /usr/lib/x86_64-linux-gnu/libatk-1.0.so.0.21809.1
7f9a49bc1000-7f9a4ba25000 r-xp 00000000 08:21 62786977                   /usr/lib/libopenblasp-r0.2.18.so
7f9a4ba25000-7f9a4bc24000 ---p 01e64000 08:21 62786977                   /usr/lib/libopenblasp-r0.2.18.so
7f9a4bc24000-7f9a4bc2a000 r--p 01e63000 08:21 62786977                   /usr/lib/libopenblasp-r0.2.18.so
7f9a4bc2a000-7f9a4bc3c000 rw-p 01e69000 08:21 62786977                   /usr/lib/libopenblasp-r0.2.18.so
7f9a4bc3c000-7f9a4dc55000 rw-p 00000000 00:00 0 
7f9a4dc7a000-7f9a4ddba000 rw-p 00000000 00:00 0 
7f9a4ddba000-7f9a4ddc6000 r-xp 00000000 08:21 62790809                   /usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so.0.3800.1
7f9a4ddc6000-7f9a4dfc5000 ---p 0000c000 08:21 62790809                   /usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so.0.3800.1
7f9a4dfc5000-7f9a4dfc6000 r--p 0000b000 08:21 62790809                   /usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so.0.3800.1
7f9a4dfc6000-7f9a4dfc7000 rw-p 0000c000 08:21 62790809                   /usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so.0.3800.1
7f9a4dfc7000-7f9a4dfca000 r-xp 00000000 08:21 62790643                   /usr/lib/x86_64-linux-gnu/libgmodule-2.0.so.0.4800.2
7f9a4dfca000-7f9a4e1c9000 ---p 00003000 08:21 62790643                   /usr/lib/x86_64-linux-gnu/libgmodule-2.0.so.0.4800.2
7f9a4e1c9000-7f9a4e1ca000 r--p 00002000 08:21 62790643                   /usr/lib/x86_64-linux-gnu/libgmodule-2.0.so.0.4800.2
7f9a4e1ca000-7f9a4e1cb000 rw-p 00003000 08:21 62790643                   /usr/lib/x86_64-linux-gnu/libgmodule-2.0.so.0.4800.2
7f9a4e1cb000-7f9a4e1d0000 r-xp 00000000 08:21 62790457                   /usr/lib/x86_64-linux-gnu/libIlmThread-2_2.so.12.0.0
7f9a4e1d0000-7f9a4e3d0000 ---p 00005000 08:21 62790457                   /usr/lib/x86_64-linux-gnu/libIlmThread-2_2.so.12.0.0
7f9a4e3d0000-7f9a4e3d1000 r--p 00005000 08:21 62790457                   /usr/lib/x86_64-linux-gnu/libIlmThread-2_2.so.12.0.0
7f9a4e3d1000-7f9a4e3d2000 rw-p 00006000 08:21 62790457                   /usr/lib/x86_64-linux-gnu/libIlmThread-2_2.so.12.0.0
7f9a4e3d2000-7f9a4e3ed000 r-xp 00000000 08:21 62790443                   /usr/lib/x86_64-linux-gnu/libIex-2_2.so.12.0.0
7f9a4e3ed000-7f9a4e5ec000 ---p 0001b000 08:21 62790443                   /usr/lib/x86_64-linux-gnu/libIex-2_2.so.12.0.0
7f9a4e5ec000-7f9a4e5ef000 r--p 0001a000 08:21 62790443                   /usr/lib/x86_64-linux-gnu/libIex-2_2.so.12.0.0
7f9a4e5ef000-7f9a4e5f0000 rw-p 0001d000 08:21 62790443                   /usr/lib/x86_64-linux-gnu/libIex-2_2.so.12.0.0
7f9a4e5f0000-7f9a4e5fb000 r-xp 00000000 08:21 62790701                   /usr/lib/x86_64-linux-gnu/libjbig.so.0
7f9a4e5fb000-7f9a4e7fa000 ---p 0000b000 08:21 62790701                   /usr/lib/x86_64-linux-gnu/libjbig.so.0
7f9a4e7fa000-7f9a4e7fb000 r--p 0000a000 08:21 62790701                   /usr/lib/x86_64-linux-gnu/libjbig.so.0
7f9a4e7fb000-7f9a4e7fe000 rw-p 0000b000 08:21 62790701                   /usr/lib/x86_64-linux-gnu/libjbig.so.0
7f9a4e7fe000-7f9a4e81f000 r-xp 00000000 08:21 38015914                   /lib/x86_64-linux-gnu/liblzma.so.5.0.0
7f9a4e81f000-7f9a4ea1e000 ---p 00021000 08:21 38015914                   /lib/x86_64-linux-gnu/liblzma.so.5.0.0
7f9a4ea1e000-7f9a4ea1f000 r--p 00020000 08:21 38015914                   /lib/x86_64-linux-gnu/liblzma.so.5.0.0
7f9a4ea1f000-7f9a4ea20000 rw-p 00021000 08:21 38015914                   /lib/x86_64-linux-gnu/liblzma.so.5.0.0
7f9a4ea20000-7f9a4ea30000 r-xp 00000000 08:21 62790582                   /usr/lib/x86_64-linux-gnu/libdrm.so.2.4.0
7f9a4ea30000-7f9a4ec30000 ---p 00010000 08:21 62790582                   /usr/lib/x86_64-linux-gnu/libdrm.so.2.4.0
7f9a4ec30000-7f9a4ec31000 r--p 00010000 08:21 62790582                   /usr/lib/x86_64-linux-gnu/libdrm.so.2.4.0
7f9a4ec31000-7f9a4ec32000 rw-p 00011000 08:21 62790582                   /usr/lib/x86_64-linux-gnu/libdrm.so.2.4.0
7f9a4ec32000-7f9a4ec37000 r-xp 00000000 08:21 62790532                   /usr/lib/x86_64-linux-gnu/libXxf86vm.so.1.0.0
7f9a4ec37000-7f9a4ee36000 ---p 00005000 08:21 62790532                   /usr/lib/x86_64-linux-gnu/libXxf86vm.so.1.0.0
7f9a4ee36000-7f9a4ee37000 r--p 00004000 08:21 62790532                   /usr/lib/x86_64-linux-gnu/libXxf86vm.so.1.0.0
7f9a4ee37000-7f9a4ee38000 rw-p 00005000 08:21 62790532                   /usr/lib/x86_64-linux-gnu/libXxf86vm.so.1.0.0
7f9a4ee38000-7f9a4ee3c000 r-xp 00000000 08:21 62790940                   /usr/lib/x86_64-linux-gnu/libxcb-dri2.so.0.0.0
7f9a4ee3c000-7f9a4f03b000 ---p 00004000 08:21 62790940                   /usr/lib/x86_64-linux-gnu/libxcb-dri2.so.0.0.0
7f9a4f03b000-7f9a4f03c000 r--p 00003000 08:21 62790940                   /usr/lib/x86_64-linux-gnu/libxcb-dri2.so.0.0.0
7f9a4f03c000-7f9a4f03d000 rw-p 00004000 08:21 62790940                   /usr/lib/x86_64-linux-gnu/libxcb-dri2.so.0.0.0
7f9a4f03d000-7f9a4f054000 r-xp 00000000 08:21 62790944                   /usr/lib/x86_64-linux-gnu/libxcb-glx.so.0.0.0
7f9a4f054000-7f9a4f253000 ---p 00017000 08:21 62790944                   /usr/lib/x86_64-linux-gnu/libxcb-glx.so.0.0.0
7f9a4f253000-7f9a4f255000 r--p 00016000 08:21 62790944                   /usr/lib/x86_64-linux-gnu/libxcb-glx.so.0.0.0
7f9a4f255000-7f9a4f256000 rw-p 00018000 08:21 62790944                   /usr/lib/x86_64-linux-gnu/libxcb-glx.so.0.0.0
7f9a4f256000-7f9a4f257000 r-xp 00000000 08:21 62790469                   /usr/lib/x86_64-linux-gnu/libX11-xcb.so.1.0.0
7f9a4f257000-7f9a4f456000 ---p 00001000 08:21 62790469                   /usr/lib/x86_64-linux-gnu/libX11-xcb.so.1.0.0
7f9a4f456000-7f9a4f457000 r--p 00000000 08:21 62790469                   /usr/lib/x86_64-linux-gnu/libX11-xcb.so.1.0.0
7f9a4f457000-7f9a4f458000 rw-p 00001000 08:21 62790469                   /usr/lib/x86_64-linux-gnu/libX11-xcb.so.1.0.0
7f9a4f458000-7f9a51458000 rw-p 00000000 00:00 0 
7f9a5145f000-7f9a5161f000 rw-p 00000000 00:00 0 
7f9a5161f000-7f9a51624000 r-xp 00000000 08:21 62790504                   /usr/lib/x86_64-linux-gnu/libXfixes.so.3.1.0
7f9a51624000-7f9a51823000 ---p 00005000 08:21 62790504                   /usr/lib/x86_64-linux-gnu/libXfixes.so.3.1.0
7f9a51823000-7f9a51824000 r--p 00004000 08:21 62790504                   /usr/lib/x86_64-linux-gnu/libXfixes.so.3.1.0
7f9a51824000-7f9a51825000 rw-p 00005000 08:21 62790504                   /usr/lib/x86_64-linux-gnu/libXfixes.so.3.1.0
7f9a51825000-7f9a51827000 r-xp 00000000 08:21 62790492                   /usr/lib/x86_64-linux-gnu/libXdamage.so.1.1.0
7f9a51827000-7f9a51a26000 ---p 00002000 08:21 62790492                   /usr/lib/x86_64-linux-gnu/libXdamage.so.1.1.0
7f9a51a26000-7f9a51a27000 r--p 00001000 08:21 62790492                   /usr/lib/x86_64-linux-gnu/libXdamage.so.1.1.0
7f9a51a27000-7f9a51a28000 rw-p 00002000 08:21 62790492                   /usr/lib/x86_64-linux-gnu/libXdamage.so.1.1.0
7f9a51a28000-7f9a51a54000 r-xp 00000000 08:21 62790635                   /usr/lib/x86_64-linux-gnu/libglapi.so.0.0.0
7f9a51a54000-7f9a51c53000 ---p 0002c000 08:21 62790635                   /usr/lib/x86_64-linux-gnu/libglapi.so.0.0.0
7f9a51c53000-7f9a51c57000 r--p 0002b000 08:21 62790635                   /usr/lib/x86_64-linux-gnu/libglapi.so.0.0.0
7f9a51c57000-7f9a51c58000 rw-p 0002f000 08:21 62790635                   /usr/lib/x86_64-linux-gnu/libglapi.so.0.0.0
7f9a51c58000-7f9a57c59000 rw-p 00000000 00:00 0 
7f9a57c8d000-7f9a57e4d000 rw-p 00000000 00:00 0 
7f9a57e4d000-7f9a57e4e000 r-xp 00000000 08:21 62790964                   /usr/lib/x86_64-linux-gnu/libxshmfence.so.1.0.0
7f9a57e4e000-7f9a5804e000 ---p 00001000 08:21 62790964                   /usr/lib/x86_64-linux-gnu/libxshmfence.so.1.0.0
7f9a5804e000-7f9a5804f000 r--p 00001000 08:21 62790964                   /usr/lib/x86_64-linux-gnu/libxshmfence.so.1.0.0
7f9a5804f000-7f9a58050000 rw-p 00002000 08:21 62790964                   /usr/lib/x86_64-linux-gnu/libxshmfence.so.1.0.0
7f9a58050000-7f9a58055000 r-xp 00000000 08:21 62790956                   /usr/lib/x86_64-linux-gnu/libxcb-sync.so.1.0.0
7f9a58055000-7f9a58255000 ---p 00005000 08:21 62790956                   /usr/lib/x86_64-linux-gnu/libxcb-sync.so.1.0.0
7f9a58255000-7f9a58256000 r--p 00005000 08:21 62790956                   /usr/lib/x86_64-linux-gnu/libxcb-sync.so.1.0.0
7f9a58256000-7f9a58257000 rw-p 00006000 08:21 62790956                   /usr/lib/x86_64-linux-gnu/libxcb-sync.so.1.0.0
7f9a58257000-7f9a58259000 r-xp 00000000 08:21 62790946                   /usr/lib/x86_64-linux-gnu/libxcb-present.so.0.0.0
7f9a58259000-7f9a58458000 ---p 00002000 08:21 62790946                   /usr/lib/x86_64-linux-gnu/libxcb-present.so.0.0.0
7f9a58458000-7f9a58459000 r--p 00001000 08:21 62790946                   /usr/lib/x86_64-linux-gnu/libxcb-present.so.0.0.0
7f9a58459000-7f9a5845a000 rw-p 00002000 08:21 62790946                   /usr/lib/x86_64-linux-gnu/libxcb-present.so.0.0.0
7f9a5845a000-7f9a5a45a000 rw-p 00000000 00:00 0 
7f9a5a48d000-7f9a5a5cd000 rw-p 00000000 00:00 0 
7f9a5a5cd000-7f9a5a5cf000 r-xp 00000000 08:21 62790942                   /usr/lib/x86_64-linux-gnu/libxcb-dri3.so.0.0.0
7f9a5a5cf000-7f9a5a7ce000 ---p 00002000 08:21 62790942                   /usr/lib/x86_64-linux-gnu/libxcb-dri3.so.0.0.0
7f9a5a7ce000-7f9a5a7cf000 r--p 00001000 08:21 62790942                   /usr/lib/x86_64-linux-gnu/libxcb-dri3.so.0.0.0
7f9a5a7cf000-7f9a5a7d0000 rw-p 00002000 08:21 62790942                   /usr/lib/x86_64-linux-gnu/libxcb-dri3.so.0.0.0
7f9a5a7d0000-7f9a5a80e000 r-xp 00000000 08:21 53355505                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0
7f9a5a80e000-7f9a5aa0d000 ---p 0003e000 08:21 53355505                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0
7f9a5aa0d000-7f9a5aa0e000 r--p 0003d000 08:21 53355505                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0
7f9a5aa0e000-7f9a5aa0f000 rw-p 0003e000 08:21 53355505                   /usr/lib/x86_64-linux-gnu/libquadmath.so.0.0.0
7f9a5aa0f000-7f9a5aa4c000 r-xp 00000000 08:33 1712536                    /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.390.48
7f9a5aa4c000-7f9a5ac4b000 ---p 0003d000 08:33 1712536                    /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.390.48
7f9a5ac4b000-7f9a5ac56000 rw-p 0003c000 08:33 1712536                    /usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.390.48
7f9a5ac56000-7f9a5cc5b000 rw-p 00000000 00:00 0 
7f9a5cc5e000-7f9a5cd9e000 rw-p 00000000 00:00 0 
7f9a5cd9e000-7f9a5ce23000 r-xp 00000000 08:21 62790885                   /usr/lib/x86_64-linux-gnu/libswscale-ffmpeg.so.3.1.101
7f9a5ce23000-7f9a5d022000 ---p 00085000 08:21 62790885                   /usr/lib/x86_64-linux-gnu/libswscale-ffmpeg.so.3.1.101
7f9a5d022000-7f9a5d024000 r--p 00084000 08:21 62790885                   /usr/lib/x86_64-linux-gnu/libswscale-ffmpeg.so.3.1.101
7f9a5d024000-7f9a5d025000 rw-p 00086000 08:21 62790885                   /usr/lib/x86_64-linux-gnu/libswscale-ffmpeg.so.3.1.101
7f9a5d025000-7f9a5d02d000 rw-p 00000000 00:00 0 
7f9a5d02d000-7f9a5db5e000 r-xp 00000000 08:21 62790543                   /usr/lib/x86_64-linux-gnu/libavcodec-ffmpeg.so.56.60.100
7f9a5db5e000-7f9a5dd5d000 ---p 00b31000 08:21 62790543                   /usr/lib/x86_64-linux-gnu/libavcodec-ffmpeg.so.56.60.100
7f9a5dd5d000-7f9a5dd88000 r--p 00b30000 08:21 62790543                   /usr/lib/x86_64-linux-gnu/libavcodec-ffmpeg.so.56.60.100
7f9a5dd88000-7f9a5ddab000 rw-p 00b5b000 08:21 62790543                   /usr/lib/x86_64-linux-gnu/libavcodec-ffmpeg.so.56.60.100
7f9a5ddab000-7f9a6045e000 rw-p 00000000 00:00 0 
7f9a60471000-7f9a604c7000 r-xp 00000000 08:21 62790555                   /usr/lib/x86_64-linux-gnu/libavutil-ffmpeg.so.54.31.100
7f9a604c7000-7f9a606c6000 ---p 00056000 08:21 62790555                   /usr/lib/x86_64-linux-gnu/libavutil-ffmpeg.so.54.31.100
7f9a606c6000-7f9a606cc000 r--p 00055000 08:21 62790555                   /usr/lib/x86_64-linux-gnu/libavutil-ffmpeg.so.54.31.100
7f9a606cc000-7f9a606cd000 rw-p 0005b000 08:21 62790555                   /usr/lib/x86_64-linux-gnu/libavutil-ffmpeg.so.54.31.100
7f9a606cd000-7f9a606e0000 rw-p 00000000 00:00 0 
7f9a606e0000-7f9a608b6000 r-xp 00000000 08:21 62790549                   /usr/lib/x86_64-linux-gnu/libavformat-ffmpeg.so.56.40.101
7f9a608b6000-7f9a60ab6000 ---p 001d6000 08:21 62790549                   /usr/lib/x86_64-linux-gnu/libavformat-ffmpeg.so.56.40.101
7f9a60ab6000-7f9a60aca000 r--p 001d6000 08:21 62790549                   /usr/lib/x86_64-linux-gnu/libavformat-ffmpeg.so.56.40.101
7f9a60aca000-7f9a60adf000 rw-p 001ea000 08:21 62790549                   /usr/lib/x86_64-linux-gnu/libavformat-ffmpeg.so.56.40.101
7f9a60adf000-7f9a60ae4000 r-xp 00000000 08:21 62790916                   /usr/lib/x86_64-linux-gnu/libv4l1.so.0.0.0
7f9a60ae4000-7f9a60ce3000 ---p 00005000 08:21 62790916                   /usr/lib/x86_64-linux-gnu/libv4l1.so.0.0.0
7f9a60ce3000-7f9a60ce4000 r--p 00004000 08:21 62790916                   /usr/lib/x86_64-linux-gnu/libv4l1.so.0.0.0
7f9a60ce4000-7f9a60ce5000 rw-p 00005000 08:21 62790916                   /usr/lib/x86_64-linux-gnu/libv4l1.so.0.0.0
7f9a60ce5000-7f9a60d1a000 r-xp 00000000 08:21 62790580                   /usr/lib/x86_64-linux-gnu/libdc1394.so.22.1.11
7f9a60d1a000-7f9a60f19000 ---p 00035000 08:21 62790580                   /usr/lib/x86_64-linux-gnu/libdc1394.so.22.1.11
7f9a60f19000-7f9a60f1a000 r--p 00034000 08:21 62790580                   /usr/lib/x86_64-linux-gnu/libdc1394.so.22.1.11
7f9a60f1a000-7f9a60f1b000 rw-p 00035000 08:21 62790580                   /usr/lib/x86_64-linux-gnu/libdc1394.so.22.1.11
7f9a60f1b000-7f9a60f5b000 rw-p 00000000 00:00 0 
7f9a60f5b000-7f9a60fb8000 r-xp 00000000 08:21 62790625                   /usr/lib/x86_64-linux-gnu/libgdkglext-x11-1.0.so.0.0.0
7f9a60fb8000-7f9a611b7000 ---p 0005d000 08:21 62790625                   /usr/lib/x86_64-linux-gnu/libgdkglext-x11-1.0.so.0.0.0
7f9a611b7000-7f9a611b9000 r--p 0005c000 08:21 62790625                   /usr/lib/x86_64-linux-gnu/libgdkglext-x11-1.0.so.0.0.0
7f9a611b9000-7f9a611bf000 rw-p 0005e000 08:21 62790625                   /usr/lib/x86_64-linux-gnu/libgdkglext-x11-1.0.so.0.0.0
7f9a611bf000-7f9a611c2000 r-xp 00000000 08:21 62790666                   /usr/lib/x86_64-linux-gnu/libgtkglext-x11-1.0.so.0.0.0
7f9a611c2000-7f9a613c1000 ---p 00003000 08:21 62790666                   /usr/lib/x86_64-linux-gnu/libgtkglext-x11-1.0.so.0.0.0
7f9a613c1000-7f9a613c2000 r--p 00002000 08:21 62790666                   /usr/lib/x86_64-linux-gnu/libgtkglext-x11-1.0.so.0.0.0
7f9a613c2000-7f9a613c3000 rw-p 00003000 08:21 62790666                   /usr/lib/x86_64-linux-gnu/libgtkglext-x11-1.0.so.0.0.0
7f9a613c3000-7f9a61415000 r-xp 00000000 08:21 62790647                   /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0.4800.2
7f9a61415000-7f9a61614000 ---p 00052000 08:21 62790647                   /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0.4800.2
7f9a61614000-7f9a61615000 r--p 00051000 08:21 62790647                   /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0.4800.2
7f9a61615000-7f9a61616000 rw-p 00052000 08:21 62790647                   /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0.4800.2
7f9a61616000-7f9a61a54000 r-xp 00000000 08:21 62790661                   /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0.2400.30
7f9a61a54000-7f9a61c53000 ---p 0043e000 08:21 62790661                   /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0.2400.30
7f9a61c53000-7f9a61c5a000 r--p 0043d000 08:21 62790661                   /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0.2400.30
7f9a61c5a000-7f9a61c5e000 rw-p 00444000 08:21 62790661                   /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0.2400.30
7f9a61c5e000-7f9a63c61000 rw-p 00000000 00:00 0 
7f9a63c9f000-7f9a63cdf000 rw-p 00000000 00:00 0 
7f9a63cdf000-7f9a63d8f000 r-xp 00000000 08:21 62790617                   /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0.2400.30
7f9a63d8f000-7f9a63f8e000 ---p 000b0000 08:21 62790617                   /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0.2400.30
7f9a63f8e000-7f9a63f92000 r--p 000af000 08:21 62790617                   /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0.2400.30
7f9a63f92000-7f9a63f94000 rw-p 000b3000 08:21 62790617                   /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0.2400.30
7f9a63f94000-7f9a6415e000 r-xp 00000000 08:21 62790449                   /usr/lib/x86_64-linux-gnu/libIlmImf-2_2.so.22.0.0
7f9a6415e000-7f9a6435d000 ---p 001ca000 08:21 62790449                   /usr/lib/x86_64-linux-gnu/libIlmImf-2_2.so.22.0.0
7f9a6435d000-7f9a64360000 r--p 001c9000 08:21 62790449                   /usr/lib/x86_64-linux-gnu/libIlmImf-2_2.so.22.0.0
7f9a64360000-7f9a64461000 rw-p 001cc000 08:21 62790449                   /usr/lib/x86_64-linux-gnu/libIlmImf-2_2.so.22.0.0
7f9a64461000-7f9a66462000 rw-p 00000000 00:00 0 
7f9a6648e000-7f9a6650e000 rw-p 00000000 00:00 0 
7f9a6650e000-7f9a66550000 r-xp 00000000 08:21 62790437                   /usr/lib/x86_64-linux-gnu/libHalf.so.12.0.0
7f9a66550000-7f9a6674f000 ---p 00042000 08:21 62790437                   /usr/lib/x86_64-linux-gnu/libHalf.so.12.0.0
7f9a6674f000-7f9a66750000 r--p 00041000 08:21 62790437                   /usr/lib/x86_64-linux-gnu/libHalf.so.12.0.0
7f9a66750000-7f9a66751000 rw-p 00042000 08:21 62790437                   /usr/lib/x86_64-linux-gnu/libHalf.so.12.0.0
7f9a66751000-7f9a6679b000 r-xp 00000000 08:21 62790698                   /usr/lib/x86_64-linux-gnu/libjasper.so.1.0.0
7f9a6679b000-7f9a6699a000 ---p 0004a000 08:21 62790698                   /usr/lib/x86_64-linux-gnu/libjasper.so.1.0.0
7f9a6699a000-7f9a6699b000 r--p 00049000 08:21 62790698                   /usr/lib/x86_64-linux-gnu/libjasper.so.1.0.0
7f9a6699b000-7f9a6699f000 rw-p 0004a000 08:21 62790698                   /usr/lib/x86_64-linux-gnu/libjasper.so.1.0.0
7f9a6699f000-7f9a669a6000 rw-p 00000000 00:00 0 
7f9a669a6000-7f9a66a17000 r-xp 00000000 08:21 62790902                   /usr/lib/x86_64-linux-gnu/libtiff.so.5.2.4
7f9a66a17000-7f9a66c17000 ---p 00071000 08:21 62790902                   /usr/lib/x86_64-linux-gnu/libtiff.so.5.2.4
7f9a66c17000-7f9a66c18000 r--p 00071000 08:21 62790902                   /usr/lib/x86_64-linux-gnu/libtiff.so.5.2.4
7f9a66c18000-7f9a66c1b000 rw-p 00072000 08:21 62790902                   /usr/lib/x86_64-linux-gnu/libtiff.so.5.2.4
7f9a66c1b000-7f9a68045000 r-xp 00000000 08:21 50074739                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libnvrtc.so.9.0.176
7f9a68045000-7f9a68244000 ---p 0142a000 08:21 50074739                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libnvrtc.so.9.0.176
7f9a68244000-7f9a683ee000 rw-p 01429000 08:21 50074739                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libnvrtc.so.9.0.176
7f9a683ee000-7f9a6a466000 rw-p 00000000 00:00 0 
7f9a6a46c000-7f9a6a5ac000 rw-p 00000000 00:00 0 
7f9a6a5ac000-7f9a6a5d0000 r-xp 00000000 08:21 62529463                   /lib/x86_64-linux-gnu/libpng12.so.0.54.0
7f9a6a5d0000-7f9a6a7cf000 ---p 00024000 08:21 62529463                   /lib/x86_64-linux-gnu/libpng12.so.0.54.0
7f9a6a7cf000-7f9a6a7d0000 r--p 00023000 08:21 62529463                   /lib/x86_64-linux-gnu/libpng12.so.0.54.0
7f9a6a7d0000-7f9a6a7d1000 rw-p 00024000 08:21 62529463                   /lib/x86_64-linux-gnu/libpng12.so.0.54.0
7f9a6a7d1000-7f9a6a828000 r-xp 00000000 08:21 62790705                   /usr/lib/x86_64-linux-gnu/libjpeg.so.8.0.2
7f9a6a828000-7f9a6aa28000 ---p 00057000 08:21 62790705                   /usr/lib/x86_64-linux-gnu/libjpeg.so.8.0.2
7f9a6aa28000-7f9a6aa29000 r--p 00057000 08:21 62790705                   /usr/lib/x86_64-linux-gnu/libjpeg.so.8.0.2
7f9a6aa29000-7f9a6aa2a000 rw-p 00058000 08:21 62790705                   /usr/lib/x86_64-linux-gnu/libjpeg.so.8.0.2
7f9a6aa2a000-7f9a6aa61000 r-xp 00000000 08:21 62790888                   /usr/lib/x86_64-linux-gnu/libtbb.so.2
7f9a6aa61000-7f9a6ac61000 ---p 00037000 08:21 62790888                   /usr/lib/x86_64-linux-gnu/libtbb.so.2
7f9a6ac61000-7f9a6ac62000 r--p 00037000 08:21 62790888                   /usr/lib/x86_64-linux-gnu/libtbb.so.2
7f9a6ac62000-7f9a6ac64000 rw-p 00038000 08:21 62790888                   /usr/lib/x86_64-linux-gnu/libtbb.so.2
7f9a6ac64000-7f9a70c67000 rw-p 00000000 00:00 0 
7f9a70c79000-7f9a70db9000 rw-p 00000000 00:00 0 
7f9a70db9000-7f9a70e29000 r-xp 00000000 08:21 62790976                   /usr/lib/x86_64-linux-gnu/mesa/libGL.so.1.2.0
7f9a70e29000-7f9a71028000 ---p 00070000 08:21 62790976                   /usr/lib/x86_64-linux-gnu/mesa/libGL.so.1.2.0
7f9a71028000-7f9a7102b000 r--p 0006f000 08:21 62790976                   /usr/lib/x86_64-linux-gnu/mesa/libGL.so.1.2.0
7f9a7102b000-7f9a7102c000 rw-p 00072000 08:21 62790976                   /usr/lib/x86_64-linux-gnu/mesa/libGL.so.1.2.0
7f9a7102c000-7f9a7102d000 rw-p 00000000 00:00 0 
7f9a7102d000-7f9a71156000 r-xp 00000000 08:21 62790627                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
7f9a71156000-7f9a71355000 ---p 00129000 08:21 62790627                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
7f9a71355000-7f9a71356000 r--p 00128000 08:21 62790627                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
7f9a71356000-7f9a71358000 rw-p 00129000 08:21 62790627                   /usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
7f9a71358000-7f9a71b9a000 r-xp 00000000 08:33 1712531                    /usr/lib/x86_64-linux-gnu/libcuda.so.390.48
7f9a71b9a000-7f9a71d99000 ---p 00842000 08:33 1712531                    /usr/lib/x86_64-linux-gnu/libcuda.so.390.48
7f9a71d99000-7f9a71eea000 rw-p 00841000 08:33 1712531                    /usr/lib/x86_64-linux-gnu/libcuda.so.390.48
7f9a71eea000-7f9a71ef8000 rw-p 00000000 00:00 0 
7f9a71ef8000-7f9a720e8000 r-xp 00000000 08:21 62790751                   /usr/lib/x86_64-linux-gnu/libopencv_imgproc.so.2.4.9
7f9a720e8000-7f9a722e7000 ---p 001f0000 08:21 62790751                   /usr/lib/x86_64-linux-gnu/libopencv_imgproc.so.2.4.9
7f9a722e7000-7f9a722ed000 r--p 001ef000 08:21 62790751                   /usr/lib/x86_64-linux-gnu/libopencv_imgproc.so.2.4.9
7f9a722ed000-7f9a722ee000 rw-p 001f5000 08:21 62790751                   /usr/lib/x86_64-linux-gnu/libopencv_imgproc.so.2.4.9
7f9a722ee000-7f9a72383000 rw-p 00000000 00:00 0 
7f9a72383000-7f9a723d1000 r-xp 00000000 08:21 62790747                   /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4.9
7f9a723d1000-7f9a725d0000 ---p 0004e000 08:21 62790747                   /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4.9
7f9a725d0000-7f9a725d3000 r--p 0004d000 08:21 62790747                   /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4.9
7f9a725d3000-7f9a725d4000 rw-p 00050000 08:21 62790747                   /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4.9
7f9a725d4000-7f9a727f1000 r-xp 00000000 08:21 62790731                   /usr/lib/x86_64-linux-gnu/libopencv_core.so.2.4.9
7f9a727f1000-7f9a729f1000 ---p 0021d000 08:21 62790731                   /usr/lib/x86_64-linux-gnu/libopencv_core.so.2.4.9
7f9a729f1000-7f9a729f5000 r--p 0021d000 08:21 62790731                   /usr/lib/x86_64-linux-gnu/libopencv_core.so.2.4.9
7f9a729f5000-7f9a729fc000 rw-p 00221000 08:21 62790731                   /usr/lib/x86_64-linux-gnu/libopencv_core.so.2.4.9
7f9a729fc000-7f9a729fe000 rw-p 00000000 00:00 0 
7f9a729fe000-7f9a72a67000 r-xp 00000000 08:21 48113201                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176
7f9a72a67000-7f9a72c66000 ---p 00069000 08:21 48113201                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176
7f9a72c66000-7f9a72c6a000 rw-p 00068000 08:21 48113201                   /usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176
7f9a72c6a000-7f9a72c6b000 rw-p 00000000 00:00 0 
7f9a72c6b000-7f9a72d5b000 r-xp 00000000 08:21 3018825                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libgfortran-ed201abd.so.3.0.0
7f9a72d5b000-7f9a72f5a000 ---p 000f0000 08:21 3018825                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libgfortran-ed201abd.so.3.0.0
7f9a72f5a000-7f9a72f5c000 rw-p 000ef000 08:21 3018825                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libgfortran-ed201abd.so.3.0.0
7f9a72f5c000-7f9a72f5d000 rw-p 00000000 00:00 0 
7f9a72f5d000-7f9a72f65000 rw-p 000f2000 08:21 3018825                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libgfortran-ed201abd.so.3.0.0
7f9a72f65000-7f9a74a65000 r-xp 00000000 08:21 3018824                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libopenblasp-r0-382c8f3a.3.5.dev.so
7f9a74a65000-7f9a74c65000 ---p 01b00000 08:21 3018824                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libopenblasp-r0-382c8f3a.3.5.dev.so
7f9a74c65000-7f9a74c7e000 rw-p 01b00000 08:21 3018824                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libopenblasp-r0-382c8f3a.3.5.dev.so
7f9a74c7e000-7f9a74c89000 rw-p 00000000 00:00 0 
7f9a74c89000-7f9a74d01000 rw-p 01beb000 08:21 3018824                    /usr/local/lib/python2.7/dist-packages/numpy/.libs/libopenblasp-r0-382c8f3a.3.5.dev.so
7f9a74d01000-7f9a75088000 r-xp 00000000 08:21 3018433                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_umath.so
7f9a75088000-7f9a75287000 ---p 00387000 08:21 3018433                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_umath.so
7f9a75287000-7f9a752a6000 rw-p 00386000 08:21 3018433                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_umath.so
7f9a752a6000-7f9a752c7000 rw-p 00000000 00:00 0 
7f9a752c7000-7f9a752ce000 rw-p 012b0000 08:21 3018433                    /usr/local/lib/python2.7/dist-packages/numpy/core/_multiarray_umath.so
7f9a752ce000-7f9a7534e000 rw-p 00000000 00:00 0 
7f9a7534e000-7f9a75569000 r-xp 00000000 08:21 45487999                   /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
7f9a75569000-7f9a75768000 ---p 0021b000 08:21 45487999                   /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
7f9a75768000-7f9a75784000 r--p 0021a000 08:21 45487999                   /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
7f9a75784000-7f9a75790000 rw-p 00236000 08:21 45487999                   /lib/x86_64-linux-gnu/libcrypto.so.1.0.0
7f9a75790000-7f9a75793000 rw-p 00000000 00:00 0 
7f9a75793000-7f9a75799000 r-xp 00000000 08:21 62787964                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
7f9a75799000-7f9a75998000 ---p 00006000 08:21 62787964                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
7f9a75998000-7f9a75999000 r--p 00005000 08:21 62787964                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
7f9a75999000-7f9a7599a000 rw-p 00006000 08:21 62787964                   /usr/lib/python2.7/lib-dynload/_hashlib.x86_64-linux-gnu.so
7f9a7599b000-7f9a75b1b000 rw-p 00000000 00:00 0 
7f9a75b1b000-7f9a75c23000 r-xp 00000000 08:21 38015915                   /lib/x86_64-linux-gnu/libm-2.23.so
7f9a75c23000-7f9a75e22000 ---p 00108000 08:21 38015915                   /lib/x86_64-linux-gnu/libm-2.23.so
7f9a75e22000-7f9a75e23000 r--p 00107000 08:21 38015915                   /lib/x86_64-linux-gnu/libm-2.23.so
7f9a75e23000-7f9a75e24000 rw-p 00108000 08:21 38015915                   /lib/x86_64-linux-gnu/libm-2.23.so
7f9a75e24000-7f9a75e3d000 r-xp 00000000 08:21 38015982                   /lib/x86_64-linux-gnu/libz.so.1.2.8
7f9a75e3d000-7f9a7603c000 ---p 00019000 08:21 38015982                   /lib/x86_64-linux-gnu/libz.so.1.2.8
7f9a7603c000-7f9a7603d000 r--p 00018000 08:21 38015982                   /lib/x86_64-linux-gnu/libz.so.1.2.8
7f9a7603d000-7f9a7603e000 rw-p 00019000 08:21 38015982                   /lib/x86_64-linux-gnu/libz.so.1.2.8
7f9a7603e000-7f9a76040000 r-xp 00000000 08:21 38015977                   /lib/x86_64-linux-gnu/libutil-2.23.so
7f9a76040000-7f9a7623f000 ---p 00002000 08:21 38015977                   /lib/x86_64-linux-gnu/libutil-2.23.so
7f9a7623f000-7f9a76240000 r--p 00001000 08:21 38015977                   /lib/x86_64-linux-gnu/libutil-2.23.so
7f9a76240000-7f9a76241000 rw-p 00002000 08:21 38015977                   /lib/x86_64-linux-gnu/libutil-2.23.so
7f9a76241000-7f9a76244000 r-xp 00000000 08:21 38015896                   /lib/x86_64-linux-gnu/libdl-2.23.so
7f9a76244000-7f9a76443000 ---p 00003000 08:21 38015896                   /lib/x86_64-linux-gnu/libdl-2.23.so
7f9a76443000-7f9a76444000 r--p 00002000 08:21 38015896                   /lib/x86_64-linux-gnu/libdl-2.23.so
7f9a76444000-7f9a76445000 rw-p 00003000 08:21 38015896                   /lib/x86_64-linux-gnu/libdl-2.23.so
7f9a76445000-7f9a76605000 r-xp 00000000 08:21 38015883                   /lib/x86_64-linux-gnu/libc-2.23.so
7f9a76605000-7f9a76805000 ---p 001c0000 08:21 38015883                   /lib/x86_64-linux-gnu/libc-2.23.so
7f9a76805000-7f9a76809000 r--p 001c0000 08:21 38015883                   /lib/x86_64-linux-gnu/libc-2.23.so
7f9a76809000-7f9a7680b000 rw-p 001c4000 08:21 38015883                   /lib/x86_64-linux-gnu/libc-2.23.so
7f9a7680b000-7f9a7680f000 rw-p 00000000 00:00 0 
7f9a7680f000-7f9a76827000 r-xp 00000000 08:21 38015951                   /lib/x86_64-linux-gnu/libpthread-2.23.so
7f9a76827000-7f9a76a26000 ---p 00018000 08:21 38015951                   /lib/x86_64-linux-gnu/libpthread-2.23.so
7f9a76a26000-7f9a76a27000 r--p 00017000 08:21 38015951                   /lib/x86_64-linux-gnu/libpthread-2.23.so
7f9a76a27000-7f9a76a28000 rw-p 00018000 08:21 38015951                   /lib/x86_64-linux-gnu/libpthread-2.23.so
7f9a76a28000-7f9a76a2c000 rw-p 00000000 00:00 0 
7f9a76a2c000-7f9a76a52000 r-xp 00000000 08:21 38015863                   /lib/x86_64-linux-gnu/ld-2.23.so
7f9a76a8a000-7f9a76a8b000 rw-p 00000000 00:00 0 
7f9a76a8b000-7f9a76a8c000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76a8c000-7f9a76a8d000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76a8d000-7f9a76a8e000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76a8e000-7f9a76b4e000 rw-p 00000000 00:00 0 
7f9a76b4e000-7f9a76b4f000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b4f000-7f9a76b50000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b50000-7f9a76b51000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b51000-7f9a76b52000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b52000-7f9a76b70000 r-xp 00000000 08:21 38015974                   /lib/x86_64-linux-gnu/libudev.so.1.6.4
7f9a76b70000-7f9a76b71000 r--p 0001d000 08:21 38015974                   /lib/x86_64-linux-gnu/libudev.so.1.6.4
7f9a76b71000-7f9a76b72000 rw-p 0001e000 08:21 38015974                   /lib/x86_64-linux-gnu/libudev.so.1.6.4
7f9a76b72000-7f9a76b73000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b73000-7f9a76b74000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b74000-7f9a76b75000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b75000-7f9a76b76000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b76000-7f9a76b77000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b77000-7f9a76b78000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b78000-7f9a76b79000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b79000-7f9a76b7a000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b7a000-7f9a76b7b000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b7b000-7f9a76b7c000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b7c000-7f9a76b7d000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b7d000-7f9a76b7e000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76b7e000-7f9a76b7f000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76b7f000-7f9a76c44000 rw-p 00000000 00:00 0 
7f9a76c44000-7f9a76c45000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c45000-7f9a76c46000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c46000-7f9a76c47000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c47000-7f9a76c48000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c48000-7f9a76c49000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c49000-7f9a76c4a000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c4a000-7f9a76c4b000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c4b000-7f9a76c4c000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c4c000-7f9a76c4d000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c4d000-7f9a76c4e000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c4e000-7f9a76c4f000 rw-s 00000000 00:06 816                        /dev/nvidia0
7f9a76c4f000-7f9a76c50000 rw-s 00000000 00:06 815                        /dev/nvidiactl
7f9a76c50000-7f9a76c51000 rwxp 00000000 00:00 0 
7f9a76c51000-7f9a76c52000 r--p 00025000 08:21 38015863                   /lib/x86_64-linux-gnu/ld-2.23.so
7f9a76c52000-7f9a76c53000 rw-p 00026000 08:21 38015863                   /lib/x86_64-linux-gnu/ld-2.23.so
7f9a76c53000-7f9a76c54000 rw-p 00000000 00:00 0 
7fff2cb1b000-7fff2cb3c000 rw-p 00000000 00:00 0                          [stack]
7fff2cb80000-7fff2cb83000 r--p 00000000 00:00 0                          [vvar]
7fff2cb83000-7fff2cb85000 r-xp 00000000 00:00 0                          [vdso]
ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]
bash: line 1: 56358 Aborted                 (core dumped) env ""JETBRAINS_REMOTE_RUN""=""1"" ""LIBRARY_ROOTS""=""C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/1227070294;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/graphviz-0.8.4-py2.7.egg!/;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-554785109;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/370154233;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-518999124;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/idna-2.6-py2.7.egg!/;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/chardet-3.0.4-py2.7.egg!/;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/201544331;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/724150857;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-154863933;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-1227933812;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-125940560;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/2085782652;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/201545290;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/452379848;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/1405239563;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-1171821208;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/530511828;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/427714987;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-541471831;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-1437370484;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/17574554;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/-669732926;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/452463671;C:/Users/chenhuizhen/.PyCharm2018.3/system/remote_sources/823358608/662605150;C:/Users/chenhuizhen/.PyCharm2018.3/system/python_stubs/823358608;C:/Program Files/JetBrains/PyCharm 2018.3.1/helpers/python-skeletons;C:/Program Files/JetBrains/PyCharm 2018.3.1/helpers/typeshed/stdlib/2;C:/Program Files/JetBrains/PyCharm 2018.3.1/helpers/typeshed/stdlib/2and3;C:/Program Files/JetBrains/PyCharm 2018.3.1/helpers/typeshed/third_party/2;C:/Program Files/JetBrains/PyCharm 2018.3.1/helpers/typeshed/third_party/2and3"" ""PYDEVD_LOAD_VALUES_ASYNC""=""True"" ""PYTHONPATH""=""/opt/kd-pavement-crackseg:/root/.pycharm_helpers/pycharm_matplotlib_backend:/root/.pycharm_helpers/third_party/thriftpy:/root/.pycharm_helpers/pydev:C:/Users/chenhuizhen/.PyCharm2018.3/system/cythonExtensions:/opt/kd-pavement-crackseg"" ""PYTHONIOENCODING""=""UTF-8"" ""PYTHONDONTWRITEBYTECODE""=""1"" ""IPYTHONENABLE""=""True"" ""PYCHARM_MATPLOTLIB_PORT""=""64619"" ""PYCHARM_HOSTED""=""1"" ""PYTHONUNBUFFERED""=""1"" ""IDE_PROJECT_ROOTS""=""/opt/kd-pavement-crackseg"" '/usr/bin/python' '-u' '/root/.pycharm_helpers/pydev/pydevd.py' '--multiproc' '--qt-support=auto' '--client' '0.0.0.0' '--port' '44975' '--file' '/opt/kd-pavement-crackseg/main_crack_segmentation.py'

Process finished with exit code 134
",Bug,"['I met this problem too, have you solved it?', '@IMJerryChen can you please post steps to reproduce the seg fault?', '@IMJerryChen ping ', 'Could u provide the code u are using?\r\n']",[],[],0,0
212,incubator-mxnet,11879,open,[MXNet-Scala] Scala Build produces warnings.,"Scala has many warnings due to different dependencies requiring different versions of Scala such as the below. One option is to consider using Scala 2.12(needs analysis if it breaks compatibility.

",Build Scala,"['@mxnet-label-bot [Good First Issue]', ""Those warning is harmless, scala promise binary compatibility between minor version. As long as all of them has the same major verison 2.11, we are fine.\r\n\r\nUpgrade to 2.12 won't solve this problem. And this warning can not be completely eliminated by us. Many of them come from our dependencies. For example: org.scalatest:scalatest_2.11:jar:3.0.5 (requires 2.11.12), itself depends on   org.scala-lang.modules:scala-xml_2.11:jar:1.0.6 (requires 2.11.7), This warning will show up unless scalatest upgrade their dependency to 2.11.12.\r\n""]","['\r\n[INFO] Checking for multiple versions of scala\r\n[WARNING]  Expected all dependencies to require Scala version: 2.11.8\r\n[WARNING]  org.apache.mxnet:mxnet-parent_2.11:1.3.0-SNAPSHOT requires scala version: 2.11.8\r\n[WARNING]  org.scala-lang:scala-reflect:2.11.8 requires scala version: 2.11.8\r\n[WARNING]  org.scalatest:scalatest_2.11:3.0.4 requires scala version: 2.11.11\r\n[WARNING] Multiple versions of scala libraries detected!\r\n[INFO] includes = [**/*.java,**/*.scala,]\r\n']",[],0,0
213,incubator-mxnet,8444,open,/include/mxnet-cpp/operator.hpp:157:31: error:        expected ';' at end of declaration   std::vector<NDArray> outputs{output};,"I built mxnet with cpp, and copied libmxnet.so and libmxnet_static.a to my project as well as the headers, but when build the error says:


What exactly why this happened?",Build,"['You need to enable c++11 (at least) for your project compilation, add -std=c++11 flag that is.', '@lebeg Hi, so many thanks for your reply, after turn on c++ 11, things seems got a very far reach, but it still gives me some errors:\r\n\r\n```\r\nUndefined symbols for architecture x86_64:\r\n  ""cv::Mat::deallocate()"", referenced from:\r\n      mxnet::Imdecode(mxnet::NDArray*, mxnet::NDArray, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, char*) in libmxnet_static.a(ndarray.cc.o)\r\n  ""cv::error(int, cv::String const&, char const*, char const*, int)"", referenced from:\r\n      cv::Mat::Mat(int, int, int, void*, unsigned long) in libmxnet_static.a(ndarray.cc.o)\r\n  ""cv::String::deallocate()"", referenced from:\r\n      cv::Mat::Mat(int, int, int, void*, unsigned long) in libmxnet_static.a(ndarray.cc.o)\r\n  ""cv::String::allocate(unsigned long)"", referenced from:\r\n      cv::Mat::Mat(int, int, int, void*, unsigned long) in libmxnet_static.a(ndarray.cc.o)\r\n  ""cv::fastFree(void*)"", referenced from:\r\n      mxnet::Imdecode(mxnet::NDArray*, mxnet::NDArray, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, char*) in libmxnet_static.a(ndarray.cc.o)\r\n  ""cv::imdecode(cv::_InputArray const&, int)"", referenced from:\r\n      mxnet::Imdecode(mxnet::NDArray*, mxnet::NDArray, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, char*) in libmxnet_static.a(ndarray.cc.o)\r\n  ""dmlc::RecordIOReader::NextRecord(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >*)"", referenced from:\r\n      _MXRecordIOReaderReadRecord in libmxnet_static.a(c_api.cc.o)\r\n  ""dmlc::RecordIOWriter::WriteRecord(void const*, unsigned long)"", referenced from:\r\n      _MXRecordIOWriterWriteRecord in libmxnet_static.a(c_api.cc.o)\r\n  ""dmlc::Stream::Create(char const*, char const*, bool)"", referenced from:\r\n      _MXNDArraySave in libmxnet_static.a(c_api.cc.o)\r\n      _MXNDArrayLoad in libmxnet_static.a(c_api.cc.o)\r\n      _MXRecordIOWriterCreate in libmxnet_static.a(c_api.cc.o)\r\n      _MXRecordIOReaderCreate in libmxnet_static.a(c_api.cc.o)\r\n      _MXSymbolCreateFromFile in libmxnet_static.a(c_api_symbolic.cc.o)\r\n      _MXSymbolSaveToFile in libmxnet_static.a(c_api_symbolic.cc.o)\r\nld: symbol(s) not found for architecture x86_64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n```\r\n\r\nThis is caused by OpenCV, but I disabled it when I build mxnet, why it still give me the error, if I want fix it, should I install opencv and link it in my project or there are anyother solutions?', ""Try adding MXNET_USE_OPENCV=0 to your project's flags?"", '@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.']","[""\r\n/Volumes/xs/CodeSpace/ng/ai/frameworks/mxnet_space/mxnet_cpp_test/./include/mxnet-cpp/operator.hpp:128:43: error: \r\n      expected expression\r\n      std::back_inserter(output_handles), [](NDArray& a) {\r\n                                          ^\r\n/Volumes/xs/CodeSpace/ng/ai/frameworks/mxnet_space/mxnet_cpp_test/./include/mxnet-cpp/operator.hpp:145:36: error: \r\n      expected expression\r\n      std::back_inserter(outputs), [](const NDArrayHandle& handle) {\r\n                                   ^\r\n/Volumes/xs/CodeSpace/ng/ai/frameworks/mxnet_space/mxnet_cpp_test/./include/mxnet-cpp/operator.hpp:157:31: error: \r\n      expected ';' at end of declaration\r\n  std::vector<NDArray> outputs{output};\r\n                              ^\r\n                              ;\r\nIn file included from /Volumes/xs/CodeSpace/ng/ai/frameworks/mxnet_space/mxnet_cpp_test/fuck.cpp:10:\r\nIn file included from /Volumes/xs/CodeSpace/ng/ai/frameworks/mxnet_space/mxnet_cpp_test/./include/mxnet-cpp/MxNetCpp.h:34:\r\nIn file included from /Volumes/xs/CodeSpace/ng/ai/frameworks/mxnet_space/mxnet_cpp_test/./include/mxnet-cpp/optimizer.hpp:37:\r\nIn file included from /Volumes/xs/CodeSpace/ng/ai/frameworks/mxnet_space/mxnet_cpp_test/./include/mxnet-cpp/op.h:17:\r\n/usr/local/include/dmlc/optional.h:28:3: error: unknown type name 'constexpr'\r\n  constexpr nullopt_t(int a) {}\r\n  ^\r\n/usr/local/include/dmlc/optional.h:28:13: error: constructor cannot have a return type\r\n  constexpr nullopt_t(int a) {}\r\n            ^~~~~~~~~\r\n/usr/local/include/dmlc/optional.h:33:1: error: unknown type name 'constexpr'\r\nconstexpr const nullopt_t nullopt = nullopt_t(0);\r\n^\r\n/usr/local/include/dmlc/optional.h:33:11: error: expected unqualified-id\r\nconstexpr const nullopt_t nullopt = nullopt_t(0);\r\n          ^\r\n/usr/local/include/dmlc/optional.h:124:52: error: 'T' does not refer to a value\r\n  typename std::aligned_storage<sizeof(T), alignof(T)>::type val;\r\n                                                   ^\r\n/usr/local/include/dmlc/optional.h:42:19: note: declared here\r\ntemplate<typename T>\r\n                  ^\r\n/usr/local/include/dmlc/optional.h:124:57: error: non-friend class member 'type' cannot have a\r\n      qualified name\r\n  typename std::aligned_storage<sizeof(T), alignof(T)>::type val;\r\n\r\n\r\n""]",[],0,0
214,incubator-mxnet,2710,open,elastic SGD,"Hi All,

Is there support for elastic SGD ?
",Call for Contribution Feature request,"['The EASGD?\n', ""@amithr1 Do you mean Elastic Averaging SGD (EASGD)? We can implement that using the current KVStore API and low-level executor APIs. @peterzcc and I have done this but it's not ready for a PR.\n"", '@sxjscience I did it too, but the solution is not nice. Can you PR one later?\n#1657 is my experience on implementation. Maybe it would be helpful for you, \n', ""@Godricly We have written a separate server optimizer for EASGD (https://github.com/sxjscience/mxnet/blob/master/python/mxnet/optimizer.py#L849-L867). The local workers will update the weights using the local optimizer and communicate with the server using `pull`, `push` primitives, which will be handled by the server optimizer.\nAccording to our experiments, EASGD is more stable than DownpourSGD (We can communicate in larger steps). However, adding EASGD support to high-level API requires additional works (performance comparisons + compatibility checks). We haven't found time to do this.\n"", 'wow...thats much better than what i did in messing up model.py with kvstore. So each local work is a node in EASGD?\n', '@Godricly Yes. The workflow looks like this. \n\n``` python\nserver_optimizer = mx.optimizer.create(name=""ServerEASGD"", learning_rate=easgd_alpha)\nkv.set_optimizer(server_optimizer)\nlocal_updater = mx.optimizer.get_updater(local_optimizer)\nwhile NOT_CONVERGE:\n   net.forward(is_train=True, data=data)\n   net.backward(label=label)\n   if total_steps % kvstore_update_period == 0:\n       for ind, k in enumerate(net.params.keys()):\n           kv.pull(ind, central_weight[k], priority=-ind)\n           net.params[k][:] -= easgd_alpha *(net.params[k] - central_weight[k])\n           kv.push(ind, net.params[k], priority=-ind)\n           net.update(updater=local_updater)\n```\n', 'Cool. Is this one based on module interface? \n', ""It's mainly based on the low-level executor. I've written a simple wrapper for that, which is similar to the module interface.\n"", ""@sxjscience \nShouldn't you do: \n         for ind, k in enumerate(net.params.keys()):\n           kv.pull(ind, central_weight[k], priority=-ind)\n            kv.push(ind, net.params[k], priority=-ind)\n           net.params[k][:] -= easgd_alpha *(net.params[k] - central_weight[k])\n           net.update(updater=local_updater)\ni.e. instead of pushing the new updated local parameter value to the server, push the old one ?\n"", 'I have this few changes for the Elastic SGD to work..The changes are to the python/mxnet/model.py on local and remote updates. The changes look straight forward to me but I may be missing something as the learning I observe is very poor..pasting what I did below:\n\n  """""" Perform update of param_arrays from central variables on kvstore. Use grad arrays to pull in the center variables""""""\n\n`def _update_params_on_kvstore(param_arrays, grad_arrays, kvstore):\n\n```\n   for index, pair in enumerate(zip(param_arrays, grad_arrays)):\n    arg_list, grad_list = pair\n    if grad_list[0] is None:\n        continue\n    # push back the weights\n    kvstore.push(index, arg_list, priority=-index)\n    # pull center variables into gradient, priority is negative index\n    kvstore.pull(index, grad_list, priority=-index)\n    for p in zip(arg_list, grad_list):\n        w, g = p\n         w -= alpha * (w-g)`\n```\n\n  """""" Perform update of param_arrays  not on kvstore.""""""\ndef _update_params(param_arrays, grad_arrays, updater, num_device,\n                   kvstore=None):\n\n` for index, pair in enumerate(zip(param_arrays, grad_arrays)):\n\n```\n    arg_list, grad_list = pair\n    if grad_list[0] is None:\n        continue\n    for k, p in enumerate(zip(arg_list, grad_list)):\n        # faked an index here, to make optimizer create diff\n        # state for the same index but on diff devs, TODO(mli)\n        # use a better solution latter\n        w, g = p\n        updater(index*num_device+k, g, w)`\n```\n\nIn the main iter loop I do:\n\n`\n           _update_params_on_kvstore(executor_manager.param_arrays,\n                                          executor_manager.grad_arrays,\n                                          kvstore)\n                executor_manager.forward(is_train=True)\n                executor_manager.backward()\n                _update_params(executor_manager.param_arrays,\n                              executor_manager.grad_arrays,\n                              updater=updater,\n                              num_device=len(ctx),\n                              kvstore=kvstore)\n`\n', ""I'm interested in EA-SGD also.  What work is left to be done here, and where is the latest code for this?"", 'Close it now. Feel free to reopen it.', ""@sxjscience Why did you close this?  I don't see a PR to support EA-SGD.  I understand that there is sample code posted here in this github issue.  But that's extremely difficult to use for most people.  I think it should be supported as a first-class algorithm in MXNet."", ""@leopd I've closed it because this issue has been inactive for more than 9 months. For now let me reopen it and see if people are interested in supporting EASGD."", '@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', ""This is a feature request. \r\n\r\nIMHO it's a feature we should add to mxnet. "", '@sxjscience The EASGD algorithm is not supported in the released versions of MXNet, and I want to implement that in MXNet to check the performance improvement, any suggestion or help. Thank you very much.']",[],[],0,0
215,incubator-mxnet,16515,open,"MXNet C++Interface, run image-classification-predict.cc example cannot exits normally","When I run the MXNet C++Interface example [image-classification-predict.cc](https://github.com/apache/incubator-mxnet/blob/master/example/image-classification/predict-cpp/image-classification-predict.cc) in windows7 with visual studio 14 2015, it cannot exits normally.

If I comment the mxnet predictor free api , then it exit successfully.


",C++ Pending Requester Info Windows,['Can you describe the error in more detail?'],[],['MXPredFree(pred_hnd);'],0,0
216,incubator-mxnet,11654,open,CI Problem: Build status not reflected on PR,"For #11631, the build is passing: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-11631/8/pipeline, but the status of the PR is not updated.
![screen shot 2018-07-11 at 2 16 43 pm](https://user-images.githubusercontent.com/11465736/42599755-20d30ab4-8515-11e8-903c-d92e93eab429.png)
",Bug CI,"['Suggested labels: CI, Bug', 'Same here https://github.com/apache/incubator-mxnet/pull/11658', '@lebeg @kellensunderland @larroy', '#11626', 'Looks like our Jenkins master is having some issues.  Working on a quick fix.', ""I believe we've addressed the root cause of the issue (a volume low on space).  I'm monitoring builds to make sure they're working properly.  You may see rebuilds being retriggered for the next 1h or so.  I'll post back if I think the issue is resolved."", 'After monitoring for a few hours I think the CI is back to normal.  Please feel free to ping if you see any other issues.', 'Seems like it has been normal for a while, closing this.', 'Hello @KellenSunderland this issue comes again for my [PR](https://github.com/apache/incubator-mxnet/pull/13687). Can you take a look?\r\n![screen shot 2018-12-20 at 10 35 11 am](https://user-images.githubusercontent.com/40650949/50303824-1b5e5e00-0443-11e9-9f94-8155a26baa40.png)\r\n![screen shot 2018-12-20 at 10 35 22 am](https://user-images.githubusercontent.com/40650949/50303828-1f8a7b80-0443-11e9-94a3-d7b835c14392.png)\r\n', 'Re-opening the issue for tracking purpose, @marcoabreu @lebeg @larroy Can you guys please take a look at this issue?', 'We had a look. Will require changes to the GitHub plugging in Jenkins. @jlcontreras', 'I believe this is due to the github plugin sometimes not being able to resolve the repo\'s url, as we get this in the logs:\r\n\r\n`[Set GitHub commit status (universal)] SUCCESS on repos [] (sha:90a0bd0) with context:ci/jenkins/mxnet-validation/windows-gpu`\r\n\r\ninstead of the usual\r\n\r\n```\r\n[Set GitHub commit status (universal)] SUCCESS on repos [GHRepository@4c52e2d2[description=Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Scala, Go, Javascript and more,homepage=https://mxnet.apache.org,name=incubator-mxnet,fork=false,size=50318,milestones={},language=C++,commits={},source=<null>,parent=<null>,responseHeaderFields={null=[HTTP/1.1 200 OK], Access-Control-Allow-Origin=[*], Access-Control-Expose-Headers=[ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type], Cache-Control=[private, max-age=60, s-maxage=60], Content-Encoding=[gzip], Content-Security-Policy=[default-src \'none\'], Content-Type=[application/json; charset=utf-8], Date=[Tue, 11 Dec 2018 03:32:57 GMT], ETag=[W/""764bedf31b7dffddb84955393efdd67a""], Last-Modified=[Tue, 11 Dec 2018 03:21:56 GMT], OkHttp-Received-Millis=[1544499177176], OkHttp-Response-Source=[CACHE 200], OkHttp-Selected-Protocol=[http/1.1], OkHttp-Sent-Millis=[1544499176983], Referrer-Policy=[origin-when-cross-origin, strict-origin-when-cross-origin], Server=[GitHub.com], Status=[200 OK], Strict-Transport-Security=[max-age=31536000; includeSubdomains; preload], Transfer-Encoding=[chunked], Vary=[Accept, Authorization, Cookie, X-GitHub-OTP, Accept-Encoding], X-Accepted-OAuth-Scopes=[repo], X-Content-Type-Options=[nosniff], X-Frame-Options=[deny], X-GitHub-Media-Type=[github.v3; format=json], X-GitHub-Request-Id=[A5E6:0A07:CD38A9:10E7E9B:5C0F2FE8], X-OAuth-Scopes=[repo:status], X-RateLimit-Limit=[5000], X-RateLimit-Remaining=[4667], X-RateLimit-Reset=[1544499459], X-XSS-Protection=[1; mode=block]},url=https://api.github.com/repos/apache/incubator-mxnet,id=34864402]] (sha:229b8fb) with context:ci/jenkins/mxnet-validation/unix-gpu\r\nSetting commit status on GitHub for https://github.com/apache/incubator-mxnet/commit/229b8fb732fdbdc96f2dec27815b332d6b856dda\r\n```\r\n\r\nI\'m currently testing this modification to the plugin to add a retry mechanism, will post updates\r\n\r\nhttps://github.com/jenkinsci/github-plugin/compare/stable-1.29.x...jlcontreras:stable-1.29.x', '@jlcontreras Were you able to push a fix on the Jenkinsci repo for this ? \r\n\r\nPlease feel free to close the issue if this is fixed. I believe the right place to track this issue would be the jenkinsci repository, rather than MXNet repository. \r\nWDYT ? ', 'Makes sense to move the discussion there, we are still unsure about how to fix it.', '@marcoabreu Can you close this issue if this does not happen anymore ? Or if the issue has been moved to JenkinsCI Git Repo, can you close this and backlink this issue there ? ', 'It still happens all the time. Please consider use more reliable DNS.']",[],[],0,0
217,incubator-mxnet,11462,open,throughput of sparse linear classification is small with small batch size,"## Description
For small batch, sparse linear classification uses all CPU, but throughput is small. 


## Environment info (Required)
Machine used: AWS AMI, c5.9xlarge,
steps to repro:
1. pip2 install mxnet-mkl
2. git clone mxnet
3. in directory , run 

We see throughput is around 600 samples/sec. I tried to set up things like . It seems that after setting this, the CPU usage reduces (only half of the cores are used), but the throughput is not reduced. This is even the case when I setting . 


## Question
How should I set things up to increase the throughput of the linear classfication training for a single machine with multiple cores? Or does MXNet currently not optimize in this direction (i.e. not using things like Hogwild!). Thanks in advance. 

with @lcytzk
",Performance Sparse,"['Hi @jiajinyu, thanks for question. @sandeep-krishnamurthy requesting this be labeled under Question.', '@jiajinyu it seems that indeed for small batch-size the CPU is doing a lot of work but it results in a small throughput.\r\n\r\nI ran with your example, and I see all my cores being used and only ~400 images/sec throughput.\r\n\r\nHowever when I increase the batch-size to 128 I see ~50k throughput, almost a linear scale-up.\r\n```\r\n2018-07-05 22:27:54,570 Epoch[0] Batch [3400]\tSpeed: 50624.32 samples/sec\tnll-loss=0.402102\r\n2018-07-05 22:27:54,819 Epoch[0] Batch [3500]\tSpeed: 51431.02 samples/sec\tnll-loss=0.401584\r\n2018-07-05 22:27:55,081 Epoch[0] Batch [3600]\tSpeed: 48777.71 samples/sec\tnll-loss=0.399383\r\n```\r\n\r\nI am not an expert in MKL-DNN or the sparse API, maybe @eric-haibin-lin or @zheng-da can shine a bit more light on the issue but I would say based on this experiment that MKLDNN parallelize a lot of operations at the batch-level, which means whether you run a batch of size 1 or a batch of size 128, it is going to take the same amount of time. So the best way to increase throughput is to increase your batch-size.', 'The sparse dot op is parallelized over batch dimension, not optimized for single batch inference. Adding label ""performance"" ']",[],"['incubator-mxnet/example/sparse/linear_classification', 'python2 train.py --batch-size 1', 'export OMP_NUM_THREADS=vCPUs / 2', 'OMP_NUM_THREADS=1']",0,0
218,incubator-mxnet,4449,closed,Error occured when runing rnn_cell_demo.py with yajiedesign mxnet release,"Environment info

Operating System: Win7 64

Compiler: VS 2013 12.0.3 Update 4

3rd Library : cudnn 4, openblas, opencv2, cuda 7.5

MXNet version: yajiedesign GPU release: 2016-12-29,2016-11-25,2016-09-09

Python version and distribution: Anaconda python 2.7.11

Error info:
mxnet.base.MXNetError: [15:45:06] D:/Program Files (x86)/Jenkins/workspace/mxnet
/mxnet/src/operator/rnn.cu:24: RNN is only available for cuDNN at the moment.

Description:

1. CNN module can be run quickly and produce good results with GPU. cudnn has been put into C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5. I think cudnn is OK

2. run rnn_cell_demo.py, error shows : 
mxnet.base.MXNetError: [15:45:06] D:/Program Files (x86)/Jenkins/workspace/mxnet
/mxnet/src/operator/rnn.cu:24: RNN is only available for cuDNN at the moment.

3. I  change many many prebuilt yajiedesign  version, error occurs still.

In addition, I would appreciate that RNN corresponding models and symbols, such like codes in bucket_io.py, can be programmed into standard mxnet library and more easily to use. It means,  just compose several existed symbol, then  I  can wrap input samples, labels and  get complete char-RNN model  or speech rnn model.

An ideal assumption:
data = mx.sym.SequenceVariable(name='data',bucket=[5,10,15])
...
rnn = mx.sym.RNN(name='rnn',data=...,num_filter=...)",,"['i will check', 'rnn.cu only work with cudnn5 .but prebuild vc12 is cudnn4.\r\nyou can use vc14 prebuild. it cudnn5.\r\nand i am update vc12 pebulid cudnn4 to cudnn5 one hour ago.now it building, you can wait it build and upload finish.If everything goes well. This takes 1 to 2 hours\r\n@artzers ', 'e..i have some problem.please wait.', 'sorry for later,you can download and test now\r\n@artzers ', 'I see that the mxnet version is 0.9.1. In past when training CNN, the GPU load is about 25%~40%, now the GPU load is 70%, but the training and prediction speed seems much lower than 2016-11-25 version. Later I will try RNN', 'hello @yajiedesign , error occured when run rnn_cell_demo.py:\r\nCheck failed: e == cudaSuccess || e == cudaErrorCudartUnloading CUDA: invalid device ordinal\r\n\r\nHowever, I run cuda deviceQueryDrv.exe, get normal information, why?\r\n\r\nCUDA Device Query (Driver API) statically linked version\r\nDetected 1 CUDA Capable device(s)\r\n\r\nDevice 0: ""GeForce GTX TITAN X""\r\n  CUDA Driver Version:                           7.5\r\n  CUDA Capability Major/Minor version number:    5.2\r\n  Total amount of global memory:                 12288 MBytes (12884901888 bytes\r\n)\r\n  (24) Multiprocessors, (128) CUDA Cores/MP:     3072 CUDA Cores\r\n  GPU Max Clock rate:                            1076 MHz (1.08 GHz)\r\n  Memory Clock rate:                             3505 Mhz\r\n  Memory Bus Width:                              384-bit\r\n  L2 Cache Size:                                 3145728 bytes\r\n  Max Texture Dimension Sizes                    1D=(65536) 2D=(65536, 65536) 3D\r\n=(4096, 4096, 4096)\r\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\r\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\r\n  Total amount of constant memory:               65536 bytes\r\n  Total amount of shared memory per block:       49152 bytes\r\n  Total number of registers available per block: 65536\r\n  Warp size:                                     32\r\n  Maximum number of threads per multiprocessor:  2048\r\n  Maximum number of threads per block:           1024\r\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\r\n  Max dimension size of a grid size (x,y,z):    (2147483647, 65535, 65535)\r\n  Texture alignment:                             512 bytes\r\n  Maximum memory pitch:                          2147483647 bytes\r\n  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)\r\n  Run time limit on kernels:                     Yes\r\n  Integrated GPU sharing Host Memory:            No\r\n  Support host page-locked memory mapping:       Yes\r\n  Concurrent kernel execution:                   Yes\r\n  Alignment requirement for Surfaces:            Yes\r\n  Device has ECC support:                        Disabled\r\n  CUDA Device Driver Mode (TCC or WDDM):         WDDM (Windows Display Driver Mo\r\ndel)\r\n  Device supports Unified Addressing (UVA):      Yes\r\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\r\n  Compute Mode:\r\n     < Default (multiple host threads can use ::cudaSetDevice() with device simu\r\nltaneously) >\r\nResult = PASS\r\n', ""@yajiedesign I meet similar issue `RNN is only available for cuDNN at the moment.`, but I've set the config cuDNN = 1 in `config.mk` and I can complete the installation."", '@zihaolucky do you set USE_CUDA=1?', ""@yajiedesign yes. I've try to print the cuda and cudnn version, seems I have to upgrade them. I use cuda7.5"", '@zihaolucky cudnn must >=5', '@yajiedesign yep, thank you.', '@yajiedesign can I use cuda7.5 but cudnn>5?', 'After I upgrade the cudnn, I met \r\n\r\n```\r\nCheck failed: err == CUDNN_STATUS_SUCCESS (1 vs. 0) CUDNN_STATUS_NOT_INITIALIZED\r\n```', '@zihaolucky update you gpu driver.', 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!\nAlso, do please check out our [forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) for general ""how-to"" questions.']",[],[],0,0
219,incubator-mxnet,3685,closed,"Cannot train on multiple nodes, because port blocked by firewall","I followed the tutorial http://mxnet.io/how_to/multi_devices.html#distributed-training-with-multiple-machines to try to train example/image-classification/train_mnist.py. I failed with launcher mpi and ssh. I can successfully run the script it never trains nor does it report any error. It just stuck there until I kill it manually.
I set environment variables on all of the nodes:
export DMLC_INTERFACE=em3
export PS_VERBOSE=2

hosts:
158.1xx.x.80
158.1xx.x.81

SSH:
While the script is running, training processes are distributed to remover servers... Nothing happens afterwards. 
$ ../../tools/launch.py --launcher ssh -n 2 -s 1 -H hosts  python train_mnist.py --network lenet --gpus 0,1,2,3 --kv-store dist_sync
[17:16:55] src/van.cc:69: Bind to role=scheduler, id=1, ip=158.1xx.x.80, port=9091, is_recovery=0
[17:17:00] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=server, ip=158.1xx.x.80, port=50368, is_recovery=0 } }
[17:17:00] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=worker, ip=158.1xx.x.80, port=51877, is_recovery=0 } }
Killed by signal 2.
Killed by signal 2.
Killed by signal 2.
2016-11-01 17:22:15,238 INFO Stop luancher

Then I try to increase the number of worker:
$ ../../tools/launch.py --launcher ssh -n 4 -s 1 -H hosts  python train_mnist.py --network lenet --gpus 0,1,2,3 --kv-store dist_sync
[17:25:19] src/van.cc:69: Bind to role=scheduler, id=1, ip=158.1xx.x.80, port=9092, is_recovery=0
[17:25:24] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=worker, ip=158.1xx.x.80, port=36202, is_recovery=0 } }
[17:25:29] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=server, ip=158.1xx.x.80, port=52936, is_recovery=0 } }
[17:25:29] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=worker, ip=158.1xx.x.80, port=45130, is_recovery=0 } }
Killed by signal 2.
Killed by signal 2.
Killed by signal 2.
Killed by signal 2.
Killed by signal 2.
2016-11-01 17:28:41,265 INFO Stop luancher
I find that all roles are assigned to 158.1xx.x.80 only, is it normal?

MPI(Open MPI 1.10.1):
Training processes can't even launch at remote server... 
$../../tools/launch.py --launcher mpi -n 4 -s 1 -H hosts python train_mnist.py --network lenet --gpus 0,1,2,3 --kv-store dist_sync
2016-11-01 17:35:05,797 INFO Start 4 workers by mpirun
[17:35:06] src/van.cc:69: Bind to role=scheduler, id=1, ip=158.182.9.80, port=9091, is_recovery=0
2016-11-01 17:49:08,476 INFO Stop luancher

I've tested other MPI applications, they work fine. MPI bandwidth test can reach up to 105.93MB/sec.

Am I missing anything that makes training on multiple nodes fail? Please help. The document gives little info about this situation. Thanks in advance!
",,"['how long did you wait before killing it?\n', 'Few minutes to half an hour...\n', 'export DMLC_INTERFACE=em3; ../../tools/launch.py --launcher ssh -n 4 -s 1 -H hosts  python train_mnist.py --network lenet --gpus 0,1,2,3 --kv-store dist_sync\n[10:23:14] src/van.cc:69: Bind to role=scheduler, id=1, ip=158.1xx.x.80, port=9091, is_recovery=0\n[10:23:19] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=server, ip=158.1xx.x.80, port=34160, is_recovery=0 } }\n[10:23:24] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=worker, ip=158.1xx.x.80, port=57697, is_recovery=0 } }\n[10:23:24] src/van.cc:155: ? => 1. Meta: request=0, timestamp=0, control={ cmd=ADD_NODE, node={ role=worker, ip=158.1xx.x.80, port=55234, is_recovery=0 } }\nKilled by signal 2.\nKilled by signal 2.\nKilled by signal 2.\nKilled by signal 2.\nKilled by signal 2.\n2016-11-02 12:23:42,985 INFO Stop luancher\n\n2 hours\n', 'it looks like these ports are blocked by firewall\n', 'Yeah, I confirmed that with the admin.\nHow can I change the port number then...\n', '@mli I tried to set the environment variable DMLC_PS_ROOT_PORT to the port that our admin opened mxnet still uses 909x :\n$ export PS_VERBOSE=2; export DMLC_PS_ROOT_PORT=5901; export DMLC_INTERFACE=em3; ../../tools/launch.py --launcher ssh -n 4 -s 1 -H hosts  python train_mnist.py --network lenet --gpus 0,1,2,3 --kv-store dist_sync\n[15:17:03] src/van.cc:69: Bind to role=scheduler, id=1, ip=158.1xx.x.80, port=9092, is_recovery=0\n', 'I finally get it run on our servers. I end up with changing the port number in the script and source code.\nHere are the changes:\nmxnet/dmlc-core/tracker/dmlc_tracker/tracker.py \n                    change the default port number in class RabitTracker\n                    change the default port number in class PSTracker\nHard-code the port number in function\n                    ps-lite/src/network_utils.h: int GetAvailablePort()\n', 'I suggest to limit the port range rather than hard code a particular number\nOn Thu, Nov 3, 2016 at 1:35 AM XU Pengfei notifications@github.com wrote:\n\n> Closed #3685 https://github.com/dmlc/mxnet/issues/3685.\n> \n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/dmlc/mxnet/issues/3685#event-846043630, or mute the\n> thread\n> https://github.com/notifications/unsubscribe-auth/AAZv4SP_SIMoL5h9TyiBjyk9T7Lq9Ya1ks5q6ZzPgaJpZM4Kl8w4\n> .\n', '@mli how to limit the port range....']",[],[],0,0
220,incubator-mxnet,8741,closed,Inference with openblas and Ubuntu 14.04 hangs on C5 instances.,"## Description
The default install of MXNet currently hangs when running most types of inference with a particular setup on C5 instances.  Any setup that has the openblas library that is, for example, installed with Ubuntu 14.04 will have this issue.  This issue may be effecting all hardware with Skylake architecture, but it is deterministically failing on C5s.

## Environment info (Required)
Ubuntu 14.04

## Steps to Reproduce:
Launch a C5 instance type with Docker support.
Build the following Dockerfile:


Package used (Python/R/Scala/Julia):
Perl for the test.  Also verified it fails with the same stack in Python.

MXNet commit hash:
fd45517614842bfa1d32d1ba54a200eb4a0dd377

## Error Message:
Only one frame with symbols on the stack:


## What have you tried to solve it?

1.   New builds of openblas fix the issue.
2.  Copying openblas build that ships with Ubuntu 16.04 fixes the issue.

## TODOs:
*  Test to see if this effects all skylake and new CPUs.
*  Contact openblas and attempt to get a fix.
*  Create a minimum reproducible example that calls openblas directly (bypass mxnet code) and pass the MRT to openblas.
*  Modify our internal docker images to use Ubuntu 16.04 as a default base.",BLAS Bug Ubuntu,"['> New builds of openblas fix the issue.\r\n\r\nWhich version of openblas?', ""I've seen similar issues before. We should keep track of a list of openblas versions that work with MXNet"", '@bhavinthaker ', 'openblas has plan to release 0.3.0 around December of this year (see xianyi/OpenBLAS#1245)', ""We've verified it works with version 0.2.18 (the version shipped by default in Ubuntu 16.04).  The version shipped in Ubuntu 14.04 is 0.2.8."", ""Thanks. pip version is currently shipped with 0.2.20 which has skylake support. I will check if there's any issue."", 'proposed labels: ""Bug"", ""Ubuntu"", ""BLAS""', 'Is this still an issue?', ""Looping back on this, it seems openblas on 14.04 is no longer supported.  I think this should remain closed / don't fix.  Enjoy Ubuntu 16.04 and up folks :-).  https://github.com/xianyi/OpenBLAS/issues/1669#event-1729620315""]","['Dockerfile\r\n# -*- mode: dockerfile -*-\r\nFROM ubuntu:14.04\r\nRUN apt-get update && apt-get install -y build-essential git libopenblas-dev liblapack-dev \\\r\n    libopencv-dev libcurl4-openssl-dev libgtest-dev cmake wget unzip\r\nRUN cd /usr/src/gtest && cmake CMakeLists.txt && make && cp *.a /usr/lib\r\nRUN git clone --recursive https://github.com/dmlc/mxnet\r\nRUN ln -s /usr/lib/libopenblas.so /usr/lib/libcblas.so\r\nRUN cd mxnet && make USE_OPENCV=0 USE_CUDA=0 USE_CUDNN=0 -j$(nproc)\r\nRUN apt-get update && apt-get install -y libmouse-perl pdl cpanminus swig libgraphviz-perl\r\nRUN cpanm -q Function::Parameters Hash::Ordered\r\nRUN cd mxnet && ./perl-package/test.sh\r\n', '\r\n#0  0x00002b260530cc93 in sgemm_kernel_PRESCOTT () from /usr/lib/libopenblas.so.0\r\n']",[],0,0
221,incubator-mxnet,9193,closed,How to use nccl kvstore,"I build mxnet with use_nccl=1 and USE_NCCL_PATH = /usr/local/lib
The version of mnxet is 1.0
The version of nccl is 1.3.4
The file in /usr/local/lib is 


When I run test_nccl.py, it seems stop at multi gpus tests.
I set NCCL_DEBUG=INFO, the output is below. And the program seems stop at here and won't going on.

The usage of gpu was like below.
",,"['@ptrendx ', '@solin319 Could you try NCCL 2? NCCL 1 is no longer under  active development and could contain bugs.', 'Thanks, NCCL2 worked', ""I use nccl 2  to train on the 8 gpus,  but it was slower than kvstore='device', can you tell the reason? thank you. ""]","['\r\nlrwxrwxrwx. 1 root root       12 Dec 25 14:45 libnccl.so -> libnccl.so.1\r\nlrwxrwxrwx. 1 root root       16 Dec 25 14:45 libnccl.so.1 -> libnccl.so.1.3.4\r\n-rwxr-xr-x. 1 root root 55396794 Dec 25 14:45 libnccl.so.1.3.4\r\n', ""\r\nINFO NCCL debug level set to INFO\r\nNCCL version 1.3.4 compiled with CUDA 8.0\r\nINFO rank 0 using buffSize = 2097152\r\nINFO rank 0 using device 0 (0000:06:00.0)\r\nINFO rank 1 using buffSize = 2097152\r\nINFO rank 1 using device 1 (0000:07:00.0)\r\nINFO rank access 0 -> 0 via common device\r\nINFO rank access 0 -> 1 via P2P device mem\r\nINFO rank access 1 -> 0 via P2P device mem\r\nINFO rank access 1 -> 1 via common device\r\nINFO Global device memory space is enabled\r\nWARN src/reduce.cu:126 Cuda failure 'invalid resource handle'\r\n\r\n"", '\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           On   | 0000:06:00.0     Off |                    0 |\r\n| N/A   75C    P0    77W / 149W |    163MiB / 11439MiB |    100%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K80           On   | 0000:07:00.0     Off |                    0 |\r\n| N/A   50C    P0    72W / 149W |    162MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla K80           On   | 0000:85:00.0     Off |                    0 |\r\n| N/A   42C    P8    27W / 149W |      2MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla K80           On   | 0000:86:00.0     Off |                    0 |\r\n| N/A   35C    P8    31W / 149W |      2MiB / 11439MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0      5571    C   python                                         161MiB |\r\n|    1      5571    C   python                                         160MiB |\r\n+-----------------------------------------------------------------------------+\r\n']",[],0,0
222,incubator-mxnet,2192,closed,does mx.sym.sum take batch size into account ?,"Hello I wanted to do something with mx.sym.sum.

I have 2 outputs that I want to diff and sum.
leg1 and leg2 are outputs of FullyConnected
minibatch size = 128



How can I tell the sum symbol to take into account to sum per row instead of summing the whole matrix ?
",,"['it sums over the entire tensor, including the batch dimension\n', ""Hello, is there an alternative ? \nI'm trying to compose various layers by low-level primitives. Sum seems to be indispensible.\nThe only thing I can come up with now is a FullyConnectedLayer with weights fixed at 1.\nBut that seems to be overkill.\n"", 'Or could I do Reshape to (128, Layeroutput, 1)\nAnd then do sum_mid_internal and after that a reshape to 128, 1\n\nStill a bit cumbersome but this might work.\n', 'FYI \n\n```\nReshape to (128, Layeroutput, 1)\nsum_mid_internal\nReshape to (128, 1)\n```\n\nWorked.\nNot ideal but manageble\n', 'We should work out a solution for sum with axis argument. Please stay tuned\nOn Fri, May 20, 2016 at 4:23 AM Julian de Wit notifications@github.com\nwrote:\n\n> FYI\n> \n> Reshape to (128, Layeroutput, 1)\n> sum_mid_internal\n> Reshape to (128, 1)\n> \n> Worked.\n> Not ideal but manageble\n> \n> —\n> You are receiving this because you modified the open/close state.\n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/dmlc/mxnet/issues/2192#issuecomment-220581146\n']","['\ndiff1 = mx.sym.sum(mx.sym.square(leg1 - leg2))\nshape of diff1 returns a shape of 1 instead of 128,1 \n']",[],0,0
223,incubator-mxnet,13664,closed,Dj,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
(Brief description of the problem in no more than 2 sentences.)

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.
",,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n ', 'No info provided. Closing for now. Feel free to update the description and reopen.']",[],"['', '\r\nWhat to do:\r\n1. Download the diagnosis script from https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/diagnose.py\r\n2. Run the script using ', ' and paste its output here.\r\n\r\n', '', 'java -version', 'mvn -version', 'scala -version', 'sessionInfo()', 'git rev-parse HEAD']",0,0
224,incubator-mxnet,4224,closed,cudaMalloc failed: out of memory,"## Environment info
Operating System:  ubuntu14.04

Compiler:  gcc4.8.4

Package used (Python/R/Scala/Julia):Python

MXNet version:  0.7.0

Or if installed from source:  yes

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:   2.7.6

If you are using R package, please provide

R :

## Error Message:

faster rcnn train error when I python train_end2end.py

I have downsize the VOC2007 train sets to1096 images,my 980 have 4G MEMORY, but it still report out of memory, I want to know how to solve this problem.Thank you!

yx@yx-X8DTL:~/mxnet/example/mx-rcnn-master$ python train_end2end.pyCalled with argument: Namespace(begin_epoch=0, dataset='PascalVOC', dataset_path='data/VOCdevkit', end_epoch=10, epoch=1, flip=True, frequent=20, gpus='0', image_set='2007_trainval', kvstore='device', lr=0.001, lr_step=50000, network='vgg', prefix='model/e2e', pretrained='model/vgg16', resume=False, root_path='data', work_load_list=None)
{'EPS': 1e-14,
'IMAGE_STRIDE': 0,
'PIXEL_MEANS': array([[[ 123.68 , 116.779, 103.939]]]),
'SCALES': [(600, 1000)],
'TEST': {'BATCH_IMAGES': 1,
'HAS_RPN': False,
'NMS': 0.3,
'RPN_MIN_SIZE': 16,
'RPN_NMS_THRESH': 0.7,
'RPN_POST_NMS_TOP_N': 300,
'RPN_PRE_NMS_TOP_N': 6000},
'TRAIN': {'BATCH_IMAGES': 1,
'BATCH_ROIS': 128,
'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
'BBOX_NORMALIZATION_PRECOMPUTED': True,
'BBOX_REGRESSION_THRESH': 0.5,
'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
'BBOX_WEIGHTS': array([ 1., 1., 1., 1.]),
'BG_THRESH_HI': 0.5,
'BG_THRESH_LO': 0.0,
'END2END': True,
'FG_FRACTION': 0.25,
'FG_THRESH': 0.5,
'RPN_BATCH_SIZE': 256,
'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
'RPN_CLOBBER_POSITIVES': False,
'RPN_FG_FRACTION': 0.5,
'RPN_MIN_SIZE': 16,
'RPN_NEGATIVE_OVERLAP': 0.3,
'RPN_NMS_THRESH': 0.7,
'RPN_POSITIVE_OVERLAP': 0.7,
'RPN_POSITIVE_WEIGHT': -1.0,
'RPN_POST_NMS_TOP_N': 6000,
'RPN_PRE_NMS_TOP_N': 12000}}
num_images 1096
voc_2007_trainval gt roidb loaded from data/cache/voc_2007_trainval_gt_roidb.pkl
append flipped images to roidb
[20:41:11] src/engine/engine.cc:36: MXNet start using engine: NaiveEngine
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
'blockgrad0_output': (1L, 128L),
'cls_prob_reshape_output': (1L, 128L, 21L),
'rpn_bbox_loss_output': (1L, 36L, 37L, 50L),
'rpn_cls_prob_output': (1L, 2L, 333L, 50L)}
[20:41:15] /home/yx/mxnet/dmlc-core/include/dmlc/./logging.h:235: [20:41:15] src/storage/./pooled_storage_manager.h:79: cudaMalloc failed: out of memory
Traceback (most recent call last):
File ""train_end2end.py"", line 185, in 
main()
File ""train_end2end.py"", line 182, in main
lr=args.lr, lr_step=args.lr_step)
File ""train_end2end.py"", line 133, in train_net
arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/module/base_module.py"", line 379, in fit
self.update()
File ""/home/yx/mxnet/example/mx-rcnn-master/rcnn/core/module.py"", line 183, in update
self._curr_module.update()
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/module/module.py"", line 419, in update
kvstore=self._kvstore)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/model.py"", line 115, in _update_params
updater(index*num_device+k, g, w)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/optimizer.py"", line 822, in updater
optimizer.update(index, weight, grad, states[index])
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/optimizer.py"", line 298, in update
grad = grad * self.rescale_grad
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/ndarray.py"", line 138, in mul
return multiply(self, other)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/ndarray.py"", line 744, in multiply
None)
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/ndarray.py"", line 655, in _ufunc_helper
return lfn_scalar(lhs, float(rhs))
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/ndarray.py"", line 1263, in generic_ndarray_function
c_array(ctypes.c_char_p, [c_str(str(i)) for i in kwargs.values()])))
File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/base.py"", line 77, in check_call
raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [20:41:15] src/storage/./pooled_storage_manager.h:79: cudaMalloc failed: out of memory
terminate called without an active exception
已放弃 (核心已转储)
## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.python train_end2end.py
2.
3.

## What have you tried to solve it?

1.Downsize the train sets, but the same error still occur.
2.
3.
",,"['4GB is too small. try a smaller batch size or get a bigger gpu with 12g ram', 'try `export MXNET_BACKWARD_DO_MIRROR=1; python xxx` ?', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!', '@yajiedesign I still met this problem', '@espectre I have this problem too, so have you solved it?']",[],"['git rev-parse HEAD', 'sessionInfo()']",0,0
225,incubator-mxnet,15254,closed,mxnet(mxnet-full_2.11-linux-x86_64-gpu-1.5.0-SNAPSHOT) cannot support cuda10.1?,"# mxnet(mxnet-full_2.11-linux-x86_64-gpu-1.5.0-SNAPSHOT) cannot support cuda10.1?
> i'm used  maven packages and check it

## ENV
* Java version:


* Maven version:


* cuda version:


* nvidia version:


* os:


## Check and Test


* for errors:  ?:


* for my compute:
",CUDA Installation Scala,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Installation', '@mxnet-label-bot add [Installation, Scala, Cuda]', '**Thank you all. I lowered the CUDA version(9.2), and now it\'s OK. \r\nBut my code can\'t use GPU. Do you have any suggestions?**\r\n\r\n```java\r\n@Test\r\npublic void testGPU(){\r\n     System.out.println(System.getenv().containsKey(""SCALA_TEST_ON_GPU""));\r\n}\r\n\r\n //  result is false.\r\n```', '> **Thank you all. I lowered the CUDA version(9.2), and now it\'s OK. But my code can\'t use GPU. Do you have any suggestions?**\r\n> \r\n> ```java\r\n> @Test\r\n> public void testGPU(){\r\n>      System.out.println(System.getenv().containsKey(""SCALA_TEST_ON_GPU""));\r\n> }\r\n> \r\n>  //  result is false.\r\n> ```\r\n\r\n@tomoncle This is merely an environment variable that is used for test/debugging purposes. \r\n\r\nIn order to make the package use GPU, you need to set the context to use GPU. \r\n```List<Context> context = new ArrayList<Context>();\r\n      context.add(Context.gpu());\r\n```\r\n\r\nHope that answers your question :) ', '@piyushghai  Thank you very much for your explanation, this has solved my problem.', ""## I'm testing a small example of using mxnet to detect entities and then tag specific locations. The specific processing logic is as follows:\r\n\r\n* 1.  Use OpenCV to read the video of each frame and save it as a picture stream\r\n\r\n* 2.  Then the pictures are processed by mxnet to be pictures with position and object labeled.\r\n\r\n* 3.  Then it is echoed to the screen through opencv.\r\n\r\n\r\n\r\n**Question** :  Processing speed is general, there is no change in the use of GPU. I wonder if there is something wrong with my processing logic. Do you have any good suggestions?\r\n\r\nSample code [click this](https://github.com/tomoncle/mxnet-spring-samples/blob/master/mxnet-spring-samples-camera-detecte/src/main/java/com/tomoncle/mxnet/camera/Application.java)"", ""@tomoncle I had a look at your code processing code. It seems like the OpenCV operations are running on CPU only.\r\nI'm not sure of how to run OpenCV on GPUs though. \r\nMaybe @lanking520 can provide some suggestions here ? "", 'For image preprocessing, you can use your personal processing toolkit. MXNet provide built-in OpenCV image conversion op. For high-performance computing, I recommend to use Java Image toolkit which is considerably supporting multi-threading that can help you get more throughput. ', 'Thank you all so much for your warm support, including many constructive advice.', '@tomoncle I am closing this issue because it seems like all the problems were addressed. Please reopen if there are remaining problems']","['bash\r\njava version ""1.8.0_191""\r\nJava(TM) SE Runtime Environment (build 1.8.0_191-b12)\r\nJava HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)\r\n', 'bash\r\nApache Maven 3.6.1 (d66c9c0b3152b2e69ee9bac180bb8fcc8e6af555; 2019-04-05T03:00:29+08:00)\r\nMaven home: /usr/local/maven\r\nJava version: 1.8.0_191, vendor: Oracle Corporation, runtime: /usr/local/jdk1.8.0_191/jre\r\nDefault locale: zh_CN, platform encoding: UTF-8\r\nOS name: ""linux"", version: ""4.15.0-51-generic"", arch: ""amd64"", family: ""unix""\r\n', 'bash\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2019 NVIDIA Corporation\r\nBuilt on Fri_Feb__8_19:08:17_PST_2019\r\nCuda compilation tools, release 10.1, V10.1.105\r\n', 'bash\r\nSun Jun 16 15:25:08 2019       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 430.09       Driver Version: 430.09       CUDA Version: 10.1     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 166...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n| N/A   45C    P0     3W /  N/A |      0MiB /  5944MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|  No running processes found                                                 |\r\n+-----------------------------------------------------------------------------+\r\n', 'bash\r\nDISTRIB_ID=Ubuntu\r\nDISTRIB_RELEASE=16.04\r\nDISTRIB_CODENAME=xenial\r\nDISTRIB_DESCRIPTION=""Ubuntu 16.04.6 LTS""\r\n', 'java\r\n    @Test\r\n    public void testGPU(){\r\n        System.out.println(System.getenv().containsKey(""SCALA_TEST_ON_GPU""));\r\n    }\r\n    //  result is false.\r\n', 'bash\r\n15:32:05.129 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.infer.MXNetThreadPoolHandler - threadId: 18\r\n15:32:05.150 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] INFO MXNetJVM - Try loading mxnet-scala from native path.\r\n15:32:05.150 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] WARN MXNetJVM - MXNet Scala native library not found in path. Copying native library from the archive. Consider installing the library somewhere in the path (for Windows: PATH, for Linux: LD_LIBRARY_PATH), or specifying by Java cmd option -Djava.library.path=[lib path].\r\n15:32:05.151 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] WARN MXNetJVM - LD_LIBRARY_PATH=/usr/local/cuda-10.1/lib64:\r\n15:32:05.151 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] WARN MXNetJVM - java.library.path=/usr/local/cuda-10.1/lib64::/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib\r\n15:32:05.159 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.util.NativeLibraryLoader - Attempting to load libmxnet-scala.so\r\n15:32:05.160 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.util.NativeLibraryLoader - tempfile.getPath() = /tmp/mxnet7650335975263211746/libmxnet.so\r\n15:32:10.770 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.util.NativeLibraryLoader - Copying libmxnet.so took 5.61 seconds.\r\n15:32:10.771 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.util.NativeLibraryLoader - tempfile.getPath() = /tmp/mxnet7650335975263211746/libgfortran.so.3\r\n15:32:10.776 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.util.NativeLibraryLoader - Copying libgfortran.so.3 took 0.005 seconds.\r\n15:32:10.776 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.util.NativeLibraryLoader - tempfile.getPath() = /tmp/mxnet7650335975263211746/libquadmath.so.0\r\n15:32:10.779 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.util.NativeLibraryLoader - Copying libquadmath.so.0 took 0.002 seconds.\r\n15:32:10.779 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.util.NativeLibraryLoader - tempfile.getPath() = /tmp/mxnet7650335975263211746/libiomp5.so\r\n15:32:10.789 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.util.NativeLibraryLoader - Copying libiomp5.so took 0.01 seconds.\r\n15:32:10.789 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.util.NativeLibraryLoader - tempfile.getPath() = /tmp/mxnet7650335975263211746/libmklml_intel.so\r\n15:32:11.290 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.util.NativeLibraryLoader - Copying libmklml_intel.so took 0.501 seconds.\r\n15:32:11.291 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.util.NativeLibraryLoader - tempfile.getPath() = /tmp/mxnet7650335975263211746/libmkldnn.so.0\r\n15:32:11.341 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.util.NativeLibraryLoader - Copying libmkldnn.so.0 took 0.05 seconds.\r\n15:32:11.342 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.util.NativeLibraryLoader - tempfile.getPath() = /tmp/mxnet7650335975263211746/mxnet-scala\r\n15:32:11.343 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.util.NativeLibraryLoader - Copying mxnet-scala took 0.001 seconds.\r\n15:32:11.343 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] DEBUG org.apache.mxnet.util.NativeLibraryLoader - Loading library from /tmp/mxnet7650335975263211746/mxnet-scala\r\n15:32:11.343 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] ERROR org.apache.mxnet.util.NativeLibraryLoader - Couldn\'t load copied link file: java.lang.UnsatisfiedLinkError: /tmp/mxnet7650335975263211746/mxnet-scala: libcudart.so.9.2: 无法打开共享对象文件: 没有那个文件或目录\r\n15:32:11.343 [org.apache.mxnet.infer.MXNetThreadPoolHandler-0] ERROR MXNetJVM - Couldn\'t find native library mxnet-scala\r\nException in thread ""main"" java.lang.UnsatisfiedLinkError: /tmp/mxnet7650335975263211746/mxnet-scala: libcudart.so.9.2: 无法打开共享对象文件: 没有那个文件或目录\r\n\tat java.lang.ClassLoader$NativeLibrary.load(Native Method)\r\n\tat java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941)\r\n\tat java.lang.ClassLoader.loadLibrary(ClassLoader.java:1824)\r\n\tat java.lang.Runtime.load0(Runtime.java:809)\r\n\tat java.lang.System.load(System.java:1086)\r\n\tat org.apache.mxnet.util.NativeLibraryLoader$.loadLibraryFromFile(NativeLibraryLoader.scala:131)\r\n\tat org.apache.mxnet.util.NativeLibraryLoader$.loadLibrary(NativeLibraryLoader.scala:99)\r\n\tat org.apache.mxnet.Base$.<init>(Base.scala:77)\r\n\tat org.apache.mxnet.Base$.<clinit>(Base.scala)\r\n\tat org.apache.mxnet.Symbol$.initSymbolModule(Symbol.scala:1134)\r\n\tat org.apache.mxnet.Symbol$.<init>(Symbol.scala:925)\r\n\tat org.apache.mxnet.Symbol$.<clinit>(Symbol.scala)\r\n\tat org.apache.mxnet.Model$.loadCheckpoint(Model.scala:70)\r\n\tat org.apache.mxnet.module.Module$.loadCheckpoint(Module.scala:644)\r\n\tat org.apache.mxnet.infer.Predictor$$anonfun$14.apply(Predictor.scala:256)\r\n\tat org.apache.mxnet.infer.Predictor$$anonfun$14.apply(Predictor.scala:256)\r\n\tat org.apache.mxnet.infer.MXNetThreadPoolHandler$$anon$4.call(MXNetHandler.scala:83)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\r\n', '\r\ntomoncle@test:/usr/local/cuda-10.1/lib64$ ls |grep libcuda\r\nlibcudadevrt.a\r\nlibcudart.so\r\nlibcudart.so.10.1\r\nlibcudart.so.10.1.105\r\nlibcudart_static.a\r\n']","['mxnet-full_2.11-linux-x86_64-gpu-1.5.0-SNAPSHOT', 'why find libcudart.so.9.2']",0,0
226,incubator-mxnet,9962,closed,how to group 2 or more outputs in gluon just like sym.Group(),"
for example, I want to group 2 outputs, and then split them in loss, how could I do it?  just return a list can not work, it will encounter error in Loss, since forward need symbol or ndarray
@piiswrong ",,"['I can do it in an ugly way...use F.concat, and then slice it', ""returning a list should work. What's error? note that you need to unpack the list and only feed the output to loss"", 'the error is ""HybridBlock input must be (nested) list of Symbol or NDArray, "" \\\r\n        ""but got %s of type %s""  \r\nI want to pass fc1_norm and output to my custom loss, since my loss need these two, is it possible?', 'You are using imperative code in the hybrid block. Either you need to move it to make it static code (or code with fixed loop) or not hybridize the loss. In the later case, returning as a list and retrieving the proper value from it should work. ', '@orchidmajumder Thanks, get your point']","[' \r\ndef hybrid_forward(self, F, x):\r\n        x = x.astype(np.float32) - 127.5\r\n        x = x * 0.0078125\r\n        fc1 = self.features(x)\r\n        if self.get_feature:\r\n            return fc1\r\n        else:\r\n            # fc1_norm = F.sqrt(F.sum(F.square(fc1), axis=1)).reshape((-1, 1))\r\n            # fc1_normalize = F.broadcast_div(fc1, fc1_norm+1e-6)\r\n            fc1_norm = F.L2Normalization(fc1, mode=""instance"")\r\n            return [fc1_norm,self.output(fc1_norm)]\r\n']",[],0,0
227,incubator-mxnet,15514,closed,dmlc.lib is not generated,"when trying to build latest head, dmlc.dll is being generated, but not dmlc.lib (using ms visual studio 2015). Therefore, building mxnet dll fails with

1>------ Build started: Project: mxnet, Configuration: Release x64 ------
1>LINK : fatal error LNK1181: cannot open input file '3rdparty\dmlc-core\Release\dmlc.lib'",Build,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Build', '@mxnet-label-bot add [build]']",[],[],0,0
228,incubator-mxnet,15201,closed,Add tensorrt and quantization in the docs of the website,"We are referrencing tensorrt and quantization in a few tutorials / blog posts etc though they do not appear under the contrib section of the docs. It would be great to add them.

@aaronmarkham ",Doc Website,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Doc', 'We can contribute to MKLDNN quantization part :)', '@IvyBazan can you please take a look at this?', 'https://mxnet.apache.org/versions/1.6/api/python/docs/api/contrib/index.html, tensorrt and quantization were added to the contrib page. Issue can be closed.']",[],[],0,0
229,incubator-mxnet,14828,closed,TypeError: object of type ‘NoneType’ has no len(),"Hi, please help me
i use im2rec.py
so when i do so
python Downloads/im2rec.py Downloads/test . --center-crop --resize 224 --pack-label

i get the error

opencv@opencv-virtual-machine:~$ python Downloads/im2rec.py Downloads/test . --center-crop --resize 224 --pack-label
Creating .rec file from /home/opencv/Downloads/test/dog.lst in /home/opencv/Downloads/test
multiprocessing not available, fall back to single threaded encoding
imread read blank (None) image for file: /home/opencv/./data/img/h_87.jpg
Traceback (most recent call last):
File “Downloads/im2rec.py”, line 386, in 
record.write_idx(item[0], s)
File “/home/opencv/.local/lib/python2.7/site-packages/mxnet/recordio.py”, line 285, in write_idx
self.write(buf)
File “/home/opencv/.local/lib/python2.7/site-packages/mxnet/recordio.py”, line 135, in write
ctypes.c_size_t(len(buf))))
TypeError: object of type ‘NoneType’ has no len()

What does it mean
here 87.jpg
https://images.guru/i/iPYR",,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Example', 'i found error,  data folder was deleted from root catalog. and it could find my pictures', '@jasperDD Thanks for your Q and A. Could you please close this issue if you are no longer facing the same problem?', 'Closing the issue now since the problem seems to be solved. @jasperDD Please feel free to re-open if you have further questions, thanks!']",[],[],0,0
230,incubator-mxnet,12480,closed,Cannot install mxnet: Could not find a version that satisfies the requirement mxnet,"## Description

When installing mxnet in my python3 virtualenv, I get the following error:



## Environment info (Required)



Package used (Python/R/Scala/Julia):
(I'm using python)

## Error Message:



## Steps to reproduce

1. ",Installation Python,"['Did you try with python3.6?', '@opringleThank you for reporting the issue requesting to try with python 3.6.\r\n\r\n@mxnet-label-bot [Installation, Python]', 'I did not. I am using python 3.7.\n\nOn Fri, Sep 7, 2018, 11:51 Marco de Abreu, <notifications@github.com> wrote:\n\n> Did you try with python3.6?\n>\n> —\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/apache/incubator-mxnet/issues/12480#issuecomment-419532095>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AVKv_sUaKL1AI19SCUwFFYp5x0I40A00ks5uYsAYgaJpZM4WfSVA>\n> .\n>\n', 'I have just tried again with anaconda python 3.6.5 and the issue is resolved. Thank you!']","['\r\n$ pip install mxnet\r\nCollecting mxnet\r\n  Could not find a version that satisfies the requirement mxnet (from versions: )\r\nNo matching distribution found for mxnet\r\n', ""\r\n----------Python Info----------\r\nVersion      : 3.7.0\r\nCompiler     : Clang 9.1.0 (clang-902.0.39.2)\r\nBuild        : ('default', 'Aug 22 2018 15:22:33')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 18.0\r\nDirectory    : /Users/opringle/Envs/gluon/lib/python3.7/site-packages/pip\r\n----------MXNet Info-----------\r\nNo MXNet installed.\r\n----------System Info----------\r\nPlatform     : Darwin-17.7.0-x86_64-i386-64bit\r\nsystem       : Darwin\r\nnode         : Olivers-MacBook-Pro.local\r\nrelease      : 17.7.0\r\nversion      : Darwin Kernel Version 17.7.0: Thu Jun 21 22:53:14 PDT 2018; root:xnu-4570.71.2~1/RELEASE_X86_64\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : i386\r\nb'machdep.cpu.brand_string: Intel(R) Core(TM) i5-7360U CPU @ 2.30GHz'\r\nb'machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C'\r\nb'machdep.cpu.leaf7_features: SMEP ERMS RDWRFSGS TSC_THREAD_OFFSET BMI1 HLE AVX2 BMI2 INVPCID RTM SMAP RDSEED ADX IPT SGX FPU_CSDS MPX CLFSOPT'\r\nb'machdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT PREFETCHW RDTSCP TSCI'\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0966 sec, LOAD: 0.7085 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.1337 sec, LOAD: 0.0826 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.1128 sec, LOAD: 0.0671 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0894 sec, LOAD: 0.0858 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0915 sec, LOAD: 1.4867 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0006 sec, LOAD: 0.0394 sec.\r\n""]","['Could not find a version that satisfies the requirement mxnet (from versions: )\r\nNo matching distribution found for mxnet', '$ pip install mxnet']",0,0
231,incubator-mxnet,9538,closed,How can I reinitialize a key in kvstore?,"I Initialize a key in kvstore.

I want to init key 3 with another shape in a same program. How can I reinitialize this key? Or is there any method to remove this key in kvstore?
",,"['Does MXNet has a interface to remove or re-init a key-value pairs saved in kvstore?\r\n@piiswrong ', 'Hello @solin319 \r\nKVStore does not allow:\r\n1. Remove a key after init\r\n2. Modify shape of a key-value pair after init\r\n\r\nYou can only:\r\n1. Change the value of existing key i.e., push and pull.\r\n2. Add new key even after init.\r\n\r\nPlease feel free to reopen if you need more help.']","[""\r\nkv = mx.kv.create('device') \r\nshape = (2,3)\r\nkv.init(3, mx.nd.ones(shape)*2)\r\n""]",[],0,0
232,incubator-mxnet,207,closed,"Building fail on mac 10.10, ""dynamic module does not define init function""","hi all,

I tried to install on my mac 10.10 to first run a demo on small datasets. I deleted the -fopenmp as suggested in XGBoost. I got the libmxnet.so and libmxnet.a in the lib/ folder. But I still failed to run the example/mnist.py as suggested by the tutorial. It reported ""dynamic module does not define init function"". What should I do next to solve this problem? Do you guys have a tutorial for installing on mac? Thanks a lot
",,"['mxnet works fine on my mbp with max os x 10.10. could you please double check your python version? this error is often due to inconsistent of python version (installed mxnet by one python, while run it by another python) \n', 'Thanks a lot, my python version was 2.7.10 but my g++ version was 4.7. Sorry about that I should check the g++ version before I asked. I change g++ to 4.8 and python to 3.5 and It works now. Really thanks a lot.\n']",[],[],0,0
233,incubator-mxnet,11289,closed,[Nightly Tests] Enable KVStore Single Node Test,"This test is currently disabled since the test requires an instance with 4 GPUs which is not available in the MXNet CI at the moment. 
Adding a new instance type is on the roadmap. ",CI Feature request,"['Thanks for submitting this issue @mbaijal \r\n@sandeep-krishnamurthy could you add label ""CI"", ""Feature"" to this?', '@mbaijal Looks like the PR for enabling the KVStore Test got merged. \r\nCan you close this issue as well ? ']",[],[],0,0
234,incubator-mxnet,2125,closed,TypeError: create() got an unexpected keyword argument 'top_k' ?,"I am using today's github latest commit (up to b5a369384e566490211cfb458bc9936d6c2a5678 ) but I had the following error. Seems like   function is damaged?



gives


",,"['Oops, sorry my bad: I updated the package but forgot to update python pack. After updating the python package, it works. Sorry for confusions.\n']","['\ncd mxnet/example/image-classification\npython train_mnist.py\n', '\n[22:22:51] src/io/iter_mnist.cc:91: MNISTIter: load 60000 images, shuffle=1, shape=(128,784)\n[22:22:52] src/io/iter_mnist.cc:91: MNISTIter: load 10000 images, shuffle=1, shape=(128,784)\nTraceback (most recent call last):\n  File ""train_mnist.py"", line 132, in <module>\n    train_model.fit(args, net, get_iterator(data_shape))\n  File ""/home/liuh/github/mxnet/example/image-classification/train_model.py"", line 85, in fit\n    eval_metrics.append(mx.metric.create(\'top_k_accuracy\', top_k = top_k))\nTypeError: create() got an unexpected keyword argument \'top_k\'\n']","['metric.py', 'create()']",0,0
235,incubator-mxnet,1127,closed,The gpu cores actually in use do not match with what I set in command ,"hi, 

I specific 2 gpus devices in command likes this,  . 
The file train_mnist.py is an example provided with source code.

Then I check the gpus status via command nvidia-smi,

it show likes,
![gpu](https://cloud.githubusercontent.com/assets/4373620/12064726/811420c6-b005-11e5-96fe-6bdaa550d571.png)

Those process name 'python' are issued by the command above.

Someone please help to look into this. 
",,"[""first nvidia-smi and cuda gpu numbering sometimes doesn't match. There is a mapping and you need to figure out your self.\nsecond, could you show your GPU utilization?\n""]",[],"['python train_mnist.py --gpus 3,2']",0,0
236,incubator-mxnet,7970,closed,"MNIST data loader requires Python ""resources"" package to be installed","MNIST data loader fails unless ""resources"" package is manually installed.

Should ""resources"" package be a dependency installed along with mxnet?

## Environment info
Operating System:
Mac OS 10.12.6

Compiler:
Package used (Python/R/Scala/Julia):
Python 3.6.1
[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.42)]

MXNet version:
0.11.0

## Error Message:
Running code in Straight Dope book,  mx.gluon.data.DataLoader fails to download MNIST data set unless python package ""resources"" is manually installed.

See https://github.com/zackchase/mxnet-the-straight-dope/issues/229


",,"['requests will be added as dependencies to pip packages starting tonight.', 'Resolved. Let me know if issue persists.']","['python\r\nbatch_size = 64\r\nnum_inputs = 784\r\nnum_outputs = 10\r\n\r\ndef transform(data, label):\r\n    return data.astype(np.float32)/255, label.astype(np.float32)\r\n\r\ntrain_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=True, transform=transform),\r\n                                      batch_size, shuffle=True)\r\n\r\ntest_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=False, transform=transform),\r\n                              batch_size, shuffle=False)\r\n\r\nDownloading /Users/<myusername>/.mxnet/datasets/train-labels-idx1-ubyte.gz from http://data.mxnet.io/data/mnist/train-labels-idx1-ubyte.gz...\r\n\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-6-aefcd2008d97> in <module>()\r\n      4 def transform(data, label):\r\n      5     return data.astype(np.float32)/255, label.astype(np.float32)\r\n----> 6 train_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=True, transform=transform),\r\n      7                                       batch_size, shuffle=True)\r\n      8 test_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=False, transform=transform),\r\n\r\n/usr/local/lib/python3.6/site-packages/mxnet/gluon/data/vision.py in __init__(self, root, train, transform)\r\n     73     def __init__(self, root=\'~/.mxnet/datasets/\', train=True,\r\n     74                  transform=None):\r\n---> 75         super(MNIST, self).__init__(root, train, transform)\r\n     76 \r\n     77     def _get_data(self):\r\n\r\n/usr/local/lib/python3.6/site-packages/mxnet/gluon/data/vision.py in __init__(self, root, train, transform)\r\n     41         self._label = None\r\n     42 \r\n---> 43         self._get_data()\r\n     44 \r\n     45     def __getitem__(self, idx):\r\n\r\n/usr/local/lib/python3.6/site-packages/mxnet/gluon/data/vision.py in _get_data(self)\r\n     83                                  sha1_hash=\'6c95f4b05d2bf285e1bfb0e7960c31bd3b3f8a7d\')\r\n     84             label_file = download(url+\'train-labels-idx1-ubyte.gz\', self._root,\r\n---> 85                                   sha1_hash=\'2a80914081dc54586dbdf242f9805a6b8d2a15fc\')\r\n     86         else:\r\n     87             data_file = download(url+\'t10k-images-idx3-ubyte.gz\', self._root,\r\n\r\n/usr/local/lib/python3.6/site-packages/mxnet/gluon/utils.py in download(url, path, overwrite, sha1_hash)\r\n    198 \r\n    199         print(\'Downloading %s from %s...\'%(fname, url))\r\n--> 200         r = requests.get(url, stream=True)\r\n    201         if r.status_code != 200:\r\n    202             raise RuntimeError(""Failed downloading url %s""%url)\r\n\r\nAttributeError: type object \'requests_failed_to_import\' has no attribute \'get\'\r\n']",[],0,0
237,incubator-mxnet,6186,closed,cudnn_deconvolution-inl.h,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
ubuntu 12.04
Compiler:
g++-4.8 nvcc
Package used (Python/R/Scala/Julia):

MXNet version:

Or if installed from source:
from source
MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :
src/operator/./cudnn_deconvolution-inl.h(124): error: identifier ""out"" is undefined
 detected during instantiation of ""mxnet::op::CuDNNDeconvolutionOp<DType>::CuDNNDeconvolutionOp(mxnet::op::DeconvolutionParam, int, int, const std::vector<mxnet::TShape, std::allocator<mxnet::TShape>> &, const std::vector<mxnet::TShape, std::allocator<mxnet::TShape>> &, const mxnet::Context &) [with DType=float]"" 
src/operator/deconvolution.cu(47): here

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. make 


## What have you tried to solve it?

1. line 136 out.dptr_  change to out_ptr,  line  258 gwmat.dptr_ also 
then can compile, but I don't know whether it is correct.",,"['Similar issue:\r\n\r\n```\r\n\r\nsrc/operator/./cudnn_deconvolution-inl.h(191): warning: variable ""gwmat_ptr"" was set but never used\r\n          detected during:\r\n            instantiation of ""void mxnet::op::CuDNNDeconvolutionOp<DType>::Backward(const mxnet::OpContext &, const std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob>> &, const std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob>> &, const std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob>> &, const std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType>> &, const std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob>> &, const std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob>> &) [with DType=mshadow::half::half_t]""\r\n(68): here\r\n            instantiation of ""mxnet::op::CuDNNDeconvolutionOp<DType>::CuDNNDeconvolutionOp(mxnet::op::DeconvolutionParam, int, int, const std::vector<nnvm::TShape, std::allocator<nnvm::TShape>> &, const std::vector<nnvm::TShape, std::allocator<nnvm::TShape>> &, const mxnet::Context &) [with DType=mshadow::half::half_t]""\r\nsrc/operator/deconvolution.cu(47): here\r\n\r\n2 errors detected in the compilation of ""/tmp/tmpxft_00004167_00000000-16_deconvolution.compute_52.cpp1.ii"".\r\nmake: *** [build/src/operator/deconvolution_gpu.o] Error 2\r\nmake: *** Waiting for unfinished jobs....\r\n```', 'I met the same problem. Then I updated the CuDNN version from v4.0 to v5.0 and complied successfully.', 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!\nAlso, do please check out our [forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) for general ""how-to"" questions.']",[],"['git rev-parse HEAD', 'sessionInfo()']",0,0
238,incubator-mxnet,5059,closed,some questions about the param num_update in optimizer.py,"Hi,
      I find there are some problems in updating the param num_update in optimizer.py.
For example,
      In the first iter, the first grad gets the lr when the num_update is 0 https://github.com/dmlc/mxnet/blob/master/python/mxnet/optimizer.py#L264 , and then it updates the num_update to 1, so the next grad and others will get the lr  when the num_update is 1,.
     In the second iter, the num_update of the first grad is 1, and others will be 2.
     ........ 
     This may lead to different grads get different lr. It doesn't matter if we use MultiFactorScheduler to get lr https://github.com/dmlc/mxnet/blob/master/python/mxnet/lr_scheduler.py#L85 . However, It does matter if we use other schedulers such as poly scheduler https://github.com/BVLC/caffe/blob/master/src/caffe/solvers/sgd_solver.cpp#L20 .  

    I think the function _update_count should be changed to       https://github.com/dmlc/mxnet/blob/master/python/mxnet/optimizer.py#L136:
         if index not in self._index_update_count:
            self._index_update_count[index] = self.begin_num_update
        self.num_update = self._index_update_count[index]
        self._index_update_count[index] += 1

and there should be changed to  https://github.com/dmlc/mxnet/blob/master/python/mxnet/optimizer.py#L264
        self._update_count(index)
         lr = self._get_lr(index)
        wd = self._get_wd(index)




          
",,"['Would you like to submit a pull request?', 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!']",[],[],0,0
239,incubator-mxnet,817,closed,Segmentation fault when using 'simple_bind',"Hi, I've got a 'Segmentation fault' when I try to use a pre-trained model to do  operation. The model is converted from [vgg16](http://www.robots.ox.ac.uk/~vgg/software/very_deep/caffe/VGG_ILSVRC_16_layers.caffemodel) Caffe model by the tool in mxnet.  And the code works if I comment out the last line.
This is the code:



This is what I got from gdb

![gdb](http://r.loli.io/NBNF3i.png)
",,"['ping @winstywang \n', ""If you want to use FeedForward model you should use it's fit API instead of binding by yourself.\n"", ""Thank you for your reply. Since I just want to do predicting instead of training, the fit API is not a choice here. And the source code in predict function in mxnet also use simple_bind like what I do above. And I've found that if I replace `devs=mx.gpu()` with `devs=mx.cpu()`, it works without segmentation fault.\n"", '@piiswrong  To make it more clear, I think the code is the same as `FeedForward._init_predictor` since I just take the `symbol` out from the model and do `simple_bind`.\n', 'Can you run any example with GPU? a quick work around is to fit with end_epoch=0 so that FeedFoward model can bind for you without training\n', ""``` C++\nmodel = mx.model.FeedForward.load('path/to/model', 5, ctx=mx.gpu(0))\ndata = your_data_iter\ndepth = model.predict(data)\n```\n\nThis code works fine for me.\n"", '@piiswrong He only needs the symbol stored in the checkpoint. If he initializes the symbol from scratch, it works fine.\n', 'https://github.com/dmlc/mxnet/issues/865\n']","[' python\nimport numpy as np\nimport mxnet as mx\n\n\nX=mx.io.ImageRecordIter(\n  path_imgrec =\'data/\'+""val_rec.bin"",\n  mean_r      =123.68,\n  mean_g      =116.779,\n  mean_b      =103.939,\n  rand_crop   =False,\n  rand_mirror =False,\n  data_shape  =(3,224,224),\n  batch_size  =32,\n  num_parts   =1,\n  part_index  =0)\n\nprefix=\'model/vgg16\'\ndevs=mx.gpu()\nvgg_model=mx.model.FeedForward.load(prefix,1,ctx=devs)\nvgg_exec=vgg_model.symbol.simple_bind(vgg_model.ctx[0],grad_req=\'null\',**dict(X.provide_data))\n']",['simple_bind'],0,0
240,incubator-mxnet,5062,closed,some question about implementing gradient normalization clip,"i implement  gradient normalization clip as followed in file optimizer.py

is it right?",,"['You can refer to this #4177 ', 'Is this implement is in update() in optimizer.py, and access only one parameter? @moveforever ', ""@feiyulv I have access the issue #4177, and know the implementation of the standard gradient clip with all parameters. \r\nDo you solve the problem about how to get the parameters list (like the 'params_grad' in function 'norm_clipping') for we can only access one parameter in the mxnet's optimizer.\r\nThank a lot :)"", '@yudeshui , yes, there only one parameter which is scalar, vector or matrix in function update. \r\nif as follow #4177, you have to reimplement all the process including load batch data, updating parameter.', ' @moveforever  Thanks :). And did you implement the idea in #4177 ?', 'What I\'m using now is like this\r\n```python\r\nclass MyModule(Module):\r\n    """"""Some enhancement to the mx.mod.Module\r\n\r\n    """"""\r\n    def norm_clipping(self, threshold=1.0):\r\n        """"""Clip the norm according to the threshold.\r\n        All the gradients are concatenated to a single vector and the overall norm is calculated.\r\n        Follows `[ICML2013] On the difficulty of training recurrent neural networks`\r\n\r\n        Parameters\r\n        ----------\r\n        threshold : float, optional\r\n\r\n        Returns\r\n        -------\r\n        norm_val : float\r\n            The norm value. It could be used to measure whether the gradients are stable.\r\n        """"""\r\n        assert self.binded and self.params_initialized\r\n        norm_val = self.get_global_norm_val()\r\n        if norm_val > threshold:\r\n            ratio = threshold / float(norm_val)\r\n            for grads in self._exec_group.grad_arrays:\r\n                for grad in grads:\r\n                    grad[:] *= ratio\r\n        return norm_val\r\n\r\n    def get_global_norm_val(self):\r\n        """"""Get the overall gradient norm ||W||_2\r\n\r\n        Parameters\r\n        ----------\r\n        net : mx.mod.Module\r\n\r\n        Returns\r\n        -------\r\n        norm_val : float\r\n        """"""\r\n        assert self.binded and self.params_initialized\r\n        #TODO The code in the following will cause the estimated norm to be different for multiple gpus\r\n        norm_val = 0.0\r\n        for i in range(len(self._exec_group.grad_arrays[0])):\r\n            norm_val += np.sqrt(\r\n                sum([nd.norm(grads[i]).asnumpy()[0] ** 2\r\n                     for grads in self._exec_group.grad_arrays]))\r\n        norm_val /= float(len(self._exec_group.grad_arrays[0]))\r\n        return norm_val\r\n```\r\nThe training workflow is like:\r\n```python\r\nnet.forward()\r\nnet.backward()\r\nnorm_val = net.norm_clipping(threshold=...)\r\n# You can also print the norm_val here, which is really helpful for debugging RNN\r\nnet.update()\r\n```\r\nThis feature is still not ready for PR due to the multi-GPU issue. The implementation will give incorrect norm for multi-gpu training. However, the impact should be small.', ""@sxjscience  It's very helpful for me. Thanks a lot. :)"", '@yudeshui Could you confirm that this works in your case? If that is so, I can PR this first and doc the incorrect behavior for multi-GPU training.', '@sxjscience Yes. I use the implement in my work with single GPU and it works well.', '@sxjscience \r\ni imitate your implementation to support multi-gpu. And i use mx.nd operation as soon as possible. \r\ni am not sure whether it\'s right\r\nThe code is as followed:\r\n\r\n```\r\n    def norm_clipping(self, threshold=1.0):\r\n        """"""Clip the norm according to the threshold.\r\n        All the gradients are concatenated to a single vector and the overall norm is calculated.\r\n        Follows `[ICML2013] On the difficulty of training recurrent neural networks`\r\n\r\n        Parameters\r\n        ----------\r\n        threshold : float, optional\r\n\r\n        Returns\r\n        -------\r\n        norm_val : float\r\n            The norm value. It could be used to measure whether the gradients are stable.\r\n        """"""\r\n        assert self.binded and self.params_initialized\r\n        norm_val = self.get_global_norm_val()\r\n\tfor i in range(len(self._exec_group.execs)):\r\n            if norm_val[i] > threshold:\r\n           \tratio = threshold / float(norm_val[i])\r\n            \tfor grads in self._exec_group.grad_arrays:\r\n                    grads[i][:] *= ratio\r\n\r\n    def get_global_norm_val(self):\r\n        """"""Get the overall gradient norm ||W||_2\r\n\r\n        Parameters\r\n        ----------\r\n        net : mx.mod.Module\r\n\r\n        Returns\r\n        -------\r\n        norm_val : float\r\n        """"""\r\n        assert self.binded and self.params_initialized\r\n\r\n\timport numpy as np\r\n        norm_val = np.zeros(len(self._exec_group.execs))\r\n\tfor grad_arr in self._exec_group.grad_arrays:\r\n\t    for i in range(len(self._exec_group.execs)):\r\n\t\tl2_norm = nd.square(nd.norm(grad_arr[i] / self._exec_group.batch_size)).asscalar()\r\n\t\tnorm_val[i] += l2_norm\r\n        return np.sqrt(norm_val)\r\n```', 'Thanks very much! I\'ll go back to Hong Kong tomorrow and will begin to finish this.\n\nXingjian\n\nGet Outlook for iOS<https://aka.ms/o0ukef>\n________________________________\nFrom: zhongyi zheng <notifications@github.com>\nSent: Friday, April 21, 2017 7:27:57 PM\nTo: dmlc/mxnet\nCc: Xingjian SHI; Mention\nSubject: Re: [dmlc/mxnet] some question about implementing gradient normalization clip (#5062)\n\n\n@sxjscience<https://github.com/sxjscience>\ni imitate your implementation to support multi-gpu. And i use mx.nd operation as soon as possible.\ni am not sure whether it\'s right\nThe code is as followed:\n\ndef norm_clipping(self, threshold=1.0): """"""Clip the norm according to the threshold. All the gradients are concatenated to a single vector and the overall norm is calculated. Follows[ICML2013] On the difficulty of training recurrent neural networks`\n\n    Parameters\n    ----------\n    threshold : float, optional\n\n    Returns\n    -------\n    norm_val : float\n        The norm value. It could be used to measure whether the gradients are stable.\n    """"""\n    assert self.binded and self.params_initialized\n    norm_val = self.get_global_norm_val()\nfor i in range(len(self._exec_group.execs)):\n        if norm_val[i] > threshold:\n        ratio = threshold / float(norm_val[i])\n                for grads in self._exec_group.grad_arrays:\n                grads[i][:] *= ratio\n\ndef get_global_norm_val(self):\n    """"""Get the overall gradient norm ||W||_2\n\n    Parameters\n    ----------\n    net : mx.mod.Module\n\n    Returns\n    -------\n    norm_val : float\n    """"""\n    assert self.binded and self.params_initialized\n    #TODO The code in the following will cause the estimated norm to be different for multiple gpus\nimport numpy as np\n    norm_val = np.zeros(len(self._exec_group.execs))\nfor grad_arr in self._exec_group.grad_arrays:\n    for i in range(len(self._exec_group.execs)):\n        l2_norm = nd.square(nd.norm(grad_arr[i] / self._exec_group.batch_size)).asscalar()\n        norm_val[i] += l2_norm\n    return np.sqrt(norm_val)\n\n\n`\n\n—\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub<https://github.com/dmlc/mxnet/issues/5062#issuecomment-296166673>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AE8D7rCIBvJP2Zp0DQgUioOmpy-YP1BHks5ryJK9gaJpZM4MFfaP>.\n', 'We have gluon now and all the implementations should be shifted to gluon.']",['\r\n        norms = norm(grad)//mx.nd.norm\r\n        if  norms > self.gradient_norm_threshold:\r\n            grad = grad * self.gradient_norm_threshold/norms\r\n'],[],0,0
241,incubator-mxnet,5580,closed,How to create a Custom Operator with extra parameters in Python?,"say if I have a layer need some input parameters e.g. size = 10 .
How to set that in Custom Operator? I didnt see any examples in 
http://mxnet.io/how_to/new_op.html",,"['You can set them like defining a python class in `__init__`.For example:\r\n\r\n```python\r\n\r\nclass Softmax(mx.operator.CustomOp):\r\n\r\n    def __init__(self, xxx, yyy):\r\n        self.xxx = xxx\r\n        self.yyy = yyy\r\n    def forward(self, is_train, req, in_data, out_data, aux):\r\n        x = in_data[0].asnumpy()\r\n        y = np.exp(x - x.max(axis=1).reshape((x.shape[0], 1)))\r\n        y /= y.sum(axis=1).reshape((x.shape[0], 1))\r\n        print self.xxx, self.yyy\r\n        self.assign(out_data[0], req[0], mx.nd.array(y))\r\n\r\n    def backward(self, req, out_grad, in_data, out_data, in_grad, aux):\r\n        l = in_data[1].asnumpy().ravel().astype(np.int)\r\n        y = out_data[0].asnumpy()\r\n        y[np.arange(l.shape[0]), l] -= 1.0\r\n        self.assign(in_grad[0], req[0], mx.nd.array(y))\r\n\r\n@mx.operator.register(""softmax"")\r\nclass SoftmaxProp(mx.operator.CustomOpProp):\r\n    def __init__(self, xxx, yyy):\r\n        super(SoftmaxProp, self).__init__(need_top_grad=False)\r\n        \r\n        # add parameter\r\n        self.xxx = xxx\r\n        self.yyy = yyy\r\n    def list_arguments(self):\r\n        return [\'data\', \'label\', \'xxx\', \'yyy\']\r\n\r\n    def list_outputs(self):\r\n        return [\'output\']\r\n\r\n    def infer_shape(self, in_shape):\r\n        data_shape = in_shape[0]\r\n        label_shape = (in_shape[0][0],)\r\n        output_shape = in_shape[0]\r\n        return [data_shape, label_shape], [output_shape], []\r\n\r\n    def create_operator(self, ctx, shapes, dtypes):\r\n        return Softmax(xxx=self.xxx, yyy=self.yyy)\r\n```\r\n\r\nHere is a example about Softmax, we can see that there are not any parametres in `__init__`, it just extend its father class, if you wanna add some parameter, you can set them in `__init__`, and this is  same as creating op by extending `mx.operator.NDArrayOp`. Just see that like a simple python class.\r\n\r\nAlso, if you use them in `forward()` or `backward()`, you can set them to class Softmax like above code.\r\n\r\nAnd when you use the customOP, you need set arguments names in `list_arguments()`, then you can input them by arguments when you use them.', '@saicoco  it works! thanks a lot!', 'nice zan!!!', 'Is it able to add parameters that are not string, but self defined classes ? \r\n\r\nI pass the class in while all the parameters are converted to str @saicoco ', '@pengwangucla \r\nYou may use cPickle to do that. When defining the symbol, passing parameters by \r\n```certain_param=cPickle.dump(self_defined_things)```\r\nAnd inside the operator, using ```cPickle.loads(self_defined_things)```\r\n\r\nI use this one when passing easydict object to operator.', 'Means that you wanna pass a class as arg to your operator? \r\n@pengwangucla \r\n\r\n', '@Oh233 How do I do that in python 3?', 'Also struggling to implement this in Python 3.']",[],[],0,0
242,incubator-mxnet,16249,closed,links broken for https://mxnet.incubator.apache.org/versions/master/gluon/,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
The link obtained when searching on google/duckduckgo for mxnet gluon is 
https://mxnet.incubator.apache.org/versions/master/gluon/
The link however appears to lead to a ""Not found"" error. 


## Steps to reproduce
Paste https://mxnet.incubator.apache.org/versions/master/gluon/ into a web browser
",Website,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended label(s): Gluon, Bug', 'lots of google search results went to 404, may due to new mxnet website launch\r\n\r\nhttps://mxnet.incubator.apache.org/api/python/kvstore/kvstore.html\r\nhttps://mxnet.incubator.apache.org/api/python/index.html', 'cc @aaronmarkham ', '@srsridharan you may want to search directly on mxnet new website for now. https://mxnet.incubator.apache.org/', 'The new website has a lot of bugs/missing documentations.\r\nFew examples:\r\n[Searching for broadcast_add does not return Symbol/ndarray broadcast_add methods](https://mxnet.incubator.apache.org/api/python/docs/search.html?q=broadcast_add) ( I also couldn\'t find it in the menu)\r\n[In Symbol.sqaure , it refers to square methods but the link is to the same page (""Convenience fluent method for square()."")](https://mxnet.incubator.apache.org/api/python/docs/api/symbol/_autogen/mxnet.symbol.Symbol.square.html#mxnet.symbol.Symbol.square)\r\n\r\n', '@roywei the whole Symbol API documentation is missing (try clicking on any links from this page):\r\nhttps://mxnet.incubator.apache.org/api/python/docs/tutorials/packages/symbol/index.html', '> @srsridharan you may want to search directly on mxnet new website for now. https://mxnet.incubator.apache.org/\r\n\r\n@roywei Thanks for the suggestion.  I raised the ticket to flag the website issue and will use the direct serach for now. However please note that the search functionality is pretty slow on the mxnet site. Perhaps requesting a recrawl of the mxnet site from the google crawler would get this resolved a bit sooner?\r\nhttps://support.google.com/webmasters/answer/6065812?hl=en\r\njust a thought..\r\n \r\n', '\r\nResult | URL | \xa0\r\n-- | -- | --\r\n404 Not found | http://mxnet.io/faq/perf.html<a href>RedirectedLinked from:\xa0http://mxnet.incubator.apache.org/get_started\xa0and\xa02 more | \xa0\r\n404 Not found | http://mxnet.incubator.apache.org/validate_mxnet.html<a href>Linked from:\xa0http://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | http://mxnet.incubator.apache.org/ubuntu_setup.html<a href>Linked from:\xa0http://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | http://mxnet.incubator.apache.org/scala_setup.html<a href>Linked from:\xa0http://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | http://mxnet.incubator.apache.org/java_setup.html<a href>Linked from:\xa0http://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | http://mxnet.incubator.apache.org/ubuntu_setup<a href>Linked from:\xa0http://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | http://mxnet.incubator.apache.org/c_plus_plus<a href>Linked from:\xa0http://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | http://mxnet.incubator.apache.org/centos_setup.html<a href>Linked from:\xa0http://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | http://mxnet.incubator.apache.org/osx_setup.html<a href>Linked from:\xa0http://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | http://mxnet.incubator.apache.org/windows_setup.html<a href>Linked from:\xa0http://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/versions/master/tutorials/embedded/wine_detector.html<a href>Linked from:\xa0http://mxnet.incubator.apache.org/get_started\xa0and\xa02 more | \xa0\r\n404 Not found | http://mxnet.incubator.apache.org/faq/env_var.html<a href>Linked from:\xa0http://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | http://mxnet.io/tutorials/embedded/wine_detector.html<a href>RedirectedLinked from:\xa0http://mxnet.incubator.apache.org/get_started\xa0and\xa02 more | \xa0\r\n404 Not found | http://mxnet.incubator.apache.org/install-jetson.html<a href>Linked from:\xa0http://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | http://mxnet.incubator.apache.org/download<a href>Linked from:\xa0http://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/validate_mxnet.html<a href>Linked from:\xa0https://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/ubuntu_setup.html<a href>Linked from:\xa0https://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/scala_setup.html<a href>Linked from:\xa0https://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/java_setup.html<a href>Linked from:\xa0https://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/ubuntu_setup<a href>Linked from:\xa0https://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/c_plus_plus<a href>Linked from:\xa0https://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/centos_setup.html<a href>Linked from:\xa0https://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/osx_setup.html<a href>Linked from:\xa0https://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/windows_setup.html<a href>Linked from:\xa0https://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/faq/env_var.html<a href>Linked from:\xa0https://mxnet.incubator.apache.org/get_started\xa0and\xa01 more | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/install-jetson.html<a href>Linked from:\xa0https://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/download<a href>Linked from:\xa0https://mxnet.incubator.apache.org/get_started | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/get_started/c_plus_plus<a href>Linked from:\xa0https://mxnet.incubator.apache.org/get_started/ | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/get_started/install-jetson.html<a href>Linked from:\xa0https://mxnet.incubator.apache.org/get_started/ | \xa0\r\n404 Not found | https://github.com/apache/incubator-mxnet/blob/master/docs/tutorials/mkldnn/MKLDNN_README.md<a href>OutboundLinked from:\xa0http://mxnet.incubator.apache.org/get_started/ubuntu_setup | \xa0\r\n404 Not found | http://mxnet.incubator.apache.org/get_started/c_plus_plus<a href>Linked from:\xa0http://mxnet.incubator.apache.org/get_started/ubuntu_setup | \xa0\r\n404 Not found | https://github.com/apache/incubator-mxnet/tree/master/docs/build_version_doc<a href>OutboundLinked from:\xa0http://mxnet.incubator.apache.org/get_started/scala_setup | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/install/build_from_source<a href>Linked from:\xa0http://mxnet.incubator.apache.org/api/cpp | \xa0\r\n404 Not found | https://github.com/dmlc/MXNet.jl/edit/master/docs/index.md<a href>OutboundLinked from:\xa0http://mxnet.incubator.apache.org/api/julia/docs/api/ | \xa0\r\n404 Not found | https://github.com/dmlc/MXNet.jl/tree/master/examples<a href>OutboundLinked from:\xa0http://mxnet.incubator.apache.org/api/julia/docs/api/ | \xa0\r\n404 Not found | http://mxnet.io/install/index.html<a href>RedirectedLinked from:\xa0http://mxnet.incubator.apache.org/api/architecture/exception_handling | \xa0\r\n404 Not found | https://mxnet.incubator.apache.org/tutorials/basic/data.html<a href>Linked from:\xa0http://mxnet.incubator.apache.org/api/architecture/note_data_loading | \xa0\r\n404 Not found | http://mxnet.io/architecture/rnn_interface.html<a href>RedirectedLinked from:\xa0http://mxnet.incubator.apache.org/api/architecture/note_engine | \xa0\r\n404 Not found | http://mxnet.incubator.apache.org/api/tutorials/mkldnn/operator_list.md<a href>Linked from:\xa0http://mxnet.incubator.apache.org/api/faq/env_var\r\n\r\n', '> > @srsridharan you may want to search directly on mxnet new website for now. https://mxnet.incubator.apache.org/\r\n> \r\n> @roywei Thanks for the suggestion. I raised the ticket to flag the website issue and will use the direct serach for now. However please note that the search functionality is pretty slow on the mxnet site. Perhaps requesting a recrawl of the mxnet site from the google crawler would get this resolved a bit sooner?\r\n> https://support.google.com/webmasters/answer/6065812?hl=en\r\n> just a thought..\r\n\r\nI already have a ticket open with Apach Infra for that.\r\nhttps://issues.apache.org/jira/browse/INFRA-19144\r\n', ""Since this is really about the google index, let's keep this issue focused on that. \r\nIf we can get a reindex, it'll fix the google search results. \r\nAs for the broken links, I'll try to knock out the ones mentioned in the comments today. I just merged a previous link pass I did on the install page and readme. If y'all find more broken links, please open another issue as I will close this one once the reindex happens. Thanks!"", 'This link is gone from the google index.']",[],[],0,0
243,incubator-mxnet,10476,closed,Flaky test for test_operator.test_reduce,"Try to use MXNET_TEST_SEED=1117986172
",,['Duplicate of https://github.com/apache/incubator-mxnet/issues/9845'],"['\r\n======================================================================\r\nFAIL: test_operator.test_reduce\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File ""/usr/lib/python2.7/dist-packages/nose/case.py"", line 197, in runTest\r\n    self.test(*self.arg)\r\n  File ""/home/ubuntu/experimentals/spidyDev_mxnet/tests/python/unittest/common.py"", line 157, in test_new\r\n    orig_test(*args, **kwargs)\r\n  File ""/home/ubuntu/experimentals/spidyDev_mxnet/tests/python/unittest/test_operator.py"", line 1826, in test_reduce\r\n    mx.symbol.max, test_none_axis=test_none)\r\n  File ""/home/ubuntu/experimentals/spidyDev_mxnet/tests/python/unittest/test_operator.py"", line 1799, in test_reduce_inner\r\n    assert equal_backward\r\nAssertionError:\r\n-------------------- >> begin captured logging << --------------------\r\ncommon: INFO: Setting module np/mx/python random seeds, use MXNET_MODULE_SEED=754316987 to reproduce.\r\ncommon: INFO: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=1117986172 to reproduce.\r\n--------------------- >> end captured logging << ---------------------\r\n\r\n----------------------------------------------------------------------\r\nRan 1 test in 22.731s\r\n\r\nFAILED (failures=1)\r\n']",[],0,0
244,incubator-mxnet,10919,closed,gluon.Block load_params method does not accept python3 pathlib.Path,"gluon.Block  method should accept not only strings, but also pathlib.Path types that are new in python 3.
",Feature request Gluon,"['I think we can remove the check. Python prefers duck typing anyway', ""Actually, we don't plan to support this. It should be easy to extract string path from pathlib\r\n\r\nClosing""]","['---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-31-aa0ab27bd19c> in <module>()\r\n----> 1 poisson_fa.load_params(cfg[\'train_dir\'] / \'model.params\')\r\n\r\n~/.local/lib/python3.6/site-packages/mxnet/gluon/block.py in load_params(self, filename, ctx, allow_missing, ignore_extra)\r\n    329             present in this Block.\r\n    330         """"""\r\n--> 331         loaded = ndarray.load(filename)\r\n    332         params = self._collect_params_with_prefix()\r\n    333         if not loaded and not params:\r\n\r\n~/.local/lib/python3.6/site-packages/mxnet/ndarray/utils.py in load(fname)\r\n    164     """"""\r\n    165     if not isinstance(fname, string_types):\r\n--> 166         raise TypeError(\'fname required to be a string\')\r\n    167     out_size = mx_uint()\r\n    168     out_name_size = mx_uint()\r\n\r\nTypeError: fname required to be a string\r\n']",['load_params'],0,0
245,incubator-mxnet,11165,closed,ImageIter much slower than ImageRecordIter,"We use ImageIter to read jpg files,.
batch_size was set to 512. 
MXNET_CPU_WORKER_NTHREADS set to 48
It use about 0.35s per batch.
But it only use about 0.0618s per batch when we use ImageRecordIter to read rec file.

Why ImageIter is too slow?
Does too many augmenters called in python affect this speed?
Does MXNet has an interface can do all the task include read,decode,resize,crop,tanspose,rgb_mean in c++?",Pending Requester Info Performance,"[""Hi @solin319 could you please provide more information about your system information and how you build the package or pip install? Please submit this question on MXNet discussion forum (https://discuss.mxnet.io), where it will get a wider audience and allow other to learn as well.\r\n\r\n@nswamy can you add 'Question', 'Performance' tag on this issue? "", ""Performance wise, even theoretically such a solution can't beat using a rec file with ImageRecordIter would be much more efficient. Are you trying to avoid using rec files?"", ""Yes,  and I think some users may used to use raw jpeg data like me.\r\nBut I can't find a performance method to read."", '@solin319 If you are willing to use Gluon I would suggest combining the `ImageFolderDataset` and `DataLoader` with `num_workers` >> 1 . The data loading is performed asynchronously on several processes and the data is pre-fetched in advance for you.\r\n\r\nHave a look at this tutorial: https://mxnet.incubator.apache.org/tutorials/gluon/datasets.html#using-own-data-with-included-datasets\r\n\r\n@solin319 Please consider closing if your query has been answered. Thanks!', ""@solin319 Most augmenters call OpenCV functions written in C++ anyway, so I wouldn't expect much of a difference by moving everything to C++. Just a small overhead from calling in Python."", 'We move some augmenters call in c++, and the speed can achieve 0.21s per batch, which is 0.35 smentioned above.\r\nSo we expect community can add an interface can read raw pic with high speed.', '@solin319, have you tried other approaches, like creating your own custom iterator, which can do the reading in the background? I mean, if you use HDD, then using 48 threads to read random images from disk can significantly reduce the speed. Did you try to reduce the number of threads to, for example, 2, to see the difference in loading speed?\r\n\r\nAlso, how much processing do you do when you read a raw image? Again, maybe you need to have a specialized pipeline: a bunch of threads who are reading files from disk, and another bunch which do processing.', '@solin319 any update?']",[],[],0,0
246,incubator-mxnet,2968,closed,Training ResNet on imagenet,"i have trained resnet-50 in imanget, top1 error is 25.41% and top-5 error is 7.93%, which is not very good, so do anyone reproduced it now? hope somebody can release the model for study other task~
(my code is in https://github.com/tornadomeet/ResNet, it support both imagnet and cifar training with different depth. )
",,"['it may be due to the image compression algorithm used by python is not good... please consider try to download a converted data at http://data.dmlc.ml/mxnet/private/ilsvrc12/, *_256_q90.rec \n\nplease shoot me an email muli@cs.cmu.edu for the username and password\n', '@mli done\n', '@tornadomeet Min has successfully reproduced Res-50/101/152/200 even in distributed environment. For Res-200 he reported exact performance but trained in 36 hours with multiple machine. We will reproduce it together with you. \n', 'great!!\n', ""@mli i just have download the train_256_q90.rec.  it's sad that i can not retrain the model directly, because my synset.txt is come from ILSVRC2015 map_clsloc.txt, that is different from yours which is widely used in caffe. \nso need to train the model from scratch.\nwait for the pre-trained model from @mavenlin\n"", ""Min won't provide pretrained model. We plan to train by ourselves from\nscratch, and check where is the issue.\nOn Tue, Aug 9, 2016 at 23:40 tornadomeet notifications@github.com wrote:\n\n> @mli https://github.com/mli i just have done the train_256_q90.rec.\n> it's sad that i can not retrain the model directly, because my synset.txt\n> is come from ILSVRC2015 map_clsloc.txt, that is different from yours which\n> is widely used in caffe.\n> so need to train the model from scratch.\n> wait for the pre-trained model from @mavenlin\n> https://github.com/mavenlin\n> \n> —\n> You are receiving this because you commented.\n> \n> Reply to this email directly, view it on GitHub\n> https://github.com/dmlc/mxnet/issues/2968#issuecomment-238778939, or mute\n> the thread\n> https://github.com/notifications/unsubscribe-auth/ABM13my0t7AmUPRatA87oKlzEvyW7k5lks5qeXJ6gaJpZM4Jfp4p\n> .\n> \n> ## \n> \n> Sent from mobile phone\n"", ""@antinucleon  ok, i'll continue to reproduced it and try to find the problem.\n"", '@antinucleon @mli  i found a  a potential problem of mx.io.ImageRecordIter --> **when set rand_crop = True, then during each epoch the cropped  area of the same image is the same.**, (wish i\'m wrong..)  \n\nif this is a bug, then it will influence the resnet result, because our training rec is 480, and for the same image in each epoch, it only see the same area, so the scale augment does\'t work at all. \n\nwe can reproduced this like this:\n\n``` python\n    train = mx.io.ImageRecordIter(...)  # set random_crop=True, data_shape less than the size of .rec\n    import numpy as np\n    import cv2\n    for i in range(10):\n        X = train.getdata().asnumpy()[i]\n        X=np.swapaxes(X, 0, 2)\n        X=np.swapaxes(X, 0, 1)\n        X = cv2.cvtColor(X, cv2.COLOR_RGB2BGR)\n        cv2.imwrite(""{}_result.jpg"".format(i), X)\n        print ""image_{}--->{}"".format(i, train.getlabel().asnumpy()[i])\n    train.reset()\n    for i in range(10):\n        X = train.getdata().asnumpy()[i]\n        X=np.swapaxes(X, 0, 2)\n        X=np.swapaxes(X, 0, 1)\n        X = cv2.cvtColor(X, cv2.COLOR_RGB2BGR)\n        cv2.imwrite(""{}_reset_result.jpg"".format(i), X)\n        print ""reset_image_{}--->{}"".format(i, train.getlabel().asnumpy()[i])\n    train.reset()\n    for i in range(10):\n        X = train.getdata().asnumpy()[i]\n        X=np.swapaxes(X, 0, 2)\n        X=np.swapaxes(X, 0, 1)\n        X = cv2.cvtColor(X, cv2.COLOR_RGB2BGR)\n        cv2.imwrite(""{}_reset2_result.jpg"".format(i), X)\n        print ""reset2_image_{}--->{}"".format(i, train.getlabel().asnumpy()[i])\n```\n\nthen the corresponding image is the same. \nthe same phenomenon may happen with random mirror.  \n\nbut when i debug into https://github.com/dmlc/mxnet/blob/master/src/io/image_aug_default.cc#L241, i print out the y and x and found it should changed after each epoch.  \ncould anybody verify this?\n', 'i just test that rand_mirror has the same problem.  so all random parameter in mx.io.ImageRecordIter() may suffer the same thing.\n@winstywang @piiswrong \n', '@tornadomeet I will be in trip from tomorrow. I think this is a really good catch. I guess this is just the reason why we cannot reproduce the results. I will let one of my interns to catch up with this issue. \n', 'you didn\'t call train.next() so it\'s always the same batch of data...\nThe bellow code gives correct result\n\n```\nimport mxnet as mx\nimport numpy as np\nimport cv2\n\ntrain = mx.io.ImageRecordIter(\n        path_imgrec = \'/archive/imagenet/train.rec\',\n        data_shape  = (3, 224, 224),\n        batch_size  = 10,\n        rand_crop   = True,\n        rand_mirror = True)  # set random_crop=True, data_shape less than the size of .rec\ntrain.reset()\ndata = train.next().data[0].asnumpy()\nfor i in range(10):\n    X = data[i]\n    X=np.swapaxes(X, 0, 2)\n    X=np.swapaxes(X, 0, 1)\n    X = cv2.cvtColor(X, cv2.COLOR_RGB2BGR)\n    cv2.imwrite(""{}_result.jpg"".format(i), X)\n    print ""image_{}--->{}"".format(i, train.getlabel().asnumpy()[i])\ntrain.reset()\ndata = train.next().data[0].asnumpy()\nfor i in range(10):\n    X = data[i]\n    X=np.swapaxes(X, 0, 2)\n    X=np.swapaxes(X, 0, 1)\n    X = cv2.cvtColor(X, cv2.COLOR_RGB2BGR)\n    cv2.imwrite(""{}_reset_result.jpg"".format(i), X)\n    print ""reset_image_{}--->{}"".format(i, train.getlabel().asnumpy()[i])\ntrain.reset()\ndata = train.next().data[0].asnumpy()\nfor i in range(10):\n    X = data[i]\n    X=np.swapaxes(X, 0, 2)\n    X=np.swapaxes(X, 0, 1)\n    X = cv2.cvtColor(X, cv2.COLOR_RGB2BGR)\n    cv2.imwrite(""{}_reset2_result.jpg"".format(i), X)\n    print ""reset2_image_{}--->{}"".format(i, train.getlabel().asnumpy()[i])\n```\n', '@piiswrong @winstywang oh, i made a mistake, so this should be no problem.\n', 'another small potential problem is that every time we start our program, the result is the same, it may not influence so much but if we change lr manual and retrain the model, then the randomness is the same each time.\n', 'Another thing is that He shuffles the dataset for each epoch. I only tested on the CIFAR 10 dataset with ResNet56:\n\n![image](https://cloud.githubusercontent.com/assets/3815006/17655271/9685f9ac-62de-11e6-8863-162f92689902.png)\n\nNote that 93.16% is about 1% higher than 92.17%. In the paper, the reference performance is 93.03% (93.16%>93.03%>92.17%). I am wondering this will also apply for the ImageNet dataset.\n\nP.S.: Shuffling the whole dataset is expensive, so I am using the following `RandomSkipResizeIter`:\n\n```\nclass RandomSkipResizeIter(mx.io.DataIter):\n    """"""Resize a DataIter to given number of batches per epoch.\n    May produce incomplete batch in the middle of an epoch due\n    to padding from internal iterator.\n\n    Parameters\n    ----------\n    data_iter : DataIter\n        Internal data iterator.\n    max_random_skip : maximum random skip number\n        If max_random_skip is 1, no random skip.\n    size : number of batches per epoch to resize to.\n    reset_internal : whether to reset internal iterator on ResizeIter.reset\n    """"""\n\n    def __init__(self, data_iter, size, skip_ratio=0.5, reset_internal=False):\n        super(RandomSkipResizeIter, self).__init__()\n        self.data_iter = data_iter\n        self.size = size\n        self.reset_internal = reset_internal\n        self.cur = 0\n        self.current_batch = None\n        self.prev_batch = None\n        self.skip_ratio = skip_ratio\n\n        self.provide_data = data_iter.provide_data\n        self.provide_label = data_iter.provide_label\n        self.batch_size = data_iter.batch_size\n\n    def reset(self):\n        self.cur = 0\n        if self.reset_internal:\n            self.data_iter.reset()\n\n    def __get_next(self):\n        try:\n            return self.data_iter.next()\n        except StopIteration:\n            self.data_iter.reset()\n            return self.data_iter.next()\n\n    def iter_next(self):\n        if self.cur == self.size:\n            return False\n\n        data, label = [], []\n        if self.current_batch is None:\n            # very first\n            batch = self.__get_next()\n            self.current_batch = mx.io.DataBatch(data=[mx.nd.empty(batch.data[0].shape)], label=[mx.nd.empty(batch.label[0].shape)])\n            keep = np.random.rand(self.batch_size) > self.skip_ratio\n            batch_data = batch.data[0].asnumpy()\n            batch_label = batch.label[0].asnumpy()\n            data.extend(batch_data[keep])\n            label.extend(batch_label[keep])\n        elif self.prev_batch is not None:\n            # prev_batch\n            batch_data, batch_label = self.prev_batch\n            data.extend(batch_data)\n            label.extend(batch_label)\n\n        while len(data) < self.batch_size:\n            batch = self.__get_next()\n            keep = np.random.rand(self.batch_size) > self.skip_ratio\n            batch_data = batch.data[0].asnumpy()\n            batch_label = batch.label[0].asnumpy()\n            data.extend(batch_data[keep])\n            label.extend(batch_label[keep])\n\n        if len(data) > self.batch_size:\n            self.prev_batch = data[self.batch_size:], label[self.batch_size:]\n        else:\n            self.prev_batch = None\n        self.current_batch.data[0][:] = np.asarray(data[:self.batch_size])\n        self.current_batch.label[0][:] = np.asarray(label[:self.batch_size])\n\n        self.cur += 1\n        return True\n\n    def getdata(self):\n        return self.current_batch.data\n\n    def getlabel(self):\n        return self.current_batch.label\n\n    def getindex(self):\n        return self.current_batch.index\n\n    def getpad(self):\n        return self.current_batch.pad\n```\n', 'cifar10 is no problem, i reproduced  resnet-164 with top1: 94.54%\n', ""@mli @antinucleon @winstywang @taoari @piiswrong  i have reproduced the result of resnet-50 using @mli 's `.rec` with io of mxnet, all the code, model, training log can be found in https://github.com/tornadomeet/ResNet  \nthanks all for discussion.\n"", ""@taoari would you give a pr of RandomSkipResizeIter? i think it will be useful when training imagenet model.\n\ni have add your `RandomSkipResizeIter` im resnet training code, and i'll verity it in imagenet trianing~\n""]",[],[],0,0
247,incubator-mxnet,17109,closed,[mxnet 2.0][item 3.2] Unify Executor ,"Scope:

1. SymbolBlock equivalent in C/C++, unify the executor implementation for symbol/module and the one for gluon blocks
2. migrate other versions of inference API
",Feature request,"['Features of the symbolic executor\r\n1. memory planning \r\n2. Infer shape, dtype, storage type \r\n3. gradient checkpointing (aka mirror)\r\n4. Subgraph support\r\n5. Control flow support\r\n6. Dynamic shape op support \r\n7. Python/C predict API\r\n8. Graph passes for fusion/quantization \r\n9. cross-device context group support \r\n\r\nFeatures missing/requires validation for Gluon imperative\r\n- gradient checkpointing\r\n- C predict API \r\n- Graph passes for fusion/quantization \r\n- whether performance is on par with symbolic executor\r\n- cross-device context group support', 'https://github.com/apache/incubator-mxnet/issues/17278']",[],[],0,0
248,incubator-mxnet,7684,closed,Python3.5 MXNet doesn't execute for loop！！,"I try to follow The Custom Iterator section's code in the tutorial page at  https://mxnet.incubator.apache.org/tutorials/basic/data.html.  But I found these two line are never executed!
data = [mx.nd.array(g(d[1])) for d,g in zip(self._provide_data, self.data_gen)]
label = [mx.nd.array(g(d[1])) for d,g in zip(self._provide_label, self.label_gen)]
My python's version is python3.5 and mxnet is 0.95.
Does any could help to fix this problem?",,['The example works fine.'],[],[],0,0
249,incubator-mxnet,8542,closed,Remove dependency on http://www.csie.ntu.edu.tw for LibSVMIter test,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues.

If the issue is non-technical, feel free to present the information in what you believe is the best form.

## Description
The dependency here on www.csie.ntu.edu.tw should be changed to be hosted on our own S3 bucket.  See https://github.com/apache/incubator-mxnet/blob/master/tests/python/unittest/test_io.py#L218 ",,"['We need to review the license of that dataset before hosting it ourselves.', 'Just had a test failure due to this external dep: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-9055-merge/11/pipeline/337\r\n\r\n```\r\n======================================================================\r\n\r\nERROR: test_io.test_LibSVMIter\r\n\r\n----------------------------------------------------------------------\r\n\r\nTraceback (most recent call last):\r\n\r\n  File ""C:\\Anaconda3\\envs\\py3\\lib\\site-packages\\nose\\case.py"", line 197, in runTest\r\n\r\n    self.test(*self.arg)\r\n\r\n  File ""C:\\jenkins_slave\\workspace\\ut-python-cpu@2\\tests\\python\\unittest\\test_io.py"", line 254, in test_LibSVMIter\r\n\r\n    check_libSVMIter_news_data()\r\n\r\n  File ""C:\\jenkins_slave\\workspace\\ut-python-cpu@2\\tests\\python\\unittest\\test_io.py"", line 238, in check_libSVMIter_news_data\r\n\r\n    news_metadata[\'origin_name\'])\r\n\r\n  File ""C:\\jenkins_slave\\workspace\\ut-python-cpu@2\\pkg_vc14_cpu\\python\\mxnet\\test_utils.py"", line 1498, in get_bz2_data\r\n\r\n    download(url, fname=data_origin_name, dirname=data_dir, overwrite=False)\r\n\r\n  File ""C:\\jenkins_slave\\workspace\\ut-python-cpu@2\\pkg_vc14_cpu\\python\\mxnet\\test_utils.py"", line 1411, in download\r\n\r\n    r = requests.get(url, stream=True)\r\n\r\n  File ""C:\\Anaconda3\\envs\\py3\\lib\\site-packages\\requests\\api.py"", line 70, in get\r\n\r\n    return request(\'get\', url, params=params, **kwargs)\r\n\r\n  File ""C:\\Anaconda3\\envs\\py3\\lib\\site-packages\\requests\\api.py"", line 56, in request\r\n\r\n    return session.request(method=method, url=url, **kwargs)\r\n\r\n  File ""C:\\Anaconda3\\envs\\py3\\lib\\site-packages\\requests\\sessions.py"", line 488, in request\r\n\r\n    resp = self.send(prep, **send_kwargs)\r\n\r\n  File ""C:\\Anaconda3\\envs\\py3\\lib\\site-packages\\requests\\sessions.py"", line 630, in send\r\n\r\n    history = [resp for resp in gen] if allow_redirects else []\r\n\r\n  File ""C:\\Anaconda3\\envs\\py3\\lib\\site-packages\\requests\\sessions.py"", line 630, in <listcomp>\r\n\r\n    history = [resp for resp in gen] if allow_redirects else []\r\n\r\n  File ""C:\\Anaconda3\\envs\\py3\\lib\\site-packages\\requests\\sessions.py"", line 190, in resolve_redirects\r\n\r\n    **adapter_kwargs\r\n\r\n  File ""C:\\Anaconda3\\envs\\py3\\lib\\site-packages\\requests\\sessions.py"", line 609, in send\r\n\r\n    r = adapter.send(request, **kwargs)\r\n\r\n  File ""C:\\Anaconda3\\envs\\py3\\lib\\site-packages\\requests\\adapters.py"", line 497, in send\r\n\r\n    raise SSLError(e, request=request)\r\n\r\nrequests.exceptions.SSLError: EOF occurred in violation of protocol (_ssl.c:749)\r\n\r\n-------------------- >> begin captured logging << --------------------\r\n\r\nrequests.packages.urllib3.connectionpool: DEBUG: Starting new HTTP connection (1): www.csie.ntu.edu.tw\r\n\r\nrequests.packages.urllib3.connectionpool: DEBUG: http://www.csie.ntu.edu.tw:80 ""GET /~cjlin/libsvmtools/datasets/multiclass/news20.t.bz2 HTTP/1.1"" 301 287\r\n\r\nrequests.packages.urllib3.connectionpool: DEBUG: Starting new HTTPS connection (1): www.csie.ntu.edu.tw\r\n\r\n--------------------- >> end captured logging << ---------------------\r\n```', 'Fixed by #9620']",[],[],0,0
250,incubator-mxnet,5153,closed,End2End Captcha Recognition (OCR) [Segmentation fault],"When I run the End2End Captcha Recognition (OCR) example, get a segmentation fault.
This is the original blog [url](http://blog.xlvector.net/2016-05/mxnet-ocr-cnn/)
**I changed the devs, from gpu to cpu, for lack of  hardware[gpu]**
Below is the main code:



## Environment info

Operating System:
virtual machine
Linux Mint 18[base on Ubuntu 16.04], 64bit
Compiler:
gcc 5.4.0
Package used (Python/R/Scala/Julia):
Python 2.7.12
MXNet version:
get from git master[2017-2-23]
If you are using python package, please provide
opencv 3.2

## Error Message:
### run in PyCharm
>Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)
### gdb py-bt
>Traceback (most recent call first):
  File ""test-g.py"", line 56, in __iter__
    img = cv2.imdecode(img, cv2.IMREAD_COLOR)
  File ""/home/mao/mxnet/python/mxnet/model.py"", line 236, in _train_multi_device
    for data_batch in train_data:
  File ""/home/mao/mxnet/python/mxnet/model.py"", line 816, in fit
    sym_gen=self.sym_gen)
  File ""test-g.py"", line 135, in <module>
    model.fit(X = data_train, eval_data = data_test, eval_metric = Accuracy, batch_end_callback=mx.callback.Speedometer(32, 50),)
### gdb bt
>#0  0x0000000000000000 in ?? ()
#1  0x00007ffff18149ee in cv::imdecode(cv::_InputArray const&, int) ()
   from /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4
#2  0x00007fffd9728f92 in pyopencv_cv_imdecode(_object*, _object*, _object*) ()
   from /usr/lib/python2.7/dist-packages/cv2.so
#3  0x00000000004c468a in call_function (oparg=<optimized out>, 
    pp_stack=0x7fffffffd440) at ../Python/ceval.c:4350
#4  PyEval_EvalFrameEx () at ../Python/ceval.c:2987
#5  0x00000000004dddca in gen_send_ex.isra.0.lto_priv ()
    at ../Objects/genobject.c:85
#6  0x00000000004c4c6f in PyEval_EvalFrameEx () at ../Python/ceval.c:2806
#7  0x00000000004c2765 in PyEval_EvalCodeEx () at ../Python/ceval.c:3582
#8  0x00000000004ca099 in fast_function (nk=17, na=<optimized out>, 
    n=<optimized out>, pp_stack=0x7fffffffd7e0, 
    func=<function at remote 0x7fffd4b0c488>) at ../Python/ceval.c:4445
#9  call_function (oparg=<optimized out>, pp_stack=0x7fffffffd7e0)
    at ../Python/ceval.c:4370
#10 PyEval_EvalFrameEx () at ../Python/ceval.c:2987
#11 0x00000000004c2765 in PyEval_EvalCodeEx () at ../Python/ceval.c:3582
#12 0x00000000004ca099 in fast_function (nk=4, na=<optimized out>, 
    n=<optimized out>, pp_stack=0x7fffffffd9f0, 
    func=<function at remote 0x7fffd4b0d0c8>) at ../Python/ceval.c:4445
#13 call_function (oparg=<optimized out>, pp_stack=0x7fffffffd9f0)
---Type <return> to continue, or q <return> to quit---
    at ../Python/ceval.c:4370
#14 PyEval_EvalFrameEx () at ../Python/ceval.c:2987
#15 0x00000000004c2765 in PyEval_EvalCodeEx () at ../Python/ceval.c:3582
#16 0x00000000004c2509 in PyEval_EvalCode (co=<optimized out>, 
    globals=<optimized out>, locals=<optimized out>) at ../Python/ceval.c:669
#17 0x00000000004f1def in run_mod.lto_priv () at ../Python/pythonrun.c:1376
#18 0x00000000004ec652 in PyRun_FileExFlags () at ../Python/pythonrun.c:1362
#19 0x00000000004eae31 in PyRun_SimpleFileExFlags ()
    at ../Python/pythonrun.c:948
#20 0x000000000049e14a in Py_Main () at ../Modules/main.c:640
#21 0x00007ffff7811830 in __libc_start_main (main=0x49dab0 <main>, argc=2, 
    argv=0x7fffffffde38, init=<optimized out>, fini=<optimized out>, 
    rtld_fini=<optimized out>, stack_end=0x7fffffffde28)
    at ../csu/libc-start.c:291
#22 0x000000000049d9d9 in _start ()


## What have you tried to solve it?

I find the point of interrupte is .
So I split this part to another file, only generate img from captcha module, and decode it by opencv.
It can run well.
But when I run the example, with mxnet, decode by opencv will be segmentation fault.

What's wrong?
",,"['Do you solve this problem?', 'No. I try my best, but there it is.\r\nSo I change my platform to Windows.', 'I have also met with this problem. Anyone has fixed it?', 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!', 'The problem happens when using the latest version of opencv, try with a previous one like 3.1.x\r\nThat solved it for me.', 'Thank you.']","['python\r\nclass OCRIter(mx.io.DataIter):\r\n    def __init__(self, count, batch_size, num_label, height, width):\r\n        super(OCRIter, self).__init__()\r\n        self.captcha = ImageCaptcha(fonts=[\'./data/OpenSans-Regular.ttf\'])\r\n        self.batch_size = batch_size\r\n        self.count = count\r\n        self.height = height\r\n        self.width = width\r\n        self.provide_data = [(\'data\', (batch_size, 3, height, width))]\r\n        self.provide_label = [(\'softmax_label\', (self.batch_size, num_label))]\r\n\r\n    def __iter__(self):\r\n        for k in range(self.count / self.batch_size):\r\n            data = []\r\n            label = []\r\n            for i in range(self.batch_size):\r\n                num = gen_rand()\r\n                img = self.captcha.generate(num)\r\n                img = np.fromstring(img.getvalue(), dtype=\'uint8\')\r\n                img = cv2.imdecode(img, cv2.IMREAD_COLOR)\r\n                img = cv2.resize(img, (self.width, self.height))\r\n                cv2.imwrite(""./tmp"" + str(i % 10) + "".png"", img)\r\n                img = np.multiply(img, 1/255.0)\r\n                img = img.transpose(2, 0, 1)\r\n                data.append(img)\r\n                label.append(get_label(num))\r\n\r\n            data_all = [mx.nd.array(data)]\r\n            label_all = [mx.nd.array(label)]\r\n            data_names = [\'data\']\r\n            label_names = [\'softmax_label\']\r\n\r\n            data_batch = OCRBatch(data_names, data_all, label_names, label_all)\r\n            yield data_batch\r\n\r\n    def reset(self):\r\n        pass\r\n\r\n\r\ndef get_ocrnet():\r\n    data = mx.symbol.Variable(\'data\')\r\n    label = mx.symbol.Variable(\'softmax_label\')\r\n    conv1 = mx.symbol.Convolution(data=data, kernel=(5,5), num_filter=32)\r\n    pool1 = mx.symbol.Pooling(data=conv1, pool_type=""max"", kernel=(2,2), stride=(1, 1))\r\n    relu1 = mx.symbol.Activation(data=pool1, act_type=""relu"")\r\n\r\n    conv2 = mx.symbol.Convolution(data=relu1, kernel=(5,5), num_filter=32)\r\n    pool2 = mx.symbol.Pooling(data=conv2, pool_type=""avg"", kernel=(2,2), stride=(1, 1))\r\n    relu2 = mx.symbol.Activation(data=pool2, act_type=""relu"")\r\n\r\n    conv3 = mx.symbol.Convolution(data=relu2, kernel=(3,3), num_filter=32)\r\n    pool3 = mx.symbol.Pooling(data=conv3, pool_type=""avg"", kernel=(2,2), stride=(1, 1))\r\n    relu3 = mx.symbol.Activation(data=pool3, act_type=""relu"")\r\n\r\n    flatten = mx.symbol.Flatten(data = relu3)\r\n    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=512)\r\n    fc21 = mx.symbol.FullyConnected(data=fc1, num_hidden=10)\r\n    fc22 = mx.symbol.FullyConnected(data=fc1, num_hidden=10)\r\n    fc23 = mx.symbol.FullyConnected(data=fc1, num_hidden=10)\r\n    fc24 = mx.symbol.FullyConnected(data=fc1, num_hidden=10)\r\n    fc2 = mx.symbol.Concat(*[fc21, fc22, fc23, fc24], dim=0)\r\n    label = mx.symbol.transpose(data=label)\r\n    label = mx.symbol.Reshape(data=label, target_shape=(0, ))\r\n    return mx.symbol.SoftmaxOutput(data=fc2, label=label, name=""softmax"")\r\n\r\n\r\ndef accuracy(label, pred):\r\n    label = label.T.reshape((-1, ))\r\n    hit = 0\r\n    total = 0\r\n    for i in range(pred.shape[0] / 4):\r\n        ok = True\r\n        for j in range(4):\r\n            k = i * 4 + j\r\n            if np.argmax(pred[k]) != int(label[k]):\r\n                ok = False\r\n                break\r\n        if ok:\r\n            hit += 1\r\n        total += 1\r\n    return 1.0 * hit / total\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    network = get_ocrnet()\r\n    devs = [mx.cpu()]\r\n    model = mx.model.FeedForward(ctx=devs,\r\n                                 symbol=network,\r\n                                 num_epoch=15,\r\n                                 learning_rate=0.001,\r\n                                 wd=0.00001,\r\n                                 initializer=mx.init.Xavier(factor_type=""in"", magnitude=2.34),\r\n                                 momentum=0.9)\r\n    \r\n    data_train = OCRIter(100000, 50, 4, 30, 80)\r\n    data_test = OCRIter(1000, 50, 4, 30, 80)\r\n    \r\n    import logging\r\n    head = \'%(asctime)-15s %(message)s\'\r\n    logging.basicConfig(level=logging.DEBUG, format=head)\r\n    \r\n    model.fit(X=data_train, eval_data=data_test, eval_metric=accuracy, \r\n              batch_end_callback=mx.callback.Speedometer(32, 50),)\r\n']","['img = cv2.imdecode(img, cv2.IMREAD_COLOR)']",0,0
251,incubator-mxnet,8969,closed,A couple of issues in benchmark_score.py,"Here are a couple of issues in incubator-mxnet/example/image-classification/benchmark_score.py.

Both prevent the script from running.

--> Issue #1
def get_symbol(network, batch_size):
    image_shape = (3,299,299) if network == 'inception-v3' else (3,224,224)
    num_layers = 0

get_symbol() for vgg16 doesn't accept a zero value for the number of layers.
Quick fix: insert this after ""num_layers = 0""
if network=='vgg':
    num_layers=16
Or use the same solution as for resnet (split and extract number of layers)

--> Issue #2
devs = [mx.gpu(0)] if len(get_gpus()) > 0 else []

get_gpus() relies on nvidia-smi which is not installed on machines that don't have GPUs (say, c4 instances on AWS).
",Example,"['Please add labels: ""Example"", ""Need Triage"" ', ""Please remove the label 'Need Triage'"", '@gautamkmr @sandeep-krishnamurthy please refrain from manually adding ""Need Triage"" label while triaging. Thanks.', ""@juliensimon just tested this out and I don't hit either of these issues.\r\n\r\nWith regards to Issue 1, there is logic to extract the number of layers from the network string for VGG (as with ResNet).\r\n\r\n```\r\nif 'vgg' in network:\r\n    num_layers = int(network.split('-')[1])\r\n```\r\n\r\nAnd for Issue 2, I tried `get_gpus()` on a CPU machine and due to the `except OSError` exception handling the function just returns an empty list which is expected behaviour of this function. In `benchmark_score.py` the cpu context is added.\r\n\r\nSo I think something must have been fixed since you filed this issue. But please do reopen if you're still hitting these issues."", '@indhub @yzhliu would appreciate if you could close this issue, many thanks!']",[],[],0,0
252,incubator-mxnet,2555,closed,OSError: exception: stack overflow,"recent problem... perhaps due to the recent changes in code.


",Bug,"['@freddycct Could you provide some code examples for us to debug?\n', 'hang on, i am compiling the latest commit, let me see if there are any problems...\n', 'i am still having this crash despite having the latest compiled codes. I will prepare some test data set and upload my code tomorrow. Thank you.\n', 'I hope you have scikit learn installed...\n\nPlease help me out here, you can see it crashes when I do the model.fit.\nUnzip and try, it is written in ipython notebook (jupyter notebook)\n\n[encoder_decoder.zip](https://github.com/dmlc/mxnet/files/338167/encoder_decoder.zip)\n\nmy specs: Windows 10, Visual Studio 2013, Python 3.5\n', 'If there is anyone working on it, please message me if you have any questions.\n', '@sxjscience Hi, can please run my code and see whether you encounter the same problem?\n', ""@freddycct I've run it and have got the same error. I'm trying to find out the cause.\n"", ""I've simplified the code a little bit. Only occurs for large graphs.\n\n``` python\nimport mxnet as mx\n\ndef sym_gen(length):\n    data = mx.sym.Variable('data')\n    wordvec = mx.sym.SliceChannel(data=data, num_outputs=length, squeeze_axis=1, axis=1)\n    hidden = mx.sym.Variable('init_hidden')\n    for i in range(length):\n        hidden = hidden + wordvec[i]\n    return hidden\nsym = sym_gen(length=20000)\ndel sym\n```\n\n`MXSymbolFree` has thrown the exception.\nhttps://github.com/dmlc/mxnet/blob/master/src/c_api/c_api.cc#L591-L595\n\nEdit:  Occurs on both windows and linux. We can change the length to a crazy number like 1000000 to make this happen.\n"", 'Thanks @sxjscience , I am happy to have made some contribution to this project by discovering a bug. I hope it will be resolved soon, so that I can continue with what I was doing.\n', '@freddycct You can remove the exception catch by replacing these two lines to `API_END_HANDLE_ERROR(delete static_cast<Symbol*>(symbol));`. The program can run after applying this hotfix.\n', ""Replace which two lines?\n\nDoes this fully fix the problem? I wouldn't want any memory leak...\n"", ""@freddycct I mean https://github.com/dmlc/mxnet/blob/master/src/c_api/c_api.cc#L593-L594. It doesn't fix the problem and only enables you to continue running the executors. Another way is to reduce the sequence length.\n"", 'The sequence length is due to the nature of my data. So I cannot reduce it. \n\nIs this is a bug within the C++ codes? If it can be addressed at the python side, I could help out. Otherwise ,the C++ codes are not very easy for me to understand and edit.\n\nMeanwhile, I will use the hotfix you suggested. Thank you.\n\nedit: I think the bug lies at the Symbol destructor, the function of the class destructor might be deleting something that does not exist, or has already been deleted...\n', ""@freddycct Yes, it's in the C++ and only occurs for large symbolic graphs. You can try Truncated BPTT for long sequences. Directly unfolding the whole sequence and performing forward/backward will be quite slow in this case.\n"", '@sxjscience Thank you for the suggestions. \n\nWhenever you are free, please continue to fix the bug at your convenience. Thank you.\n', ""I simplify the code further, nothing to do with sequence length\n\n```\nimport mxnet as mx\n\ndef sym_gen(length):\n    data = mx.sym.Variable('data')\n    hidden = mx.sym.Variable('hidden')\n    for i in range(length):\n        hidden = hidden + data\n    return hidden\nsym = sym_gen(length=20000)\ndel sym\n```\n"", 'This is an interesting problem that raises up. This was due to the usage of shared_ptr inside the symbol and the deletion triggered a chain of shared_ptr deletions, where the recursion of delete function call piles up and causes stack overflow. \n\nLike @sxjscience said, remove the delete of symbol might be a good temp solution to go. We will think of better alternatives for a safer destruction.\n\nThanks for finding this interesting case. Also  cc @mavenlin since it is interesting thing we need to address in pressure testing the graph. \n', 'should be fixed by https://github.com/dmlc/mxnet/pull/2586\n', 'Thanks for the fix, it works now...\n']","['\nException ignored in: <bound method Symbol.__del__ of <mxnet.symbol.Symbol object at 0x000001F0E408C6A0>>\nTraceback (most recent call last):\n  File ""C:\\Users\\chuaf\\AppData\\Local\\Continuum\\Miniconda3\\lib\\site-packages\\mxnet-0.7.0-py3.5.egg\\mxnet\\symbol.py"", line 106, in __del__\n    check_call(_LIB.MXSymbolFree(self.handle))\nOSError: exception: stack overflow\n']",[],0,0
253,incubator-mxnet,10012,closed,[Bug] There are two broken links on the top level README.md file which point to the old CI,"The top level README.md has two links to logos that point to builds.apache.org which is now deprecated. These must point to the new CI
This should be fixed similar to this PR - https://github.com/apache/incubator-mxnet/pull/9908
",Bug Doc,"['I think these icons were coming from this plugin: https://wiki.jenkins.io/display/JENKINS/Embeddable+Build+Status+Plugin\r\n\r\n@marcoabreu Do you know if the new CI has this plugin? If not, what is the effort involved in installing it?', '@indhub there you go: http://jenkins.mxnet-ci.amazon-ml.com/job/incubator-mxnet/job/master/badge/', ""Thanks, I'll create the PR."", 'Thanks a lot!', '@indhub can this be closed ?', 'Yes. This is fixed. ']",[],[],0,0
254,incubator-mxnet,11708,closed,test_ndarray.test_cached has fixed seed that can mask flakiness,"The unit test in title have been using fixed seed to mask flakiness. Suggested action:
1. Evaluate whether the test is flaky without fixed seed. If not, remove seed. Else move to 2
2. If test is flaky, determine whether it's an actual uncaught edge case. If so, fix the operator. Else move to 3
3. If numerical instability is inevitable, adjust tolerance level appropriately.
",Flaky Test,"['This test is tracked at #8049 already.', 'Closing as a duplicate of #8049 ']",[],[],0,0
255,incubator-mxnet,12377,closed,Flaky test: test_mkldnn.test_activation,"http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/1529/pipeline

",Disabled test Flaky MKLDNN Test,"['@luobao-intel please take a look for the reason.', ""This test is to validate the activation calculation in mkldnn by checking the gradient compared to the theano.gradient.numeric_grad. However, the activation gradient calculation of code  referring to theano is not correct with the input closed to zero.  Thus, flaky errors occurred when there are some extremely small positive numbers in the random input vector. \r\nThe experiment is as follows.\r\n\r\n## experiment 1:\r\n\r\ninput data :[[1, 2], [3, 0.0001]]\r\n\r\nlocation:\r\n{'data':\r\n<RowSparseNDArray 2x2 @cpu(0)>, '__random_proj':\r\n[[0.3546685  0.8954062 ]\r\n [0.40476447 0.7724642 ]]\r\n<NDArray 2x2 @cpu(0)>}\r\n\r\ngradient calculation referring to theano :\r\n[[0.35466552 0.8954048 ]\r\n [0.40476322 0.39395675]]\r\n\r\nmkldnn :\r\n[[0.3546685  0.8954062 ]\r\n [0.40476447 0.7724642 ]]\r\n\r\n## experiment 2:\r\ninput data :[[1, -2], [-4, 0.0005]]\r\n\r\nlocation:\r\n{'data':\r\n<RowSparseNDArray 2x2 @cpu(0)>, '__random_proj':\r\n[[0.3546685  0.8954062 ]\r\n [0.40476447 0.7724642 ]]\r\n<NDArray 2x2 @cpu(0)>}\r\n\r\ngradient calculation referring to theano :\r\n[[0.35466552 0.        ]\r\n [0.         0.4248553 ]]\r\n\r\nmkldnn :\r\n[[0.3546685 0.       ]\r\n [0.        0.7724642]]\r\n\r\n## analysis\r\nIt's easy to know that the derivative  of ReLU function is :\r\nif x < 0, output is 0. if x > 0, output is 1.\r\n\r\nTherefore, in the check_numeric_gradient function, the gradient of executor should be equal to location if the corresponding element of input data is positive and be 0 otherwise by element-wise. \r\nThe gradient based on theano is apparently false when the corresponding element of input data is close to zero. \r\n"", ""The reference checker applied the finite difference method but the eps is too large for float datatype in here. \r\nIn @luobao-intel case, the input data is about `xe-5`, so the eps can't calculate correctly.\r\nI suggest changing eps to `1e-6`. @luobao-intel will fill the PR soon.\r\n\r\nhttps://github.com/apache/incubator-mxnet/blob/e2a3eef349cb6643c08a7840d8cbd43b38fedfd5/python/mxnet/test_utils.py#L716\r\n\r\n"", 'Is failing again:\r\nhttp://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/1563/pipeline\r\n\r\n```\r\n======================================================================\r\nFAIL: test_mkldnn.test_activation\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File ""/usr/local/lib/python3.5/dist-packages/nose/case.py"", line 198, in runTest\r\n    self.test(*self.arg)\r\n  File ""/work/mxnet/tests/python/mkl/../unittest/common.py"", line 172, in test_new\r\n    orig_test(*args, **kwargs)\r\n  File ""/work/mxnet/tests/python/mkl/test_mkldnn.py"", line 298, in test_activation\r\n    check_activation_training(stype)\r\n  File ""/work/mxnet/tests/python/mkl/test_mkldnn.py"", line 294, in check_activation_training\r\n    check_numeric_gradient(test, in_location, numeric_eps=1e-6, rtol=0.16, atol=1e-4)\r\n  File ""/work/mxnet/python/mxnet/test_utils.py"", line 912, in check_numeric_gradient\r\n    (""NUMERICAL_%s""%name, ""BACKWARD_%s""%name))\r\n  File ""/work/mxnet/python/mxnet/test_utils.py"", line 491, in assert_almost_equal\r\n    raise AssertionError(msg)\r\nAssertionError: \r\nItems are not equal:\r\nError 1.153736 exceeds tolerance rtol=0.160000, atol=0.000100.  Location of maximum error:(0, 2, 1, 1), a=0.119209, b=0.146338\r\n NUMERICAL_data: array([[[[0.32782555, 0.52154064],\r\n         [0.32782555, 0.        ]],\r\n...\r\n BACKWARD_data: array([[[[0.31696534, 0.53385574],\r\n         [0.3415597 , 0.        ]],\r\n...\r\n-------------------- >> begin captured logging << --------------------\r\ncommon: INFO: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=304218922 to reproduce.\r\n--------------------- >> end captured logging << ---------------------\r\n```', 'sorry, I can\'t reproduce the same result with the same random seed XNET_TEST_SEED=304218922.\r\nIn my trial, the test_activation is ok.\r\nThe experiment is shown as follows:\r\n# experiment #\r\n## command ##\r\nexport MXNET_TEST_SEED=304218922\r\npython /usr/bin/nosetests tests/python/mkl/test_mkldnn.py:test_activation\r\n\r\n## log ##\r\n[INFO] Setting test np/mx/python random seeds, use MXNET_TEST_SEED=304218922 to reproduce.\r\n[22:51:22] src/operator/tensor/././../../common/utils.h:450:\r\nStorage type fallback detected:\r\noperator = Activation\r\ninput storage types = [row_sparse, ]\r\noutput storage types = [default, ]\r\nparams = {""act_type"" : relu, }\r\ncontext.dev_mask = cpu\r\nThe operator with default storage type will be dispatched for execution. You\'re seeing this warning message because the operator above is unable to process the given ndarrays with specified storage types, context and parameter. Temporary dense ndarrays are generated in order to execute the operator. This does not affect the correctness of the programme. You can set environment variable MXNET_STORAGE_FALLBACK_LOG_VERBOSE to 0 to suppress this warning.\r\n\r\nRan 1 test in 0.023s\r\n\r\nOK\r\n', 'Failing again - http://jenkins.mxnet-ci.amazon-ml.com/blue/rest/organizations/jenkins/pipelines/incubator-mxnet/branches/PR-12391/runs/9/nodes/951/log/?start=0\r\n\r\n```bash\r\n======================================================================\r\nFAIL: test_mkldnn.test_activation\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File ""/usr/local/lib/python3.5/dist-packages/nose/case.py"", line 198, in runTest\r\n    self.test(*self.arg)\r\n  File ""/work/mxnet/tests/python/mkl/../unittest/common.py"", line 172, in test_new\r\n    orig_test(*args, **kwargs)\r\n  File ""/work/mxnet/tests/python/mkl/test_mkldnn.py"", line 298, in test_activation\r\n    check_activation_training(stype)\r\n  File ""/work/mxnet/tests/python/mkl/test_mkldnn.py"", line 294, in check_activation_training\r\n    check_numeric_gradient(test, in_location, numeric_eps=1e-6, rtol=0.16, atol=1e-4)\r\n  File ""/work/mxnet/python/mxnet/test_utils.py"", line 912, in check_numeric_gradient\r\n    (""NUMERICAL_%s""%name, ""BACKWARD_%s""%name))\r\n  File ""/work/mxnet/python/mxnet/test_utils.py"", line 491, in assert_almost_equal\r\n    raise AssertionError(msg)\r\nAssertionError: \r\nItems are not equal:\r\nError 1.184596 exceeds tolerance rtol=0.160000, atol=0.000100.  Location of maximum error:(0, 0, 1, 0), a=0.715256, b=0.882672\r\n NUMERICAL_data: array([[[[0.        , 0.        ],\r\n         [0.71525574, 0.        ]],\r\n...\r\n BACKWARD_data: array([[[[0.        , 0.        ],\r\n         [0.8826717 , 0.        ]],\r\n...\r\n-------------------- >> begin captured logging << --------------------\r\ncommon: INFO: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=1731055743 to reproduce.\r\n--------------------- >> end captured logging << ---------------------\r\n```', 'Sorry for that, in previous situation, we confronted the situation that element of input data is close to zero.\r\nAnd we found that the extremely big  difference step, eps, should be blamed. And we turned its value down. However, in current situation, test failure is caused by the small eps for the big  element of  input data.  The smaller the eps is, the more calculation steps are required. And for big input data, every step could cause small error and finally the cumulative error may exceed the limit. Thus, suitable eps should be picked. \r\n\r\nAfter all, those problems are caused by the inaccurate baseline calculation referring to the theano gradient. We are trying to rewrite the test case with other approaches. I suggest to disable the flaky test for the time being.', 'PR to disable the test again: https://github.com/apache/incubator-mxnet/pull/12516', 'made a PR that addresses just this test (ran 10000 times with different seeds as well) https://github.com/apache/incubator-mxnet/pull/12560.\r\n\r\nin regards to @luobao-intel , this is not due to inputs being too large. activation is linear above 0 so this is not due to lack of approximation. in fact we should be able to get an exact solution. the reason the change is causing an error is the fact that with a very small eps the outputs (f(x + eps/2) and f(x - eps/2)) do not have enough precision.\r\n\r\nthe formula is \r\n\r\n```\r\ngrad = (f(x + eps/2)  - f(x - eps/s)) / eps).\r\n```\r\n\r\nsince eps was 1e-6 this means the gradient was calculated by differences must be captured below 1e-6.', 'tldr: you should never use anything less than 1e-5 as there is not enough precision in the numerator (f(x + eps/2)  - f(x - eps/s)) to derive an accurate slope.', 'Has been fixed with https://github.com/apache/incubator-mxnet/pull/12418', 'Sorry, probably this is the fix: https://github.com/apache/incubator-mxnet/pull/12560']","['\r\n======================================================================\r\nFAIL: test_mkldnn.test_activation\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File ""/usr/local/lib/python3.5/dist-packages/nose/case.py"", line 198, in runTest\r\n    self.test(*self.arg)\r\n  File ""/work/mxnet/tests/python/mkl/../unittest/common.py"", line 172, in test_new\r\n    orig_test(*args, **kwargs)\r\n  File ""/work/mxnet/tests/python/mkl/test_mkldnn.py"", line 297, in test_activation\r\n    check_activation_training(stype)\r\n  File ""/work/mxnet/tests/python/mkl/test_mkldnn.py"", line 293, in check_activation_training\r\n    check_numeric_gradient(test, in_location, numeric_eps=1e-2, rtol=0.16, atol=1e-4)\r\n  File ""/work/mxnet/python/mxnet/test_utils.py"", line 912, in check_numeric_gradient\r\n    (""NUMERICAL_%s""%name, ""BACKWARD_%s""%name))\r\n  File ""/work/mxnet/python/mxnet/test_utils.py"", line 491, in assert_almost_equal\r\n    raise AssertionError(msg)\r\nAssertionError: \r\nItems are not equal:\r\nError 2.232502 exceeds tolerance rtol=0.160000, atol=0.000100.  Location of maximum error:(0, 0, 0), a=0.445562, b=0.693506\r\n NUMERICAL_data: array([[[0.44556212, 0.2619341 , 0.77837706],\r\n        [0.        , 0.8214429 , 0.5259812 ],\r\n        [0.        , 0.        , 0.        ]],...\r\n BACKWARD_data: array([[[0.693506  , 0.26193386, 0.77837765],\r\n        [0.        , 0.8214439 , 0.52598166],\r\n        [0.        , 0.        , 0.        ]],...\r\n-------------------- >> begin captured logging << --------------------\r\ncommon: INFO: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=1284728931 to reproduce.\r\n--------------------- >> end captured logging << ---------------------\r\n']",[],0,0
256,incubator-mxnet,9758,closed,unknown output shape before inference,"I want to write a custom operation in python, the output shape is unknown before running 'forward()'. So how to write the 'infer_shape()' function? It seems I must infer the output shape from the input shape, but without the input data. ",,"[""Yes, during the phase of `infer_shape` we cannot access the input data. After `infer_shape` we can run the computation graph with input data.\r\n\r\nIf your operator's output has a maximum shape, I think there is a work around with gluon. `infer_shape` of your operator can return two shapes, the predefined maximum shape and a one dimension shape holding the actual size of your output,\r\n\r\n```\r\noutput, size = custom_op(...)\r\nactual_size = size.asscalar()\r\noutput = output.reshape(-1)[ : actual_size]\r\n```"", 'Here is a relevant issue with dynamic shape, https://github.com/apache/incubator-mxnet/issues/8822.', ""@ZiyueHuang  Thank you for your response. \r\nThere is a maximum shape of my operator's output. Did you mean the output and actual size `output, size` are two output symbols of my operator? If it is, I got an error from `asscalar()`:\r\n`NotImplementedForSymbol: Function asscalar is not implemented for Symbol and only available in NDArray.`\r\nSo is there any way to deal with the symbolic operator?"", '@cccorn - Asking usability questions at discuss - https://discuss.mxnet.io/ will yield faster response.', '@sandeep-krishnamurthy : Tag it to label ""question"" and can be closed.']",[],[],0,0
257,incubator-mxnet,1306,closed,How to make a smooth kernel in Convolution Neural Networks?,"Hello everyone,

My datasets is MNIST, I used the CNN algorithm to practice ML.

And I found the reference tutorial, [page 6 and 7](http://web.pdx.edu/~jduh/courses/Archive/geog481w07/Students/Ludwig_ImageConvolution.pdf).

<img width=""569"" alt=""2016-01-18 5 06 26"" src=""https://cloud.githubusercontent.com/assets/6274807/12387422/62b5a3e2-be07-11e5-8096-75c6f40987bc.png"">

I guess the default kernel is all '1' instances in a matrix. How to make the smoothly kernel like above slide.

This is the MXNet code with R.



Best,
Salmon.
",,"['you can init the kernel of convolution manually. And keep it invariant during the train.\n', ""@zhangchen-qinyinghua  thanks for your reply. How could I set the initial kernel in MXNet? I didn't find it in document.\n"", 'In python, I think it should be write in this way but I don\'t test yet. This is just a pseudo code. \n\n```\n# real param\ndata_nd = ...\nw_np = np.ones((3, 3)).reshape((1, 1, 3, 3))\nw_nd = mx.nd.array(w_np)\n# symbol\ndata = mx.sym.Variable(""data"")\nweight = mx.sym.Variable(""weight"")\nconv = mx.symbol.Convolution(data=data, weight=weight, no_bias=True, kernel=(3,3), num_filter=1, num_group=3) \n# note cudnn doesn\'t support group\n# alternative: use mx.sym.SplitChannel\n# bind\nexecutor = conv.bind(ctx=mx.cpu(), args={""data"":data_nd, ""weight"": w_nd}, args_grad=None, reqs=None)\n```\n']","['\nmx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)\n']",[],0,0
258,incubator-mxnet,5590,closed,callbacks destroy 'value' in BatchEndParam for subsequent callbacks of that type,"It appears that calling one callback seem destroy the value in BatchEndParam.

Using callbacks like:


Results in the following log:

> INFO:root:Epoch[0] Batch [10]   Speed: 60.70 samples/sec        Train-accuracy=0.122869
> INFO:root:Epoch[0] Batch [20]   Speed: 60.85 samples/sec        Train-accuracy=0.157031
> INFO:root:Epoch[0] Batch [20]   Speed: 61.00 samples/sec        Train-accuracy=nan
> INFO:root:Epoch[0] Batch [30]   Speed: 61.01 samples/sec        Train-accuracy=0.164844
> INFO:root:Epoch[0] Batch [40]   Speed: 61.20 samples/sec        Train-accuracy=0.191406
> INFO:root:Epoch[0] Batch [40]   Speed: 61.39 samples/sec        Train-accuracy=nan
> INFO:root:Epoch[0] Batch [50]   Speed: 60.78 samples/sec        Train-accuracy=0.194531
> INFO:root:Epoch[0] Batch [60]   Speed: 60.84 samples/sec        Train-accuracy=0.221875
> INFO:root:Epoch[0] Batch [60]   Speed: 60.90 samples/sec        Train-accuracy=nan",,"['@jmerkow it has been reset.', '@zihaolucky Do you know where this is happening? ', 'I guess\r\n\r\nhttps://github.com/dmlc/mxnet/blob/master/python/mxnet/metric.py#L43-L50\r\n\r\nhttps://github.com/dmlc/mxnet/blob/master/python/mxnet/module/base_module.py#L462\r\n\r\nhttps://github.com/dmlc/mxnet/blob/master/python/mxnet/module/base_module.py#L485-L488']","['\r\n    batch_end_callbacks = [mx.callback.Speedometer(args.batch_size, 20),\r\n                           mx.callback.Speedometer(args.batch_size, 10)]\r\n']",[],0,0
259,incubator-mxnet,11897,closed,why fixed_param_names in module have no use,"i want to fixed all the layer's parameter  befor 'fc7'layer,and i change the code like this:


but when i run using pretrained model ,and save a checkpoint after one epoch,,,i compare the model and the pretrained model,,,i find that the layers' parameters before 'fc7'layer also changed,,,i don't know why,,,can anyone please help me.",,"[""I think you can try to fix the layers' parameters before 'fc7' layer.\r\nfc7 = sym.get_internals()['fc7_output']\r\nname_list = fc7.list_arguments()"", '@lmmcc Thanks for using MXNet. For how to and usability questions, you can use MXNet discuss forum - https://discuss.mxnet.io/ where there are more people who can answer your query. We want to use Github issues mainly for bugs and feature request.\r\n\r\nClosing the issue here. Please reopen if you are finding any issues.', 'ok,thanks very much', ""@wkcn yes,i use your method,and the parameter is fixed..but when i use the new trained model to extract feature using layer 'fc1' which is before fc7 layer，the result is different from the pre-trained one ,it is so strange....and i use modle-slim.py to get the same layer betweent these two models...the *.param files is diff......their parameters is same...then which part is different......."", ""@lmmcc \r\nIt seems that the parameters' name in *.param files may not match that of the models.\r\n\r\nWhen you fine-tune the model or check the difference between *.param files, the parameters are re-initiallized. I remember that the random seed is fixed in MXNet, so the parameters are the same.\r\n\r\nYou can try to add the parameter `allow_missing = False` in `model.fit`"", ""@wkcn  if I use the `allow_missing = False in model.fit` how can i change the 'fc7' layers' class number....which i want to do is using a small number of training data to finetune the pre-trained model which is good enough to extract feature."", ""@lmmcc The function `mxnet.model.load_checkpoint` will return symbol, arg_params, aux_params\r\nYou could change `arg_params`, e.g. `arg_params['fc7_weight'] = mx.random.normal(0, 0.01, (input_size, num_classes))`\r\n\r\nThen pass `arg_params` and `aux_params` as the parameters of `model.fit`\r\n\r\nI think it's better to check the pre-trained model first."", 'hey,did you deal with the problem? I want to fix the params before fc1  that are used to extract features, and only train the new fc layers. I used two methods , fixed_param_names and  sgd.set_lr_mult, but both didnt work @wkcn @lmmcc ', '@Achhhe Hi. [Issue #9511](https://github.com/apache/incubator-mxnet/issues/9511) may be helpful.\r\nYou need to set the variable `idx2name`.', ""@wkcn thx for help, I have delt with the problem by fixed_param_names. The reason why the method didn't work is momentum=0.9 in BN, after I set the momentum=1 in BN, the params are fixed""]",[],"[""name_list=[name for name in sym.list_arguments() if 'fc7' not in name]\r\n    print(name_list)\r\n    #label_name = 'softmax_label'\r\n    #label_shape = (args.batch_size,)\r\n    model = mx.mod.Module(\r\n        context       = ctx,\r\n        symbol        = sym,\r\n        #fixed_param_names=name_list\r\n    )""]",0,0
260,incubator-mxnet,13274,closed,R test failing intermitently,"## Description
R test failing intermitently

## Environment info (Required)
Test failing on CI and could be flaky

For R user, please provide R :

http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-13266/1/pipeline

Have been observing above behavior on multiple PRs
",CI Flaky R,"['@mxnet-label-bot add [R, Flaky, CI]\r\n\r\n', 'Another PR with similar failure - https://github.com/apache/incubator-mxnet/pull/13256', 'Additional failure http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-13364/3/pipeline on https://github.com/apache/incubator-mxnet/pull/13358', 'Duplicate issue https://github.com/apache/incubator-mxnet/issues/13439\r\n\r\nCan we close this in favor of the above issue?  @nswamy ', 'Closing issue in favor of https://github.com/apache/incubator-mxnet/issues/13439']",[],['sessionInfo()'],0,0
261,incubator-mxnet,3758,closed,Windows 10 Pro & MXNET GPU (For R Environment),If someone here has successfully installed the GPU version of MXNET (gpu version for R) could please post instructions....the instructions for install do not work... ,,"['https://github.com/dmlc/mxnet/issues/3644#issuecomment-258770447\n\nScroll to the bottom\n', 'We were able to build it!!! Now running with Titan X.\nWill post detailed instructions for build under Windows 10 in short order.....\n']",[],[],0,0
262,incubator-mxnet,8042,closed,Convert network written in json format to mxnet symbol code?,"Hai,

Is there is any utility which converts network written in mxnet  *.json format to mxnet symbols level code? Any options are available kindly let us know.",HowTo,"['In python, ""mxnet.symbol.load_json()"" can load a json str to a mxnet symbol\r\n![image](https://user-images.githubusercontent.com/13029886/30890701-068c90d0-a361-11e7-813f-eab5c094a30f.png)\r\n', ""The 'convert_symbol.py' tool in 'tools\\caffe_converter' can convert the protobuf of caffe to python code of mxnet and then execute the created code to establish symbol graph and save to json. You can draw inspiration from that."", '@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', 'https://github.com/Imshepherd/MxNetR-Convert-json-to-symbol\r\nExample code which I wrote for R.', '@chowkamlee81 there is no such utility I am afraid. It would be great to be able to do that, getting the code generated from a symbol definition or also for an ONNX model for example.\r\n\r\n@sandeep-krishnamurthy can you please close this issue or convert it to Feature Request? Thanks!']",[],[],0,0
263,incubator-mxnet,2732,closed,R: How to limit mxnet to one cpu core?,"How do I limit  using  to only use one cpu core on a multicore machine in R?
",,"['The multicore usage can be from two points: (1) multithreading blas, like openblas; (2) openmp.\n\nYou can check your configuration and close them.\n']",[],"['mx.model.FeedForward.create', 'ctx = mx.cpu()']",0,0
264,incubator-mxnet,4029,closed,One vs All Classification,"Hi,

I'm using a CNN in R to perform image classification with K different classes. However, I want to try another approach and do a ""one vs all"" classification with each label, so one label would be 1 and the rest would be 0.

My question is, what output layer should I use? If I use mx.symbol.SoftmaxOutput after a FullyConnected layer with one neuron is useless because it always predict 1 or even NaN for every example. LinearRegressionOutput gives a similar result.

My basic idea is that I need an output layer that performs 0.5 threshold on the single output neuron from the last FullyConnected layer.

Sorry if this is a dumb question, I'm still new to this field.
Thanks in advanced.",,"['LogisticRegressionOutput', '@piiswrong Exactly what I was looking for, it worked like a charm. Thank you very much!', 'hi @piiswrong \r\n\r\nThanks for the answer, exactly what i am looking for.\r\n\r\nJust want to add a nab question following this issue:\r\n- which metric would be best suited for this kind of 1 vs all classification problem.\r\n\r\nI suppose standard accuracy is not good because of the big difference in the number of samples from the two classes.', 'Hi @yuan1202 ,\r\n\r\nI think I may have an answer for you. During the training phase, I just use the rmse metric, but for further analysis I do the following:\r\n\r\nFirst, I make a prediction using the test set, and afterwards I analyse all the different metrics you can obtain from the confusion matrix (as you can see [here](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)). Also, you may be interested in the F1 Score metric.\r\n\r\nI hope this is what you were looking for.', ""Hey @CarlosUziel \r\n\r\nThank you for the reply.\r\n\r\nI will try out your approach.\r\n\r\nI have a rather biased binary class situation where 0 class to 1 class ratio is about 19:1. But I suppose it's similar for all one vs all situation.\r\n\r\nWhen I just use default accuracy metric the result is around 95% which seems not right to me because it's too close to the 19:1 ratio.\r\n\r\nI tried to use F1 score but it's constantly stuck at 0.000000 no matter the number of epoch or output layer being SoftmaxOutput or LogisticRegressionOutput. So I am no sure where I got it wrong.\r\n\r\n\r\n\r\n"", 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
265,incubator-mxnet,2506,closed,caffe_converter resnet error batchnorm,"Exception: Unknown Layer BatchNorm!
",,['This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!'],[],[],0,0
266,incubator-mxnet,16937,closed,[Numpy] Zero-size tensor add zero-size sum raises exception,"## Description

Very weird problem:

Expected output:




What deepNumpy outputs:







",Bug,[],"['python\r\nimport numpy as onp\r\na = onp.ones((3,4))\r\nb = onp.ones((3,3,4))\r\na[:, :0] += b[:, :0].sum(-1)\r\nprint(a)\r\n', '\r\n[[1. 1. 1. 1.]\r\n [1. 1. 1. 1.]\r\n [1. 1. 1. 1.]]\r\n', 'python\r\nfrom mxnet import np, npx\r\nnpx.set_np()\r\na = np.ones((3,4))\r\nb = np.ones((3,3,4))\r\na[:, :0] += b[:, :0].sum(-1)\r\nprint(a)\r\n', 'python\r\nMXNetError                                Traceback (most recent call last)\r\n<ipython-input-57-ed8f66a38679> in <module>\r\n      2 b = np.ones((3,3,4))\r\n      3 a[:, :0] += b[:, :0].sum(-1)\r\n----> 4 print(a)\r\n\r\n~/mxnet_master_develop/python/mxnet/numpy/multiarray.py in __str__(self)\r\n    929     def __str__(self):\r\n    930         """"""Returns a string representation of the array.""""""\r\n--> 931         array_str = self.asnumpy().__str__()\r\n    932         context = self.ctx\r\n    933         if context.device_type == \'cpu\' or self.ndim == 0:\r\n\r\n~/mxnet_master_develop/python/mxnet/ndarray/ndarray.py in asnumpy(self)\r\n   2550             self.handle,\r\n   2551             data.ctypes.data_as(ctypes.c_void_p),\r\n-> 2552             ctypes.c_size_t(data.size)))\r\n   2553         return data\r\n   2554 \r\n\r\n~/mxnet_master_develop/python/mxnet/base.py in check_call(ret)\r\n    276     """"""\r\n    277     if ret != 0:\r\n--> 278         raise MXNetError(py_str(_LIB.MXGetLastError()))\r\n    279 \r\n    280 \r\n\r\nMXNetError: [10:12:44] /home/ubuntu/mxnet_master_develop/include/mxnet/././tensor_blob.h:198: Check failed: this->shape_.Size() == shape.Size() (0 vs. 1) : Shape size mismatch 0 v.s. 1\r\nStack trace:\r\n  [bt] (0) /home/ubuntu/mxnet_master_develop/python/mxnet/../../build/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x32) [0x7fc85352bd52]\r\n  [bt] (1) /home/ubuntu/mxnet_master_develop/python/mxnet/../../build/libmxnet.so(mxnet::TBlob::reshape(mxnet::TShape const&) const+0x140) [0x7fc8539d1570]\r\n  [bt] (2) /home/ubuntu/mxnet_master_develop/python/mxnet/../../build/libmxnet.so(void mxnet::op::ReduceAxesComputeImpl<mshadow::cpu, mxnet::op::mshadow_op::sum, false, false, mxnet::op::mshadow_op::identity>(mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, mxnet::TShape const&)+0x2255) [0x7fc85695c105]\r\n  [bt] (3) /home/ubuntu/mxnet_master_develop/python/mxnet/../../build/libmxnet.so(void mxnet::op::NumpyReduceAxesCompute<mshadow::cpu, mxnet::op::mshadow_op::sum, true, false, mxnet::op::mshadow_op::identity>(nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)+0x239) [0x7fc8569af0e9]\r\n  [bt] (4) /home/ubuntu/mxnet_master_develop/python/mxnet/../../build/libmxnet.so(mxnet::imperative::PushFCompute(std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)> const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<unsigned int, std::allocator<unsigned int> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&)::{lambda(mxnet::RunContext)#1}::operator()(mxnet::RunContext) const+0x2a6) [0x7fc855ff97f6]\r\n  [bt] (5) /home/ubuntu/mxnet_master_develop/python/mxnet/../../build/libmxnet.so(std::_Function_handler<void (mxnet::RunContext), mxnet::imperative::PushFCompute(std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)> const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<unsigned int, std::allocator<unsigned int> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&)::{lambda(mxnet::RunContext)#1}>::_M_invoke(std::_Any_data const&, mxnet::RunContext&&)+0x17) [0x7fc855ff9a47]\r\n  [bt] (6) /home/ubuntu/mxnet_master_develop/python/mxnet/../../build/libmxnet.so(+0x413328e) [0x7fc855f2f28e]\r\n  [bt] (7) /home/ubuntu/mxnet_master_develop/python/mxnet/../../build/libmxnet.so(mxnet::engine::ThreadedEngine::ExecuteOprBlock(mxnet::RunContext, mxnet::engine::OprBlock*)+0x5cf) [0x7fc855f3b4cf]\r\n  [bt] (8) /home/ubuntu/mxnet_master_develop/python/mxnet/../../build/libmxnet.so(std::_Function_handler<void (std::shared_ptr<dmlc::ManualEvent>), mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::{lambda()#1}::operator()() const::{lambda(std::shared_ptr<dmlc::ManualEvent>)#1}>::_M_invoke(std::_Any_data const&, std::shared_ptr<dmlc::ManualEvent>&&)+0x118) [0x7fc855f3ea98]\r\n\r\n']",[],0,0
267,incubator-mxnet,715,closed,Could we give one text classification example ?,"Say like binary classification  example , where each instance is sparse .
",,"['I think mxnet currently is not able to handle general sparse matrix yet. You will probably have to convert each mini-batch data into dense matrix.\n', '@pluskid  I see thanks! But that will make  sparse matrix vector multiplication too slow..\n']",[],[],0,0
268,incubator-mxnet,919,closed,Sparse Operators should be on the formal schedule,"Such as convolution, sometimes we don't need do it on all the image but only on small and sparse places.
Sparse operation can avoid unnecessary calculations. It can improve the performance on the ARM or CPU drastically.
",,"[""I don't know what you are trying to do exactly but looks like the optimal implementation will depend on your use case. You are welcome to open a PR for this.\n"", 'I guess you mean this one? Support Sparse Matrix Input #773 \n', 'move to https://github.com/dmlc/mxnet/issues/773\n', 'thanks.\n']",[],[],0,0
269,incubator-mxnet,2763,closed,how can i get the shape of a certain symbol,"Hi all,
        I want to get the shape of a certain symbol, take a look at the following code:



How can I get the shape of ?

I know for symbol, one can use  to get the shape of symbols.
But in this situation,  will return a list of shapes, which respect to all the symbol before the node of  in the compute symbol graph, say. As I want to get the shape of , and the order in  is uncertain, one can not get the expected symbol shape he wants.

Is there some solutions for this problem?
",,"['``` python\ndef infer_shape(self, *args, **kwargs):\n        """"""Infer the shape of outputs and arguments of given known shapes of arguments.\n\n        User can either pass in the known shapes in positional way or keyword argument way.\n        Tuple of Nones is returned if there is not enough information passed in.\n        An error will be raised if there is inconsistency found in the known shapes passed in.\n\n        Parameters\n        ----------\n        *args :\n            Provide shape of arguments in a positional way.\n            Unknown shape can be marked as None\n\n        **kwargs :\n            Provide keyword arguments of known shapes.\n\n        Returns\n        -------\n        arg_shapes : list of tuple or None\n            List of shapes of arguments.\n            The order is in the same order as list_arguments()\n        out_shapes : list of tuple or None\n            List of shapes of outputs.\n            The order is in the same order as list_outputs()\n        aux_shapes : list of tuple or None\n            List of shapes of outputs.\n            The order is in the same order as list_auxiliary()\n        """"""\n```\n\ndocument explains the order\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[' python\nsymbol_a = mxnet.symbol.operator1(data=xxx)\nsymbol_b = mxnet.symbol.operator2(data=symbol_a)\nsymbol_c = mxnet.symbol.operator3(data=symbol_c)\n'],"['symbol_b', 'infer_shape', 'symbol_b.infer_shape', 'symbol_b', '[(shape of symbol_a), (shape of symbol_b)]', 'symbol_b', '[(shape of symbol_a), (shape of symbol_b)]']",0,0
270,incubator-mxnet,5258,closed,Embedding layer doesn't support calculate data gradient,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
ubuntu15.10
Compiler:
gcc-4.9x
Package used (Python/R/Scala/Julia):
python
MXNet version:
0.9.4
Or if installed from source:
yes
MXNet commit hash ():
be38c5b84030a63d0ab51f19737f99a75a7feb23
If you are using python package, please provide

Python version and distribution:
python2.7
If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

following code is caption_module:  


I just use pretrain-vgg to extract fc-layer ouputs, and then input them into caption module name , I create custom-dataIter, process them by vgg and then copy them into .
However, it raises above error all the time.
## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.
2.
3.

## What have you tried to solve it?

1.Try to pop item in  about 
2.Use Module API, and bind symbol.
3.
",,"['Data is discrete. Embedding is non-differentiable wrt data', 'Thanks, by the way, what should I do to avoid the error? Write embedding layer outside of caption module? 发自网易邮箱大师 在2017年03月06日 04:19，Eric Junyuan Xie 写道： Data is discrete. Embedding is non-differentiable wrt data — You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.', ""@saicoco Change the line `word_embed = mx.sym.Embedding(data=seq, input_dim=vocab_size, output_dim=num_embed, name='seq_embed')` to\r\n`word_embed = mx.sym.Embedding(data=mx.sym.BlockGrad(seq), input_dim=vocab_size, output_dim=num_embed, name='seq_embed')`"", '@sxjscience It works~~, I just know `BlockGrad` which can get the outputs of symbol, too naive...`BlockGrad=Block The Grad of Sym`, Thanks  for your second help!']","[""\r\nsrc/operator/tensor/./indexing_op.h:227: Check failed: req[embedding::kData] == kNullOp (3 vs. 0) \r\nEmbedding layer doesn't support calculate data gradient\r\n\r\n"", ""python\r\n    cnn_shapes = {\r\n        'image_data': (batch_size, 3, 224, 224)\r\n    }\r\n    cnn_sym = vgg16_fc7('image_data')\r\n    cnn_exec = cnn_sym.simple_bind(ctx=ctx, is_train=False, **cnn_shapes)\r\n    lstm = caption_module(num_lstm_layer=num_lstm_layer, seq_len=train_data.sent_length,\r\n                          vocab_size=train_data.vocab_size, num_hidden=num_hidden, num_embed=num_embed, batch_size=batch_size)\r\n    lstm_shapes = {\r\n        'image_feature': (batch_size, 4096),\r\n        'word_data': (batch_size, train_data.sent_length),\r\n        'softmax_label': (batch_size, train_data.sent_length)\r\n    }\r\n\r\n    lstm_exec = lstm.simple_bind(\r\n        ctx=ctx, is_train=True, grad_req='add', **lstm_shapes)\r\n\r\n    # init params\r\n    pretrain = mx.nd.load(config.vgg_pretrain)\r\n    init_cnn(cnn_exec, pretrain)\r\n\r\n    # init optimazer\r\n    optimazer = mx.optimizer.create('sgd')\r\n    optimazer.lr = learning_rate\r\n    updater = mx.optimizer.get_updater(optimazer)\r\n\r\n    # init metric\r\n    perplexity = mx.metric.Perplexity(ignore_label=-1)\r\n    perplexity.reset()\r\n\r\n    # callback\r\n    callbacks = collections.namedtuple('callbacks', 'nbatch eval_metric epoch')\r\n    params = callbacks(nbatch=len(train_data.idx)//batch_size, eval_metric=perplexity, epoch=epoches)\r\n    speedometer = mx.callback.Speedometer(batch_size=batch_size, frequent=20)\r\n    for epoch in range(epoches):\r\n        for i, batch in enumerate(train_data):\r\n\r\n            # cnn forward, get image_feature\r\n            cnn_exec.arg_dict['image_data'] = batch.data[0]\r\n            cnn_exec.forward()\r\n            image_feature = cnn_exec.outputs[0]\r\n\r\n            # lstm forward\r\n            lstm_exec.arg_dict['image_feature'] = image_feature\r\n            lstm_exec.arg_dict['word_data'] = batch.data[1]\r\n            lstm_exec.arg_dict['softmax_label'] = batch.label\r\n\r\n            # update lstm grad\r\n            for key, arr in lstm_exec.grad_dict.items():\r\n                arr[:] = 0.\r\n            \r\n            lstm_exec.forward(is_train=True)\r\n            params.eval_metric.update(labels=batch.label,\r\n                              preds=lstm_exec.outputs)\r\n            if 'word_data' in lstm_exec.grad_dict.keys():\r\n                lstm_exec.grad_dict.pop('word_data')\r\n                lstm_exec.arg_dict.pop('word_data')\r\n            lstm_exec.backward()\r\n            speedometer(params)\r\n\r\n            for j, name in enumerate(lstm.list_arguments()):\r\n                if name not in lstm_shapes.keys():\r\n                    updater(j, lstm_exec.grad_dict[name], lstm_exec.arg_dict[name])\r\n"", ""python\r\ndef caption_module(num_lstm_layer, seq_len, vocab_size, num_hidden, num_embed, batch_size, dropout=0.):\r\n\r\n    seq = mx.sym.Variable('word_data')\r\n    label = mx.sym.Variable('softmax_label')\r\n    image_feature = mx.sym.Variable('image_feature')\r\n    image_embed = mx.sym.FullyConnected(data=image_feature, num_hidden=num_embed, name='img_embed')\r\n    word_embed = mx.sym.Embedding(data=seq, input_dim=vocab_size, output_dim=num_embed, name='seq_embed')\r\n\r\n    # Concat image_embed with word_embed in axis=1 (batch_size, length+1, num_hidden)\r\n    image_embed_reshape = mx.sym.expand_dims(image_embed, axis=1, name='image_embed_expand_dims')\r\n    embedd_feature = mx.sym.Concat(image_embed_reshape, word_embed, num_args=2, dim=1, name='embed_concat')\r\n\r\n    stack = mx.rnn.SequentialRNNCell()\r\n    for i in range(num_lstm_layer):\r\n        stack.add(mx.rnn.LSTMCell(num_hidden=num_hidden, prefix='lstm_l%d_' % i))\r\n    outputs, states = stack.unroll(length=seq_len+1, inputs=embedd_feature, merge_outputs=True)\r\n\r\n    outputs_crop = mx.sym.crop(outputs, begin=(0, 1, 0), end=(batch_size, seq_len+1, num_embed))\r\n    pred = mx.sym.Reshape(outputs_crop, shape=(-1, num_hidden))\r\n    pred = mx.sym.FullyConnected(pred, num_hidden=vocab_size, name='pred_fc')\r\n    label = mx.sym.Reshape(label, shape=(-1,))\r\n    softmax_output = mx.sym.SoftmaxOutput(data=pred, label=label, name='softmax')\r\n    return softmax_output\r\n""]","['git rev-parse HEAD', 'sessionInfo()', 'image_feature', 'image_feature', 'grad_dict', 'word_data']",0,0
271,incubator-mxnet,12523,closed,"Updates to tutorial ""Run MXNet Scala Examples Using the IntelliJ IDE (macOS)""","## Description
There are some minor problems with the [scala intellij tutorial](https://mxnet.incubator.apache.org/tutorials/scala/mxnet_scala_on_intellij.html) with code [here](https://github.com/apache/incubator-mxnet/blob/master/docs/tutorials/scala/mxnet_scala_on_intellij.md) that could be fixed to improve the experience for new users following the tutorial.

## Issues

- When I added the MXNet package as a dependency to the pom.xml by copying the XML from the tutorial, the package version specified (1.2.0) could not be found with Intellij notification error .  Updating the version to 1.2.1 fixed this issue.
- With the initial code, the sample specification file specs.scala is missing a dependency. It causes an error when trying to run the app on step 6
- When running, the following warning shows up: 

  I was able to resolve it by adding the org.slf4j api and log4j12 dependencies: 

- The tutorial should additionally include the file target/classes/log4j.properties
- It might be worth including a note for users building mxnet scala from source that they can use the scala mxnet they built as opposed to the version from maven by changing the pom.xml.  For me (and my SystemPath including my user), it looks like:


## Environment info (Required)
floatnp.floatingnp.float64 == np.dtype(float).type

Package used (Python/R/Scala/Julia):
Scala

For Scala user, please provide:
1. Java version: ()

2. Maven version: ()

3. Scala runtime if applicable: ()
Specified in pom.xml as 2.11.8 (scala.compat.version 2.11)

MXNet commit hash:
ac4ef212f6269469f3f3827da49e43fb42f1398f

@mxnet-label-bot[Doc, Scala]",Doc Scala,"['Thanks for submitting this issue @zachgk \r\n@mxnet-label-bot[Doc, Scala]', ""@lanking520 I had run into this issue before and had a similar resolution. I can't recall why these logger imports were removed from the tutorial. What can be done to make this easier and not throw errors?\r\n\r\nAlso, on a similar note, when building the scalapkg for docs there are a lot of these errors, and it would be nice if they went away... Here's just one example:\r\n\r\n```\r\n./core/src/main/scala/org/apache/mxnet/Callback.scala:20: error: object slf4j is not a member of package org\r\nimport org.slf4j.{Logger, LoggerFactory}\r\n           ^\r\n```"", '@zachgk could you please submit a PR since you already know what needs to be fixed. thanks.', 'Added PR #12827 ', 'Closing since PR #12827 was merged']","['\r\nSLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".\r\nSLF4J: Defaulting to no-operation (NOP) logger implementation\r\nSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\r\n', '\r\n    <dependency>\r\n      <groupId>org.slf4j</groupId>\r\n      <artifactId>slf4j-api</artifactId>\r\n      <version>${slf4jVersion}</version>\r\n    </dependency>\r\n    <dependency>\r\n      <groupId>org.slf4j</groupId>\r\n      <artifactId>slf4j-log4j12</artifactId>\r\n      <version>${slf4jVersion}</version>\r\n    </dependency>\r\n', '\r\n    <dependency>\r\n      <groupId>org.apache.mxnet</groupId>\r\n      <artifactId>mxnet-full_${scala.binary.version}-${platform}</artifactId>\r\n      <version>1.3.0</version>\r\n      <scope>system</scope>\r\n      <systemPath>/Users/kimbergz/Projects/incubator-mxnet/scala-package/assembly/osx-x86_64-cpu/target/mxnet-full_2.11-osx-x86_64-cpu-1.3.0-SNAPSHOT.jar</systemPath>\r\n    </dependency>\r\n', '\r\njava version ""1.8.0_181""\r\nJava(TM) SE Runtime Environment (build 1.8.0_181-b13)\r\nJava HotSpot(TM) 64-Bit Server VM (build 25.181-b13, mixed mode)\r\n', '\r\nApache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T11:33:14-07:00)\r\nMaven home: /usr/local/Cellar/maven/3.5.4/libexec\r\nJava version: 1.8.0_181, vendor: Oracle Corporation, runtime: /Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk/Contents/Home/jre\r\nDefault locale: en_US, platform encoding: UTF-8\r\nOS name: ""mac os x"", version: ""10.12.6"", arch: ""x86_64"", family: ""mac""\r\n']","['Failed to read artifact descriptor for org.apache.mxnet:mxnet-full_2.11-osx-x86_64-cpu:jar:1.2.0 ', '', ""\r\n----------Python Info----------\r\nVersion      : 3.6.5\r\nCompiler     : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)\r\nBuild        : ('default', 'Apr 26 2018 08:42:37')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 18.0\r\nDirectory    : /usr/local/anaconda3/lib/python3.6/site-packages/pip\r\n----------MXNet Info-----------\r\n/usr/local/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from "", ' to ', ' is deprecated. In future, it will be treated as ', "".\r\n  from ._conv import register_converters as _register_converters\r\nVersion      : 1.2.1\r\nDirectory    : /usr/local/anaconda3/lib/python3.6/site-packages/mxnet\r\nCommit Hash   : 106391a1f0ee012b1ea38764d711e76774ce77e1\r\n----------System Info----------\r\nPlatform     : Darwin-16.7.0-x86_64-i386-64bit\r\nsystem       : Darwin\r\nnode         : 88e9fe524ef0.ant.amazon.com\r\nrelease      : 16.7.0\r\nversion      : Darwin Kernel Version 16.7.0: Thu Jun 21 20:07:39 PDT 2018; root:xnu-3789.73.14~1/RELEASE_X86_64\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : i386\r\nb'machdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT PREFETCHW RDTSCP TSCI'\r\nb'machdep.cpu.leaf7_features: SMEP ERMS RDWRFSGS TSC_THREAD_OFFSET BMI1 HLE AVX2 BMI2 INVPCID RTM SMAP RDSEED ADX IPT SGX FPU_CSDS MPX CLFSOPT'\r\nb'machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C'\r\nb'machdep.cpu.brand_string: Intel(R) Core(TM) i7-7660U CPU @ 2.50GHz'\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0138 sec, LOAD: 0.6512 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0496 sec, LOAD: 0.3530 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0287 sec, LOAD: 0.2834 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0312 sec, LOAD: 0.1477 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0285 sec, LOAD: 0.4610 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0193 sec, LOAD: 0.0959 sec.\r\n"", '', 'java -version', 'mvn -version', 'scala -version']",0,0
272,incubator-mxnet,7522,closed,how to calculate an evaluation metric using intermediate layer output?,"Hi Dear mxnet users and developers:
    I understand that there is example of how to use intermediate layer output in prediction.
   However, in training and validation, is it possible to use intermediate layer output to calculate an evaluation metric?
   Thanks a lot",,"['you can define this layer in output : \r\n```python\r\ndef get_symbol():\r\n    data = mx.symbol.Variable(name=""data"")\r\n    inter = mx.symbol.FullyConnected(data=data, num_hidden=4096, name=""inter"")\r\n    fc1 = mx.symbol.FullyConnected(data=inter, num_hidden=4096, name=""fc1"")\r\n    softmax = mx.symbol.SoftmaxOutput(data=fc1, name=\'softmax\')\r\nreturn mx.symbol.Group([softmax, inter])\r\n```\r\nlook at [this](https://github.com/apache/incubator-mxnet/blob/master/example/python-howto/multiple_outputs.py)', 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!\nAlso, do please check out our [forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) for general ""how-to"" questions.']",[],[],0,0
273,incubator-mxnet,11735,closed,test_optimizer.test_ftml has fixed seed that can mask flakiness,"The unit test in title have been using fixed seed to mask flakiness. Suggested action:
1. Evaluate whether the test is flaky without fixed seed. If not, remove seed. Else move to 2
2. If test is flaky, determine whether it's an actual uncaught edge case. If so, fix the operator. Else move to 3
3. If numerical instability is inevitable, adjust tolerance level appropriately.
",Flaky Test,"['Thanks for filing this issue. We will investigate this flaky test.', 'Thannks for filing this issue. We will investigate this Flaky test', 'Fix in #12003 ']",[],[],0,0
274,incubator-mxnet,3096,closed,How to set parameter of speech demo,"I tried using part of ami data, and using the default.cfg and my transform file is like this：



then got some error:



I changed transform file to



then the following error reported:



then I modifed default.cfg



then another error reported:



please show me how to set the ydim, thanks.
",,"['@yzhang87 @pluskid \n', '@zhangjiulong seems like you need to change label size.\n\nbtw, you can change these parameters by passing ""--train-xdim"" into the python file.\n', '@zhangjiulong Is this problems solved? I seem to encounter the same problem.  \n', ' i run the speech demo,but got the same error:\n...cuda/tensor_gpu-inl.cuh:351: Check failed: (dst.size(0)) == (label.size(0)) SoftmaxGrad: label shape mismatch\n', '@wd929 That was due to some incompatible changes in `SoftmaxOutput` lately. Could you try to add `preserve_shape=True` when constructing `SoftmaxOutput` to see if it works?\n', ""@pluskid \ni try to add preserve_shape=true here\n\n if take_softmax:\n        sm = mx.sym.SoftmaxOutput(data=pred, label=label, ignore_label=0,use_ignore=True, name='softmax', preserve_shape=True)\nelse:\n        sm = pred\n\nbut it does`t work,the same error occured\n"", '@wd929 one temporary solution was reshape the label and pred.\n\npred = mx.sym.Reshape(pred, shape=(-1, num_label))\nlabel = mx.sym.Reshape(label, shape=(-1,))\n\nWe will submit a fix soon (after we combined with cudnn-lstm).\n', '@yzhang87 \ni reshape the label and pred but i got\n\nsrc/operator/./reshape-inl.h:289: Check failed: oshape.Size() == dshape.Size() Target shape size is different to source. Target: 8315056683120\n', ""i try to add preserve_shape=true here\n\n if take_softmax:\n        sm = mx.sym.SoftmaxOutput(data=pred, label=label,\nignore_label=0,use_ignore=True, name='softmax', preserve_shape=True)\nelse:\n        sm = pred\n\nbut it does`t work,the same error occured\n\n2016-10-21 0:03 GMT+08:00 Chiyuan Zhang notifications@github.com:\n\n> @wd929 https://github.com/wd929 That was due to some incompatible\n> changes in SoftmaxOutput lately. Could you try to add preserve_shape=True\n> when constructing SoftmaxOutput to see if it works?\n> \n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/dmlc/mxnet/issues/3096#issuecomment-255150185, or mute\n> the thread\n> https://github.com/notifications/unsubscribe-auth/ATgiMkhlaFOxOEIHLiEK0kH7-iYaKqHwks5q15DmgaJpZM4JpjLD\n> .\n"", '#3620 should fix this. We are planning to test cuDNN RNN cell for speech demo soon.\n', '@pluskid \nI pull the newest script.But I got another error.\nIndexError: index 1936 is out of bounds for axis 0 with size 1936\n1936 is the label dim(i.e. $ of state) I think maybe I should -1 (0~1935) but i got the same error \nIndexError: index 1935 is out of bounds for axis 0 with size 1935\nI don`t know why\n', 'The label dimension might be different from different kaldi run. @yzhang87 Maybe we should add comments on how to read out this parameter from kaldi outputs.\n', '@wd929 ""index 1936 is out of bounds for axis 0 with size 1936"", I think it means you need increase the your label dim. You can check final.occs in kaldi model file for the total number of labels.\n', '@yzhang87 \nI checked the the number label is actually 1936 in final.occs and I checked label numbers in exp_mxnet/data-for-mxnet/label_mean.ark ,which is 1936 too.\n', 'Can you show me which line throw this error? By default, 0 is reserved for garbage frame, 1-label_dim was for the actual labels. Does it work if you increase the num_label in the config? It seems you feed-in some index which exceed the label_num.\n', '@yzhang87 \nTraceback (most recent call last):\n  File ""train_lstm_proj.py"", line 303, in <module>\n    do_training(training_method, args, module, data_train, data_val)\n  File ""train_lstm_proj.py"", line 198, in do_training\n    module.update_metric(eval_metric, data_batch.label)\n  File ""mxnet/python/mxnet/module/module.py"", line 448, in update_metric\n    self._exec_group.update_metric(eval_metric, labels)\n  File ""mxnet/python/mxnet/module/executor_group.py"", line 312, in update_metric\n    eval_metric.update(labels_slice, texec.outputs)\n  File ""mxnet/python/mxnet/metric.py"", line 106, in update\n    metric.update(labels, preds)\n  File ""mxnet/python/mxnet/metric.py"", line 350, in update\n    reval = self._feval(label, pred)\n  File ""mxnet/python/mxnet/metric.py"", line 376, in feval\n    return numpy_feval(label, pred)\n  File ""train_lstm_proj.py"", line 67, in CrossEntropy\n    loss += -np.log(max(1e-10, preds[i][int(label)]))\nIndexError: index 1936 is out of bounds for axis 0 with size 1936\n\nAnd i increase the number of label to 1937,it seems to work...there is no error till now. \n', 'For this error, it seems due to the label index is from 1, not from 0. \nIn train_lstm_proj.py for function def CrossEntropy(labels, preds):\n in the loop for i in range(preds.shape[0]), you can just let label:=label-1\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']","['\nTRANSFORM scp:/home/zhangjl/git/kaldi/egs/ami62_mxnet/s5/exp_mxnet/data-for-mxnet/feats2.scp\nscp:/home/zhangjl/git/kaldi/egs/ami62_mxnet/s5/exp_mxnet/data-for-mxnet/post2.scp\n', '\nLoading data into memory...\nERROR (Input():kaldi-io.cc:742) Error opening input stream TRANSFORM\n\n[ Stack-Trace: ]\n', '\nNO_FEATURE_TRANSFORM scp:/home/zhangjl/git/kaldi/egs/ami62_mxnet/s5/exp_mxnet/data-for-mxnet/feats2.scp\nscp:/home/zhangjl/git/kaldi/egs/ami62_mxnet/s5/exp_mxnet/data-for-mxnet/post2.scp\n', '\nTraceback (most recent call last):\n  File ""train_lstm_proj.py"", line 303, in <module>\n    do_training(training_method, args, module, data_train, data_val)\n  File ""train_lstm_proj.py"", line 188, in do_training\n    for nbatch, data_batch in enumerate(data_train):\n  File ""/home/zhangjl/git/kaldi/egs/ami62_mxnet/s5/io_util.py"", line 410, in __iter__\n    np_data_buffer[i][:n_take] = fea_utt[idx_take]\nValueError: could not broadcast input array from shape (20,13) into shape (20,40)\n', '\nxdim =40 changed to xdim = 13\n', ""\n[14:31:29] /home/zhangjl/git/mxnet/dmlc-core/include/dmlc/logging.h:235: [14:31:29] /home/zhangjl/git/mxnet/mshadow/mshadow/././././cuda/tensor_gpu-inl.cuh:351: Check failed: (dst.size(0)) == (label.size(0)) SoftmaxGrad: label shape mismatch\n[14:31:29] /home/zhangjl/git/mxnet/dmlc-core/include/dmlc/logging.h:235: [14:31:29] src/engine/./threaded_engine.h:306: [14:31:29] /home/zhangjl/git/mxnet/mshadow/mshadow/././././cuda/tensor_gpu-inl.cuh:351: Check failed: (dst.size(0)) == (label.size(0)) SoftmaxGrad: label shape mismatch\nAn fatal error occurred in asynchronous engine operation. If you do not know what caused this error, you can try set environment variable MXNET_ENGINE_TYPE to NaiveEngine and run with debugger (i.e. gdb). This will force all operations to be synchronous and backtrace will give you the series of calls that lead to this error. Remember to set MXNET_ENGINE_TYPE back to empty after debugging.\nterminate called after throwing an instance of 'dmlc::Error'\n  what():  [14:31:29] src/engine/./threaded_engine.h:306: [14:31:29] /home/zhangjl/git/mxnet/mshadow/mshadow/././././cuda/tensor_gpu-inl.cuh:351: Check failed: (dst.size(0)) == (label.size(0)) SoftmaxGrad: label shape mismatch\nAn fatal error occurred in asynchronous engine operation. If you do not know what caused this error, you can try set environment variable MXNET_ENGINE_TYPE to NaiveEngine and run with debugger (i.e. gdb). This will force all operations to be synchronous and backtrace will give you the series of calls that lead to this error. Remember to set MXNET_ENGINE_TYPE back to empty after debugging.\nAborted (core dumped)\n""]",[],0,0
275,incubator-mxnet,4471,closed,Lack of control flow operators: functionally inferior to Tensorflow and Theano,"After going through so much inconveniences in Tensorflow and Theano, now I am trying MXNET.
I have read through the MXNET API, there is no control flow operation, i.e., functionally equivalent to tf.select/tf.cond or theano.switch/theano.ifelse . This missing functionality will limit the toolkit's capability in handling variable-length sequences.

Take note that without control flow operators, you can still perform LSTM-based variable-sequence-length prediction using masking. However, there is still something that you cannot do. For example, in training a RNN language model, I would like to reset the state vector to some specific trainable parameter whenever I encounter a sentence begin, i.e., .

So I hereby hope the developer can implement this important function. Thanks!",,"['@xuancong84 I have also felt a need for tf.select()/tf.switch kind of operation. I will probably implement it if no one else picks it up in the next few days.', ""select is easy to add, it's just a tenary operator.\r\ncond is better done imperatively by combining Modules"", ""It should be pretty easy to do cond with custom operators.\r\n\r\ntheano and tf have condition and loop operators because they don't support imperative programming, not because it's a good solution.\r\nthings like scan are hard to use, slow, and really shouldn't be done in the graph.\r\nIt's understandable that people used to tf and theano become attached to these operators, but you really should abandon that school of thinking and embrace hybrid symbolic/imperative programming. see tutorial here http://mxnet.io/tutorials/index.html\r\nIt's like programming with PHP+SQL. You write logic in PHP and do data processing in SQL.\r\n\r\n\r\n"", ""Glad to hear that you are going to add in for that!\r\nHowever, do not think it is easy to implement especially during the back-propagation or weight update, where you don't want to propagate the error along all paths from the conditional junction.\r\n\r\nIn addition, there is an advanced issue which I am not sure whether Theano and Tensorflow has implemented or not. It is the derivative w.r.t the conditional statement. For simple cases like whether the time index has exceeded the sequence length (for variable-length sequence input), there is no problem. However, if the conditional statement is a function of the input, say f(input)>0, it might be better to collect some statistics to decide which output choice is preferred, so that the conditional statement part of the network, f(), can be trained and updated as well. Sometimes, it might also be possible to update both paths according to their posterior likelihood, say 70% vs 30% respectively, instead of a boolean junction update where the winning branch takes all.\r\n\r\nBear in mind, things can go really tricky at the conditional branch."", 'Just curious, so has this feature been implemented?\r\nI have tried to build MXNET from source. While compiling, I do see control_flow_ops.cu, but what is the API function that calls it? select, ifelse, switch?\r\n\r\nPlease give me some hint! Thanks!', 'We are trying to add control flow operators.\r\nhttps://cwiki.apache.org/confluence/display/MXNET/Add+flow+control+operators+in+MXNet']",[],['<s>'],0,0
276,incubator-mxnet,5370,closed,LSTM MXNet perplexity score,"
Hello,

I am using Mxnet R package and walking through the following tutorial:
http://mxnet.io/tutorials/r/charRnnModel.html

I see that the lstm that was trained is used to generate text. However, is there a way to use the lstm model to evaluate test text?

When using language models, we can use perplexity to evaluate test data. Lower the perplexity, closer the language model to test data. Higher the perplexity, the farther away the language model is to test data.

Is there an equivalent score that can be generated using LSTM?

Thanks,
Aarthi

## Environment info
Operating System: MacOS

Compiler:

Package used (Python/R/Scala/Julia): R

R :
R version 3.3.2 (2016-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: macOS Sierra 10.12.3

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] mxnet_0.9.4   h2o_3.10.2.2  ggplot2_2.2.1 plyr_1.8.4   

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.7      knitr_1.15.1     magrittr_1.5     devtools_1.12.0 
 [5] munsell_0.4.3    colorspace_1.2-7 R6_2.2.0         stringr_1.1.0   
 [9] httr_1.2.1       visNetwork_1.0.3 tools_3.3.2      drat_0.1.2      
[13] grid_3.3.2       gtable_0.2.0     git2r_0.18.0     withr_1.0.2     
[17] htmltools_0.3.5  lazyeval_0.2.0   assertthat_0.1   digest_0.6.10   
[21] tibble_1.2       codetools_0.2-15 htmlwidgets_0.7  bitops_1.0-6    
[25] RCurl_1.95-4.8   curl_2.2         memoise_1.0.0    labeling_0.3    
[29] stringi_1.1.2    scales_0.4.1     jsonlite_1.1    

## Error Message:
No error message
",,['This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!'],[],['sessionInfo()'],0,0
277,incubator-mxnet,13080,closed,Jenkins failing on Scala GPU,"There is a failure occurring on the Jenkins in the Scala GPU task.  The failure is occurring when running ""make scalapkg"" to build the core module.

One sample error ending is:


We have identified a number of Jenkins runs that produced this:
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-13077/1/pipeline
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-13071/1/pipeline
http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-13052/2/pipeline

The problem has also been observed on the dev Jenkins:
http://jenkins.mxnet-ci-dev.amazon-ml.com/blue/organizations/jenkins/restricted-publish-artifacts/detail/automate-maven/61/pipeline

",Flaky Scala Test,"['One more DP http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-12995/4/pipeline/1026', '@mxnet-label-bot [flaky, test, GPU, Scala]', '@marcoabreu @lebeg @larroy Me and Zach are now investigating the issue and see if we can reproduce them. Please take a look at here as well, is there any changes on GPU config recently?', 'Resolution: This issue is typically appeared with GPU and not crash on CPU and Clojure.', 'https://stackoverflow.com/questions/50661648/spring-boot-fails-to-run-maven-surefire-plugin-classnotfoundexception-org-apache/50661649#50661649\r\n\r\nhttps://stackoverflow.com/questions/50661648/spring-boot-fails-to-run-maven-surefire-plugin-classnotfoundexception-org-apache/50661649#50661649', 'The issue appeared with a recent OpenJDK upgrade, here is the workaround we will take to solve this issue:\r\n```\r\n<plugin>\r\n    <groupId>org.apache.maven.plugins</groupId>\r\n    <artifactId>maven-surefire-plugin</artifactId>\r\n    <configuration>\r\n        <useSystemClassLoader>false</useSystemClassLoader>\r\n    </configuration>\r\n</plugin>\r\n```\r\n\r\nBut I am still thinking this problem can only reproduce on GPU, not the CPU. There might be a diff on the JDK version between these two VM,', 'No there has not been an update recently.\r\n\r\n@lebeg you rolled back, right?\r\n\r\n@chancebair fyi', 'Another occurrence of the same - http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-12775/14/pipeline/', '@zachgk since PR is merged, do we close this?', '@zachgk , please close the issue as it seems that PR has been merged. Unless there is something else to do here to address it?']","[""\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.22.0:test (default-test) on project mxnet-core_2.11: There are test failures.\r\n\r\n[ERROR] \r\n\r\n[ERROR] Please refer to /work/mxnet/scala-package/core/target/surefire-reports for the individual test results.\r\n\r\n[ERROR] Please refer to dump files (if any exist) [date]-jvmRun[N].dump, [date].dumpstream and [date]-jvmRun[N].dumpstream.\r\n\r\n[ERROR] The forked VM terminated without properly saying goodbye. VM crash or System.exit called?\r\n\r\n[ERROR] Command was /bin/sh -c cd /work/mxnet/scala-package/core && /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -jar /work/mxnet/scala-package/core/target/surefire/surefirebooter1191780993849458203.jar /work/mxnet/scala-package/core/target/surefire 2018-11-01T15-57-55_076-jvmRun1 surefire2207349951215643963tmp surefire_05921002131138985800tmp\r\n\r\n[ERROR] Error occurred in starting fork, check output in log\r\n\r\n[ERROR] Process Exit Code: 1\r\n\r\n[ERROR] org.apache.maven.surefire.booter.SurefireBooterForkException: The forked VM terminated without properly saying goodbye. VM crash or System.exit called?\r\n\r\n[ERROR] Command was /bin/sh -c cd /work/mxnet/scala-package/core && /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -jar /work/mxnet/scala-package/core/target/surefire/surefirebooter1191780993849458203.jar /work/mxnet/scala-package/core/target/surefire 2018-11-01T15-57-55_076-jvmRun1 surefire2207349951215643963tmp surefire_05921002131138985800tmp\r\n\r\n[ERROR] Error occurred in starting fork, check output in log\r\n\r\n[ERROR] Process Exit Code: 1\r\n\r\n[ERROR] at org.apache.maven.plugin.surefire.booterclient.ForkStarter.fork(ForkStarter.java:671)\r\n\r\n[ERROR] at org.apache.maven.plugin.surefire.booterclient.ForkStarter.fork(ForkStarter.java:533)\r\n\r\n[ERROR] at org.apache.maven.plugin.surefire.booterclient.ForkStarter.run(ForkStarter.java:278)\r\n\r\n[ERROR] at org.apache.maven.plugin.surefire.booterclient.ForkStarter.run(ForkStarter.java:244)\r\n\r\n[ERROR] at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1194)\r\n\r\n[ERROR] at org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1022)\r\n\r\n[ERROR] at org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:868)\r\n\r\n[ERROR] at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134)\r\n\r\n[ERROR] at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:207)\r\n\r\n[ERROR] at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)\r\n\r\n[ERROR] at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)\r\n\r\n[ERROR] at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)\r\n\r\n[ERROR] at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)\r\n\r\n[ERROR] at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)\r\n\r\n[ERROR] at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)\r\n\r\n[ERROR] at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:307)\r\n\r\n[ERROR] at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:193)\r\n\r\n[ERROR] at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:106)\r\n\r\n[ERROR] at org.apache.maven.cli.MavenCli.execute(MavenCli.java:863)\r\n\r\n[ERROR] at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288)\r\n\r\n[ERROR] at org.apache.maven.cli.MavenCli.main(MavenCli.java:199)\r\n\r\n[ERROR] at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\r\n[ERROR] at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\r\n[ERROR] at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\r\n[ERROR] at java.lang.reflect.Method.invoke(Method.java:498)\r\n\r\n[ERROR] at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)\r\n\r\n[ERROR] at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)\r\n\r\n[ERROR] at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)\r\n\r\n[ERROR] at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)\r\n\r\n[ERROR] -> [Help 1]\r\n\r\n[ERROR] \r\n\r\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\r\n\r\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\r\n\r\n[ERROR] \r\n\r\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\r\n\r\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\r\n\r\n[ERROR] \r\n\r\n[ERROR] After correcting the problems, you can resume the build with the command\r\n\r\n[ERROR]   mvn <goals> -rf :mxnet-core_2.11\r\n\r\nmake: *** [scalapkg] Error 1\r\n\r\nMakefile:606: recipe for target 'scalapkg' failed\r\n\r\nbuild.py: 2018-11-01 15:57:55,920 Waiting for status of container a9ca51005111 for 600 s.\r\n\r\nbuild.py: 2018-11-01 15:57:56,101 Container exit status: {'Error': None, 'StatusCode': 2}\r\n\r\nbuild.py: 2018-11-01 15:57:56,101 Stopping container: a9ca51005111\r\n\r\nbuild.py: 2018-11-01 15:57:56,103 Removing container: a9ca51005111\r\n\r\nbuild.py: 2018-11-01 15:57:56,230 Execution of ['/work/runtime_functions.sh', 'integrationtest_ubuntu_gpu_scala'] failed with status: 2\r\n\r\nscript returned exit code 2\r\n""]",[],0,0
278,incubator-mxnet,6600,closed,Missing `broadcast_add` layer in MXNet Scala binding,"I am trying to run a converted Caffe model, a ResNet 50 model that I trained on my own set of images. I have converted the model using the Caffe converter from the most recent master branch of MXNet. However, when trying to run with the Scala bindings, I have the following problem. Seems to me that  is not found in my Scala library (see below).

Note that I could run a VGG-16 model, after some edits.

## Environment info
Operating System: Mac OSX El Capitan 10.11.5

Compiler: SBT

Package used (Python/R/Scala/Julia): Scala

MXNet version: using  from [Maven Respositories](https://mvnrepository.com/)

## Error Message:
Please paste the full error message, including stack trace.



## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

Basically, this layer from the model definition JSON produces the problem:


The full model definition, a ResNet 50 layer model, below:



## What have you tried to solve it?

1. tried to run on my own published JAR, but the problem persists.
2. checked the Scala library, there doesn't seem to have a .

",,"['Apologies, the bindings I was using is extremely outdated. Switched to `""ml.dmlc.mxnet"" % ""mxnet-full_2.11-osx-x86_64-cpu"" % ""0.9.3a""` and everything is working fine.']","['\r\n[09:47:23] /Users/lewis/Workspace/source-codes/release/mxnet/dmlc-core/include/dmlc/logging.h:245: [09:47:23] src/operator/operator.cc:19: Cannot find Operator broadcast_add in registry\r\nException in thread ""main"" ml.dmlc.mxnet.MXNetError: Failed loading Op res2a of type broadcast_add: [09:47:23] src/operator/operator.cc:19: Cannot find Operator broadcast_add in registry\r\n\tat ml.dmlc.mxnet.Base$.checkCall(Base.scala:108)\r\n\tat ml.dmlc.mxnet.Symbol$.load(Symbol.scala:1512)\r\n\tat ml.dmlc.mxnet.Model$.loadCheckpoint(Model.scala:52)\r\n\tat ml.dmlc.mxnet.FeedForward$.load(FeedForward.scala:345)\r\n\tat com.imageintelligence.ava.og.core.Classifier.<init>(Classifier.scala:10)\r\n\tat com.imageintelligence.ava.og.Boot$.main(Boot.scala:22)\r\n\tat com.imageintelligence.ava.og.Boot.main(Boot.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)\r\n', '\r\n    {\r\n      ""op"": ""broadcast_add"",\r\n      ""name"": ""res2a"",\r\n      ""param"": {},\r\n      ""inputs"": [[17, 0], [40, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n', '\r\n{\r\n  ""nodes"": [\r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""data"",\r\n      ""param"": {},\r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""conv1_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(7, 7)"", \r\n        ""no_bias"": ""False"", \r\n        ""num_filter"": ""64"", \r\n        ""pad"": ""(3, 3)"", \r\n        ""stride"": ""(2, 2)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""conv1_bias"", \r\n      ""param"": {\r\n        ""kernel"": ""(7, 7)"", \r\n        ""no_bias"": ""False"", \r\n        ""num_filter"": ""64"", \r\n        ""pad"": ""(3, 3)"", \r\n        ""stride"": ""(2, 2)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""conv1"", \r\n      ""param"": {\r\n        ""kernel"": ""(7, 7)"", \r\n        ""no_bias"": ""False"", \r\n        ""num_filter"": ""64"", \r\n        ""pad"": ""(3, 3)"", \r\n        ""stride"": ""(2, 2)""\r\n      }, \r\n      ""inputs"": [[0, 0], [1, 0], [2, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn_conv1_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn_conv1_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn_conv1_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn_conv1_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn_conv1"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[3, 0], [4, 0], [5, 0], [6, 1], [7, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""conv1_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[8, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Pooling"", \r\n      ""name"": ""pool1"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""pool_type"": ""max"", \r\n         \r\n        ""stride"": ""(2, 2)""\r\n      }, \r\n      ""inputs"": [[9, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res2a_branch1_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res2a_branch1"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[10, 0], [11, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2a_branch1_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2a_branch1_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2a_branch1_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2a_branch1_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn2a_branch1"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[12, 0], [13, 0], [14, 0], [15, 1], [16, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res2a_branch2a_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""64"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res2a_branch2a"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""64"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[10, 0], [18, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2a_branch2a_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2a_branch2a_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2a_branch2a_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2a_branch2a_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn2a_branch2a"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[19, 0], [20, 0], [21, 0], [22, 1], [23, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res2a_branch2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[24, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res2a_branch2b_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""64"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res2a_branch2b"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""64"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[25, 0], [26, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2a_branch2b_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2a_branch2b_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2a_branch2b_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2a_branch2b_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn2a_branch2b"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[27, 0], [28, 0], [29, 0], [30, 1], [31, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res2a_branch2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[32, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res2a_branch2c_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res2a_branch2c"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[33, 0], [34, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2a_branch2c_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2a_branch2c_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2a_branch2c_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2a_branch2c_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn2a_branch2c"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[35, 0], [36, 0], [37, 0], [38, 1], [39, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""broadcast_add"",\r\n      ""name"": ""res2a"",\r\n      ""param"": {},\r\n      ""inputs"": [[17, 0], [40, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[41, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res2b_branch2a_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""64"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res2b_branch2a"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""64"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[42, 0], [43, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2b_branch2a_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2b_branch2a_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2b_branch2a_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2b_branch2a_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn2b_branch2a"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[44, 0], [45, 0], [46, 0], [47, 1], [48, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res2b_branch2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[49, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res2b_branch2b_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""64"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res2b_branch2b"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""64"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[50, 0], [51, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2b_branch2b_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2b_branch2b_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2b_branch2b_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2b_branch2b_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn2b_branch2b"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[52, 0], [53, 0], [54, 0], [55, 1], [56, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res2b_branch2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[57, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res2b_branch2c_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res2b_branch2c"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[58, 0], [59, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2b_branch2c_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2b_branch2c_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2b_branch2c_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2b_branch2c_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn2b_branch2c"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[60, 0], [61, 0], [62, 0], [63, 1], [64, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""broadcast_add"", \r\n      ""name"": ""res2b"",\r\n      ""param"": {},\r\n      ""inputs"": [[42, 0], [65, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[66, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res2c_branch2a_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""64"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res2c_branch2a"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""64"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[67, 0], [68, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2c_branch2a_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2c_branch2a_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2c_branch2a_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2c_branch2a_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn2c_branch2a"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[69, 0], [70, 0], [71, 0], [72, 1], [73, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res2c_branch2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[74, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res2c_branch2b_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""64"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res2c_branch2b"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""64"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[75, 0], [76, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2c_branch2b_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2c_branch2b_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2c_branch2b_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2c_branch2b_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn2c_branch2b"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[77, 0], [78, 0], [79, 0], [80, 1], [81, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res2c_branch2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[82, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res2c_branch2c_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res2c_branch2c"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[83, 0], [84, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2c_branch2c_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2c_branch2c_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2c_branch2c_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn2c_branch2c_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn2c_branch2c"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[85, 0], [86, 0], [87, 0], [88, 1], [89, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""broadcast_add"",\r\n      ""name"": ""res2c"",\r\n      ""param"": {},\r\n      ""inputs"": [[67, 0], [90, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res2c_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[91, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res3a_branch1_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(2, 2)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res3a_branch1"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(2, 2)""\r\n      }, \r\n      ""inputs"": [[92, 0], [93, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3a_branch1_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3a_branch1_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3a_branch1_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3a_branch1_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn3a_branch1"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[94, 0], [95, 0], [96, 0], [97, 1], [98, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res3a_branch2a_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""128"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(2, 2)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res3a_branch2a"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""128"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(2, 2)""\r\n      }, \r\n      ""inputs"": [[92, 0], [100, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3a_branch2a_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3a_branch2a_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3a_branch2a_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3a_branch2a_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn3a_branch2a"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[101, 0], [102, 0], [103, 0], [104, 1], [105, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res3a_branch2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[106, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res3a_branch2b_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""128"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res3a_branch2b"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""128"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[107, 0], [108, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3a_branch2b_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3a_branch2b_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3a_branch2b_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3a_branch2b_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn3a_branch2b"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[109, 0], [110, 0], [111, 0], [112, 1], [113, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res3a_branch2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[114, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res3a_branch2c_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res3a_branch2c"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[115, 0], [116, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3a_branch2c_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3a_branch2c_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3a_branch2c_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3a_branch2c_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn3a_branch2c"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[117, 0], [118, 0], [119, 0], [120, 1], [121, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""broadcast_add"",\r\n      ""param"": {},\r\n      ""name"": ""res3a"", \r\n      ""inputs"": [[99, 0], [122, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res3a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[123, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res3b_branch2a_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""128"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res3b_branch2a"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""128"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[124, 0], [125, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3b_branch2a_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3b_branch2a_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3b_branch2a_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3b_branch2a_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn3b_branch2a"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[126, 0], [127, 0], [128, 0], [129, 1], [130, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res3b_branch2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[131, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res3b_branch2b_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""128"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res3b_branch2b"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""128"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[132, 0], [133, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3b_branch2b_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3b_branch2b_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3b_branch2b_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3b_branch2b_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn3b_branch2b"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[134, 0], [135, 0], [136, 0], [137, 1], [138, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res3b_branch2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[139, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res3b_branch2c_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res3b_branch2c"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[140, 0], [141, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3b_branch2c_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3b_branch2c_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3b_branch2c_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3b_branch2c_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn3b_branch2c"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[142, 0], [143, 0], [144, 0], [145, 1], [146, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""broadcast_add"",\r\n      ""param"": {},\r\n      ""name"": ""res3b"", \r\n      ""inputs"": [[124, 0], [147, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res3b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[148, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res3c_branch2a_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""128"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res3c_branch2a"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""128"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[149, 0], [150, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3c_branch2a_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3c_branch2a_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3c_branch2a_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3c_branch2a_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn3c_branch2a"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[151, 0], [152, 0], [153, 0], [154, 1], [155, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res3c_branch2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[156, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res3c_branch2b_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""128"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res3c_branch2b"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""128"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[157, 0], [158, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3c_branch2b_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3c_branch2b_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3c_branch2b_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3c_branch2b_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn3c_branch2b"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[159, 0], [160, 0], [161, 0], [162, 1], [163, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res3c_branch2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[164, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res3c_branch2c_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res3c_branch2c"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[165, 0], [166, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3c_branch2c_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3c_branch2c_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3c_branch2c_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3c_branch2c_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn3c_branch2c"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[167, 0], [168, 0], [169, 0], [170, 1], [171, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""broadcast_add"",\r\n      ""param"": {},\r\n      ""name"": ""res3c"", \r\n      ""inputs"": [[149, 0], [172, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res3c_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[173, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res3d_branch2a_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""128"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res3d_branch2a"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""128"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[174, 0], [175, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3d_branch2a_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3d_branch2a_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3d_branch2a_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3d_branch2a_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn3d_branch2a"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[176, 0], [177, 0], [178, 0], [179, 1], [180, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res3d_branch2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[181, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res3d_branch2b_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""128"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res3d_branch2b"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""128"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[182, 0, 0], [183, 0, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3d_branch2b_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3d_branch2b_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3d_branch2b_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3d_branch2b_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn3d_branch2b"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[184, 0], [185, 0], [186, 0], [187, 1], [188, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res3d_branch2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[189, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res3d_branch2c_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res3d_branch2c"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[190, 0], [191, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3d_branch2c_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3d_branch2c_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3d_branch2c_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn3d_branch2c_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn3d_branch2c"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[192, 0], [193, 0], [194, 0], [195, 1], [196, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""broadcast_add"", \r\n      ""name"": ""res3d"",\r\n      ""param"": {},\r\n      ""inputs"": [[174, 0], [197, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res3d_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[198, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4a_branch1_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""1024"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(2, 2)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4a_branch1"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""1024"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(2, 2)""\r\n      }, \r\n      ""inputs"": [[199, 0], [200, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4a_branch1_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4a_branch1_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4a_branch1_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4a_branch1_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4a_branch1"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[201, 0], [202, 0], [203, 0], [204, 1], [205, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4a_branch2a_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(2, 2)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4a_branch2a"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(2, 2)""\r\n      }, \r\n      ""inputs"": [[199, 0], [207, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4a_branch2a_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4a_branch2a_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4a_branch2a_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4a_branch2a_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4a_branch2a"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[208, 0], [209, 0], [210, 0], [211, 1], [212, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4a_branch2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[213, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4a_branch2b_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4a_branch2b"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[214, 0], [215, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4a_branch2b_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4a_branch2b_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4a_branch2b_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4a_branch2b_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4a_branch2b"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[216, 0], [217, 0], [218, 0], [219, 1], [220, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4a_branch2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[221, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4a_branch2c_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""1024"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4a_branch2c"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""1024"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[222, 0], [223, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4a_branch2c_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4a_branch2c_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4a_branch2c_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4a_branch2c_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4a_branch2c"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[224, 0], [225, 0], [226, 0], [227, 1], [228, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""broadcast_add"", \r\n      ""name"": ""res4a"",\r\n      ""param"": {},\r\n      ""inputs"": [[206, 0], [229, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[230, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4b_branch2a_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4b_branch2a"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[231, 0], [232, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4b_branch2a_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4b_branch2a_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4b_branch2a_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4b_branch2a_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4b_branch2a"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[233, 0], [234, 0], [235, 0], [236, 1], [237, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4b_branch2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[238, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4b_branch2b_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4b_branch2b"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[239, 0], [240, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4b_branch2b_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4b_branch2b_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4b_branch2b_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4b_branch2b_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4b_branch2b"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[241, 0], [242, 0], [243, 0], [244, 1], [245, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4b_branch2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[246, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4b_branch2c_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""1024"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4b_branch2c"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""1024"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[247, 0], [248, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4b_branch2c_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4b_branch2c_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4b_branch2c_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4b_branch2c_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4b_branch2c"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[249, 0], [250, 0], [251, 0], [252, 1], [253, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""broadcast_add"", \r\n      ""name"": ""res4b"",\r\n      ""param"": {},\r\n      ""inputs"": [[231, 0], [254, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[255, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4c_branch2a_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4c_branch2a"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[256, 0], [257, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4c_branch2a_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4c_branch2a_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4c_branch2a_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4c_branch2a_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4c_branch2a"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[258, 0], [259, 0], [260, 0], [261, 1], [262, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4c_branch2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[263, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4c_branch2b_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4c_branch2b"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[264, 0], [265, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4c_branch2b_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4c_branch2b_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4c_branch2b_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4c_branch2b_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4c_branch2b"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[266, 0], [267, 0], [268, 0], [269, 1], [270, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4c_branch2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[271, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4c_branch2c_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""1024"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4c_branch2c"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""1024"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[272, 0], [273, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4c_branch2c_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4c_branch2c_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4c_branch2c_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4c_branch2c_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4c_branch2c"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[274, 0], [275, 0], [276, 0], [277, 1], [278, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""broadcast_add"", \r\n      ""name"": ""res4c"",\r\n      ""param"": {},\r\n      ""inputs"": [[256, 0], [279, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4c_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[280, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4d_branch2a_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4d_branch2a"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[281, 0], [282, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4d_branch2a_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4d_branch2a_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4d_branch2a_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4d_branch2a_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4d_branch2a"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[283, 0], [284, 0], [285, 0], [286, 1], [287, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4d_branch2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[288, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4d_branch2b_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4d_branch2b"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[289, 0], [290, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4d_branch2b_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4d_branch2b_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4d_branch2b_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4d_branch2b_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4d_branch2b"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[291, 0], [292, 0], [293, 0], [294, 1], [295, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4d_branch2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[296, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4d_branch2c_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""1024"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4d_branch2c"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""1024"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[297, 0], [298, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4d_branch2c_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4d_branch2c_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4d_branch2c_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4d_branch2c_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4d_branch2c"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[299, 0], [300, 0], [301, 0], [302, 1], [303, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""broadcast_add"", \r\n      ""name"": ""res4d"",\r\n      ""param"": {},\r\n      ""inputs"": [[281, 0], [304, 0, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4d_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[305, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4e_branch2a_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4e_branch2a"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[306, 0], [307, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4e_branch2a_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4e_branch2a_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4e_branch2a_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4e_branch2a_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4e_branch2a"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[308, 0], [309, 0], [310, 0], [311, 1], [312, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4e_branch2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[313, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4e_branch2b_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4e_branch2b"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[314, 0], [315, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4e_branch2b_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4e_branch2b_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4e_branch2b_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4e_branch2b_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4e_branch2b"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[316, 0], [317, 0], [318, 0], [319, 1], [320, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4e_branch2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[321, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4e_branch2c_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""1024"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4e_branch2c"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""1024"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[322, 0], [323, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4e_branch2c_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4e_branch2c_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4e_branch2c_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4e_branch2c_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4e_branch2c"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[324, 0], [325, 0], [326, 0], [327, 1], [328, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""broadcast_add"", \r\n      ""name"": ""res4e"",\r\n      ""param"": {},\r\n      ""inputs"": [[306, 0], [329, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4e_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[330, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4f_branch2a_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4f_branch2a"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[331, 0], [332, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4f_branch2a_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4f_branch2a_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4f_branch2a_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4f_branch2a_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4f_branch2a"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[333, 0], [334, 0], [335, 0], [336, 1], [337, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4f_branch2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[338, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4f_branch2b_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4f_branch2b"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""256"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[339, 0], [340, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4f_branch2b_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4f_branch2b_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4f_branch2b_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4f_branch2b_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4f_branch2b"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[341, 0], [342, 0], [343, 0], [344, 1], [345, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4f_branch2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[346, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res4f_branch2c_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""1024"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res4f_branch2c"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""1024"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[347, 0], [348, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4f_branch2c_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4f_branch2c_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4f_branch2c_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn4f_branch2c_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn4f_branch2c"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[349, 0], [350, 0], [351, 0], [352, 1], [353, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""broadcast_add"", \r\n      ""name"": ""res4f"",\r\n      ""param"": {},\r\n      ""inputs"": [[331, 0], [354, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res4f_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[355, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res5a_branch1_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""2048"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(2, 2)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res5a_branch1"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""2048"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(2, 2)""\r\n      }, \r\n      ""inputs"": [[356, 0], [357, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5a_branch1_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5a_branch1_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5a_branch1_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5a_branch1_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn5a_branch1"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[358, 0], [359, 0], [360, 0], [361, 1], [362, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res5a_branch2a_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(2, 2)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res5a_branch2a"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(2, 2)""\r\n      }, \r\n      ""inputs"": [[356, 0], [364, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5a_branch2a_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5a_branch2a_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5a_branch2a_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5a_branch2a_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn5a_branch2a"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[365, 0], [366, 0], [367, 0], [368, 1], [369, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res5a_branch2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[370, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res5a_branch2b_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res5a_branch2b"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[371, 0], [372, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5a_branch2b_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5a_branch2b_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5a_branch2b_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5a_branch2b_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn5a_branch2b"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[373, 0], [374, 0], [375, 0], [376, 1], [377, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res5a_branch2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[378, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res5a_branch2c_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""2048"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res5a_branch2c"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""2048"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[379, 0], [380, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5a_branch2c_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5a_branch2c_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5a_branch2c_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5a_branch2c_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn5a_branch2c"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[381, 0], [382, 0], [383, 0], [384, 1], [385, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""broadcast_add"", \r\n      ""name"": ""res5a"",\r\n      ""param"": {},\r\n      ""inputs"": [[363, 0], [386, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res5a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[387, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res5b_branch2a_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res5b_branch2a"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[388, 0], [389, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5b_branch2a_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5b_branch2a_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5b_branch2a_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5b_branch2a_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn5b_branch2a"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[390, 0], [391, 0], [392, 0], [393, 1], [394, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res5b_branch2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[395, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res5b_branch2b_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res5b_branch2b"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[396, 0], [397, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5b_branch2b_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5b_branch2b_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5b_branch2b_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5b_branch2b_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn5b_branch2b"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[398, 0], [399, 0], [400, 0], [401, 1], [402, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res5b_branch2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[403, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res5b_branch2c_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""2048"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res5b_branch2c"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""2048"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[404, 0], [405, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5b_branch2c_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5b_branch2c_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5b_branch2c_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5b_branch2c_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn5b_branch2c"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[406, 0], [407, 0], [408, 0], [409, 1], [410, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""broadcast_add"", \r\n      ""name"": ""res5b"",\r\n      ""param"": {},\r\n      ""inputs"": [[388, 0], [411, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res5b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[412, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res5c_branch2a_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res5c_branch2a"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[413, 0], [414, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5c_branch2a_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5c_branch2a_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5c_branch2a_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5c_branch2a_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn5c_branch2a"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[415, 0], [416, 0], [417, 0], [418, 1], [419, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res5c_branch2a_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[420, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res5c_branch2b_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res5c_branch2b"", \r\n      ""param"": {\r\n        ""kernel"": ""(3, 3)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""512"", \r\n        ""pad"": ""(1, 1)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[421, 0], [422, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5c_branch2b_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5c_branch2b_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5c_branch2b_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5c_branch2b_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn5c_branch2b"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[423, 0], [424, 0], [425, 0], [426, 1], [427, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res5c_branch2b_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[428, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""res5c_branch2c_weight"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""2048"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Convolution"", \r\n      ""name"": ""res5c_branch2c"", \r\n      ""param"": {\r\n        ""kernel"": ""(1, 1)"", \r\n        ""no_bias"": ""True"", \r\n        ""num_filter"": ""2048"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[429, 0], [430, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5c_branch2c_gamma"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5c_branch2c_beta"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5c_branch2c_moving_mean"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""bn5c_branch2c_moving_var"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""BatchNorm"", \r\n      ""name"": ""bn5c_branch2c"", \r\n      ""param"": {\r\n        ""eps"": ""0.0001"", \r\n        ""fix_gamma"": ""False""\r\n      }, \r\n      ""inputs"": [[431, 0], [432, 0], [433, 0], [434, 1], [435, 1]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""broadcast_add"", \r\n      ""name"": ""res5c"",\r\n      ""param"": {},\r\n      ""inputs"": [[413, 0], [436, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Activation"", \r\n      ""name"": ""res5c_relu"", \r\n      ""param"": {""act_type"": ""relu""}, \r\n      ""inputs"": [[437, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Pooling"", \r\n      ""name"": ""pool5"", \r\n      ""param"": {\r\n        ""kernel"": ""(7, 7)"", \r\n        ""pad"": ""(0, 0)"", \r\n        ""pool_type"": ""avg"",\r\n        ""stride"": ""(1, 1)""\r\n      }, \r\n      ""inputs"": [[438, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""Flatten"", \r\n      ""name"": ""flatten_0"", \r\n      ""inputs"": [[439, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""fc1000_binary_weight"", \r\n      ""param"": {\r\n        ""no_bias"": ""False"", \r\n        ""num_hidden"": ""2""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""fc1000_binary_bias"", \r\n      ""param"": {\r\n        ""no_bias"": ""False"", \r\n        ""num_hidden"": ""2""\r\n      }, \r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""FullyConnected"", \r\n      ""name"": ""fc1000_binary"", \r\n      ""param"": {\r\n        ""no_bias"": ""False"", \r\n        ""num_hidden"": ""2""\r\n      }, \r\n      ""inputs"": [[440, 0], [441, 0], [442, 0]],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""null"", \r\n      ""name"": ""prob_label"",\r\n      ""param"": {},\r\n      ""inputs"": [],\r\n      ""backward_source_id"": -1\r\n    }, \r\n    {\r\n      ""op"": ""SoftmaxOutput"", \r\n      ""name"": ""prob"",\r\n      ""param"": {},\r\n      ""inputs"": [[443, 0], [444, 0]],\r\n      ""backward_source_id"": -1\r\n    }\r\n  ], \r\n  ""arg_nodes"": [\r\n    0, \r\n    1, \r\n    2, \r\n    4, \r\n    5, \r\n    6, \r\n    7, \r\n    11, \r\n    13, \r\n    14, \r\n    15, \r\n    16, \r\n    18, \r\n    20, \r\n    21, \r\n    22, \r\n    23, \r\n    26, \r\n    28, \r\n    29, \r\n    30, \r\n    31, \r\n    34, \r\n    36, \r\n    37, \r\n    38, \r\n    39, \r\n    43, \r\n    45, \r\n    46, \r\n    47, \r\n    48, \r\n    51, \r\n    53, \r\n    54, \r\n    55, \r\n    56, \r\n    59, \r\n    61, \r\n    62, \r\n    63, \r\n    64, \r\n    68, \r\n    70, \r\n    71, \r\n    72, \r\n    73, \r\n    76, \r\n    78, \r\n    79, \r\n    80, \r\n    81, \r\n    84, \r\n    86, \r\n    87, \r\n    88, \r\n    89, \r\n    93, \r\n    95, \r\n    96, \r\n    97, \r\n    98, \r\n    100, \r\n    102, \r\n    103, \r\n    104, \r\n    105, \r\n    108, \r\n    110, \r\n    111, \r\n    112, \r\n    113, \r\n    116, \r\n    118, \r\n    119, \r\n    120, \r\n    121, \r\n    125, \r\n    127, \r\n    128, \r\n    129, \r\n    130, \r\n    133, \r\n    135, \r\n    136, \r\n    137, \r\n    138, \r\n    141, \r\n    143, \r\n    144, \r\n    145, \r\n    146, \r\n    150, \r\n    152, \r\n    153, \r\n    154, \r\n    155, \r\n    158, \r\n    160, \r\n    161, \r\n    162, \r\n    163, \r\n    166, \r\n    168, \r\n    169, \r\n    170, \r\n    171, \r\n    175, \r\n    177, \r\n    178, \r\n    179, \r\n    180, \r\n    183, \r\n    185, \r\n    186, \r\n    187, \r\n    188, \r\n    191, \r\n    193, \r\n    194, \r\n    195, \r\n    196, \r\n    200, \r\n    202, \r\n    203, \r\n    204, \r\n    205, \r\n    207, \r\n    209, \r\n    210, \r\n    211, \r\n    212, \r\n    215, \r\n    217, \r\n    218, \r\n    219, \r\n    220, \r\n    223, \r\n    225, \r\n    226, \r\n    227, \r\n    228, \r\n    232, \r\n    234, \r\n    235, \r\n    236, \r\n    237, \r\n    240, \r\n    242, \r\n    243, \r\n    244, \r\n    245, \r\n    248, \r\n    250, \r\n    251, \r\n    252, \r\n    253, \r\n    257, \r\n    259, \r\n    260, \r\n    261, \r\n    262, \r\n    265, \r\n    267, \r\n    268, \r\n    269, \r\n    270, \r\n    273, \r\n    275, \r\n    276, \r\n    277, \r\n    278, \r\n    282, \r\n    284, \r\n    285, \r\n    286, \r\n    287, \r\n    290, \r\n    292, \r\n    293, \r\n    294, \r\n    295, \r\n    298, \r\n    300, \r\n    301, \r\n    302, \r\n    303, \r\n    307, \r\n    309, \r\n    310, \r\n    311, \r\n    312, \r\n    315, \r\n    317, \r\n    318, \r\n    319, \r\n    320, \r\n    323, \r\n    325, \r\n    326, \r\n    327, \r\n    328, \r\n    332, \r\n    334, \r\n    335, \r\n    336, \r\n    337, \r\n    340, \r\n    342, \r\n    343, \r\n    344, \r\n    345, \r\n    348, \r\n    350, \r\n    351, \r\n    352, \r\n    353, \r\n    357, \r\n    359, \r\n    360, \r\n    361, \r\n    362, \r\n    364, \r\n    366, \r\n    367, \r\n    368, \r\n    369, \r\n    372, \r\n    374, \r\n    375, \r\n    376, \r\n    377, \r\n    380, \r\n    382, \r\n    383, \r\n    384, \r\n    385, \r\n    389, \r\n    391, \r\n    392, \r\n    393, \r\n    394, \r\n    397, \r\n    399, \r\n    400, \r\n    401, \r\n    402, \r\n    405, \r\n    407, \r\n    408, \r\n    409, \r\n    410, \r\n    414, \r\n    416, \r\n    417, \r\n    418, \r\n    419, \r\n    422, \r\n    424, \r\n    425, \r\n    426, \r\n    427, \r\n    430, \r\n    432, \r\n    433, \r\n    434, \r\n    435, \r\n    441, \r\n    442, \r\n    444\r\n  ],\r\n  ""heads"": [[445, 0]]\r\n}\r\n']","['broadcast_add', '""ml.dmlc.mxnet"" % ""mxnet-full_2.10-osx-x86_64-cpu"" % ""0.1.1""', 'Symbol.broadcast_add']",0,0
279,incubator-mxnet,12843,closed,MXNet doesn't work with scipy int64,"The following code doesn't work.

It generates the error as below:
",Bug Python,"['@mxnet-label-bot please add [bug, python, feature]', ""I don't think this is a feature request. Removing label feature..\r\n"", ""In SciPy, the dtype `np.int64` is upcasted to `np.longlong` when `csr_matrix` is called.\r\n```\r\n>>> np.int64 == np.longlong\r\nFalse\r\n>>> np.int64\r\n<class 'numpy.int64'>\r\n>>> np.longlong\r\n<class 'numpy.int64'>\r\n```\r\nPlease see the link: https://github.com/scipy/scipy/blob/master/scipy/sparse/coo.py#L358\r\n\r\n```python\r\nimport numpy as np\r\nimport scipy as sp\r\nimport mxnet as mx\r\n\r\none = np.ones((2, 2), dtype='int64')\r\nsp_one = sp.sparse.csr_matrix(one).data\r\n\r\nprint (np.dtype(sp_one.dtype).type)\r\nprint (id(np.dtype(sp_one.dtype).type))\r\n\r\nprint (np.dtype(np.int64).type)\r\nprint (id(np.dtype(np.int64).type))\r\n\r\nprint (np.int64)\r\nprint (id(np.int64))\r\n```\r\n\r\n```bash\r\n<type 'numpy.int64'>\r\n139671667680256\r\n<type 'numpy.int64'>\r\n139671667680672\r\n<type 'numpy.int64'>\r\n139671667680672\r\n```"", '@zheng-da According to PR #12972  this is a scipy issue rather than a MXNet issue, do you think we should close this issue? ', ""@zheng-da Close this issue since it's been identify a Scipy bug rather than MXNet. Please feel free to reopen if you feel like some alternative action should be taken here.""]","[""python\r\nimport numpy as np\r\nimport scipy as sp\r\nimport mxnet as mx\r\n\r\none = np.ones((2, 2), dtype='int64')\r\nprint(np.dtype(one.dtype).type == np.int64)\r\nsp_one = sp.sparse.csr_matrix(one).data\r\nmx.nd.array(sp_one, dtype=sp_one.dtype)\r\n"", '\r\nTraceback (most recent call last):\r\n  File ""test.py"", line 8, in <module>\r\n    mx.nd.array(sp_one, dtype=sp_one.dtype)\r\n  File ""/home/ubuntu/incubator-mxnet/python/mxnet/ndarray/utils.py"", line 146, in array\r\n    return _array(source_array, ctx=ctx, dtype=dtype)\r\n  File ""/home/ubuntu/incubator-mxnet/python/mxnet/ndarray/ndarray.py"", line 2488, in array\r\n    arr = empty(source_array.shape, ctx, dtype)\r\n  File ""/home/ubuntu/incubator-mxnet/python/mxnet/ndarray/ndarray.py"", line 3874, in empty\r\n    return NDArray(handle=_new_alloc_handle(shape, ctx, False, dtype))\r\n  File ""/home/ubuntu/incubator-mxnet/python/mxnet/ndarray/ndarray.py"", line 139, in _new_alloc_handle\r\n    ctypes.c_int(int(_DTYPE_NP_TO_MX[np.dtype(dtype).type])),\r\nKeyError: <type \'numpy.int64\'>\r\n']",[],0,0
280,incubator-mxnet,5028,closed,"I want to implement CNN_LSTM_CTC with C++ instead of Python, but an error arises out","I have implemented model with Python sucessfully but an error arises out in C++:

param-symbol.json ... 278523 bytes
param-0020.params ... 38367630 bytes
[15:32:30] E:\OpenSource\mxnet0.9.3\mxnet\src\nnvm\legacy_json_util.cc:153: Load
ing symbol saved by previous version v0.9.1. Attempting to upgrade...
[15:32:39] E:\OpenSource\mxnet0.9.3\mxnet\nnvm\include\dmlc/logging.h:300: [15:3
2:39] e:\opensource\mxnet0.9.3\mxnet\src\operator\./softmax_output-inl.h:307: Ch
eck failed: (*in_type)[i] == dtype (4 vs. 0) This layer requires uniform type. E
xpected 0 v.s. given 4 at label
Assertion failed: pred_hnd, file E:\OpenSource\mxnet0.9.3\mxnet\example\image-cl
assification\predict-cpp\image-classification-predict.cc, line 227
--------------------------------------------------------------------------------------------
here is my code:


----------------------------------------------------------------------
How can I fix it?",,"['The input data type for your softmax is wrong. What is your input type for label? it asked for float type.', 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!']",[],"['std::string json_file = ""param-symbol.json"";\r\n    std::string param_file = ""param-0020.params"";\r\n\r\n\r\n    BufferFile json_data(json_file);\r\n    BufferFile param_data(param_file);\r\n\r\n    // Parameters\r\n    int dev_type = 1;  // 1: cpu, 2: gpu\r\n    int dev_id = 0;  // arbitrary.\r\n    mx_uint num_input_nodes = 10;  // 1 for feedforward\r\n    const char* input_key[10] = {""data"", ""label"", ""forward_l0_init_c"", ""forward_l1_init_c"" , ""forward_l0_init_h"", ""forward_l1_init_h"" ,\r\n\t\t\t\t\t\t\t\t""backward_l0_init_c"", ""backward_l1_init_c"" , ""backward_l0_init_h"", ""backward_l1_init_h"" };\r\n    const char** input_keys = input_key;\r\n\r\n    // Image size and channels\r\n    int width = 64;\r\n    int height = 256;\r\n    int channels = 1;\r\n\tint num_hidden = 256;\r\n\r\n    const mx_uint input_shape_indptr[11] = { 0, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22 };\r\n    const mx_uint input_shape_data[22] = { 1, static_cast<mx_uint>(channels), static_cast<mx_uint>(width),static_cast<mx_uint>(height)\r\n\t\t\t\t\t\t\t\t\t\t ,1, static_cast<mx_uint>(32) #32 is the sequence length\r\n\t\t\t\t\t\t\t\t\t\t ,1, static_cast<mx_uint>(num_hidden)\r\n\t\t\t\t\t\t\t\t\t\t ,1, static_cast<mx_uint>(num_hidden) \r\n\t\t\t\t\t\t\t\t\t\t ,1, static_cast<mx_uint>(num_hidden) \r\n\t\t\t\t\t\t\t\t\t\t ,1, static_cast<mx_uint>(num_hidden) \r\n\t\t\t\t\t\t\t\t\t\t ,1, static_cast<mx_uint>(num_hidden) \r\n\t\t\t\t\t\t\t\t\t\t ,1, static_cast<mx_uint>(num_hidden) \r\n\t\t\t\t\t\t\t\t\t\t ,1, static_cast<mx_uint>(num_hidden) \r\n\t\t\t\t\t\t\t\t\t\t ,1, static_cast<mx_uint>(num_hidden) \r\n\t\t\t\t\t\t\t\t\t\t};\r\n    PredictorHandle pred_hnd = 0;\r\n\r\n    if (json_data.GetLength() == 0 ||\r\n        param_data.GetLength() == 0) {\r\n        return -1;\r\n    }\r\n\r\n    // Create Predictor\r\n    MXPredCreate((const char*)json_data.GetBuffer(),\r\n                 (const char*)param_data.GetBuffer(),\r\n                 static_cast<size_t>(param_data.GetLength()),\r\n                 dev_type,\r\n                 dev_id,\r\n                 num_input_nodes,\r\n                 input_keys,\r\n                 input_shape_indptr,\r\n                 input_shape_data,\r\n                 &pred_hnd);\r\n    assert(pred_hnd);']",0,0
281,incubator-mxnet,4539,closed,Scala example on website doesn't compile,"I don't know if this is the best place to communicate this, but I tried copy-pasting the only Scala [example](http://mxnet.io/tutorials/scala/mnist.html) in the website and it doesn't compile. 

I got it to compile by doing what's described below. I'm not sure whether that was the right fix (later I get a core dumped that I'll post in a separate issue). This is just a heads up for you guys to be aware of the problem with the website.

## Environment info
Operating System:
Ubuntu 16.10 amd64

Compiler:
sbt

Package used (Python/R/Scala/Julia):
Scala package
scalaVersion 2.11.8

MXNet version:
""ml.dmlc.mxnet"" % ""mxnet-full_2.10-linux-x86_64-gpu"" % ""0.1.1""

## Error Message:

## Minimum reproducible example


## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. Clone https://github.com/danimateos/mxnet-playground/tree/broken
2. 

## What have you tried to solve it?

I removed the  in

and got it to compile. ",,"['try to use the lastest mxnet version', ""The api has been updated.\r\nI'll deploy the latest scala pkg to maven repository soon."", 'Awesome, thx. Any idea what ""soon"" will mean?', '@danimateos This weekend or next week.']","['\r\nsbt compile ~/repos/mxnet-playground 0 10:56:28\r\n[info] Loading global plugins from /home/dani/myconfigs/.sbt/0.13/plugins\r\n[info] Set current project to mxnet-playground (in build file:/home/dani/repos/mxnet-playground/)\r\n[info] Compiling 1 Scala source to /home/dani/repos/mxnet-playground/target/scala-2.11/classes...\r\n[error] /home/dani/repos/mxnet-playground/src/main/scala/playground/MRE.scala:7: not enough arguments for method apply: (v1: Map[String,Any])ml.dmlc.mxnet.Symbol in trait Function1.\r\n[error] Unspecified value parameter v1.\r\n[error]   val fc1 = Symbol.FullyConnected(name = ""fc1"")()(Map(""data"" -> data, ""num_hidden"" -> 128))\r\n[error]                                                ^\r\n[error] one error found\r\n[error] (compile:compileIncremental) Compilation failed\r\n[error] Total time: 2 s, completed Jan 5, 2017 10:56:43 AM\r\n', 'scala\r\nimport ml.dmlc.mxnet._\r\n\r\nobject MRE extends App {\r\n  val data = Symbol.Variable(""data"")\r\n  val fc1 = Symbol.FullyConnected(name = ""fc1"")()(Map(""data"" -> data, ""num_hidden"" -> 128))\r\n}\r\n', 'scala\r\n  val fc1 = Symbol.FullyConnected(name = ""fc1"")()(Map(""data"" -> data, ""num_hidden"" -> 128))\r\n  val act1 = Symbol.Activation(name = ""relu1"")()(Map(""data"" -> fc1, ""act_type"" -> ""relu""))\r\n  val fc2 = Symbol.FullyConnected(name = ""fc2"")()(Map(""data"" -> act1, ""num_hidden"" -> 64))\r\n  val act2 = Symbol.Activation(name = ""relu2"")()(Map(""data"" -> fc2, ""act_type"" -> ""relu""))\r\n  val fc3 = Symbol.FullyConnected(name = ""fc3"")()(Map(""data"" -> act2, ""num_hidden"" -> 10))\r\n  val mlp = Symbol.SoftmaxOutput(name = ""sm"")()(Map(""data"" -> fc3))\r\n']","['sbt compile', '()']",0,0
282,incubator-mxnet,4638,closed,issue using sgd with momentum,"When I use sgd with momentum, I train for 10 epoches first and save the parameters, but the state created by mx.optimizer.Updater for gradient updates with momentum is not saved, so if I want to train the same model from 10th epoch, the state will be initialized with all zeros, which is not what i want, so i want to know whether there is the solution to this problem? Thanks",,"['use mx.callback.module_checkpoint with mx.mod.Module', '@piiswrong thanks for your help', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
283,incubator-mxnet,4303,closed,NDArrayIter hasNext ,"  // test pad
the scala code IOSuite.scala   NDArrayIter hasNext is false but the size is 32

",,"['@Ldpe2G', 'remove the line ""println(datIter0.size)""', 'because the NDArrayIter inherit DataIter, DataIter inhert Iterator, if you call the size method of an iterator,\r\nit will automatically iterate to the end.', '@rightwaitforyou you should be careful when use iterator. ', 'thanks ']","['scala\r\ndef main(args: Array[String]): Unit = {\r\n    val shape0 = Shape(Array(1000, 2, 2))\r\n    val data = IndexedSeq(NDArray.ones(shape0), NDArray.zeros(shape0))\r\n    println(data.size)\r\n    val shape1 = Shape(Array(1000, 1))\r\n    val label = IndexedSeq(NDArray.ones(shape1))\r\n    println(label.size);\r\n    val batchData0 = NDArray.ones(Shape(Array(128, 2, 2)))\r\n    val batchData1 = NDArray.zeros(Shape(Array(128, 2, 2)))\r\n    val batchLabel = NDArray.ones(Shape(Array(128, 1)))\r\n    val dataIter0 = new NDArrayIter(data, label, 32, false, ""pad"")\r\n    var batchCount = 0\r\n    val nBatch0 = 8\r\n    println(dataIter0.size)\r\n    println(dataIter0.hasNext)\r\n    while(dataIter0.hasNext) {\r\n      val tBatch = dataIter0.next()\r\n      batchCount += 1\r\n      println(batchCount)\r\n    }\r\n}\r\n']",[],0,0
284,incubator-mxnet,3086,closed,"In R documentation, remind user that softmax labels are 0 indexed","In R, I wasted hours figuring out that labels are zero-indexed, because in R it is natural to assume everything are 1-indexed. In the attached file, if the labels are 0-indexed, then the predictions will appear inaccurate.

I suggest that in the documentation for 'mx.mlp' and 'mx.model.FeedForward.create' and others that can use softmax included something saying the 'y' or 'label' is zero-indexed in the case of softmax


[R.txt](https://github.com/dmlc/mxnet/files/429063/R.txt)
",R,"['Really thanks for this. Can you send a PR on this?\n\nIt will be truly appreciated.\n', ""I'm a newby on PR requests, but can be pointed to a tutorial or include examples in this forum.\n""]","['\r\nrequire(""mxnet"")\r\n# cs231n example of softmax\r\n# GENERATE DATA\r\n\r\nN = 100 # number of points per class\r\nD = 2 # dimensionality\r\nK = 3 # number of classes\r\nnum_examples = N*K\r\nX = matrix(0,num_examples,D) # data matrix (each row = single example)\r\ny = rep(0,num_examples) # class labels\r\n\r\nfor (j in 0:(K-1)){\r\n  ix = seq(N_j+1,N_(j+1))\r\n  r = seq(0.0,1,length.out=N) # radius\r\n  t = seq(j_4,(j+1)_4,length.out=N) + rnorm(N)_0.2 # theta\r\n  X[ix,1] = r_sin(t)\r\n  X[ix,2]= r*cos(t)\r\n  y[ix] = j +1\r\n}\r\n# lets visualize the data:\r\n\r\nplot(X[, 1], X[, 2], col=rainbow(3)[y])\r\n\r\nhidden = h = 100\r\n# METHOD 1, Adjust input labels\r\n\r\nmodel = mx.mlp(X, y-1, \r\n               hidden_node = c(100), \r\n               out_node = 3, \r\n               num.round = 10000,\r\n               out_activation = ""softmax"",\r\n               learning.rate = 1e-0,\r\n               wd = 1e-3,\r\n               array.layout = ""rowmajor"",\r\n               initializer=mx.init.normal(0.01))\r\n\r\npredicted_class = apply(as.array(predict(model, X, array.layout = \'rowmajor\')),2,which.max)\r\ncat(""accuracy:"",mean(predicted_class==y),""\\n"")\r\nplot(X[, 1], X[, 2], col=rainbow(3)[y], pch = ifelse(predicted_class==y,1,4)  )\r\n# INCORRECT WAY\r\n\r\nbrowser()\r\nmodel = mx.mlp(X, y, \r\n               hidden_node = c(100), \r\n               out_node = 3, \r\n               num.round = 10000,\r\n               out_activation = ""softmax"",\r\n               learning.rate = 1e-0,\r\n               wd = 1e-3,\r\n               array.layout = ""rowmajor"",\r\n               initializer=mx.init.normal(0.01))\r\n\r\npredicted_class = apply(as.array(predict(model, X, array.layout = \'rowmajor\')),2,which.max)\r\ncat(""accuracy:"",mean(predicted_class==y),""\\n"")\r\nplot(X[, 1], X[, 2], col=rainbow(3)[y], pch = ifelse(predicted_class==y,1,4)  )\r\n\r\n']",[],0,0
285,incubator-mxnet,11430,closed,lstm_bucketing example has evenly divide problem with self create dataset ,"## Description
problem happened with a self-created dataset for lstm_bucketing example on CPU

But dataset with rnn-time-major works good 

## Environment info (Required)

floatnp.floatingnp.float64 == np.dtype(float).type

Package used (Python/R/Scala/Julia):

Python 

MXNet commit hash:
7c1acb489a2d7546ffac55f5c2764f1e92e77306

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from  to  is deprecated. In future, it will be treated as .
  from ._conv import register_converters as _register_converters
WARNING: discarded 0 sentences longer than the largest bucket.
WARNING: discarded 0 sentences longer than the largest bucket.
Traceback (most recent call last):
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/symbol/symbol.py"", line 1521, in simple_bind
    ctypes.byref(exe_handle)))
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/base.py"", line 210, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator split0: [13:51:38] src/operator/./slice_channel-inl.h:208: Check failed: dshape[real_axis] % param_.num_outputs == 0U (10 vs. 0) You are trying to split the 1-th axis of input tensor with shape [32,30,200] into num_outputs=20 evenly sized chunks, but this is not possible because 20 does not evenly divide 30

Stack trace returned 10 entries:
[bt] (0) 0   libmxnet.so                         0x000000011c0dcab4 libmxnet.so + 19124
[bt] (1) 1   libmxnet.so                         0x000000011c0dc86f libmxnet.so + 18543
[bt] (2) 2   libmxnet.so                         0x000000011d6873f1 MXTVMBridge + 3552369
[bt] (3) 3   libmxnet.so                         0x000000011d3170ce MXNDListFree + 1644494
[bt] (4) 4   libmxnet.so                         0x000000011d1d477a MXNDListFree + 323194
[bt] (5) 5   libmxnet.so                         0x000000011d1cce8c MXNDListFree + 292236
[bt] (6) 6   libmxnet.so                         0x000000011d1bf8d6 MXNDListFree + 237526
[bt] (7) 7   libmxnet.so                         0x000000011d1c544a MXNDListFree + 260938
[bt] (8) 8   libmxnet.so                         0x000000011d151e40 MXExecutorSimpleBind + 8656
[bt] (9) 9   libffi.6.dylib                      0x000000010dea8884 ffi_call_unix64 + 76



During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""lstm_bucketing.py"", line 126, in <module>
    batch_end_callback  = mx.callback.Speedometer(args.batch_size, args.disp_batches, auto_reset=False))
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/base_module.py"", line 515, in fit
    self.forward_backward(data_batch)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/base_module.py"", line 194, in forward_backward
    self.forward(data_batch, is_train=True)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/bucketing_module.py"", line 455, in forward
    data_batch.provide_label)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/bucketing_module.py"", line 376, in switch_bucket
    force_rebind=False, shared_module=self._buckets[self._default_bucket_key])
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/module.py"", line 430, in bind
    state_names=self._state_names)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/executor_group.py"", line 279, in __init__
    self.bind_exec(data_shapes, label_shapes, shared_group)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/executor_group.py"", line 375, in bind_exec
    shared_group))
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/module/executor_group.py"", line 662, in _bind_ith_exec
    shared_buffer=shared_data_arrays, **input_shapes)
  File ""/anaconda3/lib/python3.6/site-packages/mxnet/symbol/symbol.py"", line 1527, in simple_bind
    raise RuntimeError(error_msg)
RuntimeError: simple_bind error. Arguments:
data: (32, 30)
softmax_label: (32, 30)
Error in operator split0: [13:51:38] src/operator/./slice_channel-inl.h:208: Check failed: dshape[real_axis] % param_.num_outputs == 0U (10 vs. 0) You are trying to split the 1-th axis of input tensor with shape [32,30,200] into num_outputs=20 evenly sized chunks, but this is not possible because 20 does not evenly divide 30

Stack trace returned 10 entries:
[bt] (0) 0   libmxnet.so                         0x000000011c0dcab4 libmxnet.so + 19124
[bt] (1) 1   libmxnet.so                         0x000000011c0dc86f libmxnet.so + 18543
[bt] (2) 2   libmxnet.so                         0x000000011d6873f1 MXTVMBridge + 3552369
[bt] (3) 3   libmxnet.so                         0x000000011d3170ce MXNDListFree + 1644494
[bt] (4) 4   libmxnet.so                         0x000000011d1d477a MXNDListFree + 323194
[bt] (5) 5   libmxnet.so                         0x000000011d1cce8c MXNDListFree + 292236
[bt] (6) 6   libmxnet.so                         0x000000011d1bf8d6 MXNDListFree + 237526
[bt] (7) 7   libmxnet.so                         0x000000011d1c544a MXNDListFree + 260938
[bt] (8) 8   libmxnet.so                         0x000000011d151e40 MXExecutorSimpleBind + 8656
[bt] (9) 9   libffi.6.dylib                      0x000000010dea8884 ffi_call_unix64 + 76



## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. python lstm_bucketing.py
",Bug Example Python,"['Hi @liyujiel thanks for submitting the issue, @sandeep-krishnamurthy requesting this be labeled.']",[],"['', ""\r\n----------Python Info----------\r\nVersion      : 3.6.4\r\nCompiler     : GCC 7.2.0\r\nBuild        : ('default', 'Jan 16 2018 18:10:19')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 9.0.1\r\nDirectory    : /home/ubuntu/anaconda3/lib/python3.6/site-packages/pip\r\n----------MXNet Info-----------\r\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from "", ' to ', ' is deprecated. In future, it will be treated as ', '.\r\n  from ._conv import register_converters as _register_converters\r\nVersion      : 1.3.0\r\nDirectory    : /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet\r\nCommit Hash   : 5550c0afe4b202c573a1cc0e2387447c8a888769\r\n----------System Info----------\r\nPlatform     : Linux-4.4.0-1061-aws-x86_64-with-debian-stretch-sid\r\nsystem       : Linux\r\nnode         : ip-172-31-25-194\r\nrelease      : 4.4.0-1061-aws\r\nversion      : #70-Ubuntu SMP Fri May 25 21:47:34 UTC 2018\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                32\r\nOn-line CPU(s) list:   0-31\r\nThread(s) per core:    2\r\nCore(s) per socket:    16\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\nStepping:              1\r\nCPU MHz:               2699.625\r\nCPU max MHz:           3000.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              4600.08\r\nHypervisor vendor:     Xen\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              46080K\r\nNUMA node0 CPU(s):     0-31\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single kaiser fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0021 sec, LOAD: 0.3551 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0739 sec, LOAD: 0.0567 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0908 sec, LOAD: 0.4070 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0037 sec, LOAD: 0.9360 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0038 sec, LOAD: 0.1142 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0030 sec, LOAD: 0.0294 sec.\r\n\r\n', '', 'float', 'np.floating', 'np.float64 == np.dtype(float).type']",0,0
286,incubator-mxnet,14112,closed,CMakeLists.txt,line 33   AND (NOT MSVC) ? MKLDNN不支持VC编译器吗,CMake MKLDNN Windows,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Build', 'Thanks @975150313 for the question.\r\n\r\n@ZhennanQin @xinyu-intel could you help answer the question?', '@975150313 AFAIK, MKLDNN supports windows build with VC. USE_MKLDNN is turned on by default in MXNet recently, and this default enabling is on Linux build only. After some more testing, we may enable MKLDNN by default on other platform like windows. for now you can manually enable MKLDNN with cmake option `-DUSE_MKLDNN`.', '@975150313  Please refer to [the readme of MKL-DNN backend](https://github.com/apache/incubator-mxnet/blob/master/MKLDNN_README.md#3) for the build on Windows.', '> @ 975150313 请参阅[MKL-DNN后端自述文件，](https://github.com/apache/incubator-mxnet/blob/master/MKLDNN_README.md#3)了解Windows上的内置版本。\r\n\r\nLast version of Make can find MKLDNN, but now this version of Make can not compile MKLDNN to mxnet.', '> @975150313 AFAIK, MKLDNN supports windows build with VC. USE_MKLDNN is turned on by default in MXNet recently, and this default enabling is on Linux build only. After some more testing, we may enable MKLDNN by default on other platform like windows. for now you can manually enable MKLDNN with cmake option `-DUSE_MKLDNN`.\r\n\r\n![qq 20190211130553](https://user-images.githubusercontent.com/24599391/52546914-12b05580-2dfe-11e9-84aa-66fa88218e58.jpg)\r\n\r\nMkl has been installed on my computer and CMake has recognized it, but there is no MKL-DNN option in CMake, and there is no third-party library of MKL DNN in the compiled bulid folder.', '@mxnet-label-bot \r\nThank you for your reply. I will pay attention to the relevant labels.', '@juliusshufan \r\n\r\n@mxnet-label-bot add [windows]\r\n', 'Thank you very much. The community problem has been solved.']",[],[],0,0
287,incubator-mxnet,5900,closed,Using CrossEntropyLoss in the output layer,"I am trying to use the CrossEntropyLoss() layer as an output, and get an error saying it needs 2 inputs. (data and label). But when I instead use SoftmaxOutput, I only need to provide the data, and the label is provided via the training iterator. Is there a way I can use the cross entropy loss with only providing data?


## Minimum reproducible example


depth = 3

	data = mx.sym.Variable('data')
	# layer 1 is as defined
	net = mx.sym.FullyConnected(data=data,name='fc1',num_hidden=64)
	net = mx.sym.Activation(data=net,name='ac1',act_type=""relu"")
	net = mx.sym.Dropout(data=net,name='dl1',p=0.1)
	# remaining hidden layers
	for layer in xrange(2,depth+1):
		net = mx.sym.FullyConnected(data=net,name='fc'+str(layer),num_hidden=64)
		net = mx.sym.Activation(data=net,name='ac'+str(layer),act_type=""relu"")
		net = mx.sym.Dropout(data=net,name='dl'+str(layer),p=0.1)
	# output layer
	net = mx.sym.FullyConnected(data=net,name='fcout',num_hidden=10)
	net = mx.sym.SoftmaxOutput(data=net,name='softmax')
	#net = rt.CrossEntropyLoss(data=net)
	return net

uncommenting the second-last line above (and commenting the line above it) gives me the error
",,"['@nikrao , there is no `CrossEntropyLoss` symbol in MXNet, `mx.sym.SoftmaxOutput()` implements the cross entropy loss, see [here](http://mxnet.io/api/python/symbol.html#mxnet.symbol.SoftmaxOutput). ', 'Hi Jeidong,\n\nbut this is only in the backward pass right? What if I only want it in a\nfeedforward network?\n\nOn Mon, Apr 24, 2017 at 6:16 PM, Jiedong Hao <notifications@github.com>\nwrote:\n\n> @nikrao <https://github.com/nikrao> , there is no CrossEntropyLoss symbol\n> in MXNet, mx.sym.SoftmaxOutput() implements the cross entropy loss, see\n> here <http://mxnet.io/api/python/symbol.html#mxnet.symbol.SoftmaxOutput>.\n>\n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dmlc/mxnet/issues/5900#issuecomment-296864096>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/ASlOLNoz1yeFA0jildzslc_-lgKrsk1Qks5rzUlfgaJpZM4NCPg3>\n> .\n>\n', '@nikrao , what do you mean by ""I only want it in a feedforward network""? I don\'t get it.', 'sorry for the confusion. I mean the following:\n\nI just have a simple feedforward NN, with, say 1 hidden layer. I guess I\'m\nconfused with the page saying: ""In the backward pass, the logit loss, also\ncalled cross-entroy loss, is added"" .\n\nDoes this mean that while training, this is actually the cross entropy loss\nthat we are trying to minimize in the objective function?\n\nthanks\n\nOn Mon, Apr 24, 2017 at 6:44 PM, Jiedong Hao <notifications@github.com>\nwrote:\n\n> @nikrao <https://github.com/nikrao> , what do you mean by ""I only want it\n> in a feedforward network""? I don\'t get it.\n>\n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dmlc/mxnet/issues/5900#issuecomment-296867886>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/ASlOLLBoCyqLzKreSbgljpsBogIW8Ea4ks5rzU_kgaJpZM4NCPg3>\n> .\n>\n', '@nikrao , yes, according to the documentation, in forward pass, this layers only computes the softmax output of previous layer (i.e., a normalized probability distribution). \r\nDuring training, the cross entropy loss is computed by combining this info and the ground truth label info.\r\nSee [here](http://mxnet.io/tutorials/python/mnist.html#) for a complete example on how to train a MLP or CNN  on the minist dataset using `mx.sym.SoftmaxOutput` as loss function.', 'I checked this out, and this seems to be doing some funky version of softmax cross entropy, and not the traditional binary cross entropy. I am interested in the multilabel problem , so this will notwork. I have to define a new loss and add it in as referenced in other issues. \r\n\r\nI will try it an open a separate issue if that does not work\r\n']",[],[],0,0
288,incubator-mxnet,1814,closed,How to initialise BatchNorm by hand?,"Dear all,
I want to initialise the parameters of BatchNorm by hand.
Here is how I initialise  and :



Yet I encounter the following error:
 when checking the type of . I notice it is in the aux, then I am wondering what is the proper way of initialising the parameters of BatchNorm?
Thanks in advance.
",,"[' Maybe you can learn from the code example-""simple_bind"" `https://github.com/dmlc/mxnet/blob/master/example/notebooks/simple_bind.ipynb`\n\nthe code to initialize the parameters of aux_states  is like this\n\n```\naux_dict = dict(zip(aux_names, [mx.nd.zeros(shape, ctx=ctx) for shape in aux_shapes]))\nfor key, arr in aux_dict.items():\n    if ""gamma"" in key:\n        aux_dict[key][:] = 1\n    elif ""bias"" in key:\n        aux_dict[key][:] = 0\n    elif ""beta"" in key:\n        aux_dict[key][:] = 0\n```\n', '@LaoAnchor It is my mistake of mis-initialising the aux. Anyway, thank you very much for your advice.\n']","[""\nfor name, shape in zip(arg_names, arg_shapes):\n    if name in ['bn_gamma']:\n        fc_args[name] = mx.nd.array(np.ones(shape), ctx)\n    if name in [bn_beta']:\n        fc_args[name] = mx.nd.array(np.zeros(shape), ctx)\n""]","['gamma', 'beta', 'TypeError: Only Accept list of NDArrays or dict of str to NDArray', 'bn_moving_mean']",0,0
289,incubator-mxnet,6115,closed,how to share auxiliary states of batchnorm in rnn with variable length input,"hi, I want to add batchnorm layer after i2h in gru. Here is the code:



In this way, the gamma and beta of bn are shared at each time step. 
But the aux states can't be shared like this and I get this error:

seems the aux_params are unrolled with the max input length, but duplicate names are not allowed.

I also try the following code in speech_recognition example, but it seems cannot solve the unfixed number of params due to the variable length input in my case.

and it returns the aux_params index out of range error.
I find several issues related, but seems have not soloved, like #3076 and #2663.

Thanks for your time and effort.",,"[""@R1ncy Did you ever figure it out? Since I'm running the network manually and loading .params (arg_params) along with enabling batch norm, I'm running into the same error. "", 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!']","['\r\n    if dropout > 0.:\r\n        indata = mx.sym.Dropout(data=indata, p=dropout)\r\n    i2h = mx.sym.FullyConnected(data=indata,\r\n                                weight=param.gates_i2h_weight,\r\n                                bias=param.gates_i2h_bias,\r\n                                num_hidden=num_hidden * 2,\r\n                                name=""t%d_l%d_gates_i2h"" % (seqidx, layeridx))\r\n\r\n    if is_batchnorm:\r\n        i2h = mx.sym.BatchNorm(data=i2h, fix_gamma=False,\r\n                               name=""l%d_i2h_bn"" % layeridx,\r\n                               gamma=param.i2h_gamma,\r\n                               beta=param.i2h_beta)\r\n', '\r\n  File ""/usr/local/lib/python3.5/dist-packages/mxnet-0.9.5-py3.5.egg/mxnet/module/bucketing_module.py"", line 200, in init_params\r\n    force_init=force_init)\r\n  File ""/usr/local/lib/python3.5/dist-packages/mxnet-0.9.5-py3.5.egg/mxnet/module/module.py"", line 283, in init_params\r\n    self._exec_group.set_params(self._arg_params, self._aux_params)\r\n  File ""/usr/local/lib/python3.5/dist-packages/mxnet-0.9.5-py3.5.egg/mxnet/module/executor_group.py"", line 332, in set_params\r\n    exec_.copy_params_from(arg_params, aux_params)\r\n  File ""/usr/local/lib/python3.5/dist-packages/mxnet-0.9.5-py3.5.egg/mxnet/executor.py"", line 281, in copy_params_from\r\n    if name in self.aux_dict:\r\n  File ""/usr/local/lib/python3.5/dist-packages/mxnet-0.9.5-py3.5.egg/mxnet/executor.py"", line 228, in aux_dict\r\n    self._symbol.list_auxiliary_states(), self.aux_arrays)\r\n  File ""/usr/local/lib/python3.5/dist-packages/mxnet-0.9.5-py3.5.egg/mxnet/executor.py"", line 69, in _get_dict\r\n    raise ValueError(\'Duplicate names detected, %s\' % str(names))\r\nValueError: Duplicate names detected, [\'l0_i2h_bn_moving_mean\', \'l0_i2h_bn_moving_var\', \'l1_i2h_bn_moving_mean\', \'l1_i2h_bn_moving_var\', \'l0_i2h_bn_moving_mean\', \'l0_i2h_bn_moving_var\', \'l1_i2h_bn_moving_mean\', ...]\r\n', '\r\nif is_batchnorm:\r\n    batchnorm_gamma = []\r\n    batchnorm_beta = []\r\n         for seqidx in range(seq_len):\r\n             batchnorm_gamma.append(mx.sym.Variable(prefix + ""t%d_i2h_gamma"" % seqidx))\r\n             batchnorm_beta.append(mx.sym.Variable(prefix + ""t%d_i2h_beta"" % seqidx))\r\n']",[],0,0
290,incubator-mxnet,2514,closed,warp-ctc plugin compilation error,"

error is like this 

pkg-config --cflags opencvpkg-config --cflags opencv
",,"['config.mk \n1. ADD_LDFLAGS\n2. ADD_CFLAGS\n\nyou should add the include and library path of warp-ctc  to the env variable\n', 'how to set these two variable ? \n', 'make a little change about Dockerfile\n\n```\n➜  warp-docker git:(master) ✗ cat Dockerfile\nFrom dmlc/mxnet:cpu\nRUN sed -i ""s/archive.ubuntu.com/mirrors.ustc.edu.cn/g"" /etc/apt/sources.list\nRUN apt-get update && apt-get install -y cmake\nRUN  cd /home && \\\n     git clone https://github.com/baidu-research/warp-ctc && \\\n     cd warp-ctc && \\\n     mkdir build && \\\n     cd build && \\\n     cmake ../ && \\\n     make &&  make install \nRUN export LD_LIBRARY_PATH=/home/warp-ctc/build:$LD_LIBRARY_PATH && \\\n     ldconfig\n\nRUN cd /mxnet && \\\n    echo ""WARPCTC_PATH = /home/warp-ctc"" >>config.mk && \\\n    echo ""MXNET_PLUGINS += plugin/warpctc/warpctc.mk"" >>config.mk && \\\n    make -j$(nproc)\n\nVOLUME /work\nWORKDIR /work\n```\n\nthe problem goes like this \n\n```\nroot@f9df040f3302:/mxnet/example/warpctc# python toy_ctc.py \nTraceback (most recent call last):\n  File ""toy_ctc.py"", line 6, in <module>\n    import mxnet as mx\n  File ""../../python/mxnet/__init__.py"", line 7, in <module>\n    from .base import MXNetError\n  File ""../../python/mxnet/base.py"", line 43, in <module>\n    _LIB = _load_lib()\n  File ""../../python/mxnet/base.py"", line 35, in _load_lib\n    lib = ctypes.cdll.LoadLibrary(lib_path[0])\n  File ""/usr/lib/python2.7/ctypes/__init__.py"", line 443, in LoadLibrary\n    return self._dlltype(name)\n  File ""/usr/lib/python2.7/ctypes/__init__.py"", line 365, in __init__\n    self._handle = _dlopen(self._name, mode)\nOSError: libwarpctc.so: cannot open shared object file: No such file or directory\n\n```\n\ni try the following ones  just replace  /where/you/install =/home/warp-ctc/build here\n1.ln -s /where/you/install/lib/*.so /usr/lib \n2.export LD_LIBRARY_PATH=/where/you/install/lib:$LD_LIBRARY_PATH\nsudo ldconfig\nneither one is working\n\nwhat  weired is when i enter the container and use the sencond choice  ,this problem disappear \n\n```\n➜  warp-docker git:(master) ✗ docker run -it edwin/mxnet:cpu /bin/bash\nroot@2bff8e148777:/work# cd /mxnet/example/warpctc/\nroot@2bff8e148777:/mxnet/example/warpctc# python toy_ctc.py \nTraceback (most recent call last):\n  File ""toy_ctc.py"", line 6, in <module>\n    import mxnet as mx\n  File ""../../python/mxnet/__init__.py"", line 7, in <module>\n    from .base import MXNetError\n  File ""../../python/mxnet/base.py"", line 43, in <module>\n    _LIB = _load_lib()\n  File ""../../python/mxnet/base.py"", line 35, in _load_lib\n    lib = ctypes.cdll.LoadLibrary(lib_path[0])\n  File ""/usr/lib/python2.7/ctypes/__init__.py"", line 443, in LoadLibrary\n    return self._dlltype(name)\n  File ""/usr/lib/python2.7/ctypes/__init__.py"", line 365, in __init__\n    self._handle = _dlopen(self._name, mode)\nOSError: libwarpctc.so: cannot open shared object file: No such file or directory\nroot@2bff8e148777:/mxnet/example/warpctc# export LD_LIBRARY_PATH=/home/warp-ctc/build:$LD_LIBRARY_PATH\nroot@2bff8e148777:/mxnet/example/warpctc# python toy_ctc.py \nlibdc1394 error: Failed to initialize libdc1394\nbegin fit\ninfer label shape: 128\n2016-06-24 18:01:57,223 Start training with [gpu(0)]\ninfer label shape: 128\n[18:01:57] /mxnet/dmlc-core/include/dmlc/./logging.h:235: [18:01:57] src/storage/storage.cc:44: Please compile with CUDA enabled\nTraceback (most recent call last):\n  File ""toy_ctc.py"", line 161, in <module>\n    batch_end_callback=mx.callback.Speedometer(BATCH_SIZE, 50),)\n  File ""../../python/mxnet/model.py"", line 788, in fit\n    sym_gen=self.sym_gen)\n  File ""../../python/mxnet/model.py"", line 192, in _train_multi_device\n    logger=logger)\n  File ""../../python/mxnet/executor_manager.py"", line 311, in __init__\n    self.slices, train_data)\n  File ""../../python/mxnet/executor_manager.py"", line 224, in __init__\n    shared_data_arrays=self.shared_data_arrays[i])\n  File ""../../python/mxnet/executor_manager.py"", line 145, in _bind_exec\n    arg_arr = nd.zeros(arg_shape[i], ctx, dtype=arg_types[i])\n  File ""../../python/mxnet/ndarray.py"", line 815, in zeros\n    arr = empty(shape, ctx, dtype)\n  File ""../../python/mxnet/ndarray.py"", line 551, in empty\n    return NDArray(handle=_new_alloc_handle(shape, ctx, False, dtype))\n  File ""../../python/mxnet/ndarray.py"", line 68, in _new_alloc_handle\n    ctypes.byref(hdl)))\n  File ""../../python/mxnet/base.py"", line 77, in check_call\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\nmxnet.base.MXNetError: [18:01:57] src/storage/storage.cc:44: Please compile with CUDA enabled\n\n```\n', 'I did not use docker\n', '`git clone https://github.com/baidu-research/warp-ctc`\nYou cloned the code into `warp-ctc`, however in the `config.mk`, you config the  `WARPCTC_PATH` to `WARPCTC_PATH = $(HOME)/warpctc"" >>config.mk`. So I think you can either change the `WARPCTC_PATH` to `$(HOME)/warp-ctc` or rename `warp-ctc` to `warpctc`\n', '@shuokay\nno you are not true\nin config.mk  WARPCTC_PATH is already the clone target directory\n\n```\n    echo ""WARPCTC_PATH = /home/warp-ctc"" >>config.mk && \\\n```\n', ""@shuokay \n I compiled warp-ctc and mxnet successful.\nI add warp-ctc in config.mk, also generate libwarpctc.so in mxnet/lib\nbut when I run lstm_ocr.py, the problem disapper\n/*\n    sm = mx.sym.WarpCTC(data=pred, label=label, label_length = num_label, input_length = seq_len)\nAttributeError: 'module' object has no attribute 'WarpCTC'\n*/\nDid you have idea about this?\n"", '@wanghaisheng I have meet the same problem with you, when I run toy_ctc.py it occurs mxnet.base.MXNetError: [18:01:57] src/storage/storage.cc:44: Please compile with CUDA enabled\nproblem, Did you solve this problem? I want to use CPU to run this code.\n', '@sinmaystar  still not fix that \n', '@wanghaisheng issue #2470 describe he use both cpu and gpu run successfully, so it must have some way to solve this problem\n', '@everal If you have installed mxnet by `sudo python setup.py install` before, you should reinstall again.\n', '@everal I have met the same problem with you, did u solve this problem ? and how to solve this problem? thanks many!\n', '@shuokay when I run lstm_ocr.py it occurs the same problem with @everal , I have installed baidu warp-ctc and rebuild mxnet then I have uninstalled mxnet by pip uninstall, after that I have reinstall python package but it still the same problem, did u know how to solve this problem? \n', ""I also met AttributeError: 'module' object has no attribute 'WarpCTC'， and  solve it：\nuncomment the following lines：\nWARPCTC_PATH = $(HOME)/warp-ctc\nMXNET_PLUGINS += plugin/warpctc/warpctc.mk\nand reinstall the mxnet\ncopy the file:libwarpctc.so(warp-ctc/build) to usr/lib\nthen it will be ok\n"", ""```\n        thanks a lot,I have solved this problem,btw what's the accuracy do u run this code lstm_ocrI also met AttributeError: 'module' object has no attribute 'WarpCTC'， and  solve it：\n```\n\nuncomment the following lines：\nWARPCTC_PATH = $(HOME)/warp-ctc\nMXNET_PLUGINS += plugin/warpctc/warpctc.mk\nand reinstall the mxnet\ncopy the file:libwarpctc.so(warp-ctc/build) to usr/lib\nthen it will be ok\n\n—You are receiving this because you were mentioned.Reply to this email directly, view it on GitHub, or mute the thread.\n"", '@sinmaystar after epoch[9],validation-accuracy = 0.96500\n', ""@livedimg  兄弟你怎么解决module' object has no attribute 'WarpCTC'  能用中文详细说说吗？我也碰到这问题\n"", '@fq19851220 Please open config.mk file and uncomment the following lines:\r\n```\r\nWARPCTC_PATH = $(HOME)/warp-ctc\r\nMXNET_PLUGINS += plugin/warpctc/warpctc.mk\r\n```\r\ntake care the WARPCTC_PATH is our warp-ctc path so please instead of it by your correct path.\r\nand then rebuild mxnet by make clean && make -j \r\n\r\nChinese again:\r\n在mxnet目录下有一个config.mk，打开找到前面说的那两行，取消注释，然后修改WARPCTC_PATH为你的warp-ctc目录，然后重新编译mxnet，就可以了。（warp-ctc目录请到baidu warp-ctc仓库单独下载）', '@BobLiu20   谢谢', ""@BobLiu20 hello, I tried this way as you said as it in official page, but it still doesn't work .\r\nI found that if I don't comment out these two lines, it works very well.\r\nBUT when I comment out these lines, I can't REBUILD the mxnet successfully, it's crazzy.\r\nChinese : \r\n我按照官方文档安装完毕ctc后，改mxnet的config.mk的配置再重新编译mxnet就报错。warpctc测试了下没问题，mxnet不取消注释情况下编译也没问题。一取消这两行注释就报错，简直抓狂。。求教怎么办"", '@qieaaa  Can you share your error output in here? BTW, You have to specify the path of your warpctc lib for mxnet. Maybe you can export a env (eg: export LD_LIBRARY_PATH=$LIB_LIBRARY_PATH:/your/path/warp-ctc/).', '@BobLiu20 Thank you for your reply, I\'m sorry that I don\'t make myself clear.Here is what I did : \r\n1. I installed mxnet , warp-ctc respectively, totally follow the official guide. Then I run tests. each of them  works well.\r\n\r\n2. I enabled warpctc in mxnet ,commented out following lines in mxnet/config.mk\r\n    _WARPCTC_PATH = $(HOME)/warp-ctc\r\n    MXNET_PLUGINS += plugin/warpctc/warpctc.mk_\r\nrebuilt mxnet after that.\r\n\r\n3. then I get the following results,last line shows:\r\n    **_make[1]: Leaving directory `/home/lab/mxnet/dmlc-core\'_**\r\nthen the make process stopped. I found mxnet still works,but there are no bin and lib files in mxnet. when I run the lstm_ocr demo,it shows:\r\n_**Traceback (most recent call last):\r\n  File ""lstm_ocr.py"", line 157, in <module>\r\n    symbol = sym_gen(SEQ_LENGTH)\r\n  File ""lstm_ocr.py"", line 148, in sym_gen\r\n    num_label = num_label)\r\n  File ""/home/lab/mxnet/example/warpctc/lstm.py"", line 77, in lstm_unroll\r\n    sm = mx.sym.WarpCTC(data=pred, label=label, label_length = num_label, input_length = seq_len)\r\nAttributeError: \'module\' object has no attribute \'WarpCTC\'**_\r\n\r\nIt really drives me crazy. BTW, when I export a env ,it shows RuntimeError: Cannot find the files.\r\nList of candidates:\r\n_**/home/lab/mxnet/python/mxnet/libmxnet.so\r\n/home/lab/mxnet/python/mxnet/../../lib/libmxnet.so\r\n/home/lab/mxnet/python/mxnet/../../build/Release/libmxnet.so\r\nlibmxnet.so\r\n/home/lab/warp-ctc/libmxnet.so**_\r\n\r\nso I don\'t do that\r\n\r\n', '@qieaaa  Hi, It seems you don\'t had build complete because it is not lib folder with bin and lib files in mxnet. \r\n\r\nSo, Please check carefully if an error appear like ```plugin/warpctc/./warpctc-inl.h:14:17: fatal error: ctc.h: No such file or directory```.  Maybe you can search keyword ""warpctc"" in build output terminal to confirm if build done.\r\n\r\nBTW:   \r\n* Please make sure the path of warp-ctc is really in $(HOME)/warp-ctc. Because you have config it in config.mk with ```WARPCTC_PATH = $(HOME)/warp-ctc```\r\n* There are two way to build mxnet:\r\none is:\r\n```\r\nmake clean\r\ncp make/config.mk .\r\nmake -j\r\n```\r\n   another one is:\r\n```\r\nmake clean\r\nmkdir build && cd build\r\ncmake ..\r\nmake -j\r\n```\r\nI think do a make clean is nice for us.\r\nAnyway, if you still not solve, you can [Email](liubofang@cvte.com) me if possible (chat in time). ', '@qiaohaijun got exactly the same with you. Any one can help?', ""@ld909 you mean you have the same error with me ? Please follow  [this](https://github.com/baidu-research/warp-ctc/issues/46) with Mr BobLiu's solution."", 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']","['\n\n[wanghs@db2 docker-mxnet]$ cat Dockerfile\nFrom dmlc/mxnet:cpu\nRUN sed -i ""s/archive.ubuntu.com/mirrors.ustc.edu.cn/g"" /etc/apt/sources.list\nRUN apt-get update && apt-get install -y cmake\nRUN  cd ~/ && \\\n     git clone https://github.com/baidu-research/warp-ctc && \\\n     cd warp-ctc && \\\n     mkdir build && \\\n     cd build && \\\n     cmake .. && \\\n     make &&  make install\n\nRUN cd /mxnet && \\\n    echo ""WARPCTC_PATH = $(HOME)/warpctc"" >>config.mk && \\\n    echo ""MXNET_PLUGINS += plugin/warpctc/warpctc.mk"" >>config.mk && \\\n    make -j$(nproc)\n\nVOLUME /work\nWORKDIR /work\n']","['', '\n\nStep 1 : FROM dmlc/mxnet:cpu\n ---> 26b869b5bb67\nStep 2 : RUN sed -i ""s/archive.ubuntu.com/mirrors.ustc.edu.cn/g"" /etc/apt/sources.list\n ---> Using cache\n ---> f31b2e93c0a9\nStep 3 : RUN apt-get update && apt-get install -y cmake\n ---> Using cache\n ---> 5aece4b3e894\nStep 4 : RUN cd ~/ &&      git clone https://github.com/baidu-research/warp-ctc &&      cd warp-ctc &&      mkdir build &&      cd build &&      cmake .. &&      make &&  make install\n ---> Using cache\n ---> 05084853843f\nStep 5 : RUN cd /mxnet &&     echo ""WARPCTC_PATH = $(HOME)/warpctc"" >>config.mk &&     echo ""MXNET_PLUGINS += plugin/warpctc/warpctc.mk"" >>config.mk &&     make -j$(nproc)\n ---> Running in ab85027b08fa\n/bin/sh: 1: HOME: not found\ng++ -std=c++0x -DMSHADOW_FORCE_STREAM -Wall -O3 -I/mxnet/mshadow/ -I/mxnet/dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 ', ' -fopenmp  -I/warpctc/include -DMXNET_USE_NVRTC=0 -MM -MT build/plugin/warpctc/warpctc.o plugin/warpctc/warpctc.cc >build/plugin/warpctc/warpctc.d\ng++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/mxnet/mshadow/ -I/mxnet/dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 ', ' -fopenmp  -I/warpctc/include -DMXNET_USE_NVRTC=0 -c plugin/warpctc/warpctc.cc -o build/plugin/warpctc/warpctc.o\nIn file included from plugin/warpctc/warpctc.cc:8:0:\nplugin/warpctc/./warpctc-inl.h:14:17: fatal error: ctc.h: No such file or directory\n #include <ctc.h>\n                 ^\ncompilation terminated.\nmake: *** [build/plugin/warpctc/warpctc.o] Error 1\nThe command \'/bin/sh -c cd /mxnet &&     echo ""WARPCTC_PATH = $(HOME)/warpctc"" >>config.mk &&     echo ""MXNET_PLUGINS += plugin/warpctc/warpctc.mk"" >>config.mk &&     make -j$(nproc)\' returned a non-zero code: 2\n\n', '']",0,0
291,incubator-mxnet,6530,closed,nvvm's NNSymbolListInputNames,"nvvm's NNSymbolListInputNames should be implement as a new method in symbol 
to list input names @piiswrong ",,['This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!'],[],[],0,0
292,incubator-mxnet,4800,closed,Proposed improvements for the mxnet Scala package,"I propose the following improvements for the mxnet Scala package, mostly making it more idiomatic and user-friendly for Scala users (could be in the form of a higher-level API while retaining the current API as the lower-level API):

 - Current API is full of , which is not at all idiomatic Scala. Manually rewrite them to normal Scala functions with default parameters. Without the reference of the mxnet Python API I'm really lost at how to use these layers/functions.
 - RNNs: Utilize the Scala //etc operations on s to automatically unroll the RNN computation graph. E.g. make an LSTM unit as a function of type , so that you can just say  to unroll an LSTM network.
 - Revamping the BucketIO/DataBatch/etc. stuff to be more Scala-idiomatic.
 - Support for GPU on Mac OS X (I've attempted this but failed)
 - Better documentations
 - Better API for executors/gradients maps/etc.
 - [tentative] Typesafe s. Encode the rank/order of the tensor into the type system (What Scala is good at! ), so that an NDArray like  means that it is of rank-3 and each cell contains a  (can be done with the typeclass / phantom type pattern in Scala and with shapeless (https://github.com/milessabin/shapeless)). Concatenation/slicing/etc. will all encode the ranks of the resulting NDArray/Symbol. This enhances compile-time type safety, e.g.  layer is a function whose type is . You cannot pass a symbol with  into an embedding layer.
 - [tentative] Migrate the build system from  to .

I can first come up with a prototype of this (also for my own use in NLP research) and we can discuss.

@javelinjs @Ldpe2G @piiswrong @jermainewang ",Call for Contribution Feature request Roadmap Scala,"['I agree with most of your suggestions, especially for the RNN and IO things.\r\nTo modify the `kwargs` argument, we have to detect the arguments (with their types) of registered C++ functions, which may encounter some difficulties. Currently the c api doc may not be well defined for programs, e.g., the types. We need to check all the operators to make sure `scala macros` can get enough information.', '`kwargs` is difficult to deal with. How about relinquishing macros and do it manually? Or retain those APIs with `kwargs` as low-level API and wrap them up in an idiomatic way as the high-level API (prototypical example: https://github.com/ctongfei/nexus-mxnet/blob/master/src/main/scala/nexus/mxnet/Expr.scala#L51)', ""I'm working on a run interface for python. You can use it as a reference.\nIt's currently sitting in pull request\n\n\nTongfei Chen <notifications@github.com>于2017年1月24日 周二下午7:18写道：\n\n> kwargs is difficult to deal with. How about relinquishing macros and do\n> it manually? Or retain those APIs with kwargs as low-level API and wrap\n> them up in an idiomatic way as the high-level API (prototypical example:\n> https://github.com/ctongfei/nexus-mxnet/blob/master/src/main/scala/nexus/mxnet/Expr.scala#L51\n> )\n>\n>\n>\n>\n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dmlc/mxnet/issues/4800#issuecomment-275008592>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AAiudDSPd_Y7EdeHj9fTbtJsxZpHEy_Sks5rVr8PgaJpZM4LtAFs>\n> .\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n"", '@ctongfei Thanks for your suggestions. In my opinion, I think the high-level api you designed is good but a little hard to understand. Because I am not very famililar with the High-level syntax of Scala. Those users come from java side may encounter the same problem when they try to read the source code.\r\nAlso this is just my personal opinion.', '@Ldpe2G what about this? (https://github.com/ctongfei/nexus-mxnet/blob/master/src/test/scala/nexus/mxnet/MNIST.scala#L17)\r\n\r\nOr we could first publish a simple, clean Java API instead of a Scala one (java has a much larger audience), and then delegate all those fancy stuffs to Scala.', '@ctongfei ok I see. Users could construct a net with less code and a more elegant way.', ""@ctongfei The arguments for `FullyConnected`, and the name `FullyConnected` itself should be automatically generated. Otherwise it'll be too hard to sync with the cpp core."", ""@javelinjs It'd be desirable if it could be automatically generated. Is the c++ core constantly changing?"", ""I don't think doing it manually is a good idea. That really suffered so we turned to code generation. The operators can be added, deprecated, so as their arguments. And from the view of design, those changes should not be done twice, in core and its front-end binding. \r\n\r\nI think what we need to do is to ensure that scala macros can correctly parse the c++ api doc, especially for the argument types.\r\n\r\nBTW, your api design in `nexus-mxnet` is quite cool."", ""Got it. I'll read the scala macro code to see if there something I can do."", '@ctongfei I fully agree that a more idiomatic scala API would be great (an API that take more advantage of the type system).\r\n\r\nI would add one point:\r\n- use Option[T] instead of null default value for optional parameters\r\n\r\nI am willing to help if an effort in this direction is started.', '@benqua `Option[T]` would be weird because whenever you feed in such an argument, you are going to feed a `Some[T]` there, which is not quite desirable afaik.', ""@javelinjs @Ldpe2G I'll be working on my prototype `nexus-mxnet` in my freetime (next step: RNN/executor/etc.)"", '@ctongfei Great ! look forward to it.', 'I agree it would be better to avoid Option in the public API whenever possible. However, better have Option than null.\nWe should get rid of the null.', 'Is there any progress / activity on this?', ""I have updated with a CWiki page here: https://cwiki.apache.org/confluence/display/MXNET/Scala+Project+Status\r\nLet's keep all TODOs into one place and also pick up from there. @yzhliu @nswamy let's close this for now.""]",[],"['kwargs: Map[String, Any]', 'foldLeft', 'scanLeft', 'Seq', '(LSTMState, Symbol) => LSTMState)', 'xs.foldLeft(lstm)', 'NDArray', 'NDArray[Float, _3]', 'Float', 'Embedding', 'Symbol[Int, N] => Symbol[Float, N+1]', 'Float', 'maven', 'sbt']",0,0
293,incubator-mxnet,8564,closed,Test Crash -test_operator_gpu.test_residual_fused,"## Description
The test test_operator_gpu.test_residual_fused is causing a Cuda 'too many resources' error during a tests with the latest build of MXNet.

## Environment info (Required)
p2 instance with DLAMI CUDA 9, latest MXNet built with cmake.



Package used (Python/R/Scala/Julia):
Python

## Build info (Required if built from source)

Compiler gcc.

MXNet commit hash:
990bab865f5c8da168a2e68c4c6cc04fa3b117d7

Build config:
cmake -GNinja ..

## Error Message:

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.  Build using cmake
2.  Install
3.  Run gpu tests (python3 -m nose --verbose) in incubator-mxnet/tests/python/gpu.

Note: running the test individually works.

## What have you tried to solve it?

1.  Mark test as crashing.
",,"['@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', 'Hi @KellenSunderland , are you still facing the same issue? We are sorry to reply to you too late. Please try it with our most recent package V1.2. If the problem still live in there, please let me know. ', 'not able to reproduce this issue. \r\n\r\n@KellenSunderland If this is a flaky test then we should track it here - https://github.com/apache/incubator-mxnet/projects/9#card-10771341\r\n']","[""\r\n----------Python Info----------\r\nVersion      : 3.5.2\r\nCompiler     : GCC 5.4.0 20160609\r\nBuild        : ('default', 'Sep 14 2017 22:51:06')\r\nArch         : ('64bit', 'ELF')\r\n------------Pip Info-----------\r\nVersion      : 9.0.1\r\nDirectory    : /usr/local/lib/python3.5/dist-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 0.12.1\r\nDirectory    : /home/ubuntu/incubator-mxnet/python/mxnet\r\nHashtag not found. Not installed from pre-built package.\r\n----------System Info----------\r\nPlatform     : Linux-4.4.0-1022-aws-x86_64-with-Ubuntu-16.04-xenial\r\nsystem       : Linux\r\nnode         : ip-172-31-11-178\r\nrelease      : 4.4.0-1022-aws\r\nversion      : #31-Ubuntu SMP Tue Jun 27 11:27:55 UTC 2017\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                4\r\nOn-line CPU(s) list:   0-3\r\nThread(s) per core:    2\r\nCore(s) per socket:    2\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\nStepping:              1\r\nCPU MHz:               2699.984\r\nCPU max MHz:           3000.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              4600.05\r\nHypervisor vendor:     Xen\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              46080K\r\nNUMA node0 CPU(s):     0-3\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.3053 sec, LOAD: 0.6754 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0809 sec, LOAD: 0.1547 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0610 sec, LOAD: 0.3025 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0030 sec, LOAD: 0.3299 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0647 sec, LOAD: 0.6408 sec.\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0014 sec, LOAD: 0.6714 sec.\r\n"", '\r\n[21:37:20] /home/ubuntu/incubator-mxnet/dmlc-core/include/dmlc/logging.h:308: [21:37:20] /home/ubuntu/incubator-mxnet/mshadow/mshadow/././././cuda/tensor_gpu-inl.cuh:110: Check failed: err == cudaSuccess (7 vs. 0) Name: MapPlanKernel ErrStr:too many resources requested for launch\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /home/ubuntu/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fe280fe89ac]\r\n[bt] (1) /home/ubuntu/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(_ZN7mshadow4cuda7MapPlanINS_2sv6savetoENS_6TensorINS_3gpuELi2EfEENS_4expr9ScalarExpIfEEfEEvNS7_4PlanIT0_T2_EERKNSA_IT1_SC_EENS_5ShapeILi2EEEP11CUstream_st+0x1d1) [0x7fe281014a81]\r\n[bt] (2) /home/ubuntu/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet7ndarray4EvalIN7mshadow3gpuEEEvRKfPNS_5TBlobENS_10RunContextE+0x168) [0x7fe280fcfb08]\r\n[bt] (3) /home/ubuntu/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(+0x15602d7) [0x7fe281e232d7]\r\n[bt] (4) /home/ubuntu/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(_ZNSt17_Function_handlerIFvN5mxnet10RunContextENS0_6engine18CallbackOnCompleteEEZNS0_6Engine8PushSyncESt8functionIFvS1_EENS0_7ContextERKSt6vectorIPNS2_3VarESaISC_EESG_NS0_10FnPropertyEiPKcEUlS1_S3_E_E9_M_invokeERKSt9_Any_dataOS1_OS3_+0x4b) [0x7fe2811e0a7b]\r\n[bt] (5) /home/ubuntu/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet6engine14ThreadedEngine15ExecuteOprBlockENS_10RunContextEPNS0_8OprBlockE+0x93) [0x7fe2832d40d3]\r\n[bt] (6) /home/ubuntu/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(_ZNSt17_Function_handlerIFvSt10shared_ptrIN5mxnet6engine10ThreadPool11SimpleEventEEEZZNS2_23ThreadedEnginePerDevice13PushToExecuteEPNS2_8OprBlockEbENKUlvE1_clEvEUlS5_E_E9_M_invokeERKSt9_Any_dataOS5_+0x123) [0x7fe2832d8393]\r\n[bt] (7) /home/ubuntu/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(_ZNSt6thread5_ImplISt12_Bind_simpleIFSt8functionIFvSt10shared_ptrIN5mxnet6engine10ThreadPool11SimpleEventEEEES8_EEE6_M_runEv+0x4a) [0x7fe2832d526a]\r\n[bt] (8) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80) [0x7fe29a1d8c80]\r\n[bt] (9) /lib/x86_64-linux-gnu/libpthread.so.0(+0x76ba) [0x7fe29b69c6ba]\r\n']",[],0,0
294,incubator-mxnet,7279,closed,Batch processing for rcnn prediction,"I want to send pictures to rcnn network for prediction by batch. Does the current rcnn function like im_detect() and Predictor() support this. If they do not support this function, what change should I do to achieve the goal?",,"['This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!\nAlso, do please check out our [forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) for general ""how-to"" questions.']",[],[],0,0
295,incubator-mxnet,16930,closed,Plug and Play fit_batch() for the estimator class,"## Description
In the current estimator implementation, fit_batch() is a class method of the estimator class. A common workflow of fit_batch() is that the model  forwards the training batch to generate outputs and compute loss functions. The problem is that such design is not flexible enough with different model forward interfaces on the same task. For example, fit_batch() of the base estimator trains the current batch on the label prediction task:

In the above example, the model forward interface of  is  with the return value of predict labels.  The estimator is compatible with any model using this forward interface. However, if we have another model for the label prediction task with a different forward interface , the base estimator is not compatible with this model even though both models share the same loss functions, training and evaluation metrics. A real world example can be found at LM models (https://github.com/dmlc/gluon-nlp/blob/c03665bafb1e0fe0fa5c2a59bbb4845393fbf9ba/src/gluonnlp/model/train/language_model.py).  and  shares the same forward interface, whereas  has a different one.

Forward interface of  and :

Forward interface of :


A straightforward workaround is to create a new customized estimator for each model interface. It will bring the issue that we need to create a standalone estimator each time we see a new model interface even on the same task. In machine learning community, it is common to see different model forward logic on the same task. This approach will leads to prohibitively many estimators for some simple task. In the above LM example, we need to create a  and a  even most of the training logic between these two estimators are the same.

To prevent the above estimator explosion issue, we suggest adding support of a plug and play customized  which is similar to the  for the estimator class. Given an existing estimator ,  we modify the  method to take an extra argument of . So we can call  or  to use models with different interface.
If there is no  provided, we will use the default  method.",Feature request,"['CC @sxjscience @szha @roywei ', '@szhengac ', 'A common difficulty in using callback is the confusion about signature. You can work around it by defining a class, as is done in the event handler.', ""Why don't we just pack the input and unpack it when we feed it into the model? The order of input will be determined by the user, i.e, how they construct the dataloader. The RNN model specific input `begin_state` will always serve as a keyword argument."", '> A common difficulty in using callback is the confusion about signature. You can work around it by defining a class, as is done in the event handler.\r\n\r\nOk, we will wrap it in the class.', 'The same considerations should apply to `evaluate_batch`?', '> The same considerations should apply to `evaluate_batch`?\r\n\r\nI think so', ""> Why don't we just pack the input and unpack it when we feed it into the model? The order of input will be determined by the user, i.e, how they construct the dataloader. The RNN model specific input `begin_state` will always serve as a keyword argument.\r\n\r\nThe problem is even we can use pack/unpack workaround to bypass the input/output issue. The computation of loss function may still be diverse. For example, for `standardRNN`, one has:\r\n```\r\n      output, h, encoder_hs, dropped_encoder_hs = model(X, h)\r\n      l = joint_loss(output, y, encoder_hs, dropped_encoder_hs)\r\n      Ls.append(l / (len(context) * X.size))\r\n      hiddens[j] = h\r\n```\r\nOn the other hand, for `BigRNN`, one has\r\n```\r\n      output, hidden, new_target = self._model(X, y, h, s)\r\n      output = output.reshape((-3, -1))\r\n      new_target = new_target.reshape((-1,))\r\n      ls = self._loss(output, new_target) * m.reshape((-1,))\r\n      ls = ls / args.batch_size\r\n```\r\nIn this case, we may resort to if/else clause to judge which computation routine we shall use. The code will be cumbersome in the future.\r\n\r\n""]","['\r\n        with autograd.record():\r\n            pred = [self.net(x) for x in data]\r\n            loss = [self.loss(y_hat, y) for y_hat, y in zip(pred, label)]\r\n', '\r\ndef __call__(self, inputs, begin_state=None):\r\n', '\r\ndef forward(self, inputs, label, begin_state, sampled_values):\r\n']","['self.net', 'self.net', 'def forward(self, inputs)', 'def forward(self, inputs, input_length)', 'StandardRNN', 'AWDRNN', 'BigRNN', 'StandardRNN', 'AWDRNN', 'BigRNN', 'vanillaRNNEstimator', 'BigRNNEstimator', 'fit_batch()', 'event_handlers', 'est', 'fit()', 'fit_batch_handler', 'est.fit(train_data=data_loader, epochs=epochs, fit_batch_handler=fit_StandardRNN_batch)', 'est.fit(train_data=data_loader, epochs=epochs, fit_batch_handler=fit_BigRNN_batch)', 'fit_batch_handler', 'fit_batch()']",0,0
296,incubator-mxnet,3435,closed,How to get the output of the intermediate layer?,"I want to use the output of the intermediate layer in the model. 
How to get it ?
",,"[""`symbol.get_internals()['internal_node_name']`\n"", ""``` python\ninternals = model.symbol.get_internals()\noutput_layer_you_want = internals['output_layer_name']\n\nnew_model = mx.model.create()  # use this api, pass necessary symbol(the output_layer_you_want and aug_param, etc)\nnew_model.predict()\n```\n\nSearch and you would find it.\n""]",[],[],0,0
297,incubator-mxnet,8299,closed,test_cifar10 fails in CI master build,"
## Description
test_cifar10 fails in CI master build.
Failed build: https://builds.apache.org/blue/organizations/jenkins/incubator-mxnet/detail/master/532/pipeline/

## Environment info (Required)
CI build 
Python 2 CPU


MXNet commit hash:
1c1c788916d672ee3cafdc4c91d7002a94a59d13

## Error Message:



## Steps to reproduce
Build and run unit test 

",Flaky Test,"['I couldn\'t reproduce this issue, any suggestions on what I should try? Also, how could I look for last time this test failed?\r\n\r\n\r\nTested it on CPU.. \r\n\r\n\r\nPython environment:\r\n---------------------\r\n**Python 2.7.12** (default, Dec  4 2017, 14:50:18)\r\n[GCC 5.4.0 20160609] on linux2\r\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\r\n\r\nTest runs:\r\n----------\r\n(env) :/incubator-mxnet# **MXNET_TEST_COUNT=30000 nosetests --logging-level=DEBUG --verbose -s  tests/python/train/test_dtype.py:test_cifar10**\r\n\r\ntest_dtype.test_cifar10 ... [00:15:56] src/io/iter_image_recordio_2.cc:170: ImageRecordIOParser2: data/cifar/train.rec, use 1 threads for decoding..\r\n[00:15:56] src/io/iter_image_recordio_2.cc:228: Load mean image from data/cifar/mean.bin\r\n[00:15:56] src/io/iter_image_recordio_2.cc:246: Load mean image from data/cifar/mean.bin completed\r\n[00:15:57] src/io/iter_image_recordio_2.cc:170: ImageRecordIOParser2: data/cifar/test.rec, use 1 threads for decoding..\r\n[00:15:57] src/io/iter_image_recordio_2.cc:228: Load mean image from data/cifar/mean.bin\r\n[00:15:57] src/io/iter_image_recordio_2.cc:246: Load mean image from data/cifar/mean.bin completed\r\n/incubator-mxnet/incubator-mxnet/python/mxnet/model.py:1004: DeprecationWarning: mxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\r\n  optimizer=optimizer, initializer=initializer, **kwargs)\r\n/incubator-mxnet/incubator-mxnet/python/mxnet/model.py:591: DeprecationWarning: Calling initializer with init(str, NDArray) has been deprecated.please use init(mx.init.InitDesc(...), NDArray) instead.\r\n  self.initializer(k, v)\r\nStart training with [cpu(0)]\r\nEpoch[0] Batch [50]\tSpeed: 2353.29 samples/sec\taccuracy=0.169531\r\nEpoch[0] Batch [100]\tSpeed: 3413.73 samples/sec\taccuracy=0.270000\r\nEpoch[0] Batch [150]\tSpeed: 3929.30 samples/sec\taccuracy=0.323906\r\nEpoch[0] Batch [200]\tSpeed: 5827.04 samples/sec\taccuracy=0.347656\r\nEpoch[0] Batch [250]\tSpeed: 8605.79 samples/sec\taccuracy=0.368750\r\nEpoch[0] Batch [300]\tSpeed: 7193.14 samples/sec\taccuracy=0.380000\r\nEpoch[0] Batch [350]\tSpeed: 9871.67 samples/sec\taccuracy=0.400156\r\nEpoch[0] Resetting Data Iterator\r\nEpoch[0] Time cost=10.354\r\nEpoch[0] Validation-accuracy=0.409019\r\nfinal accuracy = 0.409019\r\nEpoch[0] Batch [50]\tSpeed: 6709.95 samples/sec\taccuracy=0.183517\r\nEpoch[0] Batch [100]\tSpeed: 2762.11 samples/sec\taccuracy=0.256094\r\nEpoch[0] Batch [150]\tSpeed: 2599.24 samples/sec\taccuracy=0.316719\r\nEpoch[0] Batch [200]\tSpeed: 4019.71 samples/sec\taccuracy=0.352344\r\nEpoch[0] Batch [250]\tSpeed: 4482.44 samples/sec\taccuracy=0.362969\r\nEpoch[0] Batch [300]\tSpeed: 2311.78 samples/sec\taccuracy=0.378125\r\n^[Epoch[0] Batch [350]\tSpeed: 6287.10 samples/sec\taccuracy=0.394375\r\nEpoch[0] Train-accuracy=0.390039\r\nEpoch[0] Time cost=13.991\r\nEpoch[0] Validation-accuracy=0.415843\r\nfinal accuracy = 0.415565\r\nStart training with [cpu(0)]\r\nEpoch[0] Batch [50]\tSpeed: 4131.70 samples/sec\taccuracy=0.158438\r\nEpoch[0] Batch [100]\tSpeed: 3603.14 samples/sec\taccuracy=0.255469\r\nEpoch[0] Batch [150]\tSpeed: 3880.94 samples/sec\taccuracy=0.309688\r\nEpoch[0] Batch [200]\tSpeed: 3466.17 samples/sec\taccuracy=0.346719\r\nEpoch[0] Batch [250]\tSpeed: 1907.85 samples/sec\taccuracy=0.365625\r\nEpoch[0] Batch [300]\tSpeed: 13460.59 samples/sec\taccuracy=0.377344\r\nEpoch[0] Batch [350]\tSpeed: 3278.69 samples/sec\taccuracy=0.395781\r\nEpoch[0] Resetting Data Iterator\r\nEpoch[0] Time cost=13.526\r\nEpoch[0] Validation-accuracy=0.420985\r\nfinal accuracy = 0.420985\r\nEpoch[0] Batch [50]\tSpeed: 2937.12 samples/sec\taccuracy=0.171722\r\nEpoch[0] Batch [100]\tSpeed: 3230.27 samples/sec\taccuracy=0.271875\r\nEpoch[0] Batch [150]\tSpeed: 7009.35 samples/sec\taccuracy=0.319844\r\nEpoch[0] Batch [200]\tSpeed: 7694.27 samples/sec\taccuracy=0.345938\r\nEpoch[0] Batch [250]\tSpeed: 5635.28 samples/sec\taccuracy=0.365000\r\nEpoch[0] Batch [300]\tSpeed: 3673.31 samples/sec\taccuracy=0.387344\r\nEpoch[0] Batch [350]\tSpeed: 1934.83 samples/sec\taccuracy=0.399219\r\nEpoch[0] Train-accuracy=0.394531\r\nEpoch[0] Time cost=13.540\r\nEpoch[0] Validation-accuracy=0.419600\r\nfinal accuracy = 0.418570\r\n[00:17:02] src/io/iter_image_recordio_2.cc:170: ImageRecordIOParser2: data/cifar/train.rec, use 1 threads for decoding..\r\n[00:17:03] src/io/iter_image_recordio_2.cc:170: ImageRecordIOParser2: data/cifar/test.rec, use 1 threads for decoding..\r\nStart training with [cpu(0)]\r\nEpoch[0] Batch [50]\tSpeed: 6886.05 samples/sec\taccuracy=0.157344\r\nEpoch[0] Batch [100]\tSpeed: 2879.89 samples/sec\taccuracy=0.242969\r\nEpoch[0] Batch [150]\tSpeed: 2601.20 samples/sec\taccuracy=0.255469\r\nEpoch[0] Batch [200]\tSpeed: 3848.15 samples/sec\taccuracy=0.284531\r\nEpoch[0] Batch [250]\tSpeed: 5992.76 samples/sec\taccuracy=0.293438\r\nEpoch[0] Batch [300]\tSpeed: 3103.23 samples/sec\taccuracy=0.314219\r\nEpoch[0] Batch [350]\tSpeed: 6909.95 samples/sec\taccuracy=0.332344\r\nEpoch[0] Resetting Data Iterator\r\nEpoch[0] Time cost=13.161\r\nEpoch[0] Validation-accuracy=0.352848\r\nfinal accuracy = 0.352848\r\nEpoch[0] Batch [50]\tSpeed: 7453.44 samples/sec\taccuracy=0.161612\r\nEpoch[0] Batch [100]\tSpeed: 4445.21 samples/sec\taccuracy=0.235469\r\nEpoch[0] Batch [150]\tSpeed: 3297.28 samples/sec\taccuracy=0.266719\r\nEpoch[0] Batch [200]\tSpeed: 6435.73 samples/sec\taccuracy=0.292500\r\nEpoch[0] Batch [250]\tSpeed: 9299.93 samples/sec\taccuracy=0.310625\r\nEpoch[0] Batch [300]\tSpeed: 2478.55 samples/sec\taccuracy=0.323594\r\nEpoch[0] Batch [350]\tSpeed: 4273.77 samples/sec\taccuracy=0.324844\r\nEpoch[0] Train-accuracy=0.309180\r\nEpoch[0] Time cost=10.967\r\nEpoch[0] Validation-accuracy=0.358683\r\nfinal accuracy = 0.358474\r\nok\r\n\r\n----------------------------------------------------------------------\r\nRan 1 test in 96.476s\r\n\r\nOK', '@indhub @marcoabreu  : Do you have any further suggestions to reproduce this issue? ', ""I can't find a record of this test failing in the last weeks, sorry (the data is currently not publicly accessible). I think we can close this for now, considering we got no additional data, it's from the old CI system, from October 2017 and your run succeeded 30000 times. \r\n@indhub wdyt?"", ""Given it hasn't failed on the current CI in the last weeks, I agree we can close this. ""]","['\r\n======================================================================\r\nFAIL: test_dtype.test_cifar10\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File ""/usr/local/lib/python2.7/dist-packages/nose/case.py"", line 197, in runTest\r\n    self.test(*self.arg)\r\n  File ""/workspace/tests/python/train/test_dtype.py"", line 192, in test_cifar10\r\n    run_cifar10(train, val, use_module=True)\r\n  File ""/workspace/tests/python/train/test_dtype.py"", line 136, in run_cifar10\r\n    assert (ret[0][1] > 0.08)\r\nAssertionError: \r\n-------------------- >> begin captured logging << --------------------\r\nroot: INFO: Start training with [cpu(0)]\r\nroot: INFO: Epoch[0] Batch [50]\tSpeed: 7880.07 samples/sec\taccuracy=0.109531\r\nroot: INFO: Epoch[0] Batch [100]\tSpeed: 10121.26 samples/sec\taccuracy=0.092969\r\nroot: INFO: Epoch[0] Batch [150]\tSpeed: 9358.31 samples/sec\taccuracy=0.094375\r\nroot: INFO: Epoch[0] Batch [200]\tSpeed: 9408.26 samples/sec\taccuracy=0.100312\r\nroot: INFO: Epoch[0] Batch [250]\tSpeed: 10316.01 samples/sec\taccuracy=0.099062\r\nroot: INFO: Epoch[0] Batch [300]\tSpeed: 9913.46 samples/sec\taccuracy=0.093906\r\nroot: INFO: Epoch[0] Batch [350]\tSpeed: 10337.40 samples/sec\taccuracy=0.103750\r\nroot: INFO: Epoch[0] Resetting Data Iterator\r\nroot: INFO: Epoch[0] Time cost=5.339\r\nroot: INFO: Epoch[0] Validation-accuracy=0.099881\r\nroot: INFO: final accuracy = 0.099881\r\nroot: INFO: Epoch[0] Batch [50]\tSpeed: 7869.73 samples/sec\taccuracy=0.123775\r\nroot: INFO: Epoch[0] Batch [100]\tSpeed: 9542.55 samples/sec\taccuracy=0.099375\r\nroot: INFO: Epoch[0] Batch [150]\tSpeed: 9407.05 samples/sec\taccuracy=0.094219\r\nroot: INFO: Epoch[0] Batch [200]\tSpeed: 8906.41 samples/sec\taccuracy=0.100625\r\nroot: INFO: Epoch[0] Batch [250]\tSpeed: 9453.06 samples/sec\taccuracy=0.098125\r\nroot: INFO: Epoch[0] Batch [300]\tSpeed: 8874.91 samples/sec\taccuracy=0.093281\r\nroot: INFO: Epoch[0] Batch [350]\tSpeed: 6026.26 samples/sec\taccuracy=0.104063\r\nroot: INFO: Epoch[0] Train-accuracy=0.097656\r\nroot: INFO: Epoch[0] Time cost=6.069\r\nroot: INFO: Epoch[0] Validation-accuracy=0.099881\r\nroot: INFO: final accuracy = 0.099960\r\nroot: INFO: Start training with [cpu(0)]\r\nroot: INFO: Epoch[0] Batch [50]\tSpeed: 4614.01 samples/sec\taccuracy=0.120938\r\nroot: INFO: Epoch[0] Batch [100]\tSpeed: 6189.65 samples/sec\taccuracy=0.096562\r\nroot: INFO: Epoch[0] Batch [150]\tSpeed: 6062.91 samples/sec\taccuracy=0.094844\r\nroot: INFO: Epoch[0] Batch [200]\tSpeed: 6710.55 samples/sec\taccuracy=0.100312\r\nroot: INFO: Epoch[0] Batch [250]\tSpeed: 5982.40 samples/sec\taccuracy=0.099062\r\nroot: INFO: Epoch[0] Batch [300]\tSpeed: 7129.64 samples/sec\taccuracy=0.093906\r\nroot: INFO: Epoch[0] Batch [350]\tSpeed: 6555.40 samples/sec\taccuracy=0.103750\r\nroot: INFO: Epoch[0] Resetting Data Iterator\r\nroot: INFO: Epoch[0] Time cost=8.313\r\nroot: INFO: Epoch[0] Validation-accuracy=0.099881\r\nroot: INFO: final accuracy = 0.099881\r\nroot: INFO: Epoch[0] Batch [50]\tSpeed: 4543.26 samples/sec\taccuracy=0.119638\r\nroot: INFO: Epoch[0] Batch [100]\tSpeed: 5423.21 samples/sec\taccuracy=0.103750\r\nroot: INFO: Epoch[0] Batch [150]\tSpeed: 5033.73 samples/sec\taccuracy=0.092813\r\nroot: INFO: Epoch[0] Batch [200]\tSpeed: 9233.24 samples/sec\taccuracy=0.100469\r\nroot: INFO: Epoch[0] Batch [250]\tSpeed: 9242.30 samples/sec\taccuracy=0.099375\r\nroot: INFO: Epoch[0] Batch [300]\tSpeed: 10217.41 samples/sec\taccuracy=0.093125\r\nroot: INFO: Epoch[0] Batch [350]\tSpeed: 8666.85 samples/sec\taccuracy=0.104063\r\nroot: INFO: Epoch[0] Train-accuracy=0.092188\r\nroot: INFO: Epoch[0] Time cost=7.249\r\nroot: INFO: Epoch[0] Validation-accuracy=0.099881\r\nroot: INFO: final accuracy = 0.099960\r\nroot: INFO: Start training with [cpu(0)]\r\nroot: INFO: Epoch[0] Batch [50]\tSpeed: 8083.13 samples/sec\taccuracy=0.102656\r\nroot: INFO: Epoch[0] Batch [100]\tSpeed: 9373.58 samples/sec\taccuracy=0.101250\r\nroot: INFO: Epoch[0] Batch [150]\tSpeed: 8239.63 samples/sec\taccuracy=0.092969\r\nroot: INFO: Epoch[0] Batch [200]\tSpeed: 8116.80 samples/sec\taccuracy=0.101094\r\nroot: INFO: Epoch[0] Batch [250]\tSpeed: 8595.15 samples/sec\taccuracy=0.099531\r\nroot: INFO: Epoch[0] Batch [300]\tSpeed: 9090.94 samples/sec\taccuracy=0.093906\r\nroot: INFO: Epoch[0] Batch [350]\tSpeed: 9014.57 samples/sec\taccuracy=0.103750\r\nroot: INFO: Epoch[0] Resetting Data Iterator\r\nroot: INFO: Epoch[0] Time cost=5.879\r\nroot: INFO: Epoch[0] Validation-accuracy=0.099881\r\nroot: INFO: final accuracy = 0.099881\r\nroot: INFO: Epoch[0] Batch [50]\tSpeed: 9343.27 samples/sec\taccuracy=0.102635\r\nroot: INFO: Epoch[0] Batch [100]\tSpeed: 8417.44 samples/sec\taccuracy=0.095312\r\nroot: INFO: Epoch[0] Batch [150]\tSpeed: 9007.86 samples/sec\taccuracy=0.101094\r\nroot: INFO: Epoch[0] Batch [200]\tSpeed: 9894.47 samples/sec\taccuracy=0.103125\r\nroot: INFO: Epoch[0] Batch [250]\tSpeed: 9899.44 samples/sec\taccuracy=0.100312\r\nroot: INFO: Epoch[0] Batch [300]\tSpeed: 9939.62 samples/sec\taccuracy=0.095781\r\nroot: INFO: Epoch[0] Batch [350]\tSpeed: 10021.53 samples/sec\taccuracy=0.101250\r\nroot: INFO: Epoch[0] Train-accuracy=0.097656\r\nroot: INFO: Epoch[0] Time cost=5.316\r\nroot: INFO: Epoch[0] Validation-accuracy=0.078521\r\nroot: INFO: final accuracy = 0.078425\r\n--------------------- >> end captured logging << ---------------------\r\n\r\n[success] 29.22% test_autograd.test_autograd: 68.1240s\r\n[fail] 27.32% test_dtype.test_cifar10: 63.6942s\r\n[success] 21.17% test_bucketing.test_bucket_module: 49.3386s\r\n[success] 14.59% test_mlp.test_mlp: 33.9994s\r\n[success] 7.70% test_conv.test_mnist: 17.9464s\r\n----------------------------------------------------------------------\r\nRan 5 tests in 237.792s\r\n\r\nFAILED (failures=1)\r\n']",[],0,0
298,incubator-mxnet,1099,closed,Forward,,,[],[],[],0,0
299,incubator-mxnet,16723,closed,[Bug] fused_op does not support boolean type,"@ptrendx I find that the FusedOp does not support the boolean type. The following script will trigger the error.



Stack Trace:


We can also manually disable the Fuse OP, which will generate the correct answer.

",Bug,"['I see, this is a newly added type. We will fix this.']","['python\r\nimport mxnet as mx\r\nimport numpy as np\r\nfrom mxnet.gluon import HybridBlock\r\nmx.npx.set_np()\r\n\r\nclass Foo(HybridBlock):\r\n    def __init__(self, prefix=None, params=None):\r\n        super(Foo, self).__init__(prefix=prefix, params=params)\r\n\r\n    def hybrid_forward(self, F, valid_length):\r\n        mask = (F.np.ones((10,)) < valid_length).astype(np.float32)\r\n        mask2 = (F.np.ones((10,)) < valid_length).astype(np.float32)\r\n        mask = mask * F.np.expand_dims(mask2, axis=-1)\r\n        return mask\r\n\r\nfoo = Foo()\r\nfoo.hybridize()\r\nout = foo(mx.np.ones((10,), ctx=mx.gpu()))\r\nprint(out)\r\n', '\r\nMXNetError: [02:32:00] src/operator/fusion/fused_op.cu:76: Unknown type enum 7\r\nStack trace:\r\n  [bt] (0) /home/ubuntu/mxnet/python/mxnet/../../lib/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x32) [0x7f310563bed2]\r\n  [bt] (1) /home/ubuntu/mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::FusedOp::CheckShapesAndTypes(std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<int, std::allocator<int> >*, std::vector<int, std::allocator<int> >*, std::vector<int, std::allocator<int> >*, std::vector<int, std::allocator<int> >*, int*)+0x17b3) [0x7f310b4743c3]\r\n  [bt] (2) /home/ubuntu/mxnet/python/mxnet/../../lib/libmxnet.so(void mxnet::FusedOp::Forward<mshadow::gpu>(nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)+0x1a0) [0x7f310b47df50]\r\n  [bt] (3) /home/ubuntu/mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::imperative::PushFCompute(std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)> const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<unsigned int, std::allocator<unsigned int> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&)::{lambda(mxnet::RunContext)#1}::operator()(mxnet::RunContext) const+0x1423) [0x7f3108a01733]\r\n  [bt] (4) /home/ubuntu/mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler<void (mxnet::RunContext), mxnet::imperative::PushFCompute(std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)> const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<unsigned int, std::allocator<unsigned int> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&)::{lambda(mxnet::RunContext)#1}>::_M_invoke(std::_Any_data const&, mxnet::RunContext&&)+0x17) [0x7f3108a01c17]\r\n  [bt] (5) /home/ubuntu/mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler<void (mxnet::RunContext, mxnet::engine::CallbackOnComplete), mxnet::engine::ThreadedEngine::BulkFlush()::{lambda(mxnet::RunContext, mxnet::engine::CallbackOnComplete)#1}>::_M_invoke(std::_Any_data const&, mxnet::RunContext&&, mxnet::engine::CallbackOnComplete&&)+0x1bf) [0x7f310916266f]\r\n  [bt] (6) /home/ubuntu/mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::engine::ThreadedEngine::ExecuteOprBlock(mxnet::RunContext, mxnet::engine::OprBlock*)+0x995) [0x7f3109166475]\r\n  [bt] (7) /home/ubuntu/mxnet/python/mxnet/../../lib/libmxnet.so(void mxnet::engine::ThreadedEnginePerDevice::GPUWorker<(dmlc::ConcurrentQueueType)0>(mxnet::Context, bool, mxnet::engine::ThreadedEnginePerDevice::ThreadWorkerBlock<(dmlc::ConcurrentQueueType)0>*, std::shared_ptr<dmlc::ManualEvent> const&)+0x11d) [0x7f310917ed7d]\r\n  [bt] (8) /home/ubuntu/mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler<void (std::shared_ptr<dmlc::ManualEvent>), mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::{lambda()#4}::operator()() const::{lambda(std::shared_ptr<dmlc::ManualEvent>)#1}>::_M_invoke(std::_Any_data const&, std::shared_ptr<dmlc::ManualEvent>&&)+0x4e) [0x7f310917f02e]\r\n', ""python\r\nimport mxnet as mx\r\nimport numpy as np\r\nimport os\r\nfrom mxnet.gluon import HybridBlock\r\nmx.npx.set_np()\r\n\r\nos.environ['MXNET_USE_FUSION'] = '0'\r\n\r\nclass Foo(HybridBlock):\r\n    def __init__(self, prefix=None, params=None):\r\n        super(Foo, self).__init__(prefix=prefix, params=params)\r\n\r\n    def hybrid_forward(self, F, valid_length):\r\n        mask = (F.np.ones((10,)) < valid_length).astype(np.float32)\r\n        mask2 = (F.np.ones((10,)) < valid_length).astype(np.float32)\r\n        mask = mask * F.np.expand_dims(mask2, axis=-1)\r\n        return mask\r\n\r\nfoo = Foo()\r\nfoo.hybridize()\r\nout = foo(mx.np.ones((10,), ctx=mx.gpu()))\r\nprint(out)\r\n""]",[],0,0
300,incubator-mxnet,5591,closed,Check failed: e == cudaSuccess CUDA: no CUDA-capable device is detected,"## Environment info
Operating System: Ubuntu 16.04

Compiler:


Package used (Python/R/Scala/Julia): 

MXNet version: 

Python version and distribution: , installed under virtualenv with pypi

## Error Message:


## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

1. I'm trying to run this script: https://www.kaggle.com/drn01z3/data-science-bowl-2017/mxnet-xgboost-baseline-lb-0-57 (with  instead of ) and it's incorrectly telling that there's no CUDA-capable device, which does exist:


## What have you tried to solve it?

1. I searched a bit and couldn't find a solution. The Ubuntu installation script from  pollutes the global environment so I don't want it. I can normally run keras + tensorflow/theano stuff so I don't think there's an issue with my system.",,"[""Hmm, seems like an user error. I did a system update and it broke CUDA compatibility. Didn't realize for a bit of time it apparently...""]","['\r\n(env) ➜  src gcc --version\r\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n', '\r\n(env) ➜  src nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2015 NVIDIA Corporation\r\nBuilt on Tue_Aug_11_14:27:32_CDT_2015\r\nCuda compilation tools, release 7.5, V7.5.17\r\n', '\r\npython script.py\r\n/opt/data-science-bowl-2017/env/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\r\n  ""This module will be removed in 0.20."", DeprecationWarning)\r\n[10:43:07] src/nnvm/legacy_json_util.cc:153: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\r\n[Deprecation Warning] mxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\r\n[Deprecation Warning] mxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\r\n../data/raw/stage1/33e0e8629a377e4554b26e60a1007788\r\n[10:43:07] /home/travis/build/dmlc/mxnet-distro/mxnet-build/dmlc-core/include/dmlc/./logging.h:300: [10:43:07] /home/travis/build/dmlc/mxnet-distro/mxnet-build/mshadow/mshadow/./tensor_gpu-inl.h:35: Check failed: e == cudaSuccess CUDA: no CUDA-capable device is detected\r\n\r\nStack trace returned 6 entries:\r\n[bt] (0) /opt/data-science-bowl-2017/env/local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0x13be6c) [0x7f3be28c9e6c]\r\n[bt] (1) /opt/data-science-bowl-2017/env/local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0x9894e0) [0x7f3be31174e0]\r\n[bt] (2) /opt/data-science-bowl-2017/env/local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0x98cb20) [0x7f3be311ab20]\r\n[bt] (3) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80) [0x7f3bee132c80]\r\n[bt] (4) /lib/x86_64-linux-gnu/libpthread.so.0(+0x76ba) [0x7f3bfce116ba]\r\n[bt] (5) /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7f3bfcb4782d]\r\n\r\nterminate called after throwing an instance of \'dmlc::Error\'\r\n  what():  [10:43:07] /home/travis/build/dmlc/mxnet-distro/mxnet-build/mshadow/mshadow/./tensor_gpu-inl.h:35: Check failed: e == cudaSuccess CUDA: no CUDA-capable device is detected\r\n\r\nStack trace returned 6 entries:\r\n[bt] (0) /opt/data-science-bowl-2017/env/local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0x13be6c) [0x7f3be28c9e6c]\r\n[bt] (1) /opt/data-science-bowl-2017/env/local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0x9894e0) [0x7f3be31174e0]\r\n[bt] (2) /opt/data-science-bowl-2017/env/local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0x98cb20) [0x7f3be311ab20]\r\n[bt] (3) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80) [0x7f3bee132c80]\r\n[bt] (4) /lib/x86_64-linux-gnu/libpthread.so.0(+0x76ba) [0x7f3bfce116ba]\r\n[bt] (5) /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7f3bfcb4782d]\r\n\r\n[1]    31073 abort (core dumped)  python script.py\r\n', '\r\n01:00.0 VGA compatible controller: NVIDIA Corporation GM200 [GeForce GTX TITAN X] (rev a1) (prog-if 00 [VGA controller])\r\n        Subsystem: ASUSTeK Computer Inc. GM200 [GeForce GTX TITAN X]\r\n        Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx-\r\n        Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx-\r\n        Latency: 0\r\n        Interrupt: pin A routed to IRQ 131\r\n        Region 0: Memory at f6000000 (32-bit, non-prefetchable) [size=16M]\r\n        Region 1: Memory at e0000000 (64-bit, prefetchable) [size=256M]\r\n        Region 3: Memory at f0000000 (64-bit, prefetchable) [size=32M]\r\n        Region 5: I/O ports at e000 [size=128]\r\n        [virtual] Expansion ROM at f7000000 [disabled] [size=512K]\r\n        Capabilities: <access denied>\r\n        Kernel driver in use: nvidia\r\n        Kernel modules: nvidiafb, nouveau, nvidia_375_drm, nvidia_375\r\n']","['mxnet-cu80', '(0.9.3a3)', 'Python 2.7.12', '.gpu()', '.cpu()', 'http://mxnet.io/get_started/ubuntu_setup.html']",0,0
301,incubator-mxnet,8827,closed,Question about mx.nd.split() ?,"

when the size of data in the split axis is 1, it will return incorrect result. For example,

In [1]: import mxnet as mx

In [2]: data = mx.nd.ones((2,3,4))

In [3]: data_s = mx.nd.split(data, axis=1, num_outputs=data.shape[1], squeeze_axis=False)

In [4]: len(data_s)
Out[4]: 3

In [5]: data_s[0].shape
Out[5]: (2L, 1L, 4L)

**but, when splitting x along axis=1 below, it will return 2 NDArray.**
In [6]: x = data_s[0] #with shape  (2L, 1L, 4L)

In [8]: x_s = mx.nd.split(x, axis=1, num_outputs=x.shape[1], squeeze_axis=False)

In [9]: len(x_s)
Out[9]: 2

In [10]: x_s[0].shape
Out[10]: (1L, 4L)

Is it a bug ?",,"[""len(x_s) return the first axis value in x_s, it's 2.\r\nx_s[0] return the first column in axis=0, it has a shape (1,4) "", 'As I split along the axis=1, and x has the shape (2,1,4), so normally, it will return a list containing only one ndarray with the same shape:(2,1,4), rather than two ,with each has the shape (1, 4)', ""try to print x_s, it's a (2,1,4) ndarray\r\n\r\n>>> x_s = mx.nd.split(x, axis=1, num_outputs=x.shape[1], squeeze_axis=False)\r\n>>> x_s\r\n\r\n[[[ 1.  1.  1.  1.]]\r\n\r\n [[ 1.  1.  1.  1.]]]\r\n<NDArray 2x1x4 @cpu(0)>\r\n>>> len(x_s)\r\n2\r\n>>> x_s[0].shape\r\n(1L, 4L)\r\n>>> x_s.shape\r\n(2L, 1L, 4L)"", 'I find that if the result after splitting has only  one NDArray, it will return this NDArray directly , rather than return a list . \r\nThank you~']",[],"['mxnet 0.12.0', '', '\r\n', '\r\n', '']",0,0
302,incubator-mxnet,297,closed,How can I construct the params for ImageRecordioIter in cpp?,"Hi, I want to develop some tools to manage my dataset(split,merge,append,global shuffle or something), and I found the interface to init the Iter: Init(vector< pair<string, string>>& args), How to construct this params, some param is complex just like TShape，
BTW, the api ImagerRecordIter in python is prefectcher in cpp , and ImageRecoredIoIter in cpp is another class...It is so easy to mix 
",C++,"['All the parameters are in string format. We have some easy util to help you convert the strings to the target shape, and give you the desired parameters and do type checking.\n\nCheckout https://github.com/dmlc/dmlc-core/blob/master/test/parameter_test.cc for example.\n']",[],[],0,0
303,incubator-mxnet,3924,closed,What unit test have for rnn?,"@mli  @piiswrong , do you have unit test operator for rnn so far? ",,"[""I don't think so"", ""@zhenlinluo We've created a higher-level API for RNN. See https://github.com/dmlc/mxnet/issues/3930"", 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
304,incubator-mxnet,7912,closed,Do I need to change grad_req when sharing weights?,"Hi, I was building a conv layer sharing weights with another one, using the  #557. Since the default grad_req is 'write' and I need to update the weights using the gradient from both of the two conv layer, do I need to change it to 'add'? Will it have some affect on other layers or say can I limit the 'add' req only only the shared weights?
Thanks.",,"[""no need to use add. it's automatic within one executor"", '@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', 'Answered above.']",[],[],0,0
305,incubator-mxnet,6611,closed,Reuse Variable but with different attributes,"Sometimes we need to share weights in network. And Its' advised in mxnet to reuse variable by applyinng  one weight and referencing multiple times. That's OK when variable attributes like lr_mult wd_mult is fixed.
But what if we want to change the learning rate in different network structure but still share the same weight.

My solution is to manually call symbol.set_attr with different learning_rate before different module initialization, is that OK? do you have a simpler way. Is that OK to define multiple variables with same name in this case? Thanks.",,"['You can use different symbols for different modules', 'Thanks , I will have a try.', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
306,incubator-mxnet,9588,closed,metric should have TP FP TN FN Precision Recall F1 for both macro and micro versions,"Related to #9587. The current logic only supports what's called ""macro F1"" logic where we take the mean of F1 scores for mini-batches. ""micro F1"" should also be supported by keeping the tp, fp, fn counts across batches.
Note that these metrics share the counter logics so we should be mindful when doing oo design.

https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/metric.py",Call for Contribution Feature request Metric,"['We may refer to the ""average"" option in [sklearn.metrics.f1_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score).', '@szha looks like #9777 address this ? If so please consider closing.', 'Indeed']",[],[],0,0
307,incubator-mxnet,5775,closed,Install mxnet on amazon linux,"I am trying to follow the standard installation guide @ http://mxnet.io/get_started/amazonlinux_setup.html, but get the following error.

[ec2-user@ip-xx-x-xx-xxx build]$sudo make PREFIX=/usr/local install
....
[ 89%] Built target opencv_cudaoptflow_pch_dephelp
[ 89%] Generating precomp.hpp.gch/opencv_cudaoptflow_RELEASE.gch
[ 89%] Built target pch_Generate_opencv_cudaoptflow
[ 89%] Building NVCC (Device) object modules/cudaoptflow/CMakeFiles/cuda_compile.dir/src/cuda/./cuda_compile_generated_pyrlk.cu.o
nvcc error   : 'cicc' died due to signal 11 (Invalid memory reference)
CMake Error at cuda_compile_generated_pyrlk.cu.o.cmake:266 (message):
  Error generating file
  /home/ec2-user/opencv/build/modules/cudaoptflow/CMakeFiles/cuda_compile.dir/src/cuda/./cuda_compile_generated_pyrlk.cu.o

make[2]: *** [modules/cudaoptflow/CMakeFiles/cuda_compile.dir/src/cuda/./cuda_compile_generated_pyrlk.cu.o] Error 1
make[1]: *** [modules/cudaoptflow/CMakeFiles/opencv_cudaoptflow.dir/all] Error 2
make: *** [all] Error 2
",,['Re-run the code and it works.'],[],[],0,0
308,incubator-mxnet,17167,closed,can't install mxnet-cu100,"import mxnet 
illegal instruction (core dumped)
Processor: Inter Xeon (R) CPU X5570@ 2.93 GHZ
Graphics: GeForce GTX 960/PCle/SSE2
Cuda 10.0, cudnn 7.4.2, opencv 4.1.2.
Can You help me ?",Bug,"[""@tranthanhtung04101995 \r\n- Could you please install mxnet by `pip install mxnet` and check if the native version works on your machine?\r\n- Could you please share the output of `lscpu` on your machine?\r\n\r\nI'm afraid the binary releases need AVX2 supported on your machine. See https://github.com/apache/incubator-mxnet/pull/17047#issuecomment-564863078."", 'mxnet version: 1.5.1.post0\r\nlscpu:\r\nArchitecture:        x86_64\r\nCPU op-mode(s):      32-bit, 64-bit\r\nByte Order:          Little Endian\r\nCPU(s):              8\r\nOn-line CPU(s) list: 0-7\r\nThread(s) per core:  1\r\nCore(s) per socket:  4\r\nSocket(s):           2\r\nNUMA node(s):        2\r\nVendor ID:           GenuineIntel\r\nCPU family:          6\r\nModel:               26\r\nModel name:          Intel(R) Xeon(R) CPU           X5570  @ 2.93GHz\r\nStepping:            5\r\nCPU MHz:             1605.121\r\nCPU max MHz:         2927,0000\r\nCPU min MHz:         1596,0000\r\nBogoMIPS:            5852.26\r\nVirtualization:      VT-x\r\nL1d cache:           32K\r\nL1i cache:           32K\r\nL2 cache:            256K\r\nL3 cache:            8192K\r\nNUMA node0 CPU(s):   0-3\r\nNUMA node1 CPU(s):   4-7\r\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm dca sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d', 'Does the native mxnet (without the suffix -cu100) work well on your machine? It seems that AVX2 is not supported.', 'also does not work. how to build mxnet on my machine', 'See if this works for you: https://mxnet.incubator.apache.org/get_started/ubuntu_setup.html or https://mxnet.incubator.apache.org/get_started/centos_setup.html', 'I think this is a problem of not fixing the instruction set when building the binary, and then building on a new environment. cc @ddavydenko ', ""@szha Previously I thought sse3 is the minimal requirement. I didn't see where -mavx2 is introduced. Is it from the static build of dependencies?"", 'i build mxnet. thank you.\r\nhttps://github.com/apache/incubator-mxnet/issues/14953#issuecomment-492966154', '@apeforest assign [@apeforest ] please follow up with @TaoLv ', '> i build mxnet. thank you.\r\n> [#14953 (comment)](https://github.com/apache/incubator-mxnet/issues/14953#issuecomment-492966154)\r\n\r\nCan we close this issue now?', '@apeforest no the instruction set problem should still be there.']",[],[],0,0
309,incubator-mxnet,9610,closed,Feature extraction for object detection,"Hi,

I was following this tutorial: http://mxnet.incubator.apache.org/tutorials/python/predict_image.html
and was wondering how would I use the extracted features to create a bounding box on the image.

Also the assertion in the code fails when I run the code with a different model
Using resnet-18
> (1, 512)
> Traceback (most recent call last):
>   File ""predict.py"", line 79, in <module>
>     assert features.shape == (1, 2048)
> AssertionError

features shape is (1,512). Would this affect the feature map?

Thanks.",,"[""@VintonyPadmadiredja  yes, the feature shape is expected to be different if you use another model.\r\nPlease kindly raise your questions via our [Discuss Forums](https://discuss.mxnet.io/). Closing this issue since it's expected. Please reopen if close by mistake and let us know!\r\n\r\n@sandeep-krishnamurthy  Please add label Question, and close this issue\r\nThanks!""]",[],[],0,0
310,incubator-mxnet,1976,closed,iteritems breaks Python 3 compatibility,"A few files use the  method, which is not available in Python 3.
Instead, Python 3 has , which is also available in Python 2 but apparently Python 2's version is slower.
Here it should be a non-issue, since in MXNet's codebase,  appears to be invoked when initializing modules/layers from a dictionary, so the cost should be marginal (because there are few items in each dict and initialization only happens at the start of the program).

As far as I'm aware, the behavior is the same, so it's more or less a drop-in replacement.
[There are some alternatives suggested here](http://python-future.org/compatible_idioms.html#iterating-through-dict-keys-values-items)

I will attach a pull request shortly, but I haven't done the full test sweep because all my GPUs are busy.
",,[],[],"['iteritems', '.items()', 'iteritems()']",0,0
311,incubator-mxnet,6930,closed,Fail Install Mxnet Windows 10,"Fail of install
I use this guide https://gist.github.com/thirdwing/89aa9bfc588ade138496e6932072152c

Fail on command 


C:\GPU\mxnet>R CMD INSTALL --no-multiarch R-package
* installing to library 'C:/Users/Statislove/Documents/R/win-library/3.4'
* installing *source* package 'mxnet' ...
** libs
make: Nothing to be done for `all'.
installing to C:/Users/Statislove/Documents/R/win-library/3.4/mxnet/libs/x64
** R
** demo
** inst
** preparing package for lazy loading
** help
No man pages found in package  'mxnet'
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded
Error: package or namespace load failed for 'mxnet':
 .onLoad failed in loadNamespace() for 'mxnet', details:
  call: inDL(x, as.logical(local), as.logical(now), ...)
  error: не могу загрузить разделяемый объект 'C:/Users/Statislove/Documents/R/win-library/3.4/mxnet/libs/x64/libmxnet.dll':
  LoadLibrary failure:  Не найден указанный модуль.

Ошибка: загрузка не удалась
Выполнение остановлено
ERROR: loading failed
* removing 'C:/Users/Statislove/Documents/R/win-library/3.4/mxnet'

What is mistake?",Installation R Windows,"['It seems R can\'t load the shared lib.\r\n\r\nI am sorry I can\'t figure out where is the error from the log you provided.\r\n\r\nCan you try to install the prebuilt pkg to see if it works?\r\n\r\n```r\r\ncran <- getOption(""repos"")\r\ncran[""dmlc""] <- ""https://s3.amazonaws.com/mxnet-r/GPU""\r\noptions(repos = cran)\r\ninstall.packages(""mxnet"")\r\n```', ""Thank, i setup mxnet. Really, i think it's not possible. To install, i make magic steps with UBUNTU.\r\nBut now i'm really happy 👍 "", 'I am closing this now. Feel free to reopen if necessary.']",[],['R CMD INSTALL --no-multiarch R-package'],0,0
312,incubator-mxnet,636,closed,char-lstm notebook gives different (overfeat) results than saved notebook on github (py2/3?),"I've re run the [char-lstm notebook](https://github.com/dmlc/mxnet/blob/master/example/rnn/char_lstm.ipynb) without modifing anything and compared the training and validation of the original notebook on github to the results I got (which I called SGD). It looks like something has changed and now the model is overfitting a little bit but the validation is a little bit better.
I noticed that I am running python 2.7.10 while the stored version on github was using python 3.4.2
![image](https://cloud.githubusercontent.com/assets/608789/11270580/2aafa0f4-8e8e-11e5-93ec-749177256b1a.png)
",,"[""Recently we merged a new PR which leads to these change: https://github.com/dmlc/mxnet/pull/484 .Sorry we didn't update notebook together\n"", '@antinucleon can you update the notebook result and close this issue?\n', 'closing for now, guess was fixed due to the changes\n']",[],[],0,0
313,incubator-mxnet,3604,closed,NameError: name 'CNNModel' is not defined,"Hi,
         I am getting an error in the cnn text classification example. I believe the error is how the return statement is defined as i was able to run the setup_cnn_model function step by step. I am new to python so i am not able to catch the issue.

**error:**

---

NameError                                 Traceback (most recent call last)
<ipython-input-79-41ff8a3dd1cd> in <module>()
----> 1 cnn_model = setup_cnn_model(mx.cpu(), batch_size, sentence_size, num_embed, vocab_size, dropout=0.5, with_embedding=False)

<ipython-input-78-d7501af934ba> in setup_cnn_model(ctx, batch_size, sentence_size, num_embed, vocab_size, dropout, initializer, with_embedding)
     36     label = cnn_exec.arg_dict['softmax_label']
     37 
---> 38     return CNNModel(cnn_exec=cnn_exec, symbol=cnn, data=data, label=label, param_blocks=param_blocks)

NameError: name 'CNNModel' is not defined

**code:**

def setup_cnn_model(ctx, batch_size, sentence_size, num_embed, vocab_size,
        dropout=0.5, initializer=mx.initializer.Uniform(0.1), with_embedding=True):



cnn_model = setup_cnn_model(mx.cpu(), batch_size, sentence_size, num_embed, vocab_size, dropout=0.5, with_embedding=False)
",,"['@qcl6355 i am getting following error. I am not using pretrainned embeddings.\n\nI appreciate all your help.\n\nRegards,\nAmit Bothra\n', '@amitkb3 `CNNModel` is defined in line 18 `CNNModel = namedtuple(""CNNModel"", [\'cnn_exec\', \'symbol\', \'data\', \'label\', \'param_blocks\'])`, and also notice that `namedtuple` is import from collections library (line 10). \n', '@qcl6355 I apologies. This is again an issue of my partially copying and pasting code. Github doesnot allow to download these files. I will have to download entire mxnet to get these files.\n\nI appreciate all your help.\nRegards,\nAmit Bothra\n']","[""\ncnn = make_text_cnn(sentence_size, num_embed, batch_size=batch_size,\n        vocab_size=vocab_size, dropout=dropout, with_embedding=with_embedding)\narg_names = cnn.list_arguments()\n\ninput_shapes = {}\nif with_embedding:\n    input_shapes['data'] = (batch_size, 1, sentence_size, num_embed)\nelse:\n    input_shapes['data'] = (batch_size, sentence_size)\n\narg_shape, out_shape, aux_shape = cnn.infer_shape(**input_shapes)\narg_arrays = [mx.nd.zeros(s, ctx) for s in arg_shape]\nargs_grad = {}\nfor shape, name in zip(arg_shape, arg_names):\n    if name in ['softmax_label', 'data']: # input, output\n        continue\n    args_grad[name] = mx.nd.zeros(shape, ctx)\n\ncnn_exec = cnn.bind(ctx=ctx, args=arg_arrays, args_grad=args_grad, grad_req='add')\n\nparam_blocks = []\narg_dict = dict(zip(arg_names, cnn_exec.arg_arrays))\nfor i, name in enumerate(arg_names):\n    if name in ['softmax_label', 'data']: # input, output\n        continue\n    initializer(name, arg_dict[name])\n\n    param_blocks.append( (i, arg_dict[name], args_grad[name], name) )\n\nout_dict = dict(zip(cnn.list_outputs(), cnn_exec.outputs))\n\ndata = cnn_exec.arg_dict['data']\nlabel = cnn_exec.arg_dict['softmax_label']\n\nreturn CNNModel(cnn_exec=cnn_exec, symbol=cnn, data=data, label=label, param_blocks=param_blocks)\n""]",[],0,0
314,incubator-mxnet,13718,closed,Help,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
(Brief description of the problem in no more than 2 sentences.)

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.
",,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Bug', 'Close this issue since no information is provided. @SamanthaFeidFischer Feel free to re-open with detailed description. Thank you.']",[],"['', '\r\nWhat to do:\r\n1. Download the diagnosis script from https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/diagnose.py\r\n2. Run the script using ', ' and paste its output here.\r\n\r\n', '', 'java -version', 'mvn -version', 'scala -version', 'sessionInfo()', 'git rev-parse HEAD']",0,0
315,incubator-mxnet,3665,closed,Matlab c_api gives  wrong predict result for binary classification,"Thanks for providing Matlab binding for mxnet. The Matlab binding works well when I use to predict multi-class classification, but gives wrong result when I try to do binary classification.  The predicted probability is always like [0.9998  0.0002], the index-0 is near 1 while index-1 is near zero. Can someone help me solve the problem?

",,['This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!'],[],[],0,0
316,incubator-mxnet,4485,closed,How to print loss and LR for current batch,Shall i write custom eval_metric?,,"['you can write a custom batch_end_callback', 'I am thinking this is common needs and shall we add two eval metric ?', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
317,incubator-mxnet,1841,closed,Python submodule 'module' is not installed by 'python setup.py install',"In setup.py, there's only packages=['mxnet'], so after installation, the mxnet.module will not be copied to the installation folder, import it globally will raise Import Error.

so add packages=['mxnet', 'mxnet.module'] will solve this problem.
",,['Thanks for reporting this! I added a commit 6a9fcdde3a61ef382466a714fc459de14ce8c5b2 Should be able to fix this once #1833 is merged.\n'],[],[],0,0
318,incubator-mxnet,1932,closed,"How to compile mxnet on jetson tk1？when I complie the mxnet on my jetson tk，I meet ""g++:error: unrecognitzed command line option '-msse3'. "," When I delete “-msse3”  of MSSHADOW_CFLAGS in  mshadow.mk,  it occur “fatal error:emmintrin.h: No such file or directory”.  
 PS.
My cpu architecture is ARM.
",,[],[],[],0,0
319,incubator-mxnet,15367,closed,[RFC] Add public functions to get list of registered operators and arguments,"A seen in this PR:

https://github.com/apache/incubator-mxnet/pull/15364

It's proposed to add get_all_registered_operators and get_operator_arguments to the Python bindings.


Your feedback is welcome.",Feature request,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Feature', '@mxnet-label-bot add [Feature Request]\r\n\r\n', 'Added a PR that will do this effect: https://github.com/apache/incubator-mxnet/pull/15364']",[],[],0,0
320,incubator-mxnet,8660,closed,Incorrect autograd results for elemwise_add ,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
The gradients for  seem to be incorrect when used with autograd. See the script at the bottom for details. @ptrendx do you have any insight for this? 

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash: v0.12
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.
",Autograd,"[""Not sure. I don't really know how autograd in gluon works - is it doing nnvm gradient pass under the hood?"", ""@eric-haibin-lin I've tried the scripts using the latest version again and there is no error now."", 'Possibly fixed by recent PRs. Closing it for now.']","['\r\n>>> import mxnet as mx\r\n>>> a = mx.nd.random_normal(shape=(2,2))\r\n>>> b = mx.nd.random_normal(shape=(2,2))\r\n>>> a.attach_grad()\r\n>>> b.attach_grad()\r\n>>> with mx.autograd.record():\r\n...     c = mx.nd.elemwise_add(a,b)\r\n...\r\n>>> c.backward()\r\n>>> a.grad\r\n\r\n[[ 0.  0.]\r\n [ 0.  0.]]\r\n<NDArray 2x2 @cpu(0)>\r\n>>> b.grad\r\n\r\n[[ 0.  0.]\r\n [ 0.  0.]]\r\n<NDArray 2x2 @cpu(0)>\r\n>>> with mx.autograd.record():\r\n...     c = mx.nd.broadcast_add(a,b)\r\n...\r\n>>> c.backward()\r\n>>> a.grad\r\n\r\n[[ 1.  1.]\r\n [ 1.  1.]]\r\n<NDArray 2x2 @cpu(0)>\r\n>>> b.grad\r\n\r\n[[ 1.  1.]\r\n [ 1.  1.]]\r\n']","['elemwise_add', '', '\r\nWhat to do:\r\n1. Download the diagnosis script from https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/diagnose.py\r\n2. Run the script using ', ' and paste its output here.\r\n\r\n', '', 'java -version', 'mvn -version', 'scala -version', 'sessionInfo()', 'git rev-parse HEAD']",0,0
321,incubator-mxnet,6605,closed,Large time cost over GPU computation,"I'm trying mxnet code from API,

and the result is:

Time to finish the CPU workload: 1.327401 sec
Time to finish both CPU/GPU workloads: 117.675283 sec

There are no error during compilation, and i use the same configurations as in caffe compiled on my machine.(gpu: 980m). caffe on my PC can conduct gpu computation at once, yet mxnet on my PC has to wait 100 seconds at least. What's wrong with my configuration?",,"[""what's definition of do and wait?"", ""It's okay now, I used wrong CUDA arch when compiled opencv, after changing the CUDA arch in opencv, It has been reduced to 1.8 second.""]",[],"[""   n = 10\r\n    a = mx.nd.ones((1000, 1000))\r\n    b = mx.nd.ones((6000, 6000), mx.gpu())\r\n    tic = time.time()\r\n    c = do(a, n)\r\n    wait(c)\r\n    print('Time to finish the CPU workload: %f sec' % (time.time() - tic))\r\n    d = do(b, n)\r\n    wait(d)\r\n    print('Time to finish both CPU/GPU workloads: %f sec' % (time.time() - tic))""]",0,0
322,incubator-mxnet,12567,closed,1.3.0 release pre-built package contains a buggy openblas version.  Causing gluon data loader with large num_workers to crash,"

## Description
In latest mxnet pip prebuilt packages, when using gluon data loader with num_worker > certain number, it may raise error:


Related issue: https://github.com/xianyi/OpenBLAS/issues/1735

## Environment info (Required)

Ubuntu 16




",BLAS Bug,"['@szha ', ""Looks like we just need to [upgrade the openblas dependency to 0.3.3](https://github.com/xianyi/OpenBLAS/issues/1735#issuecomment-417631520). Since it doesn't require code change in mxnet I will prepare a post-release to include the upgrade shortly."", '@mxnet-label-bot[Bug, BLAS]', ""@ankkhedia @Roshrini @lupesko - this may impact the windows instructions since we're currently having people use OpenBLAS v0.2.19 when building from source. WDYT @szha ?"", ""@aaronmarkham both versions should work. It's up to the user to decide which version of dependency to include."", 'is impact the windows? Windows need to upgrade openblas?', 'i am only receiving report on ubunutu so far', 'ok,not upgrade now,wait report.', '@zhreshold the 1.3.0.post0 releases contain the upgrade. Please verify.', 'Thanks @szha.\r\n@yajiedesign are you waiting for a confirmation before you publish the windows pip package for 1.3.0?', '@szha Verified with same code, 1.3.0 failed and 1.3.0.post0 passed. Thanks for the timely fix!', '@lupesko At present, I have uploaded 1.3.0, waiting for report.']","['\r\n OpenBLAS : Program will terminate because you tried to start too many threads.\r\n', '\r\npip install mxnet==1.3.0\r\n', 'python\r\nfrom mxnet import gluon\r\ndataset = xxx\r\nbatch_size = 16\r\nloader = gluon.data.DataLoader(dataset, batch_size, num_workers=16)\r\n']",[],0,0
323,incubator-mxnet,978,closed,[VOTE] Folder name for optional Addon,"There will be several interesting addons, that requires additional dependency, and are optionally installed, this thread is used to vote for the name of addon folder, as well as suggestions on how to dynamically load these addons.
Example ongoing addons include Torch operator and Caffe adapter.

Please vote for the name you like
- 1. 
- 2. 
- 3. 
",Discussion,"['+1 for opt\n', '+1 for plugin\n', '+1 for plugin\n', '+1 for plugin\n', 'extension?\n', 'also @mli @hotpxl @jermainewang \n', 'let us go for plugin then\n']",[],"['mxnet/opt', 'mxnet/addon', 'mxnet/plugin']",0,0
324,incubator-mxnet,1411,closed,How to deal with huge image record file,"For I am training on a 11 GB image record file and always get killed because of out of memory.
So I am just wondering that does mxnet load the entire image into the memory?
And what can I do if so.
Thanks!
",,"['What does your trianing script look like and what error are you seeing?\n', 'pretty standard one.\ndata is loaded with `mx.io.ImageRecordIter`\nthe Inception_BN is fine-tuned using `Feedforward.fit`\nAnd the log shows that\n\n```\n[3108734.905849] Out of memory: Kill process 10617 (python) score 195 or sacrifice child\n[3108734.907546] Killed process 10617 (python) total-vm:147094076kB, anon-rss:15868116kB, file-rss:344944kB\n```\n\nMy desktop has 3 titanX cards and 32 GB memory (but only 16 GB free for training)\n', 'When does this happen? At the start of training or after a while?\n', ""imagerecorditer definitely own't load the entire record file into memory. This should be caused by something else\n"", ""At the beginning of the training.\nBut I find that the training takes more then 10 GB memory beside graphic memory.\nSo what's the usage of that part of memory \n( My batch size is 384, when I switch to 256, it get killed after one epoch)\n"", ""Update,\nI upgrade the memory and now the traning won't get killed.\nAnd I just wondering when the training will take so much memory (17GB)\n"", '@tqchen Any thoughts?\n', ""There is a prefetcher buffer in mxnet. MXNet of course won't load the entire dataset into memory, but this could due to too large prefetcher buffers.  Try change the prefetch_buffer parameter here http://mxnet.readthedocs.org/en/latest/python/io.html\n\nSince there are multiple places where prefetching, and multi-threaded decoding is  happening. Some of them are not yet configurable. e.g.\n\nhttps://github.com/dmlc/mxnet/blob/master/src/io/iter_image_recordio.cc#L324\n\n@piiswrong can you confirm the memory consumption on your side normally as well?\n"", 'I am having the same problem. Today I updated and recompiled the code to the latest version but now training uses almost 31GB (inception-bn model, batch_size=128) which slows down my ubuntu OS significantly and the speed is less than 20 samples/sec. It used to be 56 samples/sec a couple of days ago.\n', '@fengjunlv Thanks for reporting the issue. Could you do a bisect ""https://git-scm.com/docs/git-bisect"" and pin point the change that caused this?\n', 'could due to my recent change to dmlc-core to increase the ingestion buffer size. I know reverted dmlc-core back to the same setting as in this commit https://github.com/dmlc/dmlc-core/commit/2d1db230e5fb0bf32bfed4e425b6fe20d05aa1c3 \n\n@piiswrong please send a PR to update dmlc-core and see if this issue is fixed\n', '@piiswrong Unfortunately, I am not sure which version it is that used to be working. It was pulled and compiled quite a few days ago. Hopefully what tqchen has found out will fix the issue.\n', ""@tqchen doesn't seem to fix it on my machine. Training still takes 16G ram\n"", '@piiswrong I see, can you look a bit into what happened?\n', ""I tried, but couldn't find a working version to start bisecting. Memory consumption starts when ImageRecordIter is created, before training starts. So you shouldn't need gpu to debug this.\n"", '@tqchen Hi,thx for the suggestion. But the way you propose cannot significantly reduce the memory usage.\n', 'Same problem is here. I use prefetch_buffer = 1 but still my data fills all the way of 30GB memory then raises out of memory error.\n\nI also have one old version of mxnet and it works with no problem. It seems something with a new update disrupt the code.\n', 'The newest version seems does not require so much memory. But after updating to the newest version. I got a problem \n\n> src/io/iter_image_recordio.cc:56: Check failed: p != end Bad ImageList format.\n\nMy ImageRecordIter are defined as follows:\n\n``` python\nbatch_size = 32\n\ntrain_dataiter = mx.io.ImageRecordIter(\n        mean_r = 123.68,\n        mean_g = 116.779,\n        mean_b = 103.939,\n        shuffle=True,\n        path_imgrec=""/home/marchhare/data/train.rec"",\n        path_imglist=""/home/marchhare/Desktop/train.lst"",\n        rand_crop=True,\n        rand_mirror=True,\n        data_shape=(3,256,256),\n        batch_size=batch_size,\n        label_width=7)\n\n\ntest_dataiter = mx.io.ImageRecordIter(\n        mean_r = 123.68,\n        mean_g = 116.779,\n        mean_b = 103.939,\n        path_imgrec=""/home/marchhare/data/test.rec"",\n        path_imglist=""/home/marchhare/Desktop/test.lst"",\n        rand_crop=False,\n        rand_mirror=False,\n        data_shape=(3,256,256),\n        batch_size=batch_size,\n        round_batch=False,\n        label_width=7) \n```\n\nAm I missing something in the multi-label for a Single Image? Thanks.\n', '@piiswrong  and @tqchen  Now it only takes ~9G CPU RAM in my case. Problem solved. Awesome. Thanks.\n']",[],[],0,0
325,incubator-mxnet,7163,closed,About sync frequency in distributed training,"I have two questions about distributed training in mxnet.

First, after reading the code in train_mnist.py, as to my understanding, the only changes you need to make is:
1 pass ""dist_sync""/ ""dist_async"" kvstore to optimizer or module.fit() method
2 make a hosts file and make sure all IPs on that list is ssh-able or mpirun-able
3 call launch.py in tools
Is my understanding correct or am I missing something?

Second, I just want to verify the sync frequency in distributed setting. Are the weights being synced every time you call module.update()? And if I want to sync on each machine for every n batches, is there any way I can do something like module.local_update() on every batch and module.global_update() every n_batch?

Thanks in advance!
",,"['First part looks right. \r\nSecondly, ya they are synced each time. Currently it seems like it is not possible to sync every n batches. ', 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!\nAlso, do please check out our [forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) for general ""how-to"" questions.']",[],[],0,0
326,incubator-mxnet,4971,closed,Mxnet symbol implementation details?,"Dear all:

I am trying to implement a structure as follows:

Image1--->Res Net(except for last layer)
//////////////////////////////////////////////diff -> predict result
Image2--->Res Net(except for last layer)

or:

Image_Combined -> slice channel-> Image1--->Res Net(except for last layer)
///////////////////////////////////////////////////////////////////////////////////////diff -> predict result
//////////////////////////////////////////Image2--->Res Net(except for last layer)

Which way is easier. I am now trying the second way. The problem is that how to use the previous resnet  symbols to do this, as the original resnet symbol get a variable named 'data' as the input, how to make the output of slice channel transmit data to the variable 'data' and how to initialize the network with pretrained parameters? Or is there are any examples or smarter ways of doing this.




",,"['The problem may be regarded as how to link a symbol to head instead of tails', ""I guess you can implement it like this,\r\n1. use a (N, 2, C, H, W) tensor as the network's input.\r\n2. reshape it to (2*N, C, H, W) and extract features for both images with any CNN you want. The output should be (2*N, M).\r\n3. use slice channel operation to split each image's feature. (2*N, M) -> (N, M) x 2;\r\n4. compute the difference like mx.sym.sum(mx.sym.square(f1-f2)) where f1 and f2 are the two feature vectors in step 3."", 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
327,incubator-mxnet,12437,closed,mxnet install page for linux mentions two different versions of Cuda,"this may very well not be the right place for this, but I didnt see a webpage specific repo for mxnet

https://mxnet.apache.org/install/index.html?platform=Linux&language=Python&processor=GPU

it says to get CUDA 9.0 at first, and then step 2 says install mxnet using CUDA 9.2.
it also says to be very sure which one it is, and I am about as far from sure as possible,
should I just gather all the latest libraries or is it imperative to use the older 9.0 library.

I dont expect my installation questions to be answered, just pointing out a possible error on the webpage.

Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
the mxnet.apache.org website has a possible error, where it points out multiple
versions of CUDA as neccesity for installation.

## Environment info (Required)
Ubuntu 18.04, Chromium, x86_64, NVIDIA GT 10 series

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. go to https://mxnet.apache.org/install/index.html?platform=Linux&language=Python&processor=GPU
2. search CUDA, and you will find it in 1, 2, and 5 out of ten results

## What have you tried to solve it?

1. Let you lot know
2. Attempting to install with cuDNN for 9.0 and what looks like the latest cuda library (9.2?)
",Doc Installation,"['@smokytheangel0 thanks for bringing this to our notice.\r\n\r\n@mxnet-label-bot [Doc, Installation]', 'This is resolved in my PR #12388.\r\nThe detailed update is here:\r\nhttps://github.com/aaronmarkham/incubator-mxnet/blob/cplusplus_install/docs/install/ubuntu_setup.md\r\nBut also when you use a similar link to what you provided:\r\nhttp://34.201.8.176/versions/cplusplus_install/install/index.html?platform=Linux&language=Python&processor=GPU', 'Hello @smokytheangel0 - looks like this issue has been resolved. Could you please close it accordingly?', '@smokytheangel0 Can you confirm if the issue got resolved ? If yes, please close this issue :) ', '@sandeep-krishnamurthy Seems like PR #12388 resolved this issue. Can you please close this issue ? \r\n\r\n@smokytheangel0 Feel free to re-open if closed in error.\r\nThanks! ']",[],[],0,0
328,incubator-mxnet,7219,closed,[R] How to include a minimum function in MakeLoss,"Hi, I am trying under R to use a constant as minimum for instance in a custom MAE loss function to cap it at 1. How do I do that?

Tried:
lro2<-mx.symbol.MakeLoss(mx.symbol.min(mx.symbol.abs(mx.symbol.Reshape(fc3, shape = 0) - label),1.0),name=""lro2"")

Which returns:
Error in mx.varg.symbol.min(list(...)) : 
  symbol.cc:302: RCheck failed: keys[i].length() != 0 Non Symbol parameters is only accepted via key=value style.

Thanks!",R,"['Can you show the full example?', 'Hi, the idea is to create a custom MAE loss function (with cap) cf. #3368 [https://github.com/dmlc/mxnet/issues/3368](url).\r\n\r\n  label <- mx.symbol.Variable(""label"")\r\n  \r\n  data <- mx.symbol.Variable(""data"")\r\n  fc1 <- mx.symbol.FullyConnected(data, name=""fc1"", num_hidden=8)\r\n  relu1 <- mx.symbol.Activation(fc1, name=""relu1"", act_type=""relu"")\r\n  fc2 <- mx.symbol.FullyConnected(relu1, name=""fc2"", num_hidden=4)\r\n  relu2<-mx.symbol.Activation(fc2, name=""relu2"", act_type=""relu"")\r\n  fc3<- mx.symbol.FullyConnected(relu2, name=""fc3"", num_hidden=1)\r\n\r\n  lro2<-mx.symbol.MakeLoss(mx.symbol.min(mx.symbol.abs(mx.symbol.Reshape(fc3, shape = 0) - \r\n  label),1.0),name=""lro2"")\r\n\r\nError in mx.varg.symbol.min(list(...)) :\r\nsymbol.cc:302: RCheck failed: keys[i].length() != 0 Non Symbol parameters is only accepted via key=value style.\r\n\r\nOr I was trying to create a constant variable on which to run the min in MakeLoss, but can we in R define a constant value behind a symbol yet?...\r\n\r\n  lossfloor <- mx.symbol.Variable(""lossfloor"")  # To be set to 1.0, but how?...\r\n  lro2<-mx.symbol.MakeLoss(mx.symbol.min({mx.symbol.abs(mx.symbol.Reshape(fc3, shape = 0) - label);lossfloor}),name=""lro2"")\r\n\r\nThanks.', '@solalm Can you try the code below. I am sorry that the function isn\'t exported correctly.\r\n\r\n```r\r\nlibrary(mxnet)\r\n\r\nlabel <- mx.symbol.Variable(""label"")\r\n\r\ndata <- mx.symbol.Variable(""data"")\r\nfc1 <- mx.symbol.FullyConnected(data, name = ""fc1"", num_hidden = 8)\r\nrelu1 <- mx.symbol.Activation(fc1, name = ""relu1"", act_type = ""relu"")\r\nfc2 <- mx.symbol.FullyConnected(relu1, name = ""fc2"", num_hidden = 4)\r\nrelu2 <- mx.symbol.Activation(fc2, name = ""relu2"", act_type = ""relu"")\r\nfc3 <- mx.symbol.FullyConnected(relu2, name = ""fc3"", num_hidden = 1)\r\nfc_abs <- mx.symbol.abs(mx.symbol.Reshape(fc3, shape = 0) - label)\r\n\r\nlro2 <- mxnet:::mx.varg.symbol.internal.MinimumScalar(list(fc_abs, scalar = 1))\r\n```\r\n\r\n![screenshot from 2017-08-04 16-18-56](https://user-images.githubusercontent.com/1547093/28990271-a70ead78-7930-11e7-96ba-6c64aded5084.png)\r\n', 'Thank you!', '@solalm You will be able to use `mx.symbol.min(fc_abs, 1)` if you use the latest code.\r\n\r\nThe prebuilt pkg will contain the fix in next release.']",[],[],0,0
329,incubator-mxnet,464,closed,[R] Add some example data to the package to be able to have example code in function documentation,"Most functions have no example code provided in their documentation.
For that purpose, the R package may include some raw data to process.

There are 3 possibilities:
- add some custom data directly in the package (like in XGBoost R package)
- add a dependency to a package which contains some data. Right now, **mlbench** is used in the RMarkdown documents.
- It is also possible to include some example without the data and mark the example code as not executable (so during the package compilation the example is not tested).

@tqchen @hetong007 @thirdwing What do you think we should do?
",R,"['I prefer the first one. Example should be the first code piece that helps a user to learn the way to call the function. So the more convenience the better.\n', 'Do you think the same dataset than XGBoost is Ok? (the one with mushroom)\nIf yes should be easy to copy paste and we are sure it works...\nMoreover, it would make it possible to compare results from both packages.\n', 'BTW, in the current building process, all examples are not tested\n', '@tqchen do we support sparse matrix input, or we need to do sparse -> dense conversion first? \nFor the latter case, I now prefer to use two data sets to represent regression and classification respectively. They could be the `Sonar` and `BostonHousing` as in the document or other ""easier"" data sets.\n', 'You can also generate some data like this: \n\n```\n#GENERATE DATA\n\nN = 100 # number of points per class\nD = 2 # dimensionality\nK = 3 # number of classes\nnum_examples = N*K\nX = matrix(0,num_examples,D) # data matrix (each row = single example)\ny = matrix(0,num_examples) # class labels\n\nfor (j in 0:(K-1)){\n  ix = seq(N*j+1,N*(j+1))\n  r = seq(0.0,1,length.out=N) # radius\n  t = seq(j*4,(j+1)*4,length.out=N) + rnorm(N)*0.2 # theta\n  X[ix,1] = r*sin(t)\n  X[ix,2]= r*cos(t)\n  y[ix] = j +1\n}\n# lets visualize the data:\nplot(X[, 1], X[, 2], col=rainbow(3)[y])\n```\n', 'I am closing this now, since example data has been provided during the unit test: https://github.com/dmlc/mxnet/blob/master/R-package/tests/testthat/get_data.R']",[],[],0,0
330,incubator-mxnet,2055,closed,Does the argument of input_shape is required for MNISTIterator?,"I am reading the code of example/image-classification/train_mnist.py. There is a argument of input_shape. 

But when I refer to the source code in src/io/iter_mnist.cc, I didn't find the parameter of input_shape. The doc don't list this argument too. When I delete these two lines, everything looks OK.
",,['This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!'],[],"['input_shape = data_shape,']",0,0
331,incubator-mxnet,2862,closed,How to access an entry of a Tensor in mshadow when using GPU mode?,"I want to create a new operator to implement hierarchical softmax by writing C++ code. At the moment, the operator works fine in CPU mode, but will crash in GPU mode. One cause of this issue is that I need to access an entry in a Tensor, i.e.,


...



....

....

So what is the correct way to access one entry in GPU mode? Thanks.
",,"[""You can't directly access memory on GPU.\n"", 'Yes. Finally solved by copying data to host.\n']",[],"['Tensor<xpu, 2, DType> label = in_data[hsoft::kLabel].get<xpu, 2, DType>(s);', 'if(label[m][n]==2.0){//crashes here', '}']",0,0
332,incubator-mxnet,15166,closed,asnumpy() fails on float16 gradient,"## Description
asnumpy() fails on float16 gradient both on cpu and gpu contexts. Interestingly, when printing out the variable itself (data16 in the MRE), it works on cpu, but only every other time on gpu.

## Environment info (Required)

Package used (Python/R/Scala/Julia):
Python

## Error Message:


## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

Run ^

## What have you tried to solve it?

N/A",FP16 Feature request Operator,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Bug', 'Documentation (https://mxnet.incubator.apache.org/api/python/symbol/linalg.html#mxnet.symbol.linalg.gelqf) says that this operator supports fp32 and fp64 only, so it is strange it does not fail to run with fp16 input.', '@charlieyou I tried it on CPU machine and it fails with the following callstack. \r\nAs per the doc the operator supports fp32 and fp64 only. We can tag the issue as ""Feature Request""\r\n\r\n`ubuntu@ip-172-31-18-214:~$ python test_fp16.py \r\nTraceback (most recent call last):\r\n  File ""test_fp16.py"", line 17, in <module>\r\n    data16.grad.asnumpy() # this fails on both\r\n  File ""/usr/local/lib/python2.7/dist-packages/mxnet/ndarray/ndarray.py"", line 1980, in asnumpy\r\n    ctypes.c_size_t(data.size)))\r\n  File ""/usr/local/lib/python2.7/dist-packages/mxnet/base.py"", line 252, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [21:16:03] src/operator/tensor/./la_op.h:533: This operation only supports 32-bit and 64-bit floating point\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x23d55a) [0x7fe6f32ae55a]\r\n[bt] (1) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x23dbc1) [0x7fe6f32aebc1]\r\n[bt] (2) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x27eaf13) [0x7fe6f585bf13]\r\n[bt] (3) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(mxnet::imperative::PushFCompute(std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)> const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<unsigned int, std::allocator<unsigned int> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&)::{lambda(mxnet::RunContext)#1}::operator()(mxnet::RunContext) const+0x2d7) [0x7fe6f5c9b587]\r\n[bt] (4) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2b7d289) [0x7fe6f5bee289]\r\n[bt] (5) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2b866b4) [0x7fe6f5bf76b4]\r\n[bt] (6) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2b8a802) [0x7fe6f5bfb802]\r\n[bt] (7) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2b86de4) [0x7fe6f5bf7de4]\r\n[bt] (8) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80) [0x7fe701fbbc80]\r\n[bt] (9) /lib/x86_64-linux-gnu/libpthread.so.0(+0x76ba) [0x7fe70644e6ba]\r\n`\r\n\r\n@mxnet-label-bot add [Feature Request, FP16, Operator]', '@mxnet-label-bot add [Feature Request, FP16, Operator]', '@leleamol This is my bad... I was attempting to post an issue that got at the root issue, but I now realize I posted something with a different cause, which is as you have pointed out, not a bug.\r\n\r\nHere is a MRE and stack trace for the actual issue I am facing. I can post it as a separate issue and close this one if desired.\r\n\r\n## MRE\r\n```\r\nimport mxnet as mx\r\nfrom mxnet.gluon.rnn import LSTM\r\n\r\nfake_data = mx.nd.random.uniform(shape=(1, 32, 32), dtype=""float16"").as_in_context(mx.gpu(0))\r\nfake_label = mx.nd.random.uniform(shape=(1, 32), dtype=""float16"").as_in_context(mx.gpu(0))\r\n\r\nlstm_layer = LSTM(32, dtype=\'float16\')\r\nlstm_layer.initialize(ctx=mx.gpu(0))\r\n\r\nctc_loss = mx.gluon.loss.CTCLoss()\r\n\r\nwith mx.autograd.record():\r\n    x = lstm_layer(fake_data)\r\n    loss = ctc_loss(x, fake_label)\r\n\r\nloss.backward()\r\nl = mx.nd.mean(loss).asnumpy()\r\n```\r\n\r\n## Stack trace\r\n```\r\n---------------------------------------------------------------------------\r\nMXNetError                                Traceback (most recent call last)\r\n<ipython-input-69-6bfc070aed48> in <module>()\r\n     13 \r\n     14 loss.backward()\r\n---> 15 l = mx.nd.mean(loss).asnumpy()\r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py in asnumpy(self)\r\n   1994             self.handle,\r\n   1995             data.ctypes.data_as(ctypes.c_void_p),\r\n-> 1996             ctypes.c_size_t(data.size)))\r\n   1997         return data\r\n   1998 \r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/base.py in check_call(ret)\r\n    251     """"""\r\n    252     if ret != 0:\r\n--> 253         raise MXNetError(py_str(_LIB.MXGetLastError()))\r\n    254 \r\n    255 \r\n\r\nMXNetError: [23:39:12] include/mxnet/././tensor_blob.h:236: Check failed: mshadow::DataType<DType>::kFlag == type_flag_: TBlob.get_with_shape: data type do not match specified type.Expected: 2 v.s. given 0\r\nStack trace:\r\n  [bt] (0) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x4ac1eb) [0x7ff57de371eb]\r\n  [bt] (1) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x30c8972) [0x7ff580a53972]\r\n  [bt] (2) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x31dc115) [0x7ff580b67115]\r\n  [bt] (3) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::imperative::PushFCompute(std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)> const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<unsigned int, std::allocator<unsigned int> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&)::{lambda(mxnet::RunContext)#1}::operator()(mxnet::RunContext) const+0x307) [0x7ff57ffd9f47]\r\n  [bt] (4) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x259adf4) [0x7ff57ff25df4]\r\n  [bt] (5) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25a8789) [0x7ff57ff33789]\r\n  [bt] (6) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25abbf0) [0x7ff57ff36bf0]\r\n  [bt] (7) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25abe86) [0x7ff57ff36e86]\r\n  [bt] (8) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25a6f94) [0x7ff57ff31f94]\r\n```', '> @leleamol This is my bad... I was attempting to post an issue that got at the root issue, but I now realize I posted something with a different cause, which is as you have pointed out, not a bug.\r\n> \r\n> ```\r\n\r\nThanks for the update @charlieyou , I would recommend opening a separate issue and closing this one. ']","[""\r\n----------Python Info----------\r\nVersion      : 3.6.5\r\nCompiler     : GCC 7.2.0\r\nBuild        : ('default', 'Apr 29 2018 16:14:56')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 10.0.1\r\nDirectory    : /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.5.0\r\nDirectory    : /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet\r\nCommit Hash   : 134a3e8cd36ee66426deedd3c8add6888378c043\r\n----------System Info----------\r\nPlatform     : Linux-4.14.114-82.97.amzn1.x86_64-x86_64-with-glibc2.9\r\nsystem       : Linux\r\nnode         : ip-10-10-82-87\r\nrelease      : 4.14.114-82.97.amzn1.x86_64\r\nversion      : #1 SMP Sun Apr 28 07:27:43 UTC 2019\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                4\r\nOn-line CPU(s) list:   0-3\r\nThread(s) per core:    2\r\nCore(s) per socket:    2\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\r\nStepping:              1\r\nCPU MHz:               2701.438\r\nBogoMIPS:              4600.07\r\nHypervisor vendor:     Xen\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              46080K\r\nNUMA node0 CPU(s):     0-3\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0017 sec, LOAD: 0.6884 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.1339 sec, LOAD: 0.3958 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.1478 sec, LOAD: 0.4110 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0270 sec, LOAD: 0.5201 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0032 sec, LOAD: 0.1016 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0016 sec, LOAD: 0.0433 sec.\r\n"", '\r\n---------------------------------------------------------------------------\r\nMXNetError                                Traceback (most recent call last)\r\n<ipython-input-64-e9fe00ede208> in <module>()\r\n     12 test16.backward()\r\n     13 \r\n---> 14 data16.grad.asnumpy()\r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py in asnumpy(self)\r\n   1994             self.handle,\r\n   1995             data.ctypes.data_as(ctypes.c_void_p),\r\n-> 1996             ctypes.c_size_t(data.size)))\r\n   1997         return data\r\n   1998 \r\n\r\n~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/base.py in check_call(ret)\r\n    251     """"""\r\n    252     if ret != 0:\r\n--> 253         raise MXNetError(py_str(_LIB.MXGetLastError()))\r\n    254 \r\n    255 \r\n\r\nMXNetError: [20:45:22] src/operator/tensor/./la_op.h:616: This operation only supports 32-bit and 64-bit floating point\r\nStack trace:\r\n  [bt] (0) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x4ac1eb) [0x7f477e2eb1eb]\r\n  [bt] (1) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x22e3152) [0x7f4780122152]\r\n  [bt] (2) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::imperative::PushFCompute(std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)> const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<unsigned int, std::allocator<unsigned int> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&)::{lambda(mxnet::RunContext)#1}::operator()(mxnet::RunContext) const+0x307) [0x7f478048df47]\r\n  [bt] (3) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x259adf4) [0x7f47803d9df4]\r\n  [bt] (4) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25a8789) [0x7f47803e7789]\r\n  [bt] (5) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25aba24) [0x7f47803eaa24]\r\n  [bt] (6) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25a6f94) [0x7f47803e5f94]\r\n  [bt] (7) /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6(+0xb86d4) [0x7f47d4f336d4]\r\n  [bt] (8) /lib64/libpthread.so.0(+0x7de5) [0x7f47e1fcade5]\r\n\r\n', '\r\nimport numpy as np\r\nfrom mxnet import autograd\r\n\r\ndef test_func(a):\r\n    q, l = mx.nd.linalg.gelqf(a)\r\n    return mx.nd.sum(l)\r\n    \r\ndata16 = mx.nd.random.normal(shape=(2, 3), ctx=mx.gpu(), dtype=np.float16)\r\ndata16.attach_grad()\r\nwith autograd.record():\r\n    test16 = test_func(data16)\r\n\r\ntest16.backward()\r\n\r\ndata16.asnumpy() # this works on cpu, but only half the time on gpu\r\ndata16.grad.asnumpy() # this fails on both\r\ntest16.asnumpy() # this fails too\r\n']",[],0,0
333,incubator-mxnet,1811,closed,Mxnet prediction on cpu is very slow,"i am trying get predictions for images using imagenet-21k-inception model through the cpp classification code but the prediction on cpu is very slow.
The prediction takes about 1.06 seconds for a single image and i tried to give images in batch but still there is no speed gain. I thought that giving images in batch will speed things up.
Is there something that i am doing wrong?
Is there a way to make predictions fast on cpu?
",,"['compile mxnet with openmp\n', 'I compiled mxnet with USE_OPENMP = 1 \nAfter some profiling i realized that MXPredForward takes only 0.04 seconds for a single image but\nMXPredGetOutput takes a lot of time about 1 second for one image. This function copies the result data after prediction\n( https://github.com/dmlc/mxnet/blob/5ff545f2345f9b607b81546a168665bd63d02d9f/src/c_api/c_predict_api.cc )\n\nAny way to make this fast?\n', '@tqchen \n', 'there are several things that can be done to speed things up.\n- Use openblas, which support multi-threading\n- Use NaiveEngine, that eliminates the thread scheduling\n', '@tqchen thanks a lot for the help! \n I used openblas with USE_OPENMP = 1  and used naive engine which speeded things up :)  The prediction now takes 0.55 seconds for a single image.\n\nI have a few more questions - \n1. I want to make predictions for a batch of 8 images using imagenet-21k-inception model in under a second in cpu mode. Is that possible?\n2. In the documentation of the predict api (http://mxnet.readthedocs.org/en/latest/doxygen/c__predict__api_8h.html) it is written that num_input_nodes = 1 for feedforward.\n   How can batching be done for feedforward prediction and will batching speed things up?\n', 'When you create the operator, change the input shape to include batch dimension should enable batching. i.e.\ninstead of\n\n`(1, channel, height, width)` change it to  `(batch_size, channel, height, width)` \n', '@tqchen  I am able to predictions for batch of images but it takes 4 seconds to get predictions for 8 images ie. i did not get any speed gain through batching.\nIs there any way to get prediction results faster for batch of images in cpu mode?\nRight now i am using the c prediction api , will using the cpp interface lead to better performance?\n', ""The bottleneck is on the computation then. Using cpp interface won't speed things up. You can, however, try NaiveEngine. Note that 21k-inception is a bigger net than normal inception used in imagenet, so the speed could be justified\n"", 'okay thanks :) @tqchen \n', 'i have tested predict in cpp,and find MXPredGetOutput is very slow(200ms), but in python executor.forward and get out is very fast(4.5ms), why?@tqchen\n', 'the python execution API is asynchronous, you can only measure the time after it is copied to numpy array\n', '@tqchen but my time methods is:\nPYTHON: (in total use 4.5ms, **get right class result**)\n` \n\n```\n    start = time.time()\n\n    outProb = model.forward(input_array) \n\n    label = np.argmax(outProb, axis=1)[0]\n\n    useTime = (time.time() - start) / 1.0\n```\n\n`\n\nCPP:(in total use 230ms, **get right class result**)\n`\n\n```\n   getTimer.begin();\n\n   MXPredGetOutput(out, output_index, &(data[0]), size);\n\n   PrintOutputResult(data, synset);\n\n   useC = getTimer.end();\n```\n\n`  \n\nin CPP api, the time-consuming function is SyncCopyToCPU (200ms).\nIs synchronization API 50times faster than asynchronous API ? Should I implement asynchronous CPP method by myself inorder to get faster speed ?\n', '@careyjiang have your problem solved? Would you give me some advice?', '@qt6636  \r\nI solve this proble by change MXPredGetOutput(out, output_index, &(data[0]), size) to:\r\n`MyPredictor* p = static_cast<MyPredictor*>(pred_hnd);//MyPredictor is the same as MXAPIPredictor in c_predict_api.cc\r\nstd::vector<mx_float> data(size);//here size is the length of output from your net\r\nmxnet::NDArray& nd_out = p->out_arrays[output_index];\r\nauto src = nd_out.data();\r\nstd::memcpy(&(data[0]), src.dptr_, size * sizeof(mx_float));`\r\nthis works for me, and the result is correct.', '@rhythm9229 could you tell me how to use openblas and naive engine?', '@KeyKy build multithreaded openblas on your system and set USE_OPENMP=1 , and set environment variable MXNET_ENGINE_TYPE to NaiveEngine']",[],[],0,0
334,incubator-mxnet,8358,closed,'module' object has no attribute 'nd',"## Description
'module' object has no attribute 'nd' when run command , while a short MXNet python program for validating MXNet Installation runs successfully in terminal.

## Environment info (Required)
system: ubuntu 14.04
mxnet version: 0.11.0


Package used (Python/R/Scala/Julia):
I'm using Python.

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
gcc

Build config:
make -j $(nproc) USE_OPENCV=1 USE_BLAS=openblas USE_CUDA=1 USE_CUDA_PATH=/usr/local/cuda USE_CUDNN=1

## Error Message:
Traceback (most recent call last):
  File ""mxnet/mxnet.py"", line 1, in <module>
    import mxnet as mx
  File ""/home/qy/documents/PythonPrj/mxnet/mxnet.py"", line 3, in <module>
    a = mx.nd.array([1, 2, 3])
AttributeError: 'module' object has no attribute 'nd'

## Details

After installing mxnet, I run the official test sample in terminal as below:

Everything is okay. However, when I write these code to python file , and run ., it returned the mentioned error.
It seems that it didn't find mxnet library.",,"['I met the same issue.', ""i have the same issue , let us know if you've solved it"", '@Hanbo-Sun @3bhady As for my case, it resulted from the filename which is the same with mxnet library. So when I tried to import mxnet library, what I imported actually is my own mxnet.py. Renaming the python file helped me solve the issue.', '@QQQYang Thank you! :)\r\nSame thing.', ""@QQQYang Thanks for replying, glad you solved yours.\r\nBut sadly this isn't the case for me i get this error on the validating program also. "", 'I have met the same question. So kindly u r,pls share with us if u have solved it.', '@wentlei have you checked this?\r\n\r\n> @Hanbo-Sun @3bhady As for my case, it resulted from the filename which is the same with mxnet library. So when I tried to import mxnet library, what I imported actually is my own mxnet.py. Renaming the python file helped me solve the issue.\r\n\r\n', ""@3bhady  Thanks for your reply. Yes , I have renamed my python file, and I haven't encountered this problem yet. It may caused by a conflict which the filename is the same with mxnet library as u mentioned."", 'I just reinstalled mxnet, and this was fixed.\r\ntry,\r\n`pip install -U mxnet-cu90` or (`pip install -U mxnet`). Don’t miss the `U` flag.']","['\r\n----------Python Info----------\r\n(\'Version      :\', \'2.7.6\')\r\n(\'Compiler     :\', \'GCC 4.8.4\')\r\n(\'Build        :\', (\'default\', \'Oct 26 2016 20:30:19\'))\r\n(\'Arch         :\', (\'64bit\', \'ELF\'))\r\n------------Pip Info-----------\r\n(\'Version      :\', \'9.0.1\')\r\n(\'Directory    :\', \'/usr/local/lib/python2.7/dist-packages/pip\')\r\n----------MXNet Info-----------\r\n(\'Version      :\', \'0.11.0\')\r\n(\'Directory    :\', \'/usr/local/lib/python2.7/dist-packages/mxnet-0.11.0-py2.7.egg/mxnet\')\r\nTraceback (most recent call last):\r\n  File ""diagnose.py"", line 108, in check_mxnet\r\n    with open(commit_hash, \'r\') as f:\r\nIOError: [Errno 2] No such file or directory: \'/usr/local/lib/python2.7/dist-packages/mxnet-0.11.0-py2.7.egg/mxnet/COMMIT_HASH\'\r\n\r\n----------System Info----------\r\n(\'Platform     :\', \'Linux-4.4.0-96-generic-x86_64-with-Ubuntu-14.04-trusty\')\r\n(\'system       :\', \'Linux\')\r\n(\'node         :\', \'ubuntu-1\')\r\n(\'release      :\', \'4.4.0-96-generic\')\r\n(\'version      :\', \'#119~14.04.1-Ubuntu SMP Wed Sep 13 08:40:48 UTC 2017\')\r\n----------Hardware Info----------\r\n(\'machine      :\', \'x86_64\')\r\n(\'processor    :\', \'x86_64\')\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                8\r\nOn-line CPU(s) list:   0-7\r\nThread(s) per core:    2\r\nCore(s) per socket:    4\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 94\r\nStepping:              3\r\nCPU MHz:               3825.625\r\nBogoMIPS:              8016.72\r\nVirtualization:        VT-x\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              8192K\r\nNUMA node0 CPU(s):     0-7\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0913 sec, LOAD: 1.2602 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0433 sec, LOAD: 1.7848 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0788 sec, LOAD: 1.2096 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0423 sec, LOAD: 0.9959 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0044 sec, LOAD: 0.4337 sec.\r\nError open Gluon Tutorial(cn): https://zh.gluon.ai, <urlopen error [Errno 1] _ssl.c:510: error:14077410:SSL routines:SSL23_GET_SERVER_HELLO:sslv3 alert handshake failure>, DNS finished in 0.0764639377594 sec.\r\n\r\n\r\n\r\n', '\r\nimport mxnet as mx\r\na = mx.nd.ones((2, 3), mx.gpu())\r\nb = a * 2 + 1\r\nb.asnumpy()\r\n']","['python mxnet.py', 'mxnet.py', 'python mxnet.py']",0,0
335,incubator-mxnet,424,closed,Add Swapaxes to Symbol,"like dimshuffle function in theano, or swapaxes in numpy, how can I do it in symbol?
",,"['This is not yet in the symbols. It can be added with no knowledge of CUDA, by adding a new operator. MXNet C++ is based on mshadow, and in mshadow it can be done by\n\n``` c++\nout = swapaxis<dim1, dim2>(src);\n```\n\nSo the general idea is create a new operator [here](https://github.com/dmlc/mxnet/tree/master/src/operator)  which is backed by mshadow implementations.\n\nSome reference:\n- http://mxnet.readthedocs.org/en/latest/developer-guide/operator.html\n\nPlease let us know if you want to take a stab\n', 'cool, i am very interested in it.\nlet me have a try.\nby the way, does what i did in mshadow will be applied in gpu automatically?\n', 'Yes\n', 'CTC is also a popular algorithm for sequence data training. ^_^\n', 'I found that the swapaxis supports template only, that means I need to enumerate all possible groups of swapaxis functions.for example:\nswap 0 and 1, then swapaxis<1, 0>(....)\nswap 0 and 2, then swapaxis<2, 0>(....)\nswap 0 and 3, then swapaxis<3, 0>(....)\nswap 2 and 3, then swapaxis<3, 2>(....)\n........\n', 'Thanks for point it out. Yes. These could be reduced to two possible cases by use it with together reshape. For example, say X is 3 dimension (c, t, h, w), what and we want to swap c and w, what we can do is \n\nSwap that involves the lowest dimension\n\n``` c++\nreshape(swapaxis<0, 2>(reshape(X, (c, t *h, w))), (w, t, h, w))\n```\n\nGeneral swap dim1, dim2\n\n``` c++\nswapaxis<1, 3>(reshape(X, (prod(shape[0:dim1]), dim1, prod(shape[dim1:dim2]), dim2, prod(dim2:end]))\n```\n\nSo you can use get_with_shape function in TBlob, which allows you to convert any TBlob contiguously into 4D Tensor using above rule,m and do swap axis on 1 and 3\n', 'I try it with numpy of python and it works, this is really a tricky one.\nThank you very much.\n', 'Thanks! Please open a PR for this\n', 'I will do PR after I implement it in mxnet.\n', 'Traceback (most recent call last):\n  File ""/home/mzhang/work/end-to-end/MXNetProject/swapaxis_test.py"", line 8, in <module>\n    import mxnet as mx\n  File ""/home/mzhang/anaconda/lib/python2.7/site-packages/mxnet-0.5.0-py2.7.egg/mxnet/**init**.py"", line 7, in <module>\n    from .base import MXNetError\n  File ""/home/mzhang/anaconda/lib/python2.7/site-packages/mxnet-0.5.0-py2.7.egg/mxnet/base.py"", line 43, in <module>\n    _LIB = _load_lib()\n  File ""/home/mzhang/anaconda/lib/python2.7/site-packages/mxnet-0.5.0-py2.7.egg/mxnet/base.py"", line 35, in _load_lib\n    lib = ctypes.cdll.LoadLibrary(lib_path[0])\n  File ""/home/mzhang/anaconda/lib/python2.7/ctypes/__init__.py"", line 443, in LoadLibrary\n    return self._dlltype(name)\n  File ""/home/mzhang/anaconda/lib/python2.7/ctypes/__init__.py"", line 365, in **init**\n    self._handle = _dlopen(self._name, mode)\nOSError: /home/mzhang/anaconda/lib/python2.7/site-packages/mxnet-0.5.0-py2.7.egg/mxnet/libmxnet.so: undefined symbol: _ZTVN5mxnet2op12SwapAxisPropE\n\nhow to fix it ?\n', 'Likely you forget to implement some function you declared in SwapAxisProp\n', 'thanks, I fix it out.\n', ""Hi, \nIt still has a problem, can not work well in python. Can I send my SwapAxis code files to you and ask you to fix  the problem ?\nwhat's your email ?\n"", 'You can open a PR with WIP flag, and I can help review it if you like\n', ""I got the following error when I push, \nremote: Permission to dmlc/mxnet.git denied to starimpact.\nfatal: unable to access 'https://github.com/dmlc/mxnet/': The requested URL returned error: 403\n"", 'You will need to do a fork, and send a pull request\n', 'Please refer: https://mxnet.readthedocs.org/en/latest/contribute.html\n', 'i did the fork\n', ""You want to clone the repo from your fork, instead of the dmlc's repo and push to your repo, something like\n\n```\ngit clone git@github.com/startimpact/mxnet\n```\n"", 'mxnet has child repository mshadow, how do i commit all changes in mxnet and mshadow?\n', 'I found that what I forked mxnet is not the newest one.\n', 'There are information here that can help you https://mxnet.readthedocs.org/en/latest/contribute.html\n\nIf you have changes made to mshadow, you want to clone mshadow separately and create a PR to https://github.com/dmlc/mshadow \n', 'hi, please check my github, you can see the swapaxis.please check it.\nthanks very much.\n', 'Made the comments there\n', 'there is 3 files in operator folder: swapaxis.cu, swapaxis.cc, swapaxis-inl.h.\nadd a Shape5 function in tensor.h in mshadow/mshadow\n', ""the following is my test file.\nthe question is the 'print 5' will not be executed.\n\n``` python\nA = mx.symbol.Variable('A')\na = mx.nd.ones((3, 4, 5))\nprint a\nswap = mx.symbol.SwapAxis(A, dim1=0, dim2=2)\nprint 2\nc_exec = swap.bind(ctx=mx.cpu(), args={'A' : a})\nprint 3\nc_exec.forward()\nprint 4\nrlt = c_exec.outputs[0].asnumpy()\nprint 5\nprint 'after swap:', rlt\n```\n"", 'Can you run a bit debug on this ? You can likely print out the messages in the forward function to see if things get executed. I also made a few comments on your impelemtnation\n', 'Forward function is not be executed!\n\n```\n2\nhello swapaxis CreateOperator!\nhello swapaxis SwapAxisOp!\n3\n4\n```\n', 'Made a few more comment that you might want to fix. I guess will need your help in making the operator work\n', 'As you see , I put the `printf` in the front of the `Forward` function.\n\n``` c++\n  virtual void Forward(const OpContext &ctx,\n                       const std::vector<TBlob> &in_data,\n                       const std::vector<OpReqType> &req,\n                       const std::vector<TBlob> &out_data,\n                       const std::vector<TBlob> &aux_args) {\n    using namespace mshadow;\n    using namespace mshadow::expr;\n    Stream<xpu> *s = ctx.get_stream<xpu>();\n#if SWAPAXIS_DBG\n    printf(""hello swapaxis Forward!\\n"");\n#endif\n    uint32_t dim1 = param_.dim1;\n    uint32_t dim2 = param_.dim2;\n```\n', 'Do you have QQ(47474167) or FB?\n', ""delivery of parameter is ok.\nbut somewhere is corrupted.\n\n``` python\n 11 A = mx.symbol.Variable('A')\n 12 a = mx.nd.ones((3, 4, 5))\n 13 print a\n 14 swap = mx.symbol.SwapAxis(A, dim1=0, dim2=2)\n 15 print 2\n 16 c_exec = swap.bind(ctx=mx.cpu(), args={'A' : a})\n 17 print 3\n 18 c_exec.forward()\n 19 print 4\n 20 rlt = c_exec.outputs[0].asnumpy()\n 21 print 5\n 22 print 'after swap:', rlt\n```\n\n```\n2\nhello swapaxis CreateOperator!\nhello swapaxis SwapAxisOp:dim1:0, dim2:2!\n3\n4\nSegmentation fault (core dumped)\n```\n"", 'I putted it into lenet.py, still can not work well.\n\n``` python\n 14 # second conv\n 15 conv2 = mx.symbol.Convolution(data=pool1, kernel=(5,5), num_filter=50)\n 16 tanh2 = mx.symbol.Activation(data=conv2, act_type=""tanh"")\n 17 pool2 = mx.symbol.Pooling(data=tanh2, pool_type=""max"",\n 18                           kernel=(2,2), stride=(2,2))\n 19 pool2 = mx.symbol.SwapAxis(data=pool2, dim1=0, dim2=2)\n```\n', 'Yeah, I solved the problem.:smile:\n', 'Great, can you cleanup the code and create a PR?\n', 'But I come across another problem, still in progress.\n', 'problem is solved, can run now, but still need more work.\n', 'I have finished the new code based on your suggestions.\nAnd the Backward is also completed.\nPlease check the code for me.Give me more suggestions.\nThank you very much.:smile:\n', 'function is ready to go. please check it.\nmaybe there is a little code style problem.\n:laughing: :smile: :smile_cat: :smiling_imp:\n', ""I come across a problem:\n`SwapAxis(..., dim1=2, dim2=3)`can work well on both cpu and gpu.\n`SwapAxis(..., dim1=3, dim2=2)`only work well on cpu, but fail on gpu with the following error:\n\n```\nINFO:root:Start training with [gpu(0)]\n[13:46:12] ./dmlc-core/include/dmlc/logging.h:208: [13:46:12] ./mshadow/mshadow/./tensor_blob.h:530: Check failed: (this->shape_.Size()) == (shape.Size()) TBlob.get_with_shape: new and old shape do not match total elements\n[13:46:12] ./dmlc-core/include/dmlc/logging.h:208: [13:46:12] src/engine/./threaded_engine.h:295: [13:46:12] ./mshadow/mshadow/./tensor_blob.h:530: Check failed: (this->shape_.Size()) == (shape.Size()) TBlob.get_with_shape: new and old shape do not match total elements\nterminate called after throwing an instance of 'dmlc::Error'\n  what():  [13:46:12] src/engine/./threaded_engine.h:295: [13:46:12] ./mshadow/mshadow/./tensor_blob.h:530: Check failed: (this->shape_.Size()) == (shape.Size()) TBlob.get_with_shape: new and old shape do not match total elements\nAborted (core dumped)\n```\n""]",[],[],0,0
336,incubator-mxnet,13386,closed,[Clojure] - Remove refer warning,"Currently on the master branch if you run the clojure package, you will see the warnings:



The reason this is occurring is because a new operator has been added that is brought dynamically by the backend and scala package.

This can be removed by adding it to the  in the 
*   - https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/org/apache/clojure_mxnet/ndarray.clj#L19 
*  - 
 https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/org/apache/clojure_mxnet/symbol.clj. 

It will also need to be added to the generated code as well which is in the  

*  https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/dev/generator.clj#L215
*  https://github.com/apache/incubator-mxnet/blob/master/contrib/clojure-package/src/dev/generator.clj#L308",Clojure good first issue,[],"[""\r\nWARNING: ref already refers to: #'clojure.core/ref in namespace: org.apache.clojure-mxnet.ndarray, being replaced by: #'org.apache.clojure-mxnet.ndarray/ref\r\nWARNING: ref already refers to: #'clojure.core/ref in namespace: org.apache.clojure-mxnet.symbol, being replaced by: #'org.apache.clojure-mxnet.symbol/ref\r\n""]","[':refer-clojure :exclude', 'ndarray.clj', 'symbol.clj', 'generator.clj']",0,0
337,incubator-mxnet,11612,closed,Find government repositories,"Find government auctions and other valueable resources that they offer online.
",Pending Requester Info,"[""Hi, I'm sorry, but I'm afraid I don't understand. Could you elaborate a bit more please?"", '@daedaesplayground1911 Please elaborate this question a bit more or provide more details. Thx', '@sandeep-krishnamurthy This question seems unrelated to MXNet Repository. \r\nCan you please close this issue ? ', '@daedaesplayground1911  - Please reopen once get more details on this issue. Resolving it for now. Thanks.', ""Yes I'm specifically searching for government liquidation sites and places where I can aquire documents relating to services that are offered to any citizen and people with disabilities."", ""I'm trying to find government liquidation places that specifically specialize in selling vehicles, weapons, used smartphones, and computers.""]",[],[],0,0
338,incubator-mxnet,14030,closed,The problem of ABI compatibility in MXTVMBridge,"## Description
Hi, there.

I would like to use  to accelerate my project, but there is a flaky problem.
The example works when MXNet is built from source by myself, but it doesn't work when MXNet is installed by PIP.

## Environment info (Required)



Package used (Python/R/Scala/Julia):
Python

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): gcc

MXNet commit hash: 
e37ff53f0a3a0cc9276a7a1d4aff0deab91c40df

Build config:


## Minimum reproducible example
https://github.com/wkcn/test_tvm_bridge

In this example, tvm_packed_func.h is simplyfied from TVM.

## Steps to reproduce

1. clone the example
2. change the path of libmxnet.so in the line 55 of the code.
3. make
4. ./test

## What have you tried to solve it?

In the function [](https://github.com/wkcn/test_tvm_bridge/blob/master/test.cpp#L28) of the reproducible example,
 is wrong and  is sometimes wrong when MXNet is installed by pip, namely .
However, the result is correct when MXNet is built by myself,  in the latest MXNet source.

In the PR #9880,  merrymercy met a similar problem. https://github.com/apache/incubator-mxnet/pull/9880#issuecomment-421779923


It seems the temporary variable  is released before calling  in the function [](https://github.com/apache/incubator-mxnet/blob/master/src/nnvm/tvm_bridge.cc#L178) because of optimization of compiler.

Thanks!
",,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Bug', 'In pip we use symbol whitelist https://github.com/apache/incubator-mxnet/blob/master/make/config/libmxnet.ver. Is any required function missing from this list? @tqchen ', 'Because the bridge uses c++ std::function, it requires a common ABI between the two in order to make things work, so build from source is indeed the best way', '@mxnet-label-bot add [question]', '@szha @tqchen @vdantu \r\nThank you!\r\nI know that the reason is about ABI compatibility now.\r\nIt will be better if there is a solution without rebuilding the sources : )', '@tqchen \r\nIs it possible to provide an API like this?\r\nIt may be available to avoid the problem of ABI compatibility.\r\n\r\n```c++\r\nclass PackedFunc {\r\n public:\r\n  using FType = std::function<void(TVMArgs args, TVMRetValue* rv)>;\r\n  PackedFunc() {\r\n    SetRemoteCallPacked();\r\n  };\r\n  explicit PackedFunc(FType body) : body_(body) {\r\n    SetRemoteCallPacked();\r\n  }\r\n  void CallPacked(TVMArgs args, TVMRetValue* rv) const {\r\n    _RemoteCallPacked(this, args, rv);\r\n  }\r\n  template <typename... Args>\r\n  inline TVMRetValue operator()(Args&&... args) const {\r\n    const int kNumArgs = sizeof...(Args);\r\n    const int kArraySize = kNumArgs > 0 ? kNumArgs : 1;\r\n    TVMValue values[kArraySize];\r\n    int type_codes[kArraySize];\r\n    detail::for_each(TVMArgsSetter(values, type_codes),\r\n                     std::forward<Args>(args)...);\r\n    TVMRetValue rv;\r\n    _RemoteCallPacked(this, TVMArgs(values, type_codes, kNumArgs), &rv);\r\n    return rv;\r\n  }\r\n private:\r\n  void SetRemoteCallPacked() {\r\n    _RemoteCallPacked = [](const PackedFunc* func, TVMArgs args, TVMRetValue* rv) {\r\n      func->body_(args, rv);\r\n    };\r\n  }\r\n  void (*_RemoteCallPacked)(const PackedFunc* func, TVMArgs args, TVMRetValue* rv);\r\n private:\r\n  FType body_;\r\n...\r\n};\r\n```', 'The problem is related to TVM, so I open an issue in TVM project.']","[""\r\n----------Python Info----------                                                                                                            \r\nVersion      : 3.7.2                                                                                                                       \r\nCompiler     : GCC 8.2.1 20181127                                                                                                          \r\nBuild        : ('default', 'Jan 10 2019 23:51:51')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 18.1                                                                                                                        \r\nDirectory    : /usr/lib/python3.7/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.5.0\r\nDirectory    : /home/wkcn/proj/incubator-mxnet/python/mxnet\r\nHashtag not found. Not installed from pre-built package.\r\n----------System Info----------\r\nPlatform     : Linux-4.20.5-arch1-1-ARCH-x86_64-with-arch\r\nsystem       : Linux\r\nnode         : MiraiT\r\nrelease      : 4.20.5-arch1-1-ARCH\r\nversion      : #1 SMP PREEMPT Sat Jan 26 12:59:18 UTC 2019\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    :\r\nArchitecture:        x86_64\r\nCPU op-mode(s):      32-bit, 64-bit\r\nByte Order:          Little Endian\r\nAddress sizes:       39 bits physical, 48 bits virtual\r\nCPU(s):              4\r\nOn-line CPU(s) list: 0-3\r\nThread(s) per core:  2\r\nCore(s) per socket:  2\r\nSocket(s):           1\r\nNUMA node(s):        1\r\nVendor ID:           GenuineIntel\r\nCPU family:          6\r\nModel:               142\r\nModel name:          Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz\r\nStepping:            9\r\nCPU MHz:             3500.069\r\nCPU max MHz:         3500.0000\r\nCPU min MHz:         400.0000\r\nBogoMIPS:            5810.00\r\nVirtualization:      VT-x\r\nL1d cache:           32K\r\nL1i cache:           32K\r\nL2 cache:            256K\r\nL3 cache:            4096K\r\nNUMA node0 CPU(s):   0-3\r\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe\r\n syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni\r\n pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsa\r\nve avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb invpcid_single pti tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_ad\r\njust bmi1 avx2 smep bmi2 erms invpcid mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp\r\n_notify hwp_act_window hwp_epp\r\n""]","['MXTVMBridge', 'make -j 5 USE_OPENCV=0 USE_BLAS=openblas ', 'SetMXTVMBridge', 'args.num_args', 'args.values[0].v_str', 'pip install mxnet --pre', 'make -j 5 USE_OPENCV=1 USE_BLAS=openblas', 'TVMArgs {""WrapAsyncCall"", PackedFunc(mxnet::WrapAsyncCall)}', 'fregister', 'MXTVMBridge']",0,0
339,incubator-mxnet,12318,closed,Sphinx is unable to access some MXNet ONNX module functions,"This causes Sphinx to fail processing the API docs when shorthand references are used. I used a workaround in #12317 to just reference the functions the long way. 

This means the reference is:

When it could be:


![2018-08-23_15-08-55](https://user-images.githubusercontent.com/5974205/44555096-657b4100-a6e8-11e8-8ea5-49cf3db31063.png)

But the shorthand route doesn't work.

Example:

@Roshrini ",Bug Build Python,"['@mxnet-label-bot [Doc, Website]', 'Hi @marcoabreu - this is more of a Python issue on the engineering side than something that can be fixed from within the website or docs systems. I might even label it a bug.', '@sandeep-krishnamurthy Could you please label above as [Python, Build, Bug] and remove [Doc, Website]', '@aaronmarkham : What needs to be done here for the docs? ']","['\r\nubuntu@ip-172-31-66-78:~/incubator-mxnet/docs$ python -c ""import mxnet.contrib.onnx.onnx2mx""\r\nubuntu@ip-172-31-66-78:~/incubator-mxnet/docs$ python -c ""import mxnet.contrib.onnx.onnx2mx.import_model""\r\nubuntu@ip-172-31-66-78:~/incubator-mxnet/docs$ python -c ""import mxnet.contrib.onnx.import_model""\r\nTraceback (most recent call last):\r\n  File ""<string>"", line 1, in <module>\r\nImportError: No module named import_model\r\n']","['mxnet.contrib.onnx.onnx2mx.import_model.import_model', 'mxnet.contrib.onnx.import_model']",0,0
340,incubator-mxnet,4469,closed,Error in make scalapkg ,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
Mac OS X 10.12.2

Compiler:

Package used (Python/R/Scala/Julia):
Scala

MXNet version:
0.9.1

Or if installed from source:

MXNet commit hash ():
d0728ca552d919fd40616149016ba4dd664c4e20

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.
make scalapkg
(cd /myhome/Tools/mxnet/scala-package; \
		mvn clean package -Posx-x86_64-gpu -Dcxx=""g++"" \
			-Dcflags=""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/myhome/Tools/mxnet/mshadow/ -I/myhome/Tools/mxnet/dmlc-core/include -fPIC -I/myhome/Tools/mxnet/nnvm/include -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/local/Cellar/opencv/2.4.13.2/include/opencv -I/usr/local/Cellar/opencv/2.4.13.2/include -DMSHADOW_USE_CUDNN=1  -I/usr/local/opt/openblas/include -DMXNET_USE_DIST_KVSTORE -I/myhome/Tools/mxnet/ps-lite/include -I/myhome/Tools/mxnet/deps/include -DMXNET_USE_NVRTC=0"" -Dldflags=""-pthread -lm -lcudart -lcublas -lcurand -L/usr/local/cuda/lib64 -L/usr/local/cuda/lib -lopenblas  -L/usr/local/Cellar/opencv/2.4.13.2/lib -lopencv_calib3d -lopencv_contrib -lopencv_core -lopencv_features2d -lopencv_flann -lopencv_gpu -lopencv_highgui -lopencv_imgproc -lopencv_legacy -lopencv_ml -lopencv_nonfree -lopencv_objdetect -lopencv_ocl -lopencv_photo -lopencv_stitching -lopencv_superres -lopencv_ts -lopencv_video -lopencv_videostab -lcudnn  -L/usr/local/opt/openblas/lib -L/usr/local/lib/graphviz/ /myhome/Tools/mxnet/deps/lib/libprotobuf-lite.a /myhome/Tools/mxnet/deps/lib/libzmq.a -lcuda"" \
			-Dlddeps=""/myhome/Tools/mxnet/ps-lite/build/libps.a /myhome/Tools/mxnet/dmlc-core/libdmlc.a /myhome/Tools/mxnet/nnvm/lib/libnnvm.a"")
[INFO] Scanning for projects...
[ERROR] [ERROR] Some problems were encountered while processing the POMs:
[ERROR] 'dependencies.dependency.artifactId' for ml.dmlc.mxnet:libmxnet-init-scala-${platform}:${libtype} with value 'libmxnet-init-scala-${platform}' does not match a valid id pattern. @ line 77, column 19
 @ 
[ERROR] The build could not read 1 project -> [Help 1]
[ERROR]   
[ERROR]   The project ml.dmlc.mxnet:mxnet-macros_2.11:0.1.2-SNAPSHOT (/myhome/Tools/mxnet/scala-package/macros/pom.xml) has 1 error
[ERROR]     'dependencies.dependency.artifactId' for ml.dmlc.mxnet:libmxnet-init-scala-${platform}:${libtype} with value 'libmxnet-init-scala-${platform}' does not match a valid id pattern. @ line 77, column 19
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http:/cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException
make: *** [scalapkg] Error 1

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.
make scalapkg

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.
After building mxnet
1. make scalapkg
2.
3.

## What have you tried to solve it?

1. Modify pom.xml
2.
3.
",,"['@javelinjs ', ""@Bill-Q seems scalapkg hasn't support osx-x86_64-gpu yet,\r\nsee https://github.com/dmlc/mxnet/blob/master/scala-package/core/pom.xml \r\nstart at line 18"", 'I see. Thanks for pointing it out. Do we have an ETA for supporting it?', 'By adding profile `osx-x86_64-gpu` in `core/pom.xml`, with a new sub module under `native`, I think it should not be hard to support gpu on osx. Are you interested in contributing this support?', '@javelinjs what does adding the support for osx-x86_64-gpu entail -- is it just `pom.xml` massage or more heavy lifting?', ""It could be done by modifying `pom.xml`, while I'm not sure whether special compile options are needed."", 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!', ""Does it build on Mac OSX?  People try and abandon the project when it does not build on Mac.  I'd think the way to close it is to make it build, and the issue should not be closed until it does. \r\n\r\nI've just checked the Installation, there's no steps for Scala clearly outlined for beginners."", '@javelinjs ', ""As we've discussed, it builds on osx for cpu, but not gpu. I'm working on maven deploy currently. The gpu support for osx is under relatively low priority. I'll make a roadmap soon."", ""yes, when i change to cpu, that's work. it's mean scala+gpu+mac not work"", 'does windows support mxnet along with scala , if so then how  ?']",[],"['git rev-parse HEAD', 'sessionInfo()']",0,0
341,incubator-mxnet,2705,closed,Creating model along with predicting in Amalgamation,"Hi,

I would like to know if there are any ways of passing the array values (layer wise), and using the FeedForward Class to create the model in amalgamation, just like using the prediction method in the FeedForward

Thanks
",,['This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!'],[],[],0,0
342,incubator-mxnet,2924,closed,cmake build failed when compile ndarray_function.cu on windows,"windows 7 
VS 2013
cuda 7.5
cmake 3.3.0

when build only with cpu, it's succeed, but when build with cuda, then failed with output log like:  



i have build mxnet with cuda on windows in 2015, and it's ok, i;m not familiar with cmake, any ideas about this? thanks. 
linux with gcc is ok here.
",,"['@yajiedesign \n', 'Need more error info.\n', 'hello, i can see only this one error when build, the last output log line is : \n\n```\n3>H:\\DLibrary\\dmlc\\mxnet\\dmlc-core\\include\\dmlc/parameter.h(584): warning : function ""dmlc::parameter::FieldEntryBase<TEntry, DType>::Get [with TEntry=TEntry, DType=DType]"" was referenced but not defined\n3>  \n3>  \n3>  \n3>h:\\dlibrary\\dmlc\\mxnet\\mshadow\\mshadow\\./expression.h(64): warning : function ""mshadow::expr::Exp<SubType, DType, exp_type>::self [with SubType=Container, DType=DType, exp_type=0]"" was referenced but not defined\n3>  \n3>  \n3>  \n3>h:\\dlibrary\\dmlc\\mxnet\\mshadow\\mshadow\\./expression.h(68): warning : function ""mshadow::expr::Exp<SubType, DType, exp_type>::ptrself [with SubType=Container, DType=DType, exp_type=0]"" was referenced but not defined\n3>  \n3>  \n3>  \n3>  1 error detected in the compilation of ""C:/Users/ADMINI~1/AppData/Local/Temp/tmpxft_00007944_00000000-6_ndarray_function.cpp4.ii"".\n3>  \n3>  ndarray_function.cu\n3>  \n3>  CMake Error at cuda_compile_generated_ndarray_function.cu.obj.cmake:266 (message):\n3>    Error generating file\n3>    H:/DLibrary/dmlc/mxnet/build/CMakeFiles/cuda_compile.dir/src/ndarray/Debug/cuda_compile_generated_ndarray_function.cu.obj\n3>  \n3>  \n4>------ 已启动全部重新生成:  项目: ALL_BUILD, 配置: Debug x64 ------\n4>  Building Custom Rule H:/DLibrary/dmlc/mxnet/CMakeLists.txt\n4>  CMake does not need to re-run because H:\\DLibrary\\dmlc\\mxnet\\build\\CMakeFiles\\generate.stamp is up-to-date.\n========== 全部重新生成:  成功 3 个，失败 1 个，跳过 0 个 ==========\n```\n', 'soloved by https://github.com/dmlc/mxnet/pull/4334']","['\n 1 error detected in the compilation of ""C:/Users/ADMINI~1/AppData/Local/Temp/tmpxft_00000b18_00000000-6_ndarray_function.cpp4.ii"".\n\n ndarray_function.cu\n\n CMake Error at cuda_compile_generated_ndarray_function.cu.obj.cmake:266 (message):\n  Error generating file\n    H:/DLibrary/dmlc/mxnet/build/CMakeFiles/cuda_compile.dir/src/ndarray/Debug/cuda_compile_generated_ndarray_function.cu.obj\n']",[],0,0
343,incubator-mxnet,7813,closed,Performance doesn't improve (scalability issue) with # GPUs with running train_imagenet.py,"While training AlexNet CNN with ImageNet data, i don't see performance improvement (in-fact i see slight performance degradation) with increasing number of GPUs

python train_imagenet.py --data-train /local/ImageNet/MXNet_data/MXNet_data.rec --data-val /local/ImageNet/MXNet_data/MXNet_data_test.rec --gpus 0,1,2,3 --network alexnet --batch-size 256  --num-epochs 1 --kv-store device

Per epoch (and batch-size/GPU : 64),
With 1 GPU, Time-cost : 910 sec
With 2 GPU, Time-cost : 924 sec
With 4 GPU, Time-cost : 964 sec

I have 4 Titan Xps

However, with synthetic data (as shown in the demo https://github.com/apache/incubator-mxnet/blob/master/example/image-classification/README.md) i see good scalability.
",,"['You are CPU limited - Alexnet is a very small network and Titans are fast. How many cores do you have on your CPU? If more than 4 then try to set `--data-nthreads N` where N is number of threads to do IO. By default MXNet uses only 4 cores to do IO. You may also limit augmentations you perform (by default train_imagenet script performs a lot of augmentations).\r\nI am in the process of improving image IO (#7152), that should also help.', ""Thank you, ptrendx.  That helps, but with 4 GPUs there isn't any performance gain\r\n\r\n\r\n% i limited the augmentations by setting 'data.set_data_aug_level(parser, 0)'\r\n%set data_threads to 8 (I have 8 physical cores)\r\npython train_imagenet.py --data-train /local/ImageNet/MXNet_data/MXNet_data.rec --data-val /local/ImageNet/MXNet_data/MXNet_data_test.rec --gpus 0,1,2,3 --network alexnet --data-nthreads 8 --batch-size 1024 --num-epochs 1 --kv-store device\r\n\r\nWith 1 GPU, Time-cost : 680 sec\r\nWith 2 GPU, Time-cost : 373 sec\r\nWith 4 GPU, Time-cost : 378 sec\r\n\r\n"", 'As I said, alexnet is a very small network, so with 8 physical cores you probably will not get a much better scaling result with those GPUs. Try a bigger network (vgg, resnet 50 or something similar) where there is not as big stress on IO and you should get a very good scaling result.\r\n\r\nStill, IO speed is a big problem going forward even for larger networks and that is why we are working on ways to improve it (besides my PR see for example #7092)']",[],[],0,0
344,incubator-mxnet,2160,closed,Ouput log of training fcn-32s and fcn-16s,"Recently, I am reproducing the result of fcn-xs in the mxnet example, I exactly follow the instruction from the README.md file, but the fcn-8s output is not like below, my train-accuracy is around 0.6 to 0.8, never get to 0.9. 

the output log may like this(when training fcn-8s):
INFO:root:Start training with gpu(3)
INFO:root:Epoch[0] Batch [50]   Speed: 1.16 samples/sec Train-accuracy=0.894318
INFO:root:Epoch[0] Batch [100]  Speed: 1.11 samples/sec Train-accuracy=0.904681
INFO:root:Epoch[0] Batch [150]  Speed: 1.13 samples/sec Train-accuracy=0.908053
INFO:root:Epoch[0] Batch [200]  Speed: 1.12 samples/sec Train-accuracy=0.912219
INFO:root:Epoch[0] Batch [250]  Speed: 1.13 samples/sec Train-accuracy=0.914238
INFO:root:Epoch[0] Batch [300]  Speed: 1.13 samples/sec Train-accuracy=0.912170
INFO:root:Epoch[0] Batch [350]  Speed: 1.12 samples/sec Train-accuracy=0.912080

Here is what I do.
First I train the fcn-32s, change the epoch: 31
Then I train the fcn-16s, change the learning rate: 10e-12 and epoch: 27
Finally I train the fcn-8s, change the learning rate: 10e-14 and epoch:19

Can anyone tell me the output log of fcn-32s and fcn-16s, just the end or the beginning log will be ok, so I can figure out which training stage is wrong
",,"['you should use larger lr(not the lr in the readme file ), because of  softmaxoutput operator has been changed from then on.  \nor you can delete the line https://github.com/dmlc/mxnet/blob/master/src/operator/softmax_output-inl.h#L108, and rebuild mxnet,then use the lr describled in the readme.\n', '@tornadomeet Thanks! I am not familiar with the source code. Could you tell me grad_scale and s[3] mean in https://github.com/dmlc/mxnet/blob/master/src/operator/softmax_output-inl.h#L108.\n', '@fangyizhang  the line is used for gradient normalization, s3[2] is the image label size(equals image size,and it is very large), so if we do not divide this,then the gradient will be very large(for it sums all the label), so we need small lr,like 1e-10.  \nif we divide the label numbers in that line, then the gradient is normalized, so we can use normal lr, which is larger than the lr in the readme.\n', '@tornadomeet Thanks a lot. I delete the code, then it works.\n']",[],[],0,0
345,incubator-mxnet,9544,closed,Can label length be different from the predicted output length,"Hi , 
I had a quick question. I have prepared my data using im2rec tool.

For each training sample I have a label which is a vector of length L. However, the first 3 elements are flags that are used to identify samples for which backward gradient should be computed (otherwise send 0.) in a custom loss layer (its multi-task learning, so I have 3 flags). Therefore, the output predicted is of length L-3.
My custom loss layer takes this into account.

I wanted to know if mxnet allows this kind of unusual labelling.

I am using mxnet 0.12.1, CUDNN V5, CUDA8, Ubuntu 14, Python 2.7, gcc 4.9
",,['Yes it works. I had made a mistake in my custom loss layer whereas I was using the shape for the prediction output on the label tensor.'],['\r\nincubator-mxnet/dmlc-core/include/dmlc/logging.h:308: [20:02:17] include/mxnet/./././tensor_blob.h:275: Check failed: this->shape_.Size() == shape.Size() (6656 vs. 6464) TBlob.get_with_shape: new and old shape do not match total elements\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /incubator-mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fea0b266afc]\r\n[bt] (1) /incubator-mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK5mxnet5TBlob14get_with_shapeIN7mshadow3gpuELi2EfEENS2_6TensorIT_XT0_ET1_EERKNS2_5ShapeIXT0_EEEPNS2_6StreamIS5_EE+0x51d) [0x7fea0d20a38d]\r\n[bt] (2) /incubator-mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op13AgeGenderLossIN7mshadow3gpuEfE8BackwardERKNS_9OpContextERKSt6vectorINS_5TBlobESaIS9_EESD_SD_RKS8_INS_9OpReqTypeESaISE_EESD_SD_+0x35f) [0x7fea0e56ad3f]\r\n[bt] (3) /incubator-mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op13OperatorState8BackwardERKNS_9OpContextERKSt6vectorINS_5TBlobESaIS6_EERKS5_INS_9OpReqTypeESaISB_EESA_+0x2c7) [0x7fea0d2ccb97]\r\n[bt] (4) /incubator-mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet4exec23StatefulComputeExecutor3RunENS_10RunContextEb+0xbb) [0x7fea0d0e265b]\r\n[bt] (5) /incubator-mxnet/python/mxnet/../../lib/libmxnet.so(+0x26d6970) [0x7fea0d0e7970]\r\n[bt] (6) /incubator-mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet6engine14ThreadedEngine15ExecuteOprBlockENS_10RunContextEPNS0_8OprBlockE+0x9d) [0x7fea0d0c9d7d]\r\n[bt] (7) /incubator-mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet6engine23ThreadedEnginePerDevice9GPUWorkerILN4dmlc19ConcurrentQueueTypeE0EEEvNS_7ContextEbPNS1_17ThreadWorkerBlockIXT_EEESt10shared_ptrINS0_10ThreadPool11SimpleEventEE+0x103) [0x7fea0d0cded3]\r\n[bt] (8) /incubator-mxnet/python/mxnet/../../lib/libmxnet.so(_ZNSt17_Function_handlerIFvSt10shared_ptrIN5mxnet6engine10ThreadPool11SimpleEventEEEZZNS2_23ThreadedEnginePerDevice13PushToExecuteEPNS2_8OprBlockEbENKUlvE1_clEvEUlS5_E_E9_M_invokeERKSt9_Any_dataS5_+0x56) [0x7fea0d0ce0d6]\r\n[bt] (9) /incubator-mxnet/python/mxnet/../../lib/libmxnet.so(_ZNSt6thread5_ImplISt12_Bind_simpleIFSt8functionIFvSt10shared_ptrIN5mxnet6engine10ThreadPool11SimpleEventEEEES8_EEE6_M_runEv+0x3b) [0x7fea0d0cb31b]\r\n'],[],0,0
346,incubator-mxnet,3212,closed,Does the motherboard need the SLI technology to support multiple gpus in mxnet?,"My motherboard is Intel B85 which doesn't support SLI technology and has two PCIE interfaces, and I have two gtx1080 gpu cards to construct my mxnet system. But I found the utilizations of two gtx1080 are very slow, the speed of two gtx1080 is slower than single gtx1080. Although I increased the batch sizes, the speed of two gpus is still lower than one gpu. How can I solve this problem?
",,"['no, sli is for gaming\n']",[],[],0,0
347,incubator-mxnet,15647,closed,Segmentation fault: 11,"(retinaface) root@docker20:/data2/yanmengkai/face/RetinaFace# pip install mxnet                                                                                                                                                       
Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple
Requirement already satisfied: mxnet in /root/anaconda3/lib/python3.7/site-packages (1.5.0)
Requirement already satisfied: numpy<2.0.0,>1.16.0 in /root/anaconda3/lib/python3.7/site-packages (from mxnet) (1.16.4)
Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /root/anaconda3/lib/python3.7/site-packages (from mxnet) (0.8.4)
Requirement already satisfied: requests<3,>=2.20.0 in /root/anaconda3/lib/python3.7/site-packages (from mxnet) (2.22.0)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /root/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /root/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (1.23)
Requirement already satisfied: idna<2.9,>=2.5 in /root/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (2.7)
Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet) (2018.8.24)
(retinaface) root@docker20:/data2/yanmengkai/face/RetinaFace# python                                                                                                                                                                  
Python 3.7.0 (default, Jun 28 2018, 13:15:42) 
[GCC 7.2.0] :: Anaconda, Inc. on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import mxnet

Segmentation fault: 11

Stack trace:
(retinaface) root@docker20:/data2/yanmengkai/face/RetinaFace#    ",Installation Pending Requester Info pip,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Build', 'Can you please provide some information about your environment?\r\n\r\n```\r\nWhat to do:\r\n1. Download the diagnosis script from https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/diagnose.py\r\n2. Run the script using `python diagnose.py` and paste its output here.\r\n\r\n```\r\n', ""I ran  ```python  diagnose.py```\r\nthen printed \r\n```shell\r\n----------Python Info----------\r\nVersion      : 3.6.8\r\nCompiler     : GCC 8.0.1 20180414 (experimental) [trunk revision 259383\r\nBuild        : ('default', 'Jan 14 2019 11:02:34')\r\nArch         : ('64bit', '')\r\n------------Pip Info-----------\r\nVersion      : 19.1.1\r\nDirectory    : /usr/local/lib/python3.6/dist-packages/pip\r\n----------MXNet Info-----------\r\n\r\nSegmentation fault: 11\r\n\r\nSegmentation fault (core dumped)\r\n```\r\n@zachgk "", 'Please uninstall and reinstall mxnet', ""It didn't work that uninstall and reinstall mxnet. I reinstall mxnet many times, please help me. @leezu "", ""Ok. Then you should uninstall and build from source. Please follow the guide at https://mxnet.apache.org/get_started/ubuntu_setup\r\nIf the error persists, add `-DCMAKE_BUILD_TYPE=Debug` instead of `-DCMAKE_BUILD_TYPE=Release` in the `cmake` line.\r\n\r\n\r\nYour problem could be related to the conda setup. If you don't want to build from source, I suggest you don't use conda and try again to install mxnet with system python."", ""Let's track segmentation fault issues in #17043 ""]",[],[],0,0
348,incubator-mxnet,2724,closed,how to get the value of 'mean_r',"in the script of 'mxnet/example/image-classification/train_imagenet.py' , there is 
# data

def get_iterator(args, kv):
    data_shape = (3, args.data_shape, args.data_shape)
    train = mx.io.ImageRecordIter(
        path_imgrec = os.path.join(args.data_dir, args.train_dataset),
        mean_r      = 123.68,
        mean_g      = 116.779,
        mean_b      = 103.939,
        data_shape  = data_shape,
        batch_size  = args.batch_size,
        rand_crop   = True,
        rand_mirror = True,
        num_parts   = kv.num_workers,
        part_index  = kv.rank)

but how to get the value of ' mean_r,  mean_g, mean_b' ?
and another question, the ' data_shape' is the size of the picture ?  for instance,  I have a picture with size of  1920_1080, then the   ' data_shape' should set be 3_1920_1080?
and if I crop the picture to the size 1080_1080, then the   ' data_shape' should set be 3_1080_1080? 
@mli 
thank your help.
",,['This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!'],[],[],0,0
349,incubator-mxnet,4447,closed,A note on data augmenation,"In the following figure, I compare commonly used data augmentation techniques for ResNet-50 on ImageNet. **Random crop, random flip, and scale augmentations** were shown to be very **effective**, and they provide as the baseline ""scale aug"". For **JPEG compression with quality 90** and **aspect ratio augmentation**, the curves indicates they almost **have no effects**. For **color augmentation**, it is shown that the accuracy is actually **decreased**.


![notes_on_aug](https://cloud.githubusercontent.com/assets/3815006/21560667/6f909480-ce9d-11e6-9340-9d8af5f41837.png)

### Compare to state-of-the-art implementation:

 (https://github.com/tornadomeet/ResNet)

For ResNet-50 on ImageNet, top-1 accuracy of 74.55% were achieved. As suggested in https://github.com/tornadomeet/ResNet, canceling scale/color/aspect augmentation will further improve the results. For a fair comparison, https://github.com/tornadomeet/ResNet actually achieved 74.20% accuracy at the 95-th epoch (right before the cancellation of scale/color/aspect augmentations). Hence, we can conclude that **augmentations beyond random crop, random flip, and scale actually hurt the performance** as (74.55%>74.20%).
",,"[""I recommend finish training. It's hard to draw conclusions at 40 epochs"", '@piiswrong I have a full training of ResNet-18 on ImageNet. With only Random crop, random flip, and scale augmentations, I am able to achieve an error rate of 30.5%, which is lower than 30.9% in https://github.com/tornadomeet/ResNet. So the conclusion should be valid. Since the evaluation is quite computational expensive. I will continue to train the models when spare GPUs are available.', '@taoari ResNet-18 which i trained is very bad! maybe for large batch-size, please ref the implementationof Microsoft which using R in MXNet, which >1% better than mine. https://blogs.technet.microsoft.com/machinelearning/2016/11/15/imagenet-deep-neural-network-training-using-microsoft-r-server-and-azure-gpu-vms/', '@tornadomeet That actually does not matter, both of them were trained on a batch size of 512 for ResNet-18. The point is that **augmentations beyond random crop, random flip, and scale actually hurt the performance**.\r\n\r\nIn the above figure, I have included the comparison results for scale/aspect ratio/color augmentations. To compare with more advanced techniques, including random rotation, random shear, etc. augmentations, I have included your results.  For a fair comparison, I am using your results at the 95-th epoch. For ResNet-50, only scale augmentation achieved 74.55%, while scale/aspect ratio/color/rotation/shear  augmentations achieved 74.20%. For ResNet-18, since I had a full training (including the cancellation of the augmentations after the 95-th epoch), only scale augmentation achieved an error rate of 30.5% (accuracy 69.5%), while scale/aspect ratio/color/rotation/shear  augmentations achieved an error rate of 30.9% (accuracy 69.1%). Hence, the conclusion that  **augmentations beyond random crop, random flip, and scale actually hurt the performance** is valid.\r\n\r\nFor the curve above, we can also conclude that aspect ratio augmentation and JPEG compression almost had no effects on the final results. While color augmentation does hurt the performance.', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
350,incubator-mxnet,1504,closed,How to build a siamese network with contrastive loss?,"Could you give a example code?
",,"['Same is here :)\n', 'I want know how to set two datainput into the mxnet.\n\nI think the idea of placeholder is nice\n', 'Any example?@tqchen\n', ""I've implemented a similar architecture using triple-loss for text classification, joint learning a text representation using CNN and a softmax after this for classification task. \n\nI think the contrastive loss you want is quite similar, siamese should share weights of your representation learning network. For more detail, you can refer the code sample and tutorial from @xlvector here: https://zhuanlan.zhihu.com/p/21725762?refer=xlvector\n"", '@qiaohaijun Two separated data input might be unnecessary in this case, as you can write a `sample_nagative` & `sample_positive` in `DataIter` to generate training samples.\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
351,incubator-mxnet,1067,closed,[install error] sdotsub.f:(.text+0x7): undefined reference to `sdot_',"Linux + blas

I have put libblas.a  libcblas.a to /usr/local/lib, when I make, the cmd complains:
outside_built/gcc4.9.0/bin/g++ -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp   -o bin/im2rec tools/im2rec.cc build/resource.o build/c_api/c_api.o build/c_api/c_api_error.o build/c_api/c_predict_api.o build/common/mxrtc.o build/common/tblob_op_registry.o build/engine/engine.o build/engine/naive_engine.o build/engine/threaded_engine.o build/engine/threaded_engine_perdevice.o build/engine/threaded_engine_pooled.o build/io/io.o build/io/iter_csv.o build/io/iter_image_recordio.o build/io/iter_mnist.o build/kvstore/kvstore.o build/ndarray/ndarray.o build/ndarray/ndarray_function.o build/ndarray/unary_function.o build/operator/activation.o build/operator/batch_norm.o build/operator/block_grad.o build/operator/concat.o build/operator/convolution.o build/operator/cross_device_copy.o build/operator/cudnn_batch_norm.o build/operator/deconvolution.o build/operator/dropout.o build/operator/elementwise_binary_op.o build/operator/elementwise_binary_scalar_op.o build/operator/elementwise_sum.o build/operator/embedding.o build/operator/fully_connected.o build/operator/identity_attach_KL_sparse_reg.o build/operator/leaky_relu.o build/operator/lrn.o build/operator/native_op.o build/operator/ndarray_op.o build/operator/operator.o build/operator/pooling.o build/operator/regression_output.o build/operator/reshape.o build/operator/slice_channel.o build/operator/softmax_activation.o build/operator/softmax_output.o build/operator/swapaxis.o build/operator/upsampling.o build/optimizer/optimizer.o build/optimizer/sgd.o build/storage/storage.o build/symbol/graph_executor.o build/symbol/static_graph.o build/symbol/symbol.o dmlc-core/libdmlc.a -pthread -lm -lcblas -lrt -lcblas  
/usr/local/lib/libcblas.a(sdotsub.o): In function sdot_'
/usr/local/lib/libcblas.a(cblas_sgemm.o): In function sgemm_'
cblas_sgemm.c:(.text+0x1e6): undefined reference to `sgemm_'
collect2: error: ld returned 1 exit status
make: **\* [bin/im2rec] Error 1
",,"['What do you mean ""I have put libblas.a libcblas.a to /usr/local/lib""? Where did they come from? Which blas library are you using? \n', 'Was due to incomplete installation of blas, consider change blas version to for example open blas, might be the quickest way to solve the issue\n', 'Hi, I have tried openblas, and fixed the problem. Thank you\n']",[],"['pkg-config --cflags opencv', 'pkg-config --libs opencv', ""sdotsub_':\nsdotsub.f:(.text+0x7): undefined reference to"", ""cblas_sgemm':\ncblas_sgemm.c:(.text+0x13c): undefined reference to""]",0,0
352,incubator-mxnet,15069,closed,Profiler RFC: Introducing new APIs,"# Profiler RFC: Introducing new APIs

## Introducing New APIs

### Motivation

MXNet comes with a profiler that allows users to monitor the performance of their models in two metrics: time and memory consumption. Internally, operator calls, C API calls, and memory allocation/deallocation are represented as events. For functions calls, we know the start and finish time of the events and therefore the duration. For memory operations, we know the time of the allocation/deallocation and the size of the memory chunk. 
![Screen Shot 2019-05-24 at 4 16 39 PM](https://user-images.githubusercontent.com/10722037/58362190-49f4c080-7e49-11e9-92a3-23664384544b.png)

Currently, the profiler has a function called  that will return the aggregate statistics, which include min, max, and average for entries in Device Memory, Operator, and C_API. The current return value is string and the data is presented in a table fashion (refer to the screenshot above). However, while the table is nicely formatted, it is only meant to be read by humans but is not easily parse-able otherwise by program. So, there is a need for an API that returns the same aggregate stats in a JSON string.


### Specification

A new API, , will be introduced. It will have two parameters: 

1. “sort_by” which specifies by which statistic should we sort the entries. It defaults to “avg” and valid options are [“min”, “max”, “avg”].
2. “ascending” which specifies how the entries should be sorted. It defaults to False and valid options are [True, False].

 Expected use cases of  include:

1. If customers are more interested in some events or stats than the others, they can customize the data presentation to more efficiently monitor their models.
2. Customers can easily pass the stats to automated performance tests or monitoring tools. They do not need to parse the table-like string returned by . 
3. This new API will be immediately useful to a new operator-level benchmark tool that @sandeep-krishnamurthy will work on. cwiki: https://cwiki.apache.org/confluence/display/MXNET/MXNet+Operator+Benchmarks. 


The structure of the JSON return value is shown below. It is a four layer dictionary structure. The 1st layer is “Time”, “Memory”, and “Unit”. The 2nd layer is the category that the operators/APIs fall into. The 3rd layer is the operators/APIs. Finally, the 4th layer is the stats. Notice that the time unit is ms and the memory unit is byte.




Asides from  we will also have another new API, , which will clear the aggregate statistics up until now. A typical use case is like:



In a more complex case, suppose we want to use the same profiler to benchmark various sections of a model, we can then call  and  at the end of each section or supposedly at the end of a loop neatly like:



OR



## Fixing the Output of Dumps()
![Screen Shot 2019-05-23 at 5 23 56 PM](https://user-images.githubusercontent.com/10722037/58362201-7c062280-7e49-11e9-88ec-3ab102c95795.png)
Currently labeling in the table is slightly off. For memory-related entries the labels should be “Usage” rather than “Time”. The “Time (ms)” column also does not make sense for memory entries, so it should be removed for memory entries.

The new table labeling should look like:






## F&Q

1. Why can't we use the current dumps() API?

We can use the current dumps API and basically get the save information, but then we need to manually parse the table which is not a good user experience.

1. Why add a new profiler API  in the back-end rather than a python parser utility that returns in JSON? 

This is we can use this new API in different languages and make sure the return is consistent. 

",Feature request Profiler,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Feature', 'Great proposal! I like that you implement this in the backend level to be able to expose it to various frontends.\r\n\r\nSo far, your design will return aggregated values. In some cases, people would also like to have the raw data to analyse it themselfes.', 'I understand the value of getting the dump output in a different format compared to tabular form. This can also be useful for doing post-processing on the dumped output as required by new profiler features like these: https://github.com/apache/incubator-mxnet/pull/14973 . Having said that, I think of `get_summary` as similar to `dumps` but outputting a different format. In this sense, we don\'t need to add a new API but just add support format to existing API. For example:\r\n```\r\ndef dumps(reset=False, format=""table"" or ""json"", sort_by=..)\r\n```\r\n', '+1', ""> Why add a new profiler API get_summary() in the back-end rather than a python parser utility that returns in JSON?\r\nThis is we can use this new API in different languages and make sure the return is consistent.\r\n\r\nI wasn't able to understand the answer for this question. @ZhaoqiZhu would you mind elaborate? I had the impression that there's no difference in the profiler dump file regardless of the frontend so I assumed that the later steps on analyzing the dump don't involve the front-end language anymore."", '> I understand the value of getting the dump output in a different format compared to tabular form. This can also be useful for doing post-processing on the dumped output as required by new profiler features like these: #14973 . Having said that, I think of `get_summary` as similar to `dumps` but outputting a different format. In this sense, we don\'t need to add a new API but just add support format to existing API. For example:\r\n> \r\n> ```\r\n> def dumps(reset=False, format=""table"" or ""json"", sort_by=..)\r\n> ```\r\n\r\nMy intension was to not change the existing APIs, but I can see your point. Do you think we need sorting for the tabular output though? @anirudh2290 ', ""> > Why add a new profiler API get_summary() in the back-end rather than a python parser utility that returns in JSON?\r\n> > This is we can use this new API in different languages and make sure the return is consistent.\r\n> \r\n> I wasn't able to understand the answer for this question. @ZhaoqiZhu would you mind elaborate? I had the impression that there's no difference in the profiler dump file regardless of the frontend so I assumed that the later steps on analyzing the dump don't involve the front-end language anymore.\r\n\r\nYes, the dump file is processed by the backend, but that's more for tracing. For aggregate information we currently only have dumps() which will return a tabular string. It prints out like this.\r\n\r\n![](https://user-images.githubusercontent.com/10722037/58362190-49f4c080-7e49-11e9-92a3-23664384544b.png)\r\n\r\nSo instead of adding a utility that parse that table into a JSON string, we can return a JSON string from the backend directly."", 'sorting for the tabular output would be great to have! There is already an issue open for this: https://github.com/apache/incubator-mxnet/issues/14100', '> sorting for the tabular output would be great to have! There is already an issue open for this: #14100\r\n\r\nThanks for the link! I will update my proposal to reflect that tomorrow.', ""> So instead of adding a utility that parse that table into a JSON string, we can return a JSON string from the backend directly.\r\n\r\nWhat's the value proposition in doing that, especially given that the raw dump is already available."", ""> > So instead of adding a utility that parse that table into a JSON string, we can return a JSON string from the backend directly.\r\n> \r\n> What's the value proposition in doing that, especially given that the raw dump is already available.\r\n\r\nRaw dump gives the events but not the stats. Before, if a user is interested in programmatically process the stats, they must call dumps() and parse the table themselves. Here we are doing that for them"", ""Yes, and a python script would do that nicely without involving other frontend (or mxnet). For example this one: https://github.com/TaoLv/mxProfileParser\r\n\r\nWhat's the value addition of having that in the backend? Is it just for those who cannot use python?"", '@szha In case of the tool you mentioned it does the aggregation too. I think the use case that @Zha0q1 is trying to address is when one wants to directly obtain the aggregated JSON directly (to do some post-processing on it) without having to do additional work in the frontend language binding. And yes it can also be useful for other frontends.', ""I think there are multiple points:\r\n1. People are already using dumps() and we want to present the information in a way (json) that it is easier to use. The script is still outputting a table.\r\n2. Users may be interested in calling dumps() at multiple points within a model. With that python script they would need to call mx.nd.waitall(), start a new process to run the script, deal with synchronization, parse the script return. This can be as easy as calling dumps(format = 'json')\r\n3. With dumps() we can do reset. However if we process the raw dump, there it will be all then events since the start of the model"", ""do you feel that aggregating raw profiler dumps is worth adding a new C API? to me, this aggregation doesn't seem like a core functionality of mxnet since it can be done outside of mxnet. we don't have a contrib namespace for C API so it needs to be right in one shot.\r\n\r\nback to the use case:\r\n> People are already using dumps() and we want to present the information in a way (json) that it is easier to use. The script is still outputting a table.\r\n> With dumps() we can do reset. However if we process the raw dump, there it will be all then events since the start of the model\r\n\r\nAdding ways for aggregation and filtering seem more principled. \r\n\r\n> Users may be interested in calling dumps() at multiple points within a model. With that python script they would need to call mx.nd.waitall()\r\n\r\nI actually suspect that this is not a use case that should be supported. `dumps()` doesn't have a clear scope so there's not guarantee that the output has a scope of what users think it might have. This is especially the case for mxnet because of the asynchronous execution."", '> do you feel that aggregating raw profiler dumps is worth adding a new C API? to me, this aggregation doesn\'t seem like a core functionality of mxnet since it can be done outside of mxnet. we don\'t have a contrib namespace for C API so it needs to be right in one shot.\r\n> \r\n> back to the use case:\r\n> \r\n> > People are already using dumps() and we want to present the information in a way (json) that it is easier to use. The script is still outputting a table.\r\n> > With dumps() we can do reset. However if we process the raw dump, there it will be all then events since the start of the model\r\n> \r\n> Adding ways for aggregation and filtering seem more principled.\r\n> \r\n> > Users may be interested in calling dumps() at multiple points within a model. With that python script they would need to call mx.nd.waitall()\r\n> \r\n> I actually suspect that this is not a use case that should be supported. `dumps()` doesn\'t have a clear scope so there\'s not guarantee that the output has a scope of what users think it might have. This is especially the case for mxnet because of the asynchronous execution.\r\n\r\nI think now where I am headed for is to add parameters for return format, sort_by, and ascending like Anirudh suggested. That way we are not going to create new C APIs.\r\n\r\n`def dumps(reset=False, format=""table"" or ""json"", sort_by=..)`', '@sandeep-krishnamurthy we can close this now', 'optionally adding json output seems reasonable. during development of this feature, the intel folks were asking for more aggregation of the output, such as convolution ops for different input shapes, for instance, which seems perfectly fair (there’s a discussion issue about it somewhere). Anyway, whatever y’all decide to do, try to keep open the extensibility to stuff like that (which would lend itself more to json output than text output). However, I still think it’s important to have simple text output available if desired, since it gives a nice, clean one-look overview.', 'output was loosely based on pytorch, btw.', '> optionally adding json output seems reasonable. during development of this feature, the intel folks were asking for more aggregation of the output, such as convolution ops for different input shapes, for instance, which seems perfectly fair (there’s a discussion issue about it somewhere). Anyway, whatever y’all decide to do, try to keep open the extensibility to stuff like that (which would lend itself more to json output than text output). However, I still think it’s important to have simple text output available if desired, since it gives a nice, clean one-look overview.\r\n\r\nThanks for the tips! We have added support for sorting and json in this PR: https://github.com/apache/incubator-mxnet/pull/15132. Basically, we have added three new parameters to `dumps`, namely `sort_by`, `ascending`, and `format` by which you can control the aggregate stats output. We are keeping the old table view as it is clear to human; json format is intended for use cases where you want to parse the aggregate stats with a script']","['\r\n{\r\n    ""Time"": {\r\n        ""operator"": {\r\n            ""mean "": {\r\n                ""Total Count"": 2,\r\n                ""Total Time"": 0.0490,\r\n                ""Min Time"": 0.0240,\r\n                ""Max Time"": 0.0250,\r\n                ""Avg Time"": 0.0245\r\n            }\r\n            ...\r\n        }\r\n        ,\r\n        ""MXNET_C_API"": {\r\n            ""MXNDArrayWaitAll"": {\r\n                ""Total Count"": 1,\r\n                ""Total Time"": 205.9560,\r\n                ""Min Time"": 205.9560,\r\n                ""Max Time"": 205.9560,\r\n                ""Avg Time"": 205.9560\r\n            }\r\n            ,\r\n            ""MXNDArraySetGradState"": {\r\n                ""Total Count"": 8,\r\n                ""Total Time"": 0.0050,\r\n                ""Min Time"": 0.0000,\r\n                ""Max Time"": 0.0010,\r\n                ""Avg Time"": 0.0006\r\n            }\r\n            ...\r\n        }\r\n    }\r\n    ,\r\n    ""Memory"": {\r\n        ""Device Storage"": {\r\n            ""Memory: cpu/0 "": {\r\n                ""Count"": 1,                \r\n                ""Max Usage"": 109037988,\r\n                ""Min Usage"": 0,\r\n                ""Avg Usage"": 54518999\r\n            }\r\n            ,\r\n            ""Memory: gpu/0 "": {\r\n                ""Count"": 1, \r\n                ""Max Usage"": 109037988,\r\n                ""Min Usage"": 0,\r\n                ""Avg Usage"": 54518999\r\n            }\r\n        }\r\n        ,\r\n        ""Pool Memory"": {\r\n            ""Pool:gpu/0 Pool Free"": {\r\n                ""Count"": 1, \r\n                ""Max Usage"": 1,\r\n                ""Min Usage"": 2,\r\n                ""Avg Usage"": 3\r\n            }\r\n            ,\r\n            ""Pool:gpu/0 Pool Used"": {\r\n                ""Count"": 1, \r\n                ""Max Usage"": 0,\r\n                ""Min Usage"": 1,\r\n                ""Avg Usage"": 2\r\n            }\r\n            ...\r\n        }\r\n    }\r\n    ""Unit"": {\r\n        ""Time"": ""ms"",\r\n        ""Memory"": ""byte""        \r\n    }\r\n}\r\n', ""\r\n# we don't care what happened before this point\r\nprofiler.reset()\r\n# model\r\nprofiler.set_state('run')\r\nrun_training_iteration(*next(itr))\r\nmx.nd.waitall()\r\nprofiler.set_state('stop')\r\n# end model\r\nfunc(profiler.get_summary())\r\n"", ""\r\n# model section 1\r\nprofiler.set_state('run')\r\n# model code here\r\nprofiler.set_state('stop')\r\nprint(profiler.get_summary())\r\nprofiler.reset()\r\n\r\n# model section 2\r\nprofiler.set_state('run')\r\n# model code here\r\nprofiler.set_state('stop')\r\nfunc(profiler.get_summary())\r\nprofiler.reset()\r\n"", ""\r\n# loop through tests functions\r\nfor f in benchmark_tests:\r\n    profiler.set_state('run')\r\n    f()\r\n    mx.nd.waitall()\r\n    profiler.set_state('stop')\r\n    print(profiler.get_summary())\r\n    profiler.reset()\r\n""]","['dumps()', 'get_summary()', 'get_summary()', 'dumps()', 'get_summary(),', 'reset()', 'get_summary()', 'reset()', '// For time entries', 'Name    Total Count    Total Time (ms)    Min Time (ms)    Max Time (ms)    Avg Time (ms)', '// For memory entries', 'Name    Total Count    Min Usage (MB)    Max Usage (MB)    Avg Usage (MB)', 'get_summary()']",0,0
353,incubator-mxnet,10520,closed,MXNet operator profile aggregate counter issue,"It looks the operator counter of the aggregated output is the 2x of real value. 

I used below gluon model (mainly copied from https://mxnet.incubator.apache.org/tutorials/gluon/gluon.html, contains 2 convolutions for each forward pass) and did profiling, the aggregated convolution counter is 4 instead of 2, the counter doubled for other OPs as well.

mx.gpu(0)[mx.gpu(0), mx.gpu(1)]",Bug Profiler,"['@pengzhao-intel', '@nswamy Can you please add labels-\r\nPython, Gluon, Profiler', '@cjolivier01 This functionality is really useful and we apply it in our daily works.\r\nCould you help fix the issue?']",['\r\n\r\n\r\nThe profile output is below:\r\n\r\n'],"['', '\r\n# import dependencies\r\nfrom __future__ import print_function\r\nimport numpy as np\r\nimport mxnet as mx\r\nimport mxnet.ndarray as F\r\nimport mxnet.gluon as gluon\r\nfrom mxnet.gluon import nn\r\nfrom mxnet import autograd\r\n\r\nclass Net(gluon.Block):\r\n    def __init__(self, **kwargs):\r\n        super(Net, self).__init__(**kwargs)\r\n        with self.name_scope():\r\n            # layers created in name_scope will inherit name space\r\n            # from parent layer.\r\n            self.conv1 = nn.Conv2D(6, kernel_size=5)\r\n            self.pool1 = nn.MaxPool2D(pool_size=(2,2))\r\n            self.conv2 = nn.Conv2D(16, kernel_size=5)\r\n            self.pool2 = nn.MaxPool2D(pool_size=(2,2))\r\n            self.fc1 = nn.Dense(120)\r\n            self.fc2 = nn.Dense(84)\r\n            self.fc3 = nn.Dense(10)\r\n\r\n    def forward(self, x):\r\n        x = self.pool1(F.relu(self.conv1(x)))\r\n        x = self.pool2(F.relu(self.conv2(x)))\r\n        # 0 means copy over size from corresponding dimension.\r\n        # -1 means infer size from the rest of dimensions.\r\n        x = x.reshape((0, -1))\r\n        x = F.relu(self.fc1(x))\r\n        x = F.relu(self.fc2(x))\r\n        x = self.fc3(x)\r\n        return x\r\n\r\nnet = Net()\r\n# Initialize on CPU. Replace with ', ', or ', "",\r\n# etc to use one or more GPUs.\r\nnet.collect_params().initialize(mx.init.Xavier(), ctx=mx.cpu())\r\n\r\nmx.profiler.set_config(aggregate_stats=True)\r\nmx.profiler.set_state('run')\r\n\r\ndata = mx.nd.random_normal(shape=(10, 1, 32, 32))  # dummy data\r\noutput = net(data)\r\noutput.wait_to_read()\r\n\r\nprint(mx.profiler.dumps())\r\n\r\n\r\n[jinhuang@mlt-ace image-classification]$ python test_gluon.py\r\n\r\nProfile Statistics.\r\n        Note that counter items are counter values and not time units.\r\nDevice Storage\r\n=================\r\nName                          Total Count        Time (ms)    Min Time (ms)    Max Time (ms)    Avg Time (ms)\r\n----                          -----------        ---------    -------------    -------------    -------------\r\nMemory: cpu/0                          65         535.0320           0.0240         726.1520         363.0640\r\n\r\nMXNET_C_API\r\n=================\r\nName                          Total Count        Time (ms)    Min Time (ms)    Max Time (ms)    Avg Time (ms)\r\n----                          -----------        ---------    -------------    -------------    -------------\r\nMXNDArrayReshape64                      1           0.0140           0.0140           0.0140           0.0140\r\nMXNDArrayFree                          21           0.1100           0.0000           0.0290           0.0052\r\nMXAutogradMarkVariables                10           0.1080           0.0080           0.0180           0.0108\r\nMXNDArrayCreateEx                      10           0.0340           0.0020           0.0070           0.0034\r\nMXNDArrayGetDType                      15           0.0000           0.0000           0.0000           0.0000\r\nMXSymbolSetAttr                        47           0.0920           0.0010           0.0130           0.0020\r\nMXNDArrayGetContext                    13           0.0070           0.0000           0.0010           0.0005\r\nMXNDArrayWaitToRead                     1          12.0930          12.0930          12.0930          12.0930\r\nMXSymbolInferShape                      7           0.5700           0.0490           0.2320           0.0814\r\nMXNet C API Calls                     230           0.2300           0.0010           0.2300           0.1145\r\nMXNet C API Concurrency               459           0.0010           0.0000           0.0010           0.0005\r\nMXSymbolCreateAtomicSymbol               7           0.3780           0.0190           0.1540           0.0540\r\nMXAutogradSetIsRecording               10           0.0140           0.0000           0.0070           0.0014\r\nMXAutogradSetIsTraining                10           0.0040           0.0000           0.0010           0.0004\r\nMXImperativeInvokeEx                   52           3.7600           0.0150           1.7250           0.0723\r\nMXNDArrayGetShape                      25           0.0190           0.0000           0.0030           0.0008\r\n\r\noperator\r\n=================\r\nName                          Total Count        Time (ms)    Min Time (ms)    Max Time (ms)    Avg Time (ms)\r\n----                          -----------        ---------    -------------    -------------    -------------\r\nWaitForVar                              2           0.0080           0.0040           0.0040           0.0040\r\nFullyConnected                          6           0.7770           0.0590           0.2380           0.1295\r\nPooling                                 4           0.5280           0.0890           0.1750           0.1320\r\n_zeros                                 20           0.6220           0.0020           0.1410           0.0311\r\nResourceParallelRandomSetSeed               2          14.7190           7.3580           7.3610           7.3595\r\nDeleteVariable                         40           0.1130           0.0010           0.0070           0.0028\r\nrelu                                    8           0.2220           0.0070           0.0770           0.0278\r\n_random_normal                          2          10.8890           5.4430           5.4460           5.4445\r\n_random_uniform                        10           0.7370           0.0100           0.2740           0.0737\r\n_full                                  10           0.0350           0.0010           0.0080           0.0035\r\nConvolution                             4          12.5590           0.5260           5.7530           3.1398\r\nzeros_like                             20           0.3800           0.0030           0.1490           0.0190\r\nCopyCPU2CPU                            20           0.4690           0.0030           0.1530           0.0235\r\nReorder                                 4           0.0110           0.0010           0.0050           0.0027\r\n"", '']",0,0
354,incubator-mxnet,5416,closed,Caffe importer fails to resnet-50,"Running  on the ResNet-50 model from [here](http://data.mxnet.io/models/imagenet/test/caffe/) produces an error importing the BatchNorm layers. I do not have Caffe installed, so am using the pure protobuf version of the importer. @nirbenz, @mli 

## Environment info
OSX

MXNet version:
0.9.4
dea87660c9d3b55ccd28a812116c93ca9e5032c2

Protobuf version:


Python version:
3.5


## Error Message:
`
converting layer conv1, wmat shape = (64, 3, 7, 7), bias shape = (64,)
Traceback (most recent call last):
  File ""convert_model.py"", line 162, in <module>
    main()
  File ""convert_model.py"", line 158, in main
    convert_model(args.prototxt, args.caffemodel, args.save_model_name)
  File ""convert_model.py"", line 127, in convert_model
    mean = mean.reshape(aux_shape_dic[mean_name])
AttributeError: 'RepeatedScalarFieldContainer' object has no attribute 'reshape'

",,"[""Hi Sebastian,\r\n\r\nI will have to investigate this further before I can get a full answer. \r\nCould you please send me the source prototxt that you are trying to convert?\r\n\r\nAnyhow, if possible, I'd try converting with Caffe installed rather than with the included protobuf.\r\n\r\nNir"", ""Okay I noticed you linked to the source prototxt. That's the same one I was testing against so it should work with Caffe installed. It seems that there are fields missing in the included protobuf."", 'this is a known bug. the current version only works with caffe installed for resnet. ', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']","[""\r\n>>> google.protobuf.__version__\r\n'3.0.0'\r\n""]","['convert_model.py', '']",0,0
355,incubator-mxnet,5098,closed,The optimizer object may not properly initialized,"Recently I run the tutorial  [Handwritten Digit Recognition](http://mxnet.io/tutorials/python/mnist.html), 
if I change the optimizer option to a optimizer object as following

I got poor result. I find that the optimizer class did not set the  mini-batch optimization parameter _rescale_grad_  to (1.0/batch_size).  The correct code is

Is this an intended design?
",,"['model is deprecated. Use module instead.', ""The problem remains when using module:\r\n```\r\nmod = mx.mod.Module(mlp)\r\noptimizer = mx.optimizer.SGD(learning_rate=0.1)\r\nmod.fit(train_data=train_iter,eval_data=val_iter,\r\n    batch_end_callback = mx.callback.Speedometer(batch_size, 200),\r\n#    optimizer='sgd', optimizer_params={'learning_rate': 0.1}, \r\n    optimizer=optimizer,\r\n    num_epoch=10)\r\n```\r\nI also need to set `optimizer = mx.optimizer.SGD(learning_rate=0.1, rescale_grad=(1.0/batch_size))`"", 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']","['\r\noptimizer = mx.optimizer.SGD(learning_rate=0.1)\r\nmodel = mx.model.FeedForward(\r\n    symbol = mlp,       # network structure\r\n    num_epoch = 10,     # number of data passes for training \r\n   optimizer = optimizer\r\n)\r\n', '\r\noptimizer = mx.optimizer.SGD(learning_rate=0.1, rescale_grad=(1.0/batch_size))\r\nmodel = mx.model.FeedForward(\r\n    symbol = mlp,       # network structure\r\n    num_epoch = 10,     # number of data passes for training \r\n   optimizer = optimizer\r\n)\r\n']",[],0,0
356,incubator-mxnet,793,closed,[mxnet paper] googlenet weight decay parameter  ,"Yesterday I read the paper, and I find the weight decay is 0.05, is this correct? 
@mli 
",,"[""currently i'm using eta *= 0.94 for each epoch. it's seems not optimal.. \n"", 'you mean weight decay of learning rate?\n', 'ah, you mean the learningsys paper. i guess that numbers are not correct. we used 0.94 for learning rate decay, 0.00001 for weight decay\n\nthe codes are  https://github.com/dmlc/mxnet/blob/master/example/image-classification/train_model.py \n', '@mli yes,the paper you post yesterday from weibo\n', ""@winstywang the parameter's name is wd, I think it is weight decay.\n"", '@qiaohaijun It should be wrong, see the clarification of mu in previous post\n', '@mli @winstywang  I got it, thx all\n', '@mli googlenet or inception-bn?\n\ngooglenet I got a not good result.\ninception-bn I got similiar result with your paper.\n', 'the numbers in the paper is fixed. \n\nwe only tested inception-bn, the proper number for googlenet is still unknown to me yet.\n']",[],[],0,0
357,incubator-mxnet,9623,closed,A tutorial for Word embeddings using mxnet,"I was trying to get familiar with mxnet framework and was browsing the tutorial section - https://mxnet.apache.org/tutorials/index.html.

I did not come across any illustrations for generating vector representations of words, like word2vec models( https://en.wikipedia.org/wiki/Word2vec ). Would it make sense to create a PR with one such tutorial. Is that something that will make sense in this code repo.",HowTo Website,"['@astonzhang ', 'I think @zackchase is doing it.', 'Is there already a PR in review?', 'Will MxNet implement a tokenizer as the one in Keras? Right now I use Keras to process the raw data and then convert it numpy array. It works well but too stupid. 😞 \r\n@anirudhacharya If you are familiar with Keras, you can follow my data iter first.\r\n[comment toxic](https://github.com/Godricly/comment_toxic)', '@anirudhacharya you can find example of word embedding training and usage in the [Gluon-NLP](http://gluon-nlp.mxnet.io/examples/word_embedding/word_embedding_training.html) project:\r\n- [Using pre-trained word embeddings](http://gluon-nlp.mxnet.io/examples/word_embedding/word_embedding.html)\r\n- [Training your own word embeddings](http://gluon-nlp.mxnet.io/examples/word_embedding/word_embedding_training.html)\r\n\r\nPlease consider closing, thanks']",[],[],0,0
358,incubator-mxnet,449,closed,Real time data augmentation and online batch generation.,"Mxnet looks very promising and I would like to give it a try. I want to train a triplet network like google facenet. One of the key issue to get a succefull training is the selection on a good triplet data to fed to the network. Since generating all possible triplets is not tractable, selecting them during the training is a good compromise.  So is it currently possible to add additional steps it the data iterator and in the SGD step such that one can do some statistics on the current batch using the current model in order to select good triplets ? The idea is to transform the source data set with just labeled image into triplet during training. Currently, I use fuel and blocks frameworks and chain different transformer to achieve this. May be Mxnet already have such kind of data pipeline transformation, or can I plug fuel into Mxnet ?
",,"['Can you give a it more detail on what kind of triplet information you would like to have.\n-  Say get multiple mini-batch of data,  run a scoring over current network, and generate the pairs training set?\n\nIt is possible, in a sense that all the things after data loading goes into python side, and you can always insert such augmentation step (pairing) on python side to generate the triplets. It requires  a bit tweaking on current code.\n', 'Precisely, I generate the batch of triplets as follow : \n- start with parent dataset that contains labeled images ( image + class )\n- at each step \n  - create a batch with an evenly distributed images per class ( say n classes with m images each)\n  - from this mini batch, Create a batch of triplets formed with an anchor image, positive image and negative image. The negative images are selected wrt to current network score. \n  - update parameters using this batch of triplets.\n    with fuel, all of this is done by chaining different data transformer. The SGD optimizer just fetches the batch from the pipeline. Do we have similar feature with Mxnet ?\n', 'The data transforming pipeline on the IO side was not as rich as you mentioned. However, the pipline you mentioned should be able to implemented using the current python API\n', 'How should I get started for that : \n- customizing the data iterator ?\n- changing the model.fit method ?\n', 'Starting from the getting data part of model.fit should be the easiest way. Customizing data iterator with a pipeline should make the approach more modularized and suitable for future usecases\n', 'After checking a closed look into model.fit method, I notice that it just need a DataIterator object. Then, what is the requirement for an iterator to make it works with model.fit ? Does fuel data stream http://fuel.readthedocs.org/en/latest/overview.html will work out of the box ?\n', 'I think if you write an adapter to implement the DataIter, things might work out of the box\n']",[],[],0,0
359,incubator-mxnet,4436,closed,Amalgamation for Android broken in v0.9.1pre,"I tested out amalgamation on v0.9.1pre and couldn't get it to work.  My environment amalgamates perfectly in v0.8.0.

The initial error I get is 


After commenting that out, I tried to manually change paths and comment out headers not located in the source.  One issue I had is that  files are linked incorrectly, e.g. 
 -> 
And several elementwise operators were missing from :


Eventually amalgamation simply fails without explanation:


Has something significant change in the requirements for amalgamation?

## Environment info
Operating System:
Android (amalgamation)

MXNet commit hash ():
84e5155fc26563ef8bebc08f201e8a88d4c3845e
",,"['@antinucleon ', 'Still a problem as of today: d4af261c485e418090d3d864b8ec7eafb417c89c', 'I built mxnet with v0.8.0 also met this problem', 'This should be fixed for v0.9.3 and later', 'This is not fixed in v0.9.3.  Amalgamation still breaking:\r\n\r\n```\r\nfrom mxnet_predict0.cc:3:\r\n[...]/mxnet/mxnet/amalgamation/../dmlc-core/include/dmlc/logging.h:18:22: fatal error: execinfo.h: No such file or directory\r\n #include <execinfo.h>\r\n                      ^\r\ncompilation terminated.\r\nmake: *** [mxnet_predict0.d] Error 1\r\n```', 'Commenting out that `#include <execinfo.h>` creates the further error:\r\n\r\n```\r\nIn file included from mxnet_predict0.cc:4:0:\r\n[...]/mxnet/amalgamation/../src/ndarray/ndarray.cc:16:30: fatal error: opencv2/opencv.hpp: No such file or directory\r\n #include <opencv2/opencv.hpp>\r\n                              ^\r\ncompilation terminated.\r\nmake: *** [mxnet_predict0.d] Error 1\r\n```\r\n\r\nIt looks like the `USE_OPENCV = 0` is being ignored?', 'Ive opened a new issue:\r\n\r\nhttps://github.com/dmlc/mxnet/issues/4783', 'git submodule update && make clean\n\nDawud Gordon <notifications@github.com>于2017年1月23日 周一下午5:37写道：\n\n> Commenting out that #include <execinfo.h> creates the further error:\n>\n>\n> In file included from mxnet_predict0.cc:4:0:\n>\n> [...]/mxnet/amalgamation/../src/ndarray/ndarray.cc:16:30: fatal error: opencv2/opencv.hpp: No such file or directory\n>\n>  #include <opencv2/opencv.hpp>\n>\n>                               ^\n>\n> compilation terminated.\n>\n> make: *** [mxnet_predict0.d] Error 1\n>\n>\n>\n> It looks like the USE_OPENCV = 0 is being ignored?\n>\n>\n>\n>\n> —\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dmlc/mxnet/issues/4436#issuecomment-274675114>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AAiudB6fjz_awCt70sZbMy17CNA3i3DZks5rVVXZgaJpZM4LX90M>\n> .\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n>\n']","['\r\n#include ""src/operator/elementwise_unary_op.cc""\r\n#include ""src/operator/elementwise_binary_op.cc""\r\n#include ""src/operator/elementwise_sum.cc""\r\n#include ""src/operator/elementwise_binary_scalar_op.cc""\r\n#include ""src/operator/elementwise_unary_op.cc""\r\n#include ""src/operator/embedding.cc""\r\n#include ""src/operator/reshape.cc""\r\n']","['[...]/mxnet/amalgamation/../dmlc-core/include/dmlc/logging.h:18:22: fatal error: execinfo.h: No such file or directory', 'nnvm', '#include <nnvm/op.h>', '#include <nnvm/include/nnvm/op.h>', 'mxnet_predict0.cc', 'make: *** [mxnet_predict0.d] Error 1', 'git rev-parse HEAD']",0,0
360,incubator-mxnet,1525,closed,Check failed: it != idx2label_.end() fail to find imagelabel for id 470889,"My problem .

I check



My data iterator


",,"['img2rec again. The error information persists.\n', 'I did several experiments and found out that the not found images are all in validation set. It is weird. How can im2rec ask for validation image, given `tr.lst`?\n\n`/mxnet/bin/im2rec ./tr.lst ./train_photos/ ./tr.rec resize=64 label_width=9`\n', 'I fix the problem by start over. I suspect that `cvs` writer is the cause.\n']","['\ncat ./va.lst | grep 470889\n470889  0 1 1 0 1 1 1 1 0   470889.jpg\n', '\ndef get_iterator(args, kv):\n    data_shape = (3, 64, 64)\n\n    # train data iterator\n    train = mx.io.ImageRecordIter(\n        path_imgrec = args.data_dir + ""tr.rec"",\n        mean_r      = 128,\n        mean_g      = 128,\n        mean_b      = 128,\n        scale       = 0.0078125,\n        max_aspect_ratio = 0.35,\n        data_shape  = data_shape,\n        label_width = 9,\n        batch_size  = args.batch_size,\n        rand_crop   = True,\n        rand_mirror = True,\n        path_imglist=""./tr.lst"",\n    )\n\n    # validate data iterator\n    val = mx.io.ImageRecordIter(\n        path_imgrec = args.data_dir + ""va.rec"",\n        mean_r      = 128,\n        mean_b      = 128,\n        mean_g      = 128,\n        scale       = 0.0078125,\n        rand_crop   = False,\n        rand_mirror = False,\n        data_shape  = data_shape,\n        label_width = 9,\n        path_imglist=""./va.lst"",\n        batch_size  = args.batch_size)\n\n    return (train, val)\n']",['Check failed: it != idx2label_.end() fail to find imagelabel for id 470889'],0,0
361,incubator-mxnet,2398,closed,Neural art save image error,"sometimes it raise up this error:


",,"['I think it is skimage bug. I repeat several times, sometimes it happens sometimes not.\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']","['\nINFO:root:save output to output/tmp_150.jpg\nTraceback (most recent call last):\n  File ""run.py"", line 221, in <module>\n    SaveImage(new_img.asnumpy(), \'output/tmp_\'+str(e+1)+\'.jpg\')\n  File ""run.py"", line 89, in SaveImage\n    io.imsave(filename, out)\n  File ""/usr/local/lib/python2.7/dist-packages/skimage/io/_io.py"", line 133, in imsave\n    return call_plugin(\'imsave\', fname, arr, plugin=plugin, **plugin_args)\n  File ""/usr/local/lib/python2.7/dist-packages/skimage/io/manage_plugins.py"", line 211, in call_plugin\n    return func(*args, **kwargs)\n  File ""/usr/local/lib/python2.7/dist-packages/skimage/io/_plugins/pil_plugin.py"", line 259, in imsave\n    img = ndarray_to_pil(arr, format_str=format_str)\n  File ""/usr/local/lib/python2.7/dist-packages/skimage/io/_plugins/pil_plugin.py"", line 163, in ndarray_to_pil\n    arr = img_as_ubyte(arr)\n  File ""/usr/local/lib/python2.7/dist-packages/skimage/util/dtype.py"", line 374, in img_as_ubyte\n    return convert(image, np.uint8, force_copy)\n  File ""/usr/local/lib/python2.7/dist-packages/skimage/util/dtype.py"", line 205, in convert\n    raise ValueError(""Images of type float must be between -1 and 1."")\nValueError: Images of type float must be between -1 and 1.\n']",[],0,0
362,incubator-mxnet,3137,closed,batch padding bug in ml.dmlc.mxnet.spark.io.LabeledPointIter,"if sample_size % batch_size != 0, the last batch generated by next() is still initialized with NDArray.empty() using original batch_size and set pad = (batch_size - real_size).

However, the mxnet training process seems to ignore the pad field of DataBatch. The whole batch is taken into calculation, which may produce NaN result in my linear regression model. I find that the uninitialized part of the last batch contains randomly huge numbers like xxxxxE10. 

Using NDArray.zeros() to initialize the batch or just discarding the last batch can fix in my case. And is it possible to use different batch_size for different batch in the DataIter object?
",,['This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!'],[],[],0,0
363,incubator-mxnet,2857,closed,"After several iteration, model.exec.output[0].asnumpy() get slower and slower !!","My training code is in following, which is just like the code in the example.


",,"['How much slower? Your GPU is heating up and slowing down automatically. So some performance drop is normal\n', '@piiswrong \nI don\'t think it is the problem. I test my work on cpu. In the first several iterations, the asnumpy cost about 6s. However, after 50 iterations, I waited for about twenty minutes. And the time cost of ""forward"" ""backward"" ""update(weight)"" is not increasing significantly.\n\nAnd there\'s another problem now.  I set the num of iterations equals 1. After the iteration finished, the program can\'t quit. And the memory seemed not be released and continuously  occupied until it is eat up.\n', '@piiswrong \n\nAfter several experiments, we found that as the iterations number increase, the time costs of program quitting increase significant. Increase the number of parameters will also increase the time cost.\n', ""Post your log and I'll likely be able to tell if it's normal or not\n"", '@piiswrong \n it convenient to send you my code？\nIt could be found here.\nhttps://github.com/gramce/Demo/blob/master/demo.py\n', '@gramce You can try to simplify the code first (like using dummy data for training). It would be much easier for us to find the cause if we have a minimal reproducible example.\n', 'I need to see your log, not code, as the problem is likely specific to your machine\n', ""@piiswrong \n\nI am sorry about that I don't know where to find the log. Is there anyway that you could tell me what log you need? And I'll add it to my code.\n\nHowever, I have tried my code on at least five machines and it seems nothing gets better.\n\nThanks.\n"", ""@sxjscience \n\nOK. I'll try to simplify my code. Thanks.\n"", ""How do you know it's getting slower? Show me the speed over time\n"", '@piiswrong \n\nI print the ""train_accuracy"" every 50 iterations. However, I found the program always hang when it try to get the model.exec.output[0] and can\'t calculate the ""training accuracy"" at all. So i tried to print the time cost every iterations. The log shows at least at the first several iterations, the ""training accuracy"" could be calculate correctly.\n', ""@piiswrong \n\nHere's part of the first several iterations' log.\n\niter_0batch_0forward_cost=5.00679016113e-05\niter_0batch_0backward_cost=5.50746917725e-05\niter_0batch_0eval_time=6.83129715919\niter_0batch_0update_cost=0.0371310710907\niter_0batch_0total_train_cost=6.86866593361\niter_0batch_1forward_cost=4.29153442383e-05\niter_0batch_1backward_cost=4.6968460083e-05\niter_0batch_1eval_time=25.0118870735\niter_0batch_1update_cost=0.0289700031281\niter_0batch_1total_train_cost=25.0410130024\niter_0batch_2forward_cost=3.81469726562e-05\niter_0batch_2backward_cost=4.00543212891e-05\niter_0batch_2eval_time=21.8669610023\niter_0batch_2update_cost=0.0204961299896\niter_0batch_2total_train_cost=21.8876068592\niter_0batch_3forward_cost=3.79085540771e-05\niter_0batch_3backward_cost=3.69548797607e-05\niter_0batch_3eval_time=21.7102849483\niter_0batch_3update_cost=0.0256681442261\niter_0batch_3total_train_cost=21.736096859\niter_1batch_0forward_cost=3.60012054443e-05\niter_1batch_0backward_cost=3.69548797607e-05\niter_1batch_0eval_time=21.6094560623\niter_1batch_0update_cost=0.0121791362762\niter_1batch_0total_train_cost=21.6217770576\niter_1batch_1forward_cost=3.60012054443e-05\niter_1batch_1backward_cost=3.60012054443e-05\niter_1batch_1eval_time=22.7317869663\niter_1batch_1update_cost=0.0251770019531\niter_1batch_1total_train_cost=22.7571120262\niter_1batch_2forward_cost=3.69548797607e-05\niter_1batch_2backward_cost=3.79085540771e-05\n"", 'maybe size of the data transferred from gpu to cpu is bigger and bigger.\n', ""...Unfortunately, I met the same problem with you.....\r\nBut I don't know how to solve it.."", 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']","['\ndef train(self, train_data, train_label,\n          dev_data,\n          dev_label,\n          batch_size,\n          optimizer=\'rmsprop\',\n          max_grad_norm=5.0,\n          learning_rate=0.0005,\n          epoch=200,\n          eval_func=None):\n    if eval_func is None:\n        eval_func = lambda x, y: np.std(x.asnumpy() - y.asnumpy())\n\n    opt = mx.optimizer.create(optimizer)\n    opt.lr = learning_rate\n\n    updater = mx.optimizer.get_updater(opt)\n\n    for iteration in range(epoch):\n        tic = time.time()\n\n        for begin in range(0, train_data.shape[0], batch_size):\n            batchX = train_data[begin:begin + batch_size]\n            batchY = train_label[begin:begin + batch_size]\n\n            if batchX.shape[0] != batch_size:\n                continue\n\n            print ""data shape, "", self.data.shape\n            print ""label shape, "", self.label.shape\n            print ""input data shape, "", batchX.shape\n            print ""input label shape, "", batchY.shape\n            self.data[:] = batchX\n            self.label[:] = batchY\n\n            self.mod_exec.forward(is_train=True)\n            self.mod_exec.backward()\n\n            train_error = eval_func(self.mod_exec.outputs[0], self.label)\n\n            norm = 0.0\n            for idx, weight, grad, name in self.param_blocks:\n                grad /= batch_size\n                l2_norm = mx.nd.norm(grad).asscalar()\n                norm += l2_norm * l2_norm\n\n            norm = math.sqrt(norm)\n            for idx, weight, grad, name in self.param_blocks:\n                if norm > max_grad_norm:\n                    grad *= (max_grad_norm / norm)\n                updater(idx, grad, weight)\n                grad[:] = 0.0\n\n            if dev_data is not None and dev_label is not None:\n                for begin in range(0, dev_data.shape[0], batch_size):\n                    batchX = dev_data[begin:begin + batch_size]\n                    batchY = dev_label[begin:begin + batch_size]\n\n                    if batchX.shape[0] != batch_size:\n                        continue\n\n                    self.data = batchX\n                    self.label = batchY\n                    self.mod_exec.forward(is_train=False)\n\n                    dev_error = eval_func(self.mod_exec.outputs[0], self.label)\n\n            if iteration % 50 == 0 and iteration > 0:\n                opt.lr *= 0.5\n                logging.info(""reset optimizer learning rate to {}"".format(opt.lr))\n\n            toc = time.time()\n            train_time = toc - tic\n            logging.info(""Iter {} Train: Time:{:.3f}s, Training Error:{:.3f} Dev Error:{:.3f}"".format(iteration,\n                                                                                                      train_time,\n                                                                                                      train_error,\n                                                                                                      dev_error))\n']",[],0,0
364,incubator-mxnet,11263,closed,Memory corruption issue with Scala test,"java': double free or corruption (fasttop): 0x00007f91e0db8270 ***
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f9527a337e5]
/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f9527a3c37a]
/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f9527a4053c]
/work/mxnet/scala-package/native/linux-x86_64-gpu/target/libmxnet-scala-linux-x86_64-gpu.so(_ZNSt10_HashtableINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_S5_ESaIS8_ENSt8__detail10_Select1stESt8equal_toIS5_ESt4hashIS5_ENSA_18_Mod_range_hashingENSA_20_Default_ranged_hashENSA_20_Prime_rehash_policyENSA_17_Hashtable_traitsILb1ELb0ELb1EEEE9_M_assignIZNSL_aSERKSL_EUlPKNSA_10_Hash_nodeIS8_Lb1EEEE0_EEvSO_RKT_+0x81)[0x7f92a8a7ef11]
/work/mxnet/scala-package/native/linux-x86_64-gpu/target/libmxnet-scala-linux-x86_64-gpu.so(_ZNSt10_HashtableINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEESt4pairIKS5_S5_ESaIS8_ENSt8__detail10_Select1stESt8equal_toIS5_ESt4hashIS5_ENSA_18_Mod_range_hashingENSA_20_Default_ranged_hashENSA_20_Prime_rehash_policyENSA_17_Hashtable_traitsILb1ELb0ELb1EEEEaSERKSL_+0xa2)[0x7f92a8a7f212]
/work/mxnet/scala-package/native/linux-x86_64-gpu/target/libmxnet-scala-linux-x86_64-gpu.so(MXInitPSEnv+0x346)[0x7f92ab65d686]
/work/mxnet/scala-package/native/linux-x86_64-gpu/target/libmxnet-scala-linux-x86_64-gpu.so(Java_org_apache_mxnet_LibInfo_mxInitPSEnv+0xf5)[0x7f92a89c8895]
[0x7f95110184e7]
`
Please see: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-11210/5/pipeline",Flaky Scala Test,"['@yzhliu @nswamy @CodingCat', 'https://github.com/apache/incubator-mxnet/pull/11264, @nswamy please close this issue. Reopen if we still see the same one happen again on CI', ""This was related to the Spark tests that were added, closing this now since the tests are disabled and we'll create a new issue if there is a different when the tests gets fixed""]",[],"['', '\r\n*** Error in ', '']",0,0
365,incubator-mxnet,13024,closed,mxnet.random.seed docs error,"## Description
Sphinx throws an error when generating the docs for this function.

## Error
",Doc,['@mxnet-label-bot [Doc]'],"['\r\n/home/ubuntu/incubator-mxnet/python/mxnet/random.py:docstring of mxnet.random.seed:0: WARNING: duplicate object description of mxnet.random.seed, other instance in /home/ubuntu/incubator-mxnet/docs/api/python/ndarray/ndarray.md, use :noindex: for one of them\r\n\r\n']",[],0,0
366,incubator-mxnet,4465,closed,MXNet Installation fails on Ubuntu 14.04.4 LTS,"## Environment info
Operating System:


Compiler:


Package used (Python/R/Scala/Julia):



MXNet version:



Python version and distribution:



## Error Message:

/root/mxnet/dmlc-core'
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o line_split.o src/io/line_split.cc
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/ndarray/ndarray_function_gpu.o src/ndarray/ndarray_function.cu >build/src/ndarray/ndarray_function_gpu.d
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/activation_gpu.o src/operator/activation.cu >build/src/operator/activation_gpu.d
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o recordio_split.o src/io/recordio_split.cc
/usr/local/cuda/bin/nvcc -c -o build/src/ndarray/ndarray_function_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/ndarray/ndarray_function.cu
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o input_split_base.o src/io/input_split_base.cc
/usr/local/cuda/bin/nvcc -c -o build/src/operator/activation_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/activation.cu
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/batch_norm_gpu.o src/operator/batch_norm.cu >build/src/operator/batch_norm_gpu.d
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o io.o src/io.cc
/usr/local/cuda/bin/nvcc -c -o build/src/operator/batch_norm_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/batch_norm.cu
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/block_grad_gpu.o src/operator/block_grad.cu >build/src/operator/block_grad_gpu.d
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o local_filesys.o src/io/local_filesys.cc
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/broadcast_mask_op_gpu.o src/operator/broadcast_mask_op.cu >build/src/operator/broadcast_mask_op_gpu.d
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o data.o src/data.cc
/usr/local/cuda/bin/nvcc -c -o build/src/operator/block_grad_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/block_grad.cu
/usr/local/cuda/bin/nvcc -c -o build/src/operator/broadcast_mask_op_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/broadcast_mask_op.cu
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o recordio.o src/recordio.cc
g++ -c -O3 -Wall -Wno-unknown-pragmas -Iinclude  -std=c++0x -fopenmp -fPIC -DDMLC_USE_HDFS=0 -DDMLC_USE_S3=0 -DDMLC_USE_AZURE=0 -msse2 -o config.o src/config.cc
/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/broadcast_reduce_op_gpu.o src/operator/broadcast_reduce_op.cu >build/src/operator/broadcast_reduce_op_gpu.d
ar cr libdmlc.a line_split.o recordio_split.o input_split_base.o io.o local_filesys.o data.o recordio.o config.o
make[1]: Leaving directory mxnet::GraphStorageAllocator::Get(long, mxnet::TShape)':
graph_memory_allocator.cc:(.text+0x6da): undefined reference to 

If you could help me understand the error, I would really appreciate it.

Thanks!

-Besir",,"['make clean && make', 'may be this is related with this problem http://stackoverflow.com/questions/1312241/using-a-static-const-int-in-a-struct-class/1312267#1312267\r\n\r\nI meet similar problem when I do amalgamation.\r\n\r\nAfter I add const int64_t GraphStorageAllocator::kBadStorageID;  Everything is ok.', ""I'd like to point out that I couldn't fix the problem, but noticed that the master branch pegged to the `1ae2905cc3c2e35541d45edab18ddffb9cf455da` git hash version seemed to be working. (the [build/src/symbol/graph_memory_allocator.h](https://github.com/dmlc/mxnet/blob/master/src/symbol/graph_memory_allocator.h) file seems to be have moved/deleted)\r\n\r\nIf anyone else is having this problem, I would recommend using a later version (other than `v0.8.0`).\r\n\r\nAt the time writing this, the most stable version was `v0.8.0`, hence why I used a git hash version instead of a tag version."", ""I ran into this problem with the 0.8.0 release as well.  Rather than using a newer commit, I added the line `const int64_t GraphStorageAllocator::kBadStorageID;` as suggested by @xlvector into graph_memory_allocator.cc at line 10.\r\n\r\nHere's a patch which does the same thing:\r\n```diff --git a/src/symbol/graph_memory_allocator.cc b/src/symbol/graph_memory_allocator.cc\r\nindex bbec1e7..19b999f 100644\r\n--- a/src/symbol/graph_memory_allocator.cc\r\n+++ b/src/symbol/graph_memory_allocator.cc\r\n@@ -7,6 +7,7 @@\r\n \r\n namespace mxnet {\r\n const uint32_t GraphStorageAllocator::kDummyColor = 1 << 31;\r\n+const int64_t GraphStorageAllocator::kBadStorageID;\r\n \r\n GraphStorageAllocator::GraphStorageAllocator(\r\n     StaticGraph *graph,\r\n```""]","['bash\r\n$ lsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID:\tUbuntu\r\nDescription:\tUbuntu 14.04.4 LTS\r\nRelease:\t14.04\r\nCodename:\ttrusty\r\n', ""bash\r\n$ gcc -v\r\nUsing built-in specs.\r\nCOLLECT_GCC=gcc\r\nCOLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/4.8/lto-wrapper\r\nTarget: x86_64-linux-gnu\r\nConfigured with: ../src/configure -v --with-pkgversion='Ubuntu 4.8.4-2ubuntu1~14.04.3' --with-bugurl=file:///usr/share/doc/gcc-4.8/README.Bugs --enable-languages=c,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-4.8 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --with-gxx-include-dir=/usr/include/c++/4.8 --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --enable-gnu-unique-object --disable-libmudflap --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-4.8-amd64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-4.8-amd64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-4.8-amd64 --with-arch-directory=amd64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-objc-gc --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --with-tune=generic --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu\r\nThread model: posix\r\ngcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.3) \r\n"", '\r\nPython\r\n', 'bash\r\nAnaconda Python 2.7\r\n', '\r\n\r\n## Minimum reproducible example\r\n\r\n']","['v0.8.0', '', ""\r\nCloning into '/root/mxnet'...\r\nSubmodule 'dmlc-core' (https://github.com/dmlc/dmlc-core.git) registered for path 'dmlc-core'\r\nSubmodule 'mshadow' (https://github.com/dmlc/mshadow.git) registered for path 'mshadow'\r\nSubmodule 'nnvm' (https://github.com/dmlc/nnvm) registered for path 'nnvm'\r\nSubmodule 'ps-lite' (https://github.com/dmlc/ps-lite) registered for path 'ps-lite'\r\nCloning into 'dmlc-core'...\r\nSubmodule path 'dmlc-core': checked out '3eb9debabb917248dbbbfe2af1aec1fc30580f96'\r\nCloning into 'mshadow'...\r\nSubmodule path 'mshadow': checked out 'c8643facd3726020edd5ff2f7fcbd915acd72edc'\r\nCloning into 'nnvm'...\r\nSubmodule path 'nnvm': checked out '288d06ce1a79cd0399e7f111b5e5eff7c3ba00a2'\r\nSubmodule 'plugin/nnvm-fusion' (https://github.com/dmlc/nnvm-fusion.git) registered for path 'plugin/nnvm-fusion'\r\nCloning into 'plugin/nnvm-fusion'...\r\nSubmodule path 'nnvm/plugin/nnvm-fusion': checked out '86853a73e93fdbcdaec6fd3eda39e8f11d554c92'\r\nCloning into 'ps-lite'...\r\nSubmodule path 'ps-lite': checked out '4a060e4e8aa40c3a931a0f8af9211279e012f8a2'\r\nwarning: unable to rmdir nnvm: Directory not empty\r\nNote: checking out 'tags/v0.8.0'.\r\n\r\nYou are in 'detached HEAD' state. You can look around, make experimental\r\nchanges and commit them, and you can discard any commits you make in this\r\nstate without impacting any branches by performing another checkout.\r\n\r\nIf you want to create a new branch to retain commits you create, you may\r\ndo so (now or later) by using -b with the checkout command again. Example:\r\n\r\n  git checkout -b new_branch_name\r\n\r\nHEAD is now at 67bee19... \t[RELEASE] v0.8 Release (Last release before NNVM refactor (#4409)\r\nM\tdmlc-core\r\nM\tmshadow\r\nMXNet root folder: /root/mxnet/\r\nInstalling build-essential, libatlas-base-dev, libopencv-dev, pip, graphviz ...\r\nIgn http://lib.stat.cmu.edu trusty/ InRelease\r\nHit http://ppa.launchpad.net trusty InRelease\r\nIgn http://archive.ubuntu.com trusty InRelease\r\nHit http://archive.ubuntu.com trusty-updates InRelease\r\nHit http://archive.ubuntu.com trusty-security InRelease\r\nHit http://lib.stat.cmu.edu trusty/ Release.gpg\r\nIgn http://ppa.launchpad.net trusty InRelease\r\nHit http://ppa.launchpad.net trusty InRelease\r\nHit https://deb.nodesource.com trusty InRelease\r\nHit http://lib.stat.cmu.edu trusty/ Release\r\nHit http://ppa.launchpad.net trusty Release.gpg\r\nHit http://archive.ubuntu.com trusty Release.gpg\r\nHit http://ppa.launchpad.net trusty Release\r\nHit http://archive.ubuntu.com trusty Release\r\nHit http://ppa.launchpad.net trusty/main amd64 Packages\r\nHit http://archive.ubuntu.com trusty-updates/main Sources\r\nHit http://archive.ubuntu.com trusty-updates/restricted Sources\r\nHit http://archive.ubuntu.com trusty-updates/universe Sources\r\nHit http://ppa.launchpad.net trusty/main amd64 Packages\r\nHit https://deb.nodesource.com trusty/main Sources\r\nHit https://deb.nodesource.com trusty/main amd64 Packages\r\nHit http://lib.stat.cmu.edu trusty/ Packages\r\nHit http://archive.ubuntu.com trusty-updates/main amd64 Packages\r\nHit http://ppa.launchpad.net trusty/main amd64 Packages\r\nHit http://archive.ubuntu.com trusty-updates/restricted amd64 Packages\r\nHit http://archive.ubuntu.com trusty-updates/universe amd64 Packages\r\nHit http://archive.ubuntu.com trusty-security/main Sources\r\nHit http://archive.ubuntu.com trusty-security/restricted Sources\r\nHit http://archive.ubuntu.com trusty-security/universe Sources\r\nHit http://archive.ubuntu.com trusty-security/main amd64 Packages\r\nHit http://archive.ubuntu.com trusty-security/restricted amd64 Packages\r\nHit http://archive.ubuntu.com trusty-security/universe amd64 Packages\r\nHit http://archive.ubuntu.com trusty/main Sources\r\nHit http://archive.ubuntu.com trusty/restricted Sources\r\nHit http://archive.ubuntu.com trusty/universe Sources\r\nHit http://archive.ubuntu.com trusty/main amd64 Packages\r\nHit http://archive.ubuntu.com trusty/restricted amd64 Packages\r\nHit http://archive.ubuntu.com trusty/universe amd64 Packages\r\nReading package lists...\r\nReading package lists...\r\nBuilding dependency tree...\r\nReading state information...\r\nbuild-essential is already the newest version.\r\nlibatlas-base-dev is already the newest version.\r\nlibopencv-dev is already the newest version.\r\ngraphviz is already the newest version.\r\nThe following packages were automatically installed and are no longer required:\r\n  cmake-data libarchive13 libboost-atomic-dev libboost-atomic1.54-dev\r\n  libboost-atomic1.54.0 libboost-chrono-dev libboost-chrono1.54-dev\r\n  libboost-chrono1.54.0 libboost-context-dev libboost-context1.54-dev\r\n  libboost-context1.54.0 libboost-coroutine-dev libboost-coroutine1.54-dev\r\n  libboost-date-time-dev libboost-date-time1.54-dev libboost-date-time1.54.0\r\n  libboost-dev libboost-exception-dev libboost-exception1.54-dev\r\n  libboost-filesystem-dev libboost-filesystem1.54-dev\r\n  libboost-filesystem1.54.0 libboost-graph-dev libboost-graph-parallel-dev\r\n  libboost-graph-parallel1.54-dev libboost-graph-parallel1.54.0\r\n  libboost-graph1.54-dev libboost-graph1.54.0 libboost-iostreams-dev\r\n  libboost-iostreams1.54-dev libboost-iostreams1.54.0 libboost-locale-dev\r\n  libboost-locale1.54-dev libboost-locale1.54.0 libboost-log-dev\r\n  libboost-log1.54-dev libboost-log1.54.0 libboost-math-dev\r\n  libboost-math1.54-dev libboost-math1.54.0 libboost-mpi-dev\r\n  libboost-mpi-python-dev libboost-mpi-python1.54-dev\r\n  libboost-mpi-python1.54.0 libboost-mpi1.54-dev libboost-mpi1.54.0\r\n  libboost-program-options-dev libboost-program-options1.54-dev\r\n  libboost-program-options1.54.0 libboost-python1.54-dev libboost-python1.54.0\r\n  libboost-random-dev libboost-random1.54-dev libboost-random1.54.0\r\n  libboost-regex-dev libboost-regex1.54-dev libboost-regex1.54.0\r\n  libboost-serialization-dev libboost-serialization1.54-dev\r\n  libboost-serialization1.54.0 libboost-signals-dev libboost-signals1.54-dev\r\n  libboost-signals1.54.0 libboost-system-dev libboost-system1.54-dev\r\n  libboost-system1.54.0 libboost-test-dev libboost-test1.54-dev\r\n  libboost-test1.54.0 libboost-thread-dev libboost-thread1.54-dev\r\n  libboost-thread1.54.0 libboost-timer-dev libboost-timer1.54-dev\r\n  libboost-timer1.54.0 libboost-tools-dev libboost-wave-dev\r\n  libboost-wave1.54-dev libboost-wave1.54.0 libboost1.54-dev\r\n  libboost1.54-tools-dev libcr0 libhwloc-dev libhwloc-plugins libhwloc5\r\n  libibverbs-dev libibverbs1 libjsoncpp0 libnettle4 libnuma1 libopenmpi-dev\r\n  libopenmpi1.6 libpci-dev libpci3 libtorque2 mpi-default-bin mpi-default-dev\r\n  ocl-icd-libopencl1 openmpi-bin openmpi-common\r\nUse 'apt-get autoremove' to remove them.\r\n0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\r\nBuilding MXNet core. This can take few minutes...\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/initialize.o src/initialize.cc >build/src/initialize.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/resource.o src/resource.cc >build/src/resource.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/c_api/c_api.o src/c_api/c_api.cc >build/src/c_api/c_api.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/c_api/c_api_error.o src/c_api/c_api_error.cc >build/src/c_api/c_api_error.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/c_api/c_predict_api.o src/c_api/c_predict_api.cc >build/src/c_api/c_predict_api.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/common/mxrtc.o src/common/mxrtc.cc >build/src/common/mxrtc.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/engine/engine.o src/engine/engine.cc >build/src/engine/engine.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/engine/naive_engine.o src/engine/naive_engine.cc >build/src/engine/naive_engine.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/initialize.cc -o build/src/initialize.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/c_api/c_api_error.cc -o build/src/c_api/c_api_error.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/resource.cc -o build/src/resource.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/common/mxrtc.cc -o build/src/common/mxrtc.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/engine/naive_engine.cc -o build/src/engine/naive_engine.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/c_api/c_predict_api.cc -o build/src/c_api/c_predict_api.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/engine/engine.cc -o build/src/engine/engine.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/c_api/c_api.cc -o build/src/c_api/c_api.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/engine/threaded_engine.o src/engine/threaded_engine.cc >build/src/engine/threaded_engine.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/engine/threaded_engine.cc -o build/src/engine/threaded_engine.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/engine/threaded_engine_perdevice.o src/engine/threaded_engine_perdevice.cc >build/src/engine/threaded_engine_perdevice.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/engine/threaded_engine_perdevice.cc -o build/src/engine/threaded_engine_perdevice.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/engine/threaded_engine_pooled.o src/engine/threaded_engine_pooled.cc >build/src/engine/threaded_engine_pooled.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/engine/threaded_engine_pooled.cc -o build/src/engine/threaded_engine_pooled.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/io/image_aug_default.o src/io/image_aug_default.cc >build/src/io/image_aug_default.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/io/image_aug_default.cc -o build/src/io/image_aug_default.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/io/io.o src/io/io.cc >build/src/io/io.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/io/io.cc -o build/src/io/io.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/io/iter_csv.o src/io/iter_csv.cc >build/src/io/iter_csv.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/io/iter_csv.cc -o build/src/io/iter_csv.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/io/iter_image_recordio.o src/io/iter_image_recordio.cc >build/src/io/iter_image_recordio.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/io/iter_image_recordio.cc -o build/src/io/iter_image_recordio.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/io/iter_mnist.o src/io/iter_mnist.cc >build/src/io/iter_mnist.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/io/iter_mnist.cc -o build/src/io/iter_mnist.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/kvstore/kvstore.o src/kvstore/kvstore.cc >build/src/kvstore/kvstore.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/kvstore/kvstore.cc -o build/src/kvstore/kvstore.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/ndarray/ndarray.o src/ndarray/ndarray.cc >build/src/ndarray/ndarray.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/ndarray/ndarray.cc -o build/src/ndarray/ndarray.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/ndarray/ndarray_function.o src/ndarray/ndarray_function.cc >build/src/ndarray/ndarray_function.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/ndarray/ndarray_function.cc -o build/src/ndarray/ndarray_function.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/activation.o src/operator/activation.cc >build/src/operator/activation.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/activation.cc -o build/src/operator/activation.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/batch_norm.o src/operator/batch_norm.cc >build/src/operator/batch_norm.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/batch_norm.cc -o build/src/operator/batch_norm.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/block_grad.o src/operator/block_grad.cc >build/src/operator/block_grad.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/broadcast_mask_op.o src/operator/broadcast_mask_op.cc >build/src/operator/broadcast_mask_op.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/block_grad.cc -o build/src/operator/block_grad.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/broadcast_mask_op.cc -o build/src/operator/broadcast_mask_op.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/broadcast_reduce_op.o src/operator/broadcast_reduce_op.cc >build/src/operator/broadcast_reduce_op.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/broadcast_reduce_op.cc -o build/src/operator/broadcast_reduce_op.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/cast.o src/operator/cast.cc >build/src/operator/cast.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/cast.cc -o build/src/operator/cast.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/concat.o src/operator/concat.cc >build/src/operator/concat.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/concat.cc -o build/src/operator/concat.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/convolution.o src/operator/convolution.cc >build/src/operator/convolution.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/convolution.cc -o build/src/operator/convolution.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/correlation.o src/operator/correlation.cc >build/src/operator/correlation.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/crop.o src/operator/crop.cc >build/src/operator/crop.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/correlation.cc -o build/src/operator/correlation.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/crop.cc -o build/src/operator/crop.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/cross_device_copy.o src/operator/cross_device_copy.cc >build/src/operator/cross_device_copy.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/cross_device_copy.cc -o build/src/operator/cross_device_copy.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/cudnn_batch_norm.o src/operator/cudnn_batch_norm.cc >build/src/operator/cudnn_batch_norm.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/cudnn_batch_norm.cc -o build/src/operator/cudnn_batch_norm.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/cudnn_convolution.o src/operator/cudnn_convolution.cc >build/src/operator/cudnn_convolution.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/cudnn_convolution.cc -o build/src/operator/cudnn_convolution.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/custom.o src/operator/custom.cc >build/src/operator/custom.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/custom.cc -o build/src/operator/custom.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/deconvolution.o src/operator/deconvolution.cc >build/src/operator/deconvolution.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/deconvolution.cc -o build/src/operator/deconvolution.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/dropout.o src/operator/dropout.cc >build/src/operator/dropout.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/dropout.cc -o build/src/operator/dropout.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/elementwise_binary_broadcast_op.o src/operator/elementwise_binary_broadcast_op.cc >build/src/operator/elementwise_binary_broadcast_op.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/elementwise_binary_broadcast_op.cc -o build/src/operator/elementwise_binary_broadcast_op.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/elementwise_binary_op.o src/operator/elementwise_binary_op.cc >build/src/operator/elementwise_binary_op.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/elementwise_binary_op.cc -o build/src/operator/elementwise_binary_op.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/elementwise_binary_scalar_op.o src/operator/elementwise_binary_scalar_op.cc >build/src/operator/elementwise_binary_scalar_op.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/elementwise_binary_scalar_op.cc -o build/src/operator/elementwise_binary_scalar_op.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/elementwise_sum.o src/operator/elementwise_sum.cc >build/src/operator/elementwise_sum.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/elementwise_sum.cc -o build/src/operator/elementwise_sum.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/elementwise_unary_op.o src/operator/elementwise_unary_op.cc >build/src/operator/elementwise_unary_op.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/elementwise_unary_op.cc -o build/src/operator/elementwise_unary_op.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/embedding.o src/operator/embedding.cc >build/src/operator/embedding.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/embedding.cc -o build/src/operator/embedding.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/fully_connected.o src/operator/fully_connected.cc >build/src/operator/fully_connected.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/fully_connected.cc -o build/src/operator/fully_connected.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/identity_attach_KL_sparse_reg.o src/operator/identity_attach_KL_sparse_reg.cc >build/src/operator/identity_attach_KL_sparse_reg.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/identity_attach_KL_sparse_reg.cc -o build/src/operator/identity_attach_KL_sparse_reg.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/instance_norm.o src/operator/instance_norm.cc >build/src/operator/instance_norm.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/instance_norm.cc -o build/src/operator/instance_norm.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/l2_normalization.o src/operator/l2_normalization.cc >build/src/operator/l2_normalization.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/l2_normalization.cc -o build/src/operator/l2_normalization.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/leaky_relu.o src/operator/leaky_relu.cc >build/src/operator/leaky_relu.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/leaky_relu.cc -o build/src/operator/leaky_relu.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/loss_binary_op.o src/operator/loss_binary_op.cc >build/src/operator/loss_binary_op.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/loss_binary_op.cc -o build/src/operator/loss_binary_op.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/lrn.o src/operator/lrn.cc >build/src/operator/lrn.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/lrn.cc -o build/src/operator/lrn.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/make_loss.o src/operator/make_loss.cc >build/src/operator/make_loss.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/make_loss.cc -o build/src/operator/make_loss.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/matrix_op.o src/operator/matrix_op.cc >build/src/operator/matrix_op.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/native_op.o src/operator/native_op.cc >build/src/operator/native_op.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/matrix_op.cc -o build/src/operator/matrix_op.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/native_op.cc -o build/src/operator/native_op.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/ndarray_op.o src/operator/ndarray_op.cc >build/src/operator/ndarray_op.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/operator.o src/operator/operator.cc >build/src/operator/operator.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/operator_util.o src/operator/operator_util.cc >build/src/operator/operator_util.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/ndarray_op.cc -o build/src/operator/ndarray_op.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/operator.cc -o build/src/operator/operator.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/operator_util.cc -o build/src/operator/operator_util.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/pad.o src/operator/pad.cc >build/src/operator/pad.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/pad.cc -o build/src/operator/pad.o\r\nIn file included from src/operator/pad.cc:7:0:\r\nsrc/operator/./pad-inl.h: In member function ‘virtual bool mxnet::op::PadProp::InferShape(std::vector<mxnet::TShape>*, std::vector<mxnet::TShape>*, std::vector<mxnet::TShape>*) const’:\r\nsrc/operator/./pad-inl.h:166:37: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     for (int i = 0; i < dshape.ndim(); ++i) {\r\n                                     ^\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/pooling.o src/operator/pooling.cc >build/src/operator/pooling.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/pooling.cc -o build/src/operator/pooling.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/regression_output.o src/operator/regression_output.cc >build/src/operator/regression_output.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/reshape.o src/operator/reshape.cc >build/src/operator/reshape.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/regression_output.cc -o build/src/operator/regression_output.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/reshape.cc -o build/src/operator/reshape.o\r\nIn file included from src/operator/reshape.cc:8:0:\r\nsrc/operator/./reshape-inl.h: In member function ‘virtual bool mxnet::op::ReshapeProp::InferShape(std::vector<mxnet::TShape>*, std::vector<mxnet::TShape>*, std::vector<mxnet::TShape>*) const’:\r\nsrc/operator/./reshape-inl.h:257:28: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n           while (src_idx < dshape_len) {\r\n                            ^\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/rnn.o src/operator/rnn.cc >build/src/operator/rnn.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/rnn.cc -o build/src/operator/rnn.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/roi_pooling.o src/operator/roi_pooling.cc >build/src/operator/roi_pooling.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/sample_op.o src/operator/sample_op.cc >build/src/operator/sample_op.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/roi_pooling.cc -o build/src/operator/roi_pooling.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/sample_op.cc -o build/src/operator/sample_op.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/sequence_last.o src/operator/sequence_last.cc >build/src/operator/sequence_last.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/sequence_last.cc -o build/src/operator/sequence_last.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/sequence_mask.o src/operator/sequence_mask.cc >build/src/operator/sequence_mask.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/sequence_mask.cc -o build/src/operator/sequence_mask.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/sequence_reverse.o src/operator/sequence_reverse.cc >build/src/operator/sequence_reverse.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/sequence_reverse.cc -o build/src/operator/sequence_reverse.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/slice_channel.o src/operator/slice_channel.cc >build/src/operator/slice_channel.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/slice_channel.cc -o build/src/operator/slice_channel.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/smooth_l1_unary.o src/operator/smooth_l1_unary.cc >build/src/operator/smooth_l1_unary.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/softmax_activation.o src/operator/softmax_activation.cc >build/src/operator/softmax_activation.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/smooth_l1_unary.cc -o build/src/operator/smooth_l1_unary.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/softmax_activation.cc -o build/src/operator/softmax_activation.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/softmax_output.o src/operator/softmax_output.cc >build/src/operator/softmax_output.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/softmax_output.cc -o build/src/operator/softmax_output.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/spatial_transformer.o src/operator/spatial_transformer.cc >build/src/operator/spatial_transformer.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/svm_output.o src/operator/svm_output.cc >build/src/operator/svm_output.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/spatial_transformer.cc -o build/src/operator/spatial_transformer.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/svm_output.cc -o build/src/operator/svm_output.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/swapaxis.o src/operator/swapaxis.cc >build/src/operator/swapaxis.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/swapaxis.cc -o build/src/operator/swapaxis.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/upsampling.o src/operator/upsampling.cc >build/src/operator/upsampling.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/upsampling.cc -o build/src/operator/upsampling.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/optimizer/optimizer.o src/optimizer/optimizer.cc >build/src/optimizer/optimizer.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/optimizer/optimizer.cc -o build/src/optimizer/optimizer.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/optimizer/sgd.o src/optimizer/sgd.cc >build/src/optimizer/sgd.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/optimizer/sgd.cc -o build/src/optimizer/sgd.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/storage/storage.o src/storage/storage.cc >build/src/storage/storage.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/symbol/graph_executor.o src/symbol/graph_executor.cc >build/src/symbol/graph_executor.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/storage/storage.cc -o build/src/storage/storage.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/symbol/graph_executor.cc -o build/src/symbol/graph_executor.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/symbol/graph_memory_allocator.o src/symbol/graph_memory_allocator.cc >build/src/symbol/graph_memory_allocator.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/symbol/graph_memory_allocator.cc -o build/src/symbol/graph_memory_allocator.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/symbol/static_graph.o src/symbol/static_graph.cc >build/src/symbol/static_graph.d\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/symbol/symbol.o src/symbol/symbol.cc >build/src/symbol/symbol.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/symbol/static_graph.cc -o build/src/symbol/static_graph.o\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/symbol/symbol.cc -o build/src/symbol/symbol.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/mkl/mkl_cppwrapper.o src/operator/mkl/mkl_cppwrapper.cc >build/src/operator/mkl/mkl_cppwrapper.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/mkl/mkl_cppwrapper.cc -o build/src/operator/mkl/mkl_cppwrapper.o\r\ng++ -std=c++11 -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -MM -MT build/src/operator/mkl/mkl_memory.o src/operator/mkl/mkl_memory.cc >build/src/operator/mkl/mkl_memory.d\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -c src/operator/mkl/mkl_memory.cc -o build/src/operator/mkl/mkl_memory.o\r\ncd /root/mxnet/dmlc-core; make libdmlc.a USE_SSE=1 config=/root/mxnet/config.mk; cd /root/mxnet\r\nmake[1]: Entering directory "", '/root/mxnet/dmlc-core\'\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/cast_gpu.o src/operator/cast.cu >build/src/operator/cast_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/broadcast_reduce_op_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/broadcast_reduce_op.cu\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/cast_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/cast.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/concat_gpu.o src/operator/concat.cu >build/src/operator/concat_gpu.d\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/convolution_gpu.o src/operator/convolution.cu >build/src/operator/convolution_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/concat_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/concat.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/correlation_gpu.o src/operator/correlation.cu >build/src/operator/correlation_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/convolution_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/convolution.cu\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/correlation_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/correlation.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/crop_gpu.o src/operator/crop.cu >build/src/operator/crop_gpu.d\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/cudnn_batch_norm_gpu.o src/operator/cudnn_batch_norm.cu >build/src/operator/cudnn_batch_norm_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/crop_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/crop.cu\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/cudnn_batch_norm_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/cudnn_batch_norm.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/deconvolution_gpu.o src/operator/deconvolution.cu >build/src/operator/deconvolution_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/deconvolution_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/deconvolution.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/dropout_gpu.o src/operator/dropout.cu >build/src/operator/dropout_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/dropout_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/dropout.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/elementwise_binary_broadcast_op_gpu.o src/operator/elementwise_binary_broadcast_op.cu >build/src/operator/elementwise_binary_broadcast_op_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/elementwise_binary_broadcast_op_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/elementwise_binary_broadcast_op.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/elementwise_binary_op_gpu.o src/operator/elementwise_binary_op.cu >build/src/operator/elementwise_binary_op_gpu.d\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/elementwise_binary_scalar_op_gpu.o src/operator/elementwise_binary_scalar_op.cu >build/src/operator/elementwise_binary_scalar_op_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/elementwise_binary_op_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/elementwise_binary_op.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/elementwise_sum_gpu.o src/operator/elementwise_sum.cu >build/src/operator/elementwise_sum_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/elementwise_binary_scalar_op_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/elementwise_binary_scalar_op.cu\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/elementwise_sum_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/elementwise_sum.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/elementwise_unary_op_gpu.o src/operator/elementwise_unary_op.cu >build/src/operator/elementwise_unary_op_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/elementwise_unary_op_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/elementwise_unary_op.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/embedding_gpu.o src/operator/embedding.cu >build/src/operator/embedding_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/embedding_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/embedding.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/fully_connected_gpu.o src/operator/fully_connected.cu >build/src/operator/fully_connected_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/fully_connected_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/fully_connected.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/identity_attach_KL_sparse_reg_gpu.o src/operator/identity_attach_KL_sparse_reg.cu >build/src/operator/identity_attach_KL_sparse_reg_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/identity_attach_KL_sparse_reg_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/identity_attach_KL_sparse_reg.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/instance_norm_gpu.o src/operator/instance_norm.cu >build/src/operator/instance_norm_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/instance_norm_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/instance_norm.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/l2_normalization_gpu.o src/operator/l2_normalization.cu >build/src/operator/l2_normalization_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/l2_normalization_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/l2_normalization.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/leaky_relu_gpu.o src/operator/leaky_relu.cu >build/src/operator/leaky_relu_gpu.d\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/loss_binary_op_gpu.o src/operator/loss_binary_op.cu >build/src/operator/loss_binary_op_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/leaky_relu_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/leaky_relu.cu\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/loss_binary_op_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/loss_binary_op.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/lrn_gpu.o src/operator/lrn.cu >build/src/operator/lrn_gpu.d\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/make_loss_gpu.o src/operator/make_loss.cu >build/src/operator/make_loss_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/lrn_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/lrn.cu\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/make_loss_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/make_loss.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/matrix_op_gpu.o src/operator/matrix_op.cu >build/src/operator/matrix_op_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/matrix_op_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/matrix_op.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/native_op_gpu.o src/operator/native_op.cu >build/src/operator/native_op_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/native_op_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/native_op.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/pad_gpu.o src/operator/pad.cu >build/src/operator/pad_gpu.d\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/pooling_gpu.o src/operator/pooling.cu >build/src/operator/pooling_gpu.d\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/regression_output_gpu.o src/operator/regression_output.cu >build/src/operator/regression_output_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/pad_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/pad.cu\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/pooling_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/pooling.cu\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/regression_output_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/regression_output.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/reshape_gpu.o src/operator/reshape.cu >build/src/operator/reshape_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/reshape_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/reshape.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/rnn_gpu.o src/operator/rnn.cu >build/src/operator/rnn_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/rnn_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/rnn.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/roi_pooling_gpu.o src/operator/roi_pooling.cu >build/src/operator/roi_pooling_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/roi_pooling_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/roi_pooling.cu\r\nsrc/operator/./pad-inl.h: In member function ‘virtual bool mxnet::op::PadProp::InferShape(std::vector<mxnet::TShape>*, std::vector<mxnet::TShape>*, std::vector<mxnet::TShape>*) const’:\r\nsrc/operator/./pad-inl.h:166:33: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     for (int i = 0; i < dshape.ndim(); ++i) {\r\n                                 ^\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/sample_op_gpu.o src/operator/sample_op.cu >build/src/operator/sample_op_gpu.d\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/sequence_last_gpu.o src/operator/sequence_last.cu >build/src/operator/sequence_last_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/sample_op_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/sample_op.cu\r\nsrc/operator/./reshape-inl.h: In member function ‘virtual bool mxnet::op::ReshapeProp::InferShape(std::vector<mxnet::TShape>*, std::vector<mxnet::TShape>*, std::vector<mxnet::TShape>*) const’:\r\nsrc/operator/./reshape-inl.h:257:18: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n           while (src_idx < dshape_len) {\r\n                  ^\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/sequence_last_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/sequence_last.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/sequence_mask_gpu.o src/operator/sequence_mask.cu >build/src/operator/sequence_mask_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/sequence_mask_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/sequence_mask.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/sequence_reverse_gpu.o src/operator/sequence_reverse.cu >build/src/operator/sequence_reverse_gpu.d\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/slice_channel_gpu.o src/operator/slice_channel.cu >build/src/operator/slice_channel_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/sequence_reverse_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/sequence_reverse.cu\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/slice_channel_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/slice_channel.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/smooth_l1_unary_gpu.o src/operator/smooth_l1_unary.cu >build/src/operator/smooth_l1_unary_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/smooth_l1_unary_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/smooth_l1_unary.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/softmax_activation_gpu.o src/operator/softmax_activation.cu >build/src/operator/softmax_activation_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/softmax_activation_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/softmax_activation.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/softmax_output_gpu.o src/operator/softmax_output.cu >build/src/operator/softmax_output_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/softmax_output_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/softmax_output.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/spatial_transformer_gpu.o src/operator/spatial_transformer.cu >build/src/operator/spatial_transformer_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/spatial_transformer_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/spatial_transformer.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/svm_output_gpu.o src/operator/svm_output.cu >build/src/operator/svm_output_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/svm_output_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/svm_output.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/swapaxis_gpu.o src/operator/swapaxis.cu >build/src/operator/swapaxis_gpu.d\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/operator/upsampling_gpu.o src/operator/upsampling.cu >build/src/operator/upsampling_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/swapaxis_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/swapaxis.cu\r\n/usr/local/cuda/bin/nvcc -c -o build/src/operator/upsampling_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/operator/upsampling.cu\r\n/usr/local/cuda/bin/nvcc -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" -M -MT build/src/optimizer/sgd_gpu.o src/optimizer/sgd.cu >build/src/optimizer/sgd_gpu.d\r\n/usr/local/cuda/bin/nvcc -c -o build/src/optimizer/sgd_gpu.o -std=c++11 -Xcompiler -D_FORCE_INLINES -g -O3 -ccbin g++  -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_50,code=compute_50 -Xcompiler ""-DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0"" src/optimizer/sgd.cu\r\nar crv lib/libmxnet.a build/src/initialize.o build/src/resource.o build/src/c_api/c_api.o build/src/c_api/c_api_error.o build/src/c_api/c_predict_api.o build/src/common/mxrtc.o build/src/engine/engine.o build/src/engine/naive_engine.o build/src/engine/threaded_engine.o build/src/engine/threaded_engine_perdevice.o build/src/engine/threaded_engine_pooled.o build/src/io/image_aug_default.o build/src/io/io.o build/src/io/iter_csv.o build/src/io/iter_image_recordio.o build/src/io/iter_mnist.o build/src/kvstore/kvstore.o build/src/ndarray/ndarray.o build/src/ndarray/ndarray_function.o build/src/operator/activation.o build/src/operator/batch_norm.o build/src/operator/block_grad.o build/src/operator/broadcast_mask_op.o build/src/operator/broadcast_reduce_op.o build/src/operator/cast.o build/src/operator/concat.o build/src/operator/convolution.o build/src/operator/correlation.o build/src/operator/crop.o build/src/operator/cross_device_copy.o build/src/operator/cudnn_batch_norm.o build/src/operator/cudnn_convolution.o build/src/operator/custom.o build/src/operator/deconvolution.o build/src/operator/dropout.o build/src/operator/elementwise_binary_broadcast_op.o build/src/operator/elementwise_binary_op.o build/src/operator/elementwise_binary_scalar_op.o build/src/operator/elementwise_sum.o build/src/operator/elementwise_unary_op.o build/src/operator/embedding.o build/src/operator/fully_connected.o build/src/operator/identity_attach_KL_sparse_reg.o build/src/operator/instance_norm.o build/src/operator/l2_normalization.o build/src/operator/leaky_relu.o build/src/operator/loss_binary_op.o build/src/operator/lrn.o build/src/operator/make_loss.o build/src/operator/matrix_op.o build/src/operator/native_op.o build/src/operator/ndarray_op.o build/src/operator/operator.o build/src/operator/operator_util.o build/src/operator/pad.o build/src/operator/pooling.o build/src/operator/regression_output.o build/src/operator/reshape.o build/src/operator/rnn.o build/src/operator/roi_pooling.o build/src/operator/sample_op.o build/src/operator/sequence_last.o build/src/operator/sequence_mask.o build/src/operator/sequence_reverse.o build/src/operator/slice_channel.o build/src/operator/smooth_l1_unary.o build/src/operator/softmax_activation.o build/src/operator/softmax_output.o build/src/operator/spatial_transformer.o build/src/operator/svm_output.o build/src/operator/swapaxis.o build/src/operator/upsampling.o build/src/optimizer/optimizer.o build/src/optimizer/sgd.o build/src/storage/storage.o build/src/symbol/graph_executor.o build/src/symbol/graph_memory_allocator.o build/src/symbol/static_graph.o build/src/symbol/symbol.o build/src/operator/mkl/mkl_cppwrapper.o build/src/operator/mkl/mkl_memory.o build/src/ndarray/ndarray_function_gpu.o build/src/operator/activation_gpu.o build/src/operator/batch_norm_gpu.o build/src/operator/block_grad_gpu.o build/src/operator/broadcast_mask_op_gpu.o build/src/operator/broadcast_reduce_op_gpu.o build/src/operator/cast_gpu.o build/src/operator/concat_gpu.o build/src/operator/convolution_gpu.o build/src/operator/correlation_gpu.o build/src/operator/crop_gpu.o build/src/operator/cudnn_batch_norm_gpu.o build/src/operator/deconvolution_gpu.o build/src/operator/dropout_gpu.o build/src/operator/elementwise_binary_broadcast_op_gpu.o build/src/operator/elementwise_binary_op_gpu.o build/src/operator/elementwise_binary_scalar_op_gpu.o build/src/operator/elementwise_sum_gpu.o build/src/operator/elementwise_unary_op_gpu.o build/src/operator/embedding_gpu.o build/src/operator/fully_connected_gpu.o build/src/operator/identity_attach_KL_sparse_reg_gpu.o build/src/operator/instance_norm_gpu.o build/src/operator/l2_normalization_gpu.o build/src/operator/leaky_relu_gpu.o build/src/operator/loss_binary_op_gpu.o build/src/operator/lrn_gpu.o build/src/operator/make_loss_gpu.o build/src/operator/matrix_op_gpu.o build/src/operator/native_op_gpu.o build/src/operator/pad_gpu.o build/src/operator/pooling_gpu.o build/src/operator/regression_output_gpu.o build/src/operator/reshape_gpu.o build/src/operator/rnn_gpu.o build/src/operator/roi_pooling_gpu.o build/src/operator/sample_op_gpu.o build/src/operator/sequence_last_gpu.o build/src/operator/sequence_mask_gpu.o build/src/operator/sequence_reverse_gpu.o build/src/operator/slice_channel_gpu.o build/src/operator/smooth_l1_unary_gpu.o build/src/operator/softmax_activation_gpu.o build/src/operator/softmax_output_gpu.o build/src/operator/spatial_transformer_gpu.o build/src/operator/svm_output_gpu.o build/src/operator/swapaxis_gpu.o build/src/operator/upsampling_gpu.o build/src/optimizer/sgd_gpu.o\r\ng++ -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -shared -o lib/libmxnet.so build/src/initialize.o build/src/resource.o build/src/c_api/c_api.o build/src/c_api/c_api_error.o build/src/c_api/c_predict_api.o build/src/common/mxrtc.o build/src/engine/engine.o build/src/engine/naive_engine.o build/src/engine/threaded_engine.o build/src/engine/threaded_engine_perdevice.o build/src/engine/threaded_engine_pooled.o build/src/io/image_aug_default.o build/src/io/io.o build/src/io/iter_csv.o build/src/io/iter_image_recordio.o build/src/io/iter_mnist.o build/src/kvstore/kvstore.o build/src/ndarray/ndarray.o build/src/ndarray/ndarray_function.o build/src/operator/activation.o build/src/operator/batch_norm.o build/src/operator/block_grad.o build/src/operator/broadcast_mask_op.o build/src/operator/broadcast_reduce_op.o build/src/operator/cast.o build/src/operator/concat.o build/src/operator/convolution.o build/src/operator/correlation.o build/src/operator/crop.o build/src/operator/cross_device_copy.o build/src/operator/cudnn_batch_norm.o build/src/operator/cudnn_convolution.o build/src/operator/custom.o build/src/operator/deconvolution.o build/src/operator/dropout.o build/src/operator/elementwise_binary_broadcast_op.o build/src/operator/elementwise_binary_op.o build/src/operator/elementwise_binary_scalar_op.o build/src/operator/elementwise_sum.o build/src/operator/elementwise_unary_op.o build/src/operator/embedding.o build/src/operator/fully_connected.o build/src/operator/identity_attach_KL_sparse_reg.o build/src/operator/instance_norm.o build/src/operator/l2_normalization.o build/src/operator/leaky_relu.o build/src/operator/loss_binary_op.o build/src/operator/lrn.o build/src/operator/make_loss.o build/src/operator/matrix_op.o build/src/operator/native_op.o build/src/operator/ndarray_op.o build/src/operator/operator.o build/src/operator/operator_util.o build/src/operator/pad.o build/src/operator/pooling.o build/src/operator/regression_output.o build/src/operator/reshape.o build/src/operator/rnn.o build/src/operator/roi_pooling.o build/src/operator/sample_op.o build/src/operator/sequence_last.o build/src/operator/sequence_mask.o build/src/operator/sequence_reverse.o build/src/operator/slice_channel.o build/src/operator/smooth_l1_unary.o build/src/operator/softmax_activation.o build/src/operator/softmax_output.o build/src/operator/spatial_transformer.o build/src/operator/svm_output.o build/src/operator/swapaxis.o build/src/operator/upsampling.o build/src/optimizer/optimizer.o build/src/optimizer/sgd.o build/src/storage/storage.o build/src/symbol/graph_executor.o build/src/symbol/graph_memory_allocator.o build/src/symbol/static_graph.o build/src/symbol/symbol.o build/src/operator/mkl/mkl_cppwrapper.o build/src/operator/mkl/mkl_memory.o /root/mxnet/dmlc-core/libdmlc.a build/src/ndarray/ndarray_function_gpu.o build/src/operator/activation_gpu.o build/src/operator/batch_norm_gpu.o build/src/operator/block_grad_gpu.o build/src/operator/broadcast_mask_op_gpu.o build/src/operator/broadcast_reduce_op_gpu.o build/src/operator/cast_gpu.o build/src/operator/concat_gpu.o build/src/operator/convolution_gpu.o build/src/operator/correlation_gpu.o build/src/operator/crop_gpu.o build/src/operator/cudnn_batch_norm_gpu.o build/src/operator/deconvolution_gpu.o build/src/operator/dropout_gpu.o build/src/operator/elementwise_binary_broadcast_op_gpu.o build/src/operator/elementwise_binary_op_gpu.o build/src/operator/elementwise_binary_scalar_op_gpu.o build/src/operator/elementwise_sum_gpu.o build/src/operator/elementwise_unary_op_gpu.o build/src/operator/embedding_gpu.o build/src/operator/fully_connected_gpu.o build/src/operator/identity_attach_KL_sparse_reg_gpu.o build/src/operator/instance_norm_gpu.o build/src/operator/l2_normalization_gpu.o build/src/operator/leaky_relu_gpu.o build/src/operator/loss_binary_op_gpu.o build/src/operator/lrn_gpu.o build/src/operator/make_loss_gpu.o build/src/operator/matrix_op_gpu.o build/src/operator/native_op_gpu.o build/src/operator/pad_gpu.o build/src/operator/pooling_gpu.o build/src/operator/regression_output_gpu.o build/src/operator/reshape_gpu.o build/src/operator/rnn_gpu.o build/src/operator/roi_pooling_gpu.o build/src/operator/sample_op_gpu.o build/src/operator/sequence_last_gpu.o build/src/operator/sequence_mask_gpu.o build/src/operator/sequence_reverse_gpu.o build/src/operator/slice_channel_gpu.o build/src/operator/smooth_l1_unary_gpu.o build/src/operator/softmax_activation_gpu.o build/src/operator/softmax_output_gpu.o build/src/operator/spatial_transformer_gpu.o build/src/operator/svm_output_gpu.o build/src/operator/swapaxis_gpu.o build/src/operator/upsampling_gpu.o build/src/optimizer/sgd_gpu.o -pthread -lm -lcudart -lcublas -lcurand -L/usr/local/cuda/lib64 -L/usr/local/cuda/lib -lcblas -fopenmp -lrt -L/usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/libopencv_calib3d.so -lopencv_calib3d /usr/lib/x86_64-linux-gnu/libopencv_contrib.so -lopencv_contrib /usr/lib/x86_64-linux-gnu/libopencv_core.so -lopencv_core /usr/lib/x86_64-linux-gnu/libopencv_features2d.so -lopencv_features2d /usr/lib/x86_64-linux-gnu/libopencv_flann.so -lopencv_flann /usr/lib/x86_64-linux-gnu/libopencv_gpu.so -lopencv_gpu /usr/lib/x86_64-linux-gnu/libopencv_highgui.so -lopencv_highgui /usr/lib/x86_64-linux-gnu/libopencv_imgproc.so -lopencv_imgproc /usr/lib/x86_64-linux-gnu/libopencv_legacy.so -lopencv_legacy /usr/lib/x86_64-linux-gnu/libopencv_ml.so -lopencv_ml /usr/lib/x86_64-linux-gnu/libopencv_objdetect.so -lopencv_objdetect /usr/lib/x86_64-linux-gnu/libopencv_ocl.so -lopencv_ocl /usr/lib/x86_64-linux-gnu/libopencv_photo.so -lopencv_photo /usr/lib/x86_64-linux-gnu/libopencv_stitching.so -lopencv_stitching /usr/lib/x86_64-linux-gnu/libopencv_superres.so -lopencv_superres /usr/lib/x86_64-linux-gnu/libopencv_ts.so -lopencv_ts /usr/lib/x86_64-linux-gnu/libopencv_video.so -lopencv_video /usr/lib/x86_64-linux-gnu/libopencv_videostab.so -lopencv_videostab   -lcudnn  -lcuda\r\na - build/src/initialize.o\r\na - build/src/resource.o\r\na - build/src/c_api/c_api.o\r\na - build/src/c_api/c_api_error.o\r\na - build/src/c_api/c_predict_api.o\r\na - build/src/common/mxrtc.o\r\na - build/src/engine/engine.o\r\na - build/src/engine/naive_engine.o\r\na - build/src/engine/threaded_engine.o\r\na - build/src/engine/threaded_engine_perdevice.o\r\na - build/src/engine/threaded_engine_pooled.o\r\na - build/src/io/image_aug_default.o\r\na - build/src/io/io.o\r\na - build/src/io/iter_csv.o\r\na - build/src/io/iter_image_recordio.o\r\na - build/src/io/iter_mnist.o\r\na - build/src/kvstore/kvstore.o\r\na - build/src/ndarray/ndarray.o\r\na - build/src/ndarray/ndarray_function.o\r\na - build/src/operator/activation.o\r\na - build/src/operator/batch_norm.o\r\na - build/src/operator/block_grad.o\r\na - build/src/operator/broadcast_mask_op.o\r\na - build/src/operator/broadcast_reduce_op.o\r\na - build/src/operator/cast.o\r\na - build/src/operator/concat.o\r\na - build/src/operator/convolution.o\r\na - build/src/operator/correlation.o\r\na - build/src/operator/crop.o\r\na - build/src/operator/cross_device_copy.o\r\na - build/src/operator/cudnn_batch_norm.o\r\na - build/src/operator/cudnn_convolution.o\r\na - build/src/operator/custom.o\r\na - build/src/operator/deconvolution.o\r\na - build/src/operator/dropout.o\r\na - build/src/operator/elementwise_binary_broadcast_op.o\r\na - build/src/operator/elementwise_binary_op.o\r\na - build/src/operator/elementwise_binary_scalar_op.o\r\na - build/src/operator/elementwise_sum.o\r\na - build/src/operator/elementwise_unary_op.o\r\na - build/src/operator/embedding.o\r\na - build/src/operator/fully_connected.o\r\na - build/src/operator/identity_attach_KL_sparse_reg.o\r\na - build/src/operator/instance_norm.o\r\na - build/src/operator/l2_normalization.o\r\na - build/src/operator/leaky_relu.o\r\na - build/src/operator/loss_binary_op.o\r\na - build/src/operator/lrn.o\r\na - build/src/operator/make_loss.o\r\na - build/src/operator/matrix_op.o\r\na - build/src/operator/native_op.o\r\na - build/src/operator/ndarray_op.o\r\na - build/src/operator/operator.o\r\na - build/src/operator/operator_util.o\r\na - build/src/operator/pad.o\r\na - build/src/operator/pooling.o\r\na - build/src/operator/regression_output.o\r\na - build/src/operator/reshape.o\r\na - build/src/operator/rnn.o\r\na - build/src/operator/roi_pooling.o\r\na - build/src/operator/sample_op.o\r\na - build/src/operator/sequence_last.o\r\na - build/src/operator/sequence_mask.o\r\na - build/src/operator/sequence_reverse.o\r\na - build/src/operator/slice_channel.o\r\na - build/src/operator/smooth_l1_unary.o\r\na - build/src/operator/softmax_activation.o\r\na - build/src/operator/softmax_output.o\r\na - build/src/operator/spatial_transformer.o\r\na - build/src/operator/svm_output.o\r\na - build/src/operator/swapaxis.o\r\na - build/src/operator/upsampling.o\r\na - build/src/optimizer/optimizer.o\r\na - build/src/optimizer/sgd.o\r\na - build/src/storage/storage.o\r\na - build/src/symbol/graph_executor.o\r\na - build/src/symbol/graph_memory_allocator.o\r\na - build/src/symbol/static_graph.o\r\na - build/src/symbol/symbol.o\r\na - build/src/operator/mkl/mkl_cppwrapper.o\r\na - build/src/operator/mkl/mkl_memory.o\r\na - build/src/ndarray/ndarray_function_gpu.o\r\na - build/src/operator/activation_gpu.o\r\na - build/src/operator/batch_norm_gpu.o\r\na - build/src/operator/block_grad_gpu.o\r\na - build/src/operator/broadcast_mask_op_gpu.o\r\na - build/src/operator/broadcast_reduce_op_gpu.o\r\na - build/src/operator/cast_gpu.o\r\na - build/src/operator/concat_gpu.o\r\na - build/src/operator/convolution_gpu.o\r\na - build/src/operator/correlation_gpu.o\r\na - build/src/operator/crop_gpu.o\r\na - build/src/operator/cudnn_batch_norm_gpu.o\r\na - build/src/operator/deconvolution_gpu.o\r\na - build/src/operator/dropout_gpu.o\r\na - build/src/operator/elementwise_binary_broadcast_op_gpu.o\r\na - build/src/operator/elementwise_binary_op_gpu.o\r\na - build/src/operator/elementwise_binary_scalar_op_gpu.o\r\na - build/src/operator/elementwise_sum_gpu.o\r\na - build/src/operator/elementwise_unary_op_gpu.o\r\na - build/src/operator/embedding_gpu.o\r\na - build/src/operator/fully_connected_gpu.o\r\na - build/src/operator/identity_attach_KL_sparse_reg_gpu.o\r\na - build/src/operator/instance_norm_gpu.o\r\na - build/src/operator/l2_normalization_gpu.o\r\na - build/g++ -DMSHADOW_FORCE_STREAM -Wall -O3 -I/root/mxnet/mshadow/ -I/root/mxnet/dmlc-core/include -fPIC -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -I/usr/local/cuda/include -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSDHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv   -fopenmp -DMSHADOW_USE_CUDNN=1  -DMXNET_USE_NVRTC=0 -std=c++11  -o bin/im2rec tools/im2rec.cc build/src/initialize.o build/src/resource.o build/src/c_api/c_api.o build/src/c_api/c_api_error.o build/src/c_api/c_predict_api.o build/src/common/mxrtc.o build/src/engine/engine.o build/src/engine/naive_engine.o build/src/engine/threaded_engine.o build/src/engine/threaded_engine_perdevice.o build/src/engine/threaded_engine_pooled.o build/src/io/image_aug_default.o build/src/io/io.o build/src/io/iter_csv.o build/src/io/iter_image_recordio.o build/src/io/iter_mnist.o build/src/kvstore/kvstore.o build/src/ndarray/ndarray.o build/src/ndarray/ndarray_function.o build/src/operator/activation.o build/src/operator/batch_norm.o build/src/operator/block_grad.o build/src/operator/broadcast_mask_op.o build/src/operator/broadcast_reduce_op.o build/src/operator/cast.o build/src/operator/concat.o build/src/operator/convolution.o build/src/operator/correlation.o build/src/operator/crop.o build/src/operator/cross_device_copy.o build/src/operator/cudnn_batch_norm.o build/src/operator/cudnn_convolution.o build/src/operator/custom.o build/src/operator/deconvolution.o build/src/operator/dropout.o build/src/operator/elementwise_binary_broadcast_op.o build/src/operator/elementwise_binary_op.o build/src/operator/elementwise_binary_scalar_op.o build/src/operator/elementwise_sum.o build/src/operator/elementwise_unary_op.o build/src/operator/embedding.o build/src/operator/fully_connected.o build/src/operator/identity_attach_KL_sparse_reg.o build/src/operator/instance_norm.o build/src/operator/l2_normalization.o build/src/operator/leaky_relu.o build/src/operator/loss_binary_op.o build/src/operator/lrn.o build/src/operator/make_loss.o build/src/operator/matrix_op.o build/src/operator/native_op.o build/src/operator/ndarray_op.o build/src/operator/operator.o build/src/operator/operator_util.o build/src/operator/pad.o build/src/operator/pooling.o build/src/operator/regression_output.o build/src/operator/reshape.o build/src/operator/rnn.o build/src/operator/roi_pooling.o build/src/operator/sample_op.o build/src/operator/sequence_last.o build/src/operator/sequence_mask.o build/src/operator/sequence_reverse.o build/src/operator/slice_channel.o build/src/operator/smooth_l1_unary.o build/src/operator/softmax_activation.o build/src/operator/softmax_output.o build/src/operator/spatial_transformer.o build/src/operator/svm_output.o build/src/operator/swapaxis.o build/src/operator/upsampling.o build/src/optimizer/optimizer.o build/src/optimizer/sgd.o build/src/storage/storage.o build/src/symbol/graph_executor.o build/src/symbol/graph_memory_allocator.o build/src/symbol/static_graph.o build/src/symbol/symbol.o build/src/operator/mkl/mkl_cppwrapper.o build/src/operator/mkl/mkl_memory.o /root/mxnet/dmlc-core/libdmlc.a build/src/ndarray/ndarray_function_gpu.o build/src/operator/activation_gpu.o build/src/operator/batch_norm_gpu.o build/src/operator/block_grad_gpu.o build/src/operator/broadcast_mask_op_gpu.o build/src/operator/broadcast_reduce_op_gpu.o build/src/operator/cast_gpu.o build/src/operator/concat_gpu.o build/src/operator/convolution_gpu.o build/src/operator/correlation_gpu.o build/src/operator/crop_gpu.o build/src/operator/cudnn_batch_norm_gpu.o build/src/operator/deconvolution_gpu.o build/src/operator/dropout_gpu.o build/src/operator/elementwise_binary_broadcast_op_gpu.o build/src/operator/elementwise_binary_op_gpu.o build/src/operator/elementwise_binary_scalar_op_gpu.o build/src/operator/elementwise_sum_gpu.o build/src/operator/elementwise_unary_op_gpu.o build/src/operator/embedding_gpu.o build/src/operator/fully_connected_gpu.o build/src/operator/identity_attach_KL_sparse_reg_gpu.o build/src/operator/instance_norm_gpu.o build/src/operator/l2_normalization_gpu.o build/src/operator/leaky_relu_gpu.o build/src/operator/loss_binary_op_gpu.o build/src/operator/lrn_gpu.o build/src/operator/make_loss_gpu.o build/src/operator/matrix_op_gpu.o build/src/operator/native_op_gpu.o build/src/operator/pad_gpu.o build/src/operator/pooling_gpu.o build/src/operator/regression_output_gpu.o build/src/operator/reshape_gpu.o build/src/operator/rnn_gpu.o build/src/operator/roi_pooling_gpu.o build/src/operator/sample_op_gpu.o build/src/operator/sequence_last_gpu.o build/src/operator/sequence_mask_gpu.o build/src/operator/sequence_reverse_gpu.o build/src/operator/slice_channel_gpu.o build/src/operator/smooth_l1_unary_gpu.o build/src/operator/softmax_activation_gpu.o build/src/operator/softmax_output_gpu.o build/src/operator/spatial_transformer_gpu.o build/src/operator/svm_output_gpu.o build/src/operator/swapaxis_gpu.o build/src/operator/upsampling_gpu.o build/src/optimizer/sgd_gpu.o -pthread -lm -lcudart -lcublas -lcurand -L/usr/local/cuda/lib64 -L/usr/local/cuda/lib -lcblas -fopenmp -lrt -L/usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/libopencv_calib3d.so -lopencv_calib3d /usr/lib/x86_64-linux-gnu/libopencv_contrib.so -lopencv_contrib /usr/lib/x86_64-linux-gnu/libopencv_core.so -lopencv_core /usr/lib/x86_64-linux-gnu/libopencv_features2d.so -lopencv_features2d /usr/lib/x86_64-linux-gnu/libopencv_flann.so -lopencv_flann /usr/lib/x86_64-linux-gnu/libopencv_gpu.so -lopencv_gpu /usr/lib/x86_64-linux-gnu/libopencv_highgui.so -lopencv_highgui /usr/lib/x86_64-linux-gnu/libopencv_imgproc.so -lopencv_imgproc /usr/lib/x86_64-linux-gnu/libopencv_legacy.so -lopencv_legacy /usr/lib/x86_64-linux-gnu/libopencv_ml.so -lopencv_ml /usr/lib/x86_64-linux-gnu/libopencv_objdetect.so -lopencv_objdetect /usr/lib/x86_64-linux-gnu/libopencv_ocl.so -lopencv_ocl /usr/lib/x86_64-linux-gnu/libopencv_photo.so -lopencv_photo /usr/lib/x86_64-linux-gnu/libopencv_stitching.so -lopencv_stitching /usr/lib/x86_64-linux-gnu/libopencv_superres.so -lopencv_superres /usr/lib/x86_64-linux-gnu/libopencv_ts.so -lopencv_ts /usr/lib/x86_64-linux-gnu/libopencv_video.so -lopencv_video /usr/lib/x86_64-linux-gnu/libopencv_videostab.so -lopencv_videostab   -lcudnn  -lcuda\r\nsrc/operator/leaky_relu_gpu.o\r\na - build/src/operator/loss_binary_op_gpu.o\r\na - build/src/operator/lrn_gpu.o\r\na - build/src/operator/make_loss_gpu.o\r\na - build/src/operator/matrix_op_gpu.o\r\na - build/src/operator/native_op_gpu.o\r\na - build/src/operator/pad_gpu.o\r\na - build/src/operator/pooling_gpu.o\r\na - build/src/operator/regression_output_gpu.o\r\na - build/src/operator/reshape_gpu.o\r\na - build/src/operator/rnn_gpu.o\r\na - build/src/operator/roi_pooling_gpu.o\r\na - build/src/operator/sample_op_gpu.o\r\na - build/src/operator/sequence_last_gpu.o\r\na - build/src/operator/sequence_mask_gpu.o\r\na - build/src/operator/sequence_reverse_gpu.o\r\na - build/src/operator/slice_channel_gpu.o\r\na - build/src/operator/smooth_l1_unary_gpu.o\r\na - build/src/operator/softmax_activation_gpu.o\r\na - build/src/operator/softmax_output_gpu.o\r\na - build/src/operator/spatial_transformer_gpu.o\r\na - build/src/operator/svm_output_gpu.o\r\na - build/src/operator/swapaxis_gpu.o\r\na - build/src/operator/upsampling_gpu.o\r\na - build/src/optimizer/sgd_gpu.o\r\nbuild/src/symbol/graph_memory_allocator.o: In function ', ""mxnet::GraphStorageAllocator::kBadStorageID'\r\ncollect2: error: ld returned 1 exit status\r\nmake: *** [bin/im2rec] Error 1\r\n\r\ngit clone https://github.com/dmlc/mxnet.git ~/mxnet --recursive && \\\r\ncd ~/mxnet && \\\r\ngit checkout tags/v0.8.0 && \\\r\nmv make/config.mk . && \\\r\nsed -i '41s/.*/USE_CUDA = 1/' config.mk && \\\r\nsed -i '46s/.*/USE_CUDA_PATH = \\/usr\\/local\\/cuda/' config.mk && \\\r\nsed -i '49s/.*/USE_CUDNN = 1/' config.mk && \\\r\nd setup-utils && \\\r\nsed -i '26s/.*/cd python; sudo \\/opt\\/anaconda2\\/bin\\/python2.7 setup.py install; \\/opt\\/anaconda3\\/bin\\/python3.5 setup.py install;/' install-mxnet-ubuntu-python.sh && \\\r\nbash install-mxnet-ubuntu-python.sh && \\\r\n. ~/.bashrc\r\n"", '']",0,0
367,incubator-mxnet,13923,closed,Cannot install MXNet R (cannot open URL),"Hi, recently i tried installing MXNet with RStudio on Windows 7. After the command:

I got error:


After:

I got:


And finally, after (found somewhere here when seaching for fix):

It installed but when trying to load library:


I know that Windows 7 is not fully supported but I hope it's not that case.
So the file on server is missing or something? 
I would be very grateful if someone could help me
Thanks


Session info:
R version 3.5.1 (2018-07-02)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=Polish_Poland.1250  LC_CTYPE=Polish_Poland.1250    LC_MONETARY=Polish_Poland.1250
[4] LC_NUMERIC=C                   LC_TIME=Polish_Poland.1250    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] arules_1.6-2  Matrix_1.2-14

loaded via a namespace (and not attached):
 [1] coin_1.2-2        lattice_0.20-38   codetools_0.2-16  mvtnorm_1.0-8     zoo_1.8-4        
 [6] MASS_7.3-51.1     grid_3.5.1        stats4_3.5.1      multcomp_1.4-8    strucchange_1.5-1
[11] party_1.3-1       sandwich_2.5-0    splines_3.5.1     TH.data_1.0-9     tools_3.5.1      
[16] survival_2.43-3   compiler_3.5.1    modeltools_0.2-22",R,"['@Kurokokoro Thanks for raising the issue. Let me ask the in-house R Gurus to try to resolve this for you.\r\n@anirudhacharya @jeremiedb @ankkhedia @hetong007  Can you guys have a look at this ? \r\n\r\n@mxnet-label-bot Add [R] ', '@Kurokokoro Do you have  OpenBlas already installed in your system?\r\n\r\nI am not sure if it is a Windows 7 issue but the installation works fine for Windows10. Alternatively you can try building from source using the instructions mentioned in http://mxnet.incubator.apache.org/install/windows_setup.html#install-mxnet-package-for-r\r\n', 'If still having issue, you may try this version compatible with R >= 3.5.0: \r\n`install.packages(""https://s3.ca-central-1.amazonaws.com/jeremiedb/share/mxnet/CPU/mxnet.zip"", repos = NULL)`\r\n\r\nI\'d guess the issue encountered was related to the installation for R <= 3.4 rather than Windows 7. Let me know otherwise. ', '> @Kurokokoro Do you have OpenBlas already installed in your  system?\r\n\r\nI tried but installation had an error, I have precompiled binaries but no idea on how to implement it with RStudio. \r\nIn Windows 10 Mxnet worked in RStudio without installing OpenBlas as I remember\r\n\r\n> If still having issue, you may try this version compatible with R >= 3.5.0:\r\ninstall.packages(""https://s3.ca-central-1.amazonaws.com/jeremiedb/share/mxnet/CPU/mxnet.zip"", repos = NULL)\r\n\r\nStill gives error:\r\n`trying URL \'https://s3.ca-central-1.amazonaws.com/jeremiedb/share/mxnet/CPU/mxnet.zip\'\r\nWarning in install.packages :\r\n  cannot open URL \'https://s3.ca-central-1.amazonaws.com/jeremiedb/share/mxnet/CPU/mxnet.zip\': HTTP status was \'403 Forbidden\'\r\nError in download.file(p, destfile, method, mode = ""wb"", ...) : \r\n  cannot open URL \'https://s3.ca-central-1.amazonaws.com/jeremiedb/share/mxnet/CPU/mxnet.zip\'`\r\n\r\nThanks for your help so far :D\r\n', '@Kurokokoro Could you give another shot, I think I had failed to change the status to public. ', ""It downloads:\r\n`trying URL 'https://s3.ca-central-1.amazonaws.com/jeremiedb/share/mxnet/CPU/mxnet.zip'\r\nContent type 'application/zip' length 30382408 bytes (29.0 MB)\r\ndownloaded 29.0 MB`\r\n\r\nBut unfortunately gives the same error when trying to load library:\r\n`Error: package ‘mxnet’ is not installed for 'arch = i386'`"", ""Oh I missed the 32 bits part. 32 bits isn't supported. Can't you use R 64 bits on Windows 7? "", 'I missed that as well, I switched to 64 bit version and it works now.\r\nThank you very much :)', '@Kurokokoro Great to know its working for you. Should we close this issue in that case?', 'Yes please, thanks for help again', '> If still having issue, you may try this version compatible with R >= 3.5.0:\r\n> `install.packages(""https://s3.ca-central-1.amazonaws.com/jeremiedb/share/mxnet/CPU/mxnet.zip"", repos = NULL)`\r\n> \r\n> I\'d guess the issue encountered was related to the installation for R <= 3.4 rather than Windows 7. Let me know otherwise.\r\n\r\njeremiedb \r\n\r\n> If still having issue, you may try this version compatible with R >= 3.5.0:\r\n> `install.packages(""https://s3.ca-central-1.amazonaws.com/jeremiedb/share/mxnet/CPU/mxnet.zip"", repos = NULL)`\r\n> \r\n> I\'d guess the issue encountered was related to the installation for R <= 3.4 rather than Windows 7. Let me know otherwise.\r\n\r\n@jeremiedb - thanks for maintaining the MxNet Repository for R Statistics. This, for me, has been the only function for the MxNet malady on R Stats. Thanks mate!']",[],"['install.packages(""mxnet"")', 'Warning in install.packages :\r\n  package ‘mxnet’ is not available (for R version 3.5.1)', 'cran <- getOption(""repos"")\r\ncran[""dmlc""] <- ""https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/""\r\noptions(repos = cran)\r\ninstall.packages(""mxnet"")', 'trying URL \'https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/src/contrib/mxnet_1.3.0.tar.gz\'\r\nWarning in install.packages :\r\n  cannot open URL \'https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/src/contrib/mxnet_1.3.0.tar.gz\': HTTP status was \'404 Not Found\'\r\nError in download.file(url, destfile, method, mode = ""wb"", ...) : \r\n  cannot open URL \'https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/src/contrib/mxnet_1.3.0.tar.gz\'\r\nWarning in install.packages :\r\n  download of package ‘mxnet’ failed', 'install.packages(""https://github.com/jeremiedb/mxnet_winbin/raw/master/mxnet.zip"", repos = NULL)', ""Error: pakiet ‘mxnet’ nie jest zainstalowany dla 'arch=i386'""]",0,0
368,incubator-mxnet,2783,closed,missing script in example bi-lstm-sort,"The [example on bidirectional LSTM](https://github.com/dmlc/mxnet/tree/master/example/bi-lstm-sort) misses the gen_data.py script that is referenced in the ReadMe
Maybe it did not get committed due to gitignore rules? 
@xlvector do you still have the script lying around?
",,"['I have the same problem,waiting for solution.\n', 'I have asked xlvector before, here is the code:\n\nimport random\n\nvocab = [str(x) for x in range(100, 1000)]\n\nsw_train = open(""sort.train.txt"", ""w"")\nsw_test = open(""sort.test.txt"", ""w"")\nsw_valid = open(""sort.valid.txt"", ""w"")\n\nfor i in range(1000000):\n    seq = "" "".join([vocab[random.randint(0, len(vocab) - 1)] for j in range(5)])\n    k = i % 50\n    if k == 0:\n        sw_test.write(seq + ""\\n"")\n    elif k == 1:\n        sw_valid.write(seq + ""\\n"")\n    else:\n        sw_train.write(seq + ""\\n"")\n\nsw_train.close()\nsw_test.close()\nsw_valid.close() \n', 'Thanks!\n', '@Ldpe2G \nTHX\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
369,incubator-mxnet,10387,closed,Flaky test(scala): test_arange,"

Please see: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-10374/1/pipeline/",Flaky Scala Test,"['See https://github.com/apache/incubator-mxnet/issues/8383 for reference', 'Happened to me too:\r\nhttp://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-10495/1/pipeline/597', 'Bumping, happened again\r\nhttp://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-10608/9/pipeline', ""Any more reports? I cannot reproduce the 'Flaky', tried to run 100 times on a single Ubuntu machine and all passed."", 'Not scala, but still: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/1053/pipeline/', '@marcoabreu Have we observed more occurrence of this?', 'Plus, seems like a duplicate issue for #8834', ""I don't know. Let's come back when we see it again.\r\n\r\nDuplicate of https://github.com/apache/incubator-mxnet/issues/8834"", 'Seems to happen again on my PR: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-14359/7/pipeline. @marcoabreu @lanking520 ', 'This is something different, with strange value came from the op']","['\r\n*** 1 TEST FAILED ***\r\n\r\n[INFO] ------------------------------------------------------------------------\r\n\r\n[INFO] Reactor Summary:\r\n\r\n[INFO] \r\n\r\n[INFO] MXNet Scala Package - Parent ....................... SUCCESS [  2.834 s]\r\n\r\n[INFO] MXNet Scala Package - Initializer .................. SUCCESS [  0.947 s]\r\n\r\n[INFO] MXNet Scala Package - Initializer Native Parent .... SUCCESS [  0.497 s]\r\n\r\n[INFO] MXNet Scala Package - Initializer Native Linux-x86_64 SUCCESS [ 11.852 s]\r\n\r\n[INFO] MXNet Scala Package - Macros ....................... SUCCESS [  0.728 s]\r\n\r\n[INFO] MXNet Scala Package - Core ......................... FAILURE [ 48.518 s]\r\n\r\n[INFO] MXNet Scala Package - Native Parent ................ SKIPPED\r\n\r\n[INFO] MXNet Scala Package - Native Linux-x86_64 CPU-only . SKIPPED\r\n\r\n[INFO] MXNet Scala Package - Inference .................... SKIPPED\r\n\r\n[INFO] MXNet Scala Package - Examples ..................... SKIPPED\r\n\r\n[INFO] MXNet Scala Package - Spark ML ..................... SKIPPED\r\n\r\n[INFO] MXNet Scala Package - Full Parent .................. SKIPPED\r\n\r\n[INFO] MXNet Scala Package - Full Linux-x86_64 CPU-only ... SKIPPED\r\n\r\n[INFO] ------------------------------------------------------------------------\r\n\r\n[INFO] BUILD FAILURE\r\n\r\n[INFO] ------------------------------------------------------------------------\r\n\r\n[INFO] Total time: 01:05 min\r\n\r\n[INFO] Finished at: 2018-04-02T22:07:11+00:00\r\n\r\n[INFO] Final Memory: 54M/2143M\r\n\r\n[INFO] ------------------------------------------------------------------------\r\n\r\n[ERROR] Failed to execute goal org.scalatest:scalatest-maven-plugin:1.0:test (test) on project mxnet-core_2.11: There are test failures -> [Help 1]\r\n\r\n[ERROR] \r\n\r\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\r\n\r\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\r\n\r\n[ERROR] \r\n\r\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\r\n\r\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\r\n\r\n[ERROR] \r\n\r\n[ERROR] After correcting the problems, you can resume the build with the command\r\n\r\n[ERROR]   mvn <goals> -rf :mxnet-core_2.11\r\n\r\nMakefile:543: recipe for target \'scalatest\' failed\r\n\r\nmake: *** [scalatest] Error 1\r\n\r\nbuild.py: 2018-04-02 22:07:12,537 Running of command in container failed: docker run --rm -v /home/jenkins_slave/workspace/ut-scala-cpu:/work/mxnet -v /home/jenkins_slave/workspace/ut-scala-cpu/build:/work/build -u 1001:1001 mxnet/build.ubuntu_cpu /work/runtime_functions.sh unittest_ubuntu_cpu_scala\r\n\r\nbuild.py: 2018-04-02 22:07:12,537 You can try to get into the container by using the following command: docker run --rm -v /home/jenkins_slave/workspace/ut-scala-cpu:/work/mxnet -v /home/jenkins_slave/workspace/ut-scala-cpu/build:/work/build -u 1001:1001 -ti --entrypoint bash mxnet/build.ubuntu_cpu /work/runtime_functions.sh unittest_ubuntu_cpu_scala\r\n\r\nTraceback (most recent call last):\r\n\r\n  File ""ci/build.py"", line 179, in <module>\r\n\r\n    sys.exit(main())\r\n\r\n  File ""ci/build.py"", line 159, in main\r\n\r\n    container_run(platform, docker_binary, command)\r\n\r\n  File ""ci/build.py"", line 110, in container_run\r\n\r\n    raise subprocess.CalledProcessError(ret, cmd)\r\n\r\nsubprocess.CalledProcessError: Command \'docker run --rm -v /home/jenkins_slave/workspace/ut-scala-cpu:/work/mxnet -v /home/jenkins_slave/workspace/ut-scala-cpu/build:/work/build -u 1001:1001 mxnet/build.ubuntu_cpu /work/runtime_functions.sh unittest_ubuntu_cpu_scala\' returned non-zero exit status 2\r\n\r\nscript returned exit code 1\r\n']",[],0,0
370,incubator-mxnet,384,closed,Question about load_checkpoint/save_checkpoint,"I am using mx.model.load_checkpoint and save_checkpoint to store/restore my model. It seems like the gpu/cpu information will also be stored in the .params file. 
When I try to load it (probably on other machine or gpu), I basically create a mx.ndarray and then use ""copyto"" to pass the value I just loaded. So:
1. How can I load it by assigning them a device number? I cannot load it if I had trained it on gpu=3 and try to load it on a machine that has only one gpu (gpu = 0). 
2. How can delete the old value? So I won't touch the gpu that I am not planning to use. 
3. Sometime when I reload the model and try to use .asnumpy() to print out the results, it will cause segmentation fault on some servers (and some does not have this problem). Error message:

Program received signal SIGSEGV, Segmentation fault.
0x00000036ee8897cb in memcpy () from /lib64/libc.so.6

I can still print out .context and .shape, but asnumpy doesn't work. Thanks!!
",,"['The checkpoint ndarrays are all on CPU, so you should be able to load them back.\nI am not aware of the problem your mentioned in asnumpy, it would be nice if you can help provide more information. For example, Is the error reproducible? , what is the size of memory copy when the memcpy happend etc.\n\nYou can make local modification to the project, either reinstall the python, or simply add path to mxnet/python to python path so the recompiled project directly take effect\n\nThanks! \n', ""Model parameter is about 500Mb, gpu is tesla k40 with 11519MiB. os is CentOS\nRegarding the first question: does it mean I need to copy my parameter to cpu ndarrays before storing them? \n\nFor the ndarray crash problem, I have tried to rebuild the code (with gcc 4.8.5 and gcc 4.9 for the previous version) and run it again, but it still produce the same result. But I Don't have this problem on a Ubuntu 4.8.2 machine.\n"", ""If the parameters are returned by fit, they are already in CPU, so you don't have to copy them. If you are training using low level interface, then probably you need to do the copy\n"", '@htung0101 do you have any updates on this? If you can give us more information with the updated version of the mxnet, for example, use gdb to print the stack trace, maybe we could help figure out what is going on the failure case.\n']",[],[],0,0
371,incubator-mxnet,4661,closed,Segmentation fault:11  with Python 2.7.11 OSX,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
   OS X 10.11.6

Compiler:
    Default Compile Turtoris

Package used (Python/R/Scala/Julia):
      Python
MXNet version   installed from source:
      0.9.1
MXNet commit hash ():
      5656c8601265a437c1cb7ea18a6f1661f346c8b5

Python version and distribution:
       2.7.11

## Error Message:
Please paste the full error message, including stack trace.



## Minimum reproducible example
  No just run the example in the source code

## Steps to reproduce
1. Install mxnet with setup in the official document: http://mxnet.io/get_started/osx_setup.html#install-mxnet-for-python

2. Download image_segementation pre trained model from baidu.yun

      FCN8S_VGG16_0019

3. Run example image_segmentation.py

    Segementation fault: 11
",Operator,"['I get this error: `[23:57:33] src/nnvm/legacy_json_util.cc:153: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\r\n[23:57:51] /Users/junyuanx/work/local/mxnet/dmlc-core/include/dmlc/./logging.h:300: [23:57:51] src/operator/./crop-inl.h:117: Check failed: param_.offset[0] <= data_shape[2]-out_shape[2] (34 vs. 33) offset[0] should be less than the residual space of height`\r\n\r\nseems to be the padding shape issue.\r\n@tornadomeet could you update it?', '@howard0su ', 'Thanks, Where Can I download compiled 0.8.0 mxnet, and have test on this pre-trained model?', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!', ""Same error here.\r\n\r\n----------\r\nI fixed it by change the crop offset of the last crop layer from 34 to 31 (according to the author's caffe github). I am now a little confused with the crop offset."", '@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', 'Issue not reproducible with MXNet 1.3.1, Python 2.7 and Python 3.6.\r\nVerified on DL AMI with Ubuntu.\r\n\r\n@shadowinlife Can this issue be closed?\r\n\r\ncc @sandeep-krishnamurthy ', '@vandanavk The original issue started with ""Operating System: OS X 10.11.6"". But you are testing on ubuntu. ', 'Update: Tested on MacOS 10.12.6, MXNet 1.3.1, Python 2.7.15 too. Segmentation fault not observed. \r\n\r\nExecuted `python2 image_segmentaion.py --input VOC2012/JPEGImages/2007_000027.jpg`\r\n\r\n@zhreshold thanks :) updated ', '@sandeep-krishnamurthy Requesting this issue to be closed as the Segmentation Fault is no longer observed. \r\n\r\n@shadowinlife Please feel free to reopen if closed in error.\r\nThanks! ']","['\r\nSystem Integrity Protection: enabled\r\n\r\nCrashed Thread:        8\r\n\r\nException Type:        EXC_BAD_ACCESS (SIGSEGV)\r\nException Codes:       KERN_INVALID_ADDRESS at 0x000000047d746000\r\n\r\nVM Regions Near 0x47d746000:\r\n    VM_ALLOCATE            000000047b746000-000000047d746000 [ 32.0M] rw-/rwx SM=PRV  \r\n--> VM_ALLOCATE            000000047d746000-000000047d747000 [    4K] rw-/rwx SM=ALI  \r\n    STACK GUARD            0000700000000000-0000700000001000 [    4K] ---/rwx SM=NUL  stack guard for thread 1\r\n\r\nThread 0:: Dispatch queue: com.apple.main-thread\r\n0   libsystem_kernel.dylib        \t0x00007fff8edf9db6 __psynch_cvwait + 10\r\n1   libsystem_pthread.dylib       \t0x00007fff8f04b728 _pthread_cond_wait + 767\r\n2   libc++.1.dylib                \t0x00007fff951af68f std::__1::condition_variable::wait(std::__1::unique_lock<std::__1::mutex>&) + 47\r\n3   libmxnet.so                   \t0x0000000110e6a7d3 mxnet::engine::ThreadedEngine::WaitForVar(mxnet::engine::Var*) + 563\r\n4   libmxnet.so                   \t0x0000000110ed86e7 mxnet::NDArray::SyncCopyToCPU(void*, unsigned long) const + 1111\r\n5   libmxnet.so                   \t0x0000000110e3769d MXNDArraySyncCopyToCPU + 13\r\n6   _ctypes.so                    \t0x00000001100bf7f7 ffi_call_unix64 + 79\r\n7   _ctypes.so                    \t0x00000001100c0030 ffi_call + 840\r\n8   _ctypes.so                    \t0x00000001100bb62a _ctypes_callproc + 591\r\n9   _ctypes.so                    \t0x00000001100b5cad PyCFuncPtr_call + 1054\r\n10  org.python.python             \t0x000000010f91c9b4 PyObject_Call + 99\r\n11  org.python.python             \t0x000000010f99be30 PyEval_EvalFrameEx + 26668\r\n12  org.python.python             \t0x000000010f99540e PyEval_EvalCodeEx + 1617\r\n13  org.python.python             \t0x000000010f99fc9e fast_function + 117\r\n14  org.python.python             \t0x000000010f99bf09 PyEval_EvalFrameEx + 26885\r\n15  org.python.python             \t0x000000010f99fd31 fast_function + 264\r\n16  org.python.python             \t0x000000010f99bf09 PyEval_EvalFrameEx + 26885\r\n17  org.python.python             \t0x000000010f99540e PyEval_EvalCodeEx + 1617\r\n18  org.python.python             \t0x000000010f994db7 PyEval_EvalCode + 48\r\n19  org.python.python             \t0x000000010f9b883c run_mod + 53\r\n20  org.python.python             \t0x000000010f9b88df PyRun_FileExFlags + 133\r\n21  org.python.python             \t0x000000010f9b8430 PyRun_SimpleFileExFlags + 702\r\n22  org.python.python             \t0x000000010f9c9d9e Py_Main + 3094\r\n23  libdyld.dylib                 \t0x00007fff932965ad start + 1\r\n']",['git rev-parse HEAD'],0,0
372,incubator-mxnet,14389,closed,Broken pip package mxnet-cu80 1.5.0b20190310,"The nightly build package for windows uploaded to pypi by the build bot on March 10 seems broken. The file https://files.pythonhosted.org/packages/9a/bc/ee216a4dbe1433d881906513768cf61f9d52c1f8dee133f69f99e1ee9ec7/mxnet_cu80-1.5.0b20190310-py2.py3-none-win_amd64.whl shows a size of 0 bytes on download when it should have 259MB size. The MD5 and SHA-256 checksums are also different.

This is causing issues in our pypi mirror sync as mxnet-cu80 can never complete sync due to broken files. Please fix this if possible.",Windows pip,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Installation', '@marcoabreu Are you aware of any issues with the nightly publishing pipeline ? \r\n\r\n@mxnet-label-bot Add [Windows, Pip]', 'It seems to be a PyPI issue because the file is correctly accessible from my home network. Apologies for this.']",[],[],0,0
373,incubator-mxnet,4945,closed,Upload the usable Android library libmxnet_predict.so please!!!,"Is there anyone have an usable android library which mxnet vision is after v0.8.0?
I have tried compile the  amalgamation many times, but it broken when using in Android app. ",,"['@xlvector ', 'You can send me an email xlvector#gmail.com, and I can send one to you.', '@xlvector, do you receive my e-mail? My e-mail address is 980078316@qq.com ', '@nihilityworld  sent!', 'could you submit it to dmlc/webdata and post the link here?\n\nXiang Liang <notifications@github.com>于2017年2月13日 周一上午1:11写道：\n\n> @nihilityworld <https://github.com/nihilityworld> sent!\n>\n> —\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/dmlc/mxnet/issues/4945#issuecomment-279330924>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AAiudJP8aMJmyc1pqADvVgPlIfX4BMLPks5rcB5IgaJpZM4L6p3->\n> .\n>\n', 'OK, I will do it this weekend.']",[],[],0,0
374,incubator-mxnet,467,closed,Raising num_args bound ?,"When I try to compile LSTM with quite a long time steps (200), following error occurs,



It seems that for whatever reason, 100 is a hard limit on the number of args that can be compiled ? I wonder whether we can change this bound (if we have more memory)

Thanks !
",,"['Please submit a PR for this, this was due to some choices in the parameters side. You should be able to locate the num_args in the operators you performed. Instead of  using `DECLARE_PARAMETER(num_args).set_range(1,100)` change it to `DECLARE_PARAMETER(num_args).set_lower_bound(1)`\n', 'cc @antinucleon \n', 'Thx ! Given that we can set this using that command, what you suggest the PR is for ?\n', 'Oh, this is the code on C++ side, not python. for example https://github.com/dmlc/mxnet/blob/master/src/operator/concat-inl.h#L31 \n', 'This being said, I do not know in which specific operator this num_args constraint sits, so will need a bit of your help in catching it:)\n', 'Can we treat it as a global environment variable ?\n', 'The idea is by default we should have no limit in num_args. The previous settings are quite arbitrary and should be corrected\n', 'seems that the only place where this hard limit is placed is \n\n```\nstruct ElementWiseSumParam : public dmlc::Parameter<ElementWiseSumParam> {\n30    int num_args;\n31    DMLC_DECLARE_PARAMETER(ElementWiseSumParam) {\n32      DMLC_DECLARE_FIELD(num_args).set_range(1, 100)\n```\n\nin src/operator/elementwise_sum-inl.h \n\nIt seems suffices to just remove that constraint there\n', 'Yes, pls go ahead to do so\nOn Mon, Nov 2, 2015 at 12:32 PM Kublai-Jing notifications@github.com\nwrote:\n\n> seems that the only place where this hard limit is placed is\n> \n> struct ElementWiseSumParam : public dmlc::Parameter<ElementWiseSumParam> {\n> 30    int num_args;\n> 31    DMLC_DECLARE_PARAMETER(ElementWiseSumParam) {\n> 32      DMLC_DECLARE_FIELD(num_args).set_range(1, 100)\n> \n> in src/operator/elementwise_sum-inl.h\n> \n> It seems suffices to just remove that constraint there\n> \n> —\n> Reply to this email directly or view it on GitHub\n> https://github.com/dmlc/mxnet/issues/467#issuecomment-153148076.\n', 'Thanks to @Kublai-Jing fixed by #469 \n']","['\n     71     """"""\n     72     if ret != 0:\n---> 73         raise MXNetError(py_str(_LIB.MXGetLastError()))\n     74 \n     75 def c_str(string):\n\nMXNetError: value 100for Parameter num_args exceed bound [1,100)\n']",[],0,0
375,incubator-mxnet,3967,closed,"the value of executor.arg_dict[""bn_conv1_gamma""] is different in different position of one iteration","I use the symbol.simple_bind to train the network batch by batch, below is the code snippet

 exe = self.symbol.simple_bind(ctx=self.ctx, **input_shapes)
 for batch in train_data:
      exe.forward(is_train=True)
      exe.backward()
      print ""before""
      print exe.arg_dict['bn_conv1_gamma'].asnumpy()
      
      for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):
            weight, grad = pair
            if i==3:
                  print ""arr_arrays""
                  print weight.asnumpy()
                  print ""arg_dict""
                  print exe.arg_dict['bn_conv1_gamma'].asnumpy()
                  
      self.updater(i, grad, weight)


where 'bn_conv1_gamma' is the 3rd(from 0) of self.symbol.list_arguments(), i found that the value of exe.arg_dict['bn_conv1_gamma'].asnumpy() is different in different position, which really confused me.",,"['why do you mean different position', '@piiswrong I ""print exe.arg_dict[\'bn_conv1_gamma\'].asnumpy()"" in two positions. As I write in the code, one is below ""print before"", the other is below ""print arg_dict"", but the value is different. ', ""if you are using fix_gamma=True for bn then it's normal. the BN layer is just forcing it to be 1"", '@piiswrong thanks a lot, i find ""fix_gamma=True"" is default for mx.symbol.BatchNorm, but i can\'t understand what you mean by ""it is normal"", can you explain more about why the value is different?\r\n\r\nI am also curious about when the value of exe.arg_arrays and exe.arg_dict will be updated, it seems that they are not updated after exe.forward or exe.backward, which really confuses me. thank you again \r\n', 'Maybe this page can help you for using executor. :)\r\nhttps://github.com/dmlc/mxnet/blob/bcc28dfb547eb8c6f7b414fa9c94269933f778a4/example/notebooks/simple_bind.ipynb', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
376,incubator-mxnet,8933,closed,How to train data with multi-class label,"There are 600 classes in the image dataset, each image belongs to one or more classes. How can I train such dataset?

**Is it a correct choice:**
Present image label by 600*1 binary vector, which contains one or more ""1"".
Bulid network with 600 outputs, and activate them with LogisticRegressionOutput()  (BTW, Will mxnet set the loss function to logistic loss automatically?)

I obtain a 0.49% mAP on this dataset, by it's reported 36.1% in the paper. (Parameters are set the same as the paper)",,"['Proposed Labels: ""Question"",""Discussion""', 'Can you please ask usage related questions at - https://discuss.mxnet.io/\r\n']",[],[],0,0
377,incubator-mxnet,331,closed,opencv not found,"I am attempting to install on a cluster running Red Hat Enterprise Linux 6. I have loaded opencv 3.0.0, and have a link to all the .so files. However,  will still fail, saying I need to find . I cannot find that in my opencv installation, can you point me in the right direction?

See error message below:

pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/c_api.cc -o build/c_api.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/resource.cc -o build/resource.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/engine/engine.cc -o build/engine/engine.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/engine/naive_engine.cc -o build/engine/naive_engine.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/engine/threaded_engine.cc -o build/engine/threaded_engine.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/engine/threaded_engine_perdevice.cc -o build/engine/threaded_engine_perdevice.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/engine/threaded_engine_pooled.cc -o build/engine/threaded_engine_pooled.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing pkg-config --cflags opencvopencv.pc'
to the PKG_CONFIG_PATH environment variable
No package 'opencv' found
g++ -std=c++0x -c -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1  -fopenmp  -c src/io/io.cc -o build/io/io.o
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing 
",,"['`opencv.pc` is usually installed to `$PREFIX/lib/pkgconfig`. For example, it might be `/usr/lib/pkgconfig`, `/usr/local/lib/pkgconfig`. Or if you compile openCV and install it locally at any prefix you specified, you might find it at `prefix/lib/pkgconfig`.\n', 'If there is no opencv.pc You can also do it by changing https://github.com/dmlc/mxnet/blob/master/Makefile#L46\n\n``pkg-config --cflags opencv`` to `-I/path/to/opencv/include`\n\n``pkg-config --libs opencv`` to `-L/path/to/opencv/libs`\n', '@tqchen, your workaround is incomplete becuase `-L/path/to/opencv/libs` only specifies the library path, but dose NOT tell the linker which libs to use. The linker still complains about objext missing in this case.\n\nMy workaround is to specify all OpenCV libraries manually, along with the lib path at the beginning. It makes the Makefile looks like:\n\n```\n# setup opencv\nifeq ($(USE_OPENCV), 1)\n        CFLAGS += -DMXNET_USE_OPENCV=1 -I/path/to/opencv/include\n        LDFLAGS += -L/path/to/opencv/lib -lopencv_calib3d -lopencv_contrib -lopencv_core -lopencv_features2d -lopencv_flann -lopencv_gpu -lopencv_highgui -lopencv_imgproc -lopencv_legacy -lopencv_ml -lopencv_nonfree -lopencv_objdetect -lopencv_ocl -lopencv_photo -lopencv_stitching -lopencv_superres -lopencv_ts -lopencv_video -lopencv_videostab\n        BIN += bin/im2rec\nelse\n        CFLAGS+= -DMXNET_USE_OPENCV=0\nendif\n```\n']",[],"['make all', 'opencv.pc', '', '\n[jmschr@n025 mxnet]$ make all\ng++ -std=c++0x -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1 ', ' -fopenmp  -MM -MT build/c_api.o src/c_api.cc >build/c_api.d\nPackage opencv was not found in the pkg-config search path.\nPerhaps you should add the directory containing ', 'pkg-config --cflags opencv', ""opencv.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'opencv' found\ng++ -std=c++0x -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1 "", ' -fopenmp  -MM -MT build/resource.o src/resource.cc >build/resource.d\nPackage opencv was not found in the pkg-config search path.\nPerhaps you should add the directory containing ', 'pkg-config --cflags opencv', ""opencv.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'opencv' found\ng++ -std=c++0x -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1 "", ' -fopenmp  -MM -MT build/engine/engine.o src/engine/engine.cc >build/engine/engine.d\nPackage opencv was not found in the pkg-config search path.\nPerhaps you should add the directory containing ', 'pkg-config --cflags opencv', ""opencv.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'opencv' found\ng++ -std=c++0x -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1 "", ' -fopenmp  -MM -MT build/engine/naive_engine.o src/engine/naive_engine.cc >build/engine/naive_engine.d\nPackage opencv was not found in the pkg-config search path.\nPerhaps you should add the directory containing ', 'pkg-config --cflags opencv', ""opencv.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'opencv' found\ng++ -std=c++0x -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1 "", ' -fopenmp  -MM -MT build/engine/threaded_engine.o src/engine/threaded_engine.cc >build/engine/threaded_engine.d\nPackage opencv was not found in the pkg-config search path.\nPerhaps you should add the directory containing ', 'pkg-config --cflags opencv', ""opencv.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'opencv' found\ng++ -std=c++0x -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1 "", ' -fopenmp  -MM -MT build/engine/threaded_engine_perdevice.o src/engine/threaded_engine_perdevice.cc >build/engine/threaded_engine_perdevice.d\nPackage opencv was not found in the pkg-config search path.\nPerhaps you should add the directory containing ', 'pkg-config --cflags opencv', ""opencv.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'opencv' found\ng++ -std=c++0x -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1 "", ' -fopenmp  -MM -MT build/engine/threaded_engine_pooled.o src/engine/threaded_engine_pooled.cc >build/engine/threaded_engine_pooled.d\nPackage opencv was not found in the pkg-config search path.\nPerhaps you should add the directory containing ', 'pkg-config --cflags opencv', ""opencv.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'opencv' found\ng++ -std=c++0x -DMSHADOW_FORCE_STREAM -Wall -O3 -I./mshadow/ -I./dmlc-core/include -fPIC -Iinclude -msse3 -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMXNET_USE_OPENCV=1 "", ' -fopenmp  -MM -MT build/io/io.o src/io/io.cc >build/io/io.d\nPackage opencv was not found in the pkg-config search path.\nPerhaps you should add the directory containing ', 'pkg-config --cflags opencv', ""opencv.pc'\nto the PKG_CONFIG_PATH environment variable\nNo package 'opencv' found\nIn file included from src/io/io.cc:5:0:\nsrc/io/./image_augmenter.h:10:30: fatal error: opencv2/opencv.hpp: No such file or directory\n #include <opencv2/opencv.hpp>\n                              ^\ncompilation terminated.\nmake: *** [build/io/io.o] Error 1\n"", '']",0,0
378,incubator-mxnet,12532,closed,caffeOp mxnet build failed,"Hi,

environment MXNet v1.0.0

I want to use caffe operator to implement some custom layers,such as the solution in mxnet/example/caffe/
I follow the install command described in https://mxnet.incubator.apache.org/faq/caffe.html, how to solve these problems?
1. git clone https://github.com/BVLC/caffe
2. cd caffe && wget https://github.com/BVLC/caffe/pull/4527.patch && git apply 4527.patch

thanks a lot !!



also if it has the cmake method for below configuration.
   CAFFE_PATH = $(HOME)/caffe
   MXNET_PLUGINS += plugin/caffe/caffe.mk



![image](https://user-images.githubusercontent.com/31586393/45429203-63981280-b6d5-11e8-9738-107f94cdc2ef.png)
",Operator,"['Thanks for submitting the issue @jacky4323 \r\nCould you also provide your system config for us to be able to assist you better?\r\n\r\n@mxnet-label-bot[Caffe Integration, Operator]', 'Hi @kalyc ,\r\n\r\nsystem  config of my linux is showed below.\r\nthanks for help!!\r\n\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                20\r\nOn-line CPU(s) list:   0-19\r\nThread(s) per core:    2\r\nCore(s) per socket:    10\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 85\r\nModel name:            Intel(R) Core(TM) i9-7900X CPU @ 3.30GHz\r\nStepping:              4\r\nCPU MHz:               2675.835\r\nCPU max MHz:           4500.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              6623.88\r\nVirtualization:        VT-x\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              1024K\r\nL3 cache:              14080K\r\nNUMA node0 CPU(s):     0-19\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb intel_pt tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx avx512f rdseed adx smap clflushopt clwb avx512cd xsaveopt xsavec xgetbv1 cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts hwp hwp_act_window hwp_epp hwp_pkg_req', 'Hi @kalyc ,\r\n\r\nsorry , Is there any update for this problem?', ""@jacky4323 Sorry for the waiting, I am taking over here to help you out. \r\nHere is what I found: Unfortunately, I cannot get it to work either. There has been an MXNet interface project with Caffe but it looks like it hasn't been updated for a while."", '@lanking520  \r\n\r\nOK , thanks for help!! ', 'Hi @lanking520 \r\n\r\nOK, thanks\r\nAre there any plans to update MXNet interface project with Caffe?\r\nsome of the custom operators are in caffe for my project. \r\nAny help would be appreciated! thanks.', '@jacky4323 I have reached out to the slack channel of MXNet to see if this is possible. In the meantime, can you try to convert your Caffe model into ONNX and then to MXNet?  I saw you mentioned some custom operators and this may block this approach.', 'Apart from that, did this help you out? https://discuss.mxnet.io/t/caffeop-mxnet-build-failed/2014', 'I responded to the relevant question on Discuss: https://discuss.mxnet.io/t/caffeop-mxnet-build-failed/2014/2\r\n\r\nCopying response for reference here:\r\n\r\nLooks like the patch hasn\'t been maintained as Caffe has evolved. You should try to reset your branch head to an older node (I tried **rc3** tag) and then apply the patch. Once patch is applied, you can then rebase it on top of the main repo. The following commands will do the job (although I haven\'t compiled Caffe and even though re-base works without any issues, you may get some compilation errors):\r\n```bash\r\ncd caffe\r\ngit reset --hard rc3\r\nwget https://github.com/BVLC/caffe/pull/4527.patch\r\ngit apply 4527.patch\r\ngit add -u\r\ngit commit -m ""mxnet patch""\r\ngit rebase origin/master\r\n```', '@safrooze ,\r\nI have tried it , the error is solved\r\nunfortunately, When I use cmake to build mxnet, I met the problems below\r\n\r\nin CMakeList.txt turn on Use Caffe Plugin\r\n`mxnet_option(USE_PLUGIN_CAFFE     ""Use Caffe Plugin"" ON) `\r\n`mkdir build/Release  && cd build/Release `\r\n`cmake ../../ `\r\n\r\n[CMakeError.log](https://github.com/apache/incubator-mxnet/files/2509111/CMakeError.log)\r\n[console_error_log.txt](https://github.com/apache/incubator-mxnet/files/2509114/console_error_log.txt)\r\n', ""Looks like the patch needs updating. Any chance you'd be interested in fixing the patch and pushing a PR to get your name as an MXNet contributor? :)"", '@safrooze Hi,\r\n\r\nnow I use an old mxnet package build with caffe, it works now!!\r\nHowever, In my caffe operator which is only implemented custom_layer.cpp (there is no custom_layer.cu),\r\nCan I set not compile Cuda with this custom operator?\r\nWhen I use the command below, I get the error due to not implementing GPU mode(cuda file)\r\n`mkdir build/Release && cd build/Release` \r\n`cmake ../../` \r\n`make -j8` \r\n\r\n![image](https://user-images.githubusercontent.com/31586393/47805275-e3f00100-dd71-11e8-9821-c099f81a7364.png)\r\n', ""@safrooze Hi ,\r\n\r\nSorry, It's my mistake, I solved the problems.\r\nI'm not familiar with this mechanism so I couldn't contribute this part,sorry.\r\nThanks!!"", 'We are deprecating caffe converter']",[],[],0,0
379,incubator-mxnet,13875,closed,importing mxnet causing subprocess to crash,"may be related to #13831

## Description
importing mxnet causes OSErrors in subprocess


## Environment info (Required)
Scientific Linux 7.5
Python 3.6.3 
MXnet 1.5.0 (from packages)
(tried on multiple computers running different cuda builds) 


## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
Using the following script (or just using the appropriate commands)


will eventually give this error message:

Traceback (most recent call last):
   File ""subcrash.py"", line 13, in <module>
     ret = subprocess.call(['ls', '/'], stdout=subprocess.PIPE)
   File ""/opt/rh/rh-python36/root/usr/lib64/python3.6/subprocess.py"", 
line 267, in call
     with Popen(*popenargs, **kwargs) as p:
   File ""/opt/rh/rh-python36/root/usr/lib64/python3.6/subprocess.py"", 
line 709, in __init__
     restore_signals, start_new_session)
   File ""/opt/rh/rh-python36/root/usr/lib64/python3.6/subprocess.py"", 
line 1344, in _execute_child
     raise child_exception_type(errno_num, err_msg, err_filename)
OSError: [Errno 14] Bad address: 'ls'

Doesn't seem to matter which executable.

## What have you tried to solve it?

Don't even know where to start.
If you try putting in a stack tract or pdb it won't break.

",Build MKL,"[""@dabraude Thank you for submitting the issue! I'm labeling it so the MXNet community members can help resolve it. \r\n@mxnet-label-bot add [Build] \r\n\r\nI tried running the script you provided locally on my Mac (So essentially non-CUDA build).\r\nI did not face any crashes. My MXNet version is : 1.5.0b20190112. \r\n\r\nCan you try this on your machine  and then run the script ? \r\nRun : ```pip install -U mxnet --pre```\r\n\r\nI'm trying to see if it's something to do with the CUDA builds of MXNet. \r\nAlso, what's the CUDA version that you tried it on ? "", 'Ok we will try running that script and get back to you.\r\n\r\nWe are running CUDA 10', 'It still crashes with the --pre\r\n\r\nWe have found that it only happens with the MKL version:\r\nmxnet-cu100mkl-1.5.0b20190115 - crashing (Intel or AMD CPU)\r\nmxnet-cu100-1.5.0b20190115 - stable (up to ~4 million calls)\r\n', '@mxnet-label-bot update [Build, MKL] \r\n\r\n@azai91 @mseth10  Can we have a look at this crash ? ', ""I'd like to note that the website CI pipeline has been intermittently failing with subprocess errors ever since the MKLDNN merge. This is when it started:\r\nhttp://jenkins.mxnet-ci.amazon-ml.com/job/mxnet-validation/job/website/job/master/141/\r\nIt's really important that we have the website check in CI, but right now it is turned off because of the failures. "", '@dabraude @aaronmarkham thanks for reporting the issues.\r\n\r\nWe will take a look for the potential issue @ZhennanQin @TaoLv ', '@aaronmarkham I guess for ""the MKLDNN merge"" you mean #13681, right? But I tried the script @dabraude shared in this issue, it also crashes with mxnet-mkl==1.3.1.\r\n\r\n@dabraude said this issue only happens with MKL build. But website build is not using MKL or MKL-DNN. So I\'m afraid they are not the same issue.\r\n\r\nBTW, @dabraude have you ever tried it with python2?', '@dabraude Please try `export KMP_INIT_AT_FORK=false` before running your script. Let me know if it works for you. Thank you.', ""I can confirm it happens with python2 and that \r\nexport KMP_INIT_AT_FORK=false seems to stop it, but with intermittent errors I can't be 100% it did"", ""Researching the build logs from the first crash... I see that mkldnn is set to 0 in some of the earlier build routines, but when making the docs, mkldnn files are being built by mshadow:\r\n```\r\n+ make docs SPHINXOPTS=-W\r\n/work/mxnet /work/mxnet\r\nmake -C docs html\r\nmake[1]: Entering directory '/work/mxnet/docs'\r\nexport BUILD_VER=\r\nEnv var set for BUILD_VER: \r\nsphinx-build -b html -d _build/doctrees  -W . _build/html\r\nRunning Sphinx v1.5.6\r\nmaking output directory...\r\nBuilding version default\r\nDocument sets to generate:\r\nscala_docs    : 1\r\njava_docs     : 1\r\nclojure_docs  : 1\r\ndoxygen_docs  : 1\r\nr_docs        : 0\r\nBuilding MXNet!\r\nBuilding Doxygen!\r\nBuilding Scala!\r\nBuilding Scala Docs!\r\nBuilding Java Docs!\r\nBuilding Clojure Docs!\r\nloading pickled environment... not yet created\r\nmake[2]: Entering directory '/work/mxnet'\r\ng++ -std=c++11 -c -DMSHADOW_FORCE_STREAM -Wall -Wsign-compare -g -O0 -I/work/mxnet/3rdparty/mshadow/ -I/work/mxnet/3rdparty/dmlc-core/include -fPIC -I/work/mxnet/3rdparty/tvm/nnvm/include -I/work/mxnet/3rdparty/dlpack/include -I/work/mxnet/3rdparty/tvm/include -Iinclude -funroll-loops -Wno-unused-parameter -Wno-unknown-pragmas -Wno-unused-local-typedefs -msse3 -mf16c -DMSHADOW_USE_CUDA=0 -DMSHADOW_USE_CBLAS=1 -DMSHADOW_USE_MKL=0 -I/include -DMSHADOW_RABIT_PS=0 -DMSHADOW_DIST_PS=0 -DMSHADOW_USE_PASCAL=0 -DMXNET_USE_OPENCV=1 -I/usr/include/opencv -fopenmp -DMXNET_USE_OPERATOR_TUNING=1 -DMXNET_USE_LAPACK  -DMXNET_USE_NCCL=0 -DMXNET_USE_LIBJPEG_TURBO=0 -MMD -c \\\r\nsrc/operator/subgraph/mkldnn/mkldnn_conv_property.cc -o build/src/operator/subgraph/mkldnn/mkldnn_conv_property.o\r\n```\r\n\r\nThen down further I see more...\r\n```\r\nar crv lib/libmxnet.a build/src/operator/subgraph/mkldnn/mkldnn_conv_property.o \r\nbuild/src/operator/subgraph/mkldnn/mkldnn_conv_post_quantize_property.o build/src/operator/subgraph/mkldnn/mkldnn_conv.o build/src/operator/nn/mkldnn/mkldnn_convolution.o build/src/operator/nn/mkldnn/mkldnn_concat.o build/src/operator/nn/mkldnn/mkldnn_base.o build/src/operator/nn/mkldnn/mkldnn_act.o build/src/operator/nn/mkldnn/mkldnn_softmax.o build/src/operator/nn/mkldnn/mkldnn_deconvolution.o build/src/operator/nn/mkldnn/mkldnn_copy.o \r\n...\r\na - build/src/operator/subgraph/mkldnn/mkldnn_conv_property.o\r\na - build/src/operator/subgraph/mkldnn/mkldnn_conv_post_quantize_property.o\r\na - build/src/operator/subgraph/mkldnn/mkldnn_conv.o\r\na - build/src/operator/nn/mkldnn/mkldnn_convolution.o\r\na - build/src/operator/nn/mkldnn/mkldnn_concat.o\r\n...\r\n```\r\nSo would this help reveal why docs is experiencing the same kind of crashing?"", '@dabraude Can you confirm if the issue is still there with the environmental variable?', ""@aaronmarkham The log of build mkldnn file is expected on USE_MKLDNN=0. Because `USE_MKLDNN` is only used as c macro in those files, instead of Makefile source control. In other words to say, USE_MKLDNN won't change the source files collected to build, but change the mkldnn file contains seen by compiler."", ""@TaoLv It didn't crash when running overnight so I assume it is working."", 'Hi all, \r\nthis bug keeps biting us. This is easily reproducible, meaning that it occurs randomly but with pretty high frequency, always within a few hundred attempts, but non deterministic.\r\nThe code I\'m using (essentially the same as above):\r\n\r\n```python\r\nimport mxnet\r\nimport subprocess\r\n\r\nfor i in range(1000):\r\n    if not i%100: print(i)\r\n    try:\r\n        ret = subprocess.call([""ls"",""/tmp""], stdout=subprocess.PIPE)\r\n    except Exception as e:\r\n        print(i, e)\r\n        exit()\r\n\r\n```\r\nand you always get a nice\r\n`OSError: [Errno 14] Bad address: \'ls\'`\r\n\r\nI managed to isolate some requirements to recreate a conda environment where this issue occurs.\r\nThis is obtained with conda + pip as follows (I have conda 4.7.12):\r\n\r\n```bash\r\nconda create -n mxnet-test --file env_conda.txt\r\nconda activate mxnet-test\r\n#make sure we\'re using the pip in the env\r\necho $(which pip)\r\npip install -r env_pip.txt\r\n```\r\n\r\nwhere the content of the files is:\r\n```bash\r\nenv_conda.txt:\r\nmkl=2019.0=118\r\nnumpy=1.16.4=py36h99e49ec_0\r\nenv_pip.txt:\r\nmxnet-cu80mkl==1.5.0\r\n```\r\n\r\nand this is the result of `conda list -e`\r\n```\r\n# platform: linux-64\r\n_libgcc_mutex=0.1=main\r\nblas=1.0=openblas\r\nca-certificates=2019.5.15=1\r\ncertifi=2019.9.11=py36_0\r\nchardet=3.0.4=pypi_0\r\nidna=2.8=pypi_0\r\nintel-openmp=2019.4=243\r\nlibedit=3.1.20181209=hc058e9b_0\r\nlibffi=3.2.1=hd88cf55_4\r\nlibgcc-ng=9.1.0=hdf63c60_0\r\nlibgfortran-ng=7.3.0=hdf63c60_0\r\nlibopenblas=0.3.6=h5a2b251_1\r\nlibstdcxx-ng=9.1.0=hdf63c60_0\r\nmkl=2019.0=118\r\nmxnet-cu80mkl=1.5.0=pypi_0\r\nncurses=6.1=he6710b0_1\r\nnumpy=1.16.4=py36h99e49ec_0\r\nnumpy-base=1.16.4=py36h2f8d375_0\r\nopenssl=1.1.1d=h7b6447c_1\r\npip=19.2.2=py36_0\r\npython=3.6.9=h265db76_0\r\npython-graphviz=0.8.4=pypi_0\r\nreadline=7.0=h7b6447c_5\r\nrequests=2.22.0=pypi_0\r\nsetuptools=41.0.1=py36_0\r\nsqlite=3.29.0=h7b6447c_0\r\ntk=8.6.8=hbc83047_0\r\nurllib3=1.25.5=pypi_0\r\nwheel=0.33.4=py36_0\r\nxz=5.2.4=h14c3975_4\r\nzlib=1.2.11=h7b6447c_3\r\n```\r\n\r\nI was able to reproduce this issue both with and without gpu (mxnet-mkl), on ubuntu 16.04, also inside docker containers.\r\n\r\n**Note** : this is non-deterministic also at ""build-time"", in the sense that, creating environments with _exactly the same requirements and exactly the same installed libraries_, you can randomly end up with an environment where the issue **does not occur**.\r\n\r\n', 'This does seem related (or really, the same thing) as https://github.com/numpy/numpy/issues/10060 and https://github.com/apache/incubator-mxnet/issues/12710\r\nand setting KMP_INIT_AT_FORK=FALSE as suggested, seems to fix the issue. \r\nNot sure if something could be done by the libraries that use MKL, such as mxnet, to warn about this behavior and how to prevent it.', '@sbebo I take this issue as a defect of the openmp library and the library will be excluded in the next minor release.', '@szha @eric-haibin-lin this bugreports describes the cause of the `OSErrors` that time-to-time happen on ci.mxnet.io (CI used by gluon-nlp.mxnet.io , gluon-cv.mxnet.io , ...)', ""Note that we didn't face the OSError related crashes anymore after upgrading to Ubuntu 18.04 (more specifically, using the following Docker container https://github.com/dmlc/gluon-nlp/blob/master/ci/batch/docker/Dockerfile )"", 'Hi @leezu, is it possible for you to try `export KMP_INIT_AT_FORK=false` in your CI environment?', ""> \r\n> \r\n> Note that we didn't face the OSError related crashes anymore after upgrading to Ubuntu 18.04 (more specifically, using the following Docker container https://github.com/dmlc/gluon-nlp/blob/master/ci/batch/docker/Dockerfile )\r\n\r\nOh, will try to move to Ubuntu 18.04 if possible. Thanks!"", '@TaoLv the issue occurred only rarely (few times a month) for us and did not occur anymore during the recent months. What would be the expectation of setting `export KMP_INIT_AT_FORK=false`? Should it fix the issue or are you asking to confirm if setting the env variable reintroduces the problem?', 'The env variable fixed the problem reported in this issue. So if GluonNLP CI is facing the same issue, I think it can be fixed by this env variable too.', ""@leezu, the same issue and same fix as #14979. I'm closing this issue as:\r\n1. `libiomp5.so` has been removed from the pip releases of MXNet;\r\n2. The problem should have been fixed in a newer version of `libiomp5.so`.\r\n\r\nFeel free to reopen if you have any question. Thanks!\r\n""]","['\r\nimport mxnet\r\nimport subprocess\r\nn = 0\r\nwhile True:\r\n    if not n%1000: print (""RUN"", n)\r\n    ret = subprocess.call([\'ls\', \'/tmp\'], stdout=subprocess.PIPE)\r\n    n += 1\r\n']",[],0,0
380,incubator-mxnet,2975,closed,"a question about rcnn exmaple, why set aux to zero when testing?","https://github.com/dmlc/mxnet/blob/master/example/rcnn/rcnn/rpn/generate.py#L30

For BN layers, this will erase the moving_mean and moving_var in aux, which will lead to wrong results; I don't know if there are any special reasons to do this? @precedenceguo 
",,['There is not. Please ignore this line and supply aux_params as saved in training.\n'],[],[],0,0
381,incubator-mxnet,11334,closed,Cannot initializing parameters of SymbolBlock.,"ref: https://discuss.mxnet.io/t/initializing-parameters-of-symbolblock/1213

It looks like SymbolBlock will initializing all the parameters using the initializer given in the block.initialize() function, including bias, which cannot be initialized by Xavier. 

Alought that [post](https://discuss.mxnet.io/t/initializing-parameters-of-symbolblock/1213) suggests a solution, and in addition, I think we should try to initialize the parameters if it was given in the symbol/json file.

e.g. 

or


Or if there a better way please let me know.",Gluon,"['Thank you for reporting the issue , @kice , @sandeep-krishnamurthy , requesting to tag this under Gluon', '@kice the question as been answered on the forum, thanks!\r\n\r\n@indhub can you please close the issue? Thanks!']","['\r\n{\r\n      ""op"": ""null"", \r\n      ""name"": ""conv_bias"", \r\n      ""attrs"": {\r\n        ""__init__"": ""[\\""zero\\"", {}]"", \r\n        ""__shape__"": ""(64,)""\r\n      }, \r\n      ""inputs"": []\r\n}\r\n']","[""bias = mx.sym.Variable(name='conv_bias', shape=(num_filter,), init=mx.init.Zero())""]",0,0
382,incubator-mxnet,5455,closed,Refactor 'softmax_label' to 'label',"softmax_label is not really a good default name, many times you are not doing softmax. I think 'label' would be a better default name. This proposed refactor would change the default values of 'softmax_label' to 'label'.",,"['We are refactoring to remove label_names entirely: https://github.com/dmlc/mxnet/tree/loss', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
383,incubator-mxnet,11241,closed,Conv1D throws CUDNN_STATUS_EXECUTION_FAILED,"Setup: 


Run the following script :

Gives the following error:

Note that there's no error if  is changed to 'write'. 

Can also be reproduced if I build mxnet from source at commit 5b99b25e5f6ab3a20c7bcf4821a6af0a1a95f823 where Conv1D CUDNN was initially introduced.",Bug CUDA,"[""Can be also reproduced by the following code `debug_gluon.py`:\r\n```\r\nimport mxnet as mx\r\nfrom mxnet import nd, sym, autograd\r\nfrom mxnet.gluon import nn, HybridBlock, Block\r\n\r\nif __name__ == '__main__':\r\n    ctx = mx.gpu()\r\n    x = mx.nd.ones((1L, 65536L, 1560L), ctx=ctx)\r\n    net = nn.Conv1D(channels=256, kernel_size=2, layout='NCW', use_bias=False)\r\n    net.initialize(ctx=ctx)\r\n\r\n    for p in net.collect_params().values():\r\n        p.grad_req = 'add'\r\n\r\n    with autograd.record():\r\n        y = net(x)\r\n    y.backward()\r\n    print(net.weight.grad())\r\n```\r\n\r\nwith `pip install mxnet-cu90 --pre`"", 'What GPU are you trying to run on?  What were the nvcc args used to build your libmxnet.so?', 'Tesla V100. \r\n\r\n```\r\ngit checkout 5b99b25e5f6ab3a20c7bcf4821a6af0a1a95f823\r\ngit submodule update --init --recursive \r\ncp make/config.mk .\r\necho ""USE_BLAS=openblas"" >>config.mk\r\necho ""ADD_CFLAGS += -I/usr/include/openblas"" >>config.mk\r\necho ""USE_CUDA=1"" >>config.mk\r\necho ""USE_CUDA_PATH=/usr/local/cuda"" >>config.mk\r\necho ""USE_CUDNN=1"" >>config.mk\r\nmake -j32\r\n```\r\n\r\nRun `python debug.py`\r\n', 'Update: CUDNN team is notified for the issue that cudnnFind() is returning algos that will fail. ']","['\r\n$ pip install mxnet-cu90==1.1.0\r\n\r\n$ nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2017 NVIDIA Corporation\r\nBuilt on Fri_Sep__1_21:08:03_CDT_2017\r\nCuda compilation tools, release 9.0, V9.0.176\r\n\r\n$ ls /usr/local/cuda/lib64/libcudnn.so.7.0.3\r\n/usr/local/cuda/lib64/libcudnn.so.7.0.3\r\n', ""\r\nimport mxnet as mx\r\nW_REQ = 'add'\r\nshape = (1, 65536, 1)\r\nctx = mx.gpu()\r\nkwargs = {'no_bias': True, 'kernel': (1,), 'num_filter': 1}\r\nx = mx.sym.var('x')\r\nw = mx.sym.var('w')\r\nx_grad = mx.nd.zeros(shape, ctx=ctx)\r\nw_grad = mx.nd.zeros(shape, ctx=ctx)\r\nargs_grad = {'x': x_grad, 'w': w_grad}\r\nsym = mx.sym.Convolution(x, w, **kwargs)\r\nexecutor = sym.bind(ctx, grad_req={'x': 'null', 'w': W_REQ},\r\n                    args={'x': mx.nd.ones(shape, ctx=ctx), 'w': mx.nd.ones(shape, ctx=ctx)},\r\n                    args_grad=args_grad)\r\nexecutor.forward()\r\nexecutor.backward([mx.nd.ones((1,1,1), ctx=ctx)])\r\nmx.nd.waitall()\r\n"", ""\r\n[06:31:41] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\nterminate called after throwing an instance of 'dmlc::Error'\r\n  what():  [06:31:41] src/engine/./threaded_engine.h:359: [06:31:41] src/operator/nn/./cudnn/cudnn_convolution-inl.h:242: Check failed: e == CUDNN_STATUS_SUCCESS (8 vs. 0) cuDNN: CUDNN_STATUS_EXECUTION_FAILED\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2a9e78) [0x7f705d9a3e78]\r\n[bt] (1) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2aa288) [0x7f705d9a4288]\r\n[bt] (2) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2a920d1) [0x7f706018c0d1]\r\n[bt] (3) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x262f5e7) [0x7f705fd295e7]\r\n[bt] (4) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x24570bb) [0x7f705fb510bb]\r\n[bt] (5) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x245d7d4) [0x7f705fb577d4]\r\n[bt] (6) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x243e2ed) [0x7f705fb382ed]\r\n[bt] (7) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2442bdb) [0x7f705fb3cbdb]\r\n[bt] (8) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2442db6) [0x7f705fb3cdb6]\r\n[bt] (9) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x243f68b) [0x7f705fb3968b]\r\n\r\n\r\nA fatal error occurred in asynchronous engine operation. If you do not know what caused this error, you can try set environment variable MXNET_ENGINE_TYPE to NaiveEngine and run with debugger (i.e. gdb). This will force all operations to be synchronous and backtrace will give you the series of calls that lead to this error. Remember to set MXNET_ENGINE_TYPE back to empty after debugging.\r\n\r\nStack trace returned 9 entries:\r\n[bt] (0) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2a9e78) [0x7f705d9a3e78]\r\n[bt] (1) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2aa288) [0x7f705d9a4288]\r\n[bt] (2) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x243e594) [0x7f705fb38594]\r\n[bt] (3) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2442bdb) [0x7f705fb3cbdb]\r\n[bt] (4) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x2442db6) [0x7f705fb3cdb6]\r\n[bt] (5) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x243f68b) [0x7f705fb3968b]\r\n[bt] (6) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80) [0x7f70d400bc80]\r\n[bt] (7) /lib/x86_64-linux-gnu/libpthread.so.0(+0x76ba) [0x7f70d52a66ba]\r\n[bt] (8) /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7f70d4fdc3dd]\r\n""]","['debug.py', 'W_REQ']",0,0
384,incubator-mxnet,16101,closed,[Feature Request]  np.where compatible operator,"
## Description
### Bug 
[mx.nd.where()](https://beta.mxnet.io/api/ndarray/_autogen/mxnet.ndarray.where.html?highlight=where#mxnet.ndarray.where) shows an incorrect behavior when one of the inputs is an NDArray with zero size. 

Here is a reproducible example

The output is weird and it seems that the NDArray with zero size has not been checked. We expect that it would raise an error showing the shape of x and y must be the same, according to [docs of mx.nd.where()](https://beta.mxnet.io/api/ndarray/_autogen/mxnet.ndarray.where.html?highlight=where#mxnet.ndarray.where). Broadcast is not supported in the latest version but where() still has an output.

 It is also a little dangerous as it outputs incorrect answers rather than error messages, when users forget to type [] for mx.nd.array([4]).


<br>

### Feature Request
#### 1. Broadcast

Currently, there are two limitations for mx.nd.where()
 - x and y must have the same shape
 - If condition does not have the same shape as x, it must be a 1D array whose size is the same as x’s first dimension size

Similar to [np.where()](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.where.html), it would be great if mx.nd.where() supports broadcast to make sure (cond, x, y) have the same shape, even if they are in different shapes as input. 

<br>

#### 2.  Scalar inputs (cond, x and y)
In some situations, we want to give a constant value for True/False.

It would be user-friendly if programmers only need to type 
 
instead of 





<br>
<br> 
<br> 
<br> 
<br>


---

## Environment info (Required)





## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): gcc

MXNet commit hash: 03f12f0fe706d35c93a2cf721b6101bcbffeb07d

Build config:  plain CMakeList.txt with USE_NCCL=1






",Feature request Numpy,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended label(s): Feature', '@mxnet-label-bot  add [Bug, Feature request]', 'Scalar tensors like below is not supported in `mx.nd` module. We need to implement a numpy-compatible where op for this purpose. I will add this op to the list and prioritize it.\r\n```python\r\ny = mx.nd.array(4)            #    y.shape: ()\r\n```', '#16829 merged, closing the issue.']","['python\r\ncond = mx.nd.array([0])       # cond.shape: (1,)\r\nx = mx.nd.array([[10,10]])    #    x.shape: (1, 2)\r\ny = mx.nd.array(4)            #    y.shape: ()\r\n\r\nprint( mx.nd.where(cond, x, y) )\r\n# output: [[4.0000e+00 3.0773e-41]]\r\n\r\n', 'mx.nd.where(cond, x, 0)', 'mx.nd.where(cond, x,  mx.nd.array([0]))', '\r\n----------Python Info----------\r\nVersion      : 3.6.9\r\nCompiler     : GCC 7.3.0\r\nBuild        : (\'default\', \'Jul 30 2019 19:07:31\')\r\nArch         : (\'64bit\', \'\')\r\n------------Pip Info-----------\r\nVersion      : 19.2.2\r\nDirectory    : /home/ubuntu/anaconda3/envs/new/lib/python3.6/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.6.0\r\nDirectory    : /home/ubuntu/new/my-mxnet/python/mxnet\r\nCommit hash file ""/home/ubuntu/new/my-mxnet/python/mxnet/COMMIT_HASH"" not found. Not installed from pre-built package or built from source.\r\nLibrary      : [\'/home/ubuntu/new/my-mxnet/python/mxnet/../../build/libmxnet.so\']\r\nBuild features:\r\nNo runtime build feature info available\r\n----------System Info----------\r\nPlatform     : Linux-4.4.0-1092-aws-x86_64-with-debian-stretch-sid\r\nsystem       : Linux\r\nnode         : ip-172-31-14-150\r\nrelease      : 4.4.0-1092-aws\r\nversion      : #103-Ubuntu SMP Tue Aug 27 10:21:48 UTC 2019\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                96\r\nOn-line CPU(s) list:   0-95\r\nThread(s) per core:    2\r\nCore(s) per socket:    24\r\nSocket(s):             2\r\nNUMA node(s):          2\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 85\r\nModel name:            Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz\r\nStepping:              4\r\nCPU MHz:               2499.998\r\nBogoMIPS:              4999.99\r\nHypervisor vendor:     KVM\r\nVirtualization type:   full\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              1024K\r\nL3 cache:              33792K\r\nNUMA node0 CPU(s):     0-23,48-71\r\nNUMA node1 CPU(s):     24-47,72-95\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc aperfmperf tsc_known_freq pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f rdseed adx smap clflushopt clwb avx512cd xsaveopt xsavec xgetbv1 ida arat pku\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0014 sec, LOAD: 0.4787 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.1707 sec, LOAD: 0.2402 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0228 sec, LOAD: 0.3108 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0107 sec, LOAD: 0.1101 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0013 sec, LOAD: 0.3356 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0135 sec, LOAD: 0.0633 sec.\r\n----------Environment----------\r\n']","['', '']",0,0
385,incubator-mxnet,9408,closed,[CI] Merging is not possible because you have unmerged files.,"Description WIP

Initial error: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-9406-merge/1/pipeline/



Future errors: http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-9406-merge/9/pipeline/


git status on Jenkins master
",CI,"['@marcoabreu : Are you still seeing this conflicts?  \r\n\r\n@sandeep-krishnamurthy : Please label it as ""CI"". ', 'Thank you for reminding me. This was due to a permission issue on CI side.']","['\r\nPull request #9406 opened\r\n\r\nConnecting to https://api.github.com using cjolivier01/******\r\n\r\nChecking out git https://github.com/apache/incubator-mxnet.git into /var/lib/jenkins/workspace/cubator-mxnet_PR-9406-merge-IWOL2LWEYWILCMVJ327KHGMU27SZHSVFB3IKRA4SZBAZPPWMBTUA@script to read Jenkinsfile\r\n\r\nCloning the remote Git repository\r\n\r\nCloning with configured refspecs honoured and without tags\r\n\r\nCloning repository https://github.com/apache/incubator-mxnet.git\r\n\r\n > git init /var/lib/jenkins/workspace/cubator-mxnet_PR-9406-merge-IWOL2LWEYWILCMVJ327KHGMU27SZHSVFB3IKRA4SZBAZPPWMBTUA@script # timeout=10\r\n\r\nFetching upstream changes from https://github.com/apache/incubator-mxnet.git\r\n\r\n > git --version # timeout=10\r\n\r\nusing GIT_ASKPASS to set credentials \r\n\r\n > git fetch --no-tags --progress https://github.com/apache/incubator-mxnet.git +refs/pull/9406/head:refs/remotes/origin/PR-9406-merge +refs/heads/master:refs/remotes/origin/master\r\n\r\n > git config remote.origin.url https://github.com/apache/incubator-mxnet.git # timeout=10\r\n\r\n > git config --add remote.origin.fetch +refs/pull/9406/head:refs/remotes/origin/PR-9406-merge # timeout=10\r\n\r\n > git config --add remote.origin.fetch +refs/heads/master:refs/remotes/origin/master # timeout=10\r\n\r\n > git config remote.origin.url https://github.com/apache/incubator-mxnet.git # timeout=10\r\n\r\nFetching without tags\r\n\r\nFetching upstream changes from https://github.com/apache/incubator-mxnet.git\r\n\r\nusing GIT_ASKPASS to set credentials \r\n\r\n > git fetch --no-tags --progress https://github.com/apache/incubator-mxnet.git +refs/pull/9406/head:refs/remotes/origin/PR-9406-merge +refs/heads/master:refs/remotes/origin/master\r\n\r\nMerging remotes/origin/master commit 67cfbc863d9d05baa2362a82cb78e0acb569d6ba into PR head commit f6b9492c8431bb111a59ff1d938813a264078d48\r\n\r\n > git config core.sparsecheckout # timeout=10\r\n\r\n > git checkout -f f6b9492c8431bb111a59ff1d938813a264078d48\r\n\r\n > git merge 67cfbc863d9d05baa2362a82cb78e0acb569d6ba # timeout=10\r\n\r\n > git config core.sparsecheckout # timeout=10\r\n\r\n > git checkout -f f6b9492c8431bb111a59ff1d938813a264078d48\r\n\r\n\r\n\r\nGitHub has been notified of this commit’s build result\r\n\r\n\r\n\r\nhudson.plugins.git.GitException: Command ""git merge 67cfbc863d9d05baa2362a82cb78e0acb569d6ba"" returned status code 1:\r\n\r\nstdout: CONFLICT (rename/delete): tests/python/unittest/test_contrib_text.py deleted in 67cfbc863d9d05baa2362a82cb78e0acb569d6ba and renamed in HEAD. Version HEAD of tests/python/unittest/test_contrib_text.py left in tree.\r\n\r\nCONFLICT (rename/delete): python/mxnet/contrib/text/utils.py deleted in 67cfbc863d9d05baa2362a82cb78e0acb569d6ba and renamed in HEAD. Version HEAD of python/mxnet/contrib/text/utils.py left in tree.\r\n\r\nCONFLICT (rename/delete): python/mxnet/contrib/text/indexer.py deleted in 67cfbc863d9d05baa2362a82cb78e0acb569d6ba and renamed in HEAD. Version HEAD of python/mxnet/contrib/text/indexer.py left in tree.\r\n\r\nCONFLICT (rename/delete): python/mxnet/contrib/text/glossary.py deleted in 67cfbc863d9d05baa2362a82cb78e0acb569d6ba and renamed in HEAD. Version HEAD of python/mxnet/contrib/text/glossary.py left in tree.\r\n\r\nCONFLICT (rename/delete): python/mxnet/contrib/text/embedding.py deleted in 67cfbc863d9d05baa2362a82cb78e0acb569d6ba and renamed in HEAD. Version HEAD of python/mxnet/contrib/text/embedding.py left in tree.\r\n\r\nCONFLICT (rename/delete): python/mxnet/contrib/text/__init__.py deleted in 67cfbc863d9d05baa2362a82cb78e0acb569d6ba and renamed in HEAD. Version HEAD of python/mxnet/contrib/text/__init__.py left in tree.\r\n\r\nRemoving example/warpctc/toy_ctc.py\r\n\r\nRemoving example/warpctc/ocr_predict.py\r\n\r\nRemoving example/warpctc/lstm_ocr.py\r\n\r\nRemoving example/warpctc/lstm_model.py\r\n\r\nRemoving example/warpctc/lstm.py\r\n\r\nRemoving example/warpctc/infer_ocr.py\r\n\r\nRemoving example/warpctc/README.md\r\n\r\nRemoving example/ctc/lstm_ocr.py\r\n\r\nRemoving docs/tutorials/speech_recognition/speech_lstm.md\r\n\r\nRemoving docs/tutorials/speech_recognition/baidu_warp_ctc.md\r\n\r\nRemoving docs/api/python/text/text.md\r\n\r\nAutomatic merge failed; fix conflicts and then commit the result.\r\n', '\r\n\r\nConnecting to https://api.github.com using cjolivier01/******\r\n\r\nChecking out git https://github.com/apache/incubator-mxnet.git into /var/lib/jenkins/workspace/cubator-mxnet_PR-9406-merge-IWOL2LWEYWILCMVJ327KHGMU27SZHSVFB3IKRA4SZBAZPPWMBTUA@script to read Jenkinsfile\r\n\r\n > git rev-parse --is-inside-work-tree # timeout=10\r\n\r\nFetching changes from the remote Git repository\r\n\r\n > git config remote.origin.url https://github.com/apache/incubator-mxnet.git # timeout=10\r\n\r\nFetching upstream changes from https://github.com/apache/incubator-mxnet.git\r\n\r\n > git --version # timeout=10\r\n\r\nusing GIT_ASKPASS to set credentials \r\n\r\n > git fetch --tags --progress https://github.com/apache/incubator-mxnet.git +refs/pull/9406/head:refs/remotes/origin/PR-9406-merge +refs/heads/master:refs/remotes/origin/master\r\n\r\nMerging remotes/origin/master commit 67cfbc863d9d05baa2362a82cb78e0acb569d6ba into PR head commit 17a93432434e87b83cfdcfd705fa7f515a220d40\r\n\r\n > git config core.sparsecheckout # timeout=10\r\n\r\n > git checkout -f 17a93432434e87b83cfdcfd705fa7f515a220d40\r\n\r\n > git merge 67cfbc863d9d05baa2362a82cb78e0acb569d6ba # timeout=10\r\n\r\n > git config core.sparsecheckout # timeout=10\r\n\r\n > git checkout -f 17a93432434e87b83cfdcfd705fa7f515a220d40\r\n\r\n\r\n\r\nGitHub has been notified of this commit’s build result\r\n\r\n\r\n\r\nhudson.plugins.git.GitException: Command ""git merge 67cfbc863d9d05baa2362a82cb78e0acb569d6ba"" returned status code 128:\r\n\r\nstdout: \r\n\r\nstderr: error: Merging is not possible because you have unmerged files.\r\n\r\nhint: Fix them up in the work tree, and then use \'git add/rm <file>\'\r\n\r\nhint: as appropriate to mark resolution and make a commit.\r\n\r\nfatal: Exiting because of an unresolved conflict.\r\n', '\r\nubuntu@jenkins:/var/lib/jenkins/workspace/cubator-mxnet_PR-9406-merge-IWOL2LWEYWILCMVJ327KHGMU27SZHSVFB3IKRA4SZBAZPPWMBTUA@script$ git status\r\nwarning: unable to access \'/home/ubuntu/.config/git/attributes\': Permission denied\r\nwarning: unable to access \'/home/ubuntu/.config/git/ignore\': Permission denied\r\nHEAD detached at 90a0eb03\r\nUnmerged paths:\r\n  (use ""git reset HEAD <file>..."" to unstage)\r\n  (use ""git add <file>..."" to mark resolution)\r\n\r\n\tadded by us:     python/mxnet/contrib/text/embedding.py\r\n\tadded by us:     python/mxnet/contrib/text/glossary.py\r\n\tadded by us:     python/mxnet/contrib/text/indexer.py\r\n\tadded by us:     python/mxnet/contrib/text/utils.py\r\n\tadded by us:     tests/python/unittest/test_contrib_text.py\r\n\r\nno changes added to commit (use ""git add"" and/or ""git commit -a"")\r\n']","['', '']",0,0
386,incubator-mxnet,1198,closed,travis sometimes suspend on threaded_engine_test.cc ,"sometimes the travis breaked in cpp_test job in pr with the log: 



but most of the time it is correct, so is due to the changed code or something else?
i met this problem a few times.
",,"['This can  be safely ignored.\n', 'be more specific, @hotpxl  and I have looked into it. we never be able to reproduced it locally, so not sure if this was due to travis hanging or some weird setups, so it can be ignored for now.\n']","['\n============= Test #4 ==============\ntests/cpp/threaded_engine_test.cc:198: IO operator pushed, should wait for 2 seconds.\nThe fox says 42\n']",[],0,0
387,incubator-mxnet,12294,closed,MXNET installation and library failing in R,"I'm trying to install MXNET in R and use the library.

**Step1**: # Install the package
install.packages(""drat"", repos=""https://cran.rstudio.com"")
drat:::addRepo(""dmlc"")
install.packages(""mxnet"")

**Comment in console:**
trying URL 'https://cran.rstudio.com/bin/macosx/el-capitan/contrib/3.5/drat_0.1.4.tgz'
Content type 'application/x-gzip' length 64654 bytes (63 KB)
==================================================
downloaded 63 KB


The downloaded binary packages are in
	/var/folders/rq/vv5bw20n3nv91pccc5krh55h0000gn/T//RtmpWtd63g/downloaded_packages

**Step2:**#install the library
library(mxnet)

**Error**
Error: package or namespace load failed for ‘mxnet’:
 .onLoad failed in loadNamespace() for 'mxnet', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object '/Library/Frameworks/R.framework/Versions/3.5/Resources/library/mxnet/libs/libmxnet.so':
  dlopen(/Library/Frameworks/R.framework/Versions/3.5/Resources/library/mxnet/libs/libmxnet.so, 10): Library not loaded: /usr/local/opt/openblas/lib/libopenblasp-r0.3.1.dylib
  Referenced from: /Library/Frameworks/R.framework/Versions/3.5/Resources/library/mxnet/libs/libmxnet.so
  Reason: image not found
In addition: Warning message:
replacing previous import ‘scales::viridis_pal’ by ‘viridis::viridis_pal’ when loading ‘DiagrammeR’ 
*****************************

**Below is my sessioninfo:**
R version 3.5.1 (2018-07-02)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Sierra 10.12.6

Matrix products: default
BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.18       pillar_1.3.0       compiler_3.5.1     RColorBrewer_1.1-2 influenceR_0.1.0   plyr_1.8.4         bindr_0.1.1        viridis_0.5.1      tools_3.5.1       
[10] digest_0.6.15      jsonlite_1.5       tibble_1.4.2       gtable_0.2.0       viridisLite_0.3.0  rgexf_0.15.3       pkgconfig_2.0.2    rlang_0.2.2        igraph_1.2.2      
[19] rstudioapi_0.7     yaml_2.2.0         bindrcpp_0.2.2     gridExtra_2.3      stringr_1.3.1      DiagrammeR_0.9.0   dplyr_0.7.6        htmlwidgets_1.2    grid_3.5.1        
[28] tidyselect_0.2.4   glue_1.3.0         R6_2.2.2           Rook_1.1-1         XML_3.98-1.16      ggplot2_3.0.0      purrr_0.2.5        magrittr_1.5       scales_1.0.0      
[37] htmltools_0.3.6    assertthat_0.2.0   colorspace_1.3-2   brew_1.0-6         stringi_1.2.4      visNetwork_2.0.4   lazyeval_0.2.1     munsell_0.5.0      crayon_1.3.4   
***********************************
Can you please help?
",Build R,"['@anirudhacharya ', '@mxnet-label-bot [R, Build, Question]', '@riddhidutta123 The issue is probably with the `openblas` version on your system. MXNet is trying to look for `/usr/local/opt/openblas/lib/libopenblasp-r0.3.1.dylib` on your system and is not able to find it. Please run the following commands in order, and then try `library(mxnet)` on your R console.\r\n\r\n```\r\nbrew upgrade openblas\r\nbrew  upgrade opencv\r\nln -sf /usr/local/opt/openblas/lib/libopenblasp-r0.3.2.dylib /usr/local/opt/openblas/lib/libopenblasp-r0.3.1.dylib\r\n```\r\n\r\nPlease let me know if this fixes your problem.\r\n\r\n@mxnet-label-bot [Pending Requester Info]', '@anirudhacharya It worked perfectly!!.\r\n\r\nThank you so much for your support. Really appreciate your help.\r\n\r\nBest regards\r\n', '@riddhidutta123 glad it worked out. please close the issue.\r\n\r\ncc @nswamy ', 'Thanks. Closing this issue.']",[],[],0,0
388,incubator-mxnet,11508,closed,【Question】Are there any examples for gradients clipping in gluon?,"This is what I guess. Is it right?

        trainer.allreduce_grads()
        with autograd.record():
            logits = model(input)
            loss = criterion(logits, target)
        loss.backward()

        grads = [i.grad(ctx) for i in model.params.values()]
        gluon.utils.clip_global_norm(grads, args.grad_clip)
        trainer.update(args.batch_size)",Gluon Modeling,"[""That's correct, though you may want to switch model.params to model.collect_params() to include the parameters of all children blocks too."", 'thanks', 'I compare the speed of grad clipping between pytorch(0.3.1) and mxnet-gluon(1.2.0) on a Titan X. Pytorch gets nearly 10  times faster than mxnet-gluon.\r\n\r\nmxnet:\r\n        grads = [i.grad(ctx) for i in model.collect_params().values() if i._grad is not None]\r\n        gluon.utils.clip_global_norm(grads, args.grad_clip)\r\npytorch:\r\n        nn.utils.clip_grad_norm(model.parameters(), args.grad_clip)\r\n\r\nAre there something wrong with my implementation?', ""@yukang2017 would you be able to open a separate issue for the performance issue? that way we can keep api usage separate from performance, and it can be tagged correctly for better community help. thanks!\r\n\r\nWith regards to how to perform gradient clipping with Gluon, another option is to specify gradient clipping as part of the `Optimizer` given to the `Trainer`. Although this will simply clip by value: potentially changing the direction of the gradient tensor and effecting different gradient tensors in different ways. So overall, `gluon.utils.clip_global_norm` is the best for maintaining direction and relative magnitudes of gradient tensors. Still, this is an example of how value gradient clipping can be done:\r\n\r\n```\r\nmxnet.gluon.Trainer(net.collect_params(), optimizer='sgd',\r\n                    optimizer_params={'learning_rate': 0.1, 'clip_gradient':5},\r\n                    kvstore='device') #for GPU\r\n```\r\n\r\nWhen elements of the gradient tensor are:\r\n* less than -5, they will be set to -5, \r\n* greater than +5, they will be set to +5."", ""@thomelane I will open a new issue. Thank you!\r\nI tested 'clip_gradient' in _mxnet.gluon.Trainer_ and torch.optim. The time cost is similar."", '@sandeep-krishnamurthy Please close this issue. Thx']",[],[],0,0
389,incubator-mxnet,5218,closed,core dumped when I try to compile mxnet0.9.3 with nnpack support WHY？,">>> import mxnet
libdc1394 error: Failed to initialize libdc1394
[01:20:36] /mnt/Mxnet/docker/mxnet93/dmlc-core/include/dmlc/logging.h:300: [01:20:36] src/operator/nnpack/nnpack_util.h:25: nnp_initialize failed status=51

Stack trace returned 48 entries:
[bt] (0) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.3-py2.7.egg/mxnet/libmxnet.so(_ZN5mxnet2op16NNPACKInitializeC1Ev+0x2fb) [0x7fb4ce55a17b]
[bt] (1) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.3-py2.7.egg/mxnet/libmxnet.so(+0x2517d6) [0x7fb4ce4ed7d6]
[bt] (2) /lib64/ld-linux-x86-64.so.2(+0x1010a) [0x7fb4d412c10a]
[bt] (3) /lib64/ld-linux-x86-64.so.2(+0x101f3) [0x7fb4d412c1f3]
[bt] (4) /lib64/ld-linux-x86-64.so.2(+0x14c30) [0x7fb4d4130c30]
[bt] (5) /lib64/ld-linux-x86-64.so.2(+0xffc4) [0x7fb4d412bfc4]
[bt] (6) /lib64/ld-linux-x86-64.so.2(+0x1437b) [0x7fb4d413037b]
[bt] (7) /lib/x86_64-linux-gnu/libdl.so.2(+0x102b) [0x7fb4d393602b]
[bt] (8) /lib64/ld-linux-x86-64.so.2(+0xffc4) [0x7fb4d412bfc4]
[bt] (9) /lib/x86_64-linux-gnu/libdl.so.2(+0x162d) [0x7fb4d393662d]
[bt] (10) /lib/x86_64-linux-gnu/libdl.so.2(dlopen+0x31) [0x7fb4d39360c1]
[bt] (11) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x741b) [0x7fb4d298341b]
[bt] (12) python(PyEval_EvalFrameEx+0x41d) [0x523f6d]
[bt] (13) python() [0x568b3a]
[bt] (14) python() [0x4c2604]
[bt] (15) python() [0x4d1c5c]
[bt] (16) python() [0x55f6db]
[bt] (17) python(PyEval_EvalFrameEx+0x98d) [0x5244dd]
[bt] (18) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (19) python(PyEval_EvalFrameEx+0x1a10) [0x525560]
[bt] (20) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (21) python(PyEval_EvalCode+0x32) [0x5b41e2]
[bt] (22) python(PyImport_ExecCodeModuleEx+0xaa) [0x5b429a]
[bt] (23) python() [0x5942af]
[bt] (24) python() [0x55642f]
[bt] (25) python() [0x556838]
[bt] (26) python() [0x556d9b]
[bt] (27) python() [0x569cd8]
[bt] (28) python(PyEval_CallObjectWithKeywords+0x6b) [0x4c8c8b]
[bt] (29) python(PyEval_EvalFrameEx+0x2958) [0x5264a8]
[bt] (30) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (31) python(PyEval_EvalCode+0x32) [0x5b41e2]
[bt] (32) python(PyImport_ExecCodeModuleEx+0xaa) [0x5b429a]
[bt] (33) python() [0x5942af]
[bt] (34) python() [0x465804]
[bt] (35) python() [0x55642f]
[bt] (36) python() [0x556838]
[bt] (37) python() [0x556c4b]
[bt] (38) python() [0x569c08]
[bt] (39) python(PyEval_CallObjectWithKeywords+0x6b) [0x4c8c8b]
[bt] (40) python(PyEval_EvalFrameEx+0x2958) [0x5264a8]
[bt] (41) python() [0x567d14]
[bt] (42) python(PyRun_InteractiveOneFlags+0x18c) [0x465a2d]
[bt] (43) python(PyRun_InteractiveLoopFlags+0xaa) [0x465b49]
[bt] (44) python(PyRun_AnyFileExFlags+0x37) [0x4661fe]
[bt] (45) python(Py_Main+0xb5e) [0x466d92]
[bt] (46) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fb4d3b5af45]
[bt] (47) python() [0x577c2e]

terminate called after throwing an instance of 'dmlc::Error'
  what():  [01:20:36] src/operator/nnpack/nnpack_util.h:25: nnp_initialize failed status=51

Stack trace returned 48 entries:
[bt] (0) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.3-py2.7.egg/mxnet/libmxnet.so(_ZN5mxnet2op16NNPACKInitializeC1Ev+0x2fb) [0x7fb4ce55a17b]
[bt] (1) /usr/local/lib/python2.7/dist-packages/mxnet-0.9.3-py2.7.egg/mxnet/libmxnet.so(+0x2517d6) [0x7fb4ce4ed7d6]
[bt] (2) /lib64/ld-linux-x86-64.so.2(+0x1010a) [0x7fb4d412c10a]
[bt] (3) /lib64/ld-linux-x86-64.so.2(+0x101f3) [0x7fb4d412c1f3]
[bt] (4) /lib64/ld-linux-x86-64.so.2(+0x14c30) [0x7fb4d4130c30]
[bt] (5) /lib64/ld-linux-x86-64.so.2(+0xffc4) [0x7fb4d412bfc4]
[bt] (6) /lib64/ld-linux-x86-64.so.2(+0x1437b) [0x7fb4d413037b]
[bt] (7) /lib/x86_64-linux-gnu/libdl.so.2(+0x102b) [0x7fb4d393602b]
[bt] (8) /lib64/ld-linux-x86-64.so.2(+0xffc4) [0x7fb4d412bfc4]
[bt] (9) /lib/x86_64-linux-gnu/libdl.so.2(+0x162d) [0x7fb4d393662d]
[bt] (10) /lib/x86_64-linux-gnu/libdl.so.2(dlopen+0x31) [0x7fb4d39360c1]
[bt] (11) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x741b) [0x7fb4d298341b]
[bt] (12) python(PyEval_EvalFrameEx+0x41d) [0x523f6d]
[bt] (13) python() [0x568b3a]
[bt] (14) python() [0x4c2604]
[bt] (15) python() [0x4d1c5c]
[bt] (16) python() [0x55f6db]
[bt] (17) python(PyEval_EvalFrameEx+0x98d) [0x5244dd]
[bt] (18) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (19) python(PyEval_EvalFrameEx+0x1a10) [0x525560]
[bt] (20) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (21) python(PyEval_EvalCode+0x32) [0x5b41e2]
[bt] (22) python(PyImport_ExecCodeModuleEx+0xaa) [0x5b429a]
[bt] (23) python() [0x5942af]
[bt] (24) python() [0x55642f]
[bt] (25) python() [0x556838]
[bt] (26) python() [0x556d9b]
[bt] (27) python() [0x569cd8]
[bt] (28) python(PyEval_CallObjectWithKeywords+0x6b) [0x4c8c8b]
[bt] (29) python(PyEval_EvalFrameEx+0x2958) [0x5264a8]
[bt] (30) python(PyEval_EvalCodeEx+0x2b1) [0x555551]
[bt] (31) python(PyEval_EvalCode+0x32) [0x5b41e2]
[bt] (32) python(PyImport_ExecCodeModuleEx+0xaa) [0x5b429a]
[bt] (33) python() [0x5942af]
[bt] (34) python() [0x465804]
[bt] (35) python() [0x55642f]
[bt] (36) python() [0x556838]
[bt] (37) python() [0x556c4b]
[bt] (38) python() [0x569c08]
[bt] (39) python(PyEval_CallObjectWithKeywords+0x6b) [0x4c8c8b]
[bt] (40) python(PyEval_EvalFrameEx+0x2958) [0x5264a8]
[bt] (41) python() [0x567d14]
[bt] (42) python(PyRun_InteractiveOneFlags+0x18c) [0x465a2d]
[bt] (43) python(PyRun_InteractiveLoopFlags+0xaa) [0x465b49]
[bt] (44) python(PyRun_AnyFileExFlags+0x37) [0x4661fe]
[bt] (45) python(Py_Main+0xb5e) [0x466d92]
[bt] (46) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fb4d3b5af45]
[bt] (47) python() [0x577c2e]

Aborted (core dumped)",,"['This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!', ""@szha I have same issue here, please re-open. I can build mxnet from the source without error but trying to import mxnet inside python, i get the error:\r\n\r\n[12:43:09] /home/lemma/mxnet/dmlc-core/include/dmlc/logging.h:308: [12:43:09] src/operator/nnpack/nnpack_util.h:43: nnp_initialize failed status=51\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /home/lemma/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op16NNPACKInitializeC1Ev+0x2fb) [0x7f25d2ced66b]\r\n[bt] (1) /home/lemma/mxnet/python/mxnet/../../lib/libmxnet.so(+0x66d0a6) [0x7f25d2a750a6]\r\n[bt] (2) /lib64/ld-linux-x86-64.so.2(+0x102da) [0x7f25fc9532da]\r\n[bt] (3) /lib64/ld-linux-x86-64.so.2(+0x103c3) [0x7f25fc9533c3]\r\n[bt] (4) /lib64/ld-linux-x86-64.so.2(+0x14e00) [0x7f25fc957e00]\r\n[bt] (5) /lib64/ld-linux-x86-64.so.2(+0x10194) [0x7f25fc953194]\r\n[bt] (6) /lib64/ld-linux-x86-64.so.2(+0x1454b) [0x7f25fc95754b]\r\n[bt] (7) /lib/x86_64-linux-gnu/libdl.so.2(+0x102b) [0x7f25fc14502b]\r\n[bt] (8) /lib64/ld-linux-x86-64.so.2(+0x10194) [0x7f25fc953194]\r\n[bt] (9) /lib/x86_64-linux-gnu/libdl.so.2(+0x162d) [0x7f25fc14562d]\r\n\r\nterminate called after throwing an instance of 'dmlc::Error'\r\n  what():  [12:43:09] src/operator/nnpack/nnpack_util.h:43: nnp_initialize failed status=51\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /home/lemma/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op16NNPACKInitializeC1Ev+0x2fb) [0x7f25d2ced66b]\r\n[bt] (1) /home/lemma/mxnet/python/mxnet/../../lib/libmxnet.so(+0x66d0a6) [0x7f25d2a750a6]\r\n[bt] (2) /lib64/ld-linux-x86-64.so.2(+0x102da) [0x7f25fc9532da]\r\n[bt] (3) /lib64/ld-linux-x86-64.so.2(+0x103c3) [0x7f25fc9533c3]\r\n[bt] (4) /lib64/ld-linux-x86-64.so.2(+0x14e00) [0x7f25fc957e00]\r\n[bt] (5) /lib64/ld-linux-x86-64.so.2(+0x10194) [0x7f25fc953194]\r\n[bt] (6) /lib64/ld-linux-x86-64.so.2(+0x1454b) [0x7f25fc95754b]\r\n[bt] (7) /lib/x86_64-linux-gnu/libdl.so.2(+0x102b) [0x7f25fc14502b]\r\n[bt] (8) /lib64/ld-linux-x86-64.so.2(+0x10194) [0x7f25fc953194]\r\n[bt] (9) /lib/x86_64-linux-gnu/libdl.so.2(+0x162d) [0x7f25fc14562d]""]",[],[],0,0
390,incubator-mxnet,329,closed,"[R, Windows] Process Tracking","- [ ] Have a configure.win in the src to search the library, put things(libmxnet.dll) in right position
- [ ] Proper error message to tell user what to install when things do not exist.
- [ ] Ideally only compile the  x64 version.
- [ ] A Makefile option winRpack, to pack a binary distributable version of package.
  - We can ship libmxnet.dll, but need to assume all thirdparty dlls are on path.
  - It is also fine to assume libmxnet.dll is on path, if we treat it as a library(maybe easier for us to go CRAN).
",R,"['close due to a bit outdated, reopen later\n']",[],[],0,0
391,incubator-mxnet,6796,closed,How to debug a C++ layer,"Hi,
I am new to Mxnet. I am interested in implementing a new C++ layer, but I am wondering how to debug during the process. Do I have to recompile the whole framework to test it? Or is there any other simpler way. It seems like recompiling takes way too much time. I did not find any useful info in the tutorial. Hope to get some hints. Thanks.
@mli @piiswrong @tqchen ",,"['If you just want to print debug log, just set DEBUG=1 in comfig.mk, then recompile the whole framework.', '@KangBing What I meant was compiling the whole framework takes too much time. Is there any way to compile only the necessary file, like a minimum package, to test the new layer.', ""@lovedl I'm not sure. But you can modify the `Makefile`, don't delete `*.o` file after compile. If you recompile, the compiler only compile the modified file and relink."", '@lovedl , you can just change the code and make, gcc will only re-compile the file you changed and those related with it\r\n\r\nif some unexpected problem  appear, try `make clean`, and make to re-compile all frame work\r\n\r\nbesides, \r\n1. `make -j  $(nproc) YOU_OPTIONS` will compile parallelly\r\n2. `gdb --args python YOU_ARGS` can debug with gdb']",[],[],0,0
392,incubator-mxnet,12497,closed,Onnx arange op not supported!,"I'm using mxnet 1.3.0 and onnx 1.3, No conversion function registered for op type _arange yet, so the arange function have not been surported?",ONNX,"['@lizhen2017 thank you for the question\r\n\r\n@mxnet-label-bot [ONNX, Question]', '@lizhen2017 thanks for reporting this issue. \r\nONNX doesnt have specific ""arange"" operator. https://github.com/onnx/onnx/blob/master/docs/Operators.md\r\nSo, it\'s not yet supported with import and export with MXNet.\r\n', '@lizhen2017 could you please close this issue if your question has been addressed?']",[],[],0,0
393,incubator-mxnet,14245,closed,visualize with global_pooling and no kernel crashes.,"Using Python. Trying to visualize with global_pooling and no kernel crashes.

The visualization code fails when trying to run:

on the layer below:

while it works on when setting a kernel:


labels: Bug",Bug,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Bug', 'relates to: https://github.com/apache/incubator-mxnet/issues/7814 https://github.com/apache/incubator-mxnet/issues/2544', '@mxnet-label-bot add [Bug]']","['\r\ngraph = mx.viz.plot_network(symbol)\r\n', ""\r\nsymbol = mx.sym.Pooling(data = data, global_pool = True, pool_type = 'avg') \r\n"", ""\r\nsymbol = mx.sym.Pooling(data = data, global_pool = True, pool_type = 'avg', kernel = (1, 1)) \r\n""]",[],0,0
394,incubator-mxnet,2715,closed,MNISTIter call getdata method throw error,"I try to use MNISTIter to get each bacth data from it. I read the document in the corresponding page. It suppose to use DataIter's getdata() method. Why it throw a error when I use this way. Could any one explain why it happen please?  
The error message is below:
Traceback (most recent call last):
  File ""testMNIST.py"", line 58, in <module>
    X_test_batch = testIter.getdata()
  File ""C:\Python34\lib\site-packages\mxnet-0.7.0-py3.4.egg\mxnet\io.py"", line 504, in getdata
    check_call(_LIB.MXDataIterGetData(self.handle, ctypes.byref(hdl)))
OSError: exception: access violation reading 0x0000000000000000
",,[],[],[],0,0
395,incubator-mxnet,4960,closed,Variable batch size ,"Hi, can we have some feature supporting varaible batch size? When doing lstm validation, I need to fill those buckets with duplicated examples if the number of example is not enough.
Alough I can bypass this issue by flating each bucket data with speical designed bucket key, is there any more elegant solution? ",,"['you can use Module.reshape', 'any example or doc about this?', 'Some related discussions can be found in https://github.com/apache/incubator-mxnet/issues/2294.\r\n\r\nAnd a good example can be found in the [Faster RCNN example](https://github.com/apache/incubator-mxnet/tree/master/example/rcnn), where a [`MutableModule`](https://github.com/apache/incubator-mxnet/blob/master/example/rcnn/rcnn/core/module.py#L30) is defined which supports variable input data.', 'Also with the Gluon API, `Block`s support variable batch sizes out of the box.']",[],[],0,0
396,incubator-mxnet,2699,closed,what is the meaning of ouput in image_segmentation.py,"

  What does output mean?
the softmax loss output or the first layers output?
If not softmax loss output,how can i get it?
",,"[""It's softmax activation. You can compute log likelihood using activation and label\n"", 'i got it now ,thanks\n', 'I found that the GPU memory usage increase in the line: \r\nexector = fcnxs.bind(ctx, fcnxs_args ,args_grad=None, grad_req=""null"", aux_states=fcnxs_args)\r\nbut it seems that the GPU memory is not released, is there any way to address the problem? Also, I wonder where the feature maps  stored.', 'Regarding bind(), the memory is expected to increase, as MXNet is building computation graph based on symbols and allocating resources for it. \n\nOn 2017年4月6日, at 08:24, KeLipeng <notifications@github.com> wrote:\n\nI found that the GPU memory usage increase in the line:\nexector = fcnxs.bind(ctx, fcnxs_args ,args_grad=None, grad_req=""null"", aux_states=fcnxs_args)\nbut it seems that the GPU memory is not released, is there any way to address the problem? Also, I wonder where the feature maps stored.\n\n—\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n', 'What confused me is the way MXNet allocating GPU memory, I was running a fcnxs example, and found that it use 777MB to store the weights/bias params, and 528 to store the gradient, but when I run the bind()   function, it use another 862MB GPU memory. I looked into the exector, and found that it stores the weight/bias params and the gradient params and they share the same id with the network params and gradient, so what does the extra 862MB GPU memory store? Does It store the feature maps? If so, how can I check the feature maps?']","['\nfcnxs, fcnxs_args, fcnxs_auxs = mx.model.load_checkpoint(model_previx, epoch)\nfcnxs_args[""data""] = mx.nd.array(get_data(img), ctx)\ndata_shape = fcnxs_args[""data""].shape\nlabel_shape = (1, data_shape[2]*data_shape[3])\nfcnxs_args[""softmax_label""] = mx.nd.empty(label_shape, ctx)\nexector = fcnxs.bind(ctx, fcnxs_args ,args_grad=None, grad_req=""null"", aux_states=fcnxs_args)\nexector.forward(is_train=False)\noutput = exector.outputs[0]\n']",[],0,0
397,incubator-mxnet,8514,closed,upload result in segnet,"![label2](https://user-images.githubusercontent.com/13029886/32312590-9120270e-bfd9-11e7-9fdb-de29aece2422.png)
![res2](https://user-images.githubusercontent.com/13029886/32312591-9159ea7a-bfd9-11e7-8658-e3fa1ce90bf2.png)
",,[],[],[],0,0
398,incubator-mxnet,14426,closed,mx.random.seed with ctx failures on a gpu build when run with cpu context,"Minimum reproducible example. 


To reproduce, this will require the exception handling support for waitall in this PR: https://github.com/apache/incubator-mxnet/pull/14397 . This issue was found because of CI failures when running test_random.py on windows. It was hidden earlier because waitall didnt have exception rethrow support. This issue may have been around since the PR was added: #10367 

Currently working on fixing this.",Backend Bug,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Bug']","[""\r\nimport mxnet as mx\r\n\r\ndef set_seed_variously_for_context(ctx, init_seed, num_init_seeds, final_seed):\r\n    end_seed = init_seed + num_init_seeds\r\n    for seed in range(init_seed, end_seed):\r\n        mx.random.seed(seed, ctx=ctx)\r\n    z = mx.random.seed(seed, ctx=ctx)\r\n    return end_seed\r\n\r\ndtype = 'float32'\r\n\r\nsamples_imp = []\r\nsamples_sym = []\r\nctx = mx.cpu()\r\nshape = (200, 200)\r\nparams = {'low': -1.5, 'high': 3.0}\r\nparams.update(shape=shape, dtype=dtype)\r\nseed = set_seed_variously_for_context(ctx, 1, 1, 1234)\r\nmx.nd.waitall()\r\n""]",[],0,0
399,incubator-mxnet,7094,closed,Save a mxnet model to keras and vice versa,Is there a function or some sample code to save a mxnet model as a keras model (such as .h5) or load a keras model into mxnet? ,,"['i am looking for the same thing!! please let me know if you find any!!!', 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!\nAlso, do please check out our [forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) for general ""how-to"" questions.']",[],[],0,0
400,incubator-mxnet,7472,closed,continuously train rnn - training data stream?,"## Question

Usually, a neural network is trained by using a training, validation and test set. 
Having a continuous series of data, an event (new training data) occurring every 1-5 seconds, is it possible to continuously train (update) a recurrent neural network using mxnet? I don't need to care to reuse previous (training) data points: I just want to update the weights slightly(!) on each new event.

It's for a behaviour/game like system: depending on the (expressed/intentional) behaviour of the players (the features), the output of the system should be estimated and continuously adapted (for further processing). The system has to learn on the way, and being able to cope with, to a certain extend, changing player behaviour and it needs to remember certain patterns from weeks and if possible, months, ago. (I'd probably be mainly an LSTM.)

Storing all data and retrain the system on that data is close to impossible because:
1. I estimate there's about 10-100GB of data per day (will be varying)
2. retraining every time, let's say, 10 seconds, on all existing data would take too long.

I want a system that continuously trains itself on the real data, not splitting into training/testing/validation sets:
1. The training set is the real data, comparing the actual state of the system with the prediction previously made
2. There's not validation, besides the fact that the system validates itself
3. Testing is done on every new event. The predictive power will be continuously determined.

Can this be done with mxnet, having a training data stream?

(In dl4j, there's https://deeplearning4j.org/usingrnns#test-time-predictions-one-step-at-a-time , and one can update the model with fit, one step at a time - having a data iterator that runs a fit every x seconds)

## Environment info
This is not really relevant, but well, I don't mind providing it :)

Operating System:


Compiler: ?

Package used (Python/R/Scala/Julia): R

MXNet version:
",R,"['You might need to build your own data and feature engineering pipeline to digest the streamed data, convert them to batches and feed them into the neural network. ', 'Hi @kurt-o-sys ,\r\nThe answer to your query is yes. However, you will need to set your own training pipelines using custom iterators which can read a batch of streaming data at some intervals and update the model. You can also customize your training loop to checkpoint and pick up from a particular point to retrain.\r\nHere is an example for writing customized training loops.\r\nYou need to write your own training loop. Here is an example: https://github.com/dmlc/mxnet-gtc-tutorial/blob/master/tutorial.ipynb\r\n\r\nAlso, please feel free to open any follow up questions on discuss.mxnet.io as it gets wider eyeballs and more prompt inputs.\r\n\r\n@sandeep-krishnamurthy Could you please close this issue.']","['\r\n$ uname -ar\r\nLinux flipflap 4.4.0-57-generic #78-Ubuntu SMP Fri Dec 9 23:50:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\r\n', '\r\n> packageVersion(""mxnet"")\r\n[1] ‘0.10.1’\r\n> sessionInfo()\r\nR version 3.4.1 (2017-06-30)\r\nPlatform: x86_64-pc-linux-gnu (64-bit)\r\nRunning under: Linux Mint 18\r\n\r\nMatrix products: default\r\nBLAS: /usr/lib/openblas-base/libblas.so.3\r\nLAPACK: /usr/lib/libopenblasp-r0.2.18.so\r\n\r\nlocale:\r\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8     LC_MONETARY=de_BE.UTF-8   \r\n [6] LC_MESSAGES=en_US.UTF-8    LC_PAPER=de_BE.UTF-8       LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C            \r\n[11] LC_MEASUREMENT=de_BE.UTF-8 LC_IDENTIFICATION=C       \r\n\r\nattached base packages:\r\n[1] stats     graphics  grDevices utils     datasets  methods   base     \r\n\r\nother attached packages:\r\n[1] mxnet_0.10.1 httr_1.2.1   jsonlite_1.5\r\n\r\nloaded via a namespace (and not attached):\r\n [1] Rcpp_0.12.12       compiler_3.4.1     RColorBrewer_1.1-2 influenceR_0.1.0   plyr_1.8.4         bindr_0.1          viridis_0.4.0     \r\n [8] tools_3.4.1        digest_0.6.12      tibble_1.3.3       gtable_0.2.0       viridisLite_0.2.0  rgexf_0.15.3       pkgconfig_2.0.1   \r\n[15] rlang_0.1.1        igraph_1.1.2       rstudioapi_0.6     curl_2.4           bindrcpp_0.2       gridExtra_2.2.1    stringr_1.2.0     \r\n[22] DiagrammeR_0.9.0   dplyr_0.7.2        htmlwidgets_0.9    grid_3.4.1         glue_1.1.1         R6_2.2.2           Rook_1.1-1        \r\n[29] XML_3.98-1.9       ggplot2_2.2.1      magrittr_1.5       codetools_0.2-15   scales_0.4.1       htmltools_0.3.6    assertthat_0.1    \r\n[36] colorspace_1.3-2   brew_1.0-6         stringi_1.1.5      visNetwork_2.0.1   lazyeval_0.2.0     munsell_0.4.3    \r\n']",[],0,0
401,incubator-mxnet,9989,closed,Cannot train example gluon style transfer,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
Cannot train gluon style transfer, needs to be outside of autograd.record() block or need to call backward.

## Environment info (Required)
----------Python Info----------
('Version      :', '2.7.10')
('Compiler     :', 'GCC 4.1.2')
('Build        :', ('default', 'Jun 29 2015 12:45:31'))
('Arch         :', ('64bit', 'ELF'))
------------Pip Info-----------
No corresponding pip install for current python.
----------MXNet Info-----------
/asset/common/software/thirdparty/mxnet/1.0.0-build1/python2.7/mxnet/optimizer.py:136: UserWarning: WARNING: New optimizer mxnet.optimizer.NAG is overriding existing optimizer mxnet.optimizer.NAG
  Optimizer.opt_registry[name].__name__))
('Version      :', '1.1.0')
('Directory    :', '/asset/common/software/thirdparty/mxnet/1.0.0-build1/python2.7/mxnet')
Hashtag not found. Not installed from pre-built package.
----------System Info----------
('Platform     :', 'Linux-3.10.105-1.el6.elrepo.x86_64-x86_64-with-centos-6.2-Final')
('system       :', 'Linux')
('node         :', 'bladerunner')                                                                                                                                                                                                            
('release      :', '3.10.105-1.el6.elrepo.x86_64')                                                                                                                                                                                           
('version      :', '#1 SMP Fri Feb 10 10:48:08 EST 2017')                                                                                                                                                                                    
----------Hardware Info----------                                                                                                                                                                                                            
('machine      :', 'x86_64')                                                                                                                                                                                                                 
('processor    :', 'x86_64')                                                                                                                                                                                                                 
Architecture:          x86_64                                                                                                                                                                                                                
CPU op-mode(s):        32-bit, 64-bit                                                                                                                                                                                                        
Byte Order:            Little Endian                                                                                                                                                                                                         
CPU(s):                12                                                                                                                                                                                                                    
On-line CPU(s) list:   0-11                                                                                                                                                                                                                  
Thread(s) per core:    1                                                                                                                                                                                                                     
Core(s) per socket:    6                                                                                                                                                                                                                     
Socket(s):             2                                                                                                                                                                                                                     
NUMA node(s):          2                                                                                                                                                                                                                     
Vendor ID:             GenuineIntel                                                                                                                                                                                                          
CPU family:            6                                                                                                                                                                                                                     
Model:                 63                                                                                                                                                                                                                    
Model name:            Intel(R) Xeon(R) CPU E5-2609 v3 @ 1.90GHz                                                                                                                                                                             
Stepping:              2                                                                                                                                                                                                                     
CPU MHz:               1900.000                                                                                                                                                                                                              
BogoMIPS:              3796.70                                                                                                                                                                                                               
Virtualization:        VT-x                                                                                                                                                                                                                  
L1d cache:             32K                                                                                                                                                                                                                   
L1i cache:             32K                                                                                                                                                                                                                   
L2 cache:              256K                                                                                                                                                                                                                  
L3 cache:              15360K                                                                                                                                                                                                                
NUMA node0 CPU(s):     0-5                                                                                                                                                                                                                   
NUMA node1 CPU(s):     6-11                                                                                                                                                                                                                  
----------Network Test----------                                                                                                                                                                                                             
Setting timeout: 10
Error open MXNet: https://github.com/apache/incubator-mxnet, <urlopen error timed out>, DNS finished in 0.0260591506958 sec.
Error open PYPI: https://pypi.python.org/pypi/pip, <urlopen error [Errno 101] Network is unreachable>, DNS finished in 0.170429944992 sec.
Error open FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, <urlopen error [Errno 101] Network is unreachable>, DNS finished in 0.204452037811 sec.
Error open Conda: https://repo.continuum.io/pkgs/free/, <urlopen error [Errno 101] Network is unreachable>, DNS finished in 0.154680967331 sec.
Error open Gluon Tutorial(en): http://gluon.mxnet.io, <urlopen error [Errno 101] Network is unreachable>, DNS finished in 0.381160974503 sec.
Error open Gluon Tutorial(cn): https://zh.gluon.ai, <urlopen error [Errno 101] Network is unreachable>, DNS finished in 0.432467937469 sec.


Package used (Python/R/Scala/Julia):
Python

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): GCC-4.8.5 on Centos 6.2

MXNet commit hash:
b73c57c526396d6485bdf65986e3819c54eb7bd9


Build config:



## Error Message:



## Minimum reproducible example
Run the main.py in 

https://github.com/apache/incubator-mxnet/tree/master/example/gluon/style_transfer

as follows

main.py train --dataset ~/dev/coco/dataset/ --style-folder images/styles --save-model-dir models

after download the coco dataset and the style images

## Steps to reproduce

1. Install mxnet
2. get the installed version into the environment
3. cd example/gluon/style_transfer/
4. python main.py train --dataset ~/dev/coco/dataset/ --style-folder images/styles --save-model-dir models


## What have you tried to solve it?

1. move https://github.com/apache/incubator-mxnet/blob/master/example/gluon/style_transfer/main.py#L82
2. to between L79 and L80
3. Model will train but produces bad result
",Example Gluon,"['@zhanghang1989 Do you have any input?', ""Hi @samhodge , you shouldn't move L82 out of autograd.record scope, because the gradient of siamese network won't back-propagate. I am testing the code and will get back to you."", '@piiswrong Need some help about API changes. \r\nIn the style transfer example, the `set_data()` function was okay for back-propagation, but the code recently broke. Is there any recent update break this, any solutions?\r\n- Error message:\r\n```\r\nmxnet.base.MXNetError: [19:08:27] src/imperative/imperative.cc:192: Check failed: AGInfo::IsNone(*(outputs [i])) Assigning to NDArrays that are already in a computational graph will cause undefined behavior when evaluating gradients. Please call backward first to clear the graph or do this out side of a record section. \r\n```\r\n- Link to the code:\r\nhttps://github.com/apache/incubator-mxnet/blob/master/example/gluon/style_transfer/net.py#L252', ""@zhanghang1989 Thanks for looking into this. I realised that moving L82 out of the autorecord messed up the resulting model, I was hoping to train a symbolic model, but I couldn't even train the original model. I guess we will wait to hear back from @piiswrong ."", 'May I ask if this has been solved yet? I have encountered the same error when I want to train the network.', 'I will look into it and get back to you. ', 'Thanks', 'Did anyone make any progress on this issue ', 'Thanks for following up! Sorry for the delay. I have fixed the training in PR https://github.com/apache/incubator-mxnet/pull/11044 , will update the pretrained model.', 'The pretrained model is ready now. It will be merged soon. Thanks again for your patient and interest in this work! ', 'Closing\r\n@samhodge Please reopen or file new issue if this is still unresolved', 'It seems that it is no longer a symbolic model, I was hoping that I would be able to apply a texture to an image of any size, is there no way to save a symbolic network?', 'The gluon interface enables applying to image with any size. This model is not hybridizable due to lack of some operations.', 'Thanks for the swift response @zhanghang1989 \r\n\r\nI was hoping to serialise the model and run in C++ as a hybrid model.\r\n\r\nDo you have any suggestions as how to run the model in C++, besides pybind11?', 'The main problem stops hybridizing is the Gram Matrix calculation, which reads the shape. https://github.com/zhanghang1989/MXNet-Gluon-Style-Transfer/blob/master/net.py#L159-L164', 'Got it. I guess I can just serialise the model for a large resolution and just downsample for some anti aliasing. It’s a pity a hybrid model would have been ideal.']","['\r\n# Licensed to the Apache Software Foundation (ASF) under one\r\n# or more contributor license agreements.  See the NOTICE file\r\n# distributed with this work for additional information\r\n# regarding copyright ownership.  The ASF licenses this file\r\n# to you under the Apache License, Version 2.0 (the\r\n# ""License""); you may not use this file except in compliance\r\n# with the License.  You may obtain a copy of the License at\r\n#\r\n#   http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing,\r\n# software distributed under the License is distributed on an\r\n# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\r\n# KIND, either express or implied.  See the License for the\r\n# specific language governing permissions and limitations\r\n# under the License.\r\n\r\n#-------------------------------------------------------------------------------\r\n#  Template configuration for compiling mxnet\r\n#\r\n#  If you want to change the configuration, please use the following\r\n#  steps. Assume you are on the root directory of mxnet. First copy the this\r\n#  file so that any local changes will be ignored by git\r\n#\r\n#  $ cp make/config.mk .\r\n#\r\n#  Next modify the according entries, and then compile by\r\n#\r\n#  $ make\r\n#\r\n#  or build in parallel with 8 threads\r\n#\r\n#  $ make -j8\r\n#-------------------------------------------------------------------------------\r\n\r\n#---------------------\r\n# choice of compiler\r\n#--------------------\r\n\r\nexport CC = gcc\r\nexport CXX = g++\r\nexport NVCC = nvcc\r\n\r\n# whether compile with options for MXNet developer\r\nDEV = 0\r\n\r\n# whether compile with debug\r\nDEBUG = 0\r\n\r\n# whether compile with profiler\r\nUSE_PROFILER =\r\n\r\n# whether to turn on segfault signal handler to log the stack trace\r\nUSE_SIGNAL_HANDLER =\r\n\r\n# the additional link flags you want to add\r\nADD_LDFLAGS = -L /asset/common/software/thirdparty/cudnn/5.1-build1/cuda/lib64/ -L /asset/common/software/thirdparty/cuda/8.0.61-build1/lib64\r\n\r\n# the additional compile flags you want to add\r\nADD_CFLAGS = -I /asset/common/software/thirdparty/mkl/2018.0.128-build2/mkl/include/ -I /asset/common/software/thirdparty/cudnn/5.1-build1/cuda/include/\r\n\r\n#---------------------------------------------\r\n# matrix computation libraries for CPU/GPU\r\n#---------------------------------------------\r\n\r\n# whether use CUDA during compile\r\nUSE_CUDA = 1\r\n\r\n# add the path to CUDA library to link and compile flag\r\n# if you have already add them to environment variable, leave it as NONE\r\n# USE_CUDA_PATH = /usr/local/cuda\r\nUSE_CUDA_PATH = /asset/common/software/thirdparty/cuda/8.0.61-build1/\r\n\r\n# whether to enable CUDA runtime compilation\r\nENABLE_CUDA_RTC = 1\r\n\r\n# whether use CuDNN R3 library\r\nUSE_CUDNN = 1\r\n\r\n#whether to use NCCL library\r\nUSE_NCCL = 0\r\n#add the path to NCCL library\r\nUSE_NCCL_PATH = NONE\r\n\r\n# whether use opencv during compilation\r\n# you can disable it, however, you will not able to use\r\n# imbin iterator\r\nUSE_OPENCV = 0\r\n\r\n#whether use libjpeg-turbo for image decode without OpenCV wrapper\r\nUSE_LIBJPEG_TURBO = 0\r\n#add the path to libjpeg-turbo library\r\nUSE_LIBJPEG_TURBO_PATH = NONE\r\n\r\n# use openmp for parallelization\r\nUSE_OPENMP = 1\r\n\r\n# MKL ML Library for Intel CPU/Xeon Phi\r\n# Please refer to MKL_README.md for details\r\n\r\n# MKL ML Library folder, need to be root for /usr/local\r\n# Change to User Home directory for standard user\r\n# For USE_BLAS!=mkl only\r\nMKLML_ROOT=/asset/common/software/thirdparty/mkl/2018.0.128-build2/\r\n\r\n# whether use MKL2017 library\r\nUSE_MKL2017 = 0\r\n\r\n# whether use MKL2017 experimental feature for high performance\r\n# Prerequisite USE_MKL2017=1\r\nUSE_MKL2017_EXPERIMENTAL = 0\r\n\r\n# whether use NNPACK library\r\nUSE_NNPACK = 0\r\n\r\n# choose the version of blas you want to use\r\n# can be: mkl, blas, atlas, openblas\r\n# in default use atlas for linux while apple for osx\r\nUNAME_S := $(shell uname -s)\r\nifeq ($(UNAME_S), Darwin)\r\nUSE_BLAS = apple\r\nelse\r\nUSE_BLAS = mkl\r\nendif\r\n\r\n# whether use lapack during compilation\r\n# only effective when compiled with blas versions openblas/apple/atlas/mkl\r\nUSE_LAPACK = 1\r\n\r\n# path to lapack library in case of a non-standard installation\r\nUSE_LAPACK_PATH =\r\n\r\n# add path to intel library, you may need it for MKL, if you did not add the path\r\n# to environment variable\r\nUSE_INTEL_PATH = /asset/common/software/thirdparty/mkl/2018.0.128-build2/\r\n\r\n# If use MKL only for BLAS, choose static link automatically to allow python wrapper\r\nifeq ($(USE_BLAS), mkl)\r\nUSE_STATIC_MKL = 1\r\nelse\r\nUSE_STATIC_MKL = NONE\r\nendif\r\n\r\n#----------------------------\r\n# Settings for power and arm arch\r\n#----------------------------\r\nARCH := $(shell uname -a)\r\nifneq (,$(filter $(ARCH), armv6l armv7l powerpc64le ppc64le aarch64))\r\n\tUSE_SSE=0\r\nelse\r\n\tUSE_SSE=1\r\nendif\r\n\r\n#----------------------------\r\n# distributed computing\r\n#----------------------------\r\n\r\n# whether or not to enable multi-machine supporting\r\nUSE_DIST_KVSTORE = 0\r\n\r\n# whether or not allow to read and write HDFS directly. If yes, then hadoop is\r\n# required\r\nUSE_HDFS = 0\r\n\r\n# path to libjvm.so. required if USE_HDFS=1\r\nLIBJVM=$(JAVA_HOME)/jre/lib/amd64/server\r\n\r\n# whether or not allow to read and write AWS S3 directly. If yes, then\r\n# libcurl4-openssl-dev is required, it can be installed on Ubuntu by\r\n# sudo apt-get install -y libcurl4-openssl-dev\r\nUSE_S3 = 0\r\n\r\n#----------------------------\r\n# performance settings\r\n#----------------------------\r\n# Use operator tuning\r\nUSE_OPERATOR_TUNING = 1\r\n\r\n# Use gperftools if found\r\nUSE_GPERFTOOLS = 1\r\n\r\n# Use JEMalloc if found, and not using gperftools\r\nUSE_JEMALLOC = 1\r\n\r\n#----------------------------\r\n# additional operators\r\n#----------------------------\r\n\r\n# path to folders containing projects specific operators that you don\'t want to put in src/operators\r\nEXTRA_OPERATORS =\r\n\r\n#----------------------------\r\n# other features\r\n#----------------------------\r\n\r\n# Create C++ interface package\r\nUSE_CPP_PACKAGE = 1\r\n\r\n#----------------------------\r\n# plugins\r\n#----------------------------\r\n\r\n# whether to use caffe integration. This requires installing caffe.\r\n# You also need to add CAFFE_PATH/build/lib to your LD_LIBRARY_PATH\r\n# CAFFE_PATH = $(HOME)/caffe\r\n# MXNET_PLUGINS += plugin/caffe/caffe.mk\r\n\r\n# WARPCTC_PATH = $(HOME)/warp-ctc\r\n# MXNET_PLUGINS += plugin/warpctc/warpctc.mk\r\n\r\n# whether to use sframe integration. This requires build sframe\r\n# git@github.com:dato-code/SFrame.git\r\n# SFRAME_PATH = $(HOME)/SFrame\r\n# MXNET_PLUGINS += plugin/sframe/plugin.mk\r\n', '\r\n samh@bladerunner ~/dev/mxnet/example/gluon/style_transfer/ run python with mxnet pillow/latest : main.py train --dataset ~/dev/coco/dataset/ --style-folder images/styles --save-model-dir models\r\n/asset/common/software/thirdparty/mxnet/1.0.0-build1/python2.7/mxnet/optimizer.py:136: UserWarning: WARNING: New optimizer mxnet.optimizer.NAG is overriding existing optimizer mxnet.optimizer.NAG                                          \r\n  Optimizer.opt_registry[name].__name__))                                                                                                                                                                                                    \r\n(\'len(style_loader):\', 21)                                                                                                                                                                                                                   \r\n(\'style_model:\', Net(                                                                                                                                                                                                                        \r\n  (gram): GramMatrix(                                                                                                                                                                                                                        \r\n                                                                                                                                                                                                                                             \r\n  )                                                                                                                                                                                                                                          \r\n  (model): Sequential(                                                                                                                                                                                                                       \r\n    (0): Sequential(\r\n      (0): ConvLayer(\r\n        (pad): ReflectancePadding(\r\n        \r\n        )\r\n        (conv2d): Conv2D(3 -> 64, kernel_size=(7, 7), stride=(1, 1))\r\n      )\r\n      (1): InstanceNorm(eps=1e-05, in_channels=64)\r\n      (2): Activation(relu)\r\n      (3): Bottleneck(\r\n        (conv_block): Sequential(\r\n          (0): InstanceNorm(eps=1e-05, in_channels=64)\r\n          (1): Activation(relu)\r\n          (2): Conv2D(64 -> 32, kernel_size=(1, 1), stride=(1, 1))\r\n          (3): InstanceNorm(eps=1e-05, in_channels=32)\r\n          (4): Activation(relu)\r\n          (5): ConvLayer(\r\n            (pad): ReflectancePadding(\r\n            \r\n            )\r\n            (conv2d): Conv2D(32 -> 32, kernel_size=(3, 3), stride=(2, 2))\r\n          )\r\n          (6): InstanceNorm(eps=1e-05, in_channels=32)\r\n          (7): Activation(relu)\r\n          (8): Conv2D(32 -> 128, kernel_size=(1, 1), stride=(1, 1))\r\n        )\r\n        (residual_layer): Conv2D(64 -> 128, kernel_size=(1, 1), stride=(2, 2))\r\n      )\r\n      (4): Bottleneck(\r\n        (conv_block): Sequential(\r\n          (0): InstanceNorm(eps=1e-05, in_channels=128)\r\n          (1): Activation(relu)\r\n          (2): Conv2D(128 -> 128, kernel_size=(1, 1), stride=(1, 1))\r\n          (3): InstanceNorm(eps=1e-05, in_channels=128)\r\n          (4): Activation(relu)\r\n          (5): ConvLayer(\r\n            (pad): ReflectancePadding(\r\n            \r\n            )\r\n            (conv2d): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(2, 2))\r\n          )\r\n          (6): InstanceNorm(eps=1e-05, in_channels=128)\r\n          (7): Activation(relu)\r\n          (8): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1))\r\n        )\r\n        (residual_layer): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(2, 2))\r\n      )\r\n    )\r\n    (1): Inspiration(N x 512)\r\n    (2): Bottleneck(\r\n      (conv_block): Sequential(\r\n        (0): InstanceNorm(eps=1e-05, in_channels=512)\r\n        (1): Activation(relu)\r\n        (2): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1))\r\n        (3): InstanceNorm(eps=1e-05, in_channels=128)\r\n        (4): Activation(relu)\r\n        (5): ConvLayer(\r\n          (pad): ReflectancePadding(\r\n          \r\n          )\r\n          (conv2d): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1))\r\n        )\r\n        (6): InstanceNorm(eps=1e-05, in_channels=128)\r\n        (7): Activation(relu)\r\n        (8): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1))\r\n      )\r\n    )\r\n    (3): Bottleneck(\r\n      (conv_block): Sequential(\r\n        (0): InstanceNorm(eps=1e-05, in_channels=512)\r\n        (1): Activation(relu)\r\n        (2): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1))\r\n        (3): InstanceNorm(eps=1e-05, in_channels=128)\r\n        (4): Activation(relu)\r\n        (5): ConvLayer(\r\n          (pad): ReflectancePadding(\r\n          \r\n          )\r\n          (conv2d): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1))\r\n        )\r\n        (6): InstanceNorm(eps=1e-05, in_channels=128)\r\n        (7): Activation(relu)\r\n        (8): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1))\r\n      )\r\n    )\r\n    (4): Bottleneck(\r\n      (conv_block): Sequential(\r\n        (0): InstanceNorm(eps=1e-05, in_channels=512)\r\n        (1): Activation(relu)\r\n        (2): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1))\r\n        (3): InstanceNorm(eps=1e-05, in_channels=128)\r\n        (4): Activation(relu)\r\n        (5): ConvLayer(\r\n          (pad): ReflectancePadding(\r\n          \r\n          )\r\n          (conv2d): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1))\r\n        )\r\n        (6): InstanceNorm(eps=1e-05, in_channels=128)\r\n        (7): Activation(relu)\r\n        (8): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1))\r\n      )\r\n    )\r\n    (5): Bottleneck(\r\n      (conv_block): Sequential(\r\n        (0): InstanceNorm(eps=1e-05, in_channels=512)\r\n        (1): Activation(relu)\r\n        (2): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1))\r\n        (3): InstanceNorm(eps=1e-05, in_channels=128)\r\n        (4): Activation(relu)\r\n        (5): ConvLayer(\r\n          (pad): ReflectancePadding(\r\n          \r\n          )\r\n          (conv2d): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1))\r\n        )\r\n        (6): InstanceNorm(eps=1e-05, in_channels=128)\r\n        (7): Activation(relu)\r\n        (8): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1))\r\n      )\r\n    )\r\n    (6): Bottleneck(\r\n      (conv_block): Sequential(\r\n        (0): InstanceNorm(eps=1e-05, in_channels=512)\r\n        (1): Activation(relu)\r\n        (2): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1))\r\n        (3): InstanceNorm(eps=1e-05, in_channels=128)\r\n        (4): Activation(relu)\r\n        (5): ConvLayer(\r\n          (pad): ReflectancePadding(\r\n          \r\n          )\r\n          (conv2d): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1))\r\n        )\r\n        (6): InstanceNorm(eps=1e-05, in_channels=128)\r\n        (7): Activation(relu)\r\n        (8): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1))\r\n      )\r\n    )\r\n    (7): Bottleneck(\r\n      (conv_block): Sequential(\r\n        (0): InstanceNorm(eps=1e-05, in_channels=512)\r\n        (1): Activation(relu)\r\n        (2): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1))\r\n        (3): InstanceNorm(eps=1e-05, in_channels=128)\r\n        (4): Activation(relu)\r\n        (5): ConvLayer(\r\n          (pad): ReflectancePadding(\r\n          \r\n          )\r\n          (conv2d): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1))\r\n        )\r\n        (6): InstanceNorm(eps=1e-05, in_channels=128)\r\n        (7): Activation(relu)\r\n        (8): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1))\r\n      )\r\n    )\r\n    (8): UpBottleneck(\r\n      (conv_block): Sequential(\r\n        (0): InstanceNorm(eps=1e-05, in_channels=512)\r\n        (1): Activation(relu)\r\n        (2): Conv2D(512 -> 32, kernel_size=(1, 1), stride=(1, 1))\r\n        (3): InstanceNorm(eps=1e-05, in_channels=32)\r\n        (4): Activation(relu)\r\n        (5): UpsampleConvLayer(\r\n          (conv2d): Conv2D(32 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n        )\r\n        (6): InstanceNorm(eps=1e-05, in_channels=32)\r\n        (7): Activation(relu)\r\n        (8): Conv2D(32 -> 128, kernel_size=(1, 1), stride=(1, 1))\r\n      )\r\n      (residual_layer): UpsampleConvLayer(\r\n        (conv2d): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1))\r\n      )\r\n    )\r\n    (9): UpBottleneck(\r\n      (conv_block): Sequential(\r\n        (0): InstanceNorm(eps=1e-05, in_channels=128)\r\n        (1): Activation(relu)\r\n        (2): Conv2D(128 -> 16, kernel_size=(1, 1), stride=(1, 1))\r\n        (3): InstanceNorm(eps=1e-05, in_channels=16)\r\n        (4): Activation(relu)\r\n        (5): UpsampleConvLayer(\r\n          (conv2d): Conv2D(16 -> 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\r\n        )\r\n        (6): InstanceNorm(eps=1e-05, in_channels=16)\r\n        (7): Activation(relu)\r\n        (8): Conv2D(16 -> 64, kernel_size=(1, 1), stride=(1, 1))\r\n      )\r\n      (residual_layer): UpsampleConvLayer(\r\n        (conv2d): Conv2D(128 -> 64, kernel_size=(1, 1), stride=(1, 1))\r\n      )\r\n    )\r\n    (10): InstanceNorm(eps=1e-05, in_channels=64)\r\n    (11): Activation(relu)\r\n    (12): ConvLayer(\r\n      (pad): ReflectancePadding(\r\n      \r\n      )\r\n      (conv2d): Conv2D(64 -> 3, kernel_size=(7, 7), stride=(1, 1))\r\n    )\r\n  )\r\n  (ins): Inspiration(N x 512)\r\n  (model1): Sequential(\r\n    (0): ConvLayer(\r\n      (pad): ReflectancePadding(\r\n      \r\n      )\r\n      (conv2d): Conv2D(3 -> 64, kernel_size=(7, 7), stride=(1, 1))\r\n    )\r\n    (1): InstanceNorm(eps=1e-05, in_channels=64)\r\n    (2): Activation(relu)\r\n    (3): Bottleneck(\r\n      (conv_block): Sequential(\r\n        (0): InstanceNorm(eps=1e-05, in_channels=64)\r\n        (1): Activation(relu)\r\n        (2): Conv2D(64 -> 32, kernel_size=(1, 1), stride=(1, 1))\r\n        (3): InstanceNorm(eps=1e-05, in_channels=32)\r\n        (4): Activation(relu)\r\n        (5): ConvLayer(\r\n          (pad): ReflectancePadding(\r\n          \r\n          )\r\n          (conv2d): Conv2D(32 -> 32, kernel_size=(3, 3), stride=(2, 2))\r\n        )\r\n        (6): InstanceNorm(eps=1e-05, in_channels=32)\r\n        (7): Activation(relu)\r\n        (8): Conv2D(32 -> 128, kernel_size=(1, 1), stride=(1, 1))\r\n      )\r\n      (residual_layer): Conv2D(64 -> 128, kernel_size=(1, 1), stride=(2, 2))\r\n    )\r\n    (4): Bottleneck(\r\n      (conv_block): Sequential(\r\n        (0): InstanceNorm(eps=1e-05, in_channels=128)\r\n        (1): Activation(relu)\r\n        (2): Conv2D(128 -> 128, kernel_size=(1, 1), stride=(1, 1))\r\n        (3): InstanceNorm(eps=1e-05, in_channels=128)\r\n        (4): Activation(relu)\r\n        (5): ConvLayer(\r\n          (pad): ReflectancePadding(\r\n          \r\n          )\r\n          (conv2d): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(2, 2))\r\n        )\r\n        (6): InstanceNorm(eps=1e-05, in_channels=128)\r\n        (7): Activation(relu)\r\n        (8): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1))\r\n      )\r\n      (residual_layer): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(2, 2))\r\n    )\r\n  )\r\n))\r\n[13:10:54] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\r\nTraceback (most recent call last):\r\n  File ""main.py"", line 228, in <module>\r\n    main()\r\n  File ""main.py"", line 213, in main\r\n    train(args)\r\n  File ""main.py"", line 82, in train\r\n    style_model.setTarget(style_image)\r\n  File ""/home/samh/dev/mxnet/example/gluon/style_transfer/net.py"", line 228, in setTarget\r\n    self.ins.setTarget(G)\r\n  File ""/home/samh/dev/mxnet/example/gluon/style_transfer/net.py"", line 252, in setTarget\r\n    self.gram.set_data(target)\r\n  File ""/asset/common/software/thirdparty/mxnet/1.0.0-build1/python2.7/mxnet/gluon/parameter.py"", line 374, in set_data\r\n    arr[:] = data\r\n  File ""/asset/common/software/thirdparty/mxnet/1.0.0-build1/python2.7/mxnet/ndarray/ndarray.py"", line 437, in __setitem__\r\n    self._set_nd_basic_indexing(key, value)\r\n  File ""/asset/common/software/thirdparty/mxnet/1.0.0-build1/python2.7/mxnet/ndarray/ndarray.py"", line 691, in _set_nd_basic_indexing\r\n    value.copyto(self)\r\n  File ""/asset/common/software/thirdparty/mxnet/1.0.0-build1/python2.7/mxnet/ndarray/ndarray.py"", line 1884, in copyto\r\n    return _internal._copyto(self, out=other)\r\n  File ""<string>"", line 25, in _copyto\r\n  File ""/asset/common/software/thirdparty/mxnet/1.0.0-build1/python2.7/mxnet/_ctypes/ndarray.py"", line 92, in _imperative_invoke\r\n    ctypes.byref(out_stypes)))\r\n  File ""/asset/common/software/thirdparty/mxnet/1.0.0-build1/python2.7/mxnet/base.py"", line 148, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [13:11:10] src/imperative/imperative.cc:192: Check failed: AGInfo::IsNone(*(outputs[i])) Assigning to NDArrays that are already in a computational graph will cause undefined behavior when evaluating gradients. Please call backward first to clear the graph or do this out side of a record section. \r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /asset/common/software/thirdparty/mxnet/1.0.0-build1/lib/libmxnet.so(dmlc::StackTrace()+0x38) [0x7f937e3b46d8]\r\n[bt] (1) /asset/common/software/thirdparty/mxnet/1.0.0-build1/lib/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x18) [0x7f937e3b4ad8]\r\n[bt] (2) /asset/common/software/thirdparty/mxnet/1.0.0-build1/lib/libmxnet.so(mxnet::Imperative::RecordOp(nnvm::NodeAttrs&&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, mxnet::OpStatePtr const&, std::vector<bool, std::allocator<bool> >*, std::vector<bool, std::allocator<bool> >*)+0x10b) [0x7f938085e7cb]\r\n[bt] (3) /asset/common/software/thirdparty/mxnet/1.0.0-build1/lib/libmxnet.so(MXImperativeInvokeImpl(void*, int, void**, int*, void***, int, char const**, char const**)+0x756) [0x7f9380790f36]\r\n[bt] (4) /asset/common/software/thirdparty/mxnet/1.0.0-build1/lib/libmxnet.so(MXImperativeInvokeEx+0x63) [0x7f93807911e3]\r\n[bt] (5) /asset/common/software/thirdparty/python/2.7.10-build1/arch/linux-centos6/x86_64/ucs4/ndebug/lib/python2.7/lib-dynload/_ctypes.so(ffi_call_unix64+0x4c) [0x7f939064f6e4]\r\n[bt] (6) /asset/common/software/thirdparty/python/2.7.10-build1/arch/linux-centos6/x86_64/ucs4/ndebug/lib/python2.7/lib-dynload/_ctypes.so(ffi_call+0x1f9) [0x7f939064f4e9]\r\n[bt] (7) /asset/common/software/thirdparty/python/2.7.10-build1/arch/linux-centos6/x86_64/ucs4/ndebug/lib/python2.7/lib-dynload/_ctypes.so(_ctypes_callproc+0x416) [0x7f9390646fb6]\r\n[bt] (8) /asset/common/software/thirdparty/python/2.7.10-build1/arch/linux-centos6/x86_64/ucs4/ndebug/lib/python2.7/lib-dynload/_ctypes.so(+0x9fef) [0x7f939063efef]\r\n[bt] (9) /asset/common/software/thirdparty/python/2.7.10-build1/arch/linux-centos6/x86_64/ucs4/ndebug/lib/libpython2.7.so.1.0(PyObject_Call+0x67) [0x7f939780b427]\r\n']",[],0,0
402,incubator-mxnet,3710,closed,how to deal with the unlabel data with the dataiter?,"hi, I want to load some labeled and unlabeled data into mxnet.  
I follow the example [https://github.com/dmlc/mxnet/blob/master/example/fcn-xs/data.py#L96](url) to create a dataiter.
how to implement the  method for unlabel data?
Thanks for your attention.",,"['Just return a dummy one\n', '@winstywang  Thank you. could you please me some example  of that? :)\n', ""I don't see the need of example for this. Just return anything you want, and do not use it later.\n"", 'I am also in trouble with this when I try to predict the text label.\nIn example, https://github.com/dmlc/mxnet/blob/master/example/cnn_text_classification/text_cnn.py#L124, the data was bind into the model in training.  But in prediction, the loaded model need to take DataIter type  data as input.\n', 'thank you\n1. if my labels are 0 and 1,  so I could set the label = -1 for the unlabeled  data.\nI want to put the label and unlabeled data to the model and only use the label of labeled data at the final layer.\n2. I see #2403 said need to use the ""ignore label"". Is it an attr of sym?  How to use it?\n', '@R1ncy you can set ignore_label in softmax loss, if the sample is with label=ignore_label, it will contribute to the gradient.\n', ""is it `mx.sym.SoftmaxOutput(..use_ignore = True, ignore_label = -1)`?\nwhat if I want to use `mx.sym.SVMOutput` ?\nseems svmoutput doesn't have ignore_label\n""]",[],['provide_label'],0,0
403,incubator-mxnet,6073,closed,Unable to run MXnet with yarn as a launcher,"$ python ../../tools/launch.py -n 2 --launcher yarn python  train_mnist.py --network lenet --kv-store dist_sync
17/05/03 01:24:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/05/03 01:24:50 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
17/05/03 01:24:50 INFO impl.TimelineClientImpl: Timeline service address: http://<server>/X.X.X.X:8188/ws/v1/timeline/
17/05/03 01:24:50 INFO client.RMProxy: Connecting to ResourceManager at <server>/X.X.X.X:8050
17/05/03 01:24:50 INFO client.AHSProxy: Connecting to Application History server at <server>/X.X.X.X:10200
17/05/03 01:24:51 INFO dmlc.Client: jobname=DMLC[nworker=2,nsever=2]:python,username=root
17/05/03 01:24:51 INFO dmlc.Client: Submitting application application_1489701902537_0147
17/05/03 01:24:51 INFO impl.YarnClientImpl: Submitted application application_1489701902537_0147
Application application_1489701902537_0147 finished with state FINISHED at 1493774702568
Diagnostics., num_tasks4, finished=0, failed=4
[DMLC] Task 0 failed more than 3times
Available queues:
default
17/05/03 01:25:02 INFO impl.YarnClientImpl: Killed application application_1489701902537_0147

Here is my config.mk for mxnet

#-------------------------------------------------------------------------------
#  Template configuration for compiling mxnet
#
#  If you want to change the configuration, please use the following
#  steps. Assume you are on the root directory of mxnet. First copy the this
#  file so that any local changes will be ignored by git
#
#  $ cp make/config.mk .
#
#  Next modify the according entries, and then compile by
#
#  $ make
#
#  or build in parallel with 8 threads
#
#  $ make -j8
#-------------------------------------------------------------------------------

#---------------------
# choice of compiler
#--------------------

export CC = gcc
export CXX = g++
export NVCC = nvcc

# whether compile with options for MXNet developer
DEV = 0

# whether compile with debug
DEBUG = 0

# whether compiler with profiler
USE_PROFILER =

# the additional link flags you want to add
ADD_LDFLAGS =

# the additional compile flags you want to add
ADD_CFLAGS =

#---------------------------------------------
# matrix computation libraries for CPU/GPU
#---------------------------------------------

# whether use CUDA during compile
USE_CUDA = 0

# add the path to CUDA library to link and compile flag
# if you have already add them to environment variable, leave it as NONE
# USE_CUDA_PATH = /usr/local/cuda
USE_CUDA_PATH = NONE

# whether use CuDNN R3 library
USE_CUDNN = 0

# CUDA architecture setting: going with all of them.
# For CUDA < 6.0, comment the *_50 lines for compatibility.
CUDA_ARCH := -gencode arch=compute_30,code=sm_30 \
		-gencode arch=compute_35,code=sm_35 \
		-gencode arch=compute_50,code=sm_50 \
		-gencode arch=compute_50,code=compute_50

# whether use cuda runtime compiling for writing kernels in native language (i.e. Python)
USE_NVRTC = 0

# whether use opencv during compilation
# you can disable it, however, you will not able to use
# imbin iterator
USE_OPENCV = 0

# use openmp for parallelization
USE_OPENMP = 1


# MKL ML Library for Intel CPU/Xeon Phi
# Please refer to MKL_README.md for details

# MKL ML Library folder, need to be root for /usr/local
# Change to User Home directory for standard user
# For USE_BLAS!=mkl only
MKLML_ROOT=/usr/local

# whether use MKL2017 library
USE_MKL2017 = 0

# whether use MKL2017 experimental feature for high performance
# Prerequisite USE_MKL2017=1
USE_MKL2017_EXPERIMENTAL = 0

# whether use NNPACK library
USE_NNPACK = 0

# choose the version of blas you want to use
# can be: mkl, blas, atlas, openblas
# in default use atlas for linux while apple for osx
UNAME_S := $(shell uname -s)
ifeq ($(UNAME_S), Darwin)
USE_BLAS = apple
else
USE_BLAS = atlas
endif

# add path to intel library, you may need it for MKL, if you did not add the path
# to environment variable
USE_INTEL_PATH = NONE

# If use MKL only for BLAS, choose static link automatically to allow python wrapper
ifeq ($(USE_MKL2017), 0)
ifeq ($(USE_BLAS), mkl)
USE_STATIC_MKL = 1
endif
else
USE_STATIC_MKL = NONE
endif

#----------------------------
# Settings for power and arm arch
#----------------------------
ARCH := $(shell uname -a)
ifneq (,$(filter $(ARCH), armv6l armv7l powerpc64le ppc64le aarch64))
	USE_SSE=0
else
	USE_SSE=1
endif

#----------------------------
# distributed computing
#----------------------------

# whether or not to enable multi-machine supporting
USE_DIST_KVSTORE = 1

# whether or not allow to read and write HDFS directly. If yes, then hadoop is
# required
USE_HDFS = 0

# path to libjvm.so. required if USE_HDFS=1
LIBJVM=$(JAVA_HOME)/jre/lib/amd64/server

# whether or not allow to read and write AWS S3 directly. If yes, then
# libcurl4-openssl-dev is required, it can be installed on Ubuntu by
# sudo apt-get install -y libcurl4-openssl-dev
USE_S3 = 0

#----------------------------
# additional operators
#----------------------------

# path to folders containing projects specific operators that you don't want to put in src/operators
EXTRA_OPERATORS =

#----------------------------
# other features
#----------------------------

# Create C++ interface package
USE_CPP_PACKAGE = 0

#----------------------------
# plugins
#----------------------------

# whether to use caffe integration. This requires installing caffe.
# You also need to add CAFFE_PATH/build/lib to your LD_LIBRARY_PATH
# CAFFE_PATH = $(HOME)/caffe
# MXNET_PLUGINS += plugin/caffe/caffe.mk

# whether to use torch integration. This requires installing torch.
# You also need to add TORCH_PATH/install/lib to your LD_LIBRARY_PATH
# TORCH_PATH = $(HOME)/torch
# MXNET_PLUGINS += plugin/torch/torch.mk

# _WARPCTC_PATH_ = $(HOME)/warp-ctc
# MXNET_PLUGINS += plugin/warpctc/warpctc.mk

# whether to use sframe integration. This requires build sframe
# git@github.com:dato-code/SFrame.git
# SFRAME_PATH = $(HOME)/SFrame
# MXNET_PLUGINS += plugin/sframe/plugin.mk
USE_BLAS=atlas
#ADD_CFLAGS += -I/usr/include/openblas
ADD_CFLAGS += -I/usr/include/openblas -L/usr/local/lib
#ADD_LDFLAGS += -lopencv_core -lopencv_imgproc -lopencv_imgcodecs

Can someone please tell me what is wrong with my set up? ",,"['I came into the same situation,and the Logs for node container shows:\r\n **INFO dmlc.ApplicationMaster: [DMLC] Task 0 killed because of exceeding allocated physical memory**\r\nI have set the following env ,but did not work\r\nexport DMLC_HDFS_OPTS=--Xmx2048m     \r\nexport DMLC_WORKER_MEMORY_MB=4096    \r\nexport DMLC_SERVER_MEMORY_MB=4096\r\nAny suggestions?\r\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!']",[],[],0,0
404,incubator-mxnet,3158,closed,How to test using mx.mod.Module?,"I have the following code to test my model:



However, it takes as long to test as to train (even a bit longer) and I'm worried I'm training it by mistake or doing something way wrong.
",,"['This looks correct. Is your test set bigger than training set?\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']","['\n    metric = mx.metric.Accuracy()\n    for batch in load_data_frame(X_data=X_test,\n                                 y_data=y_test,\n                                 batch_size=BATCH_SIZE):\n        mod.forward(batch, is_train=False)\n        mod.update_metric(metric, batch.label)\n\n    metric_m, metric_v = metric.get()\n    print(""TEST(%s): %.4f"" % (metric_m, metric_v))\n']",[],0,0
405,incubator-mxnet,2438,closed,How to update the aux parameters?,"In model.py in the python package, 
_update_params(executor_manager.param_arrays, executor_manager.grad_arrays, updater=updater, num_device=len(ctx), kvstore=kvstore) is used for updating of the parameters. However, seen from the code, the parameters (gamma and beta) of Batch Normalization operator is included in executor_manager.aux_arrays, but not included in executor_manager.param_arrays. So the parameters of Batch Normalization are not updated after each iteration ?
",,"['aux states are not updated by optimizer. Operators are responsible for maintaining it\n', 'thanks\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
406,incubator-mxnet,4906,closed,How to load ARK files in mxnet,"Hi,
I'm attempting to load some ARK files into mxnet, but I'm not exactly sure on how to go about it. I did go over the speech-demo example, but in there, there are custom io files that is loading sequences in certain format for LSTMs. I'm trying to simply load an ark file for an acoustic model, I was wondering if you could point to me exactly what files I can use in the speech-demo or a work around on how to go about it.
-Venkatesh 

@yzhang87",,"['Firstly you need to load ark data type to numpy array, you can try some parsing tools, the following one is a quite good \r\n\r\nhttps://github.com/vesis84/kaldi-io-for-python\r\n\r\nAfter converting the data into numpy arrays, then you can write your own data iterator to manage the data loading process', 'Thank you, this helped me out a lot! ', 'I am trying to create a slider in my data. Essentially, after my ARK files are processed I want to train its features such that each row of features being trained will have its surrounding context. For example, if I am training row 3 in a feature matrix - [f2], with target [t2], I want to have a slider that will provide that provide f2 with its surrounding context so it should be [f1 f2 f3] with target [t2] where the surrounding context can be a variable so a right context and a left context. Is that available in Mxnet?', 'For loading ark in speech demo, you can take a look the io_function. It actually call the Kaldi "".so"" file directly. You can load a chunk of ark file by calling `def load_next_block` in \r\nhttps://github.com/dmlc/mxnet/blob/master/example/speech-demo/io_func/feat_io.py\r\n\r\nFor adding sliding window, you can do it on Kaldi side by using nnet1 feature transform if you familiar with Kaldi. \r\nSomething like,\r\n<Nnet>\r\n<Splice> 440 40\r\n[-5 -4 -3 -2 -1 0 1 2 3 4 5]\r\n</Nnet>\r\n\r\nThen when you call load_next_block, the feature has add context. You can check the transform section in:\r\nhttps://github.com/dmlc/mxnet/blob/master/example/speech-demo/README.md\r\n', ""I think if you use Karen's https://github.com/vesis84/kaldi-io-for-python Kaldi reader, you need add some python code to do the sliding window."", 'Actually, you can pass a kaldi respecifier to the kaldi-io, and do the feature transformation in the kaldi part:\r\n\r\nFor example, you can first add deltas to the features, apply cmvn operations, and then do the feature extension (sliding).  The following script will get inputs of 13 dimension, and return outputs of (13+13+13) * (5+1+5) = 429 dimensions\r\n\r\n```python\r\nrsp = """"""ark,s,cs:add-deltas --delta-window=3 --delta-order=2 scp:test.scp ark:- |\r\n        apply-cmvn-sliding --norm-vars=false --center=true --cmn-window=300 ark:- ark:- |\r\n        splice-feats --left-context=5 --right-context=5 ark:- ark:-|""""""\r\nkaldi_io.read_mat_ark(rsp)\r\n```', 'Okay, I tried out what @wsstriving suggested and seems to do trick. Thanks! ', 'Is there an option for me to train with multiple different files? Currently I only see that I can train with one file with its corresponding labels file. ']",[],[],0,0
407,incubator-mxnet,13739,closed,Building mxnet over OpenBLAS fails,"## Description
I am building mxnet over OpenBLAS but it fails due to missing file 'cblas.h'.
Does anyone meet the same error?

## Environment info

Package used (Python/R/Scala/Julia):
I'm using Python.

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
g++

MXNet commit hash:
(Paste the output of  here.)
3bfcd93dff33d27a6087e39dd9387718456b5f51

Build config:
(Paste the content of config.mk, or the build command.)
export CPATH=/usr/include/openblas; make -j40 USE_BLAS=openblas USE_CUDA=1 USE_CUDNN=1 USE_CUDA_PATH=/usr/local/cuda-9.0 USE_OPENCV=1

## Error Message:
(Paste the complete error message, including stack trace.)
In file included from /home/mxnet/workspace/source/incubator-mxnet/3rdparty/mshadow/mshadow/tensor.h:16:0,
                 from include/mxnet/./base.h:32,
                 from include/mxnet/operator_util.h:43,
                 from src/operator/contrib/nnz.cc:25:
/home/mxnet/workspace/source/incubator-mxnet/3rdparty/mshadow/mshadow/./base.h:162:23: fatal error: cblas.h: No such file or directory
     #include <cblas.h>
                       ^
compilation terminated.


## Steps to reproduce
export CPATH=/usr/include/openblas; make -j40 USE_BLAS=openblas USE_CUDA=1 USE_CUDNN=1 USE_CUDA_PATH=/usr/local/cuda-9.0 USE_OPENCV=1

",,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Build', 'I found blas not installed in that machine. Sorry for that.']",[],['git rev-parse HEAD'],0,0
408,incubator-mxnet,5950,closed,Is there unit test for OPs ?,"I am writing OP, I want do some unit test, but I haven't find test examples for OPs, I want know if there is a easy way to test it.",,"['[example](https://github.com/dmlc/mxnet/blob/master/tests/python/gpu/test_operator_gpu.py) testing.', 'found in tests/python/unittest']",[],[],0,0
409,incubator-mxnet,9696,closed,warpctc: module object has no at tribute 'WarpCTC',"I build the mxnet from source and follows the step in [#7002](https://github.com/apache/incubator-mxnet/issues/7002).But I found it works well if I use python3 but error occurred for python2----""AttributeError: 'module' object has no attribute 'WarpCTC'""",,"['@Mendel1 - Did you make clean, set right path in config.mk and rebuild mxnet? \r\nHere is the issue with solution discussed - \r\nhttps://github.com/apache/incubator-mxnet/issues/2587 \r\n\r\nPlease reopen if issue persist.']",[],[],0,0
410,incubator-mxnet,4902,closed,"dlopen failed: cannot locate symbol ""cblas_sgemm"" referenced by ""libmxnet_predict.so""...","Operating System:ANDROID
Compiler:ANDROID NDKr13 using api 21(also 19)
I tried to build the mxnet to android using 'make  ANDROID=1' and finally get the 'libmxnet_predict.so'. But when I tried to use it in an android project, it coulde not run  throw this EXCEPTION: 
How can I solve this problem? Did I make some mistakes in compiling?
MXNet version:
I have tried the newest vision and the 0.8.0 vision, and all got that EXCEPTION.",,"['Can anyone help me compiling the android Library or give me the library directly?', 'Hi, i think i may meet with the same issue with you, have you found the root cause for the issue? thanks in advance!']",[],"['\'java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol ""cblas_sgemm"" referenced by ""libmxnet_predict.so""...\'.']",0,0
411,incubator-mxnet,13710,closed,Error in `python': malloc(): memory corruption: 0x00007f540c0a6190,"> ENV:
> 
> 
> python gluon-cv/scripts/detection/ssd/train_ssd.py
>
> INFO:root:Start training from [Epoch 0]
> *** Error in python': malloc(): memory corruption: 0x00007f540c1a9550 ***
> ======= Backtrace: =========
> /lib64/libc.so.6(+0x82c86)[0x7f54d42dec86]
> /lib64/libc.so.6(__libc_malloc+0x4c)[0x7f54d42e184c]
> /lib64/libstdc++.so.6(_Znwm+0x1d)[0x7f54b48c7ecd]
> /data/workspace/mxnet/python/mxnet/../../lib/libmxnet.so(+0x3c042d9)[0x7f54691982d9]
> /data/workspace/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet6engine14ThreadedEngine15ExecuteOprBlockENS_10RunContextEPNS0_8OprBlockE+0x589)[0x7f5469194249]
> *** Error in 
> The full trach message is here
> [error.log](https://github.com/dmlc/gluon-cv/files/2699683/error.log)

",Bug Gluon Python,"['@mxnet-label-bot add [gluon, python, bug]', ""I have met the same problem and tried to find the exact place the bug happened.\r\n\r\nENV:\r\n```\r\nCentos 7.0\r\nPython 2.7.5\r\nmxnet 1.3.0\r\ngluon-cv 0.3.0\r\n````\r\n\r\nMinimal script to reproduce the bug:\r\n```\r\nimport numpy as np\r\nimport mxnet as mx\r\nfrom mxnet import autograd\r\nfrom gluoncv.model_zoo import get_model\r\nfrom gluoncv import data as gdata\r\nfrom gluoncv.data.transforms.presets.ssd import SSDDefaultTrainTransform\r\n\r\nnet_name = 'ssd_300_vgg16_atrous_voc'\r\nnet = get_model(net_name, pretrained_base=False)\r\nnet.initialize()\r\n\r\nwidth = 300\r\nheight = 300\r\nwith autograd.train_mode():\r\n    _, _, anchors = net(mx.nd.zeros((1, 3, height, width)))\r\ntrans = SSDDefaultTrainTransform(height, width, anchors)\r\n\r\n# the bug happens when transform voc 2007 data, here I only create a random data\r\nimage = mx.nd.uniform(low=0, high=255, shape=(500, 400, 3)).astype('uint8')\r\nbox = np.array([[ 47., 239., 194., 370.,  11.,   0.],\r\n                [  7.,  11., 351., 497.,  14.,   0.]])\r\nfor _ in range(10):\r\n    trans(image, box)\r\n```\r\n\r\nThe backtrace of gdb on debug version mxnet\r\n```\r\n#0  0x00007ffff6d53277 in raise () at /lib64/libc.so.6\r\n#1  0x00007ffff6d54968 in abort () at /lib64/libc.so.6\r\n#2  0x00007ffff6d95d37 in __libc_message () at /lib64/libc.so.6\r\n#3  0x00007ffff6d9fc86 in _int_malloc () at /lib64/libc.so.6\r\n#4  0x00007ffff6da284c in malloc () at /lib64/libc.so.6\r\n#5  0x00007fffd8b84ecd in operator new(unsigned long) () at /lib64/libstdc++.so.6\r\n#6  0x00007fff9697f27c in __gnu_cxx::new_allocator<unsigned long>::allocate(unsigned long, void const*) (this=0x7fff6b45b760, __n=17464)\r\n    at /usr/include/c++/4.8.2/ext/new_allocator.h:104\r\n#7  0x00007fff96aa2835 in std::_Vector_base<unsigned long, std::allocator<unsigned long> >::_M_allocate(unsigned long) (this=0x7fff6b45b760, __n=17464)\r\n    at /usr/include/c++/4.8.2/bits/stl_vector.h:168\r\n#8  0x00007fff96aa807f in std::_Vector_base<unsigned long, std::allocator<unsigned long> >::_M_create_storage(unsigned long) (this=0x7fff6b45b760, __n=17464)\r\n    at /usr/include/c++/4.8.2/bits/stl_vector.h:181\r\n#9  0x00007fff96aa3999 in std::_Vector_base<unsigned long, std::allocator<unsigned long> >::_Vector_base(unsigned long, std::allocator<unsigned long> const&) (this=0x7fff6b45b760, __n=17464, __a=...) at /usr/include/c++/4.8.2/bits/stl_vector.h:136\r\n#10 0x00007fff96aa041c in std::vector<unsigned long, std::allocator<unsigned long> >::vector(unsigned long, std::allocator<unsigned long> const&) (this=0x7fff6b45b760, __n=17464, __a=...) at /usr/include/c++/4.8.2/bits/stl_vector.h:270\r\n#11 0x00007fff96a9ca55 in mxnet::op::SortByKey<int, float>(mshadow::Tensor<mshadow::cpu, 1, int>, mshadow::Tensor<mshadow::cpu, 1, float>, bool, mshadow::Tensor<mshadow::cpu, 1, char>*, int, int) (keys=..., values=..., is_ascend=true, workspace=0x0, begin_bit=0, end_bit=32) at src/operator/contrib/./../tensor/sort_op.h:50\r\n#12 0x00007fff96a8a08d in mxnet::op::BipartiteMatchingForward<mshadow::cpu>(nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&) (attrs=..., ctx=..., inputs=std::vector of length 1, capacity 1 = {...}, req=std::vector of length 2, capacity 2 = {...}, outputs=std::vector of length 2, capacity 2 = {...})\r\n    at src/operator/contrib/./bounding_box-inl.h:779\r\n#13 0x00007fff96861e8d in std::_Function_handler<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&), void (*)(nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)>::_M_invoke(std::_Any_data const&, nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&) (__functor=..., __args#0=..., __args#1=..., __args#2=std::vector of length 1, capacity 1 = {...}, __args#3=std::vector of length 2, capacity 2 = {...}, __args#4=std::vector of length 2, capacity 2 = {...}) at /usr/include/c++/4.8.2/functional:2071\r\n#14 0x00007fff98c896b8 in std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)>::operator()(nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&) const (this=0x1eb15d8, __args#0=..., __args#1=..., __args#2=std::vector of length 1, capacity 1 = {...}, __args#3=std::vector of length 2, capacity 2 = {...}, __args#4=std::vector of length 2, capacity 2 = {...})\r\n    at /usr/include/c++/4.8.2/functional:2471\r\n#15 0x00007fff98dae979 in mxnet::imperative::PushFCompute(std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)> const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<unsigned int, std::allocator<unsigned int> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&)::{lambda(mxnet::RunContext)#1}::operator()(mxnet::RunContext) const (__closure=0x1eb1550, rctx=...)\r\n    at src/imperative/./imperative_utils.h:401\r\n#16 0x00007fff98db4649 in std::_Function_handler<void (mxnet::RunContext), mxnet::imperative::PushFCompute(std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)> const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<unsigned int, std::allocator<unsigned int> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&)::{lambda(mxnet::RunContext)#1}>::_M_invoke(std::_Any_data const&, mxnet::RunContext) (__functor=..., __args#0=...) at /usr/include/c++/4.8.2/functional:2071\r\n#17 0x00007fff99481517 in std::function<void (mxnet::RunContext)>::operator()(mxnet::RunContext) const (this=0x1e5fd20, __args#0=...)\r\n    at /usr/include/c++/4.8.2/functional:2471\r\n#18 0x00007fff9949245a in mxnet::engine::ThreadedEngine::__lambda26::operator()(mxnet::RunContext, mxnet::Engine::CallbackOnComplete) const (__closure=0x1e5fd20, ctx=..., on_complete=...) at src/engine/threaded_engine.cc:342\r\n#19 0x00007fff99493523 in std::_Function_handler<void(mxnet::RunContext, mxnet::engine::CallbackOnComplete), mxnet::engine::ThreadedEngine::PushSync(mxnet::Engine::SyncFn, mxnet::Context, const std::vector<mxnet::engine::Var*>&, const std::vector<mxnet::engine::Var*>&, mxnet::FnProperty, int, char const*)::__lambda26>::_M_invoke(const std::_Any_data &, mxnet::RunContext, mxnet::engine::CallbackOnComplete) (__functor=..., __args#0=..., __args#1=...) at /usr/include/c++/4.8.2/functional:2071\r\n#20 0x00007fff9948218f in std::function<void (mxnet::RunContext, mxnet::engine::CallbackOnComplete)>::operator()(mxnet::RunContext, mxnet::engine::CallbackOnComplete) const (this=0x1d294b0, __args#0=..., __args#1=...) at /usr/include/c++/4.8.2/functional:2471\r\n#21 0x00007fff99487980 in mxnet::engine::ThreadedEngine::ExecuteOprBlock(mxnet::RunContext, mxnet::engine::OprBlock*) (this=0x1121140, run_ctx=..., opr_block=0x112a6b8)\r\n    at src/engine/./threaded_engine.h:363\r\n#22 0x00007fff9949b103 in mxnet::engine::ThreadedEnginePerDevice::CPUWorker<(dmlc::ConcurrentQueueType)0>(mxnet::Context, mxnet::engine::ThreadedEnginePerDevice::ThreadWorkerBlock<(dmlc::ConcurrentQueueType)0>*, std::shared_ptr<dmlc::ManualEvent> const&) (this=0x1121140, ctx=..., block=0x18ac100, ready_event=std::shared_ptr (count 2, weak 0) 0x1b886c8) at src/engine/threaded_engine_perdevice.cc:296\r\n#23 0x00007fff99499491 in mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::{lambda()#1}::operator()() const::{lambda(std::shared_ptr<dmlc::ManualEvent>)#1}::operator()(dmlc::ManualEvent) const (__closure=0x1b95f20, ready_event=std::shared_ptr (count 2, weak 0) 0x1b886c8)\r\n    at src/engine/threaded_engine_perdevice.cc:116\r\n```\r\n\r\nThe bug is related malloc, it disappears when you change the malloc implementation. I'm not sure if there is still some hidden bug.\r\n```\r\nLD_PRELOAD=/usr/lib64/libtcmalloc.so python reproduce_bug.py\r\n```"", '@wsqshiqing A PR regarding has been created, requesting you pull it in and verify it resolves the issue for you? So we can close this issue once the PR is merged', '@vrakesh It can solve my issue.']","['\r\n>     Centos 6.6(Final)\r\n>     CUDA: 9.0.176\r\n>     Python: 2.7.5\r\n>     cudnn: 7 \r\n>     mxnet: 1.3.0-cu90\r\n>     gluon-cv: 0.3.0\r\n\r\n> Run Script: \r\n>', '\r\n\r\n\r\n> The **MXNET_ENGINE_TYPE =NaiveEngine** Trace Message:\r\n> \r\n> ']","[""python': malloc(): memory corruption: 0x00007f540c0a6190 ***\r\n> ======= Backtrace: =========\r\n> /lib64/libc.so.6(+0x82c86)[0x7f54d42dec86]\r\n> /lib64/libc.so.6(__libc_malloc+0x4c)[0x7f54d42e184c]\r\n> /lib64/libstdc++.so.6(_Znwm+0x1d)[0x7f54b48c7ecd]\r\n> /data/workspace/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op9SortByKeyIifEEvN7mshadow6TensorINS2_3cpuELi1ET_EENS3_IS4_Li1ET0_EEbPNS3_IS4_Li1EcEEii+0x3b0)[0x7f546654cb90]/data/workspace/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op24BipartiteMatchingForwardIN7mshadow3cpuEEEvRKN4nnvm9NodeAttrsERKNS_9OpContextERKSt6vectorINS_5TBlobESaISC_EERKSB_INS_9OpReqTypeESaISH_EESG_+0x129f)[0x7f546655229f]\r\n> /data/workspace/mxnet/python/mxnet/../../lib/libmxnet.so(_ZZN5mxnet10imperative12PushFComputeERKSt8functionIFvRKN4nnvm9NodeAttrsERKNS_9OpContextERKSt6vectorINS_5TBlobESaISA_EERKS9_INS_9OpReqTypeESaISF_EESE_EEPKNS2_2OpES5_RKNS_7ContextERKS9_IPNS_6engine3VarESaISW_EES10_RKS9_INS_8ResourceESaIS11_EERKS9_IPNS_7NDArrayESaIS17_EES1B_RKS9_IjSaIjEESJ_ENKUlNS_10RunContextEE_clES1G_+0x2e8)[0x7f5468c8b368]\r\n> *** Error in "", ""python': corrupted size vs. prev_size: 0x00007f540c08c830 ***\r\n> ======= Backtrace: =========\r\n> /data/workspace/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op24BipartiteMatchingForwardIN7mshadow3cpuEEEvRKN4nnvm9NodeAttrsERKNS_9OpContextERKSt6vectorINS_5TBlobESaISC_EERKSB_INS_9OpReqTypeESaISH_EESG_+0x129f)[0x7f546655229f]\r\n> /data/workspace/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNSt17_Function_handlerIFvSt10shared_ptrIN4dmlc11ManualEventEEEZZN5mxnet6engine23ThreadedEnginePerDevice13PushToExecuteEPNS6_8OprBlockEbENKUlvE_clEvEUlS3_E_E9_M_invokeERKSt9_Any_dataS3_+0xd2)[0x7f54691a4df2]\r\n> /lib64/libc.so.6(+0x7f5e4)[0x7f54d42db5e4]\r\n> /data/workspace/mxnet/python/mxnet/../../lib/libmxnet.so(_ZZN5mxnet10imperative12PushFComputeERKSt8functionIFvRKN4nnvm9NodeAttrsERKNS_9OpContextERKSt6vectorINS_5TBlobESaISA_EERKS9_INS_9OpReqTypeESaISF_EESE_EEPKNS2_2OpES5_RKNS_7ContextERKS9_IPNS_6engine3VarESaISW_EES10_RKS9_INS_8ResourceESaIS11_EERKS9_IPNS_7NDArrayESaIS17_EES1B_RKS9_IjSaIjEESJ_ENKUlNS_10RunContextEE_clES1G_+0x2e8)[0x7f5468c8b368]\r\n> /data/workspace/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNSt6thread5_ImplISt12_Bind_simpleIFSt8functionIFvSt10shared_ptrIN4dmlc11ManualEventEEEES6_EEE6_M_runEv+0x44)[0x7f5469193b94]\r\n> /lib64/libc.so.6(+0x816db)[0x7f54d42dd6db]\r\n> /lib64/libstdc++.so.6(+0xb5070)[0x7f54b491e070]\r\n> /data/workspace/mxnet/python/mxnet/../../lib/libmxnet.so(+0x3c042d9)[0x7f54691982d9]\r\n> /data/workspace/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet11StorageImpl4FreeENS_7Storage6HandleE+0x77)[0x7f54691af017]\r\n> /lib64/libc.so.6(clone+0x6d)[0x7f54d435abad]\r\n> ......\r\n> "", '']",0,0
412,incubator-mxnet,2765,closed,ImageNet图片生成RecordIO文件后的失真问题,"在生成imagenet的recordio文件后, 出于好奇, 我从recordio文件中读出了图片并显示出来, 结果发现与原图明显不同, 例如(原图后是对应的失真图片):
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/original/n01484850_95.JPEG?raw=true)
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/showed/2.png?raw=true)
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/original/n01484850_17.JPEG?raw=true)
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/showed/1.png?raw=true)
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/original/n01484850_114.JPEG?raw=true)
![](https://github.com/dengdan/blog_posts/blob/master/github_issue/showed/3.png?raw=true)

生成recordio的命令:



从recordio中读取并显示图片的代码, 在jupyter notebook中运行



忽略center crop与resize造成的影响, 请问颜色失真的原因是什么? 
",,"['https://github.com/dmlc/mxnet/issues/2161\n', '> 非常感谢. \n> 总结下, 有两种解决办法. \n> \n> ```\n> for i in range(len(data)):\n>     X = data[i].transpose((1, 2, 0))\n>     plt.figure()\n>     plt.axis(\'off\')\n>     plt.imshow(X.astype(np.uint8))\n> ```\n> \n> 或\n> \n> ```\n> for i in range(len(data)):\n>     X = data[i].transpose((1, 2, 0))\n>     X = cv2.cvtColor(X, cv2.COLOR_RGB2BGR)\n>     cv2.imwrite(""result%d.png""%(i), X)\n> ```\n']","['\n~/github/mxnet/bin/im2rec  data/train.lst imgs/ data/train.rec center_crop=1 resize=224\n', ""\nimport mxnet as mx;\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\n\ntrain_iter = mx.io.ImageRecordIter(\n    path_imgrec = 'data/train.rec',\n    data_shape  = (3, 224, 224),\n    batch_size  = 3)\n\ndata = train_iter.getdata().asnumpy()\n\nfor i in range(len(data)):\n    img = data[i].transpose((1, 2, 0))\n    plt.figure()\n    plt.axis('off')\n    plt.imshow(img)\n""]",[],0,0
413,incubator-mxnet,2499,closed,Is there any completed example on distributed yarn,"The distributed mxnet on apache hadoop yarn cannot be well trained with the data directly read from HDFS. Can anybody offers an example?
",,"['I had a same problem, expect to solve. \n', ""can't read files on hdfs? any more info?\n"", 'It can used on single machine,but not on distributed !   example, if  execute \n   ""../../tools/launch.py -n 2 -H hosts python train_mnist.py  --data-dir hdfs://hadoop01:8020/mnist/""\nit will be return error like this==>\n""CalledProcessError: Command \'ssh -o StrictHostKeyChecking=no 192.168.10.2 \'export LD_LIBRARY_PATH=/usr/local/lib:/usr/local/lib::/opt/mpich/lib::/opt/hadoop-2.6.0/lib/native/:/opt/mpich/lib; export DMLC_ROLE=worker; export DMLC_PS_ROOT_PORT=9092; export DMLC_PS_ROOT_URI=192.168.10.2; export DMLC_NUM_SERVER=2; export DMLC_NUM_WORKER=2; cd /home/hadoop/yewei/mxnet-master/example/image-classification/; python train_mnist.py --data-dir hdfs://hadoop01:8020/yaofei/mnist/\'\' returned non-zero exit status 1\n""\n""loadFileSystems error:\n(unable to get stack trace for java.lang.NoClassDefFoundError exception: ExceptionUtils::getStackTrace error.)\nhdfsBuilderConnect(forceNewInstance=0, nn=hadoop01:8020, port=0, kerbTicketCachePath=(NULL), userName=(NULL)) error:\n(unable to get stack trace for java.lang.NoClassDefFoundError exception: ExceptionUtils::getStackTrace error.)\n[10:04:11] include/dmlc/logging.h:235: [10:04:11] src/io/hdfs_filesys.cc:95: Failed to load HDFS-configuration:""\n\n Otherwise if I exectue ""mxnet/tools/launch.py   -n 2 --launcher yarn python train_mnist.py  --data-dir hdfs://hadoop01:8020/mnist/""\nIt can only running on  single machine with two processes! how to submit on yarn with multiple devices.\n', '@qiaohaijun \n', 'I get the same situation when i try to run ""mxnet/tools/launch.py -n 2 --launcher yarn python train_mnist.py --data-dir hdfs://hadoop01:8020/mnist/ "", then i find ""if args.cluster == \'local\' or args.host_file is None or args.host_file == \'None\':"" in launch.py, so that means the host file must be specified when use yarn? i\'am totally confused.\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
414,incubator-mxnet,4407,closed,How to use the function  mx.nd.slice.axis()?,"Description speaks about 4 arguments.



But inside only two.



And in fact, the function waits for two arguments.



What does parameters ""X0"" & ""out"" of the function? How to use these parameters?",,['This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!'],"['\r\n> mx.nd.slice.axis                \r\ninternal C++ function <0x36441b0>\r\n    docstring : Slice the input along certain axis and return a sliced array.\r\n\r\n@param src  NDArray\r\n    Source input to the function\r\n@param axis  int, required\r\n    The axis to be sliced\r\n@param begin  int, required\r\n    The beginning index to be sliced\r\n@param end  int, required\r\n    The end index to be sliced\r\n@return out The result mx.ndarray\r\n\r\n@export\r\n\r\n    signature : void mx.nd.slice.axis()\r\n\r\n', '\r\n> mx.nd.slice.axis@   \r\nmx.nd.slice.axis@.Data      mx.nd.slice.axis@pointer    mx.nd.slice.axis@docstring  mx.nd.slice.axis@signature\r\n\r\n> mx.nd.slice.axis@.Data\r\nfunction (X1 = NULL, out = NULL) \r\n{\r\n    .External(list(name = ""InternalFunction_invoke"", address = <pointer: 0x182b4a0>, \r\n        dll = list(name = ""Rcpp"", path = ""/usr/local/lib/R/site-library/Rcpp/libs/Rcpp.so"", \r\n            dynamicLookup = TRUE, handle = <pointer: 0x2412840>, \r\n            info = <pointer: 0x7f177895cd80>), numParameters = -1L), \r\n        <pointer: 0x36441b0>, X1, out)\r\n}\r\n<environment: 0x33232c8>\r\n', ""\r\n> str(Z$value()$data)\r\nClass 'MXNDArray' <externalptr> \r\n> mx.nd.slice.axis(Z$value()$data, 1L)\r\nError in mx.nd.slice.axis(Z$value()$data, 1L) : \r\n  expecting an external pointer\r\n> mx.nd.slice.axis(Z$value()$data, 0L)\r\nError in mx.nd.slice.axis(Z$value()$data, 0L) : \r\n  expecting an external pointer\r\n> mx.nd.slice.axis(Z$value()$data, 0L, 0L, 0L)\r\nError in mx.nd.slice.axis(Z$value()$data, 0L, 0L, 0L) : \r\n  unused arguments (0, 0)\r\n> mx.nd.slice.axis(Z$value()$data, 0L, 0L)\r\nError in mx.nd.slice.axis(Z$value()$data, 0L, 0L) : unused argument (0)\r\n\r\n""]",[],0,0
415,incubator-mxnet,10906,closed,transforms.Compose not working as expected.,"
tested both with opencv-python            3.4.0.12 from pypi.",Doc Gluon,"['You cannot resize after totensor. totensor and normalize should be called at last\r\n\r\n@zhreshold We need to properly document this', 'Submitted a PR to mention this in the documentation https://github.com/apache/incubator-mxnet/pull/12186\r\n@sandeep-krishnamurthy issue can now be closed. thanks!']","['py\r\n#!/usr/bin/env python3\r\n# %% import libs\r\nimport mxnet as mx\r\nfrom mxnet.gluon.data.vision import transforms\r\n\r\n# %% set random seed\r\nmx.random.seed(123)\r\n\r\n# %% the image\r\nimg = mx.nd.random_uniform(0,255,(1024,1024,3))\r\nimg.shape #(1024, 1024, 3)\r\nimg.mean().asscalar() # 127.47173\r\n\r\n# %%\r\ntransforms.Resize((224,320))(img).shape#(320, 224, 3)\r\ntransforms.Resize((224,320))(img).mean().asscalar()#127.2181\r\n\r\ntransforms.ToTensor()(img).shape#(3, 1024, 1024)\r\ntransforms.ToTensor()(img).mean().asscalar()#0.49988914\r\n\r\n# %% This is confusing...\r\ntransform1 = transforms.Compose(\r\n    [transforms.ToTensor(), # should be (1024, 1024, 3) => (3, 1024, 1024)\r\n    transforms.Resize((224, 320))]) # should be (3, 1024, 1024) => (320, 224, 1024)\r\n\r\n# I am confused with this 2 lines\r\ntransform1(img).shape # got (1024, 320, 224) with mxnet-mkl-1.1.0; got (320, 224, 1024) with mxnet-mkl-1.2.0b20180508\r\ntransform1(img).mean().asscalar() #got 0.00097802561 with mxnet-mkl-1.1.0;  got 0.24939652 with mxnet-mkl-1.2.0b20180508\r\n\r\n# %% This is the one works as expected.\r\ntransform2 = transforms.Compose(\r\n    [transforms.Resize((224, 320)),\r\n    transforms.ToTensor()])\r\n\r\ntransform2(img).shape#(3, 320, 224)\r\ntransform2(img).mean().asscalar() # 0.49889451\r\n\r\n# %% Guess there is a ToTensor at the end implicitly.\r\ntransform3 = transforms.Compose(\r\n    [transforms.Resize((224, 320))])\r\n\r\n# Actually not!\r\ntransform3(img).shape#(320, 224, 3)\r\ntransform3(img).mean().asscalar() # 127.2181\r\n\r\n# %% those lines works exactlly as transform1 with mxnet-mkl-1.1.0, but not with mxnet-mkl-1.2.0b20180508, why?\r\nimg_mod = transforms.ToTensor()(img)\r\nimg_mod = transforms.Resize((224, 320))(img_mod)\r\nimg_mod = transforms.ToTensor()(img_mod)\r\n\r\nimg_mod.shape#(1024, 320, 224)\r\nimg_mod.mean().asscalar() # 0.00097802561\r\n']",[],0,0
416,incubator-mxnet,4255,closed,mx.nd.save function can't be used to save into S3 bucket with periods in bucket name,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
Ubuntu 16.04

Compiler:
gcc

Package used (Python/R/Scala/Julia):
Python

MXNet version:
0.7

Or if installed from source:
Yes

MXNet commit hash ():
487c22a50541686cc3fd207ad4656dbd2f9fa969

If you are using python package, please provide

Python version and distribution:
2.7

If you are using R package, please provide

R :

## Error Message:
---------------------------------------------------------------------------
MXNetError                                Traceback (most recent call last)
<ipython-input-23-133db28d92b2> in <module>()
----> 1 mx.nd.save(""s3://imagetraining.xxxx.com/testing/a"",[a,b])

/home/ubuntu/.local/lib/python2.7/site-packages/mxnet-0.7.0-py2.7.egg/mxnet/ndarray.pyc in save(fname, data)
   1082                                   mx_uint(len(handles)),
   1083                                   c_array(NDArrayHandle, handles),
-> 1084                                   keys))
   1085 
   1086 def imdecode(str_img, clip_rect=(0, 0, 0, 0), out=None, index=0, channels=3, mean=None):

/home/ubuntu/.local/lib/python2.7/site-packages/mxnet-0.7.0-py2.7.egg/mxnet/base.pyc in check_call(ret)
     75     """"""
     76     if ret != 0:
---> 77         raise MXNetError(py_str(_LIB.MXGetLastError()))
     78 
     79 if sys.version_info[0] < 3:

MXNetError: [03:32:57] src/io/s3_filesys.cc:682: Check failed: num_retry < max_error_retry_  maximum retry time reached

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

Create a new Jyputer notebook, run the following Python , make sure that the bucket name of S3 has period in it: 

a = mx.nd.zeros((100, 200))
b = a+1
mx.nd.save(""s3://imagetraining.xxx.com/testing/a"",[a,b])




## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. Start Jupyter.
2. Create a notebook with the sample code above 
3. Run it and then will fail

## What have you tried to solve it?

1. Tried another S3 bucket without period in the bucket name. It worked.
2. In the document of S3: http://docs.aws.amazon.com/AmazonS3/latest/dev/VirtualHosting.html, found the following description:

When using virtual hosted–style buckets with SSL, the SSL wild card certificate only matches buckets that do not contain periods. To work around this, use HTTP or write your own certificate verification logic.



3. Looked into the source code dmlc-core/src/io/s3_filesys.cc:682, found that the source code is using virtual host style url to access S3, as the following code shows:

surl << ""https://"" << path_.host << "".s3.amazonaws.com"" << '/'
       << RemoveBeginSlash(path_.name) << args;

This virtual host style method will fail because of SSL issue when the target bucket has period in the bucket name.
",,"['@mli ', 'One PR was created to resolve this issue:\r\n<https://github.com/dmlc/dmlc-core/pull/203>\r\n\r\nPlease help to review it and check whether it is a proper fix.']",[],"['git rev-parse HEAD', 'sessionInfo()']",0,0
417,incubator-mxnet,9392,closed,Official version of MobileNet pretrained model and .json file,"Recently i found MobileNet gluon version of model.param.

I would like to have symbolic version of mobileNet in model.param and also .json format file.
Is anything are avilable in modelzoo with json and mobilenet.param file. 
Kindly reply...
@szha do you any updates on this.... ",,"[""Gluon model zoo has it in master branch now, which you can use to generate the json and param\r\n```python\r\nmx.gluon.model_zoo.vision.mobilenet1_0(pretrained=True).export('mobilenet1_0')\r\n```"", 'Hi szha, model has been downloaded . But while exporting to .json and .param files throws an error """"Please first call block.hybridize() and then run forward with ""\r\n                ""this block at least once before calling export.""\r\n\r\nKindly help to resolve the issue as it thrown an exception in mxnet/gluon/block.py below code\r\n\r\n    def export(self, path, epoch=0):\r\n        """"""Export HybridBlock to json format that can be loaded by `mxnet.mod.Module`\r\n        or the C++ interface.\r\n\r\n        .. note:: When there are only one input, it will have name `data`. When there\r\n                  Are more than one inputs, they will be named as `data0`, `data1`, etc.\r\n\r\n        Parameters\r\n        ----------\r\n        path : str\r\n            Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\r\n            will be created, where xxxx is the 4 digits epoch number.\r\n        epoch : int\r\n            Epoch number of saved model.\r\n        """"""\r\n        if not self._cached_graph:\r\n            raise RuntimeError(\r\n                ""Please first call block.hybridize() and then run forward with ""\r\n                ""this block at least once before calling export."")', '@szha , model has been downloaded . But while exporting to .json and .param files throws an error """"Please first call block.hybridize() and then run forward with ""\r\n""this block at least once before calling export.""\r\n\r\nKindly help to resolve the issue as it thrown an exception in mxnet/gluon/block.py below code\r\n\r\ndef export(self, path, epoch=0):\r\n    """"""Export HybridBlock to json format that can be loaded by `mxnet.mod.Module`\r\n    or the C++ interface.\r\n\r\n    .. note:: When there are only one input, it will have name `data`. When there\r\n              Are more than one inputs, they will be named as `data0`, `data1`, etc.\r\n\r\n    Parameters\r\n    ----------\r\n    path : str\r\n        Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\r\n        will be created, where xxxx is the 4 digits epoch number.\r\n    epoch : int\r\n        Epoch number of saved model.\r\n    """"""\r\n    if not self._cached_graph:\r\n        raise RuntimeError(\r\n            ""Please first call block.hybridize() and then run forward with ""\r\n            ""this block at least once before calling export."")\r\n', ""Sorry, my bad.\r\n```python\r\nnet = mx.gluon.model_zoo.vision.mobilenet1_0(pretrained=True)\r\nnet.hybridize()\r\nnet(mx.nd.ones((1,3,224,224)))\r\nnet.export('mobilenet1_0')\r\n```"", 'Got the one. Thanks its working... Closing the issue...']",[],[],0,0
418,incubator-mxnet,8914,closed,The custom operator not supported for group context?,"## Description
The group context was used for model parallelism of neural network train. The mx.sym.LogisticRegressionOutput works when it's been used for loss calculation, but not customized operator.

## Environment info (Required)
OS: Ubuntu 14.04.5 LTS
Python: 2.7.13
mxnet: 0.12.1, pulled from master branch and built from source

Package used (Python/R/Scala/Julia):
Python: mxnet, numpy, scipy

## Build info (Required if built from source)
Bulit from command line by following https://mxnet.incubator.apache.org/get_started/install.html

MXNet commit hash:
2f8c1e83f94e84a25a48d2cd43136030fb3f2d1e

Build config:
Only change is to enable the profiler.

## Error Message:
Traceback (most recent call last):
  File ""_ctypes/callbacks.c"", line 315, in 'calling callback function'
  File ""/git/mxnet/python/mxnet/operator.py"", line 621, in creator
    op_prop = prop_cls(**kwargs)
TypeError: __init__() got an unexpected keyword argument '__ctx_group__'

## Minimum reproducible example
The script to generate the network, which works:

...
fc2 = mx.symbol.FullyConnected(data=concat, name='fcout_'+str(gpu), num_hidden=out_dim/num_gpus)
loss = mx.sym.LogisticRegressionOutput(data=fc2, label=labs)

The script to generate the network which used customized operator, and didn't work:

...
fc2 = mx.symbol.FullyConnected(data=concat, name='fcout_'+str(gpu), num_hidden=out_dim/num_gpus)
act2 = mx.sym.Activation(data=fc2, name='acout_'+str(gpu), act_type='sigmoid')
loss = mx.sym.Custom(data=act2, label=label, name='ce_'+str(gpu), op_type='CrossEntropyLoss')

Is this because the custom op is not support yet for group context?",Bug Operator Pending Requester Info,"['@mg0880gm could you try latest version of MXNet and update the `__init__` function of your `XXCustomOpProp` from \r\n```\r\ndef __init__(self):\r\n```\r\nto \r\n```\r\ndef __init__(self, **kwargs):\r\n```\r\nAnd see if it works? ', 'Can you please add the labels - ""Operator"", ""Bug"", ""Question"", ""Pending Requester Info""', '@mg0880gm are you still seeing this issue with the latest version of mxnet ?\r\n', 'Verified on my end that the fix works. ']",[],[],0,0
419,incubator-mxnet,15337,closed,Current MXNet-Dev master breaks loading of certain models,"## Description
The current MXNET master dev branch, pypi version 1.5.0b20190623 breaks the loading of certain MXNET-models (both in mxnet-mkl & mxnet-cu100), which previously were loaded successfully with mxnet==1.4.1.
The model uses grouped depthwise (a.ka. depthwise seperable) convolutions which could be the cause for this issue because other models (e.g.  CrazyAraFish_0.5.0_RiseV1.zip) still work correctly as usual.

## Environment info
I'm using python, but the same problem also occurs when building the MXNET-CPP package from source.

## Error Message:


## Minimum reproducible example

## Steps to reproduce

Download  release  at:
* https://github.com/QueensGambit/CrazyAra/releases
Install [python-chess](https://github.com/niklasf/python-chess).


Extract  and run 

from the commandline.
More details for install instructions can be found here:
* [Install Guide](https://github.com/QueensGambit/CrazyAra/wiki/Installation-Guide)

Alternatively, you can load the mxnet model from the  directory manually in python.

Does someones have an idea what recent change causes this?
Can you include more automated unit tests for MXNET to ensure that the loading of different model types is preserved for version updates?
",Backend Bug,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Bug', '@mxnet-label-bot add [Bug]', '@mxnet-label-bot add [Backend]', 'This issue might also be related to https://github.com/apache/incubator-mxnet/issues/15281.', 'Hi @QueensGambit I\'m getting file not found error when following the steps to reproduce\r\n\r\nI do have `model-1.19246-0.603-0223.params` under `model/params`\r\n\r\n```\r\nuciok\r\n\r\nisready\r\ninfo string The given batch_size 8 is higher than the number of threads 4. The maximum legal batch_size is the same as the number of threads (here: 4) \r\ninfo string The batch_size was reduced to 4\r\nTraceback (most recent call last):\r\n  File ""crazyara.py"", line 734, in main\r\n    self.setup_network()\r\n  File ""crazyara.py"", line 169, in setup_network\r\n    model_weights_dir=self.settings[""model_weights_dir""]))\r\n  File ""/Users/lawei/Downloads/CrazyAra_0.5.0_RiseV2_mobile/DeepCrazyhouse/src/domain/agent/neural_net_api.py"", line 60, in __init__\r\n    + \'. Please make sure that the path has a ""/"" at the end of the path.\'\r\nException: No params file (.params) was found in your given model_weights_dir: ./model/params/. Please make sure that the path has a ""/"" at the end of the path.\r\n```', 'Also I\'m getting parameter not found when trying to load the symbol and params directly\r\n```\r\n>>> gluon.nn.SymbolBlock.imports(""model-1.19246-0.603-symbol.json"", [\'data\'], ""model-1.19246-0.603-0223.params"")\r\n```\r\n\r\n```\r\n\r\n[13:25:51] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v1.4.1. Attempting to upgrade...\r\n[13:25:51] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\r\n/Users/lawei/anaconda3/lib/python3.6/site-packages/mxnet/gluon/block.py:1159: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:\r\n\tdata: None\r\n  input_sym_arg_type = in_param.infer_type()[0]\r\nTraceback (most recent call last):\r\n  File ""<stdin>"", line 1, in <module>\r\n  File ""/Users/lawei/anaconda3/lib/python3.6/site-packages/mxnet/gluon/block.py"", line 1037, in imports\r\n    ret.collect_params().load(param_file, ctx=ctx, cast_dtype=True, dtype_source=\'saved\')\r\n  File ""/Users/lawei/anaconda3/lib/python3.6/site-packages/mxnet/gluon/parameter.py"", line 960, in load\r\n    ignore_extra, restore_prefix, filename, cast_dtype, dtype_source)\r\n  File ""/Users/lawei/anaconda3/lib/python3.6/site-packages/mxnet/gluon/parameter.py"", line 995, in load_dict\r\n    name[lprefix:], error_str, _brief_print_list(arg_dict.keys()))\r\nAssertionError: Parameter \'value_label\' is missing in file: model-1.19246-0.603-0223.params, which contains parameters: \'stem_conv0_weight\', \'stem_bn0_gamma\', \'stem_bn0_beta\', ..., \'value_bn0_moving_mean\', \'value_bn0_moving_var\', \'policy_bn0_moving_mean\', \'policy_bn0_moving_var\'. Please make sure source and target networks have the same prefix.\r\n```', '@roywei Thank your for the reply.\r\nSorry, for the inconvenience there was apparently a `/` missing in the relative path of the config-files which I released. I just updated the .zip-Release files and it should work again for MXNet 1.4.1.\r\n\r\nThis is the code how the model is currently loaded:\r\nhttps://github.com/QueensGambit/CrazyAra/blob/master/DeepCrazyhouse/src/domain/agent/neural_net_api.py#L66\r\n\r\n```python\r\n        sym = mx.sym.load(self.symbol_path)\r\n        # https://github.com/apache/incubator-mxnet/issues/6951\r\n        save_dict = mx.nd.load(self.params_path)\r\n        arg_params = {}\r\n        aux_params = {}\r\n        for key, val in save_dict.items():\r\n            param_type, name = key.split("":"", 1)\r\n            if param_type == ""arg"":\r\n                arg_params[name] = val\r\n            if param_type == ""aux"":\r\n                aux_params[name] = val\r\n        # set the context on CPU, switch to GPU if there is one available\r\n        if ctx == ""cpu"":\r\n            self.ctx = mx.cpu()\r\n        elif ctx == ""gpu"":\r\n            self.ctx = mx.gpu()\r\n        else:\r\n            raise Exception(""Unavailable ctx mode given %s. You must either select \'cpu\' or \'gpu\'"" % ctx)\r\n        # define batch_size times executor objects which are used for inference\r\n        # one executor object is used for the currently requested batch batch length\r\n        # the requested batch length is variable and at maximum the given batch_size\r\n        self.executors = []\r\n        for i in range(batch_size):\r\n            executor = sym.simple_bind(\r\n                ctx=self.ctx,\r\n                # add a new length for each size starting with 1\r\n                data=(i + 1, NB_CHANNELS_FULL, BOARD_HEIGHT, BOARD_WIDTH),\r\n                grad_req=""null"",\r\n                force_rebind=True,\r\n            )\r\n            executor.copy_params_from(arg_params, aux_params)\r\n            self.executors.append(executor)\r\n```', ""I think, I know why the loading fails, thank you for help @roywei. It's because I ported the training code from Gluon to MXNet for this model. The reason for this was that I experienced long delays during training due to `MXNET_CUDNN_AUTOTUNE_DEFAULT` calls:\r\n* https://github.com/apache/incubator-mxnet/issues/15529\r\n \r\nApparently in MXNet version 1.4.1 the code above works successfully and ignores the missing label information whereas version 1.5.0 blocks it, which is a behaviour I appreciate.\r\n\r\nUsing this code I'm able to successfully load the model both in version MXNet 1.4.1 and MXNet 1.5.0:\r\n```python\r\nmodel_arch_path = 'model-1.19246-0.603-symbol.json'\r\nmodel_params_path = 'model-1.19246-0.603-0223.params'\r\nctx = mx.cpu()\r\nsymbol = mx.sym.load(model_arch_path)\r\ninputs = mx.sym.var('data', dtype='float32')\r\nvalue_out = symbol.get_internals()['value_tanh0_output']\r\npolicy_out = symbol.get_internals()['flatten0_output']\r\nsym = mx.symbol.Group([value_out, policy_out])\r\nnet = mx.gluon.SymbolBlock(sym, inputs)\r\nnet.collect_params().load(model_params_path, ctx)\r\n```\r\nConsequently, this issue can be closed."", 'See [insightface #764](https://github.com/deepinsight/insightface/issues/764)']","['python\r\nisready\r\nself.symbol_path: /home/queensgambit/Programming/Deep_Learning/models/risev2/symbol/model-1.19246-0.603-symbol.json\r\nself.params_path: /home/queensgambit/Programming/Deep_Learning/models/risev2/params/model-1.19246-0.603-0223.params\r\n[00:35:51] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v1.4.1. Attempting to upgrade...\r\n[00:35:51] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\r\nTraceback (most recent call last):\r\n  File ""/home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/symbol/symbol.py"", line 1623, in simple_bind\r\n    ctypes.byref(exe_handle)))\r\n  File ""/home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/base.py"", line 253, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: Error in operator value: [00:35:51] include/mxnet/./tuple.h:202: Check failed: i >= 0 && i < ndim(): index = 0 must be in range [0, -1)\r\nStack trace:\r\n  [bt] (0) /home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25b3ab) [0x7f186bc433ab]\r\n  [bt] (1) /home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2c5343) [0x7f186bcad343]\r\n  [bt] (2) /home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x298bf82) [0x7f186e373f82]\r\n  [bt] (3) /home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2471ee2) [0x7f186de59ee2]\r\n  [bt] (4) /home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2474794) [0x7f186de5c794]\r\n  [bt] (5) /home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::exec::GraphExecutor::Init(nnvm::Symbol, mxnet::Context const&, std::map<std::string, mxnet::Context, std::less<std::string>, std::allocator<std::pair<std::string const, mxnet::Context> > > const&, std::vector<mxnet::Context, std::allocator<mxnet::Context> > const&, std::vector<mxnet::Context, std::allocator<mxnet::Context> > const&, std::vector<mxnet::Context, std::allocator<mxnet::Context> > const&, std::unordered_map<std::string, mxnet::TShape, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, mxnet::TShape> > > const&, std::unordered_map<std::string, int, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, int> > > const&, std::unordered_map<std::string, int, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, int> > > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> >*, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> >*, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> >*, std::unordered_map<std::string, mxnet::NDArray, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, mxnet::NDArray> > >*, mxnet::Executor*, std::unordered_map<nnvm::NodeEntry, mxnet::NDArray, nnvm::NodeEntryHash, nnvm::NodeEntryEqual, std::allocator<std::pair<nnvm::NodeEntry const, mxnet::NDArray> > > const&)+0x355) [0x7f186de48455]\r\n  [bt] (6) /home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::Executor::SimpleBind(nnvm::Symbol, mxnet::Context const&, std::map<std::string, mxnet::Context, std::less<std::string>, std::allocator<std::pair<std::string const, mxnet::Context> > > const&, std::vector<mxnet::Context, std::allocator<mxnet::Context> > const&, std::vector<mxnet::Context, std::allocator<mxnet::Context> > const&, std::vector<mxnet::Context, std::allocator<mxnet::Context> > const&, std::unordered_map<std::string, mxnet::TShape, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, mxnet::TShape> > > const&, std::unordered_map<std::string, int, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, int> > > const&, std::unordered_map<std::string, int, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, int> > > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> >*, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> >*, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> >*, std::unordered_map<std::string, mxnet::NDArray, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, mxnet::NDArray> > >*, mxnet::Executor*)+0x8a8) [0x7f186de49688]\r\n  [bt] (7) /home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(MXExecutorSimpleBindEx+0x221b) [0x7f186dd9884b]\r\n  [bt] (8) /home/queensgambit/anaconda3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f1872e3eec0]\r\n\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File ""crazyara.py"", line 668, in main\r\n    self.setup_network()\r\n  File ""crazyara.py"", line 166, in setup_network\r\n    model_weights_dir=self.settings[""model_weights_dir""]))\r\n  File ""/home/queensgambit/Programming/Deep_Learning/CrazyAra/DeepCrazyhouse/src/domain/agent/neural_net_api.py"", line 95, in __init__\r\n    force_rebind=True,\r\n  File ""/home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/symbol/symbol.py"", line 1629, in simple_bind\r\n    raise RuntimeError(error_msg)\r\nRuntimeError: simple_bind error. Arguments:\r\ndata: (1, 34, 8, 8)\r\nforce_rebind: True\r\nError in operator value: [00:35:51] include/mxnet/./tuple.h:202: Check failed: i >= 0 && i < ndim(): index = 0 must be in range [0, -1)\r\nStack trace:\r\n  [bt] (0) /home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25b3ab) [0x7f186bc433ab]\r\n  [bt] (1) /home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2c5343) [0x7f186bcad343]\r\n  [bt] (2) /home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x298bf82) [0x7f186e373f82]\r\n  [bt] (3) /home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2471ee2) [0x7f186de59ee2]\r\n  [bt] (4) /home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2474794) [0x7f186de5c794]\r\n  [bt] (5) /home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::exec::GraphExecutor::Init(nnvm::Symbol, mxnet::Context const&, std::map<std::string, mxnet::Context, std::less<std::string>, std::allocator<std::pair<std::string const, mxnet::Context> > > const&, std::vector<mxnet::Context, std::allocator<mxnet::Context> > const&, std::vector<mxnet::Context, std::allocator<mxnet::Context> > const&, std::vector<mxnet::Context, std::allocator<mxnet::Context> > const&, std::unordered_map<std::string, mxnet::TShape, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, mxnet::TShape> > > const&, std::unordered_map<std::string, int, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, int> > > const&, std::unordered_map<std::string, int, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, int> > > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> >*, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> >*, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> >*, std::unordered_map<std::string, mxnet::NDArray, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, mxnet::NDArray> > >*, mxnet::Executor*, std::unordered_map<nnvm::NodeEntry, mxnet::NDArray, nnvm::NodeEntryHash, nnvm::NodeEntryEqual, std::allocator<std::pair<nnvm::NodeEntry const, mxnet::NDArray> > > const&)+0x355) [0x7f186de48455]\r\n  [bt] (6) /home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::Executor::SimpleBind(nnvm::Symbol, mxnet::Context const&, std::map<std::string, mxnet::Context, std::less<std::string>, std::allocator<std::pair<std::string const, mxnet::Context> > > const&, std::vector<mxnet::Context, std::allocator<mxnet::Context> > const&, std::vector<mxnet::Context, std::allocator<mxnet::Context> > const&, std::vector<mxnet::Context, std::allocator<mxnet::Context> > const&, std::unordered_map<std::string, mxnet::TShape, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, mxnet::TShape> > > const&, std::unordered_map<std::string, int, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, int> > > const&, std::unordered_map<std::string, int, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, int> > > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::unordered_set<std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::string> > const&, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> >*, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> >*, std::vector<mxnet::NDArray, std::allocator<mxnet::NDArray> >*, std::unordered_map<std::string, mxnet::NDArray, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, mxnet::NDArray> > >*, mxnet::Executor*)+0x8a8) [0x7f186de49688]\r\n  [bt] (7) /home/queensgambit/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(MXExecutorSimpleBindEx+0x221b) [0x7f186dd9884b]\r\n  [bt] (8) /home/queensgambit/anaconda3/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f1872e3eec0]\r\n', '\r\npip install python-chess\r\n', '\r\n$ python crazyara.py\r\n$ uci\r\n$ isready\r\n']","['CrazyAra_0.5.0_RiseV2_mobile.zip', 'CrazyAra_0.5.0_RiseV2_mobile.zip', 'model/']",0,0
420,incubator-mxnet,695,closed,mnist example disappeared,"why?
at the very least the doc has to be updated
",,"[""It's here I think https://github.com/dmlc/mxnet/blob/master/example/image-classification/train_mnist.py\n"", '@mli \n', 'fixed on #698 \n']",[],[],0,0
421,incubator-mxnet,8685,closed,Error Adding file-set for 'ml.dmlc.mxnet:libmxnet-scala-osx-x86_64-cpu:jnilib:v0.11.1a',"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
I am currently running into an error when trying to build a single jar on OSX. I get the following error:  

## Environment info (Required)
Mac OSX. Maven. Scala

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: 1.8.0_144
2. Maven version: 3.5.0
3. Scala runtime if applicable:  2.11.8

## Error Message:


## Minimum reproducible example
Below are my maven dependencies, plugins, and assembly.xml:





assembly.xml:





## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. Use dependencies and plug from pom above.

## What have you tried to solve it?

1. I added the assembly.xml page, but didn't have any luck with jni.
",,['Solved this issue by using <scope>provided</scope>'],"[""\r\nFailed to create assembly: Error adding file-set for 'ml.dmlc.mxnet:libmxnet-scala-osx-x86_64-cpu:jnilib:v0.11.1a' to archive: Error adding archived file-set. PlexusIoResourceCollection not found for: /Users/username/.m2/repository/ml/dmlc/mxnet/libmxnet-scala-osx-x86_64-cpu/v0.11.1a/libmxnet-scala-osx-x86_64-cpu-v0.11.1a.jnilib: No such archiver: 'jnilib'. \r\n"", ""\r\nFailed to create assembly: Error adding file-set for 'ml.dmlc.mxnet:libmxnet-scala-osx-x86_64-cpu:jnilib:v0.11.1a' to archive: Error adding archived file-set. PlexusIoResourceCollection not found for: /Users/dmmiller/.m2/repository/ml/dmlc/mxnet/libmxnet-scala-osx-x86_64-cpu/v0.11.1a/libmxnet-scala-osx-x86_64-cpu-v0.11.1a.jnilib: No such archiver: 'jnilib'. \r\n"", 'xml\r\n    <dependencies>\r\n\r\n        <dependency>\r\n            <groupId>ml.dmlc.mxnet</groupId>\r\n            <artifactId>mxnet-full_2.11-osx-x86_64-cpu</artifactId>\r\n            <version>v0.11.1a</version>\r\n            <exclusions>\r\n                <exclusion>\r\n                    <groupId>*</groupId>\r\n                    <artifactId>*</artifactId>\r\n                </exclusion>\r\n            </exclusions>\r\n        </dependency>\r\n\r\n        <dependency>\r\n            <groupId>args4j</groupId>\r\n            <artifactId>args4j</artifactId>\r\n            <version>2.33</version>\r\n        </dependency>\r\n\r\n    </dependencies>\r\n', 'xml\r\n            <plugin>\r\n                <groupId>org.apache.maven.plugins</groupId>\r\n                <artifactId>maven-assembly-plugin</artifactId>\r\n                <version>3.0.0</version>\r\n                <configuration>\r\n                    <appendAssemblyId>false</appendAssemblyId>\r\n\r\n                    <descriptors>\r\n                        <descriptor>src/main/assembly/assembly.xml</descriptor>\r\n                    </descriptors>\r\n                    <!-- get all project dependencies -->\r\n                    <descriptorRefs>\r\n\r\n                        <descriptorRef>jar-with-dependencies</descriptorRef>\r\n                    </descriptorRefs>\r\n                    <!-- MainClass in mainfest make a executable jar -->\r\n                    <archive>\r\n                        <manifest>\r\n                            <mainClass>com.our.stuff.MainData</mainClass>\r\n                        </manifest>\r\n                    </archive>\r\n\r\n                </configuration>\r\n                <executions>\r\n                    <execution>\r\n                        <id>make-assembly</id>\r\n                        <!-- bind to the packaging phase -->\r\n                        <phase>package</phase>\r\n                        <goals>\r\n                            <goal>single</goal>\r\n                        </goals>\r\n                    </execution>\r\n                </executions>\r\n            </plugin>\r\n', '\r\n<assembly xmlns=""http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""\r\n          xsi:schemaLocation=""http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2 http://maven.apache.org/xsd/assembly-1.1.2.xsd"">\r\n\r\n    <id>assembly-with-jnilib</id>\r\n    <formats>\r\n        <format>jar</format>\r\n    </formats>\r\n    <includeBaseDirectory>false</includeBaseDirectory>\r\n    <dependencySets>\r\n        <!-- package the regular dependencies -->\r\n        <dependencySet>\r\n            <outputDirectory>/</outputDirectory>\r\n            <useProjectArtifact>true</useProjectArtifact>\r\n            <unpack>true</unpack>\r\n            <scope>runtime</scope>\r\n            <excludes>\r\n                <exclude>ml.dmlc.mxnet:libmxnet-scala-osx-x86_64-cpu:jnilib:v0.11.1a</exclude>\r\n            </excludes>\r\n        </dependencySet>\r\n        <dependencySet>\r\n            <outputDirectory>/</outputDirectory>\r\n            <includes>\r\n                <include>ml.dmlc.mxnet:libmxnet-scala-osx-x86_64-cpu:jnilib:v0.11.1a</include>\r\n            </includes>\r\n        </dependencySet>\r\n    </dependencySets>\r\n</assembly>\r\n']",[],0,0
422,incubator-mxnet,7224,closed,Passing gradient between 2 networks,"Hello,

I'd like to use a LSTM in combination with a CNN as a feature extractor to classify videos. I am using mxnet -cu80 0.10.0.post2 in python 2.7.9. I have a pretrained resnet-50 which is loaded and then I chop off the final classification layer:


The LSTM expects an input in the NTC format, thus my forward pass first puts the entire sequence through the CNN and then  reshapes the extracted features to match the LSTM. The LSTM bind looks like this (All sequences have the same length in my model so I don't use bucketing): 

And here is the forward backward pass:




However this only works up the cnn backward pass where I get the following error which I really do not understand as the output of the CNN has exactly the same dimension as the gradient of the LSTM after reshaping and I tried to follow the dcgan example which uses a similar technique.




I should mention that 2048 is the feature dimension of the last resnet layer, the sequence lenght is fixed to 10 and batch_size (in this case the number of sequences per batch) is 2, so this explains the 20 and 2048. So lstm_grad is an NDArray of size 20x2048 and so is the cnn_output. 

Thank's for your help,
Max 


",,"['This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!\nAlso, do please check out our [forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) for general ""how-to"" questions.']","[""\r\n    symbol, arg_params, aux_params = mx.model.load_checkpoint(model_prefix, load_epoch)\r\n    all_layers = sym.get_internals()\r\n    fe_sym = all_layers[last_layer + '_output']\r\n    fe_mod = mx.mod.Module(symbol=fe_sym, data_names=('data',), label_names=None, context=cnn_dev)\r\n    data shape = [('data', (batch_size*sequence_length, 3, 224, 224 ))]\r\n    fe_mod.bind(for_training=True, data_shapes=data_shape)\r\n    fe_mod.init_params(arg_params=arg_params, aux_params=aux_params, allow_missing=False)\r\n    return fe_mod\r\n"", ""\r\n    lstm_mod = mx.mod.Module(symbol=sym, context=lstm_dev, data_names=['data'], label_names=['softmax_label'])\r\n    data_shape = [('data', (batch_size, sequence_length, feature_dim ))]\r\n    label_shapes =[('softmax_label',(batch_size,))]\r\n    lstm_mod.bind(for_training=True, data_shapes=data_shape, label_shapes=label_shapes, inputs_need_grad=True)\r\n"", '\r\n    #Feature extraction\r\n    cnn_mod.forward(cnn_batch, is_train=True)\r\n    cnn_output = cnn_mod.get_outputs()[0]\r\n\r\n    #NTC layout\r\n    features = mx.nd.reshape(cnn_output, shape=(batch_size,sequence_length,feature_dim))\r\n\r\n    lstm_batch = mx.io.DataBatch([features], [labels])\r\n\r\n    lstm_mod.forward(lstm_batch, is_train=True)\r\n    lstm_mod.backward()\r\n    lstm_mod.update()\r\n\r\n    lstm_grad = lstm_mod.get_input_grads()[0]\r\n    lstm_grad = mx.nd.reshape(lstm_grad, shape=(batch_size*sequence_length,feature_dim))\r\n\r\n    cnn_mod.backward(lstm_grad)\r\n    cnn_mod.update()\r\n\r\n', '\r\n[21:46:24] /home/travis/build/dmlc/mxnet-distro/mxnet-build/dmlc-core/include/dmlc/logging.h:304: [21:46:24] src/ndarray/ndarray.cc:299: Check failed: from.shape() == to->shape() operands shape mismatchfrom.shape = (20,) to.shape=(20,2048)\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /home/max/venv/venv_caffe/local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0x19fd3c) [0x7f636ba53d3c]\r\n[bt] (1) /home/max/venv/venv_caffe/local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xe20105) [0x7f636c6d4105]\r\n[bt] (2) /home/max/venv/venv_caffe/local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xd4c5a3) [0x7f636c6005a3]\r\n[bt] (3) /home/max/venv/venv_caffe/local/lib/python2.7/site-packages/mxnet/libmxnet.so(MXExecutorBackward+0x1c8) [0x7f636c59f108]\r\n[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f6392eb1f60]\r\n[bt] (5) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x2f8) [0x7f6392eb19c8]\r\n[bt] (6) /home/max/venv/venv_caffe/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x495) [0x7f63930c2055]\r\n[bt] (7) /home/max/venv/venv_caffe/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x119b2) [0x7f63930c69b2]\r\n[bt] (8) /home/max/venv/venv_caffe/bin/python(PyEval_EvalFrameEx+0x104b) [0x4c9e8b]\r\n[bt] (9) /home/max/venv/venv_caffe/bin/python(PyEval_EvalCodeEx+0x3c9) [0x4c7a59]\r\n\r\nTraceback (most recent call last):\r\n  File ""/opt/pycharm-2017.1.3/helpers/pydev/pydevd.py"", line 1585, in <module>\r\n    globals = debugger.run(setup[\'file\'], None, None, is_module)\r\n  File ""/opt/pycharm-2017.1.3/helpers/pydev/pydevd.py"", line 1015, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File ""/home/max/hlcv_project/mxnet_network/finetuning_sequenceCombined.py"", line 304, in <module>\r\n    main()\r\n  File ""/home/max/hlcv_project/mxnet_network/finetuning_sequenceCombined.py"", line 301, in main\r\n    train_model(model, model_dir, load_subdir, load_epoch, batch_size, gpu1, gpu2, epochs, lr)\r\n  File ""/home/max/hlcv_project/mxnet_network/finetuning_sequenceCombined.py"", line 182, in train_model\r\n    feature_dim, batch_metric, epoch_metric)\r\n  File ""/home/max/hlcv_project/mxnet_network/finetuning_sequenceCombined.py"", line 82, in combined_model_forward_backward\r\n    cnn_mod.backward(grad_cpu)\r\n  File ""/home/max/venv/venv_caffe/local/lib/python2.7/site-packages/mxnet/module/module.py"", line 559, in backward\r\n    self._exec_group.backward(out_grads=out_grads)\r\n  File ""/home/max/venv/venv_caffe/local/lib/python2.7/site-packages/mxnet/module/executor_group.py"", line 528, in backward\r\n    exec_.backward(out_grads=out_grads_slice)\r\n  File ""/home/max/venv/venv_caffe/local/lib/python2.7/site-packages/mxnet/executor.py"", line 217, in backward\r\n    ndarray))\r\n  File ""/home/max/venv/venv_caffe/local/lib/python2.7/site-packages/mxnet/base.py"", line 84, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [21:46:24] src/ndarray/ndarray.cc:299: Check failed: from.shape() == to->shape() operands shape mismatchfrom.shape = (20,) to.shape=(20,2048)\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /home/max/venv/venv_caffe/local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0x19fd3c) [0x7f636ba53d3c]\r\n[bt] (1) /home/max/venv/venv_caffe/local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xe20105) [0x7f636c6d4105]\r\n[bt] (2) /home/max/venv/venv_caffe/local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xd4c5a3) [0x7f636c6005a3]\r\n[bt] (3) /home/max/venv/venv_caffe/local/lib/python2.7/site-packages/mxnet/libmxnet.so(MXExecutorBackward+0x1c8) [0x7f636c59f108]\r\n[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f6392eb1f60]\r\n[bt] (5) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x2f8) [0x7f6392eb19c8]\r\n[bt] (6) /home/max/venv/venv_caffe/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x495) [0x7f63930c2055]\r\n[bt] (7) /home/max/venv/venv_caffe/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x119b2) [0x7f63930c69b2]\r\n[bt] (8) /home/max/venv/venv_caffe/bin/python(PyEval_EvalFrameEx+0x104b) [0x4c9e8b]\r\n[bt] (9) /home/max/venv/venv_caffe/bin/python(PyEval_EvalCodeEx+0x3c9) [0x4c7a59]\r\n\r\n\r\nProcess finished with exit code 1\r\n\r\n']",[],0,0
423,incubator-mxnet,10901,closed,Broken test_sparse_operator.test_sparse_mathematical_core with scipy 1.1.0,"Check out the latest master, build it with . 
Run with . 
Happens on all configurations, no matter whether CPU or GPU etc.

",Breaking Bug Flaky Operator Test,"['This seems to be related to the scipy version. This test breaks with scipy 1.1.0, but works with 1.0.1.', ""```\r\n+ set +x\r\n+ export PYTHONPATH=./python/\r\n+ PYTHONPATH=./python/\r\n+ export MXNET_STORAGE_FALLBACK_LOG_VERBOSE=0\r\n+ MXNET_STORAGE_FALLBACK_LOG_VERBOSE=0\r\n+ pip2 install scipy==1.0.1\r\nCollecting scipy==1.0.1\r\n  Downloading https://files.pythonhosted.org/packages/9c/0b/5deb712a9ea5bb0a1de837d04ef7625c5f3ee44efe7ed0765ceda681d7f1/scipy-1.0.1-cp27-cp27mu-manylinux1_x86_64.whl (46.7MB)\r\n    100% |################################| 46.7MB 974kB/s\r\nRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0.1) (1.14.3)\r\nmatplotlib 2.2.2 has requirement python-dateutil>=2.1, but you'll have python-dateutil 1.5 which is incompatible.\r\nInstalling collected packages: scipy\r\n  Found existing installation: scipy 1.1.0\r\n    Uninstalling scipy-1.1.0:\r\n      Successfully uninstalled scipy-1.1.0\r\nSuccessfully installed scipy-1.0.1\r\n+ pip3 install scipy==1.0.1\r\nCollecting scipy==1.0.1\r\n  Cache entry deserialization failed, entry ignored\r\n  Downloading https://files.pythonhosted.org/packages/51/3d/494e1a81121c12233cb2f511e31b0dae3944008c81bbfa0218ec2d0038a8/scipy-1.0.1-cp35-cp35m-manylinux1_x86_64.whl (49.6MB)\r\n    100% |################################| 49.7MB 1.4MB/s\r\nRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.5/dist-packages (from scipy==1.0.1) (1.14.3)\r\nInstalling collected packages: scipy\r\n  Found existing installation: scipy 1.1.0\r\n    Uninstalling scipy-1.1.0:\r\n      Successfully uninstalled scipy-1.1.0\r\nSuccessfully installed scipy-1.0.1\r\n+ nosetests-2.7 --verbose tests/python/unittest/test_sparse_operator.py:test_sparse_mathematical_core\r\n[INFO] Setting module np/mx/python random seeds, use MXNET_MODULE_SEED=1319374570 to reproduce.\r\ntest_sparse_operator.test_sparse_mathematical_core ... ok\r\n\r\n----------------------------------------------------------------------\r\nRan 1 test in 5.101s\r\n\r\nOK\r\n```"", 'Do we know the cause of this bug? @eric-haibin-lin ', 'We saw that in our internal testing and  @DickJC123 made some investigation yesterday. @DickJC123 - could you share your findings?', 'https://github.com/apache/incubator-mxnet/issues/10896', 'I also filed an issue with scipy: https://github.com/scipy/scipy/issues/8819', 'Fixed by https://github.com/apache/incubator-mxnet/pull/10961 ']","['ci/build.py --platform ubuntu_cpu /work/runtime_functions.sh build_ubuntu_cpu_openblas', 'ci/build.py --platform ubuntu_cpu /work/runtime_functions.sh unittest_ubuntu_python2_cpu', '\r\nbuild.py: 2018-05-11 08:49:35,496 Executing: docker run --rm -t --shm-size=500m -v /home/ubuntu/mxnet-apache:/work/mxnet -v /home/ubuntu/mxnet-apache/build:/work/build -u 0:0 mxnet/build.ubuntu_cpu /work/runtime_functions.sh unittest_ubuntu_python2_cpu\r\n+ set +x\r\n+ export PYTHONPATH=./python/\r\n+ PYTHONPATH=./python/\r\n+ export MXNET_STORAGE_FALLBACK_LOG_VERBOSE=0\r\n+ MXNET_STORAGE_FALLBACK_LOG_VERBOSE=0\r\n+ nosetests-2.7 --verbose tests/python/unittest/test_sparse_operator.py:test_sparse_mathematical_core\r\n[INFO] Setting module np/mx/python random seeds, use MXNET_MODULE_SEED=1188828163 to reproduce.\r\ntest_sparse_operator.test_sparse_mathematical_core ... [INFO] Setting test np/mx/python random seeds, use MXNET_TEST_SEED=1220244381 to reproduce.\r\nFAIL\r\n\r\n======================================================================\r\nFAIL: test_sparse_operator.test_sparse_mathematical_core\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File ""/usr/local/lib/python2.7/dist-packages/nose/case.py"", line 197, in runTest\r\n    self.test(*self.arg)\r\n  File ""/work/mxnet/tests/python/unittest/common.py"", line 157, in test_new\r\n    orig_test(*args, **kwargs)\r\n  File ""/work/mxnet/tests/python/unittest/test_sparse_operator.py"", line 1084, in test_sparse_mathematical_core\r\n    density=density, ograd_density=ograd_density)\r\n  File ""/work/mxnet/tests/python/unittest/test_sparse_operator.py"", line 1056, in check_mathematical_core\r\n    density=density, ograd_density=ograd_density)\r\n  File ""/work/mxnet/tests/python/unittest/test_sparse_operator.py"", line 698, in check_sparse_mathematical_core\r\n    assert_almost_equal(arr_grad, input_grad, equal_nan=True)\r\n  File ""/work/mxnet/python/mxnet/test_utils.py"", line 493, in assert_almost_equal\r\n    raise AssertionError(msg)\r\nAssertionError:\r\nItems are not equal:\r\nError nan exceeds tolerance rtol=0.000010, atol=0.000000.  Location of maximum error:(0, 0), a=inf, b=-inf\r\n a: array([[inf, inf, inf, inf, inf],\r\n       [inf, inf, inf, inf, inf],\r\n       [inf, inf, inf, inf, inf],...\r\n b: array([[-inf, -inf, -inf, -inf, -inf],\r\n       [-inf, -inf, -inf, -inf, -inf],\r\n       [-inf, -inf, -inf, -inf, -inf],...\r\n-------------------- >> begin captured stdout << ---------------------\r\n(\'pass\', 0)\r\n0.0, 0.0, False\r\n\r\n--------------------- >> end captured stdout << ----------------------\r\n-------------------- >> begin captured logging << --------------------\r\ncommon: INFO: Setting module np/mx/python random seeds, use MXNET_MODULE_SEED=1188828163 to reproduce.\r\ncommon: INFO: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=1220244381 to reproduce.\r\n--------------------- >> end captured logging << ---------------------\r\n\r\n----------------------------------------------------------------------\r\nRan 1 test in 0.031s\r\n\r\nFAILED (failures=1)\r\n']",[],0,0
424,incubator-mxnet,1336,closed,Issue installing mxnet R-package using gpu on Windows,"Hi, I'm having problems trying to install mxnet in R when using the pre-built windows binary hosted here 
https://github.com/dmlc/mxnet/releases

and using the instructions on the Installation Guide page. All seems to work ok, in that the mxnet library for R gets created. However, when I run the Handwritten Digits Tutorial using LeNet, when using the gpu it doesn't seem to optimise correctly. I've downloaded the windows release and the zip from github today.

Training using cpu (similar to example) 
Start training with 1 devices
[1] Train-accuracy=0.55708830548926

Training using gpu (different to example)
Start training with 1 devices
[1] Train-accuracy=0.0983770883054893
[2] Train-accuracy=0.0983809523809524
[3] Train-accuracy=0.0983809523809524
[4] Train-accuracy=0.0983809523809524
[5] Train-accuracy=0.0983809523809524

I realise that from the information i've given it's going to be hard to diagnose, and I probably have made a mistake during installation. Any help would be appreciated.

Regards,
Chris

I have attached the log when I run R CMD INSTALL ...
[mxnet R CMD INSTALL Output.txt](https://github.com/dmlc/mxnet/files/101155/mxnet.R.CMD.INSTALL.Output.txt)
",R,"['Can double check the gpu is actually used when running R scripts?\n', 'Yes, I believe so. GPU Load goes from 0% to 84% when training is running. Thanks for your help.\nChris\n', ""Your log seems correct. Sorry that I don't have a Windows machine to reproduce your result.\n"", 'I ran into the similar problem. The ""Train-accuracy"" remains the same from the second output on. \n', 'The older pre-built packages (until windows binary build 20151228) do not have this problem. It seems that the problem started with those packages built in 2016. \n', 'So this might be a problem about pre-built Windows lib.\n\n@hjk41 Can you help us on this?\n', 'Does any one have a solution to this? I am having the same issue on a 64 bit windows (8.1) platform in R. The mxnet library got created with no error but the classification accuracy does not replicate on GPU. The CPU runs ok with accuracy of 0.557088. Any suggestions. I am using the (prebuilt) windows binary build 20160120.\n\nThanks \n', 'Same issue here, accuracy remains stuck from the second run. Would be interested if anyone has a suggestion. Thanks a lot. \n', 'I am really sorry for this.\n\nCan you try the earlier version?\n', '@thirdwing @sanson87 @narayaba @chibberto @junshui \nSorry guys for taking so long to respond. It seems to be a common problem. I have started working on it. Currently I have failed to reproduce the problem on the machine where I compiled the code. I will move to another machine and see if it is a configuration problem. Could you guys also help by trying the following?\n1. run ""where libmxnet.dll"" and see if you are using the right version of libmxnet.dll\n2. run matrixMulCuBLAS from nvidia CUDA samples and see if it works\n3. try building mxnet from source and do the test again\n\nSince it is the same problem with #1228. Let\'s all move to issue #1228 for this problem. Thanks!\n']",[],[],0,0
425,incubator-mxnet,3837,closed,ResNet for ILSVRC12 dataset,"I was looking for the ResNet config file for the ILSVRC12 dataset, but I only find the one for the Cifar10 dataset:

https://github.com/dmlc/mxnet/blob/master/example/image-classification/symbol_resnet.py

Do we have a ResNet config file for the ILSVRC12 dataset?

Thank you very much!",,"[""https://github.com/tornadomeet/ResNet\n\n@tornadomeet Let's merge this into master\n"", 'ok, after @mli refactored the example/classification.\n', 'hope to get the refactor done this week.\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
426,incubator-mxnet,3607,closed,CNN on 6x8 data in R,"Dear team,

I am trying to use a CNN on a dataset with 6x8 data. I am working in R.
The dataset has the following header:



I am attaching the full dataset.csv [dataset.zip](https://github.com/dmlc/mxnet/files/548954/dataset.zip)
the code I am using is the following:



When I run the R code I get the following:



but I do not understand what is the reason.
May I ask you if you see any discrepancy in my code?
Thanks.
Cheers.
",R Unclear Error/Doc,"['your input is too small/kernel is too big\n', 'I think you can try to remove the second convolution.\n', 'Let me try.\nI will let you know.\nThanks\n', 'mg64ve : What happened to your trials? did it work ? as I have the same issues when starting to work with MXNet?']",[],"['feat1_01, feat1_02, feat1_03, feat1_04, feat1_05, feat1_06, feat1_07, feat1_08, feat2_01, feat2_02, feat2_03, feat2_04, feat2_05, feat2_06, feat2_07, feat2_08, feat3_01, feat3_02, feat3_03, feat3_04, feat3_05, feat3_06, feat3_07, feat3_08, feat4_01, feat4_02, feat4_03, feat4_04, feat4_05, feat4_06, feat4_07, feat4_08, feat5_01, feat5_02, feat5_03, feat5_04, feat5_05, feat5_06, feat5_07, feat5_08, feat6_01, feat6_02, feat6_03, feat6_04, feat6_05, feat6_06, feat6_07, feat6_08, objective\n -0.74629, 0.17357, -0.03206, -0.02836, -0.01762, 0.26987, 0.99520, -0.04293, 1.00000, 0.97841, 0.68888, 0.79276, 0.48054, 0.67120, 0.55006, 0.55094, -0.18272, -0.66293, -0.04991, 0.23771, 0.69086, -0.01079, -0.50588, -0.53587, -0.51685, -0.51547, -0.28356, -0.48355, -0.23543, -0.45552, -0.31626, -0.22796, -0.63986, -0.61482, -0.40867, -0.57193, -0.31578, -0.53067, -0.41354, -0.37138, -0.99783, -0.94881, -0.77554, -0.89344, -0.69781, -0.85418, -0.75107, -0.71303, -1.0\n -0.43378, -0.74629, 0.17357, -0.03206, -0.02836, -0.01762, 0.26987, 0.99520, 0.88242, 1.00000, 0.97841, 0.68888, 0.79276, 0.48054, 0.67120, 0.55006, -0.65165, -0.18272, -0.66293, -0.04991, 0.23771, 0.69086, -0.01079, -0.50588, -0.27281, -0.51685, -0.51547, -0.28356, -0.48355, -0.23543, -0.45552, -0.31626, -0.48579, -0.63986, -0.61482, -0.40867, -0.57193, -0.31578, -0.53067, -0.41354, -0.90396, -0.99783, -0.94881, -0.77554, -0.89344, -0.69781, -0.85418, -0.75107, 1.0', 'library(mxnet)\n# Data preparation\nd <- read.csv(\'dataset.csv\', sep="","", header=T)\ntrain<-d[100:1000,]\ntest<-d[1001:1100,]\n\ntrain<-data.matrix(train)\ntest<-data.matrix(test)\ntrain.x<-train[,-ncol(train)]\ntrain.y<-train[,ncol(train)]\ntrain.x<-t(train.x)\ntest_org<-test\ntest<-test[,-ncol(test)]\ntest<-t(test)\n#table(train.y)\n\n# Convolutional NN\ndata <- mx.symbol.Variable(\'data\')\n# first conv\nconv1 <- mx.symbol.Convolution(data=data, kernel=c(4,4), num_filter=20)\ntanh1 <- mx.symbol.Activation(data=conv1, act_type=""tanh"")\npool1 <- mx.symbol.Pooling(data=tanh1, pool_type=""max"",\n                           kernel=c(2,2), stride=c(2,2))\n# second conv\nconv2 <- mx.symbol.Convolution(data=pool1, kernel=c(4,4), num_filter=50)\ntanh2 <- mx.symbol.Activation(data=conv2, act_type=""tanh"")\npool2 <- mx.symbol.Pooling(data=tanh2, pool_type=""max"",\n                           kernel=c(2,2), stride=c(2,2))\n# first fullc\nflatten <- mx.symbol.Flatten(data=pool2)\nfc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=50) \n\ntanh3 <- mx.symbol.Activation(data=fc1, act_type=""tanh"")\n# second fullc\nfc2 <- mx.symbol.FullyConnected(data=tanh3, num_hidden=10)\n# loss\nlenet <- mx.symbol.SoftmaxOutput(data=fc2)\ntrain.array <- train.x\ndim(train.array) <- c(6, 8, 1, ncol(train.x))\ntest.array <- test\ndim(test.array) <- c(6, 8, 1, ncol(test))\nmx.set.seed(0)\ntic <- proc.time()\nmodel <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y,\n                                     ctx=device.cpu, num.round=20, array.batch.size=100,\n                                     learning.rate=0.05, momentum=0.9, wd=0.00001,\n                                     eval.metric=mx.metric.accuracy,\n                                     epoch.end.callback=mx.callback.log.train.metric(100))\n', '[22:30:31] /root/mxnet/mxnet/dmlc-core/include/dmlc/logging.h:235: [22:30:31] src/operator/./convolution-inl.h:373: Check failed: ksize_y <= dshape[2] + 2 * param_.pad[0] && ksize_x <= dshape[3] + 2 * param_.pad[1] kernel size exceed input\nError in eval(substitute(expr), envir, enclos) : \n  InferShape Error in convolution1: [22:30:31] src/operator/./convolution-inl.h:373: Check failed: ksize_y <= dshape[2] + 2 * param_.pad[0] && ksize_x <= dshape[3] + 2 * param_.pad[1] kernel size exceed input\nCalls: mx.model.FeedForward.create ... mx.model.init.params -> mx.symbol.infer.shape -> <Anonymous> -> .External\n']",0,0
427,incubator-mxnet,11039,closed,Linux-R,"We can not download R in the linux .
Where do we download R in the linux?

Thank You",,"['Hello, Please refer installation guide, choose Linux and R from the options: http://mxnet.incubator.apache.org/install/index.html\r\n\r\nPlease reopen if issue still persists.']",[],[],0,0
428,incubator-mxnet,1794,closed,Error when build with torch,"I built with torch and got errors as follows:



Then I use  and :



So I modified the  in  to . Then I continued the make procedure and got happy results. Maybe this is a small bug related to my torch installation. Hope this will be helpful to potential users.
",,"[""It seems like torch renamed their libraries from nn to nnx in a recent update. We haven't figured out a way to support both versions.\n""]","['\n/usr/bin/ld: cannot find -lnn\n/usr/bin/ld: cannot find -lcunn\ncollect2: error: ld returned 1 exit status\nmake: *** [lib/libmxnet.so] Error 1\n', '\n/data/wanggu/torch/extra/nnx/build/libnnx.so\n/data/wanggu/torch/install/lib/lua/5.1/libnnx.so\n/data/wanggu/torch/extra/cunnx/build/libcunnx.so\n/data/wanggu/torch/install/lib/lua/5.1/libcunnx.so\n']","['locate libnn', 'locate libcunn', 'lnn lcunn', 'torch.mk', 'lnnx lcunnx']",0,0
429,incubator-mxnet,11576,closed,AttributeError: 'ResNetV2' object has no attribute 'save_parameters',,,[],[],[],0,0
430,incubator-mxnet,2749,closed,"Any special reason for the default initializer mx.init.Xavier(factor_type=""in"", magnitude=2.34) to take the magnitude 2.34?","The Xavier initializer is mx.init.Xavier(factor_type=""in"", magnitude=3), and
The MSRA initializer  is mx.init.Xavier(factor_type=""in"", rnd_type=""gaussian"", magnitude=2).

Why the default initializer adopts a strange magnitude of 2.34, any special reason for this?
",,"[""I don't think it is a good initializer, you should change it according to your model to avoid divergence.\n"", '@srand99 Thank you, but I think there should be some reasons to use 2.34, otherwise why not simply use the Xavier initializer that is mx.init.Xavier(factor_type=""in"", magnitude=3).\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
431,incubator-mxnet,894,closed,R package compilation error,"I got following error while package compilation ():

> ndarray.cc: In static member function ‘static void mxnet::R::NDArray::Save(const List&, const string&)’:
> ndarray.cc: In static member function ‘static void mxnet::R::NDArray::Save(const List&, const string&)’:
> ndarray.cc:220:15: error: ambiguous overload for ‘operator=’ (operand types are ‘std::vectorstd::__cxx11::basic_string<char >’ and ‘Rcpp::NamesProxyPolicyRcpp::Vector<19 >::const_NamesProxy’)
>      lst_names = data_lst.names();
",R,"['I removed `-std=c++11` flag from `CXXFLAGS` in my _Makevars_  file and this resolved problem. But why this is so important?\n', ""@dselivanov I am sorry that I also don't have any idea about this.\n\nCan you tell me which operating system and which version of R you are using?\n"", 'I installed mxnet and `R 3.2.2` on fresh new _ubuntu 15.10_, `gcc 5.2`. But mxnet shared library I compiled with `gcc 4.9` because nvidia only supports 4.9 branch. \n', 'should we close this or keep as a reminder?\n', 'I have to say that we have troubles with GCC5 in other Rcpp-realted projects. I am trying to figure out the real reasons.\n', '@thirdwing same error - **ndarray.cc:220:32: error: ambiguous overload for \'operator=\'** with latest version from master ( https://github.com/dmlc/mxnet/tree/e0be39ddc6fe15b18f6fc09f9ad061ac3378b668 ) and `gcc-6/g++-6` on OS X:\n\n> g++-6 -I/Library/Frameworks/R.framework/Resources/include -DNDEBUG -I../inst/include -DUSEAVX -DUSEOMP                                                 -I/usr/local/include -I/usr/local/include/freetype2 -I/opt/X11/include -I""/Users/dymitriyselivanov/Library/R/3.3/library/Rcpp/include""  -mavx2 -fopenmp -fPIC  -Wall -mtune=core2 -g -O2  -march=native -Ofast -c ndarray.cc -o ndarray.o\n> In file included from ndarray.cc:7:0:\n> ./base.h: In function \'std::__cxx11::string mxnet::R::toPyString(const string&, const RObject&)\':\n> ./base.h:276:26: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n>      for (size_t i = 0; i < vec.size(); ++i) {\n>                         ~~^~~~~~~~~~~~\n> ./base.h: In function \'std::vector<unsigned int> mxnet::R::Dim2InternalShape(const Rcpp::Dimension&)\':\n> ./base.h:340:24: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n>    for (size_t i = 0; i < rshape.size(); ++i) {\n>                       ~~^~~~~~~~~~~~~~~\n> ./ndarray.h: In destructor \'mxnet::R::NDBlob::~NDBlob()\':\n> ./base.h:83:45: warning: throw will always call terminate() [-Wterminate]\n>        throw Rcpp::exception(MXGetLastError());                     \\\n>                                              ^\n> ./ndarray.h:34:7: note: in expansion of macro \'MX_CALL\'\n>        MX_CALL(MXNDArrayFree(handle));\n>        ^\n> ./base.h:83:45: note: in C++11 destructors default to noexcept\n>        throw Rcpp::exception(MXGetLastError());                     \\\n>                                              ^\n> ./ndarray.h:34:7: note: in expansion of macro \'MX_CALL\'\n>        MX_CALL(MXNDArrayFree(handle));\n>        ^\n> ndarray.cc: In member function \'void mxnet::R::NDArrayPacker::Push(const RObjectType&)\':\n> ndarray.cc:133:26: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n>      RCHECK(shape_.size() == rshape.size())\n>             ~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~\n> ./base.h:73:9: note: in definition of macro \'RCHECK\'\n>    if (!(x)) RLOG_FATAL << ""RCheck failed: "" #x << \' \' /\\* NOLINT(_) */\n>          ^\n> ndarray.cc:136:24: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n>        RCHECK(shape_[i] == rshape[i])  \n> ./base.h:73:9: note: in definition of macro \'RCHECK\'\n>    if (!(x)) RLOG_FATAL << ""RCheck failed: "" #x << \' \' /_ NOLINT(_) */\n>          ^\n> ndarray.cc: In member function \'Rcpp::NumericVector mxnet::R::NDArrayPacker::Get() const\':\n> ndarray.cc:153:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n>    RCHECK(ret.size() == data_.size());\n>           ~~~~~~~~~~~^~~~~~~~~~~~~~~\n> ./base.h:73:9: note: in definition of macro \'RCHECK\'\n>    if (!(x)) RLOG_FATAL << ""RCheck failed: "" #x << \' \' /_ NOLINT(*) */\n>          ^\n> ndarray.cc: In member function \'std::size_t mxnet::R::NDArray::Size() const\':\n> ndarray.cc:194:24: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n>    for (size_t i = 0; i < dim.size(); ++i) {\n>                       ~~^~~~~~~~~~~~\n> ndarray.cc: In static member function \'static void mxnet::R::NDArray::Save(const List&, const string&)\':\n> ndarray.cc:220:32: error: ambiguous overload for \'operator=\' (operand types are \'std::vectorstd::__cxx11::basic_string<char >\' and \'Rcpp::NamesProxyPolicyRcpp::Vector<19 >::const_NamesProxy\')\n>      lst_names = data_lst.names();\n', 'Reinstalled all with `clang-3.8` toolchain which comes with llvm38 (can be installed with `brew install llvm38` ) - no issues... \n(note that we also should reinstall `Rcpp` with same toolchain - see https://github.com/RcppCore/Rcpp/issues/555)\nHere is my `~/.R/Makevars` for `clang-3.8` - hope will be useful for somebody\n\n```\nCXX   = clang++-3.8\nCXX1X = clang++-3.8\nCC    = clang-3.8\nCXX1XFLAGS += -mtune=native -Ofast\nCXXFLAGS   += -mtune=native -Ofast\nCFLAGS     += -mtune=native -Ofast\n#for clang-3.8 openmp\n#copied /usr/local/Cellar/llvm/3.8.1/lib/clang/3.8.1/include/omp.h\n#to /usr/local/include\nPKG_LIBS       += -L/usr/local/Cellar/llvm/3.8.1/lib -liomp5\nPKG_CPPFLAGS   += -DUSEAVX -DUSEOMP\nPKG_CXX1XFLAGS += -mavx -fopenmp=libomp\nPKG_CXXFLAGS   += -mavx -fopenmp=libomp\nPKG_CFLAGS     += -mavx -fopenmp=libomp\n```\n\nAlso 2 lines in config.mk should be adjusted to work properly with clang-3.8 and openmp:\n\n``` sh\n# the additional link flags you want to add\nADD_LDFLAGS = -L/usr/local/Cellar/llvm/3.8.1/lib -liomp5\n# the additional compile flags you want to add\nADD_CFLAGS = -fopenmp=libomp\n```\n']",[],['R CMD INSTALL mxnet_0.5.tar.gz'],0,0
432,incubator-mxnet,5016,closed,A little bug in mxnet python code,"Hi, I'm new to mxnet, and I am walking through a kaggle project to familiar with its python interface.
But something confused me when I try to call mx.mod.Module.predict function to complete my final work.
Since there was no headache when I called mx.mod.Module.score function, predict function should also work fine unless bug around. Then I read through python source code to find the bug.
following info displayed when I run the code 



Notice it's an index out of range problems, and the fault is directed by , I check the variable  and find it equals to -1.

That's the key problem. Next I find where  defined. Since I initialize  variable by following code


I check  and find  is assigned by  from  of 455 line.
By just change the  to  , I successfully fixed the bug.
But I still not sure whether the right code is  or 
the second way also fix the problem.

Any idea about this little bug? and if I certainly fix the bug, could you give me a chance to help me pull request to merge my little work into mxnet? Thank you, ",,['This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!'],[],"['best_model.predict(eval_data=test)', '---------------------------------------------------------------------------\r\nMXNetError                                Traceback (most recent call last)\r\n<ipython-input-14-6eee4a79ad10> in <module>()\r\n----> 1 best_model.predict(eval_data=test)\r\n\r\n/usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-py2.7.egg/mxnet/module/base_module.pyc in predict(self, eval_data, num_batch, merge_batches, reset, always_output_list)\r\n    291             self.forward(eval_batch, is_train=False)\r\n    292             pad = eval_batch.pad\r\n--> 293             outputs = [out[0:out.shape[0]-pad].copy() for out in self.get_outputs()]\r\n    294 \r\n    295             output_list.append(outputs)\r\n\r\n/usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-py2.7.egg/mxnet/ndarray.pyc in __getitem__(self, in_slice)\r\n    317             raise ValueError(\'NDArray only support continuous slicing on axis 0\')\r\n    318         if in_slice.start is not None or in_slice.stop is not None:\r\n--> 319             return self._slice(in_slice.start, in_slice.stop)\r\n    320         else:\r\n    321             return self\r\n\r\n/usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-py2.7.egg/mxnet/ndarray.pyc in _slice(self, start, stop)\r\n    358         stop = mx_uint(stop) if stop else mx_uint(self.shape[0])\r\n    359         check_call(_LIB.MXNDArraySlice(\r\n--> 360             self.handle, start, stop, ctypes.byref(handle)))\r\n    361         return NDArray(handle=handle, writable=self.writable)\r\n    362 \r\n\r\n/usr/local/lib/python2.7/dist-packages/mxnet-0.9.4-py2.7.egg/mxnet/base.pyc in check_call(ret)\r\n     75     """"""\r\n     76     if ret != 0:\r\n---> 77         raise MXNetError(py_str(_LIB.MXGetLastError()))\r\n     78 \r\n     79 if sys.version_info[0] < 3:\r\n\r\nMXNetError: [23:38:09] include/mxnet/ndarray.h:262: Check failed: shape_[0] >= end (200 vs. 201) Slice end index out of range', ' outputs = [out[0:out.shape[0]-pad].copy() for out in self.get_outputs()]', 'pad', 'pad', 'test', ""test = mx.img.ImageIter(\r\n    batch_size=batch_size,\r\n    data_shape=data_shape,\r\n    path_imgrec='test/test.rec',\r\n    resize=resize,\r\n    mean=mean_img,\r\n    std=std_img)"", 'image.py', 'pad', 'batch_size-1-i', 'return io.DataBatch([batch_data], [batch_label], batch_size-1-i)', 'batch_size-1-i', 'max(batch_size-1-i, 0)', 'max(batch_size-1-i, 0)', 'batch_size-i']",0,0
433,incubator-mxnet,8062,closed,CSVIter and LibSVMIter not returning correct number of batches per epoch,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System: DeepLearninig AMI 

Compiler:

Package used (Python/R/Scala/Julia):

MXNet version:

Or if installed from source:

MXNet commit hash (): ae975e5f8a70f9e2c36f78278f2553cdd4d87e79

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. Run the above code. Same kind of error for libsvm iterator. 
2.
3.
",Bug,"['@tqchen any idea where things could go wrong?', 'Based on #2248 moving `data_train.reset()` to the end of the epoch will resolve this issue. ', ""The number of batches will be correct if reset() is moved to the end of the epoch:\r\n```\r\n        for epoch in range(10):\r\n            nbatch = 0\r\n            for batch in iter(data_train):\r\n                nbatch += 1\r\n            assert(nbatch == 100), nbatch\r\n            data_train.reset()\r\n```\r\nI've updated the documentation for this in #8111""]","['\r\n  File ""./tests/python/unittest/test_io.py"", line 301, in check_CSVIter_synthetic\r\n    assert(nbatch == 100), nbatch\r\nAssertionError: 185\r\n', ""\r\n    def check_CSVIter_synthetic():\r\n        cwd = os.getcwd()\r\n        data_path = os.path.join(cwd, 'data.t')\r\n        with open(data_path, 'w') as fout:\r\n            for i in range(100):\r\n                fout.write(','.join([str(i + 1) for _ in range(8*8)]) + '\\n')\r\n        batch_size = 1\r\n        data_train = mx.io.CSVIter(data_csv=data_path, data_shape=(8,8),\r\n                                   batch_size=batch_size)\r\n        for epoch in range(10):\r\n            data_train.reset()\r\n            nbatch = 0\r\n            for batch in iter(data_train):\r\n                nbatch += 1\r\n            assert(nbatch == 100), nbatch\r\n""]","['git rev-parse HEAD', 'sessionInfo()']",0,0
434,incubator-mxnet,1118,closed,[R] mx.symbol.bind is missing one parameter,,R,[],[],[],0,0
435,incubator-mxnet,8037,closed,How to maximize one loss function and minimize another one?,"I want to maximize a dice coefficient and minimize the smooth_l1_loss at the same time,  I tried multiple  to the dice coefficient but seems it doesn't work.",HowTo,"['Provide a simple example? Are you trying to combine this two losses into a single one? Or these two losses are bind with different models and you want something similar to adversarial network?', '@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', 'Suggested tags: ""Question"", ""HowTo""', '@lilhope If the issue is still current, could you provide an example code and post a follow-up post to https://discuss.mxnet.io referencing this issue? Thanks!\r\n\r\n@sandeep-krishnamurthy can you please close the issue? Thanks!']",[],['-1.'],0,0
436,incubator-mxnet,1008,closed,[R] How to use mx.simple.bind() in R package,"The help information of mx.simple.bind() is too simple. I just can't figure out how to really use it from its help message.  Also, I can't find any sample code that used this function. I wonder if any of you can help me understand its usage a little better. 

Many thanks for your help.
",R,"['Can anyone help me with this? The limited help documentation appears to be the biggest obstacle for mxnet to have wider acceptance. \n', '@junshui We are working to improve documents and provide more examples. I will really appreciated your understanding of the situation that we are all students and have limited time.\n\nFor usage of `mx.simple.bind()`, you can find a good example from\n\nhttps://github.com/dmlc/mxnet/blob/master/R-package/R/model.R#L472\n\nFor the documentation, my advice is to use python doc as a reference, like \n\nhttps://github.com/dmlc/mxnet/blob/master/python/mxnet/symbol.py#L495-L499\n', 'Many thanks for your help. After some research, I saw a lot of potential in mxnet. I have decided to switch to it. Hopefully, you guys can keep it up, and make it one of the dominate DL packages. \n', 'Thank you for your support. We want to make `mxnet` one of the first choices when people want to use deep learning in R.\n\nRight now I am closing this. Feel free to open it if necessary.\n']",[],[],0,0
437,incubator-mxnet,3914,closed,im2rec 各个文件里存放了每一类的图片,建立自己的数据的时候，如果我的图片不是每个类别一个文件夹，而是所有图片都在一个文件夹中，类别标签由单独的文本文件保存，那么如何使用im2rec.py生成自己的数据，还有image.lst中integer_image_index是做什么用的，感觉有类别有路径不就够了么,,"['1. 按照mxnet的格式制作自己的图像标签文本就可以了；\r\n2.  integer_image_index应该就是单纯的索引，可以用来用于检测错误等吧。', '@nsy3694 大神球分像个代码啊，im2rec把makelist合并到一起去了，我每一类也是单独放在一个文件夹里面，然后所有类放在了train/ 下面，用im2rec怎么生成啊，我把root设置成了***/train 貌似报错啊\r\n```\r\nTraceback (most recent call last):\r\n  File ""im2rec.py"", line 207, in <module>\r\n    make_list(args)\r\n  File ""im2rec.py"", line 57, in make_list\r\n    chunk = image_list[i * chunk_size:(i + 1) * chunk_size]\r\nTypeError: slice indices must be integers or None or have an __index__ method\r\n\r\n```\r\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
438,incubator-mxnet,2149,closed,How to run mxnet on GPU clusters?,"I am trying to run mxnet on nVidia GPU clusters, sugon HPC.  I don't know how to subject the jobs though . 

GPU programming is quite new to me. It is there any tutorial I can follow?
",,"['@yech1990 You can directly submit the python script like `qsub -q gpu.q test.py` . Since MXNet requires other linking libraries, you may need to create a new bash script and initialize these environment variables at the beginning. Check the usage guidance of your GPU cluster for more information.\nAlso, if you want to do distributed training, you need to read the tutorial http://mxnet.readthedocs.io/en/latest/how_to/multi_devices.html and try the examples in https://github.com/dmlc/mxnet/tree/master/example/image-classification.\n', '@sxjscience  thank you very much!\nThe GPU cluster guidance is out of date, and the administor is not willing to give any help.\n\nWould you please show one line of example for initializing the environment variables.\n\nBTW, do I need to declare any variable in the PBS script if I install python in my own direction without root. For the GPU cluster only has python 2.4. \n', ""@yech1990 Hi, I encounter the same question. I want to use cluster, but I don't kown how to edit the pbs script. Can you help me?\r\nThank you!""]",[],['qsub'],0,0
439,incubator-mxnet,12640,closed,Time bottleneck in forward_backward and next(train_iter),"## Description

In BaseModule.fit function, <code>forward_backward</code> only needs 0.00055s, <code>update</code> only needs 0.079953s, <code>next(data_iter)</code> only needs 0.000265s. However, we run <code>forward_backward</code> and <code>next(data_iter)</code> together and spend 2.919867s. Could you please tell me what is the reason of this time bottleneck?

## Environment info (Required)

Platform: MacOS
Language: Python 2.7
Platform Version: MXNet 1.2.0
Device: 2.9 GHz Intel Core i5 (The test runs using single CPU)
Memory: 8 GB 1867 MHz DDR3
Install Tool: pip

## Steps to reproduce (In BaseModule.fit function)

* Run <code>forward_backward</code> only:



result: [CALC TIME] 0.000551	

* Run <code>next(data_iter)</code> only:



result: [DATAITER TIME] 0.000265

* Run <code>forward_backward</code> and <code>next(data_iter)</code> together:



result: [CALC AND DATAITER TIME] 2.919867	

## What have you tried to solve it?

1. I read the source code of <code>forward_backward</code> and <code>ImageRecordIter</code> but have no idea.
2. I found little modify in <code>data_batch</code> variable would also cause the time bottleneck in the loop of <code>forward_backward</code>.

Thanks a lot for your kind !
",Module Performance,"['forward_backward is async. This document will help you understand how to profile performance: \r\nhttps://mxnet.incubator.apache.org/tutorials/python/profiler.html#profiling-mxnet-models ', 'Thanks a lot ! It’s helpful.', 'Thanks for submitting the issue @Lizonghang and the response @eric-haibin-lin \r\n@mxnet-label-bot[module, question, performance]', 'Closing this for now. Feel free to comment if you have follow up questions']","['\r\nwhile True:\r\n    data_batch = next_data_batch\r\n    calc_start = time.time()\r\n    self.forward_backward(data_batch)\r\n    calc_end = time.time()\r\n    self.logger.info(""[CALC TIME] %f"", calc_end - calc_start)\r\n', '\r\nwhile True:\r\n    data_iter_start = time.time()\r\n    next(data_iter)\r\n    data_iter_end = time.time()\r\n    self.logger.info(""[DATAITER TIME] %f"", data_iter_end - data_iter_start)\r\n', '\r\nwhile True:\r\n    data_batch = next_data_batch\r\n    calc_iter_start = time.time()\r\n    self.forward_backward(data_batch)\r\n    next_data_batch = next(data_iter)\r\n    calc_iter_end = time.time()\r\n    self.logger.info(""[CALC AND DATAITER TIME] %f"", calc_iter_end - calc_iter_start)\r\n']",[],0,0
440,incubator-mxnet,7552,closed,Networks for CIFAR-10.,What networks are suitable for CIFAR-10 besides inception and resnet?,,"['I think it is CV problem. Maybe you can check here: https://github.com/apache/incubator-mxnet/tree/master/example/image-classification', 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!\nAlso, do please check out our [forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) for general ""how-to"" questions.']",[],[],0,0
441,incubator-mxnet,9359,closed,Does gluon's dnn support data format of libsvm other than mxnet's?,"The data consists of lines like the following:

-1 4:1 6:1 15:1 21:1 35:1 40:1 57:1 63:1 67:1 73:1 74:1 77:1 80:1 83:1 \n",Gluon,"['@janelu9  we handle questions via discuss.mxnet.io and not issues. Please file your question there.\r\n\r\n@sandeep-krishnamurthy Please add the labels\r\n\r\n- Question\r\n- Gluon\r\nand close the issue.\r\n@janelu9  if done in error please reopen and comment', 'I think I can use embedding']",[],[],0,0
442,incubator-mxnet,3759,closed,how to get result of intermediate network?,,,[],[],[],0,0
443,incubator-mxnet,10890,closed,[R] Is it possible to train Mxnet symbols and a GLM pretrained model as loss?,"The idea is very similar to a GAN, but instead of two neural networks I want to use a neural network generator and a prebuilt GLM as the discriminator.

Is this possible using the Mxnet symbols?

Example pseudo-code:

",,"['pseudo-code seems not works, because predict.glm is implemented in R instead of mxnet. the parameter flat is just a symbol.', 'Since a GLM predictions can be expressed as a matrix product and some link function transformation, it should be relatively straightforward to convert into a symbolic representation. \r\nI think you could use the FullyCOnnected operator with num_hidden = 1 and specify the GLM weights as fixed parameters in model training. ', 'Ok I want to be able to use any other technique.  GLM, forests, SVR, boosting, etc etc.\r\n\r\nAfter looking through some of the source code I noticed that the values in the custom metric are no longer symbols, but are actual values.  So, I tried to first turn off the loss by not actually comparing the predicted value with the label:\r\n\r\n```\r\nlast_activation <- mx.symbol.Activation(data= conv_6, act_type = ""sigmoid"", name=""Last_act_8"")\r\nlast <- mx.symbol.concat(data=c(last_activation,data), num.args = 2, dim = 1, name=\'cato_last\')\r\nNN_Model <- mx.symbol.MakeLoss(last )\r\n```\r\nThen I created a custom metric:\r\n\r\n```\r\nmx.metric.GAN <- mx.metric.custom(""GAN"", function(label, pred)\r\n{\r\n   res = 0 \r\n   for(i in 1:batch_size)\r\n   {      \r\n     label.data = tail(pred[,i], 9)\r\n     pred.data = head(pred[,i], -9)     \r\n     dim(pred.data) <- c(238,238,3,1)     \r\n     flat = nn.function(pred.data[,,,1])\r\n     svr.pred = predict(svm.model, t(flat))\r\n     res = res + (svr.pred - label.data[1] )^2       \r\n   }   \r\n   return(as.array(res))\r\n})\r\n```\r\n\r\nThis seems to actually call the other R functions that I want.  But, now mxnet appears to be attempting to maximize the metric instead of minimize it.\r\n\r\nSeems like I am very close to getting this to work, but I am not sure if the way I have manipulated the custom loss function is appropriate. \r\n\r\n', '@some-guy1 \r\nit seems this is the answer:\r\nhttps://www.r-bloggers.com/deep-learning-with-mxnetr/\r\n\r\n```\r\n# Define the input data\r\ndata <- mx.symbol.Variable(""data"")\r\n# A fully connected hidden layer\r\n# data: input source\r\n# num_hidden: number of neurons in this layer\r\nfc1 <- mx.symbol.FullyConnected(data, num_hidden=1)\r\n\r\n# Use linear regression for the output layer\r\nlro <- mx.symbol.LinearRegressionOutput(fc1)\r\n```', 'Please reopen in case if issue still persists.']","['\r\ndata <- mx.symbol.Variable(\'data\')\r\nlabel <- mx.symbol.Variable(\'label\')\r\ndconv <- mx.symbol.Deconvolution(data= data , kernel = c(3,3), stride=c(3,3), num_filter = 5)\r\nnorm = mx.symbol.BatchNorm(data= dconv, fix_gamma=FALSE)\r\nact1 <- mx.symbol.LeakyReLU(data= norm, act_type = ""leaky"", name=""act_3"")\r\n\r\n#GLM that was already built and will not change\r\nflat <- mx.symbol.flatten(data = act1)\r\nclass = abs(predict.glm(flat) - label)\r\nNN_Model <- mx.symbol.MakeLoss(class )\r\n']",[],0,0
444,incubator-mxnet,7127,closed,How to use regularization for a feed forward neural network in R using mxnet? ,"## Environment info
Operating System: Windows

Package used: R (Installed using the binaries.)

Which parameter should I use to do regularization (L2) for a feed forward neural network?
Where should I implement this. 

I could find references to the weight decay parameter (wd). But I am not sure where to include it. 

An example would be much appreciated. 
 
",R,"['I think weight decay is what you are looking for.\r\n\r\nA small example is given below. You can just add `wd` in `mx.model.FeedForward.create`.\r\n\r\n```r\r\nrequire(mlbench)\r\nrequire(mxnet)\r\n\r\ndata(BostonHousing, package = ""mlbench"")\r\n\r\ntrain.ind <- seq(1, 506, 3)\r\ntrain.x <- data.matrix(BostonHousing[train.ind,-14])\r\ntrain.y <- BostonHousing[train.ind, 14]\r\ntest.x <- data.matrix(BostonHousing[-train.ind,-14])\r\ntest.y <- BostonHousing[-train.ind, 14]\r\n\r\ndata <- mx.symbol.Variable(""data"")\r\nfc1 <- mx.symbol.FullyConnected(data, num_hidden = 1)\r\nlro <- mx.symbol.LinearRegressionOutput(fc1)\r\n\r\nmx.set.seed(0)\r\nmodel <- mx.model.FeedForward.create(lro,\r\n                                     X = train.x,\r\n                                     y = train.y,\r\n                                     ctx = mx.cpu(),\r\n                                     num.round = 50,\r\n                                     array.batch.size = 20,\r\n                                     optimizer = ""sgd"",\r\n                                     learning.rate = 2e-6,\r\n                                     momentum = 0.9,\r\n                                     wd = 0.1,\r\n                                     eval.metric = mx.metric.rmse)\r\n```\r\n\r\nSorry for the lack of document.']",[],[],0,0
445,incubator-mxnet,1455,closed,About the rand_crop in the example,"in the train_cifar or train_imagenet.py, rand_crop is set to True as default, however, the crop_ratio(size) does not to be manually set. What actually happen behind this setting?
",,"['The rand_crop means if the input size of the network is less than the actual image size, it will randomly crop. The crop_ratio is different, and it is used in affine transformation.\n']",[],[],0,0
446,incubator-mxnet,3659,closed,Some questions about Embedding Layer,"Questions about Embedding layer
(1) What is the function of Embedding layer ?
 In Keras ,it says Turn positive
 integers (indexes) into dense vectors of fixed size. eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]

But what is the meaning ? When will it be used ?

(2)I try some simple codes to see how the Embedding layer works:
I use the code in the xlvector blog:
http://blog.xlvector.net/2016-05/mxnet-regression-classification-for-concret-continuous-features/
# 我们虚构了201个不同的品牌，并给每个品牌设置一个出场价格

seriesdata = [1 + i for i in range(100)] + [101 - i for i in range(100)]

for i in range(10000):
    k = random.randint(0, 199)
    #越贵的品牌，我们认为在数据集里出现的次数越少，因为它卖的少
    count = 1000 / seriesdata[k]
    for j in range(count):
        dis = random.random() \* 10
        #实际的价格是品牌的出场价除以里程数的开方
        price = seriesdata[k] / math.sqrt(1.0 + dis)
        print str(price) + '\t' + str(dis) + '\t' + str(k)
# dis 是输入的里程

dis = mx.symbol.Variable('dis')
# price 是要预测的目标价格

price = mx.symbol.Variable('price')
# price_interval 是要预测的价格区间

price_interval = mx.symbol.Variable('price_interval')
# series 是输入的车的品牌

series = mx.symbol.Variable('series')

series_out = mx.symbol.Embedding(data = series, input_dim = 200,
                             output_dim = 100, name = ""series_embed"")
ne = mx.symbol.Flatten(series_out, name = ""series_flatten"")

arg , out,aux = ne.infer_shape(series=(6,1))
print arg
print ne.list_arguments()
print out

execute = ne.bind(ctx=mx.cpu(),args={'dis_flatten':seriesdata})
execute.forward()
d_out = execute.outputs[0]
print d_out.asnumpy()

IN console:
[(6L, 1L), (200L, 100L)]
['series', 'series_embed_weight']
[(6L, 100L)]
Then throw an error:
    raise ValueError('Must specify all the arguments in %s' % arg_key)
ValueError: Must specify all the arguments in args

I know it means that I did not give values to  the series_embed_weight . But in this example, which values to give it?
",,['This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!'],[],[],0,0
447,incubator-mxnet,9372,closed,Compile Error: /usr/bin/ld: cannot find -lcuda,"
## Description
I try to compile mxnet from source code and get the error below: 
/usr/bin/ld: cannot find -lcuda
Even i try to reset the path of CUDA (such as ""USE_CUDA_PATH=/apps2/cuda/8.0.61""), however, the compiler keep finding CUDA in the system folder.

## Environment info (Required)
Red Hat Enterprise Linux Workstation release 6.7 (Santiago)

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):
gcc 4.8.2

## Error Message:
/usr/bin/ld: cannot find -lcuda
collect2: error: ld returned 1 exit status
/make: usr*** [bin/im2rec] Error 1/
bin/ld: cannot find -lcuda
make: *** Waiting for unfinished jobs....
collect2: error: ld returned 1 exit status
make: *** [lib/libmxnet.so] Error 1

## What have you tried to solve it?

1. Add following two lines into all config.mk files 
ADD_LDFLAGS=-L/apps2/cuda/8.0.61/lib64
ADD_CFLAGS=-I/apps2/cuda/8.0.61/include

The command line i use to compile as below:
make -j 10 USE_OPENCV=1 USE_BLAS=openblas USE_CUDA=1 USE_CUDA_PATH=/apps2/cuda/8.0.61

Here is one thing need to be mentioned: CUDA doesn't be installed in the default system path. We installed CUDA in the customized directory. 

Please help me to solve this problem. 
Thank you so much


",Build CUDA,"['You may try to change the USE_CUDA_PATH flag manually in the config.mk file (https://github.com/apache/incubator-mxnet/blob/master/make/config.mk#L55) to have a try ', '@sandeep-krishnamurthy Tag this - Build, CUDA. And please close the issue.\r\n\r\n@lxwgcool reopen the issue if the problem persists.']",[],[],0,0
448,incubator-mxnet,9971,closed,onnx-mxnet pip package prevents gpu use,"Using pip to install mxnet-cu90 and onnx-mxnet causes pip to reinstall mxnet, removing GPU support. Changing the order the packages are installed does not address this issue.
",Bug Installation ONNX,"['@KellenSunderland ', 'The onnx import functionality has now been ported into MXNet repo itself under contrib and it does not prevent GPU use. There are GPU tests currently running successfully on the CI piepline. \r\nThis change will ship as part of MXNet v1.2 release. We will EOL the onnx-mxnet pip package after the release. Will close this bug after that.\r\n\r\nWe should also consider adding ""ONNX"" as a new label for issues on this repo.', '> We should also consider adding ""ONNX"" as a new label for issues on this repo.\r\n\r\nDone', '@jwfromm The above issue should not exist in the current mxnet v1.2 release. Please reopen the issue if it persists.\r\n\r\n@marcoabreu please close this issue ']",[],[],0,0
449,incubator-mxnet,17113,closed,3rdparty/openmp cmake build broken on some systems,"## Description
See https://github.com/apache/incubator-mxnet/pull/17098 and please help to review it.

 will currently fail on some systems, as OpenMP detects and attempts to build nvptx offloading target (which is not needed, but whose build fails).",Bug,['Fixed by https://github.com/apache/incubator-mxnet/pull/17098'],[],['cmake -GNinja -DUSE_CUDA=ON'],0,0
450,incubator-mxnet,4249,closed,[Keras] Add support for std (deviation) operator.,Add support for std deviation operator. Refer#4207 on how this could be done.,,['This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!'],[],[],0,0
451,incubator-mxnet,7457,closed,Minimal C example fails to register operators,"This is the most minimal example of what should be used to load a symbol with the c_api and it doesn't work. Unless I'm missing something completely like a compiler flag, otherwise


## Environment info
Operating System:

centos

Compiler:

gcc

Package used (Python/R/Scala/Julia):

C

MXNet version:

0.9.3

## Error Message:
Please paste the full error message, including stack trace.

[16:17:17] /share/tools/mxnet/dmlc-core/include/dmlc/./logging.h:300: [16:17:17] src/core/op.cc:55: Check failed: op != nullptr Operator FullyConnected is not registered

Stack trace returned 10 entries:
[bt] (0) /share/tools/mxnet/lib/libmxnet.so(_ZN4nnvm2Op3GetERKSs+0x329) [0x7fcb0323f179]
[bt] (1) /share/tools/mxnet/lib/libmxnet.so(+0xef8268) [0x7fcb03227268]
[bt] (2) /share/tools/mxnet/lib/libmxnet.so(_ZN4dmlc20JSONObjectReadHelper13ReadAllFieldsEPNS_10JSONReaderE+0x100) [0x7fcb0322d680]
[bt] (3) /share/tools/mxnet/lib/libmxnet.so(+0xef70ef) [0x7fcb032260ef]
[bt] (4) /share/tools/mxnet/lib/libmxnet.so(_ZNSt17_Function_handlerIFN4nnvm5GraphES1_EPS2_E9_M_invokeERKSt9_Any_dataS1_+0x11f) [0x7fcb02e8c3ef]
[bt] (5) /share/tools/mxnet/lib/libmxnet.so(_ZN4nnvm11ApplyPassesENS_5GraphERKSt6vectorISsSaISsEE+0x501) [0x7fcb03232b51]
[bt] (6) /share/tools/mxnet/lib/libmxnet.so(_ZN5mxnet18LoadLegacyJSONPassEN4nnvm5GraphE+0x180) [0x7fcb02e851c0]
[bt] (7) /share/tools/mxnet/lib/libmxnet.so(_ZNSt17_Function_handlerIFN4nnvm5GraphES1_EPS2_E9_M_invokeERKSt9_Any_dataS1_+0x11f) [0x7fcb02e8c3ef]
[bt] (8) /share/tools/mxnet/lib/libmxnet.so(_ZN4nnvm11ApplyPassesENS_5GraphERKSt6vectorISsSaISsEE+0x501) [0x7fcb03232b51]
[bt] (9) /share/tools/mxnet/lib/libmxnet.so(_ZN4nnvm9ApplyPassENS_5GraphERKSs+0x8e) [0x7fcb0318006e]



## Minimum reproducible example
test.c : 

#include <stdio.h>
#include ""mxnet/c_api.h""

int main(void)
{
    const char * symfn = ""net_symbol.json"";
    SymbolHandle sym;
    MXSymbolCreateFromFile(symfn, &sym);
    return 0;
}


## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. compiled with   gcc -I../include -L. -Wl,--whole-archive -lmxnet -Wl,--no-whole-archive test.c -o testrun
2. run 

## What have you tried to solve it?

1. including every header in the include/mxnet directory
2. copying all compiler flags from the make file 

",,"['if you add \r\n\r\nmx_uint out_size;\r\nconst char **out_array;\r\nMXListAllOpNames(&out_size, &out_array);\r\n\r\nit will work, there is no way to invoke other than that or MXSymbolListAtomicSymbolCreators\r\nmxnet::op::RegisterLegacyOpProp();\r\nmxnet::op::RegisterLegacyNDFunc(); \r\n\r\nso there should be a function that runs those functions under ""Part 0: Global State setups"" \r\nMXInitialise(); \r\n\r\nthat needs to be run before using the library this can run those functions and any other needed\r\n\r\n\r\n\r\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!\nAlso, do please check out our [forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) for general ""how-to"" questions.']",[],[],0,0
452,incubator-mxnet,3205,closed,ImportError: No module named captcha.image,"I compiled warp-ctc and mxnet successful.
I add warp-ctc in config.mk，and compiled mxnet，
but when I run lstm_ocr.py, the problem disappear

> > > from captcha.image import ImageCaptcha
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > > ImportError: No module named captcha.image

Did you have idea about this?
",,"['you have not installed the python package captcha\n', '@SDASDASA  How do you install the python package captcha? I install it and still find `No module named captcha.image`\n', 'i just do as this : ""sudo pip install captcha""\n', 'I meet the same problem as you, do you find the method to solve it ?', 'I also meet this same problem, how to solve it?', 'C:\\Users\\my\\Desktop\\Python\\Django\\onlineEducation\\Mxonline3>python manage.py runserver 8002\r\nUnhandled exception in thread started by <function check_errors.<locals>.wrapper at 0x0000000003E17400>\r\nTraceback (most recent call last):\r\n  File ""g:\\ProgramData\\Anaconda3\\lib\\site-packages\\django\\utils\\autoreload.py"", line 225, in wrapper\r\n    fn(*args, **kwargs)\r\n  File ""g:\\ProgramData\\Anaconda3\\lib\\site-packages\\django\\core\\management\\commands\\runserver.py"", line 113, in inner_run\r\n    autoreload.raise_last_exception()\r\n  File ""g:\\ProgramData\\Anaconda3\\lib\\site-packages\\django\\utils\\autoreload.py"", line 248, in raise_last_exception\r\n    raise _exception[1]\r\n  File ""g:\\ProgramData\\Anaconda3\\lib\\site-packages\\django\\core\\management\\__init__.py"", line 327, in execute\r\n    autoreload.check_errors(django.setup)()\r\n  File ""g:\\ProgramData\\Anaconda3\\lib\\site-packages\\django\\utils\\autoreload.py"", line 225, in wrapper\r\n    fn(*args, **kwargs)\r\n  File ""g:\\ProgramData\\Anaconda3\\lib\\site-packages\\django\\__init__.py"", line 24, in setup\r\n    apps.populate(settings.INSTALLED_APPS)\r\n  File ""g:\\ProgramData\\Anaconda3\\lib\\site-packages\\django\\apps\\registry.py"", line 89, in populate\r\n    app_config = AppConfig.create(entry)\r\n  File ""g:\\ProgramData\\Anaconda3\\lib\\site-packages\\django\\apps\\config.py"", line 90, in create\r\n    module = import_module(entry)\r\n  File ""g:\\ProgramData\\Anaconda3\\lib\\importlib\\__init__.py"", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import\r\n  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load\r\n  File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked\r\nModuleNotFoundError: No module named \'captcha\'\r\n\r\nI\'m try pip install captcha ', 'I have met the same problem now! so how do you solve it?', 'fukk the same', 'same as me\r\n', 'Finally I have found the origin of my problem. That\'s the same name as the package I have given to my directory file. They are both named ""captcha"". So I guess some conflict occured between them.', ""haha  I think they have made the same problem as you\r\nit's so awkward"", ""Maybe you've created a new python file named captach？\r\nJust rename！"", ""i am facing same problem \r\nrun command : `pip install  django-simple-captcha`\r\nthen add url in rout urls\r\n`urlpatterns = [\r\n    path('captcha/', `include('captcha.urls')),`\r\n]`\r\nthen apply migrations\r\n`python manage.py migrate`\r\n"", 'I was experiencing the same issue, turn out I was calling my file captcha.py xD third time I do this error.']",[],[],0,0
453,incubator-mxnet,7997,closed,Question about benchmarking imagenet,"Hi,

If I run the train_imagenet with benchmark option, I can see that for each epoch it executes 50 batches irrespective of batch size.

Is there a way to change the number of batches?

Thanks,
Saiful",,"['https://github.com/apache/incubator-mxnet/blob/master/example/image-classification/common/data.py#L113\r\n\r\nThe maximum iteration for each epoch is 500. \r\n\r\nYou can also try gluon image benchmark which is easier to use: https://github.com/apache/incubator-mxnet/blob/master/example/gluon/image_classification.py', '@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', 'Recommnded Labels: ""Question"", ""Need Requestor Info""', 'Please reopen if you cannot find the required answer.']",[],[],0,0
454,incubator-mxnet,13011,closed,mxnet.module.BaseModule docs errors,"## Description
Sphinx is throwing errors when generating docs for .

## Error

",Doc,['@mxnet-label-bot [Doc]'],['\r\n/home/ubuntu/incubator-mxnet/docs/api/python/module/module.md:1: WARNING: failed to import BucketModule.switch_bucket\r\n/home/ubuntu/incubator-mxnet/python/mxnet/module/base_module.py:docstring of mxnet.module.BaseModule.iter_predict:4: WARNING: Title underline too short.\r\n\r\nExample Usage:\r\n----------\r\n/home/ubuntu/incubator-mxnet/python/mxnet/module/base_module.py:docstring of mxnet.module.BaseModule.iter_predict:4: SEVERE: Unexpected section title.\r\n'],['mxnet.module.BaseModule'],0,0
455,incubator-mxnet,3192,closed,get each layer output,"whether i can get each neural output when i finish my training
",,"['yes, you can. when you get your sym, just use sym.get_internals(a_output), a is your layer name.\n', '@tornadomeet sym.get_internals() has no parameters.\n@windelu you can use sym.Group to gather the internal layers as outputs.\n', ""@starimpact  i just make a mistake, it should be used like this `sym.get_internals()['***_output']`.\n"", 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!', '`sym.list_outputs()` will work too.']",[],[],0,0
456,incubator-mxnet,4699,closed,[Scala] fail to run the example ExampleCustomOpWithRtc.scala,"

## Environment info
Operating System: Ubuntu 14.04

Compiler: gcc 4.8

Package used (Python/R/Scala/Julia): Scala

MXNet version: v0.9

Or if installed from source:

MXNet commit hash (): 6d05979cce53041f356204b17db2effb09371328

## Error Message:


## Steps to reproduce
1. compile mxnet with CUDA & NVRTC and then compile the scalapkg


2.



3.


## What have you tried to solve it?

I have locate the commit which cause the problem, it's the pr #4528 
after I roll back to the commit 50a3a3184e3034a98b2d4ad82f186d035803ab9b before #4528 
the problem have solved.

And I also check the CUDA doc, error code 201 means:

CUDA_ERROR_INVALID_CONTEXT = 201
This most frequently indicates that there is no context bound to the current thread. This can also be returned if the context passed to an API call is not a valid handle (such as a context that has had cuCtxDestroy() invoked on it). This can also be returned if a user mixes different API versions (i.e. 3010 context with 3020 API calls). See cuCtxGetApiVersion() for more details.


@javelinjs @piiswrong 
",,"['@Ldpe2G I also have this problem and I use CPU. I roll back to the commit, but still have the problem.\r\n\r\nSLF4J: Class path contains multiple SLF4J bindings.\r\nSLF4J: Found binding in [jar:file:/home/yxzf/mxnet/scala-package/assembly/linux-x86_64-cpu/target/mxnet-full_2.11-linux-x86_64-cpu-0.1.2-SNAPSHOT.jar!/org/slf4j/impl/StaticLoggerBinder.class]\r\nSLF4J: Found binding in [jar:file:/home/yxzf/mxnet/scala-package/examples/target/classes/lib/slf4j-log4j12-1.7.7.jar!/org/slf4j/impl/StaticLoggerBinder.class]\r\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\r\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\r\n2017-01-18 07:52:50,198 [main] [MXNetJVM] [INFO] - Try loading mxnet-scala from native path.\r\n2017-01-18 07:52:50,200 [main] [MXNetJVM] [WARN] - Failed to load from native path. Exception:\r\njava.lang.UnsatisfiedLinkError: no mxnet-scala in java.library.path\r\n\tat java.lang.ClassLoader.loadLibrary(ClassLoader.java:1867)\r\n\tat java.lang.Runtime.loadLibrary0(Runtime.java:870)\r\n\tat java.lang.System.loadLibrary(System.java:1122)\r\n\tat ml.dmlc.mxnet.Base$.tryLoadLibraryOS(Base.scala:76)\r\n\tat ml.dmlc.mxnet.Base$.<init>(Base.scala:45)\r\n\tat ml.dmlc.mxnet.Base$.<clinit>(Base.scala)\r\n\tat ml.dmlc.mxnet.Operator$.register(Operator.scala:217)\r\n\tat ml.dmlc.mxnet.examples.customop.ExampleCustomOpWithRtc$.<init>(ExampleCustomOpWithRtc.scala:104)\r\n\tat ml.dmlc.mxnet.examples.customop.ExampleCustomOpWithRtc$.<clinit>(ExampleCustomOpWithRtc.scala)\r\n\tat ml.dmlc.mxnet.examples.customop.ExampleCustomOpWithRtc.main(ExampleCustomOpWithRtc.scala)\r\n2017-01-18 07:52:50,202 [main] [MXNetJVM] [INFO] - Try loading mxnet-scala-linux-x86_64-gpu from native path.\r\n2017-01-18 07:52:50,202 [main] [MXNetJVM] [INFO] - Try loading mxnet-scala-linux-x86_64-cpu from native path.\r\n2017-01-18 07:52:50,203 [main] [MXNetJVM] [WARN] - MXNet Scala native library not found in path. Copying native library from the archive. Consider installing the library somewhere in the path (for Windows: PATH, for Linux: LD_LIBRARY_PATH), or specifying by Java cmd option -Djava.library.path=[lib path].Exception:\r\njava.lang.UnsatisfiedLinkError: no mxnet-scala-linux-x86_64-cpu in java.library.path\r\n\tat java.lang.ClassLoader.loadLibrary(ClassLoader.java:1867)\r\n\tat java.lang.Runtime.loadLibrary0(Runtime.java:870)\r\n\tat java.lang.System.loadLibrary(System.java:1122)\r\n\tat ml.dmlc.mxnet.Base$.tryLoadLibraryXPU(Base.scala:102)\r\n\tat ml.dmlc.mxnet.Base$.tryLoadLibraryOS(Base.scala:83)\r\n\tat ml.dmlc.mxnet.Base$.<init>(Base.scala:45)\r\n\tat ml.dmlc.mxnet.Base$.<clinit>(Base.scala)\r\n\tat ml.dmlc.mxnet.Operator$.register(Operator.scala:217)\r\n\tat ml.dmlc.mxnet.examples.customop.ExampleCustomOpWithRtc$.<init>(ExampleCustomOpWithRtc.scala:104)\r\n\tat ml.dmlc.mxnet.examples.customop.ExampleCustomOpWithRtc$.<clinit>(ExampleCustomOpWithRtc.scala)\r\n\tat ml.dmlc.mxnet.examples.customop.ExampleCustomOpWithRtc.main(ExampleCustomOpWithRtc.scala)\r\n2017-01-18 07:52:50,219 [main] [ml.dmlc.mxnet.util.NativeLibraryLoader] [INFO] - Loading libmxnet-scala.so from /lib/native/ copying to mxnet-scala\r\n[20:52:52] src/io/iter_mnist.cc:91: MNISTIter: load 60000 images, shuffle=1, shape=(100,784)\r\n[20:52:52] src/io/iter_mnist.cc:91: MNISTIter: load 10000 images, shuffle=1, shape=(100,784)\r\n[20:52:52] include/dmlc/./logging.h:300: [20:52:52] src/storage/storage.cc:78: Compile with USE_CUDA=1 to enable GPU usage\r\n', '@yxzf if you want to run the example ExampleCustomOpWithRtc.scala you must use gpu.', '@Ldpe2G I use run_gan_mnist.sh, also have this problem', '@yxzf compile the mxnet with cuda and try again', '@yxzf if you compile the mxnet without cuda, try to modify the \r\n\r\nCLASS_PATH=$MXNET_ROOT/scala-package/assembly/linux-x86_64-gpu/target/* ...\r\nto\r\nCLASS_PATH=$MXNET_ROOT/scala-package/assembly/linux-x86_64-cpu/target/* ...\r\n\r\nin the script', '@Ldpe2G I had modified it to cpu and the same errors raised...', '@yxzf how did you run the script, could you provide the full command?', '@Ldpe2G \r\n<img width=""571"" alt=""2017-01-19 8 08 38"" src=""https://cloud.githubusercontent.com/assets/9815568/22106311/2084ba88-de83-11e6-91a4-94ddf95056cc.png"">\r\n\r\n<img width=""1123"" alt=""2017-01-19 8 08 24"" src=""https://cloud.githubusercontent.com/assets/9815568/22106316/29544d0e-de83-11e6-8c97-a7d1612b8202.png"">\r\n\r\n#!/bin/bash\r\n\r\nMXNET_ROOT=$(cd ""$(dirname $0)/../../..""; pwd)\r\nCLASS_PATH=$MXNET_ROOT/scala-package/assembly/linux-x86_64-cpu/target/*:$MXNET_ROOT/scala-package/examples/target/*:$MXNET_ROOT/scala-package/examples/target/classes/lib/*\r\n\r\n# which gpu card to use, -1 means cpu\r\nGPU=$1\r\n\r\n# the mnist data path\r\n# you can get the mnist data using the script core/scripts/get_mnist_data.sh\r\nMNIST_DATA_PATH=$2\r\n\r\n# the path to save the generated results\r\nOUTPUT_PATH=$3\r\n\r\njava -Xmx4G -cp $CLASS_PATH \\\r\n        ml.dmlc.mxnet.examples.gan.GanMnist \\\r\n        --mnist-data-path $MNIST_DATA_PATH \\\r\n        --gpu $GPU \\\r\n        --output-path $OUTPUT_PATH', '@yxzf I mean how did you run this script, did you run it like the following?\r\n```bash\r\nbash run_gan_mnist.sh -1 path_to_mnist_data output_path\r\n```']","[""bash\r\nSLF4J: Class path contains multiple SLF4J bindings.\r\nSLF4J: Found binding in [jar:file:/home/ldpe2g/Mxnet/mxnet_Scala/mxnet/scala-package/assembly/linux-x86_64-gpu/target/mxnet-full_2.11-linux-x86_64-gpu-0.1.2-SNAPSHOT.jar!/org/slf4j/impl/StaticLoggerBinder.class]\r\nSLF4J: Found binding in [jar:file:/home/ldpe2g/Mxnet/mxnet_Scala/mxnet/scala-package/examples/target/classes/lib/slf4j-log4j12-1.7.7.jar!/org/slf4j/impl/StaticLoggerBinder.class]\r\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\r\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\r\n2017-01-17 18:21:35,123 [main] [MXNetJVM] [INFO] - Try loading mxnet-scala from native path.\r\n2017-01-17 18:21:35,124 [main] [MXNetJVM] [WARN] - Failed to load from native path. Exception:\r\njava.lang.UnsatisfiedLinkError: no mxnet-scala in java.library.path\r\n\tat java.lang.ClassLoader.loadLibrary(ClassLoader.java:1867)\r\n\tat java.lang.Runtime.loadLibrary0(Runtime.java:870)\r\n\tat java.lang.System.loadLibrary(System.java:1122)\r\n\tat ml.dmlc.mxnet.Base$.tryLoadLibraryOS(Base.scala:76)\r\n\tat ml.dmlc.mxnet.Base$.<init>(Base.scala:45)\r\n\tat ml.dmlc.mxnet.Base$.<clinit>(Base.scala)\r\n\tat ml.dmlc.mxnet.Operator$.register(Operator.scala:217)\r\n\tat ml.dmlc.mxnet.examples.customop.ExampleCustomOpWithRtc$.<init>(ExampleCustomOpWithRtc.scala:104)\r\n\tat ml.dmlc.mxnet.examples.customop.ExampleCustomOpWithRtc$.<clinit>(ExampleCustomOpWithRtc.scala)\r\n\tat ml.dmlc.mxnet.examples.customop.ExampleCustomOpWithRtc.main(ExampleCustomOpWithRtc.scala)\r\n2017-01-17 18:21:35,125 [main] [MXNetJVM] [INFO] - Try loading mxnet-scala-linux-x86_64-gpu from native path.\r\n2017-01-17 18:21:35,125 [main] [MXNetJVM] [INFO] - Try loading mxnet-scala-linux-x86_64-cpu from native path.\r\n2017-01-17 18:21:35,125 [main] [MXNetJVM] [WARN] - MXNet Scala native library not found in path. Copying native library from the archive. Consider installing the library somewhere in the path (for Windows: PATH, for Linux: LD_LIBRARY_PATH), or specifying by Java cmd option -Djava.library.path=[lib path].Exception:\r\njava.lang.UnsatisfiedLinkError: no mxnet-scala-linux-x86_64-cpu in java.library.path\r\n\tat java.lang.ClassLoader.loadLibrary(ClassLoader.java:1867)\r\n\tat java.lang.Runtime.loadLibrary0(Runtime.java:870)\r\n\tat java.lang.System.loadLibrary(System.java:1122)\r\n\tat ml.dmlc.mxnet.Base$.tryLoadLibraryXPU(Base.scala:102)\r\n\tat ml.dmlc.mxnet.Base$.tryLoadLibraryOS(Base.scala:83)\r\n\tat ml.dmlc.mxnet.Base$.<init>(Base.scala:45)\r\n\tat ml.dmlc.mxnet.Base$.<clinit>(Base.scala)\r\n\tat ml.dmlc.mxnet.Operator$.register(Operator.scala:217)\r\n\tat ml.dmlc.mxnet.examples.customop.ExampleCustomOpWithRtc$.<init>(ExampleCustomOpWithRtc.scala:104)\r\n\tat ml.dmlc.mxnet.examples.customop.ExampleCustomOpWithRtc$.<clinit>(ExampleCustomOpWithRtc.scala)\r\n\tat ml.dmlc.mxnet.examples.customop.ExampleCustomOpWithRtc.main(ExampleCustomOpWithRtc.scala)\r\n2017-01-17 18:21:35,136 [main] [ml.dmlc.mxnet.util.NativeLibraryLoader] [INFO] - Loading libmxnet-scala.so from /lib/native/ copying to mxnet-scala\r\n[18:21:37] src/io/iter_mnist.cc:91: MNISTIter: load 60000 images, shuffle=1, shape=(100,784)\r\n[18:21:37] src/io/iter_mnist.cc:91: MNISTIter: load 10000 images, shuffle=1, shape=(100,784)\r\n[18:21:38] ./include/dmlc/logging.h:208: [18:21:38] src/common/mxrtc.cc:46: Check failed: err = cuModuleLoadDataEx(&module, ptx_, 0, 0, 0) == CUDA_SUCCESS (201 vs. 0) CudaError: 201\r\nml.dmlc.mxnet.MXNetError: [18:21:38] src/common/mxrtc.cc:46: Check failed: err = cuModuleLoadDataEx(&module, ptx_, 0, 0, 0) == CUDA_SUCCESS (201 vs. 0) CudaError: 201\r\n\tat ml.dmlc.mxnet.Base$.checkCall(Base.scala:116)\r\n\tat ml.dmlc.mxnet.Rtc.push(Rtc.scala:62)\r\n\tat ml.dmlc.mxnet.examples.customop.ExampleCustomOpWithRtc$Softmax.forward(ExampleCustomOpWithRtc.scala:60)\r\n\tat ml.dmlc.mxnet.CustomOp.forwardEntry(Operator.scala:65)\r\n[18:21:38] ./include/dmlc/logging.h:208: [18:21:38] src/operator/custom.cc:81: Check failed: op_info_->forward(ptrs.size(), ptrs.data(), tags.data(), reqs.data(), ctx.is_train, op_info_->p_forward) \r\nterminate called after throwing an instance of 'dmlc::Error'\r\n  what():  [18:21:38] src/operator/custom.cc:81: Check failed: op_info_->forward(ptrs.size(), ptrs.data(), tags.data(), reqs.data(), ctx.is_train, op_info_->p_forward) \r\n"", 'bash\r\nmake -j4 && make scalapkg\r\n', 'bash \r\ncd scala-package/examples/scripts/customop\r\n', 'bash\r\n bash run_customopwithrtc.sh path_to_mnist_data\r\n']",['git rev-parse HEAD'],0,0
457,incubator-mxnet,5176,closed,source_array must be array like object,"Hi!

I got following error when try some demo code, 

 I thought the usage is fine since there is no problems in numpy, but a TypeError occur


Is that normal?

Best Regards,
Haria",,['This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!'],"['python\r\n>>> import mxnet as mx\r\n>>> mx.__version__\r\n\'0.9.3\'\r\n>>> a=mx.nd.array([1,2,3])\r\n>>> b=mx.nd.array(a)\r\nTraceback (most recent call last):\r\n  File ""<stdin>"", line 1, in <module>\r\n  File ""/home/haria/anaconda2/lib/python2.7/site-packages/mxnet-0.9.3-py2.7-linux-x86_64.egg/mxnet/ndarray.py"", line 1121, in array\r\n    raise TypeError(\'source_array must be array like object\')\r\nTypeError: source_array must be array like object\r\n', 'python\r\n>>> import numpy as np\r\n>>> aa=np.array([1,2,3])\r\n>>> bb=np.array(aa)\r\n>>> \r\n']",[],0,0
458,incubator-mxnet,4236,closed,how to  find the max value of a tensor,"i want to find the max value of a tensor.
i think of a method as follows:
Tensor<xpu, 2, DType> data = in_data[activation::kData].FlatTo2D<xpu, DType>(s);
Shape<1> maxshape=Shape<1>(1);
Tensor<xpu, 1, DType> out_max=NewTensor<xpu,DType,2>(maxshape,Dtype(0),false);
out_max=pool<mshadow::red::maximum>(pad(data,0,0),Shape<1>,data.shape_[0],data.shape_[1],1,1);

Are there any concise way?
And if i want to use the max value to the following calculation in gpu ,i can't access it using out_max[0] in cpu kernal, so how to solve it?
",,"[""I think you could move this issue to [mshadow](http://github.com/dmlc/mshadow) repo since it is more relevant (and the question won't be flooded by other questions in this repo).""]",[],[],0,0
459,incubator-mxnet,7533,closed,Call symbol/nd.smooth_l1 without scalar causing uncaught exception,"Call mx.nd.smooth_l1 without scalar parameter will cause mxnet to crash


## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.



## What have you tried to solve it?

Specify scalar will solve it

However, in the example, the argument is specified as , which is very confusing.
http://mxnet.io/api/python/symbol.html#mxnet.symbol.smooth_l1

We should add a default value for scalar (1.0), fix the document, and fix the uncaught exception anyway
",Bug Operator,"['Mark and will fix later.', '@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', 'I though it was resolved, but apprarently not, it exception is still uncaugh in python.', '@sxjscience Please also tag as ""Bug"" because of the crash.', '@sandeep-krishnamurthy please close this issue as the fix PR is now merged. Thanks!']","['\r\nlibc++abi.dylib: terminating with uncaught exception of type std::invalid_argument: stod: no conversion\r\n', '\r\nimport mxnet.ndarray as nd\r\nnd.smooth_l1(nd.array([1, 2]))\r\n', '\r\nnd.smooth_l1(nd.array([1, 2]), scalar=1.0)\r\n']",['sigma'],0,0
460,incubator-mxnet,7766,closed,How to implement fixed size pooling like spatial pyramid pooling?,"Fixed size pooling such as SPP is commonly used in CNN, however I found SPP doesn't exist in mxnet symbols.",,"['@ArsenLuca , To implement spp, you actually need adaptive pooling, but mxnet does not support it now. Fortunately, there is [PyTorch that support it](http://pytorch.org/docs/master/nn.html#adaptivemaxpool2d). If you can not implement it by yourself in MXNET, consider PyTorch. aha :)', 'You can use the ROIPooling function used in Faster RCNN\r\n[`mx.symbol.ROIPooling`](https://mxnet.incubator.apache.org/api/python/symbol.html#mxnet.symbol.ROIPooling)', ""It's straight forward. You can pooling multiple times with different sizes and concat the result together.\r\nHowever, the SPP  is unable to update weights below the spatial pyramid pooling layer so it's not practical."", 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!\nAlso, do please check out our [forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) for general ""how-to"" questions.']",[],[],0,0
461,incubator-mxnet,3347,closed,"Is there any typo in ""Dependency Engine for Deep Learning""?","https://github.com/dmlc/mxnet/blob/master/docs/system/note_engine.md#case-study-on-multi-gpu-neural-net

The original sample code is:



Should it be revised as following?



There is same problem in the graph show:

![](https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/engine/dep_net.png)
",,['This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!'],"[' python\n# aggregate gradient and update\nfc1_wgrad[cpu]  = fc1_wgrad[gpu0] + fc1_wgrad[gpu1]\nfc2_wgrad[cpu]  = fc2_wgrad[gpu0] + fc2_wgrad[gpu1]\nfc1_weight[cpu] -= lr *  fc1_wgrad[gpu0] # typo here?\nfc2_weight[cpu] -= lr *  fc2_wgrad[gpu0] # typo here?\nfc1_weight[cpu].copyto(fc1_weight[gpu0] , fc1_weight[gpu1])\nfc2_weight[cpu].copyto(fc2_weight[gpu0] , fc2_weight[gpu1])\n', ' python\nfc1_weight[cpu] -= lr *  fc1_wgrad[cpu] # corrected here\nfc2_weight[cpu] -= lr *  fc2_wgrad[cpu] # corrected here\n']",[],0,0
462,incubator-mxnet,11567,closed,MXNet v1.2.0 branch PR build failure,"## Description
HI, following PR Builds are failing on dockcross-linux-arm64. 
https://github.com/apache/incubator-mxnet/pull/11478
https://github.com/apache/incubator-mxnet/pull/11548

Probably some issue with this dockerfile:
https://hub.docker.com/r/mxnetci/dockcross-linux-arm64/tags/

@marcoabreu  Can you please take a look?

@anirudh2290 

## Environment info (Required)

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...)

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio):

MXNet commit hash:
(Paste the output of  here.)

Build config:
(Paste the content of config.mk, or the build command.)

## Error Message:
(Paste the complete error message, including stack trace.)

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1.
2.

## What have you tried to solve it?

1.
2.
",,"['@larroy', '@lebeg add to our lists please', 'I have a fix for this on a branch.', '@Roshrini It seems the two PRs you listed in description have been merged. Could you verify if they are built successfully?', 'Thanks for working on the issue. Builds were successful and PRs are merged. Thanks!']",[],"['', '\r\nWhat to do:\r\n1. Download the diagnosis script from https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/diagnose.py\r\n2. Run the script using ', ' and paste its output here.\r\n\r\n', '', 'java -version', 'mvn -version', 'scala -version', 'sessionInfo()', 'git rev-parse HEAD']",0,0
463,incubator-mxnet,16037,closed,LSTM with MKL-DNN produces wrong output after weights are changed,"## Description
1) Create an RNN op with  and bind it
2) Run a forward pass
3) Change the NDArray holding the RNN parameters
4) Run a forward pass again

The output doesn't change, unless the second forward pass is performed in training mode (). Setting  doesn't fix the issue, but using a build without MKL-DNN does.

This severly impacts training with a validation set, because evaluating the performance on the validation set is typically performed with  after several updates of the weights. In this case, validation shows no improvement because the output of the layer is stuck at the very first training iteration.

## Environment info (Required)



Package used (Python/R/Scala/Julia): python

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): gcc

MXNet commit hash: 076b2f330c60f05cb939beea28dd04cd571a34c0

Build config: plain config.mk, except for USE_OPENCV=0

## Minimum reproducible example


When using a build with MKL-DNN, this script print something like this:

Which shows that the output doesn't change after changing the weights unless the forward pass is performed in training mode. Setting  doesn't fix the issue, but using a build without MKL-DNN does.",Bug MKLDNN RNN,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended label(s): Bug', '@mxnet-label-bot add [Bug, MKLDNN, RNN]', ""Probably it's because the stateful RNN op doesn't check if weight is changed. We will look at this. @pengzhao-intel "", '@zixuanweeei Would you  please have a look for this?', ""@ZhennanQin Sure. Just as you have said, it is definitely caused by that stateful RNN op won't check weights again after it has been initialized with MKL-DNN memory format in inference procedure."", '@matteosal Thanks for you reporting this issue. We are addressing the problem. PR is on the way. Thanks.', 'Great!\r\nI also see the same problem with modes `rnn_relu` and `rnn_tanh`, while `gru` is fine.\r\n', ""@matteosal That's right. The problem won't apear with GRU, because we haven't integrated MKL-DNN GRU into MXNet yet. It will be available in the near future."", '@matteosal thanks to reporting the issues which are really helpful.\r\nWould you mind introducing some background of how your organizations are using MKL-DNN so that we can have better supports or more cooperations?\r\nMy official email: patric.zhao@intel.com', ""> @matteosal thanks to reporting the issues which are really helpful.\r\n> Would you mind introducing some background of how your organizations are using MKL-DNN so that we can have better supports or more cooperations?\r\n> My official email: [patric.zhao@intel.com](mailto:patric.zhao@intel.com)\r\n\r\nSure, I'm writing you from my Wolfram work email"", 'Fixed and closing. Thanks to reporting the issue :)']","['\r\n----------Python Info----------\r\nVersion      : 3.7.2\r\nCompiler     : GCC 7.3.0\r\nBuild        : (\'default\', \'Dec 29 2018 06:19:36\')\r\nArch         : (\'64bit\', \'\')\r\n------------Pip Info-----------\r\nVersion      : 19.0.1\r\nDirectory    : /opt/Anaconda/lib/python3.7/site-packages/pip\r\n----------MXNet Info-----------\r\nVersion      : 1.5.0\r\nDirectory    : /home/matteo/Git/mxnet/python/mxnet\r\nCommit hash file ""/home/matteo/Git/mxnet/python/mxnet/COMMIT_HASH"" not found. Not installed from pre-built package or built from source.\r\nLibrary      : [\'/home/matteo/Git/mxnet/python/mxnet/../../lib/libmxnet.so\']\r\nBuild features:\r\n✖ CUDA\r\n✖ CUDNN\r\n✖ NCCL\r\n✖ CUDA_RTC\r\n✖ TENSORRT\r\n✔ CPU_SSE\r\n✔ CPU_SSE2\r\n✔ CPU_SSE3\r\n✔ CPU_SSE4_1\r\n✔ CPU_SSE4_2\r\n✖ CPU_SSE4A\r\n✔ CPU_AVX\r\n✖ CPU_AVX2\r\n✖ OPENMP\r\n✖ SSE\r\n✔ F16C\r\n✔ JEMALLOC\r\n✖ BLAS_OPEN\r\n✔ BLAS_ATLAS\r\n✖ BLAS_MKL\r\n✖ BLAS_APPLE\r\n✖ LAPACK\r\n✔ MKLDNN\r\n✖ OPENCV\r\n✖ CAFFE\r\n✖ PROFILER\r\n✖ DIST_KVSTORE\r\n✖ CXX14\r\n✖ INT64_TENSOR_SIZE\r\n✖ SIGNAL_HANDLER\r\n✖ DEBUG\r\n----------System Info----------\r\nPlatform     : Linux-4.15.0-55-generic-x86_64-with-debian-buster-sid\r\nsystem       : Linux\r\nnode         : mongolius\r\nrelease      : 4.15.0-55-generic\r\nversion      : #60-Ubuntu SMP Tue Jul 2 18:22:20 UTC 2019\r\n----------Hardware Info----------\r\nmachine      : x86_64\r\nprocessor    : x86_64\r\nArchitecture:        x86_64\r\nCPU op-mode(s):      32-bit, 64-bit\r\nByte Order:          Little Endian\r\nCPU(s):              8\r\nOn-line CPU(s) list: 0-7\r\nThread(s) per core:  2\r\nCore(s) per socket:  4\r\nSocket(s):           1\r\nNUMA node(s):        1\r\nVendor ID:           GenuineIntel\r\nCPU family:          6\r\nModel:               94\r\nModel name:          Intel(R) Core(TM) i7-6700HQ CPU @ 2.60GHz\r\nStepping:            3\r\nCPU MHz:             2700.253\r\nCPU max MHz:         3500,0000\r\nCPU min MHz:         800,0000\r\nBogoMIPS:            5184.00\r\nVirtualization:      VT-x\r\nL1d cache:           32K\r\nL1i cache:           32K\r\nL2 cache:            256K\r\nL3 cache:            6144K\r\nNUMA node0 CPU(s):   0-7\r\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp md_clear flush_l1d\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0117 sec, LOAD: 0.8935 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0599 sec, LOAD: 2.1901 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.1028 sec, LOAD: 0.9832 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0657 sec, LOAD: 1.2597 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0380 sec, LOAD: 0.8543 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0395 sec, LOAD: 0.4625 sec.\r\n', ""\r\nimport mxnet as mx\r\n\r\nsym = mx.sym.RNN(mode='lstm', num_layers=1, state_outputs=False, state_size=1, name='rnn')\r\n\r\nex = sym.bind(mx.cpu(), \r\n\t{\r\n\t\t'rnn_data': mx.ndarray.random.uniform(low=-1, high=1, shape=(10, 128, 5)),\r\n\t\t'rnn_parameters': mx.ndarray.random.uniform(low=-1, high=1, shape=(32)),\r\n\t\t'rnn_state': mx.ndarray.zeros(shape=(1, 128, 1)),\r\n\t\t'rnn_state_cell': mx.ndarray.zeros(shape=(1, 128, 1)),\r\n\t}\r\n)\r\n\r\nprint('---- Output in training mode:')\r\nex.forward(is_train=True)\r\nprint(ex.output_dict['rnn_output'].sum().asnumpy())\r\n\r\nprint('\\n---- Output in test mode:')\r\nex.forward(is_train=False)\r\nprint(ex.output_dict['rnn_output'].sum().asnumpy())\r\n\r\nex.copy_params_from(\t\r\n\t{\r\n\t\t'rnn_data': ex.arg_dict['rnn_data'],\r\n\t\t'rnn_parameters': mx.ndarray.random.uniform(low=-1, high=1, shape=(32)),\r\n\t\t'rnn_state': ex.arg_dict['rnn_state'],\r\n\t\t'rnn_state_cell': ex.arg_dict['rnn_state_cell'],\r\n\t}\r\n)\r\n\r\nprint('\\n---- Output in training mode after changing weights:')\r\nex.forward(is_train=True)\r\nprint(ex.output_dict['rnn_output'].sum().asnumpy())\r\n\r\nprint('\\n---- Output in test mode after changing weights:')\r\nex.forward(is_train=False)\r\nprint(ex.output_dict['rnn_output'].sum().asnumpy())\r\n"", '\r\n---- Output in training mode:\r\n[-112.02175]\r\n\r\n---- Output in test mode:\r\n[-112.02175]\r\n\r\n---- Output in training mode after changing weights:\r\n[-362.91537]\r\n\r\n---- Output in test mode after changing weights:\r\n[-112.02175]\r\n']","[""mode='lstm'"", 'is_train=True', 'MXNET_MKLDNN_ENABLED=0', 'is_train=False', 'MXNET_MKLDNN_ENABLED=0']",0,0
464,incubator-mxnet,5224,closed,"include/dmlc/logging.h:235: [00:59:21] src/io/local_filesys.cc:154: Check failed: allow_null  LocalFileSystem: fail to open ""model/det1-symbol.json""","hello, Now I use mxnet and face detection model 'mtcnn' to inference an image, but it shows error: 
I doubt that whether it is caused by mxnet or not.
Can you give me some advices how to solve this problem?",,"['same problem. @piiswrong ', ""same problem.@piiswrong\r\n\r\n--------------------------------------\r\n@IvyGongoogle @ysh329 i fixed~\r\nand i figure out i'm so stupid,this mistake caused by the file is not found.so you guys take carefully inspect of your file path"", '@novioleo Okay, thanks my dear friend and stupid me. :rofl: ', ""@ysh329 i know it's too late~lol\r\n"", 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!\nAlso, do please check out our [forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) for general ""how-to"" questions.']",[],"['include/dmlc/logging.h:235: [00:38:08] src/io/local_filesys.cc:154: Check failed: allow_null  LocalFileSystem: fail to open ""model/det1-symbol.json""']",0,0
465,incubator-mxnet,6095,closed,Multiple calls to train cause cudaMalloc to fail,"If calling train several times, I ran out of GPU memory:

pooled_storage_manager.h:80: cudaMalloc failed: out of memory

looks like GPU buffers are never cleared and memory runs out. 
It needs to be solved to be able to use MXNet in the larger application, where multiple train attempts are made in sequence, without restarting the app.",,"['it looks like the problem can be solved by setting \r\n\r\nptr = new storage::NaiveStorageManager<storage::GPUDeviceStorage>();\r\n\r\ninstead of GPUPooledStorageManager in storage.cc\r\n\r\nCan this be made as an option to be configured at runtime? It really is a bad practice to allocate all available GRAM and never release it. Another option is to add a public method that would allow all allocated memory to be released.', 'Hi, is this problem solved? I met the same question.', 'no it is not solved, we have ended up modifying storage.cc and making native storage manager a default. The threaded pooled one is garbage, never frees the memory making it impossible to use in any application where we need to be able to use DNN and cuda at the same time.', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
466,incubator-mxnet,9711,closed,Is it possible to support 5-dim or x-dim data operation,"Presently, we are use 4-dim data flow to build most of our models, **BatchSize x W x H x Channels** or **BatchSize x Channels x H x W**.

Is it possible to build 5-dim data flow? Maybe **BatchSize x Capsule x W x H x Channels**, which should be useful in ideas like CapsNet for that we don't have to reshape out data. So we can build high dimensions models which are more complicated and should be better both in structure and data extraction performance. 

According to **MobileNetV2**, performance of relu  is better in high dimensions than in low dimensions. So it maybe even more better if we can build our entire model with high dimensions operations. 
Further more, how about 6-dim or 7-dim operations, even x-dim operations?

Is this kind of operations possible? If possible, how hard will it be to implement them?",,"['5 dim version is ok. I already implemented Capsule with MxNet. You can refer to mine. But printting ndarray of high dim is not supported. Gluon is very friendly if you want to have a try.', '@dwSun Please use discuss.mxnet.io forum for usability questions like this to get quicker answer and get a larger audience involved. \r\n\r\n@sandeep-krishnamurthy Can you add label\r\n- Question and close the issue\r\n']",[],[],0,0
467,incubator-mxnet,6005,closed,An advice for set_params() when using kvstore,"finally, I found why my training loss can not decreased with kvstore.
that is because kvstore can not get the new weight value after its init.
kvstore only updates the weight in itself.
set_param() can not affect the weight of kvstore actually!
but, In my training, I need to exchange the weight value periodically.
So, I suggest kvstore can accept the new weight value by using set_params() in the training time.

@piiswrong @tqchen 
",,"['Can I delete the \r\n```cpp\r\n      CHECK(local_.find(keys[i]) == local_.end())\r\n          << ""duplicate init of key "" << keys[i];\r\n```\r\nof \r\n```cpp\r\n  void Init(const std::vector<int>& keys,\r\n            const std::vector<NDArray>& values) override {\r\n    for (size_t i = 0; i < keys.size(); ++i) {\r\n      CHECK(local_.find(keys[i]) == local_.end())\r\n          << ""duplicate init of key "" << keys[i];\r\n      local_[keys[i]] = values[i].Copy(pinned_ctx_);\r\n      comm_->Init(keys[i], values[i].shape());\r\n    }\r\n  }\r\n```\r\nbecause, I want to reinitialize the weight value on training procedure...\r\nthe ```comm_->Init``` will be a problem, it has push_back(...)\r\n@piiswrong ', 'I add Reset function into kvstore and related files, do you need it? I can pull a request.\r\nin ```kvstore_local.h```\r\n```cpp\r\n  //by starimpact\r\n  void Reset(const std::vector<int>& keys,\r\n            const std::vector<NDArray>& values,\r\n            int priority) override {\r\n    std::vector<int> uniq_keys;\r\n    std::vector<std::vector<NDArray> > grouped_vals;\r\n    GroupKVPairs(keys, values, &uniq_keys, &grouped_vals);\r\n\r\n    for (size_t i = 0; i < uniq_keys.size(); ++i) {\r\n      int key = uniq_keys[i];\r\n      const NDArray& merged = comm_->Reduce(key, grouped_vals[i], priority);\r\n      NDArray& local = local_[key];\r\n      if (updater_ != nullptr) {\r\n        CHECK(!local.is_none()) << ""key "" << key << "" has not been inited"";\r\n        CopyFromTo(merged, &local);\r\n      }\r\n    }\r\n  }\r\n```\r\nin ```c_api.cc```\r\n```cpp\r\n//by starimpact\r\nint MXKVStoreReset(KVStoreHandle handle,\r\n                  mx_uint num,\r\n                  const int* keys,\r\n                  NDArrayHandle* vals,\r\n                  int priority) {\r\n  API_BEGIN();\r\n  std::vector<int> v_keys(num);\r\n  std::vector<NDArray> v_vals(num);\r\n  for (mx_uint i = 0; i < num; ++i) {\r\n    v_keys[i] = keys[i];\r\n    v_vals[i] = *static_cast<NDArray*>(vals[i]);\r\n  }\r\n  static_cast<KVStore*>(handle)->Reset(v_keys, v_vals, priority);\r\n  API_END();\r\n}\r\n```\r\nin ```kvstore.py```\r\n```python\r\n    def reset(self, key, value, priority=0):\r\n        # by starimpact\r\n        ckeys, cvals = _ctype_key_value(key, value)\r\n        check_call(_LIB.MXKVStoreReset(\r\n            self.handle, mx_uint(len(ckeys)), ckeys, cvals,\r\n            ctypes.c_int(priority)))\r\n```\r\nin ```model.py```\r\n```python\r\ndef _reset_params_on_kvstore(param_arrays, kvstore):\r\n    # by starimpact\r\n    """""" Perform reset of param_arrays on kvstore.""""""\r\n    for index, arg_list in enumerate(param_arrays):\r\n        kvstore.reset(index, arg_list, priority=-index)\r\n```\r\nin ```module.py```\r\n```python\r\n        # by starimpact\r\n        if self._update_on_kvstore:\r\n            param_list = [args[0] for args in self._exec_group.param_arrays]\r\n            _reset_params_on_kvstore(param_list, self._kvstore)\r\n```', '@piiswrong ', ""I'm maintaining a version based on mxnet_v0.8.0:\r\nhttps://github.com/starimpact/mxnet_v0.8.0"", 'I just did a pull request.', 'the problem wanted to solve:\r\nassume there is a very big weight parameter weight_Z, like 100Wx128 dims. we can only update a part of it each time, such as 4Wx128.\r\nI have implemented in the local calculation by using reset function. but It seems to change a lot code if I want to do it in a distribution calculation.It is feasible, but just a little not easy to do it.', 'Which layer only has 4Wx128 gradients? ', 'the last layer, such as softmax or proxy.', 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!']",[],[],0,0
468,incubator-mxnet,9847,closed,Imperative regression output layers are broken,"I tried to implement a simple linear regression with ndarray in imperative style.

batchDataBatch
I think the point of the error is **""src/imperative/./imperative_utils.h:123: Check failed: infertype.count(attrs.op) Operator LinearRegressionOutput is missing FInferType attribute""**.

I also got the similar errors with  and . With  I get no errors while it is not the regression that I want. The imperative style regression outputs may not be used frequently but anyway they could be useful sometimes and listed in the API document anyway. Please fix them.
",Bug,"['Thanks for reporting this issue. I fix it in the PR above. Then your code is ok on my machine.\r\n\r\nBy the way, I think `mx.nd.waitall()` should be in the last line otherwise the computation is not triggered.', '@ZiyueHuang Thanks, the fix works. For the `waitall` call, why do we need explicit synchronization here? In my machine the code works without it.']",['\r\nI got the following error message.\r\n'],"['', ""python\r\nimport mxnet as mx\r\nfrom mxnet import nd\r\n\r\nnum_inputs = 3\r\nnum_outputs = 1\r\nnum_examples = 1000\r\n\r\ndef real_fn(X):\r\n    return 2 * X[:, 0] - 3.4 * X[:, 1] + 4.2\r\n\r\ntrain_data = nd.random_normal(shape=(num_examples, num_inputs))\r\nnoise = 0.01 * nd.random_normal(shape=(num_examples,))\r\ntrain_label = real_fn(train_data) + noise\r\n\r\nbatch_size = 4\r\ntrain_iter = mx.io.NDArrayIter(train_data, train_label, batch_size, shuffle=True, label_name='lin_reg_label')\r\n\r\nweight = nd.random_normal(0, 0.01, shape=(num_outputs, num_inputs))\r\nweight.attach_grad()\r\nbias = nd.random_normal(0, 0.01, shape=(num_outputs, ))\r\nbias.attach_grad()\r\noptimizer = mx.optimizer.SGD(learning_rate=0.1, momentum=0.9)\r\noptimizer_weight_st = optimizer.create_state(0, weight)\r\noptimizer_bias_st = optimizer.create_state(0, bias)\r\n\r\nfor epoch in range(10):\r\n\ttrain_iter.reset()\r\n\tfor batch in train_iter: # "", ' is a ', '\r\n\t\twith mx.autograd.record():\r\n\t\t\tfc0 = nd.FullyConnected(data=batch.data[0], weight=weight, bias=bias, num_hidden=num_outputs)\r\n\t\t\tout = nd.LinearRegressionOutput(data=fc0, label=batch.label[0]) # RMS cost function\r\n\t\tout.backward()\r\n\t\toptimizer.update(0, weight, weight.grad, optimizer_weight_st)\r\n\t\toptimizer.update(0, bias, bias.grad, optimizer_bias_st)\r\n\r\n/usr/lib/python3.6/site-packages/mxnet/optimizer.py:136: UserWarning: WARNING: New optimizer mxnet.optimizer.NAG is overriding existing optimizer mxnet.optimizer.NAG\r\n  Optimizer.opt_registry[name].__name__))\r\nTraceback (most recent call last):\r\n  File ""Tmp.py"", line 31, in <module>\r\n    out = nd.LinearRegressionOutput(data=fc0, label=batch.label[0]) # RMS cost function\r\n  File ""<string>"", line 52, in LinearRegressionOutput\r\n  File ""/usr/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py"", line 92, in _imperative_invoke\r\n    ctypes.byref(out_stypes)))\r\n  File ""/usr/lib/python3.6/site-packages/mxnet/base.py"", line 148, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [20:58:23] src/imperative/./imperative_utils.h:123: Check failed: infertype.count(attrs.op) Operator LinearRegressionOutput is missing FInferType attribute\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /usr/lib/python3.6/site-packages/mxnet/libmxnet.so(dmlc::StackTrace[abi:cxx11]()+0x46) [0x7f380a187db6]\r\n[bt] (1) /usr/lib/python3.6/site-packages/mxnet/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x28) [0x7f380a185be8]\r\n[bt] (2) /usr/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::imperative::SetShapeType(mxnet::Context const&, nnvm::NodeAttrs const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, mxnet::DispatchMode*)+0xc2e) [0x7f380b93416e]\r\n[bt] (3) /usr/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::Imperative::Invoke(mxnet::Context const&, nnvm::NodeAttrs const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&)+0x25a) [0x7f380b921cea]\r\n[bt] (4) /usr/lib/python3.6/site-packages/mxnet/libmxnet.so(MXImperativeInvokeImpl(void*, int, void**, int*, void***, int, char const**, char const**)+0x1e4) [0x7f380bd24c44]\r\n[bt] (5) /usr/lib/python3.6/site-packages/mxnet/libmxnet.so(MXImperativeInvokeEx+0x13c) [0x7f380bd2544c]\r\n[bt] (6) /usr/lib/libffi.so.6(ffi_call_unix64+0x4c) [0x7f3811e561c8]\r\n[bt] (7) /usr/lib/libffi.so.6(ffi_call+0x32a) [0x7f3811e55c2a]\r\n[bt] (8) /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f38120b654e]\r\n[bt] (9) /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x11f85) [0x7f38120b6f85]\r\n', '', 'LogisticRegressionOutput', 'MAERegressionOutput', 'SoftmaxOutput']",0,0
469,incubator-mxnet,9826,closed,Crash Mxnet: Error in `python3': corrupted double-linked list: 0x00007f1c4b2e09d0,"I try to test Mtcnn face detection from this repository: https://github.com/pangyupo/mxnet_mtcnn_face_detection

After some iteration I got a severe crash of Mxnet with this error : https://gist.github.com/edmBernard/91731e795decd7b7c5456cb0d7a1d303

I was not able to reproduce this out of my code. All the code was in python only Mxnet use C++.
Does someone have a idea where this can come from ?

Note: maybe it's linked but this code use a old API with FeedForward


Note: 
On GPU I got this error : 
On CPU I got this error : ",,"['What version of mxnet are you using ? Please provide commit hash ? Please provide reproduction steps.', 'I find the issu. It come from Python Pool management. \r\nWe try to launch prediction on several worker at the same time. \r\nWithout the Pool with an old sequential processing it work fine.']",[],"['/usr/local/lib/python3.5/dist-packages/mxnet-1.0.1-py3.5.egg/mxnet/model.py:927: DeprecationWarning: mxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\r\n  **kwargs)', '*** Error in python3: corrupted double-linked list: 0x00007f1c4b2e09d0 ***', '*** Error in python3: double free or corruption (fasttop): 0x0000000003d0d290 ***']",0,0
470,incubator-mxnet,5163,closed,How to generate synset.txt files?,"We can use im2rec according to the lst file to generate rec files. But how could we generate synset.txt files? And if we use NDArrayIter, how to find the relation between the sequence of the prediction and label file?
Many thanks.",,"[""For example, for a 2 class classification problem. The label is 0 or 1. And we get the prediction results from the network which is [0.5, 0.4], what's the possibility of getting result of 1 and what's the possibility of getting result 0."", '@lincolnBush is this what you are after? http://data.dmlc.ml/mxnet/models/imagenet/synset.txt\r\n\r\nThe mapping from index to label in the `synset.txt` file is done outside the training/evaluation process, and the actual labels are not encoded in the mxnet symbol or data iterators as it is not required.  Does this clarify your question?', 'Thank you very much for your reply. I mean how to generate this file by programme. How does this file related to the label by programme.', 'This file is supplied together with the training dataset, and is not created by any script in the MXNet repo.  You can find out about the origin of the `synset.txt` here: http://image-net.org/challenges/LSVRC/2015/browse-synsets', '@lincolnBush \r\nAfter creating .lst and .rec files you can make your own `synset` (example in R for cifar10 dataset):\r\n\r\n    labels <- read.table(""cifar_train.lst"")\r\n    labels <- labels[!duplicated(labels$V2), ]\r\n    class_labels <- data.frame(response = labels$V2,\r\n                               label = sapply(tmp, function(x) x[1]))\r\n    class_labels <- class_labels[order(class_labels$response), ]\r\n    write.table(class_labels, ""synset.txt"", row.names = FALSE, col.names = TRUE)', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!', ""I have the same problem with that. What's the mean of the id(e.g. n01440764) in front of the class name? And, how can I do to make my own synset.txt?"", 'Hi! I was stuck with the same problem and solved with this way : creating a .lst file from my dataset. Convering the .lst file to the synset file with this python code : \r\n\r\nf= open(""C:/Users/SAHINA/Desktop/mxnet_sample/mxnet_sample/OKNOK.lst"",""r"")\r\n\r\nf2 = open(""C:/Users/SAHINA/Desktop/mxnet_sample/mxnet_sample/OKNOKsynset.txt"", ""w"")\r\n\r\nfor line in f:\r\n    line = line[line.find(""\\t"")+1:len(line)]\r\n    line = line[line.find(""c""):len(line)-5] + "" "" + line[line.find(""\\t"")+1:line.find(""\\\\"")]\r\n    f2.write(line)\r\n    f2.write(""\\n"")\r\n    \r\nf.close()\r\nf2.close()  \r\n\r\nSo you just need to change the file path and the characters to find and move for having the synset order. An example line from my .lst file to synset file is :\r\n 315\t0.000000\tNOK\\crop53_3906_2.jpg   ---> crop53_3906_2 NOK', '> @lincolnBush is this what you are after? http://data.dmlc.ml/mxnet/models/imagenet/synset.txt\r\n> \r\n> The mapping from index to label in the `synset.txt` file is done outside the training/evaluation process, and the actual labels are not encoded in the mxnet symbol or data iterators as it is not required. Does this clarify your question?\r\n\r\nHi,\r\nThe domain may changed, \r\nMay i have the latest domain of \r\n     http://data.dmlc.ml/mxnet/models/imagenet/synset.txt\r\nTY']",[],[],0,0
471,incubator-mxnet,4660,closed,cudnn-convolution performance tests on cnn-lstm-ctc,"## Environment info
Operating System: ubuntu 14.04

Compiler: gcc 4.8

Package used (Python/R/Scala/Julia): python

MXNet version: 0.9.1 (0.7.1 nightly 32cb6bc)

Or if installed from source:

MXNet commit hash (): 32cb6bc

If you are using python package, please provide

Python version and distribution: anaconda 2.7.11

## Error Message:
I used cnn-lstm-ctc to do ocr tasks, and it can work well with mxnet 0.7 version, but when I use the latest mxnet version 0.9.1 it will block here forever :

## Minimum reproducible example

## Steps to reproduce
1.
2.
3.

## What have you tried to solve it?

",,"[""@xinghedyc ,can you release your predict code, i don't know how to predict\r\nhere is my issue ,can you help me[4650](https://github.com/dmlc/mxnet/issues/4650)\r\n\r\nwhen I try the latest mxnet , i also meet the problem, i find i is caused by pred = pred.asnumpy() in metric.py.update(), but i don't kown how to solve it"", '`export MXNET_CUDNN_AUTOTUNE_DEFAULT=0` to disable this', ""@poorfriend I haven't write predict code yet, I will try the following days, if I make it , I'll inform you for sure.\r\n@piiswrong Thanks a lot ,I'll try it and send you feedback later."", '@piiswrong when I try to run example in warp-ctc/toy-ctc.py, it also block here :\r\n```\r\n~/mxnet/example/warpctc$ python toy_ctc.py\r\nWARNING:root:[Deprecation Warning] mxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\r\nbegin fit\r\n```\r\nwhen I crtl + c to stop the job here is the log :\r\n```\r\nFile ""toy_ctc.py"", line 162, in <module>\r\n    batch_end_callback=mx.callback.Speedometer(BATCH_SIZE, 50),)\r\n  File ""../../python/mxnet/model.py"", line 814, in fit\r\n    sym_gen=self.sym_gen)\r\n  File ""../../python/mxnet/model.py"", line 259, in _train_multi_device\r\n    executor_manager.update_metric(eval_metric, data_batch.label)\r\n  File ""../../python/mxnet/executor_manager.py"", line 425, in update_metric\r\n    self.curr_execgrp.update_metric(metric, labels)\r\n  File ""../../python/mxnet/executor_manager.py"", line 277, in update_metric\r\n    metric.update(labels_slice, texec.outputs)\r\n  File ""../../python/mxnet/metric.py"", line 348, in update\r\n    pred = pred.asnumpy()\r\n  File ""../../python/mxnet/ndarray.py"", line 500, in asnumpy\r\n    ctypes.c_size_t(data.size)))\r\n```', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']","['\r\nsrc/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...\r\n']",['git rev-parse HEAD'],0,0
472,incubator-mxnet,3684,closed,Would predict and NDArray.toArray cause BLOCK ?,"Hi @javelinjs 

I use MXNet-Scala to deploy my model for a while and it works great, the engineering team stress tested my service and found the service could stop response after a while.

They printed the info with :



Here's my code:



",,"['I use the old `FeedForward` but not `mod.Module` api, is it the reason? As https://github.com/dmlc/mxnet/issues/3570 @piiswrong \n', 'async push in mxnet engine is not thread-safe, which means `Executor.forward` and `FeedForward.predict` is not thread-safe.\n\nI suggest to use these approaches to work around:\n- Load one model per thread, which can be easily achieved by using `java.lang.ThreadLocal`\n- `synchronized` your `predict` function. But this means you can hardly take advantage of multi-threads\n- Use one (or several) threads for prediction (as consumers), each with a model, and make producers collect a batch of samples for your consumers. Batch forward can speedup your prediction.\n']","['\r\nThread 226126: (state = IN_NATIVE)\r\n - ml.dmlc.mxnet.LibInfo.mxNDArraySyncCopyToCPU(long, float[], int) @bci=0 (Compiled frame; information may be imprecise)\r\n - ml.dmlc.mxnet.NDArray.toArray() @bci=38, line=896 (Compiled frame)\r\n\r\nThread 156913: (state = IN_NATIVE)\r\n - ml.dmlc.mxnet.LibInfo.mxNDArrayWaitToRead(long) @bci=0 (Compiled frame; information may be imprecise)\r\n - ml.dmlc.mxnet.NDArray.waitToRead() @bci=13, line=754 (Compiled frame)\r\n', 'scala\r\n/**\r\n    * predict\r\n    *\r\n    * @param flat A flat feature input vector.\r\n    * @param shape Shape of input data.\r\n    * @return\r\n    */\r\n  def predict(flat: Array[Float], shape: Array[Int]): Array[NDArray] = {\r\n    val ndArray = NDArray.array(flat, Shape(shape))\r\n\r\n    val data: IndexedSeq[NDArray] = IndexedSeq(ndArray)\r\n    val label: IndexedSeq[NDArray] = IndexedSeq()\r\n\r\n    val valData: NDArrayIter = new NDArrayIter(data, label, batchSize)\r\n    val prediction = model.predict(valData)\r\n    return prediction\r\n\r\n  }\r\n\r\n  /**\r\n    * Top-1 prediction results for a batch data.\r\n    *\r\n    * @param flat A flat feature input vector.\r\n    * @param shape Shape of input data.\r\n    * @return Return top-1 prediction results for a batch data.\r\n    */\r\n  def predictTop1(flat: Array[Float], shape: Array[Int]): NDArray = {\r\n    val prediction = predict(flat, shape)(0)\r\n    NDArray.argmaxChannel(prediction)\r\n  }\r\n', ""java\r\n    public String predict(String utterance) {\r\n        float[] features = generateFeature(utterance);\r\n        int[] shape = {batchSize, 1, sentenceSize, featureSize};\r\n\r\n        if (features.length == (batchSize*sentenceSize*featureSize)) {\r\n            NDArray prediction = predictor.predictTop1(features, shape);  // use scala code above.\r\n            // prediction.waitToRead();  we tested here but it didn't work.\r\n            int index = (int) prediction.toArray()[0];\r\n            return index2label.get(index);\r\n        }\r\n\r\n        return null;\r\n    }\r\n""]",['jstack'],0,0
473,incubator-mxnet,371,closed,computing image mean,"I recall, from version 1 of Cxxnet, that there was a utility for creating the .bin for the image mean; I can iterate through the dataset, compute the mean image, save it as a jpg, and then convert it with ./bin/im2rec, but I was wondering if there was a utility to do this that I missed in the documentation?
",,"['On the subject of preprocessing, I\'m currently getting some sort of memory allocation issue I don\'t understand when  trying to read my own train/test .rec files:\n\n```\nmxnet.base.MXNetError: [21:18:51] src/storage/./cpu_device_storage.h:48: Check failed: (ret) == (0) Allocation failed\n```\n\nMy train.lst looks like this (all images are 1024x1024x3):\n\n```\n0   222 w_7812.jpg\n1   44  w_4598.jpg\n```\n\nI create the train/test records like so:\n\n```\n./bin/im2rec train.lst /home/user/Desktop/train/ train.rec\n```\n\nand everything seems to work fine. My iterators are defined as follows:\n\n```\ntrain_dataiter = mx.io.ImageRecordIter(\n    path_imgrec=""train.rec"",\n    rand_crop=False,\n    rand_mirror=True,\n    data_shape=(3,1024,1024),\n    batch_size=64,\n    preprocess_threads=1)\ntest_dataiter = mx.io.ImageRecordIter(\n    path_imgrec=""test.rec"",\n    rand_crop=False,\n    rand_mirror=False,\n    data_shape=(3,1024,1024),\n    batch_size=64,\n    preprocess_threads=1)\n```\n\nAnd the remainder is just a truncation of the Cifar10 network example\n\n```\ndata = mx.symbol.Variable(name=""data"")\nconv1 = ConvFactory(data=data, kernel=(3,3), pad=(1,1), num_filter=96, act_type=""relu"")\nin3a = SimpleFactory(conv1, 32, 32)\nin3b = SimpleFactory(in3a, 32, 48)\nin3c = DownsampleFactory(in3b, 80)\nin4bb =mx.symbol.Dropout(in3c) \nin4c = SimpleFactory(in4bb, 80, 80)\nin4cc= mx.symbol.LeakyReLU(in4c)\nin4d = SimpleFactory(in4cc, 48, 96)\npool = mx.symbol.Pooling(data=in4cc, pool_type=""avg"", kernel=(7,7), name=""global_pool"")\nflatten = mx.symbol.Flatten(data=pool, name=""flatten1"")\nfc = mx.symbol.FullyConnected(data=flatten, num_hidden=447, name=""fc1"")\nsoftmax = mx.symbol.Softmax(data=fc, name=""loss"")\n\ngpus=mx.gpu(0)\nmodel=mx.model.FeedForward(ctx=gpus,symbol=softmax,num_round=2,learning_rate=0.05,momentum=.9,wd=0.0001,initializer=mx.init.Uniform(0.07))\nmodel.fit(X=train_dataiter,eval_data=test_dataiter,epoch_end_callback=mx.callback.Speedometer(64))\n```\n', 'Hmm, this could due to the allocation of too large memory chunk being requested. Can you check what was the size being requested on your side https://github.com/dmlc/mxnet/blob/master/src/storage/cpu_device_storage.h#L47\n', ""I can check when I get home; is the output of posix_memalign produced at some point in the run?  I'm not entirely clear on how to check the size of the request.\n"", 'You can change this line https://github.com/dmlc/mxnet/blob/master/src/storage/cpu_device_storage.h#L48 to\n\n```\n  CHECK_EQ(ret, 0) << ""Allocation failed, "" << ""requested size = ""<< size;\n```\n', 'Do I need to recompile anything?\n', 'Yes, you will need to rebuild libmxnet.so, and re-install the python. \n', ""It was trying to allocate 73 GB, and I cap out at 32 GB; I'm somewhat surprised, though, as it only looked like it was taking up 16 GB when I loaded them all as numpy arrays.  I suppose  I'm going to have to do segmentation instead of trying to feed them in as is; thank you for the diagnostic help.\n\nRe: the original question, is there an existing tool for computing the image mean, or do I need to build that utility?\n"", 'The image iterator will automatically calculate/load mean file if you set `mean_file=mean.nd`. Personally, I set `mean_r=117`, `mean_g=117`, `mean_b=117` instead of such a mean file. There is no performance hurt.\n', ""Is there a GPU equivalent line for the requested CPU memory? Just to make sure I could get it working, I resized all my images to 256x256; even with a batch size of 2, it's throwing \n\n```\nmxnet.base.MXNetError: [10:57:24] src/storage/./gpu_device_storage.h:39: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading CUDA: out of memory\n```\n\nThe fully loaded 256x256 takes up 1.6 GB or so of CPU RAM, and my GPU is a titan X, so it seems unlikely that it genuinely can't find the memory for that.  I've also tried converting to greyscale (1x512x512), although it seemed to have difficulty loading it.\n"", 'There is no limit on how much memory to get. As everything is cutting the edge of memory, maybe you can check the memory requested, maybe the input size is indeed too large for this configuration(it was used for cifar, which means it expects a small input size). Try to use the one for imagenet, which might solve your probem\n', 'I am going to close this for now as the original question of mean image get answered, please feel free to re-open this if there is future questions.\n', '@antinucleon Could you please detail ""The image iterator will automatically calculate/load mean file if you set mean_file=mean.nd.""? How to write an image iterator to have such functionality?\n\n```\n    train_dataiter = mx.io.ImageRecordIter(\n        path_imgrec = args.data_dir + ""train.rec"",\n        data_shape  = data_shape,\n        batch_size  = args.batch_size,\n        rand_crop   = True,\n        rand_mirror = True,\n        shuffle     = True, # Note that it will only shuffle in the batch!\n        num_parts   = kv.num_workers,\n        part_index  = kv.rank)\n```\n\nBesides, will the `mean_image` or `mean_r, mean_g, mean_b` also be conducted on the validation and testing data? The document says that they are only augmentation parameters. \n\n![image](https://cloud.githubusercontent.com/assets/3724085/12377662/266f89fe-bd60-11e5-9072-beb3fbd9d770.png)\n', 'Put this line in your training ImageRecordIter (call it what you want, put it where you want)\r\nmean_img           = ""../recordIO_dir/mean.bin""   \r\nIts not there to start.  But when you fit your model it will be **created for you**.  (I think after the first epoch but am not positive).  Then when the validation set is run its there and used, same with your test set.\r\n\r\n', 'Yeah, Put mean_img=""path/to/mean.nd"". If the file does not exist, ImageRecordIterator will first create this file and calculate mean value, store result in the file. And then start training. Detail can be seen in file ""iter_image_recordio_2.cc"", the new version of recordio data iterator under ""mxnetRoot/src/io/iter_image_recordio_2.cc"". Maybe from line 216, the Normalize init and the CreateMeanImg function.']",[],[],0,0
474,incubator-mxnet,8391,closed,use 224x224 size to train mobilenet will encounter memory problem,"I was trying to use CIFAR dataset to train a mobilenet, since the origin size is 32x32 so I resize them to 224x224 which is the size of the mobilenet input:

but after I resize them, I will encounter this problem:
**mxnet_source/dmlc-core/include/dmlc/./logging.h:308: [16:20:13] include/mxnet/././tensor_blob.h:275: Check failed: this->shape_.Size() == shape.Size() (4515840000 vs. 220872704) TBlob.get_with_shape: new and old shape do not match total elements**

if I did not resize the image, it will be ok, and I check the meomery use, seems a memory leak happened, my computer has 64GB memory, the program will use them all.

the other parts of my script is:



can any one help?
",Bug Memory NDArray Python,"['use tiny imagenet but not cifar', 'I tried to use imagerecorditer, it will be ok, maybe its a bug in NDarray', '@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', '@sandeep-krishnamurthy please add Python, Bug, NDArray, Memory to this topic', '@HaoLiuHust are you still seeing this issue?\r\n\r\nwith the latest code, I don\'t see the issue ""Check failed: this->shape_.Size() == shape.Size() (4515840000 vs. 220872704) TBlob.get_with_shape: new and old shape do not match total elements"". \r\n\r\nCould you share the system configuration on which you see this issue?', '@vandanavk It is a long time..., the program has lost, maybe it is ok now..', 'Closing the issue as it is not reproducible. Please reopen in case issue still persists.']","[""\r\ndef ExtractImageAndLabel(path,file):\r\n    with open(path+file, 'rb') as f:\r\n        data = cPickle.load(f)\r\n        images = data['data']\r\n        images = np.reshape(images, (10000, 3, 32, 32))\r\n        images_resize = mx.nd.zeros(shape=(10000, 3, 224, 224))\r\n        imagearray = mx.nd.array(images)\r\n\r\n        for i, img in enumerate(imagearray):\r\n            img=mx.nd.transpose(img,(2,1,0))\r\n            images_rs = mx.image.imresize(img,224,224)\r\n            images_resize[i]=mx.nd.transpose(images_rs,(2,1,0))\r\n\r\n        labels = data['labels']\r\n\r\n        labelarray = mx.nd.array(labels)\r\n\r\n        return images_resize, labelarray_\r\n"", '\r\n_import mxnet as mx\r\nfrom mxnet import nd, autograd, gluon\r\nimport numpy as np\r\nimport time\r\nimport Utils\r\nimport logging\r\nimport mobilenet\r\n\r\ndef ReadTrainSets(path):\r\n    train_data = []\r\n    train_label = []\r\n\r\n    data_pre = \'data_batch_\'\r\n    for i in range(1,6):\r\n        file_name = data_pre+str(i)\r\n        data_batch, label_batch = Utils.ExtractImageAndLabel(path, file_name)\r\n        if not len(train_data):\r\n            train_data = data_batch\r\n            train_label = label_batch\r\n\r\n        else:\r\n            train_data = mx.nd.concatenate([train_data,data_batch])\r\n            train_label = mx.nd.concatenate([train_label,label_batch])\r\n\r\n    return train_data, train_label\r\n\r\npath = \'./cifar-10-batches-py/\'\r\nbatch = 128\r\nctx =(mx.gpu(2),mx.gpu(3))\r\ntrain_data, train_label=ReadTrainSets(path)\r\n\r\nprint train_data.shape\r\nprint train_label.shape\r\n\r\ntrain_iter = mx.io.NDArrayIter(data=train_data,label=train_label,batch_size=batch,shuffle=True)\r\n\r\nnet = gluon.model_zoo.vision.get_mobilenet(pretrained=False,ctx=ctx, multiplier = 1,classes=10)\r\ndata=mx.sym.Variable(\'data\')\r\noutput = net(data)\r\nsoftmax = mx.symbol.SoftmaxOutput(data=output, name=\'softmax\')\r\n#softmax = mobilenet.get_symbol(10)\r\n\r\nlogging.basicConfig(level=logging.INFO)\r\n\r\nmod = mx.mod.Module(symbol=softmax, context=ctx)\r\n\r\nprint mod.symbol.get_internals()\r\n\r\nmod.bind(data_shapes=train_iter.provide_data, label_shapes=train_iter.provide_label)\r\nmod.init_params(initializer=mx.init.Xavier(magnitude=2.))\r\n\r\nmod.fit(train_iter, optimizer_params={\'learning_rate\':0.1, \'momentum\':0.9}, num_epoch=100)\r\nmod.save_checkpoint(""mobilenet"", epoch=100)_\r\n']",[],0,0
475,incubator-mxnet,14961,closed,CI Build Failures: unix-gpu TensorRT,"http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-14959/2/pipeline.
TensorRT build fails with:
",Bug Build CI,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: CI, Build', '@marcoabreu @Chancebair Any pointers to who might solve this issue? Thanks!', ""I'm looking into it - I've created a PR to disabled it for the time being. I think I've also figured out the issue. Testing the fix in a different PR."", ""Those stages have been temporarily disabled. So, CI should be unblocked now.\r\nI've posted a PR with a fix. Just waiting for it to get merged."", '@haojin2 you can probably close this']","['\r\n-- Could NOT find TENSORRT (missing: TENSORRT_INCLUDE_DIR TENSORRT_LIBRARY) \r\nERRORCannot find TensorRT library.\r\nCMake Error: The following variables are used in this project, but they are set to NOTFOUND.\r\nPlease set them or make sure they are set and tested correctly in the CMake files:\r\n/work/mxnet/3rdparty/onnx-tensorrt/TENSORRT_INCLUDE_DIR\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n-- Configuring incomplete, errors occurred!\r\nSee also ""/work/mxnet/3rdparty/onnx-tensorrt/build/CMakeFiles/CMakeOutput.log"".\r\nSee also ""/work/mxnet/3rdparty/onnx-tensorrt/build/CMakeFiles/CMakeError.log"".\r\nTENSORRT_INCLUDE_DIR\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n   used as include directory in directory /work/mxnet/3rdparty/onnx-tensorrt\r\nTENSORRT_LIBRARY_INFER\r\n    linked by target ""nvonnxparser_static"" in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n    linked by target ""nvonnxparser"" in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n    linked by target ""nvonnxparser_runtime"" in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n    linked by target ""nvonnxparser_plugin"" in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n    linked by target ""nvonnxparser_runtime_static"" in directory /work/mxnet/3rdparty/onnx-tensorrt\r\nTENSORRT_LIBRARY_INFER_PLUGIN\r\n    linked by target ""nvonnxparser_static"" in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n    linked by target ""nvonnxparser"" in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n    linked by target ""nvonnxparser_runtime"" in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n    linked by target ""nvonnxparser_plugin"" in directory /work/mxnet/3rdparty/onnx-tensorrt\r\n    linked by target ""nvonnxparser_runtime_static"" in directory /work/mxnet/3rdparty/onnx-tensorrt\r\nbuild.py: 2019-05-15 08:02:20,417Z INFO Waiting for status of container cc30cac8c8bd for 600 s.\r\nbuild.py: 2019-05-15 08:02:22,337Z INFO Container exit status: {\'Error\': None, \'StatusCode\': 1}\r\nbuild.py: 2019-05-15 08:02:22,337Z ERROR Container exited with an error 😞\r\n']",[],0,0
476,incubator-mxnet,3244,closed,"Pkg.test on v 0.6 succeeds, but fails on 0.4.6","I have checked out the latest master in both Julia 0.4.6 and latest 0.6. Pkg.test runs correctly in 0.6, but fails in 0.4.6 at:

/usr/bin/julia --check-bounds=yes --code-coverage=none --color=yes /home/colin/.julia/v0.4/MXNet/test/runtests.jl
",,"['Thanks for reporting this. The Julia code lives at https://github.com/dmlc/MXNet.jl which is the right place for issues with the Julia binsings.\n\nHow have you build MXNet? Did you build it yourself or with `Pkg.build`? What is the result of `Pkg.status(""MXNet"")`?\n', 'OK, must have been confused by the upper/lower case and thought I was in the right place. Shall I close the comment and repost over there? I checked out the master with Pkg.checkout followed by Pkg.build. Pkg.status shows the same in both 0.6 and 0.4.6:\n\n```\nPkg.status(""MXNet"")\n - MXNet                         0.0.8+             master\n```\n', 'Let\'s leave it here for now. Can you send me the `versioninfo()` from 0.4? Did you install julia `v""0.4""` from source or via the package manager? What does `Libdl.dlpath(Libdl.dlopen(Base.libblas_name))` and `Base.blas_vendor()`, return?\n', '```\nversioninfo()\nJulia Version 0.4.6\nCommit 2e358ce* (2016-06-19 17:16 UTC)\nPlatform Info:\n  System: Linux (x86_64-suse-linux)\n  CPU: Intel(R) Core(TM) i5-4460  CPU @ 3.20GHz\n  WORD_SIZE: 64\n  BLAS: liblapack.so.3\n  LAPACK: liblapack\n  LIBM: libopenlibm\n  LLVM: libLLVM-3.3\n```\n\nJulia 0.4.6 is from an openSUSE yast repo, and Julia 0.6 is from github.\nAgain in Julia 0.4.6:\n\n```\njulia> Libdl.dlpath(Libdl.dlopen(Base.libblas_name))\n""/usr/lib64/liblapack.so.3""\n\njulia> Base.blas_vendor()\n:unknown\n```\n', '`Pkg.build(""MXNet"")` only supports Julia builds with openblas. Your source build fro v""0.6"" uses openblas and so that works without a problem. \nThis is sadly an upstream problem with openSUSE, so your best bet is to manually build MXNet (http://dmlc.ml/MXNet.jl/latest/user-guide/install/) or use the generic linux binaries from julialang.org.\n', 'OK I will inform openSUSE that there is an issue with their 0.4.6. Thanks much.\n', ""opensuse really shouldn't be building against reference blas, but they might be doing some funny naming with calling openblas libblas to make it switchable with update-alternatives? That mess isn't really worth the hassle IMO, since openBLAS is so much better or more mature than any other open-source option.\n"", '@tkelman @vchuravy I went to the openSUSE forum and found other people complaining of problems with -lcblas and failed builds. I also investigated the utility \n\n```\n# update-alternatives --config liblapack.so.3 \nThere are 4 choices for the alternative liblapack.so.3 (providing /usr/lib64/liblapack.so.3).\n\n  Selection    Path                                  Priority   Status\n------------------------------------------------------------\n* 0            /usr/lib64/lapack/liblapack.so.3       50        auto mode\n  1            /usr/lib64/atlas/libsatlas.so.3        20        manual mode\n  2            /usr/lib64/atlas/libtatlas.so.3        20        manual mode\n  3            /usr/lib64/lapack/liblapack.so.3       50        manual mode\n  4            /usr/lib64/libopenblas_pthreads.so.0   20        manual mode\n```\n\nBut I have no information about what might be more suitable in the circumstances.\nJulia 0.6 works well with MXNet so at this point I am quite happy to blaze away up there, even if the version is a bit unstable.\n', ""We can move this discussion elsewhere since it's not a mxnet issue, but the opensuse package for julia should declare a hard dependency on openblas, since building with one implementation and switching to another would likely not work with multithreading. atlas and the reference have not very good performance, and mkl isn't open source so you can't get it from a linux distro.\n"", 'I will transfer this discussion to Julia.\n']","['\n\nMy LD_LIBRARY_PATH was empty, but changing it to /usr/lib64/blas was ineffective. I can echo the contents of $LD_LIBRARY_PATH in the system shell, but inside Julia in both versions the content of this variable is not visible/defined.\nUsing:\n\n']","['', '\nINFO: SymbolicNode::Attributes\nINFO: SymbolicNode::Functions\nINFO: SymbolicNode::dot\n/usr/bin/julia: symbol lookup error: /home/colin/.julia/v0.4/MXNet/deps/usr/lib/libmxnet.so: undefined symbol: cblas_sgemm\n=============================================[ ERROR: MXNet ]=============================================\n\nfailed process: Process(', ', ProcessExited(127)) [127]\n\n==========================================================================================================\nERROR: MXNet had test errors\n in test at pkg/entry.jl:803\n in anonymous at pkg/dir.jl:31\n in cd at file.jl:22\n in cd at pkg/dir.jl:31\n in test at pkg.jl:71\n\nJulia Version 0.6.0-dev.524\nCommit 442af7b* (2016-09-07 03:35 UTC)\nPlatform Info:\n  System: Linux (x86_64-suse-linux)\n  CPU: Intel(R) Core(TM) i5-4460  CPU @ 3.20GHz\n  WORD_SIZE: 64\n  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Haswell)\n  LAPACK: libopenblas64_\n  LIBM: libopenlibm\n  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)\n\n', '']",0,0
477,incubator-mxnet,9176,closed,row_sparse ndarray + 0 should not return dense ndarray,"Currently  and  return dense NDArray. Instead it can return a row-sparse NDArray directly. This is causing extra conversions when checkpointing the model, as  calls [this](https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/module/executor_group.py#L414-L416) which in turn calls . 
To support sparse ndarray output for these two operators we just need to update the infer storage logic [here](https://github.com/apache/incubator-mxnet/blob/05047ad8fee4e8ee63ae2b7f96e7e9c7684fa4a0/src/operator/tensor/elemwise_binary_scalar_op_basic.cc#L61-L66)

Also  should also return sparse result. 
",Operator Sparse,[],[],"['nd._plus_scalar(row_sparse, 0)', 'nd._minus_scalar(row_sparse, 0)', 'module.get_params', 'nd._plus_scalar(row_sparse, 0)', 'nd._div_scalar(row_sparse, non-zero)']",0,0
478,incubator-mxnet,10648,closed,Why examlpe wide_deep runs faster on win10(cpu) than linux(gpu-Tesla M40 24GB),"## Description
code link is here https://github.com/apache/incubator-mxnet/tree/master/example/sparse/wide_deep    
Why examlpe wide_deep runs faster on win10(cpu) than linux(gpu-Tesla M40 24GB)

## Environment info (Required)
### win10
----------Python Info----------
Version      : 3.5.2
Compiler     : MSC v.1900 64 bit (AMD64)
Build        : ('default', 'Jul  5 2016 11:41:13')
Arch         : ('64bit', 'WindowsPE')
------------Pip Info-----------
Version      : 10.0.1
----------MXNet Info-----------
Version      : 1.1.0
Hashtag not found. Not installed from pre-built package.
----------System Info----------
Platform     : Windows-10-10.0.15063-SP0
system       : Windows
node         : minhozhou-PC0
release      : 10
version      : 10.0.15063
----------Hardware Info----------
machine      : AMD64
processor    : Intel64 Family 6 Model 158 Stepping 9, GenuineIntel
Name
Intel(R) Core(TM) i5-7500 CPU @ 3.40GHz
### Linux
----------Python Info----------
('Version      :', '2.7.5')
('Compiler     :', 'GCC 4.8.5 20150623 (Red Hat 4.8.5-4)')
('Build        :', ('default', 'Nov 20 2015 02:00:19'))
('Arch         :', ('64bit', 'ELF'))
------------Pip Info-----------
('Version      :', '9.0.1')
----------System Info----------
('Platform     :', 'Linux-3.10.104-1-tlinux2-0041.tl2-x86_64-with-centos-7.2-Final')
('system       :', 'Linux')
('release      :', '3.10.104-1-tlinux2-0041.tl2')
('version      :', '#1 SMP Fri Oct 28 20:58:27 CST 2016')
----------Hardware Info----------
('machine      :', 'x86_64')
('processor    :', 'x86_64')
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                56
On-line CPU(s) list:   0-55
Thread(s) per core:    2
Core(s) per socket:    14
Socket(s):             2
NUMA node(s):          2
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 79
Model name:            Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
Stepping:              1
CPU MHz:               2401.000
BogoMIPS:              4801.66
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              35840K
NUMA node0 CPU(s):     0-13,28-41
NUMA node1 CPU(s):     14-27,42-55

## log
### win10
2018-04-23 11:33:37,170 epoch 0, accuracy = 0.7957062007874016
2018-04-23 11:33:37,173 Saved checkpoint to ""checkpoint-0000.params""
2018-04-23 11:33:37,175 Saved optimizer state to ""checkpoint-0000.states""
2018-04-23 11:33:37,276 Epoch[1] Batch [100]    Speed: 127659.84 samples/sec    accuracy=0.811797
2018-04-23 11:33:37,378 Epoch[1] Batch [200]    Speed: 126396.03 samples/sec    accuracy=0.826719
2018-04-23 11:33:37,484 epoch 1, accuracy = 0.8258489173228346
2018-04-23 11:33:37,488 Saved checkpoint to ""checkpoint-0001.params""
2018-04-23 11:33:37,489 Saved optimizer state to ""checkpoint-0001.states""
2018-04-23 11:33:37,593 Epoch[2] Batch [100]    Speed: 125157.28 samples/sec    accuracy=0.826250
2018-04-23 11:33:37,696 Epoch[2] Batch [200]    Speed: 123941.43 samples/sec    accuracy=0.829922
2018-04-23 11:33:37,806 epoch 2, accuracy = 0.8415969488188977

### Linux
2018-04-23 11:43:50,156 Epoch[1] Batch [100]	Speed: 24695.55 samples/sec	accuracy=0.782266
2018-04-23 11:43:50,755 Epoch[1] Batch [200]	Speed: 21366.17 samples/sec	accuracy=0.783750
2018-04-23 11:43:51,558 epoch 1, accuracy = 0.795583169291
2018-04-23 11:43:51,570 Saved checkpoint to ""checkpoint-0001.params""
2018-04-23 11:43:51,574 Saved optimizer state to ""checkpoint-0001.states""
2018-04-23 11:43:52,132 Epoch[2] Batch [100]	Speed: 23574.39 samples/sec	accuracy=0.789219
2018-04-23 11:43:52,721 Epoch[2] Batch [200]	Speed: 21724.27 samples/sec	accuracy=0.793438
2018-04-23 11:43:53,718 epoch 2, accuracy = 0.799950787402


**win10: 127659.84 samples/sec**
**Linux : 23574.39 samples/sec**

",,"['Sparse op is faster on CPU than on GPU.', 'thanks']",[],[],0,0
479,incubator-mxnet,12869,closed,Python trained model gives different features set in C++,"Hi,

We have model trained in python and want to use it from c++ as for getting 512D float features.

c++ gives different output when we try with image-classification-predict.cpp 

We just want to get data (as in code) 512d float vector as in python output ? 

model:
https://pan.baidu.com/s/1mj6X7MK 
or

 https://www.dropbox.com/s/ou8v3c307vyzawc/model-r50-arcface-ms1m-refine-v1.zip?dl=0

Isnt there a clear method for C++ feature extraction ?

Best

 ",C++ Pending Requester Info,"['@MyraBaba thanks for your question and thanks for trying out the C++ API. Could you please bring me more context on the difference with the result? How would you build your C++ package and your system info? \r\n@leleamol here since he is the developer with C++.\r\n\r\n@mxnet-label-bot please add label [C++, Question]', ""Hi\r\n@leleamol \r\n\r\nSystem is Mac os X and also ubuntu 18\r\nbuild mxnet with cpp support\r\n\r\nWe want to use Mxnet in our all production.\r\n\r\nWe just stuck in first attemp :)\r\n\r\nhttps://github.com/blob/master/deploy/test.py this is the our first test.\r\n\r\nWe can extract  feature in pyhton.\r\n\r\nWe tried to use predict-cpp api to use model and extract future with same model above first message .\r\n\r\nc++ image-classification-predict-cpp we put same model same picture in the above repo Tom-hanks.\r\n\r\nit gives different outpu (512D but different float numbers).\r\n\r\nClearly we are missing something because we are new to mxnet .\r\n\r\nBasically ; We want to this in c++ as  in python  and want to get same features: \r\n\r\nimg = cv2.imread('Tom_Hanks_54745.png')\r\nimg = cv2.resize(img , (112,112))\r\n\r\nimg = model.get_input(img)\r\nf2 = model.get_feature(img)\r\ndist = np.sum(np.square(f1-f2))\r\nsim = np.dot(f1, f2.T)\r\n\r\nBest...\r\n\r\n"", '@leleamol \r\n@lanking520 \r\n\r\nany idea ? what could be the basic steps in C++ for : \r\n```\r\n\r\nimg = model.get_input(img)\r\nf2 = model.get_feature(img)\r\ndist = np.sum(np.square(f1-f2))\r\nsim = np.dot(f1, f2.T)\r\n\r\n\r\n```\r\n\r\nWe loved the mxnet framework bu fi we cant use it in our C++ environment unfortunately we have to  drop mxnet and back to the old system.\r\n\r\nfor mxnet experts specially on the C , C++ side it should be trivial example which means a lot for the community.\r\n\r\nWhat we can do to make it works ? ', '@MyraBaba \r\nThe MXNet supports C++ APIs in cpp-package directory.  I am working on an example to demonstrate a workflow that will\r\n1. Load the model,\r\n2. Load the parameters, and\r\n3. Run a forward pass. \r\n\r\nI will try out your model with that example. Will update this issue with my observations.\r\nThanks\r\n', 'We almost exhausted :)  It certainly should work but we are very new to mxnet framwork. On the other hand training speed and mem usage fantastic.\r\n\r\nIf we succesfully get same results in c++ as in our python test.py we will change our AI to the mxnet completely .\r\n\r\nThanks for your help and attention.\r\n\r\nBest\r\n\r\n', 'With my test program I was able to get the output of float vector of 512. Without using sklearn.preprocessing.normalize on that output (similar to what was done in the test python script),  the maximum accuracy was reported to be 2.7216 at index 84.   The rest of the entries in 512D vector were 0.03412.  ( I have used the same image as that of test.py)\r\n\r\nI did not normalize the image before running forward pass.\r\nIf this helps, I can share the code of my example.', 'I will work on your c++ code and try to make progress. \n\nI will run under  the cpp-package /example/ feature_extract. Right ? \n\nI  can finalise this week this we will move money and there will be support requested we can discuss separately\n\nBest\n\n\n> On 22 Oct 2018, at 20:42, Amol Lele <notifications@github.com> wrote:\n> \n> With my test program I was able to get the output of float vector of 512. Without using sklearn.preprocessing.normalize on that output (similar to what was done in the test python script), the maximum accuracy was reported to be 2.7216 at index 84. The rest of the entries in 512D vector were 0.03412. ( I have used the same image as that of test.py)\n> \n> I did not normalize the image before running forward pass.\n> If this helps, I can share the code of my example.\n> \n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub <https://github.com/apache/incubator-mxnet/issues/12869#issuecomment-431910422>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AQscn9zC_lg0ZG6AfMOZUy_oGMhnxeygks5ungN2gaJpZM4XvOz7>.\n> \n\n', '@MyraBaba \r\nThe cpp-package/example/feature_extract is a good start but it is not very optimized and does not follow the recommended approach to run the inference workflow.\r\nFor example, the program is invoking ""SimpleBind"" operation every time before running the Forward() call. Since, SimpleBind() is an expensive operation, it should be invoked only once.\r\n\r\nPlease let us know if you need help.\r\n', 'Can you share your code that you mentioned above please , I will start from your code.', '@MyraBaba \r\nI have submitted a PR #12915.  It will be under review.  I have used the same example to load the model you have mentioned in the issue and run the inference workflow with the image Tom_Hanks_54745.png\r\n', '@leleamol \r\nThanks I started to working on it.\r\ninception_inference is asking synset file. All we need 512D feature we will use it for our own purposes. we dont need labels.  How we can just produce 512 features ? \r\n\r\nI used synset.tx (inception) with below command and get error below.:\r\n\r\nHow did you run exactly for tom_hanks (112x112) ?\r\n\r\n```\r\n`./inception_inference --symbol /Users/alpullu/Projects/inSAF-face/models/model-r50-am-lfw/-symbol.json --params /Users/alpullu/Projects/inSAF-face/models/model-r50-am-lfw/-0000.params  --input_shape 3 112 112 --image /Users/alpullu/Projects/inSAF-face/deploy/Tom_Hanks_54745.png --synset ./sysnset.txt --mean mean_224.nd \r\n[13:50:28] inception_inference.cpp:121: Loading the model from /Users/alpullu/Projects/inSAF-face/models/model-r50-am-lfw/-symbol.json\r\n\r\n[13:50:28] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.12.1. Attempting to upgrade...\r\n[13:50:28] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\r\n[13:50:28] inception_inference.cpp:130: Loading the model parameters from /Users/alpullu/Projects/inSAF-face/models/model-r50-am-lfw/-0000.params\r\n\r\n[13:50:28] inception_inference.cpp:153: Loading the synset file.\r\nlibc++abi.dylib: terminating with uncaught exception of type dmlc::Error: [13:50:28] ../../include/mxnet-cpp/symbol.hpp:211: Check failed: MXSymbolInferShape(GetHandle(), keys.size(), keys.data(), arg_ind_ptr.data(), arg_shape_data.data(), &in_shape_size, &in_shape_ndim, &in_shape_data, &out_shape_size, &out_shape_ndim, &out_shape_data, &aux_shape_size, &aux_shape_ndim, &aux_shape_data, &complete) == 0 (-1 vs. 0) \r\n\r\nStack trace returned 9 entries:\r\n[bt] (0) 0   inception_inference                 0x0000000107ca386b dmlc::StackTrace() + 299\r\n[bt] (1) 1   inception_inference                 0x0000000107ca35ff dmlc::LogMessageFatal::~LogMessageFatal() + 47\r\n[bt] (2) 2   inception_inference                 0x0000000107ca5ad3 mxnet::cpp::Symbol::InferShape(std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<unsigned int, std::__1::allocator<unsigned int> >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > > > > const&, std::__1::vector<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> >, std::__1::allocator<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > > >*, std::__1::vector<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> >, std::__1::allocator<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > > >*, std::__1::vector<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> >, std::__1::allocator<std::__1::vector<unsigned int, std::__1::allocator<unsigned int> > > >*) const + 947\r\n[bt] (3) 3   inception_inference                 0x0000000107ca4a64 mxnet::cpp::Symbol::InferExecutorArrays(mxnet::cpp::Context const&, std::__1::vector<mxnet::cpp::NDArray, std::__1::allocator<mxnet::cpp::NDArray> >*, std::__1::vector<mxnet::cpp::NDArray, std::__1::allocator<mxnet::cpp::NDArray> >*, std::__1::vector<mxnet::cpp::OpReqType, std::__1::allocator<mxnet::cpp::OpReqType> >*, std::__1::vector<mxnet::cpp::NDArray, std::__1::allocator<mxnet::cpp::NDArray> >*, std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, mxnet::cpp::NDArray, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, mxnet::cpp::NDArray> > > const&, std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, mxnet::cpp::NDArray, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, mxnet::cpp::NDArray> > > const&, std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, mxnet::cpp::OpReqType, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, mxnet::cpp::OpReqType> > > const&, std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, mxnet::cpp::NDArray, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, mxnet::cpp::NDArray> > > const&) const + 548\r\n[bt] (4) 4   inception_inference                 0x0000000107c9e6cf mxnet::cpp::Symbol::SimpleBind(mxnet::cpp::Context const&, std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, mxnet::cpp::NDArray, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, mxnet::cpp::NDArray> > > const&, std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, mxnet::cpp::NDArray, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, mxnet::cpp::NDArray> > > const&, std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, mxnet::cpp::OpReqType, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, mxnet::cpp::OpReqType> > > const&, std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, mxnet::cpp::NDArray, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, mxnet::cpp::NDArray> > > const&) + 127\r\n[bt] (5) 5   inception_inference                 0x0000000107c9d981 Predictor::Predictor(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, mxnet::cpp::Shape const&) + 641\r\n[bt] (6) 6   inception_inference                 0x0000000107ca1d49 main + 1849\r\n[bt] (7) 7   libdyld.dylib                       0x00007fffb9881235 start + 1\r\n[bt] (8) 8   ???                                 0x000000000000000f 0x0 + 15\r\n\r\n\r\n```\r\n`', '@MyraBaba The synset file and mean image file are not mandatory. But there is a bug in code that mandates synset file to be specified. I am sending out the fix. \r\nThe crash you are seeing is due to incorrect input image shape.\r\nThe program assumes the input image shape to be 3 * 224 * 224, if not specified on the command line.\r\nFor your model your command line would something like this:\r\n\r\ninception_inference --symbol <model_json_file> --params <parameter file> --image <image file>  --synset <./synset file> --input_shape ""3 112 112""\r\n\r\n', 'Here is the PR #12930 after fixing the example.', '@leleamol How I can contact you  ? have you email ?  I could be get paid support from you / also a contribution for your effort .\r\n\r\nBest\r\n', ""@MyraBaba you can join our Slack channel where everybody can ask questions and it's for free! \r\nTo join it: http://mxnet.incubator.apache.org/community/contribute.html#slack"", '@MyraBaba as @lanking520  suggested you can join the slack channel and can ask questions there.\r\nI was wondering whether the example in PR helpful in solving your issue?', '@leleamol Thanks for your PR it is very good start for me.\r\n\r\nBut time is limited for me and I need the produce same results for same picture as in python version  which is requires more deep knowledge mxnet &  align and normalisation I think.\r\n\r\n', 'I send mail to slack channel and it got bact to me error. FYI', ""@MyraBaba you can send a email to dev@mxnet.apache.org requesting an invite, we'll invite your email address."", 'Hi @leleamol \r\n\r\nI am trying to integrate and testing your new inference.\r\n\r\n\r\ndo you know the equilavent of the beloq python code in mxnet or Ndarray ?  :\r\n \r\ndistance = numpy.sum(numpy.square(descA512 - descB512))\r\n\r\nI will test with my own preprocessed faces first to see difference..\r\n\r\n', '@MyraBaba \r\nAccording to the [ndarray.h](https://github.com/apache/incubator-mxnet/blob/master/cpp-package/include/mxnet-cpp/ndarray.h), the NDArray does support ""-"" and ""*"" operators with which you can implement ""numpy.square(descA512- descB512)"" operations.  However, numpy.sum equivalent operation is not yet supported for NDArray.\r\n', 'than I can use ** instead of numpy.square right ? \r\n\r\nPS: I have trouble to linking  #12930  in cmake . what could be the proper way to do in cmake ?\r\n\r\nBest', 'You should be able to use ""*"" operator in NDArray to get the square.\r\n\r\nRegarding #12930 the example contains Makefile. What is the error that you are getting?\r\n\r\n', '@mxnet-label-bot add [Pending Requester Info]', '@leleamol Hi,\r\n\r\nI am back to project and able to compile with Cmake ypur inception_inference.cpp with above mentioned models.\r\n\r\nCan you direct me to where is the output of float vector of 512 variable ? can I get this 512 float vector features with this .cpp ? If so I couldnt find it with debugging.  Could you possibly let me \r\nknow?\r\n\r\nBest\r\n\r\n\r\n> With my test program I was able to get the output of float vector of 512. Without using sklearn.preprocessing.normalize on that output (similar to what was done in the test python script), the maximum accuracy was reported to be 2.7216 at index 84. The rest of the entries in 512D vector were 0.03412. ( I have used the same image as that of test.py)\r\n> \r\n> I did not normalize the image before running forward pass.\r\n> If this helps, I can share the code of my example.\r\n\r\n', 'Hi @MyraBaba \r\n\r\nIn the [inception_inference.cpp] <https://github.com/apache/incubator-mxnet/blob/master/cpp-package/example/inference/inception_inference.cpp> example, you can add following line \r\n\r\n```\r\nLG << array;\r\n```\r\nafter the line [309]<https://github.com/apache/incubator-mxnet/blob/master/cpp-package/example/inference/inception_inference.cpp#L309>.\r\nIt will print out all the values of the output vector.\r\n\r\nIn the example, we use ArgmaxChannel on this output to get the index with highest probability.\r\nI hope this helps.\r\n', '@MyraBaba : Were you able to output the float vector? Just checking in to see how you were doing with using the CPP example for your use-case. \r\n\r\nIf you were able to successfully use the CPP example, could we close this issue? ', 'when I add the LG << array saw the output. \r\n\r\nnow I need to test both python and the c++ inference outputs is same.\r\n\r\nbest', '@MyraBaba Close this issue for now, Please feel free to reopen if problem persist.']",[],[],0,0
480,incubator-mxnet,9703,closed,Can't run mx.nd.smooth_l1,"## Description
(Brief description of the problem in no more than 2 sentences.)
Can't run mx.nd.smooth_l1

## Environment info (Required)
----------Python Info----------
Version      : 3.5.2
Compiler     : MSC v.1900 64 bit (AMD64)
Build        : ('v3.5.2:4def2a2901a5', 'Jun 25 2016 22:18:55')
Arch         : ('64bit', 'WindowsPE')
------------Pip Info-----------
Version      : 9.0.1
Directory    : C:\Users\67009\AppData\Local\Programs\Python\Python35\lib\site-packages\pip
----------MXNet Info-----------
Version      : 1.0.0
Directory    : C:\Users\67009\AppData\Local\Programs\Python\Python35\lib\site-packages\mxnet
Hashtag not found. Not installed from pre-built package.
----------System Info----------
Platform     : Windows-10-10.0.16299-SP0
system       : Windows
node         : DESKTOP-NRACBB8
release      : 10
version      : 10.0.16299
----------Hardware Info----------
machine      : AMD64
processor    : Intel64 Family 6 Model 60 Stepping 3, GenuineIntel
Name
Intel(R) Core(TM) i7-4710HQ CPU @ 2.50GHz

----------Network Test----------
Setting timeout: 10
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0393 sec, LOAD: 1.9675 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0338 sec, LOAD: 1.6308 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0321 sec, LOAD: 0.4048 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.2478 sec, LOAD: 1.1301 sec.
Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0341 sec, LOAD: 1.5128 sec.
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0072 sec, LOAD: 1.3811 sec.


## Build info (Required if built from source)
N/A

## Error Message:
Traceback (most recent call last):
  File ""<pyshell#13>"", line 1, in <module>
    b=mx.nd.smooth_l1(a)
  File ""<string>"", line 48, in smooth_l1
  File ""C:\Users\67009\AppData\Local\Programs\Python\Python35\lib\site-packages\mxnet\_ctypes\ndarray.py"", line 92, in _imperative_invoke
    ctypes.byref(out_stypes)))
OSError: [WinError -529697949] Windows Error 0xe06d7363

## Steps to reproduce



",NDArray,"['Seems that `scalar` parameter is omitted, please refer to the documents.\r\n\r\n`b=mx.nd.smooth_l1(a, scalar=1)`\r\n\r\nIt works fine for me on ubuntu.', 'Your answer solved my problem. Thanks.', ""@sandeep-krishnamurthy Can you please add this label and also close the issue as it's resolved.\r\n- MXNet\r\n- NDArray\r\n\r\nThanks!""]","['\r\na=mx.nd.array([5,9,4])\r\nb=mx.nd.smooth_l1(a)\r\n']",[],0,0
481,incubator-mxnet,861,closed,Can I fix some layer when training a big network,"Hi, I wonder if I can fix the parameter of some layer while training, like have a different learning rate for different layer and make some of them zero. Thank you
",,"[""Don't bind the gradient for the weights that you don't want to update\n"", 'Thanks a lot.\n']",[],[],0,0
482,incubator-mxnet,3062,closed,batch_end_callback doesn't show eval_metric,"I want to implement CNN for text on my own but failed to get evaluation metric in batch_end_callback like this(not exactly top-k, its just accuracy):



Here's my network:



I use DataIter in which the shape in  and  are same as the netowrk's :







It makes me confused why evaluation metrics doesn't show up. I suppose it should have even though I do not provide .
",,"['After I post this issue, the report came out surprisingly. Close the issue.\n\nNow I get it after I checked the source code. The evaluation metric would only report when you do have multiple batches in an epoch: https://github.com/dmlc/mxnet/blob/721fd800be0dab51c594bf956e0188a78a8a7a70/python/mxnet/callback.py#L78-L93\n']","['\n2016-08-12 20:15:43,819 Node[0] Epoch[5] Batch [50]    Speed: 444.47 samples/sec    Train-accuracy=0.844219\n2016-08-12 20:15:43,819 Node[0] Epoch[5] Batch [50]    Speed: 444.47 samples/sec    Train-top_k_accuracy_5=0.994219\n2016-08-12 20:15:43,820 Node[0] Epoch[5] Batch [50]    Speed: 444.47 samples/sec    Train-top_k_accuracy_10=1.000000\n2016-08-12 20:15:43,820 Node[0] Epoch[5] Batch [50]    Speed: 444.47 samples/sec    Train-top_k_accuracy_20=1.000000\n2016-08-12 20:15:58,518 Node[0] Epoch[5] Batch [100]    Speed: 435.42 samples/sec    Train-accuracy=0.846094\n2016-08-12 20:15:58,519 Node[0] Epoch[5] Batch [100]    Speed: 435.42 samples/sec    Train-top_k_accuracy_5=0.995625\n2016-08-12 20:15:58,519 Node[0] Epoch[5] Batch [100]    Speed: 435.42 samples/sec    Train-top_k_accuracy_10=1.000000\n2016-08-12 20:15:58,519 Node[0] Epoch[5] Batch [100]    Speed: 435.42 samples/sec    Train-top_k_accuracy_20=1.000000\n2016-08-12 20:16:13,001 Node[0] Epoch[5] Batch [150]    Speed: 441.95 samples/sec    Train-accuracy=0.860938\n', ' python\n10 def get_net(vocab_size, embedding_size, sentence_size, batch_size, num_classes, with_embedding, dropout=0.0, filter_list=[3,4,5], num_filter=100):\n 11     """"""\n 12     Network structure.\n 13     """"""\n 14     import logging\n 15     head = head = \'%(asctime)-15s %(message)s\'\n 16     logging.basicConfig(level=logging.DEBUG, format=head)\n 17\n 18     data = mx.symbol.Variable(\'data\')\n 19     label = mx.symbol.Variable(\'softmax_label\')\n 20\n 21     # embedding layer\n 22     if not with_embedding:\n 23         word_embed = mx.symbol.Embedding(data=data, input_dim=vocab_size,\n 24                                       output_dim=embedding_size, name=\'word_embedding\')\n 25         conv_input = mx.symbol.Reshape(data=word_embed, target_shape=(batch_size, 1, sentence_size, embedding_size))  # convolution layer needs 4D input.\n 26     else:\n 27         logging.info(\'with pretrained embedding.\')\n 28         conv_input = data\n 29\n 30     # convolution and pooling layer\n 31     pooled_outputs = []\n 32     for i, filter_size in enumerate(filter_list):\n 33         convi = mx.symbol.Convolution(data=conv_input, kernel=(filter_size, embedding_size),\n 34                                    num_filter=num_filter)\n 35         acti  = mx.symbol.Activation(data=convi, act_type=\'relu\')\n 36         pooli = mx.symbol.Pooling(data=acti, pool_type=\'max\', kernel=(sentence_size - filter_size + 1, 1), stride=(1,1))  # max pooling on entire sentence feature ma    p.\n 37         pooled_outputs.append(pooli)\n 38\n 39     # combine all pooled outputs\n 40     num_feature_maps = num_filter * len(filter_list)\n 41     concat = mx.symbol.Concat(*pooled_outputs, dim=1)  # max-overtime pooling. concat all feature maps into a long feature before feeding into final dropout and full    y connected layer.\n 42     h_pool = mx.symbol.Reshape(data=concat, shape=(batch_size, num_feature_maps))  # make it flat/horizontal\n 43\n 44     # dropout\n 45     if dropout > 0.0:\n 46         logging.info(\'use dropout.\')\n 47         drop = mx.symbol.Dropout(data=h_pool, p=dropout)\n 48     else:\n 49         logging.info(\'Do not use dropout.\')\n 50         drop = h_pool\n 51\n 52     # fully connected and softmax output.\n 53     fc = mx.symbol.FullyConnected(data=drop, num_hidden=num_classes)\n 54     softmax = mx.symbol.SoftmaxOutput(data=fc, label=label)\n 55\n 56     return softmax\n 57\n\n', ""\n2016-08-18 22:24:20,943 provide_data. [('data', (64L, 1L, 19L, 128L))]\n2016-08-18 22:24:20,943 provide_label. [('softmax_label', (64L,))]\n"", ' python\n 66 class DataIter(mx.io.DataIter):\n 67     """"""\n 68     Define data loading and batch-iter related functionality.\n 69     """"""\n 70     def __init__(self, batch_size, num_classes, embedding_size, num_epochs,\n 71                  input_file, word2vec_file, with_embedding):\n 72         super(DataIter, self).__init__()\n...\n...\n 92         if with_embedding:\n 93             # word2vec\n 94             self.word2vec = data_helpers.load_pretrained_word2vec(word2vec_file)\n 95             self.vocab_size = len(self.word2vec)\n 96             # text image\n 97             self.data, self.label = data_helpers.load_data_with_word2vec(input_file, self.word2vec)\n 98             self.sentence_size = self.data.shape[1]\n 99             self.provide_data = [(\'data\', (self.batch_size, 1, self.sentence_size, self.embedding_size))]\n100             self.provide_label = [(\'softmax_label\', (self.batch_size, ))]\n101         else:\n102             # training sample\n103             self.data, self.label, self.vocab, self.vocab_inv = data_helpers.load_data(input_file)\n104             self.vocab_size = len(self.vocab)\n105             self.sentence_size = self.data.shape[1]\n106             self.provide_data = [(\'data\', (self.batch_size, self.sentence_size))]\n107             self.provide_label = [(\'softmax_label\', (self.batch_size, ))]\n', ' python\n186     data_train = DataIter(batch_size, num_classes, embedding_size, num_epoch,\n187                           input_file, word2vec_file, with_embedding=True)\n190\n191\n192     # get text_cnn network and model\n193     cnn = get_net(vocab_size=data_train.vocab_size, embedding_size=embedding_size,\n194                   sentence_size=data_train.sentence_size, batch_size=batch_size,\n195                   num_classes=num_classes, with_embedding=True, dropout=0.5)\n196\n197\n198     model = mx.model.FeedForward(ctx = mx.gpu(0),\n199                                  symbol = cnn,\n200                                  num_epoch = num_epoch,\n201                                  learning_rate = 0.3,\n202                                  momentum = 0.9,\n203                                  wd = 0.0000,\n204                                  initializer = mx.init.Xavier(factor_type=\'in\', magnitude=2.34))\n205\n206     eval_metrics = [""acc""]\n209\n210     # training\n211     model.fit(X                  = data_train,\n212               #eval_data                 = data_eval,\n213               eval_metric        = eval_metrics,\n214               batch_end_callback = mx.callback.Speedometer(batch_size, 50))\n']","['provide_data', 'provide_label', 'eval_data']",0,0
483,incubator-mxnet,8531,closed,How to get the correlation result of two feature maps?,"Suppose I have two feature maps F1 and F2 output by a network. I want to compute convolution of F1 and F2. Assume that F1 has shape (1, C, 10, 10) and F2 has shape (1, C, 3, 3) and the wanted result should have shape (1, 1, 8, 8) if pad = 0, stride = 1 and dilate = 1.
How to implement this using MXNet?
I have come up with one possible way that uses mx.sym.Correlation, but I cannot get the idea how correlation operator computes by reading the doc.
Or, can I set the weight of a mx.sym.Convolution layer to F2, and data to F1? Would this interfere the propagation of grads when training?",HowTo,"['I am confused. For correlation, the F1 and F2 must have same shapes.\r\nFor convolution, F2 should be (C, 1, 3, 3)', '@zhreshold By correlation, I mean F2 acts like a correlation kernel (or convolution kernel) that slides on F1. For example,\r\n```\r\n     1 1 1 2 2\r\nF1 = 2 3 4 1 1\r\n     0 0 0 2 3 \r\n\r\n     0 1 0\r\nF2 = 1 0 1\r\n     0 1 0\r\n``` \r\nThen, the correlation result should be\r\n```\r\nR = F1 * F2 = 7 5 9\r\n```\r\nwhere \r\n```\r\n7 = 1 + 2 + 4 + 0\r\n5 = 1 + 3 + 1 + 0\r\n9 = 2 + 4 + 1 + 2\r\n```\r\nIn the above example, stride = 1, pad = 0, dilate = 0, thus there are three correlation positions at F1', 'Can someone help me with this?', '@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', 'just do convolution with another matrix?', '@squidszyd \r\nYou can do the following:\r\n```\r\nC = 64\r\nF1 = mx.nd.ones((1,C,10,10))\r\nF2 = mx.nd.ones((1,C,3,3))\r\nconvolution = mx.gluon.nn.Conv2D(channels=1, kernel_size=(3,3), use_bias=False)\r\nconvolution.initialize(mx.init.Constant(F2))\r\nout = convolution(F1)\r\nprint(out.shape)\r\n```\r\n```\r\n(1, 1, 8, 8)\r\n```\r\n\r\nAnd with your second example:\r\n```\r\nC = 1\r\nF1 = mx.nd.array([[1, 1, 1, 2, 2], [2, 3, 4, 1, 1], [0, 0, 0, 2, 3]]).reshape((1,C,3,5))\r\nF2 = mx.nd.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]]).reshape((3,3))\r\nconvolution = mx.gluon.nn.Conv2D(channels=1, kernel_size=(3,3), use_bias=False)\r\nconvolution.initialize(mx.init.Constant(F2))\r\nout = convolution(F1)\r\nprint(out)\r\n```\r\n```\r\n[[[[7. 5. 9.]]]]\r\n<NDArray 1x1x1x3 @cpu(0)>\r\n```\r\n@szha can you please close the issue? Thanks', ""@ThomasDelteil \r\nThanks for reply. I've figured out this exact solution months before :P\r\nI'll close this issue.""]",[],[],0,0
484,incubator-mxnet,12539,closed,Failing nighty test: test_pixel2pixel (test_notebooks_single_gpu.StraightDopeSingleGpuTests),"http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/NightlyTests_onBinaries/detail/NightlyTests_onBinaries/148/pipeline

",Bug Flaky Gluon Test,"['The test is not Flaky. \r\nThis PR https://github.com/apache/incubator-mxnet/pull/12537 - reverts the change in the NDArrayIter\r\n\r\n[WIP] PR - https://github.com/apache/incubator-mxnet/pull/12545 to capture edge case of empty label', 'Resolving this issue as the change is reverted and tests are passing.']","['\r\nFAIL: test_pixel2pixel (test_notebooks_single_gpu.StraightDopeSingleGpuTests)\r\n\r\n----------------------------------------------------------------------\r\n\r\nTraceback (most recent call last):\r\n\r\n  File ""/work/mxnet/tests/nightly/straight_dope/test_notebooks_single_gpu.py"", line 255, in test_pixel2pixel\r\n\r\n    assert _test_notebook(\'chapter14_generative-adversarial-networks/pixel2pixel\')\r\n\r\nAssertionError\r\n']",[],0,0
485,incubator-mxnet,8902,closed,A todo list for usability improvement for sparse tensor,"## throw exception on storage fallback
Currently when storage fallback happens, the log message is printed in the console, but it's very hard for the user to figure out when the fallback happens in the code even if they use NaiveEngine for debugging. We should throw an exception when storage fallback happens to help the user debug it. 
https://github.com/apache/incubator-mxnet/blob/master/src/operator/operator_common.h#L526

## missing storage fallback message/exception during ndarray copy
cast_storage may happen when the source and destination ndarray are of different storage types. Currently it's converted in silence and the user is not aware. 

## sparse vector with shape=(10)
https://github.com/apache/incubator-mxnet/issues/8817 
Still under discussion. We should either fix it or at least not let VM crash. 

## distributed training tutorial for sparse
Maybe do this after kvstore=device is done. 

## Testing
https://github.com/apache/incubator-mxnet/issues/8709
https://github.com/apache/incubator-mxnet/issues/8542 
#8980
",Sparse,['+1 for distributed training tutorial. I can take this task after https://github.com/apache/incubator-mxnet/pull/8732 is done.'],[],[],0,0
486,incubator-mxnet,6181,closed,Problem with implementing tree-LSTM's in mxnet,"I am implementing tree-LSTM's for predicting the negativity/positivity of sentences in mxnet and I am using the [BucketingModule](https://github.com/dmlc/mxnet/blob/master/docs/how_to/bucketing.md) to do this. The tree LSTM is structured similar to the structure of the parse-tree of each sentence. Therefore, each training sample will need a different structure. So I am using one bucket per input sample. Also, not all the LSTM blocks in a single structure have shared weights. For example, in a tree consisting of n nodes, k of the nodes can share the same weights and the other (n-k) can share their weights. The partition is not limited to two. In fact, it often is the case that most of the blocks do not share weights with the others.

  * My first problem is with training. If I train using 'sgd', and 'momentum' : 0.0, the training works fine. However, if I change momentum or try to use other optimizers such as 'adam', the training returns an inconsistency shape error due to the self.states dictionary in the Updater class in [optimizer.py](https://github.com/dmlc/mxnet/blob/master/python/mxnet/optimizer.py). It initializes the self.states dictionary for the first sentence. When the second sentence is fed, the ""index"" of the states is not necessarily the same as the first sentence. But the updater re-uses the already created states for the first sentence and fails at look-up time for the second equation. 

  * My second question is how can I do mini-batch training under this setting?

[My code](https://github.com/ForoughA/neuralTrig) is available on github. The main file to run is neuralTrig.py.

**NOTE: In order to run the code, the 'allow_extra_params' flag needs to be sat to True in exec_.copy_params_from(arg_params, aux_params, allow_extra_params=True) in function set_params(self, arg_params, aux_params) in file [executor_group.py](https://github.com/dmlc/mxnet/blob/master/python/mxnet/module/executor_group.py) line 332.**


## Environment info
Operating System: 
MAC OS X El Capitan

Compiler: 
clang-800.0.38

Package used (Python/R/Scala/Julia): 
Python

MXNet version:

Or if installed from source:

MXNet commit hash ():
58e334639c4d5a875bb5b8b33036c3fab8ed7115

If you are using python package, please provide

Python version and distribution:
Python 2.7.13 :: Anaconda 4.3.1 (x86_64)

If you are using R package, please provide

R :

## Error Message:

[08:11:32] /Users/Forough/mxnet/dmlc-core/include/dmlc/logging.h:300: [08:11:32] src/operator/nn/../tensor/../elemwise_op_common.h:31: Check failed: assign(&dattr, (*vec)[i]) Incompatible attr in node  at 2-th input: expected (1,120), got (120,240)

Stack trace returned 9 entries:
[bt] (0) 0   libmxnet.so                         0x00000001074d5f35 _ZN4dmlc15LogMessageFatalD2Ev + 37
[bt] (1) 1   libmxnet.so                         0x00000001074d3539 _ZN4dmlc15LogMessageFatalD1Ev + 9
[bt] (2) 2   libmxnet.so                         0x000000010754de72 _ZZN5mxnet2op12ElemwiseAttrIN4nnvm6TShapeEXadL_ZNS0_13shape_is_noneERKS3_EEXadL_ZNS0_12shape_assignEPS3_S5_EELb1EEEbRKNS2_9NodeAttrsEPNSt3__16vectorIT_NSA_9allocatorISC_EEEESG_RKSC_ENKUlPNSB_IS3_NSD_IS3_EEEEPKcE_clESL_SN_ + 498
[bt] (3) 3   libmxnet.so                         0x000000010754db26 _ZN5mxnet2op12ElemwiseAttrIN4nnvm6TShapeEXadL_ZNS0_13shape_is_noneERKS3_EEXadL_ZNS0_12shape_assignEPS3_S5_EELb1EEEbRKNS2_9NodeAttrsEPNSt3__16vectorIT_NSA_9allocatorISC_EEEESG_RKSC_ + 198
[bt] (4) 4   libmxnet.so                         0x0000000107bf7e92 _ZN5mxnet2op13ElemwiseShapeILi3ELi1EEEbRKN4nnvm9NodeAttrsEPNSt3__16vectorINS2_6TShapeENS6_9allocatorIS8_EEEESC_ + 226
[bt] (5) 5   libmxnet.so                         0x0000000107a11b7e _Z12SetShapeTypePKN4nnvm2OpERKNS_9NodeAttrsERKN5mxnet7ContextERKNSt3__16vectorINS6_7NDArrayENSA_9allocatorISC_EEEERKiPSF_ + 1326
[bt] (6) 6   libmxnet.so                         0x0000000107a156b5 MXImperativeInvoke + 1093
[bt] (7) 7   _ctypes.so                          0x0000000101e59f57 ffi_call_unix64 + 79
[bt] (8) 8   ???                                 0x00007fff5e40bc90 0x0 + 140734774688912

Traceback (most recent call last):
  File ""neuralTrig.py"", line 214, in <module>
    main()
  File ""neuralTrig.py"", line 184, in main
    epoch_end_callback  = mx.rnn.do_rnn_checkpoint(cell, 'trainedModel', 1))
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/module/base_module.py"", line 475, in fit
    self.update()
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/module/bucketing_module.py"", line 401, in update
    self._curr_module.update()
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/module/module.py"", line 570, in update
    kvstore=self._kvstore)
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/model.py"", line 123, in _update_params
    updater(index*num_device+k, g, w)
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/optimizer.py"", line 690, in __call__
    self.optimizer.update(index, weight, grad, self.states[index])
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/optimizer.py"", line 324, in update
    lr=lr, wd=wd, **self.kwargs)
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/_ctypes/ndarray.py"", line 133, in generic_ndarray_function
    c_array(ctypes.c_char_p, [c_str(str(i)) for i in kwargs.values()])))
  File ""/Users/Forough/anaconda2/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/base.py"", line 78, in check_call
    **raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [08:11:32] src/operator/nn/../tensor/../elemwise_op_common.h:31: Check failed: assign(&dattr, (*vec)[i]) Incompatible attr in node  at 2-th input: expected (1,120), got (120,240)**

Stack trace returned 9 entries:
[bt] (0) 0   libmxnet.so                         0x00000001074d5f35 _ZN4dmlc15LogMessageFatalD2Ev + 37
[bt] (1) 1   libmxnet.so                         0x00000001074d3539 _ZN4dmlc15LogMessageFatalD1Ev + 9
[bt] (2) 2   libmxnet.so                         0x000000010754de72 _ZZN5mxnet2op12ElemwiseAttrIN4nnvm6TShapeEXadL_ZNS0_13shape_is_noneERKS3_EEXadL_ZNS0_12shape_assignEPS3_S5_EELb1EEEbRKNS2_9NodeAttrsEPNSt3__16vectorIT_NSA_9allocatorISC_EEEESG_RKSC_ENKUlPNSB_IS3_NSD_IS3_EEEEPKcE_clESL_SN_ + 498
[bt] (3) 3   libmxnet.so                         0x000000010754db26 _ZN5mxnet2op12ElemwiseAttrIN4nnvm6TShapeEXadL_ZNS0_13shape_is_noneERKS3_EEXadL_ZNS0_12shape_assignEPS3_S5_EELb1EEEbRKNS2_9NodeAttrsEPNSt3__16vectorIT_NSA_9allocatorISC_EEEESG_RKSC_ + 198
[bt] (4) 4   libmxnet.so                         0x0000000107bf7e92 _ZN5mxnet2op13ElemwiseShapeILi3ELi1EEEbRKN4nnvm9NodeAttrsEPNSt3__16vectorINS2_6TShapeENS6_9allocatorIS8_EEEESC_ + 226
[bt] (5) 5   libmxnet.so                         0x0000000107a11b7e _Z12SetShapeTypePKN4nnvm2OpERKNS_9NodeAttrsERKN5mxnet7ContextERKNSt3__16vectorINS6_7NDArrayENSA_9allocatorISC_EEEERKiPSF_ + 1326
[bt] (6) 6   libmxnet.so                         0x0000000107a156b5 MXImperativeInvoke + 1093
[bt] (7) 7   _ctypes.so                          0x0000000101e59f57 ffi_call_unix64 + 79
[bt] (8) 8   ???                                 0x00007fff5e40bc90 0x0 + 140734774688912

## Minimum reproducible example
Here is [my code](https://github.com/ForoughA/neuralTrig) on git. 
The main file to run is neuralTrig.py. 

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

Here is [my code](https://github.com/ForoughA/neuralTrig) on git. 
The main file to run is neuralTrig.py. If we set the momentum to something other than zero it fails. If we use another optimzier it also fails.
**NOTE: In order to run the code, the 'allow_extra_params' flag needs to be sat to True in exec_.copy_params_from(arg_params, aux_params, allow_extra_params=True) in function set_params(self, arg_params, aux_params) in file [executor_group.py](https://github.com/dmlc/mxnet/blob/master/python/mxnet/module/executor_group.py) line 332.**
",,"['My issue was resolved by tweaking the _update_params(..) function in [model.py](https://github.com/dmlc/mxnet/blob/master/python/mxnet/model.py) with the function below. \r\n\r\nNOTE: this does not support multiple devices, the way the original MxNet code does. It rather changes the dictionary keys (index passed to updater) to the parameter names, so that if the graph is dynamic, the newly created states in updater are attached to the right names. This is essential since for a dynamic graph list indexing is not preserved from one graph to the next. Therefore, the initial implementation does not support it. However, as noted this is just a temporary hack.\r\n\r\nAfter changing the function, the arg_names and param_names should be passed to _update_params() in function update() in file [module.py](https://github.com/dmlc/mxnet/blob/master/python/mxnet/module/module.py).\r\ni.e.: \r\n```\r\n_update_params(self._exec_group.param_arrays,\r\n                           self._exec_group.grad_arrays,\r\n                           updater=self._updater,\r\n                           num_device=len(self._context),\r\n                           kvstore=self._kvstore,\r\n                           param_names=self._exec_group.param_names,\r\n                           arg_names=self._exec_group.arg_names)\r\n```\r\n\r\nThis is the tweaked version of _update_params(..) in file  [model.py](https://github.com/dmlc/mxnet/blob/master/python/mxnet/model.py)\r\n\r\n```\r\ndef _update_params(param_arrays, grad_arrays, updater, num_device,\r\n                   kvstore=None, param_names=None, arg_names=None):\r\n    """""" Perform update of param_arrays from grad_arrays not on kvstore.""""""\r\n    if param_names==None and arg_names==None:\r\n        for index, pair in enumerate(zip(param_arrays, grad_arrays)):\r\n            arg_list, grad_list = pair\r\n            if grad_list[0] is None:\r\n                continue\r\n            if kvstore:\r\n                # push gradient, priority is negative index\r\n                kvstore.push(index, grad_list, priority=-index)\r\n                # pull back the sum gradients, to the same locations.\r\n                kvstore.pull(index, grad_list, priority=-index)\r\n            for k, p in enumerate(zip(arg_list, grad_list)):\r\n                # faked an index here, to make optimizer create diff\r\n                # state for the same index but on diff devs, TODO(mli)\r\n                # use a better solution latter\r\n                w, g = p\r\n                updater(index*num_device+k, g, w)\r\n    elif param_names!=None and arg_names!=None:\r\n        ctr = -1\r\n        for i, index in enumerate(arg_names):\r\n            if index in param_names:\r\n                ctr += 1\r\n                arg_list  = param_arrays[ctr]\r\n                grad_list = grad_arrays[ctr]\r\n\r\n                if grad_list[0] is None:\r\n                    continue\r\n                if kvstore:\r\n                    # push gradient, priority is negative index\r\n                    kvstore.push(ctr, grad_list, priority=-ctr)\r\n                    # pull back the sum gradients, to the same locations.\r\n                    kvstore.pull(ctr, grad_list, priority=-ctr)\r\n\r\n                for k, p in enumerate(zip(arg_list, grad_list)):\r\n                    w, g = p\r\n                    # This deos not support the diff device implemented in the \r\n                    # if statement above. This is a hack for TreeLSTM application\r\n                    # with different structures per sample\r\n                    updater(index, g, w)\r\n    else:\r\n        raise AssertionError(""Both arg_names (%s) and param_names (%s) should be fed.""\r\n                             %(str(arg_names), str(param_names)))\r\n```', 'Hi, do you figure out how to do mini-batch training with TreeLSTM?', 'Mini batching is not possible using the bucketing module. \r\n\r\nThere is a new interface that is better for tree-lstms [here](https://github.com/dmlc/mxnet/pull/7022/files#diff-67f289376d3b2858314672c2a21dfb38R5) with these [tutorials](https://github.com/dmlc/mxnet/tree/master/docs/tutorials/gluon) and [examples](https://github.com/dmlc/mxnet/tree/master/example/gluon)', ""I read the examples and the tutorials, but I don't think the example [tree_lstm](https://github.com/dmlc/mxnet/blob/master/example/gluon/tree_lstm/main.py#L160) really does mini-batch physically. The example calculates forward() and backward() for every instance, then it just update gradients to weight after a batch_size, but in the core engine, the real calculation with CPU/GPU is not parallelized by mini-batch. Do I understand it right?  "", ""@herokang that's right. Batching on a dynamic graph is not straightforward, and will take some work on the backend."", '@szha so does mxnet have a plan on how to batch dynamic computation graphs? Like TensorFlow Fold.']",[],"['git rev-parse HEAD', 'sessionInfo()']",0,0
487,incubator-mxnet,3353,closed,Why is LOG(INFO)  not working as supposed in mxnet C++ code ?,"I ran example/image-classification/train_mnist.py with batch_size = 10000, so there would be 6 batches for the forword training ( val is set to None)，the Forword function of the first Fully-connect layer should be called 6 times. I added some debug codes as follows:
![p hayw f d 0 t 11 i u3j](https://cloud.githubusercontent.com/assets/21171292/18749082/de8e6ada-8107-11e6-9df1-3f52a0650dcc.png)
![o466yu t _ tq_ yrezt3oy](https://cloud.githubusercontent.com/assets/21171292/18749092/e5510e18-8107-11e6-9b6c-40553ccf2522.png)

But the log printed  is not what I supposed:
![_o smuqtw sdk ou 6 ji](https://cloud.githubusercontent.com/assets/21171292/18749230/6e527bfc-8108-11e6-9e58-a54226372fd3.png)

why is ""logger.info(load123)"" in python executed 6 times as supposed, while  ""LOG(INFO) << ""forward123"" in fully_connected-inl.h just once ? 
@piiswrong 
",,"['add execmanager.update_metric at the end\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
488,incubator-mxnet,5943,closed, Multi GPU training speed LOW,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:ubuntu 16.0.4

Compiler: g++

Package used (Python/R/Scala/Julia): Python

MXNet version: 0.9.3

Or if installed from source: 

MXNet commit hash (): 0.9.3 release

If you are using python package, please provide python 3.5

Python version and distribution: python 3.5

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

~/mx/mxnet-0.9.3/example/image-classification$ python train_mnist.py --network mlp --gpus 0,1
INFO:root:Epoch[0] Batch [100] Speed: 189.20 samples/sec Train-accuracy=0.100402


~/mx/mxnet-0.9.3/example/image-classification$ python train_mnist.py --network mlp --gpus 0
INFO:root:Epoch[0] Batch [300] Speed: 81716.01 samples/sec Train-accuracy=0.928594




## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1. python train_mnist.py --network mlp 
2. python train_mnist.py --network mlp --gpus 0
3. python train_mnist.py --network mlp --gpus 0,1

## What have you tried to solve it?

1.
2.
3.
",,['In BIOS\r\nAdvanced->North Bridge Configuration\r\nIOMMU disable\r\n'],[],"['git rev-parse HEAD', 'sessionInfo()']",0,0
489,incubator-mxnet,2657,closed,how to edit and write mxnet model for json file or to converter from code?,"thanks.
",,"['normally you do not edit json file direction. Instead, use the symbolic API to load and modify the graphs then save back to json file.\n', ""thanks , i find it . \n\ntrain_model.save('mymodel',get_iterator(data_shape)) \n\nthis code ?\n""]",[],[],0,0
490,incubator-mxnet,2539,closed,"""ValueError:NDArray only support continous slicing on axis 0"" what it happened","Hello,everyone.I am a mxnet and python beginer.So when I use MXnet ,I encounter some errors that confuse me so much.

I wanna use MXnet to do the image's  super resolution.So when I set up the DataIter object,I refer to the data.py in fcn-xs example. Because I use gray images,so I modify some codes. and  set the batch_size=1

Some changed codes as follows:
""'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
 def _read_img(self, img_name, label_name):
        img = Image.open(os.path.join(self.root_dir, img_name))
        label = Image.open(os.path.join(self.root_dir, label_name))
        img = np.array(img, dtype=np.float32)  # (h, w, c)
        label = np.array(label)  # (h, w)
        img = img - self.mean
        img = np.expand_dims(img, axis=0)  # (1, c, h, w)
        img = np.expand_dims(img, axis=0)
        label = np.array(label)  # (h, w)
        label = np.expand_dims(label, axis=0)  # (1, h, w)
""''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

""'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
 def next(self):
        """"""return one dict which contains ""data"" and ""label"" """"""
        if self.iter_next():
            self.data, self.label = self._read()
           # return {self.data_name  :  self.data[0][1],
           #         self.label_name :  self.label[0][1]}
           #change the numpy to nd
            mydata=mx.nd.array(self.data[0][1],self.ctx)
            mylabel=mx.nd.array(self.label[0][1],self.ctx)
            return mx.io.DataBatch(data=mydata,label=mylabel)
        else:
            raise StopIteration
""'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

When I create the Dataiter object ,it it right.But when I  execute the following command ,I get errors below:
'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

> > > model=mx.model.FeedForward.create(mynet,X=train_data,num_epoch=10,learning_rate=0.01)
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > >   File ""/opt/mxnet/python/mxnet/model.py"", line 901, in create
> > >     eval_batch_end_callback=eval_batch_end_callback)
> > >   File ""/opt/mxnet/python/mxnet/model.py"", line 784, in fit
> > >     sym_gen=self.sym_gen)
> > >   File ""/opt/mxnet/python/mxnet/model.py"", line 222, in _train_multi_device
> > >     executor_manager.load_data_batch(data_batch)
> > >   File ""/opt/mxnet/python/mxnet/executor_manager.py"", line 394, in load_data_batch
> > >     self.curr_execgrp.load_data_batch(data_batch)
> > >   File ""/opt/mxnet/python/mxnet/executor_manager.py"", line 245, in load_data_batch
> > >     _load_data(data_batch, self.data_arrays)
> > >   File ""/opt/mxnet/python/mxnet/executor_manager.py"", line 87, in _load_data
> > >     _load_general(batch.data, targets)
> > >   File ""/opt/mxnet/python/mxnet/executor_manager.py"", line 78, in _load_general
> > >     for d_src, d_targets in zip(data, targets):
> > >   File ""/opt/mxnet/python/mxnet/ndarray.py"", line 212, in __getitem__
> > >     raise ValueError('NDArray only support continuous slicing on axis 0')
> > > ValueError: NDArray only support continuous slicing on axis 0
> > > ''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

I have no idea about the error.I hope that some expert can give me some advice.Thank you so much
",,"['hello, @lugui2009 could you provide the full code then we can help you? from the error message, it means you are using the NDArray slice on axis like 1,2,3 which do not support, just convert it to numpy array using .asnumpy().\n', ""@tornadomeet   Thank you for your reply.Yesterday,I read the code again.And I am sure I have  mistaken  this code .I have no idea of the concept of slice,and don't know what it is used for.Could you give me an template that how to write an DataIter of MXnet? Thank you again.\n"", 'just read the code of python/mxnet/io.py, then you can know how to write, because we only need the next() function to get the data and label.\n', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
491,incubator-mxnet,1563,closed,A mx.symbol.JoinList is needed?,"I wonder if a  should be added, which joins a list of symbols into a symbol.
This feature is very important if we want to build a complicated end-to-end symbol graph.
",,['mx.symbol.Group seems does the job. \n'],[],['mx.symbol.JoinList'],0,0
492,incubator-mxnet,11535,closed,installed mxnet-cu92 on ubuntu but can't run example code correctly,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.

For Q & A and discussion, please start a discussion thread at https://discuss.mxnet.io 

## Description
I'm on ubuntu16.04 with GPU and pip, and follows instruction in official documentation web page (https://mxnet.incubator.apache.org/install/index.html?platform=Linux&language=Python&processor=GPU). I follow that instructions, which can install mxnet-cu92 but cannot run example code correctly.

## Environment info (Required)




Package used Python2.7.12

## Build info
I first download and intalled cuda-9.2 and cudnn7.1 from nvidia website.
Then I 

## Error Message:
see next section for full info

## Minimum reproducible example
I use the official website's example code in a interpret envirionment. The code and output is:




## Steps to reproduce
install ubuntu16.04
install cuda9.2
install cudnn7.1
use python 2.7.12
Open terminal and type:


## What have you tried to solve it?
Note that I can build official Caffe with my installed cuda9.2 and cudnn7.1 (https://github.com/BVLC/caffe). It only gives some cudnn warnings  but can complete compilation.",,"['Thank you for submitting the issue! @sandeep-krishnamurthy requesting this be labeled as installation.', 'Finally I figured this out. Its my incorrect configuration. I should have installed newer GPU Card driver since I installed newer version of CUDA (9.2). In fact I installed nvidia-396 on my 1080Ti.\r\n', 'Hey, how did you get the nvidia-396 driver?', '@zhuotest you can confirm\r\nBut @rohun-tripathi does this help - https://www.nvidia.com/drivers/beta ?']","[""\r\n➜  test python diag.py \r\n----------Python Info----------\r\n('Version      :', '2.7.12')\r\n('Compiler     :', 'GCC 5.4.0 20160609')\r\n('Build        :', ('default', 'Dec  4 2017 14:50:18'))\r\n('Arch         :', ('64bit', 'ELF'))\r\n------------Pip Info-----------\r\n('Version      :', '10.0.1')\r\n('Directory    :', '/usr/local/lib/python2.7/dist-packages/pip')\r\n----------MXNet Info-----------\r\n('Version      :', '1.2.0')\r\n('Directory    :', '/usr/local/lib/python2.7/dist-packages/mxnet')\r\n('Commit Hash   :', '297c64fd2ee404612aa3ecc880b940fb2538039c')\r\n----------System Info----------\r\n('Platform     :', 'Linux-4.4.0-127-generic-x86_64-with-Ubuntu-16.04-xenial')\r\n('system       :', 'Linux')\r\n('node         :', '1080')\r\n('release      :', '4.4.0-127-generic')\r\n('version      :', '#153-Ubuntu SMP Sat May 19 10:58:46 UTC 2018')\r\n----------Hardware Info----------\r\n('machine      :', 'x86_64')\r\n('processor    :', 'x86_64')\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                8\r\nOn-line CPU(s) list:   0-7\r\nThread(s) per core:    2\r\nCore(s) per socket:    4\r\nSocket(s):             1\r\nNUMA node(s):          1\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 60\r\nModel name:            Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz\r\nStepping:              3\r\nCPU MHz:               3799.828\r\nCPU max MHz:           4000.0000\r\nCPU min MHz:           800.0000\r\nBogoMIPS:              7183.49\r\nVirtualization:        VT-x\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              8192K\r\nNUMA node0 CPU(s):     0-7\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt ibpb ibrs stibp dtherm ida arat pln pts\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0637 sec, LOAD: 2.6516 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.5115 sec, LOAD: 9.2181 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.2099 sec, LOAD: 1.9156 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.5327 sec, LOAD: 2.1375 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.8268 sec, LOAD: 3.7883 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.5108 sec, LOAD: 6.5522 sec.\r\n"", '\r\nchris@1080:~$ python\r\nPython 2.7.12 (default, Dec  4 2017, 14:50:18) \r\n[GCC 5.4.0 20160609] on linux2\r\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\r\n>>> import mxnet as mx\r\n>>> a = mx.nd.ones((2, 3), mx.gpu())\r\nTraceback (most recent call last):\r\n  File ""<stdin>"", line 1, in <module>\r\n  File ""/usr/local/lib/python2.7/dist-packages/mxnet/ndarray/ndarray.py"", line 2271, in ones\r\n    return _internal._ones(shape=shape, ctx=ctx, dtype=dtype, **kwargs)\r\n  File ""<string>"", line 34, in _ones\r\n  File ""/usr/local/lib/python2.7/dist-packages/mxnet/_ctypes/ndarray.py"", line 92, in _imperative_invoke\r\n    ctypes.byref(out_stypes)))\r\n  File ""/usr/local/lib/python2.7/dist-packages/mxnet/base.py"", line 149, in check_call\r\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\r\nmxnet.base.MXNetError: [08:07:26] src/engine/threaded_engine.cc:318: Check failed: device_count_ > 0 (-1 vs. 0) GPU usage requires at least 1 GPU\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x308362) [0x7fc4411d8362]\r\n[bt] (1) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x308938) [0x7fc4411d8938]\r\n[bt] (2) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x29433a3) [0x7fc4438133a3]\r\n[bt] (3) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x294445f) [0x7fc44381445f]\r\n[bt] (4) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x29bf09f) [0x7fc44388f09f]\r\n[bt] (5) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x29c3693) [0x7fc443893693]\r\n[bt] (6) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x29c45e3) [0x7fc4438945e3]\r\n[bt] (7) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(+0x28fc3cb) [0x7fc4437cc3cb]\r\n[bt] (8) /usr/local/lib/python2.7/dist-packages/mxnet/libmxnet.so(MXImperativeInvokeEx+0x6f) [0x7fc4437cc98f]\r\n[bt] (9) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fc47d496e40]\r\n\r\n', '\r\npython\r\nimport mxnet as mx\r\na = mx.nd.ones((2, 3), mx.gpu())\r\n']",['sudo pip install mxnet-cu92'],0,0
493,incubator-mxnet,5250,closed,`mx.metric.Perplexity(-1) ` update_metric raise segement fault,"For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:
ubuntu15.10
Compiler:
gcc-9.4.x
Package used (Python/R/Scala/Julia):
Python
MXNet version:
0.9.4
Or if installed from source:
yeap
MXNet commit hash ():
be38c5b84030a63d0ab51f19737f99a75a7feb23

If you are using python package, please provide
anaconda4.2
Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.


Also, I custom my dataprovider, here , , , my word are padding to 37, so I dont use BucketingModule.

## Steps to reproduce

For above code, when it run into  and run at the line where , it will raise segfault, when I comment it and it works well. My dataIter works well and I test it some times. So I think the error must be related to update_metric... However, the example--lstm_bucketing.py runs well..I dont what I should do .

",,[],"['\r\nSegmentation fault (core dumped)\r\n\r\n[Done] exited with code=139 in 39.916 seconds\r\n', ""python\r\ndef caption_module(num_lstm_layer, seq_len, vocab_size, num_hidden, num_embed, batch_size, dropout=0.):\r\n\r\n    seq = mx.sym.Variable('word_data')\r\n    label = mx.sym.Variable('softmax_label')\r\n    image_feature = mx.sym.Variable('image_feature')\r\n    image_embed = mx.sym.FullyConnected(data=image_feature, num_hidden=num_embed, name='img_embed')\r\n    word_embed = mx.sym.Embedding(data=seq, input_dim=vocab_size, output_dim=num_embed, name='seq_embed')\r\n\r\n    # Concat image_embed with word_embed in axis=1 (batch_size, length+1, num_hidden)\r\n    image_embed_reshape = mx.sym.expand_dims(image_embed, axis=1, name='image_embed_expand_dims')\r\n    embedd_feature = mx.sym.Concat(image_embed_reshape, word_embed, num_args=2, dim=1, name='embed_concat')\r\n\r\n    stack = mx.rnn.SequentialRNNCell()\r\n    for i in range(num_lstm_layer):\r\n        stack.add(mx.rnn.LSTMCell(num_hidden=num_hidden, prefix='lstm_l%d_' % i))\r\n    outputs, states = stack.unroll(length=seq_len+1, inputs=embedd_feature, merge_outputs=True)\r\n\r\n    outputs_crop = mx.sym.crop(outputs, begin=(0, 1, 0), end=(batch_size, seq_len+1, num_embed))\r\n    pred = mx.sym.Reshape(outputs_crop, shape=(-1, num_hidden))\r\n    pred = mx.sym.FullyConnected(pred, num_hidden=vocab_size, name='pred_fc')\r\n    label = mx.sym.Reshape(label, shape=(-1,))\r\n    softmax_output = mx.sym.SoftmaxOutput(data=pred, label=label, name='softmax')\r\n    return softmax_output\r\n"", 'python\r\nlstm = caption_module(num_lstm_layer=num_lstm_layer, seq_len=train_data.sent_length,\r\n                          vocab_size=train_data.vocab_size, num_hidden=num_hidden, num_embed=num_embed, batch_size=batch_size)\r\n\r\n    caption = mx.mod.Module(symbol=lstm, data_names=[\'image_feature\', \'word_data\'], label_names=(\'softmax_label\',), context=ctx)\r\n\r\n    caption.fit(\r\n        train_data=train_wrap,\r\n        eval_data=val_wrap,\r\n        eval_metric=mx.metric.Perplexity(-1),\r\n        kvstore=\'device\',\r\n        optimizer=\'sgd\',\r\n        optimizer_params={\'learning_rate\': 0.01,\r\n                          \'momentum\': 0.9,\r\n                          \'wd\': 0.00001},\r\n        initializer=mx.init.Xavier(factor_type=""in"", magnitude=2.34),\r\n        num_epoch=20,\r\n        batch_end_callback=mx.callback.Speedometer(batch_size, 1))\r\n']","['git rev-parse HEAD', 'sessionInfo()', 'image_feature=(batch_size, 4096)', 'word_length=(batch_size, 37)', 'len(vocab)=8976', 'fit', 'update_metric(metric)']",0,0
494,incubator-mxnet,8510,closed,Minor differences in distributed training with GPU/without GPU.,"Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues.

If the issue is non-technical, feel free to present the information in what you believe is the best form.

## Description
mnist accuracy differ slightly when training with local gpu and distributed training with GPU but accuracy is the same when training with CPU.

## Environment info (Required)
CentOS 7
MxNet latest master 

python diagnose.py

Package used (Python/R/Scala/Julia):
(I'm using ...) Python!

For Scala user, please provide:
1. Java version: ()
2. Maven version: ()
3. Scala runtime if applicable: ()

For R user, please provide R :

## Build info (Required if built from source)
train_mnist.py with data shuffle turned off so accuracy of each run is the same.

Compiler (gcc/clang/mingw/visual studio):
gcc 4.9

MXNet commit hash:
(Paste the output of  here.)
8592e1cd3b9f79cff740f29e599ba7788a454c54

Build config:
(Paste the content of config.mk, or the build command.)

USE_DISTRIBUTED_KVSTORE=1
USE_CUDNN=1
USE_CUDA=/usr/local/cuda

## Error Message:
1 server 1 client training with train_mnist.py WITHOUT GPU
INFO:root:Epoch[0] Batch [100]  Speed: 3606.78 samples/sec      accuracy=0.807859
INFO:root:Epoch[0] Batch [200]  Speed: 3747.11 samples/sec      accuracy=0.895469
INFO:root:Epoch[0] Batch [300]  Speed: 3982.58 samples/sec      accuracy=0.912656
INFO:root:Epoch[0] Batch [400]  Speed: 3960.68 samples/sec      accuracy=0.928594
INFO:root:Epoch[0] Batch [500]  Speed: 5376.55 samples/sec      accuracy=0.933906
INFO:root:Epoch[0] Batch [600]  Speed: 4133.33 samples/sec      accuracy=0.943906
INFO:root:Epoch[0] Batch [700]  Speed: 5935.95 samples/sec      accuracy=0.944688
INFO:root:Epoch[0] Batch [800]  Speed: 3966.74 samples/sec      accuracy=0.940312
INFO:root:Epoch[0] Batch [900]  Speed: 3803.05 samples/sec      accuracy=0.953906
INFO:root:Epoch[0] Train-accuracy=0.966639
INFO:root:Epoch[0] Time cost=14.467
INFO:root:Epoch[0] Validation-accuracy=0.943670

1 server 1 client training with train_mnist.py WITH GPU
INFO:root:Epoch[0] Batch [100]  Speed: 13700.01 samples/sec     accuracy=0.807859
INFO:root:Epoch[0] Batch [200]  Speed: 27909.23 samples/sec     accuracy=0.895469
INFO:root:Epoch[0] Batch [300]  Speed: 23719.16 samples/sec     accuracy=0.910781
INFO:root:Epoch[0] Batch [400]  Speed: 30796.60 samples/sec     accuracy=0.925312
INFO:root:Epoch[0] Batch [500]  Speed: 26746.35 samples/sec     accuracy=0.933906
INFO:root:Epoch[0] Batch [600]  Speed: 29120.16 samples/sec     accuracy=0.943906
INFO:root:Epoch[0] Batch [700]  Speed: 30805.82 samples/sec     accuracy=0.944531
INFO:root:Epoch[0] Batch [800]  Speed: 22852.49 samples/sec     accuracy=0.937813
INFO:root:Epoch[0] Batch [900]  Speed: 28238.62 samples/sec     accuracy=0.952031
INFO:root:Epoch[0] Train-accuracy=0.969172
INFO:root:Epoch[0] Time cost=2.452
INFO:root:Epoch[0] Validation-accuracy=0.936505

## Minimum reproducible example
(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)

(pgrep python | xargs kill -9 && rm ~/train/profile.json) &>/dev/null
(pgrep memcheck-amd64- | xargs kill -9) &> /dev/null
export DMLC_PS_ROOT_PORT=9091;
export DMLC_NUM_WORKER=1;
export DMLC_NUM_SERVER=1;
export DMLC_PS_ROOT_URI=127.0.0.1;
export DMLC_ROLE=scheduler;
python train_mnist.py &

export DMLC_ROLE=server; 
export DMLC_SERVER_ID=0
python train_mnist.py --kv-store dist_sync --gpus 0 &

export DMLC_ROLE=worker; 
export DMLC_WORKER_ID=0
python train_mnist.py --kv-store dist_sync --num-epochs 1 --gpus 0&

## Steps to reproduce
(Paste the commands you ran that produced the error.)

1. Run the example and toggle --gpus 0
2. Observe accuracy differences.

## What have you tried to solve it?

1. The problem seems to be the initialization of params in GPU.
2. The first divergence of these two training is the first gradient sent out after the first batch.
",Bug CUDA,"['@apache/mxnet-committers: This issue has been inactive for the past 90 days. It has no label and needs triage.\n\nFor general ""how-to"" questions, our [user forum](https://discuss.mxnet.io/) (and [Chinese version](https://discuss.gluon.ai/)) is a good place to get help.', 'have you tried to fix the seed for initialization?', ""@Luo-Liang Have you tried fixed seed for initialization as per @ThomasDelteil's suggestion? Requesting to close this issue, if the issue is resolved."", ""Yes. This is no longer a problem. I have confirmed it's due to initialization.""]",[],"['', '\r\nWhat to do:\r\n1. Download the diagnosis script from https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/diagnose.py\r\n2. Run the script using ', ' and paste its output here.\r\n', '', 'java -version', 'mvn -version', 'scala -version', 'sessionInfo()', 'git rev-parse HEAD']",0,0
495,incubator-mxnet,9745,closed,MultiIter example should also return pad in next(self),"Error caused by eval_data.pad not found:
https://github.com/apache/incubator-mxnet/blob/8205e24d99b95cc2971006f3453a7e7addac7ffe/python/mxnet/module/base_module.py#L295

These templates need to change:
https://mxnet.incubator.apache.org/api/python/io.html#develop-a-new-iterator

I am not quite sure if this example is simple'', but it also needs to include pad in return:
https://mxnet.incubator.apache.org/tutorials/basic/data.html#custom-iterator

Thanks,
Yifei",Call for Contribution Doc Python,"['@sandeep-krishnamurthy\xa0Can you please add labels:\r\n- Python\r\n- Call for contribution\r\n- Example\r\n\r\n@yifeim Can you please create a PR for this with relevant changes so that members can review it.\r\n\r\nThanks!', ""Hi Karan,\r\n\r\nThanks for attending to this issue. Unfortunately, I ended up using NDArrayIter instead of creating my own. Since I did not find a good use case for a custom DataIter, and additionally, anyone who is really interested in DataIter should write one in C++, e.g., LibSVMIter. I guess I should be working at lower levels if I were to create a PR.\r\n\r\nIn short, fixing the doc does not solve a more fundamental issue which is whoever decides to write Custom DataIter must have a good reason and reasonable understanding of the codes under the hood. Don't you think so?\r\n\r\nThanks,\r\nYifei"", '@yizhi can we close this out? doc example has been fixed/made more explicit on how to write a custom DataIter here: https://mxnet.incubator.apache.org/tutorials/basic/data.html#custom-iterator']",[],[''],0,0
496,incubator-mxnet,66,closed,ThreadEngine is buggy with CuDNN,"NaiveEngine works well
",,[],[],[],0,0
497,incubator-mxnet,11108,closed,Seems the gperftools-devel and jemalloc-devel wouldn't be detected correctly on rhel(Redhat Enterprise Linux),"https://github.com/apache/incubator-mxnet/blob/2dbd143e4892bb9ad4aa1835c79f0046603e3531/Makefile#L221

Refer to the mxnet Makefile above, the search paths for gperftools-devel and jemalloc-devel are under //.
But gperftools-devel and jemalloc-devel package installed via yum will place the dynamic library files into ****

TL,DR;
As the title said.",Bug Build,"['@sandeep-krishnamurthy please label - ""Build"", ', '@myme5261314 Is this issue still seen on your setup?', ""Seems my pull request had solved it when I proposed this issue.\nDon't have time to verify now.\n\n发自我的 iPhone\n\n> 在 2018年9月27日，02:46，Vandana Kannan <notifications@github.com> 写道：\n> \n> @myme5261314 Is this issue still seen on your setup?\n> \n> —\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n"", 'Closing as the issue is resolved. Please reopen if issue still persists']",[],"['/lib', '/usr/lib', '/usr/local/lib', '/usr/lib64']",0,0
498,incubator-mxnet,1253,closed,Running Adam optimizer error,"Hi,

When I change the optimizer to Adam. For example,



I get the following error message:



Isn't this the correct way of setting the optimizer?
",,"['Seems the `__init__` function of the Adam optimizer has no `arg_names` keyword.\n\nDoes the following revision help? In https://github.com/dmlc/mxnet/blob/master/python/mxnet/optimizer.py#L348, add `arg_names = None` after `lr_schedule = None` and change https://github.com/dmlc/mxnet/blob/master/python/mxnet/optimizer.py#L349 to `super(Adam, self).__init__(rescale_grad, arg_names)`\n', 'Now I get the following error instead:\n\n``` python\n  File ""<ipython-input-3-9b6e62614107>"", line 2, in <module>\n    X                  = data_train)\n  File ""/home/rick/anaconda/lib/python2.7/site-packages/mxnet-0.5.0-py2.7.egg/mxnet/model.py"", line 641, in fit\n    **(self.kwargs))\n  File ""/home/rick/anaconda/lib/python2.7/site-packages/mxnet-0.5.0-py2.7.egg/mxnet/optimizer.py"", line 52, in create_optimizer\n    **kwargs)\n  File ""/home/rick/anaconda/lib/python2.7/site-packages/mxnet-0.5.0-py2.7.egg/mxnet/optimizer.py"", line 342, in __init__\n    super(Adam, self).__init__(rescale_grad, arg_names)\nTypeError: __init__() takes at most 2 arguments (3 given)\n```\n', '@rfarouni In my computer this revision solves the problem. Is it possible that you need to re-install the python package? Or update the rest part of MXNet to the latest version?\n\n```\n   lr_scheduler=None, arg_names=None):\nsuper(Adam, self).__init__(rescale_grad, arg_names)\n```\n', 'This is definitely an issue that should be fixed.\n\nBut you don\'t have to hotfix the mxnet code to use the Adam optimizer.\nIt\'s also possible to provide an optimizer object instead of a string:\n\n``` python\nmodel = mx.model.FeedForward(\n        ctx           = [mx.gpu(0)],\n        num_epoch     = 60,\n        symbol        = network,\n        optimizer     = mx.optimizer.Adam(),\n        initializer   = mx.init.Xavier(factor_type=""in"", magnitude=2.34))\n\nmodel.fit(X=data_train)\n```\n', ""After fixing the code and re-installing the python package, it worked. I think  I tried providing an  optimizer object but that didn't work.\n"", ""@rfarouni I think it's worthwhile to make a pr for this issue. Would you like to pr?\n"", 'I opened a pull request. Thanks\n']","[' python\nmodel = mx.model.FeedForward(\n        ctx                = [mx.gpu(0)],\n        num_epoch     = 60,\n        symbol            = network,\n        optimizer        =  \'adam\',\n        initializer        = mx.init.Xavier(factor_type=""in"", magnitude=2.34))\n\nmodel.fit(X= data_train)   \n', ' python\n  File ""<ipython-input-6-3732cc3a7cd0>"", line 2, in <module>\n    X                  = data_train)\n  File ""/home/rick/anaconda/lib/python2.7/site-packages/mxnet-0.5.0-py2.7.egg/mxnet/model.py"", line 641, in fit\n    **(self.kwargs))\n  File ""/home/rick/anaconda/lib/python2.7/site-packages/mxnet-0.5.0-py2.7.egg/mxnet/optimizer.py"", line 52, in create_optimizer\n    **kwargs)\nTypeError: __init__() got an unexpected keyword argument \'arg_names\'\n']",[],0,0
499,incubator-mxnet,4301,closed,"When I use the 'mx.symbol.Convolution' with 3d kernel,  I get the problem""Volume convolution is not implmented in mshadow"" .",Does mxnet still not support 3D convolution？？,,"['3d convolution only support in MXNet when use cudnn, not support onnormal  cpu and cuda.', 'I see, thx', '@tornadomeet Is there detail documentary for 3d convolution on MXNET? I have great interesting on 3D CNN. THX', '@tornadomeet @JaggerYoung I got the same error. Is there some example for using 3d convolution with cudnn? Thanks.', '@rongrongxiangxin You can read the document of mxnet about mx.symbol.Convolution.', '@JaggerYoung please using cudnn because 3d conv only support with cudnn in MXNet.  \r\n  i am not sure whether there is 3d convolution examples.', 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],[],0,0
500,incubator-mxnet,16495,closed,docs for gluon.data.* are missing,"Probably related to git filters when adding the files.
https://stackoverflow.com/questions/8006393/force-add-despite-the-gitignore-file



",Doc,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended label(s): Gluon, Doc']",[],[],0,0
501,incubator-mxnet,5233,closed,How to create a custom GPU operation with custom CUDA kernels for computation,"Although mxnet documentation did mention that it is possible to Use C++/mshadow and CUDA to create custom operations, it has no real examples of how to used a custom CUDA kernel (taking gpu pointers) as part of a custom operation. Can anyone provide a simple example of this flow?",,"['You can refer to roi_pooling operator inside mxnet, [roi_pooling-inl.h](https://github.com/dmlc/mxnet/blob/master/src/operator/roi_pooling-inl.h), [roi_pooling.cc](https://github.com/dmlc/mxnet/blob/master/src/operator/roi_pooling.cc) and [roi_pooling.cu](https://github.com/dmlc/mxnet/blob/master/src/operator/roi_pooling.cu).', 'what about this one: https://github.com/dmlc/mxnet/blob/master/example/numpy-ops/ndarray_softmax.py\r\n', 'Thanks']",[],[],0,0
502,incubator-mxnet,12526,closed,#12285 Breaks NDArrayIter For 3D Arrays,"## Description
Our mnist smokescreen tests are breaking in the latest build (mxnet-1.3.0b20180911) as a result of this PR (#12285) with an index out of range error.

## Environment info (Required)

Breaks on both Linux and OSX. Build mxnet-1.3.0b20180909 is fine, 1.3.0b20180911 is faulty.",Bug NDArray,"['Can you provide more details? For example, length of the NDArray, batch size?', 'Interested to understand the issue with an example. If this is a critical issue and takes time to fix, we can revert that commit till we root cause the issue.', '@sandeep-krishnamurthy  @zhreshold \r\n\r\nHere\'s a specific example from the Nightly Binary test which just failed:\r\n\r\n```\r\n[StraightDope: Python2 Single-GPU]\r\n[StraightDope: Python2 Single-GPU]\r\n[StraightDope: Python2 Single-GPU] IndexErrorTraceback (most recent call last)\r\n[StraightDope: Python2 Single-GPU] <ipython-input-8-d40071ee971d> in <module>()\r\n[StraightDope: Python2 Single-GPU]      20     train_data.reset()\r\n[StraightDope: Python2 Single-GPU]      21     iter = 0\r\n[StraightDope: Python2 Single-GPU] ---> 22     for batch in train_data:\r\n[StraightDope: Python2 Single-GPU]      23         ############################\r\n[StraightDope: Python2 Single-GPU]      24         # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\r\n[StraightDope: Python2 Single-GPU]\r\n[StraightDope: Python2 Single-GPU] /work/mxnet/python/mxnet/io/io.pyc in next(self)\r\n[StraightDope: Python2 Single-GPU]     678             raise StopIteration\r\n[StraightDope: Python2 Single-GPU]     679         data = self.getdata()\r\n[StraightDope: Python2 Single-GPU] --> 680         label = self.getlabel()\r\n[StraightDope: Python2 Single-GPU]     681         # iter should stop when last batch is not complete\r\n[StraightDope: Python2 Single-GPU]     682         if data[0].shape[0] != self.batch_size:\r\n[StraightDope: Python2 Single-GPU]\r\n[StraightDope: Python2 Single-GPU] /work/mxnet/python/mxnet/io/io.pyc in getlabel(self)\r\n[StraightDope: Python2 Single-GPU]     748     def getlabel(self):\r\n[StraightDope: Python2 Single-GPU]     749         """"""Get label.""""""\r\n[StraightDope: Python2 Single-GPU] --> 750         return self._batchify(self.label)\r\n[StraightDope: Python2 Single-GPU]     751\r\n[StraightDope: Python2 Single-GPU]     752     def getpad(self):\r\n[StraightDope: Python2 Single-GPU]\r\n[StraightDope: Python2 Single-GPU] /work/mxnet/python/mxnet/io/io.pyc in _batchify(self, data_source)\r\n[StraightDope: Python2 Single-GPU]     730             self.cursor + self.batch_size > self.num_data:\r\n[StraightDope: Python2 Single-GPU]     731             pad = self.batch_size - self.num_data + self.cursor\r\n[StraightDope: Python2 Single-GPU] --> 732             first_data = self._getdata(data_source, start=self.cursor)\r\n[StraightDope: Python2 Single-GPU]     733             second_data = self._getdata(data_source, end=pad)\r\n[StraightDope: Python2 Single-GPU]     734             return self._concat(first_data, second_data)\r\n[StraightDope: Python2 Single-GPU]\r\n[StraightDope: Python2 Single-GPU] /work/mxnet/python/mxnet/io/io.pyc in _getdata(self, data_source, start, end)\r\n[StraightDope: Python2 Single-GPU]     692         assert start is not None or end is not None, \'should at least specify start or end\'\r\n[StraightDope: Python2 Single-GPU]     693         start = start if start is not None else 0\r\n[StraightDope: Python2 Single-GPU] --> 694         end = end if end is not None else data_source[0][1].shape[0]\r\n[StraightDope: Python2 Single-GPU]     695         s = slice(start, end)\r\n[StraightDope: Python2 Single-GPU]     696         return [\r\n[StraightDope: Python2 Single-GPU]\r\n[StraightDope: Python2 Single-GPU] IndexError: list index out of range\r\n[StraightDope: Python2 Single-GPU] IndexError: list index out of range\r\n```\r\nhttp://jenkins.mxnet-ci.amazon-ml.com/job/NightlyTests_onBinaries/148/console\r\n\r\nThe two notebooks are from The Straight Dope book that both repro the out of bounds error:\r\nchapter14_generative-adversarial-networks/dcgan and\r\nchapter14_generative-adversarial-networks/pixel2pixel available at\r\nhttps://github.com/zackchase/mxnet-the-straight-dope\r\n\r\nVishaal', 'Thanks Vishaal. \r\n\r\nOn a side note, how did we miss nightly master build failure. We need to revisit it once.', 'Thanks @vishaalkapoor.\r\nwork on it', 'Thanks for submitting the issue @iamthebot \r\n@mxnet-label-bot[NDArray, Bug]', ""@stu1130 Do we still need a repro? Sorry, I haven't gotten around to it."", ""@iamthebot I am able to find the root cause, so don't worry about it. Thanks"", '@iamthebot \r\nCould you give me the repro of what the data shape is and how you used and initialized the NDArrayIter?\r\nWe would like to make sure all the existing use cases work!\r\nThank you so much!', 'The patch is merged, @sandeep-krishnamurthy please close it']",[],[],0,0
503,incubator-mxnet,5243,closed,error C1083: Cannot open include file: 'cub/device/device_radix_sort.cuh': No such file or directory,"Hello,

I am trying to compile the newest MxNet in Windows, by using Visual Studio. I am constantly getting that error and can't fix it. The cub directory is included in the MxNet source and the CMake seems to have it added in the Additional Include Directories line in the project properties, under C/C++. The line which creates problem is in the sort_op-inl.cuh file:

    /*!
     *  Copyright (c) 2017 by Contributors
     * \file sort_op-inl.cuh
     * \brief CUDA implementations for sort_op.h
     */
     #ifndef MXNET_OPERATOR_TENSOR_SORT_OP_INL_CUH_
     #define MXNET_OPERATOR_TENSOR_SORT_OP_INL_CUH_
     #include <thrust/device_ptr.h>
     #include <thrust/sort.h>
     #include <cub/device/device_radix_sort.cuh>
     #if CUDA_VERSION >= 7000
     #include <thrust/system/cuda/execution_policy.h>
     #endif


The line   generates the error. I double checked both the cub folder and the device_radix_sort.cuh file; both do exist and under the appropriate location pointed by the entry in Additional Include Directories.

What else may cause that error? The file being included has the .cuh extension, which belongs to a CUDA kernel for example, can this cause a problem with the Visual Studio while trying to include?

Thanks in advance",,['I have installed CUDA 8.0 and the problem seems to be solved. (Old version was 7.5)'],[],['#include <cub/device/device_radix_sort.cuh>'],0,0
504,incubator-mxnet,9131,closed,random_uniform causes VM to crash,"The code  crashes with 


caused by



Experienced with mxnet 1.0.0 on macOS Sierra and python 3.6.3",,"[""In this case, low=3, high=1, raising an error is consistent with NumPy's random.uniform definition.\r\n\r\n[When high == low, values of low will be returned. If high < low, the results are officially undefined and may eventually raise an error, i.e. do not rely on this function to behave when passed arguments satisfying that inequality condition.](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.uniform.html#numpy-random-uniform)"", 'I think that crashing the VM because of wrong parameters should not be the right behavior. The expected one should be a python exception.', 'Agree that crashing the vm is not a desired behavior. Need to add exception handling in frontend.', '@anirudh2290 is working on general exception handling. ', '#9154 ', '#7335 ']","[' nd.random_uniform(3)', '\r\n[19:51:29] /Users/travis/build/dmlc/mxnet-distro/mxnet-build/dmlc-core/include/dmlc/logging.h:308: [19:51:29] src/operator/random/./sample_op.h:294: Check failed: param.high >= param.low (1 vs. 3) low must be less or equal to high in uniform distribution\r\n', '\r\nlibc++abi.dylib: terminating with uncaught exception of type dmlc::Error: [19:51:29] src/engine/./threaded_engine.h:359: [19:51:29] src/operator/random/./sample_op.h:294: Check failed: param.high >= param.low (1 vs. 3) low must be less or equal to high in uniform distribution\r\n']",[],0,0
505,incubator-mxnet,2883,closed,How to generate the mean file of a dataset used in the iterator.,"I notice that some experiments should use the mean_img file and set the path of the mean_img in the iterator.But I can't find a tool in the mxnet that generate the mean file.
Can someone tell me how to do it ?
",,"['If you are using `io.ImageRecordIter`, mean img will be automatically created if it is missing, as indicated  by the source code [here](https://github.com/dmlc/mxnet/blob/master/src/io/iter_normalize.h#L216)\n']",[],[],0,0
506,incubator-mxnet,14280,closed,Compiling from source code error,"## Description
Compiling from source code occurred ***link libzmq*** error.
## Environment info (Required)


Package used (Python/R/Scala/Julia):
I'm using Python.

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): gcc

MXNet commit hash:
7c617ccc7a8655f3b93acdfac8aeee20eee2a778

Build config:
In CMakeLists.txt, I set:

and build files with 

## Error Message:
std::_Sp_counted_deleter<char*, ps::ZMQVan::RecvMsg(ps::Message*)::{lambda(char*)#1}, std::allocator<void>, (__gnu_cxx::_Lock_policy)2>::_M_dispose()':
van.cc:(.text._ZNSt19_Sp_counted_deleterIPcZN2ps6ZMQVan7RecvMsgEPNS1_7MessageEEUlS0_E_SaIvELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv[_ZNSt19_Sp_counted_deleterIPcZN2ps6ZMQVan7RecvMsgEPNS1_7MessageEEUlS0_E_SaIvELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv]+0x9): undefined reference to ps::ZMQVan::Stop()':
van.cc:(.text._ZN2ps6ZMQVan4StopEv[_ZN2ps6ZMQVan4StopEv]+0xe5): undefined reference to zmq_close'
van.cc:(.text._ZN2ps6ZMQVan4StopEv[_ZN2ps6ZMQVan4StopEv]+0x2c2): undefined reference to zmq_close'
van.cc:(.text._ZN2ps6ZMQVan4StopEv[_ZN2ps6ZMQVan4StopEv]+0x55d): undefined reference to ps::ZMQVan::Bind(ps::Node const&, int)':
van.cc:(.text._ZN2ps6ZMQVan4BindERKNS_4NodeEi[_ZN2ps6ZMQVan4BindERKNS_4NodeEi]+0x3a): undefined reference to zmq_bind'
van.cc:(.text._ZN2ps6ZMQVan4BindERKNS_4NodeEi[_ZN2ps6ZMQVan4BindERKNS_4NodeEi]+0x3e7): undefined reference to ps::ZMQVan::Connect(ps::Node const&)':
van.cc:(.text._ZN2ps6ZMQVan7ConnectERKNS_4NodeE[_ZN2ps6ZMQVan7ConnectERKNS_4NodeE]+0x20d): undefined reference to zmq_setsockopt'
van.cc:(.text._ZN2ps6ZMQVan7ConnectERKNS_4NodeE[_ZN2ps6ZMQVan7ConnectERKNS_4NodeE]+0x423): undefined reference to zmq_strerror'
van.cc:(.text._ZN2ps6ZMQVan7ConnectERKNS_4NodeE[_ZN2ps6ZMQVan7ConnectERKNS_4NodeE]+0x5c5): undefined reference to zmq_strerror'
3rdparty/ps-lite/libpslite.a(van.cc.o): In function zmq_ctx_new'
van.cc:(.text._ZN2ps6ZMQVan5StartEi[_ZN2ps6ZMQVan5StartEi]+0x11d): undefined reference to zmq_ctx_new'
van.cc:(.text._ZN2ps6ZMQVan5StartEi[_ZN2ps6ZMQVan5StartEi]+0x15e): undefined reference to zmq_ctx_set'
3rdparty/ps-lite/libpslite.a(van.cc.o): In function zmq_msg_init_data'
van.cc:(.text._ZN2ps6ZMQVan7SendMsgERKNS_7MessageE[_ZN2ps6ZMQVan7SendMsgERKNS_7MessageE]+0x267): undefined reference to zmq_msg_init_data'
van.cc:(.text._ZN2ps6ZMQVan7SendMsgERKNS_7MessageE[_ZN2ps6ZMQVan7SendMsgERKNS_7MessageE]+0x348): undefined reference to zmq_strerror'
3rdparty/ps-lite/libpslite.a(van.cc.o): In function zmq_msg_init'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0xf6): undefined reference to zmq_msg_data'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x116): undefined reference to zmq_msg_size'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x217): undefined reference to zmq_strerror'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x300): undefined reference to zmq_msg_more'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x3d0): undefined reference to zmq_msg_close'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x3ff): undefined reference to zmq_msg_data'
van.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x56a): undefined reference to 

## Steps to reproduce

1. mkdir cmake_build && cd cmake_build
2. cmake -DBLAS=open -DUSE_OPENCV=1 -GNinja ..
3. ninja -v

## What have you tried to solve it?

1. Use Makefile to install mxnet, but failed with the above error, either.

## Alternative information
1. opencv version: 4.0.1
",Build,"['Hey, this is the MXNet Label Bot. \n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it. \n Here are my recommended labels: Build', '@mxnet-label-bot add [Build]', ""Can anyone help me fix this problem please? I'm really in a hurry."", 'Do you install zmq?\r\n\r\nAnd I recommend to use make to build MXNet.\r\n\r\nBuild Setup:\r\nhttp://mxnet.incubator.apache.org/versions/master/install/ubuntu_setup.html', ""@wkcn I do install zmq and I've tried to use make to build MXNet, but still meet the same link problem."", 'How did you install zmq? build from source or apt-get install?\r\nIt seems that the version of zmq installed does not match with the c++ compiler.', 'My c++ compiler version is:\r\n```\r\ngcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.11)\r\n```\r\nand libzmq is installed by apt-get install, its version is:\r\n```\r\nlibzmq3-dev/xenial,now 4.1.4-7 amd64 [installed]\r\nlibzmq5/xenial,now 4.1.4-7 amd64 [installed,automatic]\r\n```\r\nDoes it make any difference?', 'Could you try to uninstall zmq, then build zmq from source?', ""Sure. I'll try as soon as possible. Thanks a lot."", ""I have built successfully according to the above reply:\r\n\r\n> Do you install zmq?\r\n> \r\n> And I recommend to use make to build MXNet.\r\n> \r\n> Build Setup:\r\n> http://mxnet.incubator.apache.org/versions/master/install/ubuntu_setup.html\r\n\r\nBut failed by following this page: https://mxnet.incubator.apache.org/versions/master/install/build_from_source.html#build-mxnet-with-c++\r\n\r\nAnyway, @wkcn thanks a lot for helping me fix this. I'll close this issue.""]","[""\r\n----------Python Info----------\r\n('Version      :', '2.7.12')\r\n('Compiler     :', 'GCC 5.4.0 20160609')\r\n('Build        :', ('default', 'Nov 12 2018 14:36:49'))\r\n('Arch         :', ('64bit', 'ELF'))\r\n------------Pip Info-----------\r\n('Version      :', '8.1.1')\r\n('Directory    :', '/usr/lib/python2.7/dist-packages/pip')\r\n----------MXNet Info-----------\r\n('Version      :', '1.3.1')\r\n('Directory    :', '/home/ubuntu/.local/lib/python2.7/site-packages/mxnet')\r\n('Commit Hash   :', '19c501680183237d52a862e6ae1dc4ddc296305b')\r\n----------System Info----------\r\n('Platform     :', 'Linux-4.4.0-142-generic-x86_64-with-Ubuntu-16.04-xenial')\r\n('system       :', 'Linux')\r\n('node         :', 'cpu15')\r\n('release      :', '4.4.0-142-generic')\r\n('version      :', '#168-Ubuntu SMP Wed Jan 16 21:00:45 UTC 2019')\r\n----------Hardware Info----------\r\n('machine      :', 'x86_64')\r\n('processor    :', 'x86_64')\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                24\r\nOn-line CPU(s) list:   0-23\r\nThread(s) per core:    2\r\nCore(s) per socket:    6\r\nSocket(s):             2\r\nNUMA node(s):          2\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 62\r\nModel name:            Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz\r\nStepping:              4\r\nCPU MHz:               2600.000\r\nCPU max MHz:           3100.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              5201.74\r\nVirtualization:        VT-x\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              15360K\r\nNUMA node0 CPU(s):     0-5,12-17\r\nNUMA node1 CPU(s):     6-11,18-23\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm epb ssbd ibrs ibpb stibp kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase smep erms xsaveopt dtherm arat pln pts flush_l1d\r\n----------Network Test----------\r\nSetting timeout: 10\r\nTiming for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0010 sec, LOAD: 1.4220 sec.\r\nTiming for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.3412 sec, LOAD: 1.2661 sec.\r\nTiming for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.1701 sec, LOAD: 10.9662 sec.\r\nTiming for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0634 sec, LOAD: 0.2553 sec.\r\nTiming for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.2422 sec, LOAD: 1.0355 sec.\r\nTiming for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.6101 sec, LOAD: 1.2469 sec.\r\n"", '\r\nmxnet_option(USE_CUDA             ""Build with CUDA support""   OFF)\r\nmxnet_option(USE_OLDCMAKECUDA     ""Build with old cmake cuda"" OFF)\r\nmxnet_option(USE_NCCL             ""Use NVidia NCCL with CUDA"" OFF)\r\nmxnet_option(USE_OPENCV           ""Build with OpenCV support"" ON)\r\nmxnet_option(USE_OPENMP           ""Build with Openmp support"" OFF)\r\nmxnet_option(USE_CUDNN            ""Build with cudnn support""  OFF) # one could set CUDNN_ROOT for search path\r\nmxnet_option(USE_SSE              ""Build with x86 SSE instruction support"" ON IF NOT ARM)\r\nmxnet_option(USE_F16C             ""Build with x86 F16C instruction support"" ON) # autodetects support if ON\r\nmxnet_option(USE_LAPACK           ""Build with lapack support"" ON)\r\nmxnet_option(USE_MKL_IF_AVAILABLE ""Use MKL if found"" ON)\r\nmxnet_option(USE_MKLML_MKL        ""Use MKLDNN variant of MKL (if MKL found)"" ON IF USE_MKL_IF_AVAILABLE AND (NOT APPLE))\r\nmxnet_option(USE_MKLDNN           ""Use MKLDNN variant of MKL (if MKL found)"" ON IF USE_MKL_IF_AVAILABLE AND (NOT APPLE) AND (NOT MSVC) AND (CMAKE_HOST_SYSTEM_PROCESSOR STREQUAL ""x86_64"") AND (NOT CMAKE_CROSSCOMPILING))\r\nmxnet_option(USE_OPERATOR_TUNING  ""Enable auto-tuning of operators"" ON IF NOT MSVC)\r\nmxnet_option(USE_GPERFTOOLS       ""Build with GPerfTools support (if found)"" ON)\r\nmxnet_option(USE_JEMALLOC         ""Build with Jemalloc support""   ON)\r\nmxnet_option(USE_PROFILER         ""Build with Profiler support""   ON)\r\nmxnet_option(USE_DIST_KVSTORE     ""Build with DIST_KVSTORE support"" ON)\r\nmxnet_option(USE_PLUGINS_WARPCTC  ""Use WARPCTC Plugins"" OFF)\r\nmxnet_option(USE_PLUGIN_CAFFE     ""Use Caffe Plugin"" OFF)\r\nmxnet_option(USE_CPP_PACKAGE      ""Build C++ Package"" ON)\r\nmxnet_option(USE_MXNET_LIB_NAMING ""Use MXNet library naming conventions."" ON)\r\nmxnet_option(USE_GPROF            ""Compile with gprof (profiling) flag"" OFF)\r\nmxnet_option(USE_CXX14_IF_AVAILABLE ""Build with C++14 if the compiler supports it"" ON)\r\nmxnet_option(USE_VTUNE            ""Enable use of Intel Amplifier XE (VTune)"" OFF) # one could set VTUNE_ROOT for search path\r\nmxnet_option(ENABLE_CUDA_RTC      ""Build with CUDA runtime compilation support"" OFF)\r\nmxnet_option(BUILD_CPP_EXAMPLES   ""Build cpp examples"" ON)\r\nmxnet_option(INSTALL_EXAMPLES     ""Install the example source files."" OFF)\r\nmxnet_option(USE_SIGNAL_HANDLER   ""Print stack traces on segfaults."" OFF)\r\nmxnet_option(USE_TENSORRT         ""Enable infeference optimization with TensorRT."" OFF)\r\nmxnet_option(USE_ASAN             ""Enable Clang/GCC ASAN sanitizers."" OFF)\r\nmxnet_option(ENABLE_TESTCOVERAGE  ""Enable compilation with test coverage metric output"" OFF)\r\n', 'ninja -v ']","['', '\r\nFAILED: : && /usr/bin/c++   -Wall -Wno-unknown-pragmas -Wno-sign-compare -O3 -msse2 -std=c++14 -mf16c -std=c++1y   example/image-classification/predict-cpp/CMakeFiles/image-classification-predict.dir/image-classification-predict.cc.o  -o example/image-classification/predict-cpp/image-classification-predict -L/home/ubuntu/incubator-mxnet/cmake_build/mklml/mklml_lnx_2019.0.1.20180928/lib -rdynamic -Wl,--whole-archive libmxnet.a -Wl,--no-whole-archive 3rdparty/dmlc-core/libdmlc.a 3rdparty/mkldnn/src/libmkldnn.so.0.17.4.0 -lopenblas -lrt /usr/local/lib/libopencv_highgui.so.4.0.1 -lpthread -llapack -lprotobuf -lzmq 3rdparty/ps-lite/libpslite.a -lprotobuf -lmklml_intel mklml/mklml_lnx_2019.0.1.20180928/lib/libiomp5.so /usr/local/lib/libopencv_videoio.so.4.0.1 /usr/local/lib/libopencv_imgcodecs.so.4.0.1 /usr/local/lib/libopencv_imgproc.so.4.0.1 /usr/local/lib/libopencv_core.so.4.0.1 -Wl,-rpath,/home/ubuntu/incubator-mxnet/cmake_build/3rdparty/mkldnn/src:/usr/local/lib:/home/ubuntu/incubator-mxnet/cmake_build/mklml/mklml_lnx_2019.0.1.20180928/lib && :\r\n3rdparty/ps-lite/libpslite.a(van.cc.o): In function ', ""zmq_msg_close'\r\n3rdparty/ps-lite/libpslite.a(van.cc.o): In function "", ""zmq_setsockopt'\r\nvan.cc:(.text._ZN2ps6ZMQVan4StopEv[_ZN2ps6ZMQVan4StopEv]+0x14c): undefined reference to "", ""zmq_setsockopt'\r\nvan.cc:(.text._ZN2ps6ZMQVan4StopEv[_ZN2ps6ZMQVan4StopEv]+0x31c): undefined reference to "", ""zmq_ctx_destroy'\r\n3rdparty/ps-lite/libpslite.a(van.cc.o): In function "", ""zmq_socket'\r\nvan.cc:(.text._ZN2ps6ZMQVan4BindERKNS_4NodeEi[_ZN2ps6ZMQVan4BindERKNS_4NodeEi]+0x1a3): undefined reference to "", ""zmq_strerror'\r\n3rdparty/ps-lite/libpslite.a(van.cc.o): In function "", ""zmq_socket'\r\nvan.cc:(.text._ZN2ps6ZMQVan7ConnectERKNS_4NodeE[_ZN2ps6ZMQVan7ConnectERKNS_4NodeE]+0x29a): undefined reference to "", ""zmq_connect'\r\nvan.cc:(.text._ZN2ps6ZMQVan7ConnectERKNS_4NodeE[_ZN2ps6ZMQVan7ConnectERKNS_4NodeE]+0x437): undefined reference to "", ""zmq_close'\r\nvan.cc:(.text._ZN2ps6ZMQVan7ConnectERKNS_4NodeE[_ZN2ps6ZMQVan7ConnectERKNS_4NodeE]+0x619): undefined reference to "", ""ps::ZMQVan::Start(int)':\r\nvan.cc:(.text._ZN2ps6ZMQVan5StartEi[_ZN2ps6ZMQVan5StartEi]+0xa3): undefined reference to "", ""zmq_ctx_set'\r\nvan.cc:(.text._ZN2ps6ZMQVan5StartEi[_ZN2ps6ZMQVan5StartEi]+0x13c): undefined reference to "", ""zmq_ctx_set'\r\nvan.cc:(.text._ZN2ps6ZMQVan5StartEi[_ZN2ps6ZMQVan5StartEi]+0x17a): undefined reference to "", ""ps::ZMQVan::SendMsg(ps::Message const&)':\r\nvan.cc:(.text._ZN2ps6ZMQVan7SendMsgERKNS_7MessageE[_ZN2ps6ZMQVan7SendMsgERKNS_7MessageE]+0x241): undefined reference to "", ""zmq_msg_send'\r\nvan.cc:(.text._ZN2ps6ZMQVan7SendMsgERKNS_7MessageE[_ZN2ps6ZMQVan7SendMsgERKNS_7MessageE]+0x310): undefined reference to "", ""zmq_msg_send'\r\nvan.cc:(.text._ZN2ps6ZMQVan7SendMsgERKNS_7MessageE[_ZN2ps6ZMQVan7SendMsgERKNS_7MessageE]+0x379): undefined reference to "", ""ps::ZMQVan::RecvMsg(ps::Message*)':\r\nvan.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0xad): undefined reference to "", ""zmq_msg_recv'\r\nvan.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x105): undefined reference to "", ""zmq_msg_data'\r\nvan.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x123): undefined reference to "", ""zmq_msg_more'\r\nvan.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x245): undefined reference to "", ""zmq_strerror'\r\nvan.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x384): undefined reference to "", ""zmq_msg_close'\r\nvan.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x3f7): undefined reference to "", ""zmq_msg_more'\r\nvan.cc:(.text._ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE[_ZN2ps6ZMQVan7RecvMsgEPNS_7MessageE]+0x4bc): undefined reference to "", ""zmq_msg_close'\r\ncollect2: error: ld returned 1 exit status\r\nIn file included from ../tests/cpp/operator/dropout_perf.cc:30:0:\r\n../3rdparty/mshadow/../../src/operator/nn/dropout-inl.h:492:19: warning: ‘mxnet::OpStatePtr mxnet::op::CreateDropoutState(const nnvm::NodeAttrs&, mxnet::Context, const std::vector<nnvm::TShape, std::allocator<nnvm::TShape> >&, const std::vector<int>&)’ defined but not used [-Wunused-function]\r\n static OpStatePtr CreateDropoutState(const nnvm::NodeAttrs &attrs,\r\n                   ^\r\nninja: build stopped: subcommand failed.\r\n"", '']",0,0
507,incubator-mxnet,5275,closed,Why no mxnet.symbol.relu (or sigmoid)?,"I've noticed that in mxnet.symbol we have defined:
* mxnet.symbol.tanh
* mnet.symbol.LeakyReLU
However, we don't have mxnet.symbol.ReLU or mxnet.symbol.sigmoid defined. These functions are defined but only within the 

I think this is bad for a couple reasons:
* This appears disorganized. Like functions should be grouped in like folders.
* This makes our library overly married to neural network notation. We could imagine other times when someone might want to access the sigmoid or hinge functions but wouldn't think of them as activation functions.

I think both ReLU (better to spell ""relu"") and sigmoid should both be available in mxnet.symbol



For bugs or installation issues, please provide the following information.
The more information you provide, the more likely people will be able to help you.

## Environment info
Operating System:

Compiler:

Package used (Python/R/Scala/Julia):

MXNet version:

Or if installed from source:

MXNet commit hash ():

If you are using python package, please provide

Python version and distribution:

If you are using R package, please provide

R :

## Error Message:
Please paste the full error message, including stack trace.

## Minimum reproducible example
if you are using your own code, please provide a short script that reproduces the error.

## Steps to reproduce
or if you are running standard examples, please provide the commands you have run that lead to the error.

1.
2.
3.

## What have you tried to solve it?

1.
2.
3.
",,"[""Activation(act_type='relu')"", 'per discussion with zack, we should add make these activation functions individual operators, such as `sym.relu` and `sym.sigmod`.\r\n\r\nbesides, we should also add lower case alias to these neural network functions, this is consistent with google python style. ', ""I'm in favor with the idea to add lower case alias. It will unite the style of operators"", 'This issue is closed due to lack of activity in the last 90 days. Feel free to ping me to reopen if this is still an active issue. Thanks!']",[],"['git rev-parse HEAD', 'sessionInfo()']",0,0
508,incubator-mxnet,12923,closed,Deadlock happend while calling MXNDArraySyncCopyToCPU() ?,"**We have been troubled by the problem for a few days, so we need everyone's help, thank you!**

**Environment**：
GPU: Tesla P4; CPU: Intel(R) Xeon(R) Gold 6133 CPU @ 2.50GHz.

**Appearance**：
The program receives the Image data as a server. After a period of time, the program starts to appear similar to Deadlock (may be caused by some requests, but cannot be accurately reproduced)

We tested on mxnet versions 1.0, 1.2, and 1.3, and the program showed the same appearance.

**Program running process**：
We called the python engine in a C++ multithreaded program that uses the mxnet-python api. As can be seen from the stack information, MXNDArraySyncCopyToCPU() waits for a condition variable during execution, and the program will always be stuck in this place.

**Stack information**：
Thread 85 (Thread 0x7f3cba52f700 (LWP 41394)):
#0  0x00007f3d582fd6d5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0
#1  0x00007f3d580979bc in __gthread_cond_wait (__mutex=<optimized out>, __cond=<optimized out>) at /data/home/xxx/gcc-build/gcc-4.9.4/build/x86_64-redhat-linux/libstdc++-v3/include/x86_64-redhat-linux/bits/gthr-default.h:864
#2  std::condition_variable::wait (this=<optimized out>, __lock=...) at ../../../../../libstdc++-v3/src/c++11/condition_variable.cc:52
#3  0x00007f3c7bcb86d5 in ?? () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#4  0x00007f3c7bd94b4d in ?? () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#5  0x00007f3c7be7e9c3 in ?? () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#6  0x00007f3c7bc516db in MXNDArraySyncCopyToCPU () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#7  0x00007f3d53e15adc in ffi_call_unix64 () from my_app/libs/./libffi.so.6
#8  0x00007f3d53e15282 in ffi_call () from my_app/libs/./libffi.so.6
#9  0x00007f3bfdd09376 in _call_function_pointer (argcount=3, resmem=0x7f3b3c1c4040, restype=<optimized out>, atypes=<optimized out>, avalues=0x7f3b3c1c4010, pProc=0x7f3c7bc516b0 <MXNDArraySyncCopyToCPU>, flags=4353) at /home/xxx/minonda/conda-bld/python-2.7_1482296880985/work/Python-2.7.13/Modules/_ctypes/callproc.c:841
#10 _ctypes_callproc (pProc=0x7f3c7bc516b0 <MXNDArraySyncCopyToCPU>, argtuple=0x7f3b3c1c4130, flags=4353, argtypes=<optimized out>, restype=0x1616b80, checker=0x0) at /home/xxx/minonda/conda-bld/python-2.7_1482296880985/work/Python-2.7.13/Modules/_ctypes/callproc.c:1184
#11 0x00007f3bfdd00db3 in PyCFuncPtr_call (self=<optimized out>, inargs=<optimized out>, kwds=0x0) at /home/xxx/minonda/conda-bld/python-2.7_1482296880985/work/Python-2.7.13/Modules/_ctypes/_ctypes.c:3979
#12 0x00007f3d52c42e93 in PyObject_Call (func=0x7f3d2a11a050, arg=<optimized out>, kw=<optimized out>) at Objects/abstract.c:2547
#13 0x00007f3d52cf580d in do_call (nk=<optimized out>, na=<optimized out>, pp_stack=0x7f3b3c1c43b8, func=0x7f3d2a11a050) at Python/ceval.c:4569
#14 call_function (oparg=<optimized out>, pp_stack=0x7f3b3c1c43b8) at Python/ceval.c:4374
#15 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:2989
#16 0x00007f3d52cf7c3e in PyEval_EvalCodeEx (co=0x7f3d3f730030, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=1, kws=0x7f3d2a186fd0, kwcount=0, defs=0x0, defcount=0, closure=0x0) at Python/ceval.c:3584
#17 0x00007f3d52cf71f7 in fast_function (nk=<optimized out>, na=1, n=<optimized out>, pp_stack=0x7f3b3c1c45d8, func=0x7f3d3f6ee5f0) at Python/ceval.c:4447
#18 call_function (oparg=<optimized out>, pp_stack=0x7f3b3c1c45d8) at Python/ceval.c:4372
#19 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:2989
#20 0x00007f3d52cf7345 in fast_function (nk=<optimized out>, na=<optimized out>, n=<optimized out>, pp_stack=0x7f3b3c1c4748, func=0x7f3d2aea9c80) at Python/ceval.c:4437
#21 call_function (oparg=<optimized out>, pp_stack=0x7f3b3c1c4748) at Python/ceval.c:4372
#22 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:2989
#23 0x00007f3d52cf7c3e in PyEval_EvalCodeEx (co=0x7f3d528fcc30, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=2, kws=0x7f3d2a18dc68, kwcount=0, defs=0x0, defcount=0, closure=0x0) at Python/ceval.c:3584
#24 0x00007f3d52cf71f7 in fast_function (nk=<optimized out>, na=2, n=<optimized out>, pp_stack=0x7f3b3c1c4968, func=0x7f3d2a33f0c8) at Python/ceval.c:4447
#25 call_function (oparg=<optimized out>, pp_stack=0x7f3b3c1c4968) at Python/ceval.c:4372
#26 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:2989
#27 0x00007f3d52cf7345 in fast_function (nk=<optimized out>, na=<optimized out>, n=<optimized out>, pp_stack=0x7f3b3c1c4ad8, func=0x7f3d2a33f410) at Python/ceval.c:4437
#28 call_function (oparg=<optimized out>, pp_stack=0x7f3b3c1c4ad8) at Python/ceval.c:4372
#29 PyEval_EvalFrameEx (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:2989
#30 0x00007f3d52cf7c3e in PyEval_EvalCodeEx (co=0x7f3d52963db0, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=1, kws=0x0, kwcount=0, defs=0x0, defcount=0, closure=0x0) at Python/ceval.c:3584
#31 0x00007f3d52c72a61 in function_call (func=0x7f3d2a33f8c0, arg=0x7f3d529377d0, kw=0x0) at Objects/funcobject.c:523
#32 0x00007f3d52c42e93 in PyObject_Call (func=0x7f3d2a33f8c0, arg=<optimized out>, kw=<optimized out>) at Objects/abstract.c:2547
#33 0x00007f3d52ced7b3 in PyEval_CallObjectWithKeywords (func=0x7f3d2a33f8c0, arg=0x7f3d529377d0, kw=<optimized out>) at Python/ceval.c:4221
#34 0x00007f3d52d13468 in PyEval_CallMethod (obj=<optimized out>, methodname=<optimized out>, format=<optimized out>) at Python/modsupport.c:612
#35 0x00007f3d5303141f in ?? ()
#36 0x0000000000000000 in ?? ()




----------------------------------------------------------------------------------------------------


**In addition**:
there are occasions when other threads are blocked at the same time, such as the stack information below, which is the stack information of an unrelated CPU thread. The strange thing is that there is actually libmxnet.so:

Thread 70 (Thread 0x7f3b0bff6700 (LWP 41409)):
#0  0x00007f3d582fd6d5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0
#1  0x00007f3d580979bc in __gthread_cond_wait (__mutex=<optimized out>, __cond=<optimized out>) at /data/home/xxx/gcc-build/gcc-4.9.4/build/x86_64-redhat-linux/libstdc++-v3/include/x86_64-redhat-linux/bits/gthr-default.h:864
#2  std::condition_variable::wait (this=<optimized out>, __lock=...) at ../../../../../libstdc++-v3/src/c++11/condition_variable.cc:52
#3  0x00007f3c7bcb88a3 in ?? () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#4  0x00007f3c7bcc0339 in ?? () from my_app/anaconda2/lib/python2.7/site-packages/mxnet/libmxnet.so
#5  0x00007f3d577c4702 in fork () from /lib64/libc.so.6
......",Python Thread Safety,"['Are there any hints for the reason why the thread is blocked when calling the MXNDArraySyncCopyToCPU  method ? Just like under some special suitations or usage ?', ""Hi, MXNet does not support multithreaded interaction with its frontend APIs. We rather require a sticky-thread for this.\r\n\r\nThis means that you have to follow the dispatcher model which dedicates one thread during the entire lifecycle of your application to internet with MXNet. It's important that you don't only use a mutex since we depend on the threadlocal variables that are assigned to the dispatcher thread."", ""> Hi, MXNet does not support multithreaded interaction with its frontend APIs. We rather require a sticky-thread for this.\r\n> \r\n> This means that you have to follow the dispatcher model which dedicates one thread during the entire lifecycle of your application to internet with MXNet. It's important that you don't only use a mutex since we depend on the threadlocal variables that are assigned to the dispatcher thread.\r\n\r\n----------------------------------------------------------------------------------------------------\r\nThanks for the reply, I did not make it clear before. We started 8 processes on one machine, and only 1 thread per process uses mxnet (other threads handle different works). We called the python engine in a C++ program that uses the mxnet-python api. Is there a problem with this usage?"", ""That sounds good to me. Could you maybe show some minimal example that allows to reproduce the problem? \r\n\r\nI'll let somebody else follow up on your issue since we're now getting to the Python-API."", '@mxnet-label-bot [Python, Thread Safety]', ""> That sounds good to me. Could you maybe show some minimal example that allows to reproduce the problem?\r\n> \r\n> I'll let somebody else follow up on your issue since we're now getting to the Python-API.\r\n\r\nHello, sorry to reply so late. This problem no longer occurs after changing the engine type of MxNet from the default ThreadedEnginePerDevice to ThreadedEngine. I hope this can give you some clues."", ""@coconutyao Good to see that your issue was resolved. I'm closing this issue. Please feel free to re-open if closed in error.\r\n\r\n@lanking520 Can you please close this issue ? \r\n\r\nThanks!"", '@coconutyao Close the issue for now. Please feel free to reopen it if you are still facing the problem']",[],[],0,0
509,incubator-mxnet,6814,closed,Can not find the link to 'local_allreduce_cpu'  example according to the mxnet doc,"I read the page: http://mxnet-tqchen.readthedocs.io/en/latest/system/multi_node.html  
But i can not find the AlexNet on imagenet example.
Can anyone give some help here?  


> local_allreduce_cpu is similar to local_update_cpu except that the averaged gradients are copied back to the devices, and then weights are updated on devices. It is faster than 1 when the weight size is large so we can use the device to accelerate the computation (but we increase the workload by k times). Examples are AlexNet on imagenet.  

",,['Here is alexnet model definition: https://github.com/dmlc/mxnet/blob/master/example/image-classification/symbols/alexnet.py\r\n\r\nYou can train with https://github.com/dmlc/mxnet/blob/master/example/image-classification/train_imagenet.py'],[],[],0,0
510,incubator-mxnet,13374,closed,"[Bug] ValueError: There are multiple outputs with name ""resnetv1b0_layers1_relu0_fwd_output"".","Outputs of diagnose.py:
floatnp.floatingnp.float64 == np.dtype(float).typefloatnp.floatingnp.float64 == np.dtype(float).type",Bug Gluon,"['@mxnet-label-bot add [Gluon, Question, Bug]', '+1 also effecting a user here https://discuss.mxnet.io/t/error-when-trying-to-import-a-trained-net-multiple-outputs-with-name/2426', 'Seems that `mx.gluon.nn.SymbolBlock` constructs the graph based on output names, when it should use the index of outputs instead.', ""I also encounter this problem when using TextCNN, here is my model:\r\n\r\n    class TextCNN(HybridBlock):\r\n        def __init__(self, args, vocab, kernel_sizes, num_channels, **kwargs):\r\n            super(TextCNN, self).__init__(**kwargs)\r\n            self.embedding = nn.Embedding(len(vocab), args.embed_size)\r\n            self.constant_embedding = nn.Embedding(len(vocab), args.embed_size)\r\n            self.dropout = nn.Dropout(0.5)\r\n            self.decoder = nn.Dense(5)\r\n            self.pool = nn.GlobalMaxPool1D()\r\n            self.convs = nn.HybridSequential()\r\n            for c, k in zip(num_channels, kernel_sizes):\r\n                self.convs.add(nn.Conv1D(c, k, activation='relu'))\r\n\r\n        def hybrid_forward(self, F, inputs):\r\n            embeddings = F.concat(self.embedding(inputs), self.constant_embedding(inputs), dim=2)\r\n            embeddings = embeddings.transpose((0, 2, 1))\r\n            encoding = F.concat(*[F.flatten(\r\n                self.pool(conv(embeddings))) for conv in self.convs], dim=1)\r\n            outputs = self.decoder(self.dropout(encoding))\r\n            return F.softmax(outputs)"", 'Hi @**kohillyang**, could you please upgrade your gluoncv version to 0.4.0(latest) using `pip install gluoncv —upgrade` since the issue is fixed in the latest gluoncv version. I have tried below scripts and it\'s working for me:\r\n\r\n```python\r\nimport gluoncv\r\nimport mxnet as mx\r\ndata = mx.sym.var(name=""data"")\r\nnet = gluoncv.model_zoo.resnet50_v1b(pretrained=False)\r\nnet.initialize()\r\nsym = net(data)\r\nsym_block = mx.gluon.nn.SymbolBlock(sym, [data])\r\n```\r\n\r\n\r\n\r\n```python\r\nfrom mxnet import gluon, nd\r\nfrom gluoncv.model_zoo import get_model\r\n\r\nx = nd.zeros(shape=(32,3,256,256))\r\nmodel = get_model(""ResNet50_v1c"", pretrained=True)\r\nmodel.hybridize()\r\nmodel(x)\r\nmodel.export(""net"",epoch=0)\r\nmodel2 = gluon.nn.SymbolBlock.imports(""net-symbol.json"", [\'data\'], ""net-0000.params"")\r\n```\r\n\r\n\r\n\r\nMXNet version: 1.4.0\r\ngluoncv version: 0.4.0', ""@kohillyang This issue is indeed fixed in the latest version of MXNet and GluonCV. Please upgrade to both. \r\n\r\nI'm suggesting to close this issue. Please feel free to re-open if closed in error.\r\n\r\n@Roshrini Can you please close this issue ? "", ""Yes, this issue has been fixed, I'll close it. Thanks.""]","['\r\n\r\n\r\nError Message:\r\n', '\r\nrelated issues:\r\n[#12795](https://github.com/apache/incubator-mxnet/issues/12795)\r\n\r\n# Minimum reproducible example\r\n']","['', ""\r\n----------Python Info----------\r\n('Version      :', '2.7.14')\r\n('Compiler     :', 'GCC 7.2.0')\r\n('Build        :', ('default', 'Dec  7 2017 17:05:42'))\r\n('Arch         :', ('64bit', ''))\r\n------------Pip Info-----------\r\n('Version      :', '18.0')\r\n('Directory    :', '/data1/zyx/Anaconda2/lib/python2.7/site-packages/pip')\r\n----------MXNet Info-----------\r\n/data1/zyx/Anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from "", ' to ', ' is deprecated. In future, it will be treated as ', "".\r\n  from ._conv import register_converters as _register_converters\r\n('Version      :', '1.3.0')\r\n('Directory    :', '/data1/zyx/Anaconda2/lib/python2.7/site-packages/mxnet')\r\n('Commit Hash   :', 'b3be92f4a48bce62a5a8424271871c2f81c8f7f1')\r\n----------System Info----------\r\n('Platform     :', 'Linux-4.4.0-122-generic-x86_64-with-debian-stretch-sid')\r\n('system       :', 'Linux')\r\n('node         :', '7b5642bf21b5')\r\n('release      :', '4.4.0-122-generic')\r\n('version      :', '#146-Ubuntu SMP Mon Apr 23 15:34:04 UTC 2018')\r\n----------Hardware Info----------\r\n('machine      :', 'x86_64')\r\n('processor    :', 'x86_64')\r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                56\r\nOn-line CPU(s) list:   0-55\r\nThread(s) per core:    2\r\nCore(s) per socket:    14\r\nSocket(s):             2\r\nNUMA node(s):          2\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz\r\nStepping:              1\r\nCPU MHz:               1277.351\r\nCPU max MHz:           3500.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              5201.87\r\nVirtualization:        VT-x\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              35840K\r\nNUMA node0 CPU(s):     0-13,28-41\r\nNUMA node1 CPU(s):     14-27,42-55\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts\r\n----------Network Test----------\r\nSetting timeout: 10\r\nError open MXNet: https://github.com/apache/incubator-mxnet, <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:661)>, DNS finished in 0.301597118378 sec.\r\nError open PYPI: https://pypi.python.org/pypi/pip, <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:661)>, DNS finished in 0.295644044876 sec.\r\nError open FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:661)>, DNS finished in 0.346220016479 sec.\r\nError open Conda: https://repo.continuum.io/pkgs/free/, <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:661)>, DNS finished in 0.287996053696 sec.\r\nError open Gluon Tutorial(en): http://gluon.mxnet.io, <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:661)>, DNS finished in 0.320595979691 sec.\r\nError open Gluon Tutorial(cn): https://zh.gluon.ai, <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:661)>, DNS finished in 0.320269107819 sec.\r\n\r\n/data1/zyx/Anaconda2/bin/python /data3/zyx/yks/mx-detection/bug.py\r\n/data1/zyx/Anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from "", ' to ', ' is deprecated. In future, it will be treated as ', '.\r\n  from ._conv import register_converters as _register_converters\r\nTraceback (most recent call last):\r\n  File ""/data3/zyx/yks/mx-detection/bug.py"", line 7, in <module>\r\n    sym_block = mx.gluon.nn.SymbolBlock(sym, [data])\r\n  File ""/data1/zyx/Anaconda2/lib/python2.7/site-packages/mxnet/gluon/block.py"", line 1051, in __init__\r\n    for j in i.get_internals():\r\n  File ""/data1/zyx/Anaconda2/lib/python2.7/site-packages/mxnet/symbol/symbol.py"", line 93, in <genexpr>\r\n    return (self[i] for i in self.list_outputs())\r\n  File ""/data1/zyx/Anaconda2/lib/python2.7/site-packages/mxnet/symbol/symbol.py"", line 517, in __getitem__\r\n    raise ValueError(\'There are multiple outputs with name \\""%s\\""\' % index)\r\nValueError: There are multiple outputs with name ""resnetv1b0_layers1_relu0_fwd_output""\r\npython\r\nimport gluoncv\r\nimport mxnet as mx\r\ndata = mx.sym.var(name=""data"")\r\nnet = gluoncv.model_zoo.resnet50_v1b(pretrained=False)\r\nnet.initialize()\r\nsym = net(data)\r\nsym_block = mx.gluon.nn.SymbolBlock(sym, [data])\r\n\r\n', '']",0,0
511,incubator-mxnet,9198,closed,parallel decoding (mxnet.image.imdecode) is not working,"## Description
https://mxnet.incubator.apache.org/architecture/release_note_0_9.html?highlight=cython#image-io
> mx.image provides a set of fast image processing API that leverage MXNet Engine to automatically parallelize processing. You can write  and decoding will be automatically run in parallel.

**i tried parallel decoding using mxnet.image.imdecode() function. but it's not working.**

## Build info (Required if built from source)

Compiler (gcc/clang/mingw/visual studio): 

MXNet commit hash: 
(Paste the output of  here.)

Build config:





## Steps to reproduce





## What have you tried to solve it?

1. build from latest sources

",,"['\r\n```\r\n$ MXNET_CPU_WORKER_NTHREADS=1 python pp.py\r\nMXNET_CPU_WORKER_NTHREADS=1, time=0.434\r\n$ MXNET_CPU_WORKER_NTHREADS=2 python pp.py\r\nMXNET_CPU_WORKER_NTHREADS=2, time=0.233\r\n$ MXNET_CPU_WORKER_NTHREADS=4 python pp.py\r\nMXNET_CPU_WORKER_NTHREADS=4, time=0.125\r\n$ MXNET_CPU_WORKER_NTHREADS=8 python pp.py\r\nMXNET_CPU_WORKER_NTHREADS=8, time=0.071\r\n$ MXNET_CPU_WORKER_NTHREADS=16 python pp.py\r\nMXNET_CPU_WORKER_NTHREADS=16, time=0.049\r\n```\r\n\r\nI tried again with mxnet version 1.0.1 and it works fine.']","['\r\n* Python 3.6.2\r\n* OpenCV 3.3 (build from source)\r\n* OpenBLAS\r\n* CUDA 8.0\r\n', ""\r\n#-------------------------------------------------------------------------------\r\n#  Template configuration for compiling mxnet\r\n#\r\n#  If you want to change the configuration, please use the following\r\n#  steps. Assume you are on the root directory of mxnet. First copy the this\r\n#  file so that any local changes will be ignored by git\r\n#\r\n#  $ cp make/config.mk .\r\n#\r\n#  Next modify the according entries, and then compile by\r\n#\r\n#  $ make\r\n#\r\n#  or build in parallel with 8 threads\r\n#\r\n#  $ make -j8\r\n#-------------------------------------------------------------------------------\r\n\r\n#---------------------\r\n# choice of compiler\r\n#--------------------\r\n\r\nexport CC = gcc\r\nexport CXX = g++\r\nexport NVCC = nvcc\r\n\r\n# whether compile with options for MXNet developer\r\nDEV = 0\r\n\r\n# whether compile with debug\r\nDEBUG = 0\r\n\r\n# whether compile with profiler\r\nUSE_PROFILER =\r\n\r\n# whether to turn on segfault signal handler to log the stack trace\r\nUSE_SIGNAL_HANDLER =\r\n\r\n# the additional link flags you want to add\r\nADD_LDFLAGS =\r\n\r\n# the additional compile flags you want to add\r\nADD_CFLAGS =\r\n\r\n#---------------------------------------------\r\n# matrix computation libraries for CPU/GPU\r\n#---------------------------------------------\r\n\r\n# whether use CUDA during compile\r\nUSE_CUDA = 1\r\n\r\n# add the path to CUDA library to link and compile flag\r\n# if you have already add them to environment variable, leave it as NONE\r\n# USE_CUDA_PATH = /usr/local/cuda\r\nUSE_CUDA_PATH = /usr/local/cuda\r\n\r\n# whether use CuDNN R3 library\r\nUSE_CUDNN = 1\r\n\r\n#whether to use NCCL library\r\nUSE_NCCL = 0\r\n#add the path to NCCL library\r\nUSE_NCCL_PATH = NONE\r\n\r\n# whether use opencv during compilation\r\n# you can disable it, however, you will not able to use\r\n# imbin iterator\r\nUSE_OPENCV = 1\r\n\r\n#whether use libjpeg-turbo for image decode without OpenCV wrapper\r\nUSE_LIBJPEG_TURBO = 0\r\n#add the path to libjpeg-turbo library\r\nUSE_LIBJPEG_TURBO_PATH = NONE\r\n\r\n# use openmp for parallelization\r\nUSE_OPENMP = 1\r\n\r\n# MKL ML Library for Intel CPU/Xeon Phi\r\n# Please refer to MKL_README.md for details\r\n\r\n# MKL ML Library folder, need to be root for /usr/local\r\n# Change to User Home directory for standard user\r\n# For USE_BLAS!=mkl only\r\nMKLML_ROOT=/usr/local\r\n\r\n# whether use MKL2017 library\r\nUSE_MKL2017 = 0\r\n\r\n# whether use MKL2017 experimental feature for high performance\r\n# Prerequisite USE_MKL2017=1\r\nUSE_MKL2017_EXPERIMENTAL = 0\r\n\r\n# whether use NNPACK library\r\nUSE_NNPACK = 0\r\n\r\n# choose the version of blas you want to use\r\n# can be: mkl, blas, atlas, openblas\r\n# in default use atlas for linux while apple for osx\r\nUNAME_S := $(shell uname -s)\r\nifeq ($(UNAME_S), Darwin)\r\nUSE_BLAS = apple\r\nelse\r\nUSE_BLAS = openblas\r\nendif\r\n\r\n# whether use lapack during compilation\r\n# only effective when compiled with blas versions openblas/apple/atlas/mkl\r\nUSE_LAPACK = 1\r\n\r\n# path to lapack library in case of a non-standard installation\r\nUSE_LAPACK_PATH =\r\n\r\n# by default, disable lapack when using MKL\r\n# switch on when there is a full installation of MKL available (not just MKL2017/MKL_ML)\r\nifeq ($(USE_BLAS), mkl)\r\nUSE_LAPACK = 0\r\nendif\r\n\r\n# add path to intel library, you may need it for MKL, if you did not add the path\r\n# to environment variable\r\nUSE_INTEL_PATH = NONE\r\n\r\n# If use MKL only for BLAS, choose static link automatically to allow python wrapper\r\nifeq ($(USE_MKL2017), 0)\r\nifeq ($(USE_BLAS), mkl)\r\nUSE_STATIC_MKL = 1\r\nendif\r\nelse\r\nUSE_STATIC_MKL = NONE\r\nendif\r\n\r\n#----------------------------\r\n# Settings for power and arm arch\r\n#----------------------------\r\nARCH := $(shell uname -a)\r\nifneq (,$(filter $(ARCH), armv6l armv7l powerpc64le ppc64le aarch64))\r\n\tUSE_SSE=0\r\nelse\r\n\tUSE_SSE=1\r\nendif\r\n\r\n#----------------------------\r\n# distributed computing\r\n#----------------------------\r\n\r\n# whether or not to enable multi-machine supporting\r\nUSE_DIST_KVSTORE = 0\r\n\r\n# whether or not allow to read and write HDFS directly. If yes, then hadoop is\r\n# required\r\nUSE_HDFS = 0\r\n\r\n# path to libjvm.so. required if USE_HDFS=1\r\nLIBJVM=$(JAVA_HOME)/jre/lib/amd64/server\r\n\r\n# whether or not allow to read and write AWS S3 directly. If yes, then\r\n# libcurl4-openssl-dev is required, it can be installed on Ubuntu by\r\n# sudo apt-get install -y libcurl4-openssl-dev\r\nUSE_S3 = 0\r\n\r\n#----------------------------\r\n# performance settings\r\n#----------------------------\r\n# Use operator tuning\r\nUSE_OPERATOR_TUNING = 1\r\n\r\n# Use gperftools if found\r\nUSE_GPERFTOOLS = 1\r\n\r\n# Use JEMalloc if found, and not using gperftools\r\nUSE_JEMALLOC = 1\r\n\r\n#----------------------------\r\n# additional operators\r\n#----------------------------\r\n\r\n# path to folders containing projects specific operators that you don't want to put in src/operators\r\nEXTRA_OPERATORS =\r\n\r\n#----------------------------\r\n# other features\r\n#----------------------------\r\n\r\n# Create C++ interface package\r\nUSE_CPP_PACKAGE = 0\r\n\r\n#----------------------------\r\n# plugins\r\n#----------------------------\r\n\r\n# whether to use caffe integration. This requires installing caffe.\r\n# You also need to add CAFFE_PATH/build/lib to your LD_LIBRARY_PATH\r\n# CAFFE_PATH = $(HOME)/caffe\r\n# MXNET_PLUGINS += plugin/caffe/caffe.mk\r\n\r\n# WARPCTC_PATH = $(HOME)/warp-ctc\r\n# MXNET_PLUGINS += plugin/warpctc/warpctc.mk\r\n\r\n# whether to use sframe integration. This requires build sframe\r\n# git@github.com:dato-code/SFrame.git\r\n# SFRAME_PATH = $(HOME)/SFrame\r\n# MXNET_PLUGINS += plugin/sframe/plugin.mk\r\n"", ""py\r\nimport os\r\nimport time\r\nimport mxnet as mx\r\n\r\n\r\nimage_path = './images/7095e5342174b6a1e79da0ce8e6426ea.jpg'\r\n__t1 = time.time()\r\nbatch_images = [mx.image.imdecode(open(image_path, 'rb').read()) for _ in range(100)]\r\n__t2 = time.time()\r\nprint('MXNET_CPU_WORKER_NTHREADS={}, time={:.3f}'.format(os.environ.get('MXNET_CPU_WORKER_NTHREADS', 1),\r\n                                                         __t2 - __t1))\r\n\r\n"", '\r\n$ python test.py\r\nMXNET_CPU_WORKER_NTHREADS=1, time=2.104\r\n\r\n$ MXNET_CPU_WORKER_NTHREADS=2 python test.py\r\nMXNET_CPU_WORKER_NTHREADS=2, time=2.103\r\n\r\n$ MXNET_CPU_WORKER_NTHREADS=4 python test.py\r\nMXNET_CPU_WORKER_NTHREADS=4, time=2.104\r\n\r\n$ MXNET_CPU_WORKER_NTHREADS=16 python test.py\r\nMXNET_CPU_WORKER_NTHREADS=16, time=2.112\r\n']","['imgs = [mx.image.imdecode(open(f).read()) for f in img_paths]', 'GCC', 'ef850631bfea20685e63c1a099f6d5fde1301188', 'git rev-parse HEAD']",0,0
512,incubator-mxnet,1875,closed,run example/rnn/char-rnn.ipynb failed,"i am new, i got this error here

07:33:45 INFO:Start training with [gpu(0)]
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
[19:36:00] src/symbol/static_graph.cc:383: Memory efficient gradient aggregation on... to disable, set MXNET_EXEC_INPLACE_GRAD_SUM_CAP to big number
Traceback (most recent call last):
  File ""char-rnn.py"", line 120, in <module>
    epoch_end_callback=mx.callback.do_checkpoint(""obama""))
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/model.py"", line 774, in fit
    sym_gen=self.sym_gen)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/model.py"", line 244, in _train_multi_device
    executor_manager.update_metric(eval_metric, data_batch.label)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/executor_manager.py"", line 406, in update_metric
    self.curr_execgrp.update_metric(metric, labels)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/executor_manager.py"", line 262, in update_metric
    metric.update(labels_slice, texec.outputs)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/metric.py"", line 338, in update
    self.sum_metric += self._feval(label, pred)
  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/metric.py"", line 355, in feval
    return numpy_feval(label, pred)
  File ""char-rnn.py"", line 50, in Perplexity
    loss += -np.log(max(1e-10, pred[i][int(label[i])]))
TypeError: only length-1 arrays can be converted to Python scalars
",,"['This must be due to a recent refactoring of lstm example. I will try to fix it.\n', ""3q. it's been fixed. can this program support chinese language now？i want to try run a chinese languate data.\n"", 'when i run a chinese language data,seems ok? but it failed as follows: \n\n08:22:20 INFO:Epoch[0] Batch [50]   Speed: 95.20 samples/sec    Train-Perplexity=26.682578\n08:22:37 INFO:Epoch[0] Batch [100]  Speed: 93.06 samples/sec    Train-Perplexity=17.048589\n08:22:52 INFO:Epoch[0] Resetting Data Iterator\n08:22:52 INFO:Epoch[0] Train-Perplexity=13.995063\n08:22:52 INFO:Epoch[0] Time cost=49.586\n08:22:52 INFO:Saved checkpoint to ""obama-0001.params""\n08:23:09 INFO:Epoch[1] Batch [50]   Speed: 95.04 samples/sec    Train-Perplexity=7.092565\n08:23:27 INFO:Epoch[1] Batch [100]  Speed: 93.18 samples/sec    Train-Perplexity=6.897969\n08:23:42 INFO:Epoch[1] Resetting Data Iterator\n08:23:42 INFO:Epoch[1] Train-Perplexity=6.883966\n08:23:42 INFO:Epoch[1] Time cost=49.628\n08:23:42 INFO:Saved checkpoint to ""obama-0002.params""\n[20:23:42] /home/chao/dnn/mxnet/dmlc-core/include/dmlc/logging.h:235: [20:23:42] src/ndarray/ndarray.cc:227: Check failed: from.shape() == to->shape() operands shape mismatch\nTraceback (most recent call last):\n  File ""char-rnn.py"", line 268, in <module>\n    num_label=len(vocab) + 1, arg_params=arg_params, ctx=mx.gpu(), dropout=0.2)\n  File ""/home/chao/dnn/mxnet/example/rnn/rnn_model.py"", line 40, in **init**\n    arg_params[key].copyto(self.executor.arg_dict[key])\n  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/ndarray.py"", line 434, in copyto\n    return NDArray._copyto(self, out=other)\n  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/ndarray.py"", line 1081, in unary_ndarray_function\n    c_array(ctypes.c_char_p, [])))\n  File ""/usr/local/lib/python2.7/dist-packages/mxnet-0.5.0-py2.7.egg/mxnet/base.py"", line 77, in check_call\n    raise MXNetError(py_str(_LIB.MXGetLastError()))\nmxnet.base.MXNetError: [20:23:42] src/ndarray/ndarray.cc:227: Check failed: from.shape() == to->shape() operands shape mismatch\n', ""when i change checkpoint 75 in the code to checkpoint2 , there is no this error.\nbut i can't handle chinese file now , can this code support it? 3q.\n"", '3ks. support unicode is done. ＾＿＾\n']",[],[],0,0
513,incubator-mxnet,11407,closed,Corrupt image fails Caffe converter test,"http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/PR-11358/9/pipeline

",Disabled test Flaky Test,"['It seems like http://writm.com/wp-content/uploads/2016/08/Cat-hd-wallpapers.jpg is gone now and thus the test is failing. This is breaking CI.', 'can’t you just use any cat picture as a replacement?', '@marcoabreu Thank you for reporting the Flaky test, this is added to the to do test improvements', ""it's there: https://github.com/dmlc/web-data/raw/master/mxnet/doc/tutorials/python/predict_image/cat.jpg"", 'Still getting occasional failures pulling from github.  \r\n\r\nSample output:\r\n```\r\nINFO:root:getting image https://github.com/dmlc/web-data/raw/master/mxnet/doc/tutorials/python/predict_image/cat.jpg\r\nOpenCV(3.4.1) Error: Assertion failed (scn == 3 || scn == 4) in cvtColor, file /io/opencv/modules/imgproc/src/color.cpp, line 11115\r\nTraceback (most recent call last):\r\n  File ""tools/caffe_converter/test_converter.py"", line 109, in <module>\r\n    main()\r\n  File ""tools/caffe_converter/test_converter.py"", line 103, in main\r\n    test_model_weights_and_outputs(m, args.image_url, gpus[0])\r\n  File ""tools/caffe_converter/test_converter.py"", line 77, in test_model_weights_and_outputs\r\n    mean_diff_allowed=1e-03, max_diff_allowed=1e-01)\r\n  File ""/work/mxnet/tools/caffe_converter/compare_layers.py"", line 120, in convert_and_compare_caffe_to_mxnet\r\n    img_rgb = read_image(image_url, image_dims, caffe_mean)\r\n  File ""/work/mxnet/tools/caffe_converter/compare_layers.py"", line 51, in read_image\r\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\ncv2.error: OpenCV(3.4.1) /io/opencv/modules/imgproc/src/color.cpp:11115: error: (-215) scn == 3 || scn == 4 in function cvtColor\r\n```\r\n\r\nReference failed build:\r\n http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/incubator-mxnet/detail/master/1207/pipeline', 'Caffe converter should be deprecated in 2.0 since caffe maintenance has been stopped for a long time.']","['\r\nINFO:root:getting image http://writm.com/wp-content/uploads/2016/08/Cat-hd-wallpapers.jpg\r\n\r\nOpenCV(3.4.1) Error: Assertion failed (scn == 3 || scn == 4) in cvtColor, file /io/opencv/modules/imgproc/src/color.cpp, line 11115\r\n\r\nTraceback (most recent call last):\r\n\r\n  File ""tools/caffe_converter/test_converter.py"", line 108, in <module>\r\n\r\n    main()\r\n\r\n  File ""tools/caffe_converter/test_converter.py"", line 102, in main\r\n\r\n    test_model_weights_and_outputs(m, args.image_url, gpus[0])\r\n\r\n  File ""tools/caffe_converter/test_converter.py"", line 77, in test_model_weights_and_outputs\r\n\r\n    mean_diff_allowed=1e-03, max_diff_allowed=1e-01)\r\n\r\n  File ""/work/mxnet/tools/caffe_converter/compare_layers.py"", line 120, in convert_and_compare_caffe_to_mxnet\r\n\r\n    img_rgb = read_image(image_url, image_dims, caffe_mean)\r\n\r\n  File ""/work/mxnet/tools/caffe_converter/compare_layers.py"", line 51, in read_image\r\n\r\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n\r\ncv2.error: OpenCV(3.4.1) /io/opencv/modules/imgproc/src/color.cpp:11115: error: (-215) scn == 3 || scn == 4 in function cvtColor\r\n\r\n\r\n\r\nbuild.py: 2018-06-26 22:42:35,570 Running of command in container failed (1): nvidia-docker run --rm -t --shm-size=500m -v /home/jenkins_slave/workspace/it-caffe:/work/mxnet -v /home/jenkins_slave/workspace/it-caffe/build:/work/build -v /tmp/ci_ccache:/work/ccache -u 1001:1001 -e CCACHE_MAXSIZE=500G -e CCACHE_TEMPDIR=/tmp/ccache -e CCACHE_DIR=/work/ccache -e CCACHE_LOGFILE=/tmp/ccache.log mxnetci/build.ubuntu_gpu /work/runtime_functions.sh integrationtest_ubuntu_gpu_caffe\r\n\r\nbuild.py: 2018-06-26 22:42:35,570 You can try to get into the container by using the following command: nvidia-docker run --rm -t --shm-size=500m -v /home/jenkins_slave/workspace/it-caffe:/work/mxnet -v /home/jenkins_slave/workspace/it-caffe/build:/work/build -v /tmp/ci_ccache:/work/ccache -u 1001:1001 -ti --entrypoint /bin/bash -e CCACHE_MAXSIZE=500G -e CCACHE_TEMPDIR=/tmp/ccache -e CCACHE_DIR=/work/ccache -e CCACHE_LOGFILE=/tmp/ccache.log mxnetci/build.ubuntu_gpu /work/runtime_functions.sh integrationtest_ubuntu_gpu_caffe\r\n\r\nTraceback (most recent call last):\r\n\r\n  File ""ci/build.py"", line 358, in <module>\r\n\r\n    sys.exit(main())\r\n\r\n  File ""ci/build.py"", line 291, in main\r\n\r\n    command=command, docker_registry=args.docker_registry, local_ccache_dir=args.ccache_dir)\r\n\r\n  File ""ci/build.py"", line 185, in container_run\r\n\r\n    raise subprocess.CalledProcessError(ret, cmd)\r\n\r\nsubprocess.CalledProcessError: Command \'nvidia-docker run --rm -t --shm-size=500m -v /home/jenkins_slave/workspace/it-caffe:/work/mxnet -v /home/jenkins_slave/workspace/it-caffe/build:/work/build -v /tmp/ci_ccache:/work/ccache -u 1001:1001 -e CCACHE_MAXSIZE=500G -e CCACHE_TEMPDIR=/tmp/ccache -e CCACHE_DIR=/work/ccache -e CCACHE_LOGFILE=/tmp/ccache.log mxnetci/build.ubuntu_gpu /work/runtime_functions.sh integrationtest_ubuntu_gpu_caffe\' returned non-zero exit status 1\r\n\r\nscript returned exit code 1\r\n']",[],0,0
514,incubator-mxnet,6628,closed,[C++][Tutorial Error] Model file for image-classification-predict.cc seems like broken,"Hi folks. 😄 

Now, I'm trying to run [image-classification-predict.cc](https://github.com/dmlc/mxnet/blob/master/example/image-classification/predict-cpp/image-classification-predict.cc) as a sample code of image classification with using pre-trained model.

I'm facing an error at the point of creating a predictor like,



The error I got is like,


If any of you know how to solve and run this code, please help me out.

Thanks in advance! 🎉 

## Environment info
Operating System: OS X 10.12.4

Compiler: AppleClang

Package used (Python/R/Scala/Julia): C++

MXNet commit hash (): 918d48526481cf424197079ae47841e1b8afe399

## Error Message:
The whole error message is as below.



## Minimum reproducible example
I only modified the name of the model files and their paths.
I use the models downloaded from [here](https://pan.baidu.com/s/1sjXKrqX).
And the image I used was a size of 240 x 240.
![apple](https://user-images.githubusercontent.com/19764434/26961671-85bf35de-4d1b-11e7-9c48-f25434ff8638.jpg)


Since this is running at my own local project, I wrote a  like this.



## Steps to reproduce
I tried to run this program with the command of  and received that error.
",,"[""I'll be appreciate it if any of you could provide me any hints or thoughts for my issue!!"", 'It seems like that the model file was broken for some reasons.\r\n\r\nI changed a `.param` file to a different file and I could make it to pass through creating a predictor.', 'yes,replace the json and params to http://data.dmlc.ml/models/imagenet/inception-bn/\r\nEverything is OK~!']","['cpp\r\nMXPredCreate((const char*)json_data.GetBuffer(),\r\n                 (const char*)param_data.GetBuffer(),\r\n                 param_data.GetLength(),\r\n                 dev_type,\r\n                 dev_id,\r\n                 num_input_nodes,\r\n                 input_keys,\r\n                 input_shape_indptr,\r\n                 input_shape_data,\r\n                 &pred_hnd);\r\n    assert(pred_hnd);\r\n', 'bash\r\nmxnet/dmlc-core/include/dmlc/logging.h:304: [19:36:24] src/operator/./concat-inl.h:166: Check failed: shape_assign(&(*in_shape)[i], dshape) Incompatible input shape: expected (1,0,14,14), got (1,320,13,13)\r\n', 'bash\r\n[19:36:24] src/nnvm/legacy_json_util.cc:190: Loading symbol saved by previous version v0.8.0. Attempting to up\r\n\r\ngrade...\r\n[19:36:24] src/operator/./softmax_output-inl.h:369: Softmax symbol is renamed to SoftmaxOutput. This API will be deprecated in Dec, 2015\r\n[19:36:24] src/nnvm/legacy_json_util.cc:198: Symbol successfully upgraded!\r\n[19:36:24] /Users/chicn/Programs/oss/mxnet/dmlc-core/include/dmlc/logging.h:304: [19:36:24] src/operator/./concat-inl.h:166: Check failed: shape_assign(&(*in_shape)[i], dshape) Incompatible input shape: expected (1,0,14,14), got (1,320,13,13)\r\n\r\nStack trace returned 10 entries:\r\n[bt] (0) 0   libmxnet.so                         0x0000000104c3f078 _ZN4dmlc15LogMessageFatalD2Ev + 40\r\n[bt] (1) 1   libmxnet.so                         0x0000000105381ba6 _ZNK5mxnet2op10ConcatProp10InferShapeEPNSt3__16vectorIN4nnvm6TShapeENS2_9allocatorIS5_EEEES9_S9_ + 1686\r\n[bt] (2) 2   libmxnet.so                         0x00000001053494ae _ZN5mxnet2op16OpPropInferShapeERKN4nnvm9NodeAttrsEPNSt3__16vectorINS1_6TShapeENS5_9allocatorIS7_EEEESB_ + 878\r\n[bt] (3) 3   libmxnet.so                         0x000000010557dc2c _ZZN4nnvm4pass12_GLOBAL__N_19InferAttrINS_6TShapeEZNKS1_3$_0clENS_5GraphEEUlRKS3_E_DnEES5_OS5_T_PKcSC_SC_SC_SC_T0_T1_ENKUljbE_clEjb + 2204\r\n[bt] (4) 4   libmxnet.so                         0x000000010557c61a _ZNSt3__110__function6__funcIN4nnvm4pass12_GLOBAL__N_13$_0ENS_9allocatorIS5_EEFNS2_5GraphES8_EEclEOS8_ + 3098\r\n[bt] (5) 5   libmxnet.so                         0x0000000105567adb _ZN4nnvm11ApplyPassesENS_5GraphERKNSt3__16vectorINS1_12basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEENS6_IS8_EEEE + 795\r\n[bt] (6) 6   libmxnet.so                         0x0000000105240cbb _ZN4nnvm9ApplyPassENS_5GraphERKNSt3__112basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEE + 187\r\n[bt] (7) 7   libmxnet.so                         0x000000010524412b _ZN4nnvm4pass10InferShapeENS_5GraphENSt3__16vectorINS_6TShapeENS2_9allocatorIS4_EEEENS2_12basic_stringIcNS2_11char_traitsIcEENS5_IcEEEE + 891\r\n[bt] (8) 8   libmxnet.so                         0x000000010524db75 MXPredCreatePartialOut + 8309\r\n[bt] (9) 9   libmxnet.so                         0x000000010524baf9 MXPredCreate + 25\r\n\r\nAssertion failed: (pred_hnd), function main, file /Users/chicn/Desktop/test_mtcnn/image_classification_predict_ex.cpp, line 241.\r\n\r\nProcess finished with exit code 6\r\n', 'cmake\r\ncmake_minimum_required(VERSION 3.7)\r\nproject(image_classification_predict_ex)\r\n\r\nset(CMAKE_CXX_STANDARD 11)\r\nfile(COPY ${PROJECT_SOURCE_DIR}/lib/libmxnet.so ${PROJECT_SOURCE_DIR}/lib/libmxnet.a\r\n            DESTINATION ${PROJECT_BINARY_DIR}/lib)\r\nfile(COPY ${PROJECT_SOURCE_DIR}/model DESTINATION ${PROJECT_BINARY_DIR}/)\r\nfile(COPY ${PROJECT_SOURCE_DIR}/image DESTINATION ${PROJECT_BINARY_DIR}/)\r\n\r\nset(IMAGE_CLASSIFICATION_SOURCES image_classification_predict_ex.cpp)\r\nadd_executable(image_classification_predict_ex ${IMAGE_CLASSIFICATION_SOURCES})\r\n\r\n# Add OpenCV\r\nfind_package(OpenCV REQUIRED)\r\ninclude_directories(${OpenCV_INCLUDE_DIRS})\r\ntarget_link_libraries(image_classification_predict_ex ${OpenCV_LIBS})\r\n\r\n\r\n# Add lib\r\ninclude_directories(${PROJECT_SOURCE_DIR}/lib)\r\n\r\n# Add MxNet\r\nfind_library(LIBMXNET NAMES mxnet PATHS ${PROJECT_SOURCE_DIR}/lib)\r\ntarget_link_libraries(image_classification_predict_ex ${LIBMXNET})\r\n']","['git rev-parse HEAD', 'CMakeLists.txt', './image_classification_predict image/apple.jpg']",0,0
515,incubator-mxnet,3668,closed,Difficult to get/save symbols in new API mxnet.module,"I've been using MXNET for a while and get used to the interface mxnet.model.FeedForward, which has a method save_checkpoint(). This method returns a JSON file of symbol definition and .params for saving args and aux params. But with the new API mxnet.module I can't figure out how to get/save the symbol easily in this module, and it makes more complex to use or finetune on models based on this interface, since loading a model requires a JSON file for symbol definition.

In  there's a property  which allows us to get the symbol in module. But in other inherit classes like  and , we can comprise/stack modules to build more complex networks. This makes harder to access the whole symbol in these modules, even though we can get symbols of each submodules in recursive way and concat them, but this is still not straightforward for me.",,"['@pluskid How about a save_symbol() or save_checkpoint method for module?\n', '@piiswrong checkpoint saving and loading is already supported for plain `Module`. For example, the built-in `checkpoint` callback works fine in the same way. I think @bearsroom is talking about more complicated modules like `SequentialModule` and `BucketingModule`. In some cases, there are multiple symbols (like bucketing). I was thinking about saving all the instantiated instances as a key-value dictionary. But that might not be enough during testing. In some other cases, such a `PythonModule`, there might not even be any symbol associated with it.\n\nCurrently a better solution might be to isolate the network definition functions of your experiment in a separate file, and load that file to define networks in both training and testing, and then it will work even if no symbols are loaded. But I agree this is not ideal for deploying.\n', ""@pluskid  Saving and loading params using `load_params` and `save_params` in `Module` works fine for me, but I was thinking about another advantage of having a complete definition of network: We can easily check every component and visualize the network using `mxnet.visualization` (it requires symbol definitions too!). Also it's more straightforward for caffe people, as the whole network is well defined in a single prototxt file.\n"", 'This issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!']",[],"['mxnet.module.BaseModule', 'symbol', 'mxnet.module.Module', 'mxnet.module.SequentialModule']",0,0
