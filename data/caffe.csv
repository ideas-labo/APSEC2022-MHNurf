,Repository,Number,State,Title,Body,Labels,Comments,Codes,Commands,class,related
0,caffe,3075,closed,strange result when running blvc_reference_caffenet model,"Hi,

I tried to run the example here: https://github.com/BVLC/caffe/blob/master/examples/00-classification.ipynb, but find that my result is quite different from the notebook's description,

Here is my result:
**Predicted class is #48281.**

And the example says:
**Predicted class is #281.**

Does anyone know why here it's different?

BTW, first I think it might be category#48 and category#281, but now I'm sure that it's not, since I check the _/data/ilsvrc12/synset_words.txt_ and think they're unrelated. I have done several times with the newest caffe repos and download the models from the _readme_'s url: [http://dl.caffe.berkeleyvision.org/bvlc_reference_caffenet.caffemodel](http://dl.caffe.berkeleyvision.org/bvlc_reference_caffenet.caffemodel), I tried to download(Model Zoo) with **./scripts/download_model_binary.py models/bvlc_reference_caffenet/** but it's too slow so I don't test this model, but I wonder that maybe this model is the same as the previous url.

Any suggestions will be much appreciated, Thanks.
",,"[""You need to do\nout['prob'].argmax(axis=1)\nto get the prediction for each item in the batch.\n\nOtherwise, it's the argmax across the flattened array which could include images from other batches, if your batchsize isn't set to 1.\n"", 'Also:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n', 'Thank you very much @seanbell , and for your suggestion. I just found that google group which is also very useful!\n']",[],[],1,0
1,caffe,4102,closed,Change the batch_size by the method Reshape(),"I used a deploy.prototxt to initialize a new net, the batch_size is 256, loading from the deploy.prototxt



when I use the following code:



As after I run the forward(),the runing time is about 13 ms.
But when I change the size in deploy.prototxt,the forward() runing time as follows:

prototxt_size: 256  new_batch_size: 16    runing time: 13ms
prototxt_size: 16   new_batch_size: 16     runing time: 1.5ms
prototxt_size: 1024 new_batch_size: 16      runing time: 60ms

the method Reshape() seems did not work.
Thanks~
",,"['One probably reason I found in the code is : \n\nIn blob.cpp:\n\nvoid Blob<Dtype>::Reshape(const vector<int>& shape) {\n    ...\n\n  if (count_ > capacity_) {\n    capacity_ = count_;\n    data_.reset(new SyncedMemory(capacity_ \\* sizeof(Dtype)));\n    diff_.reset(new SyncedMemory(capacity_ \\* sizeof(Dtype)));\n  }\n}\n\nthe line ""if (count_ > capacity_) "" means if the new batch_size is bigger than the old one, it will apply for more memory, and if the new batch_size is smaller than the old one , it will do nothing.\nWhy do like this?\n', '@7oud the reason is that constantly reallocating memory on the GPU can be inefficient if you are changing blob sizes every iteration.\n\nIf you want to hard-code a batchsize into your net `deploy.prototxt` and then change it at runtime, I recommend making the batchsize much smaller (e.g. 1).\n\nIn your above experiments, after calling `net.Reshape`, are the blobs reshaped correctly (the input blob, and all other intermediate blobs)?  Do they all have batchsize 16?\n', ""@seanbell Yes, after calling `net.Reshape`, the blobs reshaped correctly. e.g. `Blob->shape_` has changed to the new batch size. But the `Blob->count_` may not equal to `Blob->capacity_`.\n\nSo when the batchsize changes to bigger, it must reallocate bigger memory on gpu and `Blob->count_ == Blob->capacity_, data_.reset(), diff_.reset()`. On the contray, when the batchsize changes to smaller, it won't  reallocate smaller memory for efficiency, so `Blob->count_ < Blob->capacity_` and the `net->forward` time may take more time when the new batchsize much smaller than the orginal one, because much computaition is wasted.\n"", ""Adding something like:\n\n```\n// in Blob::Reshape \n  static const int kShrinkageFactor = 2;\n  if (count_ < capacity_ / kShrinkageFactor) {\n    capacity_ = count_;\n    data_.reset(new SyncedMemory(capacity_ * sizeof(Dtype)));\n    diff_.reset(new SyncedMemory(capacity_ * sizeof(Dtype)));\n  }\n```\n\nmight help for this. It's a tradeoff that might or might not work for your problem.\n"", ""@7oud I don't understand why extra unused capacity will make things run slower.  Every layer uses the Blob shape metadata to index into the blobs, so any allocated but unused memory should not cause a slowdown in the computation.  If the unused memory is used by some function, then that's a bug in caffe.  Layers should not access data outside the blob shape metadata.\n"", '@seanbell Actually it was slow down. you can do some experiments to verify the problem. I think the specific function (e.g. convolution) may run on the ""capacity"" not on the ""blob"", it means it won\'t distinguish ""used"" or ""unused"" memory.\n\n@shelhamer Could you give some advice? Thanks!\n', ""@7oud that's not possible since `capacity_` is a protected variable (https://github.com/BVLC/caffe/blob/14dc012b782c9296f370f8cb620104396fc1b414/include/caffe/blob.hpp#L274).  Layers can only use the `shape` and `count` as reported by the Blob.\n"", '@seanbell Could you repeat the experiment and tell me your result?\n', '@seanbell is right, and this does not seem to be reproducible.\n']","['\ninput: ""data""\ninput_shape {\n  dim: 256\n  dim: 3\n  dim: 227\n  dim: 227\n}\n', '\n////\nint new_batch_size = 16;\nBlob<float>* input_layer = net_->input_blobs()[0];\ninput_layer->Reshape(new_batch_size, num_channels_,input_geometry_.height, input_geometry_.width);\nnet_->Reshape();\n////\n']",[],1,0
2,caffe,5643,open,Convert caffemodel into C++/python scripts to improve detection speed?,"Hi all, I have a question to discuss with anyone who is interested in mobile applications. I have trained a caffemodel and the result is good(~35FPS) when I test it with my desktop, which is equipped with Nvidia Titan XP. But when I transform all these work into Nvidia Tx2, it can work but the detection speed is slow (2FPS). To solve this problem, I get an idea. Since I have got the trained model, I can convert the forward pass into C++/python scripts and get rid of caffe framework. Anyone has ever done same kind of things before and do you think it's workable and can improve detection speed? Any discussion is appreciated.
Thx",,"[""No that won't help you get more speed. The Caffe framework is already highly optimized C++ and CUDA code. Make sure however that you use cuDNN on your Tx2."", 'Also have a look at TensorRT to speed things up by combining operations and by doing inference in 8 bit.', '@naibaf7 Hi, thanks for your reply. I have used cuDNN on TX2. So it seems that there is no way to improve speed except for changing another framework. Can I say that? If so, is there any advice for another framework?\r\nthx~', '@willyd thx for your reply. I will check more details. ^ ^']",[],[],1,0
3,caffe,3086,closed,PyCaffe backward() produces zero gradients when GPU mode,"I'm working on generating saliency maps though gradient data, as in [this](http://www.robots.ox.ac.uk/~vgg/publications/2014/Simonyan14a/simonyan14a.pdf) famous paper.

It works well when using pycaffe in CPU mode. When in GPU mode, all the gradients computed by the backward pass are zeros.

I'm using Ubuntu 14.04, VGG Net without a Data Layer and I set force_backward : true.

This is the code that works



This works, indeed


",,"[""Closing as there is not enough information here to suggest a bug; how are you reading the gradient?\n\nIf there's still a problem you can reproduce with the latest Caffe master, feel free to open a new issue with instructions to recreate it; see https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md.\n"", ""@fferrara Were you able to resolve it? I'm also facing the same error\n"", ""Actually, I kind of gave up. I didn't try the latest master branch, because I can still use CPU for producing saliency maps.\n"", ""I see. I also did give up earlier, but now have to look for a way to fix it since the CPU is getting too slow for me. I'll try this with the master branch and create a new issue there.\n""]","[""\nimport caffe\nimport numpy as np\ncaffe.set_mode_gpu()\nnet = caffe.Net('deploy_saliency.prototxt', 'models/snapshot.caffemodel', caffe.TEST)\n\nin_ = 'data'\ntransformer = caffe.io.Transformer(\n                {in_: net.blobs[in_].data.shape})\ntransformer.set_transpose(in_, (2, 0, 1))\ntransformer.set_mean(in_, np.array([104, 117, 123]))\ntransformer.set_raw_scale(in_, 255)\ntransformer.set_channel_swap(in_, (2, 1, 0))\nimg = 'example_class_2.jpg'\nimage = caffe.io.load_image(img)\ninput_ = transformer.preprocess(in_, image)\nnet.blobs[in_].data[...] = input_\nnet.forward()\nlabel = np.zeros((1, 5))\nlabel[0,2] = 1\nnet.backward(**{'prob':label})\n"", ""\nimport caffe\nimport numpy as np\ncaffe.set_mode_cpu()\nnet = caffe.Net('deploy_saliency.prototxt', 'models/snapshot.caffemodel', caffe.TEST)\n\nin_ = 'data'\ntransformer = caffe.io.Transformer(\n                {in_: net.blobs[in_].data.shape})\ntransformer.set_transpose(in_, (2, 0, 1))\ntransformer.set_mean(in_, np.array([104, 117, 123]))\ntransformer.set_raw_scale(in_, 255)\ntransformer.set_channel_swap(in_, (2, 1, 0))\nimg = 'example_class_2.jpg'\nimage = caffe.io.load_image(img)\ninput_ = transformer.preprocess(in_, image)\nnet.blobs[in_].data[...] = input_\nnet.forward()\nlabel = np.zeros((1, 5))\nlabel[0,2] = 1\nnet.backward(**{'prob':label})\n""]",[],1,0
4,caffe,2448,closed,CPU usage at a low level,"Hi everyone. When I run Caffe with CPU usage close to 100%,   each iteration needs only about 0.34s. However, after several iterations the CPU usage drops significantly, and each iteration needs about > 5s, and most of the time is for data IO. 

My system is Ubuntu 14.04 and the data layer is LMDB. Does anybody know how to solve the problem? Thanks!

Here is the comparison of running time:
1. High CPU usage:


1. Low CPU usage



Thanks! 
",,"[""@bearpaw Hey dude, are you using CPU only? My lab's server does not have GPUs so I want to use CPU. But I can only use one CPU core. So I am looking around to see how to configure caffe/OpenBLAS to use all the CPU cores. Thanks.\n"", 'Please ask usage questions on the caffe-users list. Thanks!\n']","['\nI0512 22:09:43.043788  7012 caffe.cpp:273] Average time per layer: \nI0512 22:09:43.043794  7012 caffe.cpp:276]       data   forward: 2.7368 ms.\nI0512 22:09:43.043799  7012 caffe.cpp:279]       data   backward: 0.00166464 ms.\nI0512 22:09:43.043804  7012 caffe.cpp:276]      conv1   forward: 31.2199 ms.\nI0512 22:09:43.043812  7012 caffe.cpp:279]      conv1   backward: 49.7723 ms.\nI0512 22:09:43.043818  7012 caffe.cpp:276]      relu1   forward: 2.58098 ms.\nI0512 22:09:43.043823  7012 caffe.cpp:279]      relu1   backward: 3.68689 ms.\nI0512 22:09:43.043824  7012 caffe.cpp:276]      pool1   forward: 4.98866 ms.\nI0512 22:09:43.043828  7012 caffe.cpp:279]      pool1   backward: 10.5119 ms.\nI0512 22:09:43.043829  7012 caffe.cpp:276]      norm1   forward: 0.975877 ms.\nI0512 22:09:43.043833  7012 caffe.cpp:279]      norm1   backward: 2.00289 ms.\nI0512 22:09:43.043835  7012 caffe.cpp:276]      conv2   forward: 10.6961 ms.\nI0512 22:09:43.043838  7012 caffe.cpp:279]      conv2   backward: 32.7071 ms.\nI0512 22:09:43.043841  7012 caffe.cpp:276]      relu2   forward: 0.74297 ms.\nI0512 22:09:43.043844  7012 caffe.cpp:279]      relu2   backward: 1.14658 ms.\nI0512 22:09:43.043846  7012 caffe.cpp:276]      pool2   forward: 1.8016 ms.\nI0512 22:09:43.043848  7012 caffe.cpp:279]      pool2   backward: 5.62796 ms.\nI0512 22:09:43.043851  7012 caffe.cpp:276]      norm2   forward: 0.751883 ms.\nI0512 22:09:43.043853  7012 caffe.cpp:279]      norm2   backward: 1.68432 ms.\nI0512 22:09:43.043858  7012 caffe.cpp:276]      conv3   forward: 6.93256 ms.\nI0512 22:09:43.043859  7012 caffe.cpp:279]      conv3   backward: 20.4368 ms.\nI0512 22:09:43.043862  7012 caffe.cpp:276]      relu3   forward: 0.193908 ms.\nI0512 22:09:43.043864  7012 caffe.cpp:279]      relu3   backward: 0.295624 ms.\nI0512 22:09:43.043867  7012 caffe.cpp:276]      conv4   forward: 6.88309 ms.\nI0512 22:09:43.043869  7012 caffe.cpp:279]      conv4   backward: 20.3601 ms.\nI0512 22:09:43.043872  7012 caffe.cpp:276]      relu4   forward: 0.193293 ms.\nI0512 22:09:43.043874  7012 caffe.cpp:279]      relu4   backward: 0.294272 ms.\nI0512 22:09:43.043879  7012 caffe.cpp:276]      conv5   forward: 6.78724 ms.\nI0512 22:09:43.043881  7012 caffe.cpp:279]      conv5   backward: 20.3044 ms.\nI0512 22:09:43.043884  7012 caffe.cpp:276]      relu5   forward: 0.192744 ms.\nI0512 22:09:43.043886  7012 caffe.cpp:279]      relu5   backward: 0.297262 ms.\nI0512 22:09:43.043889  7012 caffe.cpp:276]        fc6   forward: 15.4341 ms.\nI0512 22:09:43.043892  7012 caffe.cpp:279]        fc6   backward: 24.1346 ms.\nI0512 22:09:43.043895  7012 caffe.cpp:276]      relu6   forward: 0.0837414 ms.\nI0512 22:09:43.043897  7012 caffe.cpp:279]      relu6   backward: 0.126348 ms.\nI0512 22:09:43.043900  7012 caffe.cpp:276]      drop6   forward: 0.204159 ms.\nI0512 22:09:43.043902  7012 caffe.cpp:279]      drop6   backward: 0.119359 ms.\nI0512 22:09:43.043905  7012 caffe.cpp:276]        fc7   forward: 5.93108 ms.\nI0512 22:09:43.043907  7012 caffe.cpp:279]        fc7   backward: 10.1628 ms.\nI0512 22:09:43.043910  7012 caffe.cpp:276]      relu7   forward: 0.0824173 ms.\nI0512 22:09:43.043912  7012 caffe.cpp:279]      relu7   backward: 0.128106 ms.\nI0512 22:09:43.043925  7012 caffe.cpp:276]      drop7   forward: 0.198971 ms.\nI0512 22:09:43.043930  7012 caffe.cpp:279]      drop7   backward: 0.121266 ms.\nI0512 22:09:43.043931  7012 caffe.cpp:276]        fc8   forward: 11.797 ms.\nI0512 22:09:43.043934  7012 caffe.cpp:279]        fc8   backward: 21.8924 ms.\nI0512 22:09:43.043937  7012 caffe.cpp:276]       loss   forward: 0.793592 ms.\nI0512 22:09:43.043941  7012 caffe.cpp:279]       loss   backward: 0.374767 ms.\nI0512 22:09:43.043953  7012 caffe.cpp:284] Average Forward pass: 113.092 ms.\nI0512 22:09:43.043956  7012 caffe.cpp:286] Average Backward pass: 227.2 ms.\nI0512 22:09:43.043962  7012 caffe.cpp:288] Average Forward-Backward: 340.386 ms.\nI0512 22:09:43.043965  7012 caffe.cpp:290] Total Time: 17019.3 ms.\nI0512 22:09:43.043969  7012 caffe.cpp:291] *** Benchmark ends ***\n', '\nI0512 21:52:33.160395 10122 caffe.cpp:273] Average time per layer: \nI0512 21:52:33.160399 10122 caffe.cpp:276]       data   forward: 5222.5 ms.\nI0512 21:52:33.160403 10122 caffe.cpp:279]       data   backward: 0.00177088 ms.\nI0512 21:52:33.160405 10122 caffe.cpp:276]      conv1   forward: 30.1762 ms.\nI0512 21:52:33.160408 10122 caffe.cpp:279]      conv1   backward: 48.7598 ms.\nI0512 21:52:33.160410 10122 caffe.cpp:276]      relu1   forward: 2.53738 ms.\nI0512 21:52:33.160413 10122 caffe.cpp:279]      relu1   backward: 3.70294 ms.\nI0512 21:52:33.160415 10122 caffe.cpp:276]      pool1   forward: 4.86257 ms.\nI0512 21:52:33.160418 10122 caffe.cpp:279]      pool1   backward: 10.3474 ms.\nI0512 21:52:33.160420 10122 caffe.cpp:276]      norm1   forward: 0.970911 ms.\nI0512 21:52:33.160423 10122 caffe.cpp:279]      norm1   backward: 1.96504 ms.\nI0512 21:52:33.160424 10122 caffe.cpp:276]      conv2   forward: 10.5993 ms.\nI0512 21:52:33.160437 10122 caffe.cpp:279]      conv2   backward: 32.0202 ms.\nI0512 21:52:33.160440 10122 caffe.cpp:276]      relu2   forward: 0.744714 ms.\nI0512 21:52:33.160442 10122 caffe.cpp:279]      relu2   backward: 1.13676 ms.\nI0512 21:52:33.160444 10122 caffe.cpp:276]      pool2   forward: 1.78942 ms.\nI0512 21:52:33.160447 10122 caffe.cpp:279]      pool2   backward: 5.45584 ms.\nI0512 21:52:33.160449 10122 caffe.cpp:276]      norm2   forward: 0.75441 ms.\nI0512 21:52:33.160452 10122 caffe.cpp:279]      norm2   backward: 1.70248 ms.\nI0512 21:52:33.160454 10122 caffe.cpp:276]      conv3   forward: 6.74193 ms.\nI0512 21:52:33.160456 10122 caffe.cpp:279]      conv3   backward: 20.059 ms.\nI0512 21:52:33.160459 10122 caffe.cpp:276]      relu3   forward: 0.1937 ms.\nI0512 21:52:33.160465 10122 caffe.cpp:279]      relu3   backward: 0.29271 ms.\nI0512 21:52:33.160477 10122 caffe.cpp:276]      conv4   forward: 6.73032 ms.\nI0512 21:52:33.160481 10122 caffe.cpp:279]      conv4   backward: 20.0403 ms.\nI0512 21:52:33.160485 10122 caffe.cpp:276]      relu4   forward: 0.193898 ms.\nI0512 21:52:33.160497 10122 caffe.cpp:279]      relu4   backward: 0.295028 ms.\nI0512 21:52:33.160501 10122 caffe.cpp:276]      conv5   forward: 6.69046 ms.\nI0512 21:52:33.160513 10122 caffe.cpp:279]      conv5   backward: 20.2724 ms.\nI0512 21:52:33.160519 10122 caffe.cpp:276]      relu5   forward: 0.193786 ms.\nI0512 21:52:33.160532 10122 caffe.cpp:279]      relu5   backward: 0.29513 ms.\nI0512 21:52:33.160537 10122 caffe.cpp:276]        fc6   forward: 15.8236 ms.\nI0512 21:52:33.160542 10122 caffe.cpp:279]        fc6   backward: 24.2208 ms.\nI0512 21:52:33.160553 10122 caffe.cpp:276]      relu6   forward: 0.0840685 ms.\nI0512 21:52:33.160559 10122 caffe.cpp:279]      relu6   backward: 0.125889 ms.\nI0512 21:52:33.160574 10122 caffe.cpp:276]      drop6   forward: 0.206337 ms.\nI0512 21:52:33.160578 10122 caffe.cpp:279]      drop6   backward: 0.119312 ms.\nI0512 21:52:33.160591 10122 caffe.cpp:276]        fc7   forward: 6.01617 ms.\nI0512 21:52:33.160595 10122 caffe.cpp:279]        fc7   backward: 10.2691 ms.\nI0512 21:52:33.160601 10122 caffe.cpp:276]      relu7   forward: 0.083296 ms.\nI0512 21:52:33.160615 10122 caffe.cpp:279]      relu7   backward: 0.128798 ms.\nI0512 21:52:33.160619 10122 caffe.cpp:276]      drop7   forward: 0.199663 ms.\nI0512 21:52:33.160624 10122 caffe.cpp:279]      drop7   backward: 0.121845 ms.\nI0512 21:52:33.160635 10122 caffe.cpp:276]        fc8   forward: 11.7489 ms.\nI0512 21:52:33.160640 10122 caffe.cpp:279]        fc8   backward: 21.8078 ms.\nI0512 21:52:33.160646 10122 caffe.cpp:276]       loss   forward: 0.804949 ms.\nI0512 21:52:33.160660 10122 caffe.cpp:279]       loss   backward: 0.392463 ms.\nI0512 21:52:33.160686 10122 caffe.cpp:284] Average Forward pass: 5331.43 ms.\nI0512 21:52:33.160693 10122 caffe.cpp:286] Average Backward pass: 224.558 ms.\nI0512 21:52:33.160701 10122 caffe.cpp:288] Average Forward-Backward: 5556.07 ms.\nI0512 21:52:33.160708 10122 caffe.cpp:290] Total Time: 277804 ms.\nI0512 21:52:33.160714 10122 caffe.cpp:291] *** Benchmark ends ***\n']",[],1,0
5,caffe,2322,closed,"loss very small 0.0002 but accuracy ""not that high""","I have trained a ConvNet and I am getting a loss of 0.0002. The output of the softmax containing the votes for each class is also very high for one class (0.99 in general, but some are also 0.8) and very low for the others.
Wouldn't that mean that the network is doing very accurate predictions? why am I then getting an accuracy of ""only"" 80%?

Thanks!
",,"['would that mean that the network is learning my data set ""by heart"" in the training phase? Is there a way to avoid this?\n', 'Please ask modeling questions on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) group or refer to general machine learning tutorials and tips.\n']",[],[],1,0
6,caffe,6557,closed,Caffe hang without any error prompt at Creating layer data when using  fine-tuning train,"Thank you for watching, I have spent lots of time but cannot find any solution.
## problem
when I was doing fine-tuning train, caffe hang without any error when  
*[layer_factory.hpp:77] Creating layer data*  
* my console shows that caffe initializing net from parameters and then create layers.  
It completed the first time but hang the second time.  *you can see it at the bottom*
**I wonder if there is no more memory to import parameters and create layers?**
* or what I changed to the origin is illeagal, such as
**when I change output num, it means that the num of parameters changed as well, so how origin caffelmodel file do to fit this change?**
* or it's a limit on Windows and imageData doesn't work
**the net uses imageData layer that will do image-lmdb automatically, but it doesn't happend, can it do on Windows?**
## what I changed
what I changed to the origin net is what finetuning should do, I think.
* I want to finetune a googLeNet,so I change output num of 3 Inproduct layer but I don't change their name
* I add propagate_down choice to some layers to avoid backward-evaluation.
* I changed source path,batch_size and some rate parameter.
* I decrease some parameter of solver file because my data set is small.
* I changed solver to CPU mode.
## terminal message
using git bash terminal.
",,"['I think *caffe itself is ok*.\r\nbecause I have another caffe in my computer which was built by cmake and VS2015 and uses python35.\r\nbut **same problem**.', 'I solve this problem by **using `Data` type layer** with lmdb set that I convert myself.\r\nAnd it work and run well, so the problem is that\r\n**ImageData meet errors when create data set on Windows**.\r\nmy solution is that\r\n**use Data layer and lmdb data set**  \r\n  \r\n*-- 2018.10.8 --*']","['\r\nremark1x@pc-Windows10 MINGW64 /d/remark/caffe-windows-ms\r\n$ ./Build/x64/Release/caffe.exe train -solver ./examples/finetune_gesture_recognize/solver_1007.prototxt -weights ./examples/finetune_gesture_recognize/1miohands-v2_origin.caffemodel\r\nI1008 11:27:25.093991 11844 caffe.cpp:212] Use CPU.\r\nI1008 11:27:25.100036 11844 solver.cpp:44] Initializing solver from parameters:\r\ntest_iter: 20\r\ntest_interval: 400\r\nbase_lr: 0.0002\r\ndisplay: 50\r\nmax_iter: 20000\r\nlr_policy: ""step""\r\ngamma: 0.5\r\npower: 0.5\r\nmomentum: 0.9\r\nweight_decay: 0.0005\r\nstepsize: 10000\r\nsnapshot: 400\r\nsnapshot_prefix: ""snapshot_1007""\r\nsolver_mode: CPU\r\nnet: "".\\\\examples\\\\finetune_gesture_recognize\\\\net_1007.prototxt""\r\ntrain_state {\r\n  level: 0\r\n  stage: """"\r\n}\r\ntest_state {\r\n  stage: ""1""\r\n}\r\ntest_initialization: false\r\naverage_loss: 40\r\nI1008 11:27:25.100036 11844 solver.cpp:87] Creating training net from net file: .\\examples\\finetune_gesture_recognize\\net_1007.prototxt\r\nI1008 11:27:25.101033 11844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data\r\nI1008 11:27:25.101033 11844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer loss1/top-1\r\nI1008 11:27:25.101033 11844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer loss1/top-5\r\nI1008 11:27:25.105211 11844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer loss2/top-1\r\nI1008 11:27:25.105211 11844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer loss2/top-5\r\nI1008 11:27:25.105211 11844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer loss3/top-1\r\nI1008 11:27:25.105211 11844 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer loss3/top-5\r\nI1008 11:27:25.106207 11844 net.cpp:51] Initializing net from parameters:\r\nname: ""GoogleNet""\r\nstate {\r\n  phase: TRAIN\r\n  level: 0\r\n  stage: """"\r\n}\r\nlayer {\r\n  name: ""data""\r\n  type: ""ImageData""\r\n  top: ""data""\r\n  top: ""label""\r\n  include {\r\n    phase: TRAIN\r\n  }\r\n  transform_param {\r\n    mirror: true\r\n    crop_size: 224\r\n    mean_file: "".\\\\examples\\\\finetune_gesture_recognize\\\\mean_origin.mean""\r\n  }\r\n  image_data_param {\r\n    source: ""D:\\\\remark\\\\caffe-windows-ms\\\\examples\\\\finetune_gesture_recognize\\\\video\\\\train.txt""\r\n    batch_size: 4\r\n    shuffle: true\r\n    new_height: 227\r\n    new_width: 227\r\n  }\r\n}\r\nlayer {\r\n  name: ""conv1/7x7_s2""\r\n  type: ""Convolution""\r\n  bottom: ""data""\r\n  top: ""conv1/7x7_s2""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    pad: 3\r\n    kernel_size: 7\r\n    stride: 2\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.1\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""conv1/relu_7x7""\r\n  type: ""ReLU""\r\n  bottom: ""conv1/7x7_s2""\r\n  top: ""conv1/7x7_s2""\r\n}\r\nlayer {\r\n  name: ""pool1/3x3_s2""\r\n  type: ""Pooling""\r\n  bottom: ""conv1/7x7_s2""\r\n  top: ""pool1/3x3_s2""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 2\r\n  }\r\n}\r\nlayer {\r\n  name: ""pool1/norm1""\r\n  type: ""LRN""\r\n  bottom: ""pool1/3x3_s2""\r\n  top: ""pool1/norm1""\r\n  lrn_param {\r\n    local_size: 5\r\n    alpha: 0.0001\r\n    beta: 0.75\r\n  }\r\n}\r\nlayer {\r\n  name: ""conv2/3x3_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""pool1/norm1""\r\n  top: ""conv2/3x3_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.1\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""conv2/relu_3x3_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""conv2/3x3_reduce""\r\n  top: ""conv2/3x3_reduce""\r\n}\r\nlayer {\r\n  name: ""conv2/3x3""\r\n  type: ""Convolution""\r\n  bottom: ""conv2/3x3_reduce""\r\n  top: ""conv2/3x3""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 192\r\n    pad: 1\r\n    kernel_size: 3\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""conv2/relu_3x3""\r\n  type: ""ReLU""\r\n  bottom: ""conv2/3x3""\r\n  top: ""conv2/3x3""\r\n}\r\nlayer {\r\n  name: ""conv2/norm2""\r\n  type: ""LRN""\r\n  bottom: ""conv2/3x3""\r\n  top: ""conv2/norm2""\r\n  lrn_param {\r\n    local_size: 5\r\n    alpha: 0.0001\r\n    beta: 0.75\r\n  }\r\n}\r\nlayer {\r\n  name: ""pool2/3x3_s2""\r\n  type: ""Pooling""\r\n  bottom: ""conv2/norm2""\r\n  top: ""pool2/3x3_s2""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 2\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3a/1x1""\r\n  type: ""Convolution""\r\n  bottom: ""pool2/3x3_s2""\r\n  top: ""inception_3a/1x1""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3a/relu_1x1""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3a/1x1""\r\n  top: ""inception_3a/1x1""\r\n}\r\nlayer {\r\n  name: ""inception_3a/3x3_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""pool2/3x3_s2""\r\n  top: ""inception_3a/3x3_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 96\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.09\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3a/relu_3x3_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3a/3x3_reduce""\r\n  top: ""inception_3a/3x3_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_3a/3x3""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3a/3x3_reduce""\r\n  top: ""inception_3a/3x3""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 128\r\n    pad: 1\r\n    kernel_size: 3\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3a/relu_3x3""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3a/3x3""\r\n  top: ""inception_3a/3x3""\r\n}\r\nlayer {\r\n  name: ""inception_3a/5x5_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""pool2/3x3_s2""\r\n  top: ""inception_3a/5x5_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 16\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.2\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3a/relu_5x5_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3a/5x5_reduce""\r\n  top: ""inception_3a/5x5_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_3a/5x5""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3a/5x5_reduce""\r\n  top: ""inception_3a/5x5""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 32\r\n    pad: 2\r\n    kernel_size: 5\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3a/relu_5x5""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3a/5x5""\r\n  top: ""inception_3a/5x5""\r\n}\r\nlayer {\r\n  name: ""inception_3a/pool""\r\n  type: ""Pooling""\r\n  bottom: ""pool2/3x3_s2""\r\n  top: ""inception_3a/pool""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 1\r\n    pad: 1\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3a/pool_proj""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3a/pool""\r\n  top: ""inception_3a/pool_proj""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 32\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.1\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3a/relu_pool_proj""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3a/pool_proj""\r\n  top: ""inception_3a/pool_proj""\r\n}\r\nlayer {\r\n  name: ""inception_3a/output""\r\n  type: ""Concat""\r\n  bottom: ""inception_3a/1x1""\r\n  bottom: ""inception_3a/3x3""\r\n  bottom: ""inception_3a/5x5""\r\n  bottom: ""inception_3a/pool_proj""\r\n  top: ""inception_3a/output""\r\n}\r\nlayer {\r\n  name: ""inception_3b/1x1""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3a/output""\r\n  top: ""inception_3b/1x1""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 128\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3b/relu_1x1""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3b/1x1""\r\n  top: ""inception_3b/1x1""\r\n}\r\nlayer {\r\n  name: ""inception_3b/3x3_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3a/output""\r\n  top: ""inception_3b/3x3_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 128\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.09\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3b/relu_3x3_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3b/3x3_reduce""\r\n  top: ""inception_3b/3x3_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_3b/3x3""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3b/3x3_reduce""\r\n  top: ""inception_3b/3x3""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 192\r\n    pad: 1\r\n    kernel_size: 3\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3b/relu_3x3""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3b/3x3""\r\n  top: ""inception_3b/3x3""\r\n}\r\nlayer {\r\n  name: ""inception_3b/5x5_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3a/output""\r\n  top: ""inception_3b/5x5_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 32\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.2\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3b/relu_5x5_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3b/5x5_reduce""\r\n  top: ""inception_3b/5x5_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_3b/5x5""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3b/5x5_reduce""\r\n  top: ""inception_3b/5x5""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 96\r\n    pad: 2\r\n    kernel_size: 5\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3b/relu_5x5""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3b/5x5""\r\n  top: ""inception_3b/5x5""\r\n}\r\nlayer {\r\n  name: ""inception_3b/pool""\r\n  type: ""Pooling""\r\n  bottom: ""inception_3a/output""\r\n  top: ""inception_3b/pool""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 1\r\n    pad: 1\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3b/pool_proj""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3b/pool""\r\n  top: ""inception_3b/pool_proj""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.1\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3b/relu_pool_proj""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3b/pool_proj""\r\n  top: ""inception_3b/pool_proj""\r\n}\r\nlayer {\r\n  name: ""inception_3b/output""\r\n  type: ""Concat""\r\n  bottom: ""inception_3b/1x1""\r\n  bottom: ""inception_3b/3x3""\r\n  bottom: ""inception_3b/5x5""\r\n  bottom: ""inception_3b/pool_proj""\r\n  top: ""inception_3b/output""\r\n}\r\nlayer {\r\n  name: ""pool3/3x3_s2""\r\n  type: ""Pooling""\r\n  bottom: ""inception_3b/output""\r\n  top: ""pool3/3x3_s2""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 2\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4a/1x1""\r\n  type: ""Convolution""\r\n  bottom: ""pool3/3x3_s2""\r\n  top: ""inception_4a/1x1""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 192\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4a/relu_1x1""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4a/1x1""\r\n  top: ""inception_4a/1x1""\r\n}\r\nlayer {\r\n  name: ""inception_4a/3x3_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""pool3/3x3_s2""\r\n  top: ""inception_4a/3x3_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 96\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.09\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4a/relu_3x3_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4a/3x3_reduce""\r\n  top: ""inception_4a/3x3_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4a/3x3""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4a/3x3_reduce""\r\n  top: ""inception_4a/3x3""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 208\r\n    pad: 1\r\n    kernel_size: 3\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4a/relu_3x3""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4a/3x3""\r\n  top: ""inception_4a/3x3""\r\n}\r\nlayer {\r\n  name: ""inception_4a/5x5_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""pool3/3x3_s2""\r\n  top: ""inception_4a/5x5_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 16\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.2\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4a/relu_5x5_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4a/5x5_reduce""\r\n  top: ""inception_4a/5x5_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4a/5x5""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4a/5x5_reduce""\r\n  top: ""inception_4a/5x5""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 48\r\n    pad: 2\r\n    kernel_size: 5\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4a/relu_5x5""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4a/5x5""\r\n  top: ""inception_4a/5x5""\r\n}\r\nlayer {\r\n  name: ""inception_4a/pool""\r\n  type: ""Pooling""\r\n  bottom: ""pool3/3x3_s2""\r\n  top: ""inception_4a/pool""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 1\r\n    pad: 1\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4a/pool_proj""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4a/pool""\r\n  top: ""inception_4a/pool_proj""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.1\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4a/relu_pool_proj""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4a/pool_proj""\r\n  top: ""inception_4a/pool_proj""\r\n}\r\nlayer {\r\n  name: ""inception_4a/output""\r\n  type: ""Concat""\r\n  bottom: ""inception_4a/1x1""\r\n  bottom: ""inception_4a/3x3""\r\n  bottom: ""inception_4a/5x5""\r\n  bottom: ""inception_4a/pool_proj""\r\n  top: ""inception_4a/output""\r\n}\r\nlayer {\r\n  name: ""loss1/ave_pool""\r\n  type: ""Pooling""\r\n  bottom: ""inception_4a/output""\r\n  top: ""loss1/ave_pool""\r\n  pooling_param {\r\n    pool: AVE\r\n    kernel_size: 5\r\n    stride: 3\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss1/conv""\r\n  type: ""Convolution""\r\n  bottom: ""loss1/ave_pool""\r\n  top: ""loss1/conv""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 128\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.08\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss1/relu_conv""\r\n  type: ""ReLU""\r\n  bottom: ""loss1/conv""\r\n  top: ""loss1/conv""\r\n}\r\nlayer {\r\n  name: ""loss1/fc""\r\n  type: ""InnerProduct""\r\n  bottom: ""loss1/conv""\r\n  top: ""loss1/fc""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  propagate_down: false\r\n  inner_product_param {\r\n    num_output: 1024\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.02\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss1/relu_fc""\r\n  type: ""ReLU""\r\n  bottom: ""loss1/fc""\r\n  top: ""loss1/fc""\r\n}\r\nlayer {\r\n  name: ""loss1/drop_fc""\r\n  type: ""Dropout""\r\n  bottom: ""loss1/fc""\r\n  top: ""loss1/fc""\r\n  dropout_param {\r\n    dropout_ratio: 0.7\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss1/SLclassifier""\r\n  type: ""InnerProduct""\r\n  bottom: ""loss1/fc""\r\n  top: ""loss1/SLclassifier""\r\n  param {\r\n    lr_mult: 10\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 20\r\n    decay_mult: 0\r\n  }\r\n  inner_product_param {\r\n    num_output: 7\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.0009765625\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss1/loss""\r\n  type: ""SoftmaxWithLoss""\r\n  bottom: ""loss1/SLclassifier""\r\n  bottom: ""label""\r\n  top: ""loss1/loss1""\r\n  loss_weight: 0.3\r\n}\r\nlayer {\r\n  name: ""inception_4b/1x1""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4a/output""\r\n  top: ""inception_4b/1x1""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 160\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4b/relu_1x1""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4b/1x1""\r\n  top: ""inception_4b/1x1""\r\n}\r\nlayer {\r\n  name: ""inception_4b/3x3_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4a/output""\r\n  top: ""inception_4b/3x3_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 112\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.09\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4b/relu_3x3_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4b/3x3_reduce""\r\n  top: ""inception_4b/3x3_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4b/3x3""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4b/3x3_reduce""\r\n  top: ""inception_4b/3x3""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 224\r\n    pad: 1\r\n    kernel_size: 3\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4b/relu_3x3""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4b/3x3""\r\n  top: ""inception_4b/3x3""\r\n}\r\nlayer {\r\n  name: ""inception_4b/5x5_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4a/output""\r\n  top: ""inception_4b/5x5_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 24\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.2\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4b/relu_5x5_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4b/5x5_reduce""\r\n  top: ""inception_4b/5x5_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4b/5x5""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4b/5x5_reduce""\r\n  top: ""inception_4b/5x5""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    pad: 2\r\n    kernel_size: 5\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4b/relu_5x5""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4b/5x5""\r\n  top: ""inception_4b/5x5""\r\n}\r\nlayer {\r\n  name: ""inception_4b/pool""\r\n  type: ""Pooling""\r\n  bottom: ""inception_4a/output""\r\n  top: ""inception_4b/pool""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 1\r\n    pad: 1\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4b/pool_proj""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4b/pool""\r\n  top: ""inception_4b/pool_proj""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.1\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4b/relu_pool_proj""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4b/pool_proj""\r\n  top: ""inception_4b/pool_proj""\r\n}\r\nlayer {\r\n  name: ""inception_4b/output""\r\n  type: ""Concat""\r\n  bottom: ""inception_4b/1x1""\r\n  bottom: ""inception_4b/3x3""\r\n  bottom: ""inception_4b/5x5""\r\n  bottom: ""inception_4b/pool_proj""\r\n  top: ""inception_4b/output""\r\n}\r\nlayer {\r\n  name: ""inception_4c/1x1""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4b/output""\r\n  top: ""inception_4c/1x1""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 128\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4c/relu_1x1""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4c/1x1""\r\n  top: ""inception_4c/1x1""\r\n}\r\nlayer {\r\n  name: ""inception_4c/3x3_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4b/output""\r\n  top: ""inception_4c/3x3_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 128\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.09\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4c/relu_3x3_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4c/3x3_reduce""\r\n  top: ""inception_4c/3x3_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4c/3x3""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4c/3x3_reduce""\r\n  top: ""inception_4c/3x3""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 256\r\n    pad: 1\r\n    kernel_size: 3\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4c/relu_3x3""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4c/3x3""\r\n  top: ""inception_4c/3x3""\r\n}\r\nlayer {\r\n  name: ""inception_4c/5x5_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4b/output""\r\n  top: ""inception_4c/5x5_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 24\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.2\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4c/relu_5x5_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4c/5x5_reduce""\r\n  top: ""inception_4c/5x5_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4c/5x5""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4c/5x5_reduce""\r\n  top: ""inception_4c/5x5""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    pad: 2\r\n    kernel_size: 5\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4c/relu_5x5""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4c/5x5""\r\n  top: ""inception_4c/5x5""\r\n}\r\nlayer {\r\n  name: ""inception_4c/pool""\r\n  type: ""Pooling""\r\n  bottom: ""inception_4b/output""\r\n  top: ""inception_4c/pool""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 1\r\n    pad: 1\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4c/pool_proj""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4c/pool""\r\n  top: ""inception_4c/pool_proj""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.1\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4c/relu_pool_proj""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4c/pool_proj""\r\n  top: ""inception_4c/pool_proj""\r\n}\r\nlayer {\r\n  name: ""inception_4c/output""\r\n  type: ""Concat""\r\n  bottom: ""inception_4c/1x1""\r\n  bottom: ""inception_4c/3x3""\r\n  bottom: ""inception_4c/5x5""\r\n  bottom: ""inception_4c/pool_proj""\r\n  top: ""inception_4c/output""\r\n}\r\nlayer {\r\n  name: ""inception_4d/1x1""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4c/output""\r\n  top: ""inception_4d/1x1""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 112\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4d/relu_1x1""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4d/1x1""\r\n  top: ""inception_4d/1x1""\r\n}\r\nlayer {\r\n  name: ""inception_4d/3x3_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4c/output""\r\n  top: ""inception_4d/3x3_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 144\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.09\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4d/relu_3x3_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4d/3x3_reduce""\r\n  top: ""inception_4d/3x3_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4d/3x3""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4d/3x3_reduce""\r\n  top: ""inception_4d/3x3""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 288\r\n    pad: 1\r\n    kernel_size: 3\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4d/relu_3x3""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4d/3x3""\r\n  top: ""inception_4d/3x3""\r\n}\r\nlayer {\r\n  name: ""inception_4d/5x5_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4c/output""\r\n  top: ""inception_4d/5x5_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 32\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.2\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4d/relu_5x5_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4d/5x5_reduce""\r\n  top: ""inception_4d/5x5_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4d/5x5""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4d/5x5_reduce""\r\n  top: ""inception_4d/5x5""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    pad: 2\r\n    kernel_size: 5\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4d/relu_5x5""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4d/5x5""\r\n  top: ""inception_4d/5x5""\r\n}\r\nlayer {\r\n  name: ""inception_4d/pool""\r\n  type: ""Pooling""\r\n  bottom: ""inception_4c/output""\r\n  top: ""inception_4d/pool""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 1\r\n    pad: 1\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4d/pool_proj""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4d/pool""\r\n  top: ""inception_4d/pool_proj""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.1\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4d/relu_pool_proj""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4d/pool_proj""\r\n  top: ""inception_4d/pool_proj""\r\n}\r\nlayer {\r\n  name: ""inception_4d/output""\r\n  type: ""Concat""\r\n  bottom: ""inception_4d/1x1""\r\n  bottom: ""inception_4d/3x3""\r\n  bottom: ""inception_4d/5x5""\r\n  bottom: ""inception_4d/pool_proj""\r\n  top: ""inception_4d/output""\r\n}\r\nlayer {\r\n  name: ""loss2/ave_pool""\r\n  type: ""Pooling""\r\n  bottom: ""inception_4d/output""\r\n  top: ""loss2/ave_pool""\r\n  pooling_param {\r\n    pool: AVE\r\n    kernel_size: 5\r\n    stride: 3\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss2/conv""\r\n  type: ""Convolution""\r\n  bottom: ""loss2/ave_pool""\r\n  top: ""loss2/conv""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 128\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.08\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss2/relu_conv""\r\n  type: ""ReLU""\r\n  bottom: ""loss2/conv""\r\n  top: ""loss2/conv""\r\n}\r\nlayer {\r\n  name: ""loss2/fc""\r\n  type: ""InnerProduct""\r\n  bottom: ""loss2/conv""\r\n  top: ""loss2/fc""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  propagate_down: false\r\n  inner_product_param {\r\n    num_output: 1024\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.02\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss2/relu_fc""\r\n  type: ""ReLU""\r\n  bottom: ""loss2/fc""\r\n  top: ""loss2/fc""\r\n}\r\nlayer {\r\n  name: ""loss2/drop_fc""\r\n  type: ""Dropout""\r\n  bottom: ""loss2/fc""\r\n  top: ""loss2/fc""\r\n  dropout_param {\r\n    dropout_ratio: 0.7\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss2/SLclassifier""\r\n  type: ""InnerProduct""\r\n  bottom: ""loss2/fc""\r\n  top: ""loss2/SLclassifier""\r\n  param {\r\n    lr_mult: 10\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 20\r\n    decay_mult: 0\r\n  }\r\n  inner_product_param {\r\n    num_output: 7\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.0009765625\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss2/loss""\r\n  type: ""SoftmaxWithLoss""\r\n  bottom: ""loss2/SLclassifier""\r\n  bottom: ""label""\r\n  top: ""loss2/loss1""\r\n  loss_weight: 0.3\r\n}\r\nlayer {\r\n  name: ""inception_4e/1x1""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4d/output""\r\n  top: ""inception_4e/1x1""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 256\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4e/relu_1x1""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4e/1x1""\r\n  top: ""inception_4e/1x1""\r\n}\r\nlayer {\r\n  name: ""inception_4e/3x3_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4d/output""\r\n  top: ""inception_4e/3x3_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 160\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.09\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4e/relu_3x3_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4e/3x3_reduce""\r\n  top: ""inception_4e/3x3_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4e/3x3""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4e/3x3_reduce""\r\n  top: ""inception_4e/3x3""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 320\r\n    pad: 1\r\n    kernel_size: 3\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4e/relu_3x3""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4e/3x3""\r\n  top: ""inception_4e/3x3""\r\n}\r\nlayer {\r\n  name: ""inception_4e/5x5_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4d/output""\r\n  top: ""inception_4e/5x5_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 32\r\nI1008 11:27:25.106207 11844 layer_factory.hpp:77] Creating layer data\r\nI1008 11:27:25.109459 11844 net.cpp:84] Creating Layer data\r\nI1008 11:27:25.109459 11844 net.cpp:380] data -> data\r\nI1008 11:27:25.109459 11844 net.cpp:380] data -> label\r\nI1008 11:27:25.109459 11844 data_transformer.cpp:26] Loading mean file from: .\\examples\\finetune_gesture_recognize\\mean_origin.mean\r\nI1008 11:27:25.110455 11844 image_data_layer.cpp:39] Opening file D:\\remark\\caffe-windows-ms\\examples\\finetune_gesture_recognize\\video\\train.txt\r\nI1008 11:27:25.113939 11844 image_data_layer.cpp:88] Shuffling data\r\nI1008 11:27:25.113939 11844 image_data_layer.cpp:98] A total of 2444 images.\r\nI1008 11:27:25.499213 11844 image_data_layer.cpp:125] output data size: 4,3,224,224\r\nI1008 11:27:25.501333 11844 net.cpp:122] Setting up data\r\nI1008 11:27:25.501333 11844 net.cpp:129] Top shape: 4 3 224 224 (602112)\r\nI1008 11:27:25.501333 11844 net.cpp:129] Top shape: 4 (4)\r\nI1008 11:27:25.506737 11844 net.cpp:137] Memory required for data: 2408464\r\nI1008 11:27:25.506737 11844 layer_factory.hpp:77] Creating layer label_data_1_split\r\nI1008 11:27:25.506737 11844 net.cpp:84] Creating Layer label_data_1_split\r\nI1008 11:27:25.506737 11844 net.cpp:406] label_data_1_split <- label\r\nI1008 11:27:25.506737 11844 net.cpp:380] label_data_1_split -> label_data_1_split_0\r\nI1008 11:27:25.506737 11844 net.cpp:380] label_data_1_split -> label_data_1_split_1\r\nI1008 11:27:25.506737 11844 net.cpp:380] label_data_1_split -> label_data_1_split_2\r\nI1008 11:27:25.506737 11844 net.cpp:122] Setting up label_data_1_split\r\nI1008 11:27:25.506737 11844 net.cpp:129] Top shape: 4 (4)\r\nI1008 11:27:25.506737 11844 net.cpp:129] Top shape: 4 (4)\r\nI1008 11:27:25.506737 11844 net.cpp:129] Top shape: 4 (4)\r\nI1008 11:27:25.506737 11844 net.cpp:137] Memory required for data: 2408512\r\nI1008 11:27:25.506737 11844 layer_factory.hpp:77] Creating layer conv1/7x7_s2\r\nI1008 11:27:25.506737 11844 net.cpp:84] Creating Layer conv1/7x7_s2\r\nI1008 11:27:25.506737 11844 net.cpp:406] conv1/7x7_s2 <- data\r\nI1008 11:27:25.506737 11844 net.cpp:380] conv1/7x7_s2 -> conv1/7x7_s2\r\nI1008 11:27:25.507735 11844 net.cpp:122] Setting up conv1/7x7_s2\r\nI1008 11:27:25.507735 11844 net.cpp:129] Top shape: 4 64 112 112 (3211264)\r\nI1008 11:27:25.507735 11844 net.cpp:137] Memory required for data: 15253568\r\nI1008 11:27:25.507735 11844 layer_factory.hpp:77] Creating layer conv1/relu_7x7\r\nI1008 11:27:25.507735 11844 net.cpp:84] Creating Layer conv1/relu_7x7\r\nI1008 11:27:25.507735 11844 net.cpp:406] conv1/relu_7x7 <- conv1/7x7_s2\r\nI1008 11:27:25.507735 11844 net.cpp:367] conv1/relu_7x7 -> conv1/7x7_s2 (in-place)\r\nI1008 11:27:25.507735 11844 net.cpp:122] Setting up conv1/relu_7x7\r\nI1008 11:27:25.507735 11844 net.cpp:129] Top shape: 4 64 112 112 (3211264)\r\nI1008 11:27:25.507735 11844 net.cpp:137] Memory required for data: 28098624\r\nI1008 11:27:25.507735 11844 layer_factory.hpp:77] Creating layer pool1/3x3_s2\r\nI1008 11:27:25.507735 11844 net.cpp:84] Creating Layer pool1/3x3_s2\r\nI1008 11:27:25.507735 11844 net.cpp:406] pool1/3x3_s2 <- conv1/7x7_s2\r\nI1008 11:27:25.507735 11844 net.cpp:380] pool1/3x3_s2 -> pool1/3x3_s2\r\nI1008 11:27:25.507735 11844 net.cpp:122] Setting up pool1/3x3_s2\r\nI1008 11:27:25.507735 11844 net.cpp:129] Top shape: 4 64 56 56 (802816)\r\nI1008 11:27:25.507735 11844 net.cpp:137] Memory required for data: 31309888\r\nI1008 11:27:25.507735 11844 layer_factory.hpp:77] Creating layer pool1/norm1\r\nI1008 11:27:25.507735 11844 net.cpp:84] Creating Layer pool1/norm1\r\nI1008 11:27:25.507735 11844 net.cpp:406] pool1/norm1 <- pool1/3x3_s2\r\nI1008 11:27:25.507735 11844 net.cpp:380] pool1/norm1 -> pool1/norm1\r\nI1008 11:27:25.507735 11844 net.cpp:122] Setting up pool1/norm1\r\nI1008 11:27:25.507735 11844 net.cpp:129] Top shape: 4 64 56 56 (802816)\r\nI1008 11:27:25.507735 11844 net.cpp:137] Memory required for data: 34521152\r\nI1008 11:27:25.507735 11844 layer_factory.hpp:77] Creating layer conv2/3x3_reduce\r\nI1008 11:27:25.507735 11844 net.cpp:84] Creating Layer conv2/3x3_reduce\r\nI1008 11:27:25.507735 11844 net.cpp:406] conv2/3x3_reduce <- pool1/norm1\r\nI1008 11:27:25.507735 11844 net.cpp:380] conv2/3x3_reduce -> conv2/3x3_reduce\r\nI1008 11:27:25.507735 11844 net.cpp:122] Setting up conv2/3x3_reduce\r\nI1008 11:27:25.507735 11844 net.cpp:129] Top shape: 4 64 56 56 (802816)\r\nI1008 11:27:25.507735 11844 net.cpp:137] Memory required for data: 37732416\r\nI1008 11:27:25.508730 11844 layer_factory.hpp:77] Creating layer conv2/relu_3x3_reduce\r\nI1008 11:27:25.508730 11844 net.cpp:84] Creating Layer conv2/relu_3x3_reduce\r\nI1008 11:27:25.508795 11844 net.cpp:406] conv2/relu_3x3_reduce <- conv2/3x3_reduce\r\nI1008 11:27:25.508795 11844 net.cpp:367] conv2/relu_3x3_reduce -> conv2/3x3_reduce (in-place)\r\nI1008 11:27:25.508795 11844 net.cpp:122] Setting up conv2/relu_3x3_reduce\r\nI1008 11:27:25.508795 11844 net.cpp:129] Top shape: 4 64 56 56 (802816)\r\nI1008 11:27:25.508795 11844 net.cpp:137] Memory required for data: 40943680\r\nI1008 11:27:25.508795 11844 layer_factory.hpp:77] Creating layer conv2/3x3\r\nI1008 11:27:25.508795 11844 net.cpp:84] Creating Layer conv2/3x3\r\nI1008 11:27:25.508795 11844 net.cpp:406] conv2/3x3 <- conv2/3x3_reduce\r\nI1008 11:27:25.508795 11844 net.cpp:380] conv2/3x3 -> conv2/3x3\r\nI1008 11:27:25.509793 11844 net.cpp:122] Setting up conv2/3x3\r\nI1008 11:27:25.510859 11844 net.cpp:129] Top shape: 4 192 56 56 (2408448)\r\nI1008 11:27:25.510859 11844 net.cpp:137] Memory required for data: 50577472\r\nI1008 11:27:25.510859 11844 layer_factory.hpp:77] Creating layer conv2/relu_3x3\r\nI1008 11:27:25.510859 11844 net.cpp:84] Creating Layer conv2/relu_3x3\r\nI1008 11:27:25.510859 11844 net.cpp:406] conv2/relu_3x3 <- conv2/3x3\r\nI1008 11:27:25.510859 11844 net.cpp:367] conv2/relu_3x3 -> conv2/3x3 (in-place)\r\nI1008 11:27:25.510859 11844 net.cpp:122] Setting up conv2/relu_3x3\r\nI1008 11:27:25.510859 11844 net.cpp:129] Top shape: 4 192 56 56 (2408448)\r\nI1008 11:27:25.510859 11844 net.cpp:137] Memory required for data: 60211264\r\nI1008 11:27:25.510859 11844 layer_factory.hpp:77] Creating layer conv2/norm2\r\nI1008 11:27:25.510859 11844 net.cpp:84] Creating Layer conv2/norm2\r\nI1008 11:27:25.510859 11844 net.cpp:406] conv2/norm2 <- conv2/3x3\r\nI1008 11:27:25.510859 11844 net.cpp:380] conv2/norm2 -> conv2/norm2\r\nI1008 11:27:25.510859 11844 net.cpp:122] Setting up conv2/norm2\r\nI1008 11:27:25.510859 11844 net.cpp:129] Top shape: 4 192 56 56 (2408448)\r\nI1008 11:27:25.510859 11844 net.cpp:137] Memory required for data: 69845056\r\nI1008 11:27:25.510859 11844 layer_factory.hpp:77] Creating layer pool2/3x3_s2\r\nI1008 11:27:25.510859 11844 net.cpp:84] Creating Layer pool2/3x3_s2\r\nI1008 11:27:25.510859 11844 net.cpp:406] pool2/3x3_s2 <- conv2/norm2\r\nI1008 11:27:25.510859 11844 net.cpp:380] pool2/3x3_s2 -> pool2/3x3_s2\r\nI1008 11:27:25.510859 11844 net.cpp:122] Setting up pool2/3x3_s2\r\nI1008 11:27:25.510859 11844 net.cpp:129] Top shape: 4 192 28 28 (602112)\r\nI1008 11:27:25.510859 11844 net.cpp:137] Memory required for data: 72253504\r\nI1008 11:27:25.510859 11844 layer_factory.hpp:77] Creating layer pool2/3x3_s2_pool2/3x3_s2_0_split\r\nI1008 11:27:25.510859 11844 net.cpp:84] Creating Layer pool2/3x3_s2_pool2/3x3_s2_0_split\r\nI1008 11:27:25.510859 11844 net.cpp:406] pool2/3x3_s2_pool2/3x3_s2_0_split <- pool2/3x3_s2\r\nI1008 11:27:25.510859 11844 net.cpp:380] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_0\r\nI1008 11:27:25.510859 11844 net.cpp:380] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_1\r\nI1008 11:27:25.510859 11844 net.cpp:380] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_2\r\nI1008 11:27:25.510859 11844 net.cpp:380] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_3\r\nI1008 11:27:25.510859 11844 net.cpp:122] Setting up pool2/3x3_s2_pool2/3x3_s2_0_split\r\nI1008 11:27:25.510859 11844 net.cpp:129] Top shape: 4 192 28 28 (602112)\r\nI1008 11:27:25.510859 11844 net.cpp:129] Top shape: 4 192 28 28 (602112)\r\nI1008 11:27:25.510859 11844 net.cpp:129] Top shape: 4 192 28 28 (602112)\r\nI1008 11:27:25.510859 11844 net.cpp:129] Top shape: 4 192 28 28 (602112)\r\nI1008 11:27:25.510859 11844 net.cpp:137] Memory required for data: 81887296\r\nI1008 11:27:25.511857 11844 layer_factory.hpp:77] Creating layer inception_3a/1x1\r\nI1008 11:27:25.511885 11844 net.cpp:84] Creating Layer inception_3a/1x1\r\nI1008 11:27:25.511885 11844 net.cpp:406] inception_3a/1x1 <- pool2/3x3_s2_pool2/3x3_s2_0_split_0\r\nI1008 11:27:25.511885 11844 net.cpp:380] inception_3a/1x1 -> inception_3a/1x1\r\nI1008 11:27:25.511885 11844 net.cpp:122] Setting up inception_3a/1x1\r\nI1008 11:27:25.511885 11844 net.cpp:129] Top shape: 4 64 28 28 (200704)\r\nI1008 11:27:25.511885 11844 net.cpp:137] Memory required for data: 82690112\r\nI1008 11:27:25.511885 11844 layer_factory.hpp:77] Creating layer inception_3a/relu_1x1\r\nI1008 11:27:25.511885 11844 net.cpp:84] Creating Layer inception_3a/relu_1x1\r\nI1008 11:27:25.511885 11844 net.cpp:406] inception_3a/relu_1x1 <- inception_3a/1x1\r\nI1008 11:27:25.511885 11844 net.cpp:367] inception_3a/relu_1x1 -> inception_3a/1x1 (in-place)\r\nI1008 11:27:25.511885 11844 net.cpp:122] Setting up inception_3a/relu_1x1\r\nI1008 11:27:25.511885 11844 net.cpp:129] Top shape: 4 64 28 28 (200704)\r\nI1008 11:27:25.511885 11844 net.cpp:137] Memory required for data: 83492928\r\nI1008 11:27:25.511885 11844 layer_factory.hpp:77] Creating layer inception_3a/3x3_reduce\r\nI1008 11:27:25.511885 11844 net.cpp:84] Creating Layer inception_3a/3x3_reduce\r\nI1008 11:27:25.511885 11844 net.cpp:406] inception_3a/3x3_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_1\r\nI1008 11:27:25.511885 11844 net.cpp:380] inception_3a/3x3_reduce -> inception_3a/3x3_reduce\r\nI1008 11:27:25.512883 11844 net.cpp:122] Setting up inception_3a/3x3_reduce\r\nI1008 11:27:25.512954 11844 net.cpp:129] Top shape: 4 96 28 28 (301056)\r\nI1008 11:27:25.512954 11844 net.cpp:137] Memory required for data: 84697152\r\nI1008 11:27:25.512954 11844 layer_factory.hpp:77] Creating layer inception_3a/relu_3x3_reduce\r\nI1008 11:27:25.512954 11844 net.cpp:84] Creating Layer inception_3a/relu_3x3_reduce\r\nI1008 11:27:25.512954 11844 net.cpp:406] inception_3a/relu_3x3_reduce <- inception_3a/3x3_reduce\r\nI1008 11:27:25.512954 11844 net.cpp:367] inception_3a/relu_3x3_reduce -> inception_3a/3x3_reduce (in-place)\r\nI1008 11:27:25.512954 11844 net.cpp:122] Setting up inception_3a/relu_3x3_reduce\r\nI1008 11:27:25.512954 11844 net.cpp:129] Top shape: 4 96 28 28 (301056)\r\nI1008 11:27:25.512954 11844 net.cpp:137] Memory required for data: 85901376\r\nI1008 11:27:25.512954 11844 layer_factory.hpp:77] Creating layer inception_3a/3x3\r\nI1008 11:27:25.512954 11844 net.cpp:84] Creating Layer inception_3a/3x3\r\nI1008 11:27:25.512954 11844 net.cpp:406] inception_3a/3x3 <- inception_3a/3x3_reduce\r\nI1008 11:27:25.512954 11844 net.cpp:380] inception_3a/3x3 -> inception_3a/3x3\r\nI1008 11:27:25.513953 11844 net.cpp:122] Setting up inception_3a/3x3\r\nI1008 11:27:25.515099 11844 net.cpp:129] Top shape: 4 128 28 28 (401408)\r\nI1008 11:27:25.515099 11844 net.cpp:137] Memory required for data: 87507008\r\nI1008 11:27:25.515099 11844 layer_factory.hpp:77] Creating layer inception_3a/relu_3x3\r\nI1008 11:27:25.515099 11844 net.cpp:84] Creating Layer inception_3a/relu_3x3\r\nI1008 11:27:25.515099 11844 net.cpp:406] inception_3a/relu_3x3 <- inception_3a/3x3\r\nI1008 11:27:25.515099 11844 net.cpp:367] inception_3a/relu_3x3 -> inception_3a/3x3 (in-place)\r\nI1008 11:27:25.515099 11844 net.cpp:122] Setting up inception_3a/relu_3x3\r\nI1008 11:27:25.515099 11844 net.cpp:129] Top shape: 4 128 28 28 (401408)\r\nI1008 11:27:25.515099 11844 net.cpp:137] Memory required for data: 89112640\r\nI1008 11:27:25.515099 11844 layer_factory.hpp:77] Creating layer inception_3a/5x5_reduce\r\nI1008 11:27:25.515099 11844 net.cpp:84] Creating Layer inception_3a/5x5_reduce\r\nI1008 11:27:25.515099 11844 net.cpp:406] inception_3a/5x5_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_2\r\nI1008 11:27:25.515099 11844 net.cpp:380] inception_3a/5x5_reduce -> inception_3a/5x5_reduce\r\nI1008 11:27:25.515099 11844 net.cpp:122] Setting up inception_3a/5x5_reduce\r\nI1008 11:27:25.515099 11844 net.cpp:129] Top shape: 4 16 28 28 (50176)\r\nI1008 11:27:25.515099 11844 net.cpp:137] Memory required for data: 89313344\r\nI1008 11:27:25.515099 11844 layer_factory.hpp:77] Creating layer inception_3a/relu_5x5_reduce\r\nI1008 11:27:25.515099 11844 net.cpp:84] Creating Layer inception_3a/relu_5x5_reduce\r\nI1008 11:27:25.515099 11844 net.cpp:406] inception_3a/relu_5x5_reduce <- inception_3a/5x5_reduce\r\nI1008 11:27:25.515099 11844 net.cpp:367] inception_3a/relu_5x5_reduce -> inception_3a/5x5_reduce (in-place)\r\nI1008 11:27:25.515099 11844 net.cpp:122] Setting up inception_3a/relu_5x5_reduce\r\nI1008 11:27:25.515099 11844 net.cpp:129] Top shape: 4 16 28 28 (50176)\r\nI1008 11:27:25.515099 11844 net.cpp:137] Memory required for data: 89514048\r\nI1008 11:27:25.515099 11844 layer_factory.hpp:77] Creating layer inception_3a/5x5\r\nI1008 11:27:25.515099 11844 net.cpp:84] Creating Layer inception_3a/5x5\r\nI1008 11:27:25.515099 11844 net.cpp:406] inception_3a/5x5 <- inception_3a/5x5_reduce\r\nI1008 11:27:25.515099 11844 net.cpp:380] inception_3a/5x5 -> inception_3a/5x5\r\nI1008 11:27:25.516096 11844 net.cpp:122] Setting up inception_3a/5x5\r\nI1008 11:27:25.516096 11844 net.cpp:129] Top shape: 4 32 28 28 (100352)\r\nI1008 11:27:25.516343 11844 net.cpp:137] Memory required for data: 89915456\r\nI1008 11:27:25.516343 11844 layer_factory.hpp:77] Creating layer inception_3a/relu_5x5\r\nI1008 11:27:25.516343 11844 net.cpp:84] Creating Layer inception_3a/relu_5x5\r\nI1008 11:27:25.516343 11844 net.cpp:406] inception_3a/relu_5x5 <- inception_3a/5x5\r\nI1008 11:27:25.516343 11844 net.cpp:367] inception_3a/relu_5x5 -> inception_3a/5x5 (in-place)\r\nI1008 11:27:25.516343 11844 net.cpp:122] Setting up inception_3a/relu_5x5\r\nI1008 11:27:25.516343 11844 net.cpp:129] Top shape: 4 32 28 28 (100352)\r\nI1008 11:27:25.516343 11844 net.cpp:137] Memory required for data: 90316864\r\nI1008 11:27:25.516343 11844 layer_factory.hpp:77] Creating layer inception_3a/pool\r\nI1008 11:27:25.516343 11844 net.cpp:84] Creating Layer inception_3a/pool\r\nI1008 11:27:25.516343 11844 net.cpp:406] inception_3a/pool <- pool2/3x3_s2_pool2/3x3_s2_0_split_3\r\nI1008 11:27:25.516343 11844 net.cpp:380] inception_3a/pool -> inception_3a/pool\r\nI1008 11:27:25.516343 11844 net.cpp:122] Setting up inception_3a/pool\r\nI1008 11:27:25.516343 11844 net.cpp:129] Top shape: 4 192 28 28 (602112)\r\nI1008 11:27:25.516343 11844 net.cpp:137] Memory required for data: 92725312\r\nI1008 11:27:25.516343 11844 layer_factory.hpp:77] Creating layer inception_3a/pool_proj\r\nI1008 11:27:25.516343 11844 net.cpp:84] Creating Layer inception_3a/pool_proj\r\nI1008 11:27:25.516343 11844 net.cpp:406] inception_3a/pool_proj <- inception_3a/pool\r\nI1008 11:27:25.516343 11844 net.cpp:380] inception_3a/pool_proj -> inception_3a/pool_proj\r\nI1008 11:27:25.516343 11844 net.cpp:122] Setting up inception_3a/pool_proj\r\nI1008 11:27:25.516343 11844 net.cpp:129] Top shape: 4 32 28 28 (100352)\r\nI1008 11:27:25.516343 11844 net.cpp:137] Memory required for data: 93126720\r\nI1008 11:27:25.516343 11844 layer_factory.hpp:77] Creating layer inception_3a/relu_pool_proj\r\nI1008 11:27:25.516343 11844 net.cpp:84] Creating Layer inception_3a/relu_pool_proj\r\nI1008 11:27:25.516343 11844 net.cpp:406] inception_3a/relu_pool_proj <- inception_3a/pool_proj\r\nI1008 11:27:25.516343 11844 net.cpp:367] inception_3a/relu_pool_proj -> inception_3a/pool_proj (in-place)\r\nI1008 11:27:25.516343 11844 net.cpp:122] Setting up inception_3a/relu_pool_proj\r\nI1008 11:27:25.516343 11844 net.cpp:129] Top shape: 4 32 28 28 (100352)\r\nI1008 11:27:25.516343 11844 net.cpp:137] Memory required for data: 93528128\r\nI1008 11:27:25.516343 11844 layer_factory.hpp:77] Creating layer inception_3a/output\r\nI1008 11:27:25.516343 11844 net.cpp:84] Creating Layer inception_3a/output\r\nI1008 11:27:25.517340 11844 net.cpp:406] inception_3a/output <- inception_3a/1x1\r\nI1008 11:27:25.517340 11844 net.cpp:406] inception_3a/output <- inception_3a/3x3\r\nI1008 11:27:25.517377 11844 net.cpp:406] inception_3a/output <- inception_3a/5x5\r\nI1008 11:27:25.517377 11844 net.cpp:406] inception_3a/output <- inception_3a/pool_proj\r\nI1008 11:27:25.517377 11844 net.cpp:380] inception_3a/output -> inception_3a/output\r\nI1008 11:27:25.517377 11844 net.cpp:122] Setting up inception_3a/output\r\nI1008 11:27:25.517377 11844 net.cpp:129] Top shape: 4 256 28 28 (802816)\r\nI1008 11:27:25.517377 11844 net.cpp:137] Memory required for data: 96739392\r\nI1008 11:27:25.517377 11844 layer_factory.hpp:77] Creating layer inception_3a/output_inception_3a/output_0_split\r\nI1008 11:27:25.517377 11844 net.cpp:84] Creating Layer inception_3a/output_inception_3a/output_0_split\r\nI1008 11:27:25.517377 11844 net.cpp:406] inception_3a/output_inception_3a/output_0_split <- inception_3a/output\r\nI1008 11:27:25.517377 11844 net.cpp:380] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0\r\nI1008 11:27:25.517377 11844 net.cpp:380] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1\r\nI1008 11:27:25.517377 11844 net.cpp:380] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_2\r\nI1008 11:27:25.517377 11844 net.cpp:380] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_3\r\nI1008 11:27:25.517377 11844 net.cpp:122] Setting up inception_3a/output_inception_3a/output_0_split\r\nI1008 11:27:25.517377 11844 net.cpp:129] Top shape: 4 256 28 28 (802816)\r\nI1008 11:27:25.517377 11844 net.cpp:129] Top shape: 4 256 28 28 (802816)\r\nI1008 11:27:25.517377 11844 net.cpp:129] Top shape: 4 256 28 28 (802816)\r\nI1008 11:27:25.517377 11844 net.cpp:129] Top shape: 4 256 28 28 (802816)\r\nI1008 11:27:25.517377 11844 net.cpp:137] Memory required for data: 109584448\r\nI1008 11:27:25.517377 11844 layer_factory.hpp:77] Creating layer inception_3b/1x1\r\nI1008 11:27:25.517377 11844 net.cpp:84] Creating Layer inception_3b/1x1\r\nI1008 11:27:25.517377 11844 net.cpp:406] inception_3b/1x1 <- inception_3a/output_inception_3a/output_0_split_0\r\nI1008 11:27:25.517377 11844 net.cpp:380] inception_3b/1x1 -> inception_3b/1x1\r\nI1008 11:27:25.518375 11844 net.cpp:122] Setting up inception_3b/1x1\r\nI1008 11:27:25.518623 11844 net.cpp:129] Top shape: 4 128 28 28 (401408)\r\nI1008 11:27:25.518623 11844 net.cpp:137] Memory required for data: 111190080\r\nI1008 11:27:25.518623 11844 layer_factory.hpp:77] Creating layer inception_3b/relu_1x1\r\nI1008 11:27:25.518623 11844 net.cpp:84] Creating Layer inception_3b/relu_1x1\r\nI1008 11:27:25.518623 11844 net.cpp:406] inception_3b/relu_1x1 <- inception_3b/1x1\r\nI1008 11:27:25.518623 11844 net.cpp:367] inception_3b/relu_1x1 -> inception_3b/1x1 (in-place)\r\nI1008 11:27:25.518623 11844 net.cpp:122] Setting up inception_3b/relu_1x1\r\nI1008 11:27:25.518623 11844 net.cpp:129] Top shape: 4 128 28 28 (401408)\r\nI1008 11:27:25.518623 11844 net.cpp:137] Memory required for data: 112795712\r\nI1008 11:27:25.518623 11844 layer_factory.hpp:77] Creating layer inception_3b/3x3_reduce\r\nI1008 11:27:25.518623 11844 net.cpp:84] Creating Layer inception_3b/3x3_reduce\r\nI1008 11:27:25.518623 11844 net.cpp:406] inception_3b/3x3_reduce <- inception_3a/output_inception_3a/output_0_split_1\r\nI1008 11:27:25.518623 11844 net.cpp:380] inception_3b/3x3_reduce -> inception_3b/3x3_reduce\r\nI1008 11:27:25.518623 11844 net.cpp:122] Setting up inception_3b/3x3_reduce\r\nI1008 11:27:25.518623 11844 net.cpp:129] Top shape: 4 128 28 28 (401408)\r\nI1008 11:27:25.518623 11844 net.cpp:137] Memory required for data: 114401344\r\nI1008 11:27:25.518623 11844 layer_factory.hpp:77] Creating layer inception_3b/relu_3x3_reduce\r\nI1008 11:27:25.519619 11844 net.cpp:84] Creating Layer inception_3b/relu_3x3_reduce\r\nI1008 11:27:25.519619 11844 net.cpp:406] inception_3b/relu_3x3_reduce <- inception_3b/3x3_reduce\r\nI1008 11:27:25.519656 11844 net.cpp:367] inception_3b/relu_3x3_reduce -> inception_3b/3x3_reduce (in-place)\r\nI1008 11:27:25.519656 11844 net.cpp:122] Setting up inception_3b/relu_3x3_reduce\r\nI1008 11:27:25.519656 11844 net.cpp:129] Top shape: 4 128 28 28 (401408)\r\nI1008 11:27:25.519656 11844 net.cpp:137] Memory required for data: 116006976\r\nI1008 11:27:25.519656 11844 layer_factory.hpp:77] Creating layer inception_3b/3x3\r\nI1008 11:27:25.519656 11844 net.cpp:84] Creating Layer inception_3b/3x3\r\nI1008 11:27:25.519656 11844 net.cpp:406] inception_3b/3x3 <- inception_3b/3x3_reduce\r\nI1008 11:27:25.519656 11844 net.cpp:380] inception_3b/3x3 -> inception_3b/3x3\r\nI1008 11:27:25.520653 11844 net.cpp:122] Setting up inception_3b/3x3\r\nI1008 11:27:25.523491 11844 net.cpp:129] Top shape: 4 192 28 28 (602112)\r\nI1008 11:27:25.523491 11844 net.cpp:137] Memory required for data: 118415424\r\nI1008 11:27:25.523491 11844 layer_factory.hpp:77] Creating layer inception_3b/relu_3x3\r\nI1008 11:27:25.523491 11844 net.cpp:84] Creating Layer inception_3b/relu_3x3\r\nI1008 11:27:25.523491 11844 net.cpp:406] inception_3b/relu_3x3 <- inception_3b/3x3\r\nI1008 11:27:25.523491 11844 net.cpp:367] inception_3b/relu_3x3 -> inception_3b/3x3 (in-place)\r\nI1008 11:27:25.523491 11844 net.cpp:122] Setting up inception_3b/relu_3x3\r\nI1008 11:27:25.523491 11844 net.cpp:129] Top shape: 4 192 28 28 (602112)\r\nI1008 11:27:25.523491 11844 net.cpp:137] Memory required for data: 120823872\r\nI1008 11:27:25.523491 11844 layer_factory.hpp:77] Creating layer inception_3b/5x5_reduce\r\nI1008 11:27:25.523491 11844 net.cpp:84] Creating Layer inception_3b/5x5_reduce\r\nI1008 11:27:25.523491 11844 net.cpp:406] inception_3b/5x5_reduce <- inception_3a/output_inception_3a/output_0_split_2\r\nI1008 11:27:25.523491 11844 net.cpp:380] inception_3b/5x5_reduce -> inception_3b/5x5_reduce\r\nI1008 11:27:25.523491 11844 net.cpp:122] Setting up inception_3b/5x5_reduce\r\nI1008 11:27:25.523491 11844 net.cpp:129] Top shape: 4 32 28 28 (100352)\r\nI1008 11:27:25.523491 11844 net.cpp:137] Memory required for data: 121225280\r\nI1008 11:27:25.523491 11844 layer_factory.hpp:77] Creating layer inception_3b/relu_5x5_reduce\r\nI1008 11:27:25.523491 11844 net.cpp:84] Creating Layer inception_3b/relu_5x5_reduce\r\nI1008 11:27:25.523491 11844 net.cpp:406] inception_3b/relu_5x5_reduce <- inception_3b/5x5_reduce\r\nI1008 11:27:25.523491 11844 net.cpp:367] inception_3b/relu_5x5_reduce -> inception_3b/5x5_reduce (in-place)\r\nI1008 11:27:25.523491 11844 net.cpp:122] Setting up inception_3b/relu_5x5_reduce\r\nI1008 11:27:25.523491 11844 net.cpp:129] Top shape: 4 32 28 28 (100352)\r\nI1008 11:27:25.523491 11844 net.cpp:137] Memory required for data: 121626688\r\nI1008 11:27:25.523491 11844 layer_factory.hpp:77] Creating layer inception_3b/5x5\r\nI1008 11:27:25.523491 11844 net.cpp:84] Creating Layer inception_3b/5x5\r\nI1008 11:27:25.523491 11844 net.cpp:406] inception_3b/5x5 <- inception_3b/5x5_reduce\r\nI1008 11:27:25.523491 11844 net.cpp:380] inception_3b/5x5 -> inception_3b/5x5\r\nI1008 11:27:25.524562 11844 net.cpp:122] Setting up inception_3b/5x5\r\nI1008 11:27:25.524562 11844 net.cpp:129] Top shape: 4 96 28 28 (301056)\r\nI1008 11:27:25.524562 11844 net.cpp:137] Memory required for data: 122830912\r\nI1008 11:27:25.524562 11844 layer_factory.hpp:77] Creating layer inception_3b/relu_5x5\r\nI1008 11:27:25.524562 11844 net.cpp:84] Creating Layer inception_3b/relu_5x5\r\nI1008 11:27:25.524562 11844 net.cpp:406] inception_3b/relu_5x5 <- inception_3b/5x5\r\nI1008 11:27:25.524562 11844 net.cpp:367] inception_3b/relu_5x5 -> inception_3b/5x5 (in-place)\r\nI1008 11:27:25.524562 11844 net.cpp:122] Setting up inception_3b/relu_5x5\r\nI1008 11:27:25.525559 11844 net.cpp:129] Top shape: 4 96 28 28 (301056)\r\nI1008 11:27:25.525559 11844 net.cpp:137] Memory required for data: 124035136\r\nI1008 11:27:25.525559 11844 layer_factory.hpp:77] Creating layer inception_3b/pool\r\nI1008 11:27:25.525559 11844 net.cpp:84] Creating Layer inception_3b/pool\r\nI1008 11:27:25.525559 11844 net.cpp:406] inception_3b/pool <- inception_3a/output_inception_3a/output_0_split_3\r\nI1008 11:27:25.525559 11844 net.cpp:380] inception_3b/pool -> inception_3b/pool\r\nI1008 11:27:25.525559 11844 net.cpp:122] Setting up inception_3b/pool\r\nI1008 11:27:25.525559 11844 net.cpp:129] Top shape: 4 256 28 28 (802816)\r\nI1008 11:27:25.525559 11844 net.cpp:137] Memory required for data: 127246400\r\nI1008 11:27:25.525559 11844 layer_factory.hpp:77] Creating layer inception_3b/pool_proj\r\nI1008 11:27:25.525559 11844 net.cpp:84] Creating Layer inception_3b/pool_proj\r\nI1008 11:27:25.525559 11844 net.cpp:406] inception_3b/pool_proj <- inception_3b/pool\r\nI1008 11:27:25.525559 11844 net.cpp:380] inception_3b/pool_proj -> inception_3b/pool_proj\r\nI1008 11:27:25.525559 11844 net.cpp:122] Setting up inception_3b/pool_proj\r\nI1008 11:27:25.525559 11844 net.cpp:129] Top shape: 4 64 28 28 (200704)\r\nI1008 11:27:25.525559 11844 net.cpp:137] Memory required for data: 128049216\r\nI1008 11:27:25.525559 11844 layer_factory.hpp:77] Creating layer inception_3b/relu_pool_proj\r\nI1008 11:27:25.525559 11844 net.cpp:84] Creating Layer inception_3b/relu_pool_proj\r\nI1008 11:27:25.525559 11844 net.cpp:406] inception_3b/relu_pool_proj <- inception_3b/pool_proj\r\nI1008 11:27:25.525559 11844 net.cpp:367] inception_3b/relu_pool_proj -> inception_3b/pool_proj (in-place)\r\nI1008 11:27:25.525559 11844 net.cpp:122] Setting up inception_3b/relu_pool_proj\r\nI1008 11:27:25.525559 11844 net.cpp:129] Top shape: 4 64 28 28 (200704)\r\nI1008 11:27:25.525559 11844 net.cpp:137] Memory required for data: 128852032\r\nI1008 11:27:25.525559 11844 layer_factory.hpp:77] Creating layer inception_3b/output\r\nI1008 11:27:25.525559 11844 net.cpp:84] Creating Layer inception_3b/output\r\nI1008 11:27:25.525559 11844 net.cpp:406] inception_3b/output <- inception_3b/1x1\r\nI1008 11:27:25.525559 11844 net.cpp:406] inception_3b/output <- inception_3b/3x3\r\nI1008 11:27:25.525559 11844 net.cpp:406] inception_3b/output <- inception_3b/5x5\r\nI1008 11:27:25.526556 11844 net.cpp:406] inception_3b/output <- inception_3b/pool_proj\r\nI1008 11:27:25.526568 11844 net.cpp:380] inception_3b/output -> inception_3b/output\r\nI1008 11:27:25.526620 11844 net.cpp:122] Setting up inception_3b/output\r\nI1008 11:27:25.526620 11844 net.cpp:129] Top shape: 4 480 28 28 (1505280)\r\nI1008 11:27:25.526620 11844 net.cpp:137] Memory required for data: 134873152\r\nI1008 11:27:25.526620 11844 layer_factory.hpp:77] Creating layer pool3/3x3_s2\r\nI1008 11:27:25.526620 11844 net.cpp:84] Creating Layer pool3/3x3_s2\r\nI1008 11:27:25.526620 11844 net.cpp:406] pool3/3x3_s2 <- inception_3b/output\r\nI1008 11:27:25.526620 11844 net.cpp:380] pool3/3x3_s2 -> pool3/3x3_s2\r\nI1008 11:27:25.526620 11844 net.cpp:122] Setting up pool3/3x3_s2\r\nI1008 11:27:25.526620 11844 net.cpp:129] Top shape: 4 480 14 14 (376320)\r\nI1008 11:27:25.526620 11844 net.cpp:137] Memory required for data: 136378432\r\nI1008 11:27:25.526620 11844 layer_factory.hpp:77] Creating layer pool3/3x3_s2_pool3/3x3_s2_0_split\r\nI1008 11:27:25.526620 11844 net.cpp:84] Creating Layer pool3/3x3_s2_pool3/3x3_s2_0_split\r\nI1008 11:27:25.526620 11844 net.cpp:406] pool3/3x3_s2_pool3/3x3_s2_0_split <- pool3/3x3_s2\r\nI1008 11:27:25.526620 11844 net.cpp:380] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_0\r\nI1008 11:27:25.526620 11844 net.cpp:380] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_1\r\nI1008 11:27:25.526620 11844 net.cpp:380] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_2\r\nI1008 11:27:25.526620 11844 net.cpp:380] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_3\r\nI1008 11:27:25.526620 11844 net.cpp:122] Setting up pool3/3x3_s2_pool3/3x3_s2_0_split\r\nI1008 11:27:25.526620 11844 net.cpp:129] Top shape: 4 480 14 14 (376320)\r\nI1008 11:27:25.526620 11844 net.cpp:129] Top shape: 4 480 14 14 (376320)\r\nI1008 11:27:25.526620 11844 net.cpp:129] Top shape: 4 480 14 14 (376320)\r\nI1008 11:27:25.526620 11844 net.cpp:129] Top shape: 4 480 14 14 (376320)\r\nI1008 11:27:25.526620 11844 net.cpp:137] Memory required for data: 142399552\r\nI1008 11:27:25.526620 11844 layer_factory.hpp:77] Creating layer inception_4a/1x1\r\nI1008 11:27:25.526620 11844 net.cpp:84] Creating Layer inception_4a/1x1\r\nI1008 11:27:25.526620 11844 net.cpp:406] inception_4a/1x1 <- pool3/3x3_s2_pool3/3x3_s2_0_split_0\r\nI1008 11:27:25.526620 11844 net.cpp:380] inception_4a/1x1 -> inception_4a/1x1\r\nI1008 11:27:25.528861 11844 net.cpp:122] Setting up inception_4a/1x1\r\nI1008 11:27:25.528861 11844 net.cpp:129] Top shape: 4 192 14 14 (150528)\r\nI1008 11:27:25.528861 11844 net.cpp:137] Memory required for data: 143001664\r\nI1008 11:27:25.528861 11844 layer_factory.hpp:77] Creating layer inception_4a/relu_1x1\r\nI1008 11:27:25.528861 11844 net.cpp:84] Creating Layer inception_4a/relu_1x1\r\nI1008 11:27:25.528861 11844 net.cpp:406] inception_4a/relu_1x1 <- inception_4a/1x1\r\nI1008 11:27:25.528861 11844 net.cpp:367] inception_4a/relu_1x1 -> inception_4a/1x1 (in-place)\r\nI1008 11:27:25.528861 11844 net.cpp:122] Setting up inception_4a/relu_1x1\r\nI1008 11:27:25.528861 11844 net.cpp:129] Top shape: 4 192 14 14 (150528)\r\nI1008 11:27:25.528861 11844 net.cpp:137] Memory required for data: 143603776\r\nI1008 11:27:25.528861 11844 layer_factory.hpp:77] Creating layer inception_4a/3x3_reduce\r\nI1008 11:27:25.528861 11844 net.cpp:84] Creating Layer inception_4a/3x3_reduce\r\nI1008 11:27:25.528861 11844 net.cpp:406] inception_4a/3x3_reduce <- pool3/3x3_s2_pool3/3x3_s2_0_split_1\r\nI1008 11:27:25.528861 11844 net.cpp:380] inception_4a/3x3_reduce -> inception_4a/3x3_reduce\r\nI1008 11:27:25.529857 11844 net.cpp:122] Setting up inception_4a/3x3_reduce\r\nI1008 11:27:25.530014 11844 net.cpp:129] Top shape: 4 96 14 14 (75264)\r\nI1008 11:27:25.530014 11844 net.cpp:137] Memory required for data: 143904832\r\nI1008 11:27:25.530014 11844 layer_factory.hpp:77] Creating layer inception_4a/relu_3x3_reduce\r\nI1008 11:27:25.530014 11844 net.cpp:84] Creating Layer inception_4a/relu_3x3_reduce\r\nI1008 11:27:25.530014 11844 net.cpp:406] inception_4a/relu_3x3_reduce <- inception_4a/3x3_reduce\r\nI1008 11:27:25.530014 11844 net.cpp:367] inception_4a/relu_3x3_reduce -> inception_4a/3x3_reduce (in-place)\r\nI1008 11:27:25.530014 11844 net.cpp:122] Setting up inception_4a/relu_3x3_reduce\r\nI1008 11:27:25.530014 11844 net.cpp:129] Top shape: 4 96 14 14 (75264)\r\nI1008 11:27:25.530014 11844 net.cpp:137] Memory required for data: 144205888\r\nI1008 11:27:25.530014 11844 layer_factory.hpp:77] Creating layer inception_4a/3x3\r\nI1008 11:27:25.530014 11844 net.cpp:84] Creating Layer inception_4a/3x3\r\nI1008 11:27:25.530014 11844 net.cpp:406] inception_4a/3x3 <- inception_4a/3x3_reduce\r\nI1008 11:27:25.530014 11844 net.cpp:380] inception_4a/3x3 -> inception_4a/3x3\r\nI1008 11:27:25.531010 11844 net.cpp:122] Setting up inception_4a/3x3\r\nI1008 11:27:25.531010 11844 net.cpp:129] Top shape: 4 208 14 14 (163072)\r\nI1008 11:27:25.531010 11844 net.cpp:137] Memory required for data: 144858176\r\nI1008 11:27:25.533253 11844 layer_factory.hpp:77] Creating layer inception_4a/relu_3x3\r\nI1008 11:27:25.533253 11844 net.cpp:84] Creating Layer inception_4a/relu_3x3\r\nI1008 11:27:25.533253 11844 net.cpp:406] inception_4a/relu_3x3 <- inception_4a/3x3\r\nI1008 11:27:25.533253 11844 net.cpp:367] inception_4a/relu_3x3 -> inception_4a/3x3 (in-place)\r\nI1008 11:27:25.533253 11844 net.cpp:122] Setting up inception_4a/relu_3x3\r\nI1008 11:27:25.533253 11844 net.cpp:129] Top shape: 4 208 14 14 (163072)\r\nI1008 11:27:25.533253 11844 net.cpp:137] Memory required for data: 145510464\r\nI1008 11:27:25.533253 11844 layer_factory.hpp:77] Creating layer inception_4a/5x5_reduce\r\nI1008 11:27:25.533253 11844 net.cpp:84] Creating Layer inception_4a/5x5_reduce\r\nI1008 11:27:25.533253 11844 net.cpp:406] inception_4a/5x5_reduce <- pool3/3x3_s2_pool3/3x3_s2_0_split_2\r\nI1008 11:27:25.533253 11844 net.cpp:380] inception_4a/5x5_reduce -> inception_4a/5x5_reduce\r\nI1008 11:27:25.533253 11844 net.cpp:122] Setting up inception_4a/5x5_reduce\r\nI1008 11:27:25.533253 11844 net.cpp:129] Top shape: 4 16 14 14 (12544)\r\nI1008 11:27:25.533253 11844 net.cpp:137] Memory required for data: 145560640\r\nI1008 11:27:25.533253 11844 layer_factory.hpp:77] Creating layer inception_4a/relu_5x5_reduce\r\nI1008 11:27:25.533253 11844 net.cpp:84] Creating Layer inception_4a/relu_5x5_reduce\r\nI1008 11:27:25.533253 11844 net.cpp:406] inception_4a/relu_5x5_reduce <- inception_4a/5x5_reduce\r\nI1008 11:27:25.533253 11844 net.cpp:367] inception_4a/relu_5x5_reduce -> inception_4a/5x5_reduce (in-place)\r\nI1008 11:27:25.533253 11844 net.cpp:122] Setting up inception_4a/relu_5x5_reduce\r\nI1008 11:27:25.533253 11844 net.cpp:129] Top shape: 4 16 14 14 (12544)\r\nI1008 11:27:25.533253 11844 net.cpp:137] Memory required for data: 145610816\r\nI1008 11:27:25.533253 11844 layer_factory.hpp:77] Creating layer inception_4a/5x5\r\nI1008 11:27:25.533253 11844 net.cpp:84] Creating Layer inception_4a/5x5\r\nI1008 11:27:25.533253 11844 net.cpp:406] inception_4a/5x5 <- inception_4a/5x5_reduce\r\nI1008 11:27:25.533253 11844 net.cpp:380] inception_4a/5x5 -> inception_4a/5x5\r\nI1008 11:27:25.534251 11844 net.cpp:122] Setting up inception_4a/5x5\r\nI1008 11:27:25.534431 11844 net.cpp:129] Top shape: 4 48 14 14 (37632)\r\nI1008 11:27:25.534431 11844 net.cpp:137] Memory required for data: 145761344\r\nI1008 11:27:25.534431 11844 layer_factory.hpp:77] Creating layer inception_4a/relu_5x5\r\nI1008 11:27:25.534431 11844 net.cpp:84] Creating Layer inception_4a/relu_5x5\r\nI1008 11:27:25.534431 11844 net.cpp:406] inception_4a/relu_5x5 <- inception_4a/5x5\r\nI1008 11:27:25.534431 11844 net.cpp:367] inception_4a/relu_5x5 -> inception_4a/5x5 (in-place)\r\nI1008 11:27:25.534431 11844 net.cpp:122] Setting up inception_4a/relu_5x5\r\nI1008 11:27:25.534431 11844 net.cpp:129] Top shape: 4 48 14 14 (37632)\r\nI1008 11:27:25.534431 11844 net.cpp:137] Memory required for data: 145911872\r\nI1008 11:27:25.534431 11844 layer_factory.hpp:77] Creating layer inception_4a/pool\r\nI1008 11:27:25.534431 11844 net.cpp:84] Creating Layer inception_4a/pool\r\nI1008 11:27:25.534431 11844 net.cpp:406] inception_4a/pool <- pool3/3x3_s2_pool3/3x3_s2_0_split_3\r\nI1008 11:27:25.534431 11844 net.cpp:380] inception_4a/pool -> inception_4a/pool\r\nI1008 11:27:25.534431 11844 net.cpp:122] Setting up inception_4a/pool\r\nI1008 11:27:25.534431 11844 net.cpp:129] Top shape: 4 480 14 14 (376320)\r\nI1008 11:27:25.534431 11844 net.cpp:137] Memory required for data: 147417152\r\nI1008 11:27:25.534431 11844 layer_factory.hpp:77] Creating layer inception_4a/pool_proj\r\nI1008 11:27:25.534431 11844 net.cpp:84] Creating Layer inception_4a/pool_proj\r\nI1008 11:27:25.534431 11844 net.cpp:406] inception_4a/pool_proj <- inception_4a/pool\r\nI1008 11:27:25.534431 11844 net.cpp:380] inception_4a/pool_proj -> inception_4a/pool_proj\r\nI1008 11:27:25.535429 11844 net.cpp:122] Setting up inception_4a/pool_proj\r\nI1008 11:27:25.535543 11844 net.cpp:129] Top shape: 4 64 14 14 (50176)\r\nI1008 11:27:25.535543 11844 net.cpp:137] Memory required for data: 147617856\r\nI1008 11:27:25.535543 11844 layer_factory.hpp:77] Creating layer inception_4a/relu_pool_proj\r\nI1008 11:27:25.535543 11844 net.cpp:84] Creating Layer inception_4a/relu_pool_proj\r\nI1008 11:27:25.535543 11844 net.cpp:406] inception_4a/relu_pool_proj <- inception_4a/pool_proj\r\nI1008 11:27:25.535543 11844 net.cpp:367] inception_4a/relu_pool_proj -> inception_4a/pool_proj (in-place)\r\nI1008 11:27:25.535543 11844 net.cpp:122] Setting up inception_4a/relu_pool_proj\r\nI1008 11:27:25.535543 11844 net.cpp:129] Top shape: 4 64 14 14 (50176)\r\nI1008 11:27:25.535543 11844 net.cpp:137] Memory required for data: 147818560\r\nI1008 11:27:25.535543 11844 layer_factory.hpp:77] Creating layer inception_4a/output\r\nI1008 11:27:25.535543 11844 net.cpp:84] Creating Layer inception_4a/output\r\nI1008 11:27:25.535543 11844 net.cpp:406] inception_4a/output <- inception_4a/1x1\r\nI1008 11:27:25.535543 11844 net.cpp:406] inception_4a/output <- inception_4a/3x3\r\nI1008 11:27:25.535543 11844 net.cpp:406] inception_4a/output <- inception_4a/5x5\r\nI1008 11:27:25.535543 11844 net.cpp:406] inception_4a/output <- inception_4a/pool_proj\r\nI1008 11:27:25.535543 11844 net.cpp:380] inception_4a/output -> inception_4a/output\r\nI1008 11:27:25.535543 11844 net.cpp:122] Setting up inception_4a/output\r\nI1008 11:27:25.535543 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.535543 11844 net.cpp:137] Memory required for data: 149424192\r\nI1008 11:27:25.535543 11844 layer_factory.hpp:77] Creating layer inception_4a/output_inception_4a/output_0_split\r\nI1008 11:27:25.535543 11844 net.cpp:84] Creating Layer inception_4a/output_inception_4a/output_0_split\r\nI1008 11:27:25.535543 11844 net.cpp:406] inception_4a/output_inception_4a/output_0_split <- inception_4a/output\r\nI1008 11:27:25.535543 11844 net.cpp:380] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_0\r\nI1008 11:27:25.535543 11844 net.cpp:380] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_1\r\nI1008 11:27:25.535543 11844 net.cpp:380] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_2\r\nI1008 11:27:25.535543 11844 net.cpp:380] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_3\r\nI1008 11:27:25.535543 11844 net.cpp:380] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_4\r\nI1008 11:27:25.535543 11844 net.cpp:122] Setting up inception_4a/output_inception_4a/output_0_split\r\nI1008 11:27:25.535543 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.535543 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.535543 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.535543 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.535543 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.535543 11844 net.cpp:137] Memory required for data: 157452352\r\nI1008 11:27:25.535543 11844 layer_factory.hpp:77] Creating layer loss1/ave_pool\r\nI1008 11:27:25.535543 11844 net.cpp:84] Creating Layer loss1/ave_pool\r\nI1008 11:27:25.536541 11844 net.cpp:406] loss1/ave_pool <- inception_4a/output_inception_4a/output_0_split_0\r\nI1008 11:27:25.536541 11844 net.cpp:380] loss1/ave_pool -> loss1/ave_pool\r\nI1008 11:27:25.536579 11844 net.cpp:122] Setting up loss1/ave_pool\r\nI1008 11:27:25.536579 11844 net.cpp:129] Top shape: 4 512 4 4 (32768)\r\nI1008 11:27:25.536579 11844 net.cpp:137] Memory required for data: 157583424\r\nI1008 11:27:25.536579 11844 layer_factory.hpp:77] Creating layer loss1/conv\r\nI1008 11:27:25.536579 11844 net.cpp:84] Creating Layer loss1/conv\r\nI1008 11:27:25.536579 11844 net.cpp:406] loss1/conv <- loss1/ave_pool\r\nI1008 11:27:25.536579 11844 net.cpp:380] loss1/conv -> loss1/conv\r\nI1008 11:27:25.537576 11844 net.cpp:122] Setting up loss1/conv\r\nI1008 11:27:25.537654 11844 net.cpp:129] Top shape: 4 128 4 4 (8192)\r\nI1008 11:27:25.537654 11844 net.cpp:137] Memory required for data: 157616192\r\nI1008 11:27:25.537654 11844 layer_factory.hpp:77] Creating layer loss1/relu_conv\r\nI1008 11:27:25.537654 11844 net.cpp:84] Creating Layer loss1/relu_conv\r\nI1008 11:27:25.537654 11844 net.cpp:406] loss1/relu_conv <- loss1/conv\r\nI1008 11:27:25.537654 11844 net.cpp:367] loss1/relu_conv -> loss1/conv (in-place)\r\nI1008 11:27:25.537654 11844 net.cpp:122] Setting up loss1/relu_conv\r\nI1008 11:27:25.537654 11844 net.cpp:129] Top shape: 4 128 4 4 (8192)\r\nI1008 11:27:25.537654 11844 net.cpp:137] Memory required for data: 157648960\r\nI1008 11:27:25.537654 11844 layer_factory.hpp:77] Creating layer loss1/fc\r\nI1008 11:27:25.537654 11844 net.cpp:84] Creating Layer loss1/fc\r\nI1008 11:27:25.537654 11844 net.cpp:406] loss1/fc <- loss1/conv\r\nI1008 11:27:25.537654 11844 net.cpp:380] loss1/fc -> loss1/fc\r\nI1008 11:27:25.562117 11844 net.cpp:122] Setting up loss1/fc\r\nI1008 11:27:25.562117 11844 net.cpp:129] Top shape: 4 1024 (4096)\r\nI1008 11:27:25.562117 11844 net.cpp:137] Memory required for data: 157665344\r\nI1008 11:27:25.562117 11844 layer_factory.hpp:77] Creating layer loss1/relu_fc\r\nI1008 11:27:25.571279 11844 net.cpp:84] Creating Layer loss1/relu_fc\r\nI1008 11:27:25.571279 11844 net.cpp:406] loss1/relu_fc <- loss1/fc\r\nI1008 11:27:25.571279 11844 net.cpp:367] loss1/relu_fc -> loss1/fc (in-place)\r\nI1008 11:27:25.571279 11844 net.cpp:122] Setting up loss1/relu_fc\r\nI1008 11:27:25.571279 11844 net.cpp:129] Top shape: 4 1024 (4096)\r\nI1008 11:27:25.571279 11844 net.cpp:137] Memory required for data: 157681728\r\nI1008 11:27:25.571279 11844 layer_factory.hpp:77] Creating layer loss1/drop_fc\r\nI1008 11:27:25.571279 11844 net.cpp:84] Creating Layer loss1/drop_fc\r\nI1008 11:27:25.571279 11844 net.cpp:406] loss1/drop_fc <- loss1/fc\r\nI1008 11:27:25.571279 11844 net.cpp:367] loss1/drop_fc -> loss1/fc (in-place)\r\nI1008 11:27:25.571279 11844 net.cpp:122] Setting up loss1/drop_fc\r\nI1008 11:27:25.571279 11844 net.cpp:129] Top shape: 4 1024 (4096)\r\nI1008 11:27:25.571279 11844 net.cpp:137] Memory required for data: 157698112\r\nI1008 11:27:25.571279 11844 layer_factory.hpp:77] Creating layer loss1/SLclassifier\r\nI1008 11:27:25.571279 11844 net.cpp:84] Creating Layer loss1/SLclassifier\r\nI1008 11:27:25.571279 11844 net.cpp:406] loss1/SLclassifier <- loss1/fc\r\nI1008 11:27:25.571279 11844 net.cpp:380] loss1/SLclassifier -> loss1/SLclassifier\r\nI1008 11:27:25.571279 11844 net.cpp:122] Setting up loss1/SLclassifier\r\nI1008 11:27:25.571279 11844 net.cpp:129] Top shape: 4 7 (28)\r\nI1008 11:27:25.571279 11844 net.cpp:137] Memory required for data: 157698224\r\nI1008 11:27:25.571279 11844 layer_factory.hpp:77] Creating layer loss1/loss\r\nI1008 11:27:25.572273 11844 net.cpp:84] Creating Layer loss1/loss\r\nI1008 11:27:25.572273 11844 net.cpp:406] loss1/loss <- loss1/SLclassifier\r\nI1008 11:27:25.572273 11844 net.cpp:406] loss1/loss <- label_data_1_split_0\r\nI1008 11:27:25.572273 11844 net.cpp:380] loss1/loss -> loss1/loss1\r\nI1008 11:27:25.572273 11844 layer_factory.hpp:77] Creating layer loss1/loss\r\nI1008 11:27:25.572273 11844 net.cpp:122] Setting up loss1/loss\r\nI1008 11:27:25.572273 11844 net.cpp:129] Top shape: (1)\r\nI1008 11:27:25.572273 11844 net.cpp:132]     with loss weight 0.3\r\nI1008 11:27:25.572273 11844 net.cpp:137] Memory required for data: 157698228\r\nI1008 11:27:25.572273 11844 layer_factory.hpp:77] Creating layer inception_4b/1x1\r\nI1008 11:27:25.572273 11844 net.cpp:84] Creating Layer inception_4b/1x1\r\nI1008 11:27:25.572273 11844 net.cpp:406] inception_4b/1x1 <- inception_4a/output_inception_4a/output_0_split_1\r\nI1008 11:27:25.572273 11844 net.cpp:380] inception_4b/1x1 -> inception_4b/1x1\r\nI1008 11:27:25.574268 11844 net.cpp:122] Setting up inception_4b/1x1\r\nI1008 11:27:25.574268 11844 net.cpp:129] Top shape: 4 160 14 14 (125440)\r\nI1008 11:27:25.574268 11844 net.cpp:137] Memory required for data: 158199988\r\nI1008 11:27:25.574268 11844 layer_factory.hpp:77] Creating layer inception_4b/relu_1x1\r\nI1008 11:27:25.574268 11844 net.cpp:84] Creating Layer inception_4b/relu_1x1\r\nI1008 11:27:25.574268 11844 net.cpp:406] inception_4b/relu_1x1 <- inception_4b/1x1\r\nI1008 11:27:25.574268 11844 net.cpp:367] inception_4b/relu_1x1 -> inception_4b/1x1 (in-place)\r\nI1008 11:27:25.574870 11844 net.cpp:122] Setting up inception_4b/relu_1x1\r\nI1008 11:27:25.574870 11844 net.cpp:129] Top shape: 4 160 14 14 (125440)\r\nI1008 11:27:25.574870 11844 net.cpp:137] Memory required for data: 158701748\r\nI1008 11:27:25.574870 11844 layer_factory.hpp:77] Creating layer inception_4b/3x3_reduce\r\nI1008 11:27:25.574870 11844 net.cpp:84] Creating Layer inception_4b/3x3_reduce\r\nI1008 11:27:25.574870 11844 net.cpp:406] inception_4b/3x3_reduce <- inception_4a/output_inception_4a/output_0_split_2\r\nI1008 11:27:25.574870 11844 net.cpp:380] inception_4b/3x3_reduce -> inception_4b/3x3_reduce\r\nI1008 11:27:25.575867 11844 net.cpp:122] Setting up inception_4b/3x3_reduce\r\nI1008 11:27:25.576043 11844 net.cpp:129] Top shape: 4 112 14 14 (87808)\r\nI1008 11:27:25.576043 11844 net.cpp:137] Memory required for data: 159052980\r\nI1008 11:27:25.576043 11844 layer_factory.hpp:77] Creating layer inception_4b/relu_3x3_reduce\r\nI1008 11:27:25.576043 11844 net.cpp:84] Creating Layer inception_4b/relu_3x3_reduce\r\nI1008 11:27:25.576043 11844 net.cpp:406] inception_4b/relu_3x3_reduce <- inception_4b/3x3_reduce\r\nI1008 11:27:25.576043 11844 net.cpp:367] inception_4b/relu_3x3_reduce -> inception_4b/3x3_reduce (in-place)\r\nI1008 11:27:25.576043 11844 net.cpp:122] Setting up inception_4b/relu_3x3_reduce\r\nI1008 11:27:25.576043 11844 net.cpp:129] Top shape: 4 112 14 14 (87808)\r\nI1008 11:27:25.576043 11844 net.cpp:137] Memory required for data: 159404212\r\nI1008 11:27:25.576043 11844 layer_factory.hpp:77] Creating layer inception_4b/3x3\r\nI1008 11:27:25.576043 11844 net.cpp:84] Creating Layer inception_4b/3x3\r\nI1008 11:27:25.576043 11844 net.cpp:406] inception_4b/3x3 <- inception_4b/3x3_reduce\r\nI1008 11:27:25.576043 11844 net.cpp:380] inception_4b/3x3 -> inception_4b/3x3\r\nI1008 11:27:25.579661 11844 net.cpp:122] Setting up inception_4b/3x3\r\nI1008 11:27:25.579661 11844 net.cpp:129] Top shape: 4 224 14 14 (175616)\r\nI1008 11:27:25.579661 11844 net.cpp:137] Memory required for data: 160106676\r\nI1008 11:27:25.579661 11844 layer_factory.hpp:77] Creating layer inception_4b/relu_3x3\r\nI1008 11:27:25.579661 11844 net.cpp:84] Creating Layer inception_4b/relu_3x3\r\nI1008 11:27:25.579661 11844 net.cpp:406] inception_4b/relu_3x3 <- inception_4b/3x3\r\nI1008 11:27:25.579661 11844 net.cpp:367] inception_4b/relu_3x3 -> inception_4b/3x3 (in-place)\r\nI1008 11:27:25.579661 11844 net.cpp:122] Setting up inception_4b/relu_3x3\r\nI1008 11:27:25.579661 11844 net.cpp:129] Top shape: 4 224 14 14 (175616)\r\nI1008 11:27:25.579661 11844 net.cpp:137] Memory required for data: 160809140\r\nI1008 11:27:25.579661 11844 layer_factory.hpp:77] Creating layer inception_4b/5x5_reduce\r\nI1008 11:27:25.579661 11844 net.cpp:84] Creating Layer inception_4b/5x5_reduce\r\nI1008 11:27:25.580657 11844 net.cpp:406] inception_4b/5x5_reduce <- inception_4a/output_inception_4a/output_0_split_3\r\nI1008 11:27:25.580657 11844 net.cpp:380] inception_4b/5x5_reduce -> inception_4b/5x5_reduce\r\nI1008 11:27:25.580657 11844 net.cpp:122] Setting up inception_4b/5x5_reduce\r\nI1008 11:27:25.580657 11844 net.cpp:129] Top shape: 4 24 14 14 (18816)\r\nI1008 11:27:25.580657 11844 net.cpp:137] Memory required for data: 160884404\r\nI1008 11:27:25.580657 11844 layer_factory.hpp:77] Creating layer inception_4b/relu_5x5_reduce\r\nI1008 11:27:25.580657 11844 net.cpp:84] Creating Layer inception_4b/relu_5x5_reduce\r\nI1008 11:27:25.580657 11844 net.cpp:406] inception_4b/relu_5x5_reduce <- inception_4b/5x5_reduce\r\nI1008 11:27:25.580657 11844 net.cpp:367] inception_4b/relu_5x5_reduce -> inception_4b/5x5_reduce (in-place)\r\nI1008 11:27:25.580657 11844 net.cpp:122] Setting up inception_4b/relu_5x5_reduce\r\nI1008 11:27:25.581322 11844 net.cpp:129] Top shape: 4 24 14 14 (18816)\r\nI1008 11:27:25.581322 11844 net.cpp:137] Memory required for data: 160959668\r\nI1008 11:27:25.581322 11844 layer_factory.hpp:77] Creating layer inception_4b/5x5\r\nI1008 11:27:25.581322 11844 net.cpp:84] Creating Layer inception_4b/5x5\r\nI1008 11:27:25.581322 11844 net.cpp:406] inception_4b/5x5 <- inception_4b/5x5_reduce\r\nI1008 11:27:25.581322 11844 net.cpp:380] inception_4b/5x5 -> inception_4b/5x5\r\nI1008 11:27:25.581322 11844 net.cpp:122] Setting up inception_4b/5x5\r\nI1008 11:27:25.581322 11844 net.cpp:129] Top shape: 4 64 14 14 (50176)\r\nI1008 11:27:25.582319 11844 net.cpp:137] Memory required for data: 161160372\r\nI1008 11:27:25.582368 11844 layer_factory.hpp:77] Creating layer inception_4b/relu_5x5\r\nI1008 11:27:25.582368 11844 net.cpp:84] Creating Layer inception_4b/relu_5x5\r\nI1008 11:27:25.582368 11844 net.cpp:406] inception_4b/relu_5x5 <- inception_4b/5x5\r\nI1008 11:27:25.582368 11844 net.cpp:367] inception_4b/relu_5x5 -> inception_4b/5x5 (in-place)\r\nI1008 11:27:25.582368 11844 net.cpp:122] Setting up inception_4b/relu_5x5\r\nI1008 11:27:25.582368 11844 net.cpp:129] Top shape: 4 64 14 14 (50176)\r\nI1008 11:27:25.582368 11844 net.cpp:137] Memory required for data: 161361076\r\nI1008 11:27:25.582368 11844 layer_factory.hpp:77] Creating layer inception_4b/pool\r\nI1008 11:27:25.582368 11844 net.cpp:84] Creating Layer inception_4b/pool\r\nI1008 11:27:25.582368 11844 net.cpp:406] inception_4b/pool <- inception_4a/output_inception_4a/output_0_split_4\r\nI1008 11:27:25.582368 11844 net.cpp:380] inception_4b/pool -> inception_4b/pool\r\nI1008 11:27:25.582368 11844 net.cpp:122] Setting up inception_4b/pool\r\nI1008 11:27:25.582368 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.582368 11844 net.cpp:137] Memory required for data: 162966708\r\nI1008 11:27:25.582368 11844 layer_factory.hpp:77] Creating layer inception_4b/pool_proj\r\nI1008 11:27:25.582368 11844 net.cpp:84] Creating Layer inception_4b/pool_proj\r\nI1008 11:27:25.582368 11844 net.cpp:406] inception_4b/pool_proj <- inception_4b/pool\r\nI1008 11:27:25.582368 11844 net.cpp:380] inception_4b/pool_proj -> inception_4b/pool_proj\r\nI1008 11:27:25.583365 11844 net.cpp:122] Setting up inception_4b/pool_proj\r\nI1008 11:27:25.583365 11844 net.cpp:129] Top shape: 4 64 14 14 (50176)\r\nI1008 11:27:25.583365 11844 net.cpp:137] Memory required for data: 163167412\r\nI1008 11:27:25.583365 11844 layer_factory.hpp:77] Creating layer inception_4b/relu_pool_proj\r\nI1008 11:27:25.583365 11844 net.cpp:84] Creating Layer inception_4b/relu_pool_proj\r\nI1008 11:27:25.583750 11844 net.cpp:406] inception_4b/relu_pool_proj <- inception_4b/pool_proj\r\nI1008 11:27:25.583750 11844 net.cpp:367] inception_4b/relu_pool_proj -> inception_4b/pool_proj (in-place)\r\nI1008 11:27:25.583750 11844 net.cpp:122] Setting up inception_4b/relu_pool_proj\r\nI1008 11:27:25.583750 11844 net.cpp:129] Top shape: 4 64 14 14 (50176)\r\nI1008 11:27:25.583750 11844 net.cpp:137] Memory required for data: 163368116\r\nI1008 11:27:25.583750 11844 layer_factory.hpp:77] Creating layer inception_4b/output\r\nI1008 11:27:25.583750 11844 net.cpp:84] Creating Layer inception_4b/output\r\nI1008 11:27:25.583750 11844 net.cpp:406] inception_4b/output <- inception_4b/1x1\r\nI1008 11:27:25.583750 11844 net.cpp:406] inception_4b/output <- inception_4b/3x3\r\nI1008 11:27:25.583750 11844 net.cpp:406] inception_4b/output <- inception_4b/5x5\r\nI1008 11:27:25.583750 11844 net.cpp:406] inception_4b/output <- inception_4b/pool_proj\r\nI1008 11:27:25.583750 11844 net.cpp:380] inception_4b/output -> inception_4b/output\r\nI1008 11:27:25.583750 11844 net.cpp:122] Setting up inception_4b/output\r\nI1008 11:27:25.583750 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.583750 11844 net.cpp:137] Memory required for data: 164973748\r\nI1008 11:27:25.583750 11844 layer_factory.hpp:77] Creating layer inception_4b/output_inception_4b/output_0_split\r\nI1008 11:27:25.583750 11844 net.cpp:84] Creating Layer inception_4b/output_inception_4b/output_0_split\r\nI1008 11:27:25.583750 11844 net.cpp:406] inception_4b/output_inception_4b/output_0_split <- inception_4b/output\r\nI1008 11:27:25.583750 11844 net.cpp:380] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_0\r\nI1008 11:27:25.583750 11844 net.cpp:380] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_1\r\nI1008 11:27:25.583750 11844 net.cpp:380] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_2\r\nI1008 11:27:25.583750 11844 net.cpp:380] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_3\r\nI1008 11:27:25.583750 11844 net.cpp:122] Setting up inception_4b/output_inception_4b/output_0_split\r\nI1008 11:27:25.584746 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.584746 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.584746 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.584746 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.584746 11844 net.cpp:137] Memory required for data: 171396276\r\nI1008 11:27:25.584746 11844 layer_factory.hpp:77] Creating layer inception_4c/1x1\r\nI1008 11:27:25.584746 11844 net.cpp:84] Creating Layer inception_4c/1x1\r\nI1008 11:27:25.584746 11844 net.cpp:406] inception_4c/1x1 <- inception_4b/output_inception_4b/output_0_split_0\r\nI1008 11:27:25.584746 11844 net.cpp:380] inception_4c/1x1 -> inception_4c/1x1\r\nI1008 11:27:25.584746 11844 net.cpp:122] Setting up inception_4c/1x1\r\nI1008 11:27:25.584746 11844 net.cpp:129] Top shape: 4 128 14 14 (100352)\r\nI1008 11:27:25.584746 11844 net.cpp:137] Memory required for data: 171797684\r\nI1008 11:27:25.584746 11844 layer_factory.hpp:77] Creating layer inception_4c/relu_1x1\r\nI1008 11:27:25.584746 11844 net.cpp:84] Creating Layer inception_4c/relu_1x1\r\nI1008 11:27:25.584746 11844 net.cpp:406] inception_4c/relu_1x1 <- inception_4c/1x1\r\nI1008 11:27:25.584746 11844 net.cpp:367] inception_4c/relu_1x1 -> inception_4c/1x1 (in-place)\r\nI1008 11:27:25.584746 11844 net.cpp:122] Setting up inception_4c/relu_1x1\r\nI1008 11:27:25.584746 11844 net.cpp:129] Top shape: 4 128 14 14 (100352)\r\nI1008 11:27:25.584746 11844 net.cpp:137] Memory required for data: 172199092\r\nI1008 11:27:25.584746 11844 layer_factory.hpp:77] Creating layer inception_4c/3x3_reduce\r\nI1008 11:27:25.584746 11844 net.cpp:84] Creating Layer inception_4c/3x3_reduce\r\nI1008 11:27:25.584746 11844 net.cpp:406] inception_4c/3x3_reduce <- inception_4b/output_inception_4b/output_0_split_1\r\nI1008 11:27:25.584746 11844 net.cpp:380] inception_4c/3x3_reduce -> inception_4c/3x3_reduce\r\nI1008 11:27:25.584746 11844 net.cpp:122] Setting up inception_4c/3x3_reduce\r\nI1008 11:27:25.584746 11844 net.cpp:129] Top shape: 4 128 14 14 (100352)\r\nI1008 11:27:25.584746 11844 net.cpp:137] Memory required for data: 172600500\r\nI1008 11:27:25.584746 11844 layer_factory.hpp:77] Creating layer inception_4c/relu_3x3_reduce\r\nI1008 11:27:25.584746 11844 net.cpp:84] Creating Layer inception_4c/relu_3x3_reduce\r\nI1008 11:27:25.584746 11844 net.cpp:406] inception_4c/relu_3x3_reduce <- inception_4c/3x3_reduce\r\nI1008 11:27:25.584746 11844 net.cpp:367] inception_4c/relu_3x3_reduce -> inception_4c/3x3_reduce (in-place)\r\nI1008 11:27:25.584746 11844 net.cpp:122] Setting up inception_4c/relu_3x3_reduce\r\nI1008 11:27:25.584746 11844 net.cpp:129] Top shape: 4 128 14 14 (100352)\r\nI1008 11:27:25.584746 11844 net.cpp:137] Memory required for data: 173001908\r\nI1008 11:27:25.584746 11844 layer_factory.hpp:77] Creating layer inception_4c/3x3\r\nI1008 11:27:25.589931 11844 net.cpp:84] Creating Layer inception_4c/3x3\r\nI1008 11:27:25.589931 11844 net.cpp:406] inception_4c/3x3 <- inception_4c/3x3_reduce\r\nI1008 11:27:25.589931 11844 net.cpp:380] inception_4c/3x3 -> inception_4c/3x3\r\nI1008 11:27:25.595118 11844 net.cpp:122] Setting up inception_4c/3x3\r\nI1008 11:27:25.596115 11844 net.cpp:129] Top shape: 4 256 14 14 (200704)\r\nI1008 11:27:25.596115 11844 net.cpp:137] Memory required for data: 173804724\r\nI1008 11:27:25.596252 11844 layer_factory.hpp:77] Creating layer inception_4c/relu_3x3\r\nI1008 11:27:25.596252 11844 net.cpp:84] Creating Layer inception_4c/relu_3x3\r\nI1008 11:27:25.596252 11844 net.cpp:406] inception_4c/relu_3x3 <- inception_4c/3x3\r\nI1008 11:27:25.596252 11844 net.cpp:367] inception_4c/relu_3x3 -> inception_4c/3x3 (in-place)\r\nI1008 11:27:25.596252 11844 net.cpp:122] Setting up inception_4c/relu_3x3\r\nI1008 11:27:25.596252 11844 net.cpp:129] Top shape: 4 256 14 14 (200704)\r\nI1008 11:27:25.596252 11844 net.cpp:137] Memory required for data: 174607540\r\nI1008 11:27:25.596252 11844 layer_factory.hpp:77] Creating layer inception_4c/5x5_reduce\r\nI1008 11:27:25.596252 11844 net.cpp:84] Creating Layer inception_4c/5x5_reduce\r\nI1008 11:27:25.596252 11844 net.cpp:406] inception_4c/5x5_reduce <- inception_4b/output_inception_4b/output_0_split_2\r\nI1008 11:27:25.596252 11844 net.cpp:380] inception_4c/5x5_reduce -> inception_4c/5x5_reduce\r\nI1008 11:27:25.596252 11844 net.cpp:122] Setting up inception_4c/5x5_reduce\r\nI1008 11:27:25.596252 11844 net.cpp:129] Top shape: 4 24 14 14 (18816)\r\nI1008 11:27:25.596252 11844 net.cpp:137] Memory required for data: 174682804\r\nI1008 11:27:25.596252 11844 layer_factory.hpp:77] Creating layer inception_4c/relu_5x5_reduce\r\nI1008 11:27:25.596252 11844 net.cpp:84] Creating Layer inception_4c/relu_5x5_reduce\r\nI1008 11:27:25.596252 11844 net.cpp:406] inception_4c/relu_5x5_reduce <- inception_4c/5x5_reduce\r\nI1008 11:27:25.597249 11844 net.cpp:367] inception_4c/relu_5x5_reduce -> inception_4c/5x5_reduce (in-place)\r\nI1008 11:27:25.597249 11844 net.cpp:122] Setting up inception_4c/relu_5x5_reduce\r\nI1008 11:27:25.597249 11844 net.cpp:129] Top shape: 4 24 14 14 (18816)\r\nI1008 11:27:25.597249 11844 net.cpp:137] Memory required for data: 174758068\r\nI1008 11:27:25.597249 11844 layer_factory.hpp:77] Creating layer inception_4c/5x5\r\nI1008 11:27:25.597249 11844 net.cpp:84] Creating Layer inception_4c/5x5\r\nI1008 11:27:25.597249 11844 net.cpp:406] inception_4c/5x5 <- inception_4c/5x5_reduce\r\nI1008 11:27:25.597249 11844 net.cpp:380] inception_4c/5x5 -> inception_4c/5x5\r\nI1008 11:27:25.598245 11844 net.cpp:122] Setting up inception_4c/5x5\r\nI1008 11:27:25.598245 11844 net.cpp:129] Top shape: 4 64 14 14 (50176)\r\nI1008 11:27:25.598245 11844 net.cpp:137] Memory required for data: 174958772\r\nI1008 11:27:25.598245 11844 layer_factory.hpp:77] Creating layer inception_4c/relu_5x5\r\nI1008 11:27:25.598245 11844 net.cpp:84] Creating Layer inception_4c/relu_5x5\r\nI1008 11:27:25.598245 11844 net.cpp:406] inception_4c/relu_5x5 <- inception_4c/5x5\r\nI1008 11:27:25.598245 11844 net.cpp:367] inception_4c/relu_5x5 -> inception_4c/5x5 (in-place)\r\nI1008 11:27:25.598245 11844 net.cpp:122] Setting up inception_4c/relu_5x5\r\nI1008 11:27:25.598886 11844 net.cpp:129] Top shape: 4 64 14 14 (50176)\r\nI1008 11:27:25.598886 11844 net.cpp:137] Memory required for data: 175159476\r\nI1008 11:27:25.598886 11844 layer_factory.hpp:77] Creating layer inception_4c/pool\r\nI1008 11:27:25.598886 11844 net.cpp:84] Creating Layer inception_4c/pool\r\nI1008 11:27:25.598886 11844 net.cpp:406] inception_4c/pool <- inception_4b/output_inception_4b/output_0_split_3\r\nI1008 11:27:25.598886 11844 net.cpp:380] inception_4c/pool -> inception_4c/pool\r\nI1008 11:27:25.598886 11844 net.cpp:122] Setting up inception_4c/pool\r\nI1008 11:27:25.598886 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.598886 11844 net.cpp:137] Memory required for data: 176765108\r\nI1008 11:27:25.598886 11844 layer_factory.hpp:77] Creating layer inception_4c/pool_proj\r\nI1008 11:27:25.598886 11844 net.cpp:84] Creating Layer inception_4c/pool_proj\r\nI1008 11:27:25.598886 11844 net.cpp:406] inception_4c/pool_proj <- inception_4c/pool\r\nI1008 11:27:25.598886 11844 net.cpp:380] inception_4c/pool_proj -> inception_4c/pool_proj\r\nI1008 11:27:25.599882 11844 net.cpp:122] Setting up inception_4c/pool_proj\r\nI1008 11:27:25.599882 11844 net.cpp:129] Top shape: 4 64 14 14 (50176)\r\nI1008 11:27:25.599882 11844 net.cpp:137] Memory required for data: 176965812\r\nI1008 11:27:25.599882 11844 layer_factory.hpp:77] Creating layer inception_4c/relu_pool_proj\r\nI1008 11:27:25.599882 11844 net.cpp:84] Creating Layer inception_4c/relu_pool_proj\r\nI1008 11:27:25.599882 11844 net.cpp:406] inception_4c/relu_pool_proj <- inception_4c/pool_proj\r\nI1008 11:27:25.599882 11844 net.cpp:367] inception_4c/relu_pool_proj -> inception_4c/pool_proj (in-place)\r\nI1008 11:27:25.600636 11844 net.cpp:122] Setting up inception_4c/relu_pool_proj\r\nI1008 11:27:25.600636 11844 net.cpp:129] Top shape: 4 64 14 14 (50176)\r\nI1008 11:27:25.600636 11844 net.cpp:137] Memory required for data: 177166516\r\nI1008 11:27:25.600636 11844 layer_factory.hpp:77] Creating layer inception_4c/output\r\nI1008 11:27:25.600636 11844 net.cpp:84] Creating Layer inception_4c/output\r\nI1008 11:27:25.600636 11844 net.cpp:406] inception_4c/output <- inception_4c/1x1\r\nI1008 11:27:25.600636 11844 net.cpp:406] inception_4c/output <- inception_4c/3x3\r\nI1008 11:27:25.600636 11844 net.cpp:406] inception_4c/output <- inception_4c/5x5\r\nI1008 11:27:25.600636 11844 net.cpp:406] inception_4c/output <- inception_4c/pool_proj\r\nI1008 11:27:25.600636 11844 net.cpp:380] inception_4c/output -> inception_4c/output\r\nI1008 11:27:25.600636 11844 net.cpp:122] Setting up inception_4c/output\r\nI1008 11:27:25.600636 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.600636 11844 net.cpp:137] Memory required for data: 178772148\r\nI1008 11:27:25.600636 11844 layer_factory.hpp:77] Creating layer inception_4c/output_inception_4c/output_0_split\r\nI1008 11:27:25.600636 11844 net.cpp:84] Creating Layer inception_4c/output_inception_4c/output_0_split\r\nI1008 11:27:25.600636 11844 net.cpp:406] inception_4c/output_inception_4c/output_0_split <- inception_4c/output\r\nI1008 11:27:25.600636 11844 net.cpp:380] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_0\r\nI1008 11:27:25.600636 11844 net.cpp:380] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_1\r\nI1008 11:27:25.601632 11844 net.cpp:380] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_2\r\nI1008 11:27:25.601632 11844 net.cpp:380] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_3\r\nI1008 11:27:25.601632 11844 net.cpp:122] Setting up inception_4c/output_inception_4c/output_0_split\r\nI1008 11:27:25.601632 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.601632 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.601632 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.601632 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.601632 11844 net.cpp:137] Memory required for data: 185194676\r\nI1008 11:27:25.601632 11844 layer_factory.hpp:77] Creating layer inception_4d/1x1\r\nI1008 11:27:25.601632 11844 net.cpp:84] Creating Layer inception_4d/1x1\r\nI1008 11:27:25.601632 11844 net.cpp:406] inception_4d/1x1 <- inception_4c/output_inception_4c/output_0_split_0\r\nI1008 11:27:25.601632 11844 net.cpp:380] inception_4d/1x1 -> inception_4d/1x1\r\nI1008 11:27:25.601632 11844 net.cpp:122] Setting up inception_4d/1x1\r\nI1008 11:27:25.603232 11844 net.cpp:129] Top shape: 4 112 14 14 (87808)\r\nI1008 11:27:25.603232 11844 net.cpp:137] Memory required for data: 185545908\r\nI1008 11:27:25.603232 11844 layer_factory.hpp:77] Creating layer inception_4d/relu_1x1\r\nI1008 11:27:25.603232 11844 net.cpp:84] Creating Layer inception_4d/relu_1x1\r\nI1008 11:27:25.603232 11844 net.cpp:406] inception_4d/relu_1x1 <- inception_4d/1x1\r\nI1008 11:27:25.603232 11844 net.cpp:367] inception_4d/relu_1x1 -> inception_4d/1x1 (in-place)\r\nI1008 11:27:25.603232 11844 net.cpp:122] Setting up inception_4d/relu_1x1\r\nI1008 11:27:25.603232 11844 net.cpp:129] Top shape: 4 112 14 14 (87808)\r\nI1008 11:27:25.603232 11844 net.cpp:137] Memory required for data: 185897140\r\nI1008 11:27:25.603232 11844 layer_factory.hpp:77] Creating layer inception_4d/3x3_reduce\r\nI1008 11:27:25.603232 11844 net.cpp:84] Creating Layer inception_4d/3x3_reduce\r\nI1008 11:27:25.603232 11844 net.cpp:406] inception_4d/3x3_reduce <- inception_4c/output_inception_4c/output_0_split_1\r\nI1008 11:27:25.603232 11844 net.cpp:380] inception_4d/3x3_reduce -> inception_4d/3x3_reduce\r\nI1008 11:27:25.604230 11844 net.cpp:122] Setting up inception_4d/3x3_reduce\r\nI1008 11:27:25.604939 11844 net.cpp:129] Top shape: 4 144 14 14 (112896)\r\nI1008 11:27:25.604939 11844 net.cpp:137] Memory required for data: 186348724\r\nI1008 11:27:25.604939 11844 layer_factory.hpp:77] Creating layer inception_4d/relu_3x3_reduce\r\nI1008 11:27:25.604939 11844 net.cpp:84] Creating Layer inception_4d/relu_3x3_reduce\r\nI1008 11:27:25.604939 11844 net.cpp:406] inception_4d/relu_3x3_reduce <- inception_4d/3x3_reduce\r\nI1008 11:27:25.604939 11844 net.cpp:367] inception_4d/relu_3x3_reduce -> inception_4d/3x3_reduce (in-place)\r\nI1008 11:27:25.604939 11844 net.cpp:122] Setting up inception_4d/relu_3x3_reduce\r\nI1008 11:27:25.604939 11844 net.cpp:129] Top shape: 4 144 14 14 (112896)\r\nI1008 11:27:25.604939 11844 net.cpp:137] Memory required for data: 186800308\r\nI1008 11:27:25.604939 11844 layer_factory.hpp:77] Creating layer inception_4d/3x3\r\nI1008 11:27:25.604939 11844 net.cpp:84] Creating Layer inception_4d/3x3\r\nI1008 11:27:25.604939 11844 net.cpp:406] inception_4d/3x3 <- inception_4d/3x3_reduce\r\nI1008 11:27:25.604939 11844 net.cpp:380] inception_4d/3x3 -> inception_4d/3x3\r\nI1008 11:27:25.608172 11844 net.cpp:122] Setting up inception_4d/3x3\r\nI1008 11:27:25.609724 11844 net.cpp:129] Top shape: 4 288 14 14 (225792)\r\nI1008 11:27:25.609724 11844 net.cpp:137] Memory required for data: 187703476\r\nI1008 11:27:25.609724 11844 layer_factory.hpp:77] Creating layer inception_4d/relu_3x3\r\nI1008 11:27:25.609724 11844 net.cpp:84] Creating Layer inception_4d/relu_3x3\r\nI1008 11:27:25.609724 11844 net.cpp:406] inception_4d/relu_3x3 <- inception_4d/3x3\r\nI1008 11:27:25.609724 11844 net.cpp:367] inception_4d/relu_3x3 -> inception_4d/3x3 (in-place)\r\nI1008 11:27:25.609724 11844 net.cpp:122] Setting up inception_4d/relu_3x3\r\nI1008 11:27:25.609724 11844 net.cpp:129] Top shape: 4 288 14 14 (225792)\r\nI1008 11:27:25.609724 11844 net.cpp:137] Memory required for data: 188606644\r\nI1008 11:27:25.609724 11844 layer_factory.hpp:77] Creating layer inception_4d/5x5_reduce\r\nI1008 11:27:25.609724 11844 net.cpp:84] Creating Layer inception_4d/5x5_reduce\r\nI1008 11:27:25.609724 11844 net.cpp:406] inception_4d/5x5_reduce <- inception_4c/output_inception_4c/output_0_split_2\r\nI1008 11:27:25.609724 11844 net.cpp:380] inception_4d/5x5_reduce -> inception_4d/5x5_reduce\r\nI1008 11:27:25.609724 11844 net.cpp:122] Setting up inception_4d/5x5_reduce\r\nI1008 11:27:25.609724 11844 net.cpp:129] Top shape: 4 32 14 14 (25088)\r\nI1008 11:27:25.609724 11844 net.cpp:137] Memory required for data: 188706996\r\nI1008 11:27:25.609724 11844 layer_factory.hpp:77] Creating layer inception_4d/relu_5x5_reduce\r\nI1008 11:27:25.609724 11844 net.cpp:84] Creating Layer inception_4d/relu_5x5_reduce\r\nI1008 11:27:25.609724 11844 net.cpp:406] inception_4d/relu_5x5_reduce <- inception_4d/5x5_reduce\r\nI1008 11:27:25.609724 11844 net.cpp:367] inception_4d/relu_5x5_reduce -> inception_4d/5x5_reduce (in-place)\r\nI1008 11:27:25.609724 11844 net.cpp:122] Setting up inception_4d/relu_5x5_reduce\r\nI1008 11:27:25.609724 11844 net.cpp:129] Top shape: 4 32 14 14 (25088)\r\nI1008 11:27:25.609724 11844 net.cpp:137] Memory required for data: 188807348\r\nI1008 11:27:25.609724 11844 layer_factory.hpp:77] Creating layer inception_4d/5x5\r\nI1008 11:27:25.609724 11844 net.cpp:84] Creating Layer inception_4d/5x5\r\nI1008 11:27:25.609724 11844 net.cpp:406] inception_4d/5x5 <- inception_4d/5x5_reduce\r\nI1008 11:27:25.610734 11844 net.cpp:380] inception_4d/5x5 -> inception_4d/5x5\r\nI1008 11:27:25.610734 11844 net.cpp:122] Setting up inception_4d/5x5\r\nI1008 11:27:25.610734 11844 net.cpp:129] Top shape: 4 64 14 14 (50176)\r\nI1008 11:27:25.610734 11844 net.cpp:137] Memory required for data: 189008052\r\nI1008 11:27:25.610734 11844 layer_factory.hpp:77] Creating layer inception_4d/relu_5x5\r\nI1008 11:27:25.610734 11844 net.cpp:84] Creating Layer inception_4d/relu_5x5\r\nI1008 11:27:25.610734 11844 net.cpp:406] inception_4d/relu_5x5 <- inception_4d/5x5\r\nI1008 11:27:25.610734 11844 net.cpp:367] inception_4d/relu_5x5 -> inception_4d/5x5 (in-place)\r\nI1008 11:27:25.610734 11844 net.cpp:122] Setting up inception_4d/relu_5x5\r\nI1008 11:27:25.610734 11844 net.cpp:129] Top shape: 4 64 14 14 (50176)\r\nI1008 11:27:25.610734 11844 net.cpp:137] Memory required for data: 189208756\r\nI1008 11:27:25.610734 11844 layer_factory.hpp:77] Creating layer inception_4d/pool\r\nI1008 11:27:25.610734 11844 net.cpp:84] Creating Layer inception_4d/pool\r\nI1008 11:27:25.610734 11844 net.cpp:406] inception_4d/pool <- inception_4c/output_inception_4c/output_0_split_3\r\nI1008 11:27:25.610734 11844 net.cpp:380] inception_4d/pool -> inception_4d/pool\r\nI1008 11:27:25.611732 11844 net.cpp:122] Setting up inception_4d/pool\r\nI1008 11:27:25.611776 11844 net.cpp:129] Top shape: 4 512 14 14 (401408)\r\nI1008 11:27:25.611776 11844 net.cpp:137] Memory required for data: 190814388\r\nI1008 11:27:25.611776 11844 layer_factory.hpp:77] Creating layer inception_4d/pool_proj\r\nI1008 11:27:25.611776 11844 net.cpp:84] Creating Layer inception_4d/pool_proj\r\nI1008 11:27:25.611776 11844 net.cpp:406] inception_4d/pool_proj <- inception_4d/pool\r\nI1008 11:27:25.611776 11844 net.cpp:380] inception_4d/pool_proj -> inception_4d/pool_proj\r\nI1008 11:27:25.611776 11844 net.cpp:122] Setting up inception_4d/pool_proj\r\nI1008 11:27:25.611776 11844 net.cpp:129] Top shape: 4 64 14 14 (50176)\r\nI1008 11:27:25.611776 11844 net.cpp:137] Memory required for data: 191015092\r\nI1008 11:27:25.611776 11844 layer_factory.hpp:77] Creating layer inception_4d/relu_pool_proj\r\nI1008 11:27:25.611776 11844 net.cpp:84] Creating Layer inception_4d/relu_pool_proj\r\nI1008 11:27:25.611776 11844 net.cpp:406] inception_4d/relu_pool_proj <- inception_4d/pool_proj\r\nI1008 11:27:25.611776 11844 net.cpp:367] inception_4d/relu_pool_proj -> inception_4d/pool_proj (in-place)\r\nI1008 11:27:25.611776 11844 net.cpp:122] Setting up inception_4d/relu_pool_proj\r\nI1008 11:27:25.611776 11844 net.cpp:129] Top shape: 4 64 14 14 (50176)\r\nI1008 11:27:25.611776 11844 net.cpp:137] Memory required for data: 191215796\r\nI1008 11:27:25.611776 11844 layer_factory.hpp:77] Creating layer inception_4d/output\r\nI1008 11:27:25.611776 11844 net.cpp:84] Creating Layer inception_4d/output\r\nI1008 11:27:25.611776 11844 net.cpp:406] inception_4d/output <- inception_4d/1x1\r\nI1008 11:27:25.611776 11844 net.cpp:406] inception_4d/output <- inception_4d/3x3\r\nI1008 11:27:25.611776 11844 net.cpp:406] inception_4d/output <- inception_4d/5x5\r\nI1008 11:27:25.612776 11844 net.cpp:406] inception_4d/output <- inception_4d/pool_proj\r\nI1008 11:27:25.612818 11844 net.cpp:380] inception_4d/output -> inception_4d/output\r\nI1008 11:27:25.612818 11844 net.cpp:122] Setting up inception_4d/output\r\nI1008 11:27:25.612818 11844 net.cpp:129] Top shape: 4 528 14 14 (413952)\r\nI1008 11:27:25.612818 11844 net.cpp:137] Memory required for data: 192871604\r\nI1008 11:27:25.612818 11844 layer_factory.hpp:77] Creating layer inception_4d/output_inception_4d/output_0_split\r\nI1008 11:27:25.612818 11844 net.cpp:84] Creating Layer inception_4d/output_inception_4d/output_0_split\r\nI1008 11:27:25.612818 11844 net.cpp:406] inception_4d/output_inception_4d/output_0_split <- inception_4d/output\r\nI1008 11:27:25.612818 11844 net.cpp:380] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_0\r\nI1008 11:27:25.612818 11844 net.cpp:380] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_1\r\nI1008 11:27:25.612818 11844 net.cpp:380] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_2\r\nI1008 11:27:25.612818 11844 net.cpp:380] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_3\r\nI1008 11:27:25.612818 11844 net.cpp:380] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_4\r\nI1008 11:27:25.612818 11844 net.cpp:122] Setting up inception_4d/output_inception_4d/output_0_split\r\nI1008 11:27:25.612818 11844 net.cpp:129] Top shape: 4 528 14 14 (413952)\r\nI1008 11:27:25.612818 11844 net.cpp:129] Top shape: 4 528 14 14 (413952)\r\nI1008 11:27:25.612818 11844 net.cpp:129] Top shape: 4 528 14 14 (413952)\r\nI1008 11:27:25.612818 11844 net.cpp:129] Top shape: 4 528 14 14 (413952)\r\nI1008 11:27:25.612818 11844 net.cpp:129] Top shape: 4 528 14 14 (413952)\r\nI1008 11:27:25.612818 11844 net.cpp:137] Memory required for data: 201150644\r\nI1008 11:27:25.612818 11844 layer_factory.hpp:77] Creating layer loss2/ave_pool\r\nI1008 11:27:25.612818 11844 net.cpp:84] Creating Layer loss2/ave_pool\r\nI1008 11:27:25.612818 11844 net.cpp:406] loss2/ave_pool <- inception_4d/output_inception_4d/output_0_split_0\r\nI1008 11:27:25.612818 11844 net.cpp:380] loss2/ave_pool -> loss2/ave_pool\r\nI1008 11:27:25.612818 11844 net.cpp:122] Setting up loss2/ave_pool\r\nI1008 11:27:25.612818 11844 net.cpp:129] Top shape: 4 528 4 4 (33792)\r\nI1008 11:27:25.612818 11844 net.cpp:137] Memory required for data: 201285812\r\nI1008 11:27:25.612818 11844 layer_factory.hpp:77] Creating layer loss2/conv\r\nI1008 11:27:25.612818 11844 net.cpp:84] Creating Layer loss2/conv\r\nI1008 11:27:25.612818 11844 net.cpp:406] loss2/conv <- loss2/ave_pool\r\nI1008 11:27:25.613842 11844 net.cpp:380] loss2/conv -> loss2/conv\r\nI1008 11:27:25.613842 11844 net.cpp:122] Setting up loss2/conv\r\nI1008 11:27:25.613842 11844 net.cpp:129] Top shape: 4 128 4 4 (8192)\r\nI1008 11:27:25.613842 11844 net.cpp:137] Memory required for data: 201318580\r\nI1008 11:27:25.613842 11844 layer_factory.hpp:77] Creating layer loss2/relu_conv\r\nI1008 11:27:25.613842 11844 net.cpp:84] Creating Layer loss2/relu_conv\r\nI1008 11:27:25.613842 11844 net.cpp:406] loss2/relu_conv <- loss2/conv\r\nI1008 11:27:25.613842 11844 net.cpp:367] loss2/relu_conv -> loss2/conv (in-place)\r\nI1008 11:27:25.613842 11844 net.cpp:122] Setting up loss2/relu_conv\r\nI1008 11:27:25.613842 11844 net.cpp:129] Top shape: 4 128 4 4 (8192)\r\nI1008 11:27:25.613842 11844 net.cpp:137] Memory required for data: 201351348\r\nI1008 11:27:25.614840 11844 layer_factory.hpp:77] Creating layer loss2/fc\r\nI1008 11:27:25.614876 11844 net.cpp:84] Creating Layer loss2/fc\r\nI1008 11:27:25.614876 11844 net.cpp:406] loss2/fc <- loss2/conv\r\nI1008 11:27:25.614876 11844 net.cpp:380] loss2/fc -> loss2/fc\r\nI1008 11:27:25.645296 11844 net.cpp:122] Setting up loss2/fc\r\nI1008 11:27:25.645296 11844 net.cpp:129] Top shape: 4 1024 (4096)\r\nI1008 11:27:25.645296 11844 net.cpp:137] Memory required for data: 201367732\r\nI1008 11:27:25.645666 11844 layer_factory.hpp:77] Creating layer loss2/relu_fc\r\nI1008 11:27:25.645666 11844 net.cpp:84] Creating Layer loss2/relu_fc\r\nI1008 11:27:25.645666 11844 net.cpp:406] loss2/relu_fc <- loss2/fc\r\nI1008 11:27:25.645666 11844 net.cpp:367] loss2/relu_fc -> loss2/fc (in-place)\r\nI1008 11:27:25.645666 11844 net.cpp:122] Setting up loss2/relu_fc\r\nI1008 11:27:25.645666 11844 net.cpp:129] Top shape: 4 1024 (4096)\r\nI1008 11:27:25.645666 11844 net.cpp:137] Memory required for data: 201384116\r\nI1008 11:27:25.645666 11844 layer_factory.hpp:77] Creating layer loss2/drop_fc\r\nI1008 11:27:25.645666 11844 net.cpp:84] Creating Layer loss2/drop_fc\r\nI1008 11:27:25.645666 11844 net.cpp:406] loss2/drop_fc <- loss2/fc\r\nI1008 11:27:25.645666 11844 net.cpp:367] loss2/drop_fc -> loss2/fc (in-place)\r\nI1008 11:27:25.645666 11844 net.cpp:122] Setting up loss2/drop_fc\r\nI1008 11:27:25.645666 11844 net.cpp:129] Top shape: 4 1024 (4096)\r\nI1008 11:27:25.645666 11844 net.cpp:137] Memory required for data: 201400500\r\nI1008 11:27:25.645666 11844 layer_factory.hpp:77] Creating layer loss2/SLclassifier\r\nI1008 11:27:25.645666 11844 net.cpp:84] Creating Layer loss2/SLclassifier\r\nI1008 11:27:25.645666 11844 net.cpp:406] loss2/SLclassifier <- loss2/fc\r\nI1008 11:27:25.645666 11844 net.cpp:380] loss2/SLclassifier -> loss2/SLclassifier\r\nI1008 11:27:25.645666 11844 net.cpp:122] Setting up loss2/SLclassifier\r\nI1008 11:27:25.645666 11844 net.cpp:129] Top shape: 4 7 (28)\r\nI1008 11:27:25.645666 11844 net.cpp:137] Memory required for data: 201400612\r\nI1008 11:27:25.645666 11844 layer_factory.hpp:77] Creating layer loss2/loss\r\nI1008 11:27:25.645666 11844 net.cpp:84] Creating Layer loss2/loss\r\nI1008 11:27:25.645666 11844 net.cpp:406] loss2/loss <- loss2/SLclassifier\r\nI1008 11:27:25.645666 11844 net.cpp:406] loss2/loss <- label_data_1_split_1\r\nI1008 11:27:25.645666 11844 net.cpp:380] loss2/loss -> loss2/loss1\r\nI1008 11:27:25.645666 11844 layer_factory.hpp:77] Creating layer loss2/loss\r\nI1008 11:27:25.645666 11844 net.cpp:122] Setting up loss2/loss\r\nI1008 11:27:25.646663 11844 net.cpp:129] Top shape: (1)\r\nI1008 11:27:25.646663 11844 net.cpp:132]     with loss weight 0.3\r\nI1008 11:27:25.646726 11844 net.cpp:137] Memory required for data: 201400616\r\nI1008 11:27:25.646726 11844 layer_factory.hpp:77] Creating layer inception_4e/1x1\r\nI1008 11:27:25.646726 11844 net.cpp:84] Creating Layer inception_4e/1x1\r\nI1008 11:27:25.646726 11844 net.cpp:406] inception_4e/1x1 <- inception_4d/output_inception_4d/output_0_split_1\r\nI1008 11:27:25.646726 11844 net.cpp:380] inception_4e/1x1 -> inception_4e/1x1\r\nI1008 11:27:25.647725 11844 net.cpp:122] Setting up inception_4e/1x1\r\nI1008 11:27:25.647725 11844 net.cpp:129] Top shape: 4 256 14 14 (200704)\r\nI1008 11:27:25.649039 11844 net.cpp:137] Memory required for data: 202203432\r\nI1008 11:27:25.649039 11844 layer_factory.hpp:77] Creating layer inception_4e/relu_1x1\r\nI1008 11:27:25.649039 11844 net.cpp:84] Creating Layer inception_4e/relu_1x1\r\nI1008 11:27:25.649039 11844 net.cpp:406] inception_4e/relu_1x1 <- inception_4e/1x1\r\nI1008 11:27:25.649039 11844 net.cpp:367] inception_4e/relu_1x1 -> inception_4e/1x1 (in-place)\r\nI1008 11:27:25.649039 11844 net.cpp:122] Setting up inception_4e/relu_1x1\r\nI1008 11:27:25.649039 11844 net.cpp:129] Top shape: 4 256 14 14 (200704)\r\nI1008 11:27:25.649039 11844 net.cpp:137] Memory required for data: 203006248\r\nI1008 11:27:25.649039 11844 layer_factory.hpp:77] Creating layer inception_4e/3x3_reduce\r\nI1008 11:27:25.649039 11844 net.cpp:84] Creating Layer inception_4e/3x3_reduce\r\nI1008 11:27:25.649039 11844 net.cpp:406] inception_4e/3x3_reduce <- inception_4d/output_inception_4d/output_0_split_2\r\nI1008 11:27:25.649039 11844 net.cpp:380] inception_4e/3x3_reduce -> inception_4e/3x3_reduce\r\nI1008 11:27:25.650038 11844 net.cpp:122] Setting up inception_4e/3x3_reduce\r\nI1008 11:27:25.650038 11844 net.cpp:129] Top shape: 4 160 14 14 (125440)\r\nI1008 11:27:25.650708 11844 net.cpp:137] Memory required for data: 203508008\r\nI1008 11:27:25.650708 11844 layer_factory.hpp:77] Creating layer inception_4e/relu_3x3_reduce\r\nI1008 11:27:25.650708 11844 net.cpp:84] Creating Layer inception_4e/relu_3x3_reduce\r\nI1008 11:27:25.650708 11844 net.cpp:406] inception_4e/relu_3x3_reduce <- inception_4e/3x3_reduce\r\nI1008 11:27:25.650708 11844 net.cpp:367] inception_4e/relu_3x3_reduce -> inception_4e/3x3_reduce (in-place)\r\nI1008 11:27:25.650708 11844 net.cpp:122] Setting up inception_4e/relu_3x3_reduce\r\nI1008 11:27:25.650708 11844 net.cpp:129] Top shape: 4 160 14 14 (125440)\r\nI1008 11:27:25.650708 11844 net.cpp:137] Memory required for data: 204009768\r\nI1008 11:27:25.650708 11844 layer_factory.hpp:77] Creating layer inception_4e/3x3\r\nI1008 11:27:25.650708 11844 net.cpp:84] Creating Layer inception_4e/3x3\r\nI1008 11:27:25.650708 11844 net.cpp:406] inception_4e/3x3 <- inception_4e/3x3_reduce\r\nI1008 11:27:25.650708 11844 net.cpp:380] inception_4e/3x3 -> inception_4e/3x3\r\nI1008 11:27:25.658435 11844 net.cpp:122] Setting up inception_4e/3x3\r\nI1008 11:27:25.658435 11844 net.cpp:129] Top shape: 4 320 14 14 (250880)\r\nI1008 11:27:25.658435 11844 net.cpp:137] Memory required for data: 205013288\r\nI1008 11:27:25.658435 11844 layer_factory.hpp:77] Creating layer inception_4e/relu_3x3\r\nI1008 11:27:25.658435 11844 net.cpp:84] Creating Layer inception_4e/relu_3x3\r\nI1008 11:27:25.658435 11844 net.cpp:406] inception_4e/relu_3x3 <- inception_4e/3x3\r\nI1008 11:27:25.658435 11844 net.cpp:367] inception_4e/relu_3x3 -> inception_4e/3x3 (in-place)\r\nI1008 11:27:25.658435 11844 net.cpp:122] Setting up inception_4e/relu_3x3\r\nI1008 11:27:25.658435 11844 net.cpp:129] Top shape: 4 320 14 14 (250880)\r\nI1008 11:27:25.658435 11844 net.cpp:137] Memory required for data: 206016808\r\nI1008 11:27:25.658435 11844 layer_factory.hpp:77] Creating layer inception_4e/5x5_reduce\r\nI1008 11:27:25.658435 11844 net.cpp:84] Creating Layer inception_4e/5x5_reduce\r\nI1008 11:27:25.658435 11844 net.cpp:406] inception_4e/5x5_reduce <- inception_4d/output_inception_4d/output_0_split_3\r\nI1008 11:27:25.658435 11844 net.cpp:380] inception_4e/5x5_reduce -> inception_4e/5x5_reduce\r\nI1008 11:27:25.658435 11844 net.cpp:122] Setting up inception_4e/5x5_reduce\r\nI1008 11:27:25.658435 11844 net.cpp:129] Top shape: 4 32 14 14 (25088)\r\nI1008 11:27:25.658435 11844 net.cpp:137] Memory required for data: 206117160\r\nI1008 11:27:25.658435 11844 layer_factory.hpp:77] Creating layer inception_4e/relu_5x5_reduce\r\nI1008 11:27:25.658435 11844 net.cpp:84] Creating Layer inception_4e/relu_5x5_reduce\r\nI1008 11:27:25.658435 11844 net.cpp:406] inception_4e/relu_5x5_reduce <- inception_4e/5x5_reduce\r\nI1008 11:27:25.658435 11844 net.cpp:367] inception_4e/relu_5x5_reduce -> inception_4e/5x5_reduce (in-place)\r\nI1008 11:27:25.658435 11844 net.cpp:122] Setting up inception_4e/relu_5x5_reduce\r\nI1008 11:27:25.658435 11844 net.cpp:129] Top shape: 4 32 14 14 (25088)\r\nI1008 11:27:25.658435 11844 net.cpp:137] Memory required for data: 206217512\r\nI1008 11:27:25.659432 11844 layer_factory.hpp:77] Creating layer inception_4e/5x5\r\nI1008 11:27:25.659432 11844 net.cpp:84] Creating Layer inception_4e/5x5\r\nI1008 11:27:25.659432 11844 net.cpp:406] inception_4e/5x5 <- inception_4e/5x5_reduce\r\nI1008 11:27:25.659432 11844 net.cpp:380] inception_4e/5x5 -> inception_4e/5x5\r\nI1008 11:27:25.659432 11844 net.cpp:122] Setting up inception_4e/5x5\r\nI1008 11:27:25.659432 11844 net.cpp:129] Top shape: 4 128 14 14 (100352)\r\nI1008 11:27:25.660430 11844 net.cpp:137] Memory required for data: 206618920\r\nI1008 11:27:25.660430 11844 layer_factory.hpp:77] Creating layer inception_4e/relu_5x5\r\nI1008 11:27:25.660482 11844 net.cpp:84] Creating Layer inception_4e/relu_5x5\r\nI1008 11:27:25.660482 11844 net.cpp:406] inception_4e/relu_5x5 <- inception_4e/5x5\r\nI1008 11:27:25.660482 11844 net.cpp:367] inception_4e/relu_5x5 -> inception_4e/5x5 (in-place)\r\nI1008 11:27:25.660482 11844 net.cpp:122] Setting up inception_4e/relu_5x5\r\nI1008 11:27:25.660482 11844 net.cpp:129] Top shape: 4 128 14 14 (100352)\r\nI1008 11:27:25.660482 11844 net.cpp:137] Memory required for data: 207020328\r\nI1008 11:27:25.660482 11844 layer_factory.hpp:77] Creating layer inception_4e/pool\r\nI1008 11:27:25.660482 11844 net.cpp:84] Creating Layer inception_4e/pool\r\nI1008 11:27:25.660482 11844 net.cpp:406] inception_4e/pool <- inception_4d/output_inception_4d/output_0_split_4\r\nI1008 11:27:25.660482 11844 net.cpp:380] inception_4e/pool -> inception_4e/pool\r\nI1008 11:27:25.660482 11844 net.cpp:122] Setting up inception_4e/pool\r\nI1008 11:27:25.660482 11844 net.cpp:129] Top shape: 4 528 14 14 (413952)\r\nI1008 11:27:25.660482 11844 net.cpp:137] Memory required for data: 208676136\r\nI1008 11:27:25.660482 11844 layer_factory.hpp:77] Creating layer inception_4e/pool_proj\r\nI1008 11:27:25.660482 11844 net.cpp:84] Creating Layer inception_4e/pool_proj\r\nI1008 11:27:25.660482 11844 net.cpp:406] inception_4e/pool_proj <- inception_4e/pool\r\nI1008 11:27:25.660482 11844 net.cpp:380] inception_4e/pool_proj -> inception_4e/pool_proj\r\nI1008 11:27:25.660482 11844 net.cpp:122] Setting up inception_4e/pool_proj\r\nI1008 11:27:25.660482 11844 net.cpp:129] Top shape: 4 128 14 14 (100352)\r\nI1008 11:27:25.660482 11844 net.cpp:137] Memory required for data: 209077544\r\nI1008 11:27:25.660482 11844 layer_factory.hpp:77] Creating layer inception_4e/relu_pool_proj\r\nI1008 11:27:25.660482 11844 net.cpp:84] Creating Layer inception_4e/relu_pool_proj\r\nI1008 11:27:25.661506 11844 net.cpp:406] inception_4e/relu_pool_proj <- inception_4e/pool_proj\r\nI1008 11:27:25.661506 11844 net.cpp:367] inception_4e/relu_pool_proj -> inception_4e/pool_proj (in-place)\r\nI1008 11:27:25.661506 11844 net.cpp:122] Setting up inception_4e/relu_pool_proj\r\nI1008 11:27:25.661506 11844 net.cpp:129] Top shape: 4 128 14 14 (100352)\r\nI1008 11:27:25.661506 11844 net.cpp:137] Memory required for data: 209478952\r\nI1008 11:27:25.661506 11844 layer_factory.hpp:77] Creating layer inception_4e/output\r\nI1008 11:27:25.661506 11844 net.cpp:84] Creating Layer inception_4e/output\r\nI1008 11:27:25.661506 11844 net.cpp:406] inception_4e/output <- inception_4e/1x1\r\nI1008 11:27:25.661506 11844 net.cpp:406] inception_4e/output <- inception_4e/3x3\r\nI1008 11:27:25.661506 11844 net.cpp:406] inception_4e/output <- inception_4e/5x5\r\nI1008 11:27:25.661506 11844 net.cpp:406] inception_4e/output <- inception_4e/pool_proj\r\nI1008 11:27:25.661506 11844 net.cpp:380] inception_4e/output -> inception_4e/output\r\nI1008 11:27:25.661506 11844 net.cpp:122] Setting up inception_4e/output\r\nI1008 11:27:25.661506 11844 net.cpp:129] Top shape: 4 832 14 14 (652288)\r\nI1008 11:27:25.661506 11844 net.cpp:137] Memory required for data: 212088104\r\nI1008 11:27:25.661506 11844 layer_factory.hpp:77] Creating layer pool4/3x3_s2\r\nI1008 11:27:25.661506 11844 net.cpp:84] Creating Layer pool4/3x3_s2\r\nI1008 11:27:25.661506 11844 net.cpp:406] pool4/3x3_s2 <- inception_4e/output\r\nI1008 11:27:25.661506 11844 net.cpp:380] pool4/3x3_s2 -> pool4/3x3_s2\r\nI1008 11:27:25.661506 11844 net.cpp:122] Setting up pool4/3x3_s2\r\nI1008 11:27:25.661506 11844 net.cpp:129] Top shape: 4 832 7 7 (163072)\r\nI1008 11:27:25.661506 11844 net.cpp:137] Memory required for data: 212740392\r\nI1008 11:27:25.661506 11844 layer_factory.hpp:77] Creating layer pool4/3x3_s2_pool4/3x3_s2_0_split\r\nI1008 11:27:25.661506 11844 net.cpp:84] Creating Layer pool4/3x3_s2_pool4/3x3_s2_0_split\r\nI1008 11:27:25.661506 11844 net.cpp:406] pool4/3x3_s2_pool4/3x3_s2_0_split <- pool4/3x3_s2\r\nI1008 11:27:25.661506 11844 net.cpp:380] pool4/3x3_s2_pool4/3x3_s2_0_split -> pool4/3x3_s2_pool4/3x3_s2_0_split_0\r\nI1008 11:27:25.661506 11844 net.cpp:380] pool4/3x3_s2_pool4/3x3_s2_0_split -> pool4/3x3_s2_pool4/3x3_s2_0_split_1\r\nI1008 11:27:25.661506 11844 net.cpp:380] pool4/3x3_s2_pool4/3x3_s2_0_split -> pool4/3x3_s2_pool4/3x3_s2_0_split_2\r\nI1008 11:27:25.661506 11844 net.cpp:380] pool4/3x3_s2_pool4/3x3_s2_0_split -> pool4/3x3_s2_pool4/3x3_s2_0_split_3\r\nI1008 11:27:25.661506 11844 net.cpp:122] Setting up pool4/3x3_s2_pool4/3x3_s2_0_split\r\nI1008 11:27:25.661506 11844 net.cpp:129] Top shape: 4 832 7 7 (163072)\r\nI1008 11:27:25.661506 11844 net.cpp:129] Top shape: 4 832 7 7 (163072)\r\nI1008 11:27:25.661506 11844 net.cpp:129] Top shape: 4 832 7 7 (163072)\r\nI1008 11:27:25.661506 11844 net.cpp:129] Top shape: 4 832 7 7 (163072)\r\nI1008 11:27:25.661506 11844 net.cpp:137] Memory required for data: 215349544\r\nI1008 11:27:25.661506 11844 layer_factory.hpp:77] Creating layer inception_5a/1x1\r\nI1008 11:27:25.661506 11844 net.cpp:84] Creating Layer inception_5a/1x1\r\nI1008 11:27:25.662503 11844 net.cpp:406] inception_5a/1x1 <- pool4/3x3_s2_pool4/3x3_s2_0_split_0\r\nI1008 11:27:25.662503 11844 net.cpp:380] inception_5a/1x1 -> inception_5a/1x1\r\nI1008 11:27:25.663502 11844 net.cpp:122] Setting up inception_5a/1x1\r\nI1008 11:27:25.664500 11844 net.cpp:129] Top shape: 4 256 7 7 (50176)\r\nI1008 11:27:25.664500 11844 net.cpp:137] Memory required for data: 215550248\r\nI1008 11:27:25.664500 11844 layer_factory.hpp:77] Creating layer inception_5a/relu_1x1\r\nI1008 11:27:25.664572 11844 net.cpp:84] Creating Layer inception_5a/relu_1x1\r\nI1008 11:27:25.664572 11844 net.cpp:406] inception_5a/relu_1x1 <- inception_5a/1x1\r\nI1008 11:27:25.664572 11844 net.cpp:367] inception_5a/relu_1x1 -> inception_5a/1x1 (in-place)\r\nI1008 11:27:25.664572 11844 net.cpp:122] Setting up inception_5a/relu_1x1\r\nI1008 11:27:25.664572 11844 net.cpp:129] Top shape: 4 256 7 7 (50176)\r\nI1008 11:27:25.664572 11844 net.cpp:137] Memory required for data: 215750952\r\nI1008 11:27:25.664572 11844 layer_factory.hpp:77] Creating layer inception_5a/3x3_reduce\r\nI1008 11:27:25.664572 11844 net.cpp:84] Creating Layer inception_5a/3x3_reduce\r\nI1008 11:27:25.664572 11844 net.cpp:406] inception_5a/3x3_reduce <- pool4/3x3_s2_pool4/3x3_s2_0_split_1\r\nI1008 11:27:25.664572 11844 net.cpp:380] inception_5a/3x3_reduce -> inception_5a/3x3_reduce\r\nI1008 11:27:25.665570 11844 net.cpp:122] Setting up inception_5a/3x3_reduce\r\nI1008 11:27:25.665570 11844 net.cpp:129] Top shape: 4 160 7 7 (31360)\r\nI1008 11:27:25.666005 11844 net.cpp:137] Memory required for data: 215876392\r\nI1008 11:27:25.666005 11844 layer_factory.hpp:77] Creating layer inception_5a/relu_3x3_reduce\r\nI1008 11:27:25.666005 11844 net.cpp:84] Creating Layer inception_5a/relu_3x3_reduce\r\nI1008 11:27:25.666005 11844 net.cpp:406] inception_5a/relu_3x3_reduce <- inception_5a/3x3_reduce\r\nI1008 11:27:25.666005 11844 net.cpp:367] inception_5a/relu_3x3_reduce -> inception_5a/3x3_reduce (in-place)\r\nI1008 11:27:25.666005 11844 net.cpp:122] Setting up inception_5a/relu_3x3_reduce\r\nI1008 11:27:25.666005 11844 net.cpp:129] Top shape: 4 160 7 7 (31360)\r\nI1008 11:27:25.666005 11844 net.cpp:137] Memory required for data: 216001832\r\nI1008 11:27:25.666005 11844 layer_factory.hpp:77] Creating layer inception_5a/3x3\r\nI1008 11:27:25.666005 11844 net.cpp:84] Creating Layer inception_5a/3x3\r\nI1008 11:27:25.666005 11844 net.cpp:406] inception_5a/3x3 <- inception_5a/3x3_reduce\r\nI1008 11:27:25.666005 11844 net.cpp:380] inception_5a/3x3 -> inception_5a/3x3\r\nI1008 11:27:25.667004 11844 net.cpp:122] Setting up inception_5a/3x3\r\nI1008 11:27:25.667004 11844 net.cpp:129] Top shape: 4 320 7 7 (62720)\r\nI1008 11:27:25.667004 11844 net.cpp:137] Memory required for data: 216252712\r\nI1008 11:27:25.670511 11844 layer_factory.hpp:77] Creating layer inception_5a/relu_3x3\r\nI1008 11:27:25.670511 11844 net.cpp:84] Creating Layer inception_5a/relu_3x3\r\nI1008 11:27:25.670511 11844 net.cpp:406] inception_5a/relu_3x3 <- inception_5a/3x3\r\nI1008 11:27:25.670511 11844 net.cpp:367] inception_5a/relu_3x3 -> inception_5a/3x3 (in-place)\r\nI1008 11:27:25.670511 11844 net.cpp:122] Setting up inception_5a/relu_3x3\r\nI1008 11:27:25.670511 11844 net.cpp:129] Top shape: 4 320 7 7 (62720)\r\nI1008 11:27:25.670511 11844 net.cpp:137] Memory required for data: 216503592\r\nI1008 11:27:25.670511 11844 layer_factory.hpp:77] Creating layer inception_5a/5x5_reduce\r\nI1008 11:27:25.670511 11844 net.cpp:84] Creating Layer inception_5a/5x5_reduce\r\nI1008 11:27:25.670511 11844 net.cpp:406] inception_5a/5x5_reduce <- pool4/3x3_s2_pool4/3x3_s2_0_split_2\r\nI1008 11:27:25.670511 11844 net.cpp:380] inception_5a/5x5_reduce -> inception_5a/5x5_reduce\r\nI1008 11:27:25.670511 11844 net.cpp:122] Setting up inception_5a/5x5_reduce\r\nI1008 11:27:25.670511 11844 net.cpp:129] Top shape: 4 32 7 7 (6272)\r\nI1008 11:27:25.670511 11844 net.cpp:137] Memory required for data: 216528680\r\nI1008 11:27:25.670511 11844 layer_factory.hpp:77] Creating layer inception_5a/relu_5x5_reduce\r\nI1008 11:27:25.670511 11844 net.cpp:84] Creating Layer inception_5a/relu_5x5_reduce\r\nI1008 11:27:25.670511 11844 net.cpp:406] inception_5a/relu_5x5_reduce <- inception_5a/5x5_reduce\r\nI1008 11:27:25.670511 11844 net.cpp:367] inception_5a/relu_5x5_reduce -> inception_5a/5x5_reduce (in-place)\r\nI1008 11:27:25.670511 11844 net.cpp:122] Setting up inception_5a/relu_5x5_reduce\r\nI1008 11:27:25.670511 11844 net.cpp:129] Top shape: 4 32 7 7 (6272)\r\nI1008 11:27:25.670511 11844 net.cpp:137] Memory required for data: 216553768\r\nI1008 11:27:25.670511 11844 layer_factory.hpp:77] Creating layer inception_5a/5x5\r\nI1008 11:27:25.670511 11844 net.cpp:84] Creating Layer inception_5a/5x5\r\nI1008 11:27:25.670511 11844 net.cpp:406] inception_5a/5x5 <- inception_5a/5x5_reduce\r\nI1008 11:27:25.670511 11844 net.cpp:380] inception_5a/5x5 -> inception_5a/5x5\r\nI1008 11:27:25.671509 11844 net.cpp:122] Setting up inception_5a/5x5\r\nI1008 11:27:25.671509 11844 net.cpp:129] Top shape: 4 128 7 7 (25088)\r\nI1008 11:27:25.672264 11844 net.cpp:137] Memory required for data: 216654120\r\nI1008 11:27:25.672264 11844 layer_factory.hpp:77] Creating layer inception_5a/relu_5x5\r\nI1008 11:27:25.672264 11844 net.cpp:84] Creating Layer inception_5a/relu_5x5\r\nI1008 11:27:25.672264 11844 net.cpp:406] inception_5a/relu_5x5 <- inception_5a/5x5\r\nI1008 11:27:25.672264 11844 net.cpp:367] inception_5a/relu_5x5 -> inception_5a/5x5 (in-place)\r\nI1008 11:27:25.672264 11844 net.cpp:122] Setting up inception_5a/relu_5x5\r\nI1008 11:27:25.672264 11844 net.cpp:129] Top shape: 4 128 7 7 (25088)\r\nI1008 11:27:25.672264 11844 net.cpp:137] Memory required for data: 216754472\r\nI1008 11:27:25.672264 11844 layer_factory.hpp:77] Creating layer inception_5a/pool\r\nI1008 11:27:25.672264 11844 net.cpp:84] Creating Layer inception_5a/pool\r\nI1008 11:27:25.672264 11844 net.cpp:406] inception_5a/pool <- pool4/3x3_s2_pool4/3x3_s2_0_split_3\r\nI1008 11:27:25.672264 11844 net.cpp:380] inception_5a/pool -> inception_5a/pool\r\nI1008 11:27:25.672264 11844 net.cpp:122] Setting up inception_5a/pool\r\nI1008 11:27:25.672264 11844 net.cpp:129] Top shape: 4 832 7 7 (163072)\r\nI1008 11:27:25.672264 11844 net.cpp:137] Memory required for data: 217406760\r\nI1008 11:27:25.672264 11844 layer_factory.hpp:77] Creating layer inception_5a/pool_proj\r\nI1008 11:27:25.672264 11844 net.cpp:84] Creating Layer inception_5a/pool_proj\r\nI1008 11:27:25.673262 11844 net.cpp:406] inception_5a/pool_proj <- inception_5a/pool\r\nI1008 11:27:25.673262 11844 net.cpp:380] inception_5a/pool_proj -> inception_5a/pool_proj\r\nI1008 11:27:25.673262 11844 net.cpp:122] Setting up inception_5a/pool_proj\r\nI1008 11:27:25.673262 11844 net.cpp:129] Top shape: 4 128 7 7 (25088)\r\nI1008 11:27:25.673262 11844 net.cpp:137] Memory required for data: 217507112\r\nI1008 11:27:25.675791 11844 layer_factory.hpp:77] Creating layer inception_5a/relu_pool_proj\r\nI1008 11:27:25.675791 11844 net.cpp:84] Creating Layer inception_5a/relu_pool_proj\r\nI1008 11:27:25.675791 11844 net.cpp:406] inception_5a/relu_pool_proj <- inception_5a/pool_proj\r\nI1008 11:27:25.675791 11844 net.cpp:367] inception_5a/relu_pool_proj -> inception_5a/pool_proj (in-place)\r\nI1008 11:27:25.675791 11844 net.cpp:122] Setting up inception_5a/relu_pool_proj\r\nI1008 11:27:25.675791 11844 net.cpp:129] Top shape: 4 128 7 7 (25088)\r\nI1008 11:27:25.675791 11844 net.cpp:137] Memory required for data: 217607464\r\nI1008 11:27:25.675791 11844 layer_factory.hpp:77] Creating layer inception_5a/output\r\nI1008 11:27:25.675791 11844 net.cpp:84] Creating Layer inception_5a/output\r\nI1008 11:27:25.675791 11844 net.cpp:406] inception_5a/output <- inception_5a/1x1\r\nI1008 11:27:25.675791 11844 net.cpp:406] inception_5a/output <- inception_5a/3x3\r\nI1008 11:27:25.675791 11844 net.cpp:406] inception_5a/output <- inception_5a/5x5\r\nI1008 11:27:25.675791 11844 net.cpp:406] inception_5a/output <- inception_5a/pool_proj\r\nI1008 11:27:25.675791 11844 net.cpp:380] inception_5a/output -> inception_5a/output\r\nI1008 11:27:25.675791 11844 net.cpp:122] Setting up inception_5a/output\r\nI1008 11:27:25.675791 11844 net.cpp:129] Top shape: 4 832 7 7 (163072)\r\nI1008 11:27:25.675791 11844 net.cpp:137] Memory required for data: 218259752\r\nI1008 11:27:25.675791 11844 layer_factory.hpp:77] Creating layer inception_5a/output_inception_5a/output_0_split\r\nI1008 11:27:25.675791 11844 net.cpp:84] Creating Layer inception_5a/output_inception_5a/output_0_split\r\nI1008 11:27:25.675791 11844 net.cpp:406] inception_5a/output_inception_5a/output_0_split <- inception_5a/output\r\nI1008 11:27:25.675791 11844 net.cpp:380] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0\r\nI1008 11:27:25.675791 11844 net.cpp:380] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1\r\nI1008 11:27:25.675791 11844 net.cpp:380] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_2\r\nI1008 11:27:25.675791 11844 net.cpp:380] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_3\r\nI1008 11:27:25.675791 11844 net.cpp:122] Setting up inception_5a/output_inception_5a/output_0_split\r\nI1008 11:27:25.676786 11844 net.cpp:129] Top shape: 4 832 7 7 (163072)\r\nI1008 11:27:25.676846 11844 net.cpp:129] Top shape: 4 832 7 7 (163072)\r\nI1008 11:27:25.676846 11844 net.cpp:129] Top shape: 4 832 7 7 (163072)\r\nI1008 11:27:25.676846 11844 net.cpp:129] Top shape: 4 832 7 7 (163072)\r\nI1008 11:27:25.676846 11844 net.cpp:137] Memory required for data: 220868904\r\nI1008 11:27:25.676846 11844 layer_factory.hpp:77] Creating layer inception_5b/1x1\r\nI1008 11:27:25.676846 11844 net.cpp:84] Creating Layer inception_5b/1x1\r\nI1008 11:27:25.676846 11844 net.cpp:406] inception_5b/1x1 <- inception_5a/output_inception_5a/output_0_split_0\r\nI1008 11:27:25.676846 11844 net.cpp:380] inception_5b/1x1 -> inception_5b/1x1\r\nI1008 11:27:25.677844 11844 net.cpp:122] Setting up inception_5b/1x1\r\nI1008 11:27:25.683187 11844 net.cpp:129] Top shape: 4 384 7 7 (75264)\r\nI1008 11:27:25.683187 11844 net.cpp:137] Memory required for data: 221169960\r\nI1008 11:27:25.683187 11844 layer_factory.hpp:77] Creating layer inception_5b/relu_1x1\r\nI1008 11:27:25.683187 11844 net.cpp:84] Creating Layer inception_5b/relu_1x1\r\nI1008 11:27:25.683187 11844 net.cpp:406] inception_5b/relu_1x1 <- inception_5b/1x1\r\nI1008 11:27:25.683187 11844 net.cpp:367] inception_5b/relu_1x1 -> inception_5b/1x1 (in-place)\r\nI1008 11:27:25.683187 11844 net.cpp:122] Setting up inception_5b/relu_1x1\r\nI1008 11:27:25.683187 11844 net.cpp:129] Top shape: 4 384 7 7 (75264)\r\nI1008 11:27:25.683187 11844 net.cpp:137] Memory required for data: 221471016\r\nI1008 11:27:25.683187 11844 layer_factory.hpp:77] Creating layer inception_5b/3x3_reduce\r\nI1008 11:27:25.683187 11844 net.cpp:84] Creating Layer inception_5b/3x3_reduce\r\nI1008 11:27:25.683187 11844 net.cpp:406] inception_5b/3x3_reduce <- inception_5a/output_inception_5a/output_0_split_1\r\nI1008 11:27:25.683187 11844 net.cpp:380] inception_5b/3x3_reduce -> inception_5b/3x3_reduce\r\nI1008 11:27:25.684181 11844 net.cpp:122] Setting up inception_5b/3x3_reduce\r\nI1008 11:27:25.684181 11844 net.cpp:129] Top shape: 4 192 7 7 (37632)\r\nI1008 11:27:25.684181 11844 net.cpp:137] Memory required for data: 221621544\r\nI1008 11:27:25.686342 11844 layer_factory.hpp:77] Creating layer inception_5b/relu_3x3_reduce\r\nI1008 11:27:25.686342 11844 net.cpp:84] Creating Layer inception_5b/relu_3x3_reduce\r\nI1008 11:27:25.686342 11844 net.cpp:406] inception_5b/relu_3x3_reduce <- inception_5b/3x3_reduce\r\nI1008 11:27:25.686342 11844 net.cpp:367] inception_5b/relu_3x3_reduce -> inception_5b/3x3_reduce (in-place)\r\nI1008 11:27:25.686342 11844 net.cpp:122] Setting up inception_5b/relu_3x3_reduce\r\nI1008 11:27:25.686342 11844 net.cpp:129] Top shape: 4 192 7 7 (37632)\r\nI1008 11:27:25.686342 11844 net.cpp:137] Memory required for data: 221772072\r\nI1008 11:27:25.686342 11844 layer_factory.hpp:77] Creating layer inception_5b/3x3\r\nI1008 11:27:25.686342 11844 net.cpp:84] Creating Layer inception_5b/3x3\r\nI1008 11:27:25.686342 11844 net.cpp:406] inception_5b/3x3 <- inception_5b/3x3_reduce\r\nI1008 11:27:25.686342 11844 net.cpp:380] inception_5b/3x3 -> inception_5b/3x3\r\nI1008 11:27:25.697196 11844 net.cpp:122] Setting up inception_5b/3x3\r\nI1008 11:27:25.697196 11844 net.cpp:129] Top shape: 4 384 7 7 (75264)\r\nI1008 11:27:25.697196 11844 net.cpp:137] Memory required for data: 222073128\r\nI1008 11:27:25.697196 11844 layer_factory.hpp:77] Creating layer inception_5b/relu_3x3\r\nI1008 11:27:25.698021 11844 net.cpp:84] Creating Layer inception_5b/relu_3x3\r\nI1008 11:27:25.698021 11844 net.cpp:406] inception_5b/relu_3x3 <- inception_5b/3x3\r\nI1008 11:27:25.698021 11844 net.cpp:367] inception_5b/relu_3x3 -> inception_5b/3x3 (in-place)\r\nI1008 11:27:25.698021 11844 net.cpp:122] Setting up inception_5b/relu_3x3\r\nI1008 11:27:25.698021 11844 net.cpp:129] Top shape: 4 384 7 7 (75264)\r\nI1008 11:27:25.698021 11844 net.cpp:137] Memory required for data: 222374184\r\nI1008 11:27:25.698021 11844 layer_factory.hpp:77] Creating layer inception_5b/5x5_reduce\r\nI1008 11:27:25.698021 11844 net.cpp:84] Creating Layer inception_5b/5x5_reduce\r\nI1008 11:27:25.698021 11844 net.cpp:406] inception_5b/5x5_reduce <- inception_5a/output_inception_5a/output_0_split_2\r\nI1008 11:27:25.698021 11844 net.cpp:380] inception_5b/5x5_reduce -> inception_5b/5x5_reduce\r\nI1008 11:27:25.698021 11844 net.cpp:122] Setting up inception_5b/5x5_reduce\r\nI1008 11:27:25.699021 11844 net.cpp:129] Top shape: 4 48 7 7 (9408)\r\nI1008 11:27:25.699021 11844 net.cpp:137] Memory required for data: 222411816\r\nI1008 11:27:25.699021 11844 layer_factory.hpp:77] Creating layer inception_5b/relu_5x5_reduce\r\nI1008 11:27:25.699100 11844 net.cpp:84] Creating Layer inception_5b/relu_5x5_reduce\r\nI1008 11:27:25.699100 11844 net.cpp:406] inception_5b/relu_5x5_reduce <- inception_5b/5x5_reduce\r\nI1008 11:27:25.699100 11844 net.cpp:367] inception_5b/relu_5x5_reduce -> inception_5b/5x5_reduce (in-place)\r\nI1008 11:27:25.699100 11844 net.cpp:122] Setting up inception_5b/relu_5x5_reduce\r\nI1008 11:27:25.699100 11844 net.cpp:129] Top shape: 4 48 7 7 (9408)\r\nI1008 11:27:25.699100 11844 net.cpp:137] Memory required for data: 222449448\r\nI1008 11:27:25.699100 11844 layer_factory.hpp:77] Creating layer inception_5b/5x5\r\nI1008 11:27:25.699100 11844 net.cpp:84] Creating Layer inception_5b/5x5\r\nI1008 11:27:25.699100 11844 net.cpp:406] inception_5b/5x5 <- inception_5b/5x5_reduce\r\nI1008 11:27:25.699100 11844 net.cpp:380] inception_5b/5x5 -> inception_5b/5x5\r\nI1008 11:27:25.700129 11844 net.cpp:122] Setting up inception_5b/5x5\r\nI1008 11:27:25.700129 11844 net.cpp:129] Top shape: 4 128 7 7 (25088)\r\nI1008 11:27:25.700129 11844 net.cpp:137] Memory required for data: 222549800\r\nI1008 11:27:25.701598 11844 layer_factory.hpp:77] Creating layer inception_5b/relu_5x5\r\nI1008 11:27:25.701598 11844 net.cpp:84] Creating Layer inception_5b/relu_5x5\r\nI1008 11:27:25.701598 11844 net.cpp:406] inception_5b/relu_5x5 <- inception_5b/5x5\r\nI1008 11:27:25.701598 11844 net.cpp:367] inception_5b/relu_5x5 -> inception_5b/5x5 (in-place)\r\nI1008 11:27:25.701598 11844 net.cpp:122] Setting up inception_5b/relu_5x5\r\nI1008 11:27:25.701598 11844 net.cpp:129] Top shape: 4 128 7 7 (25088)\r\nI1008 11:27:25.701598 11844 net.cpp:137] Memory required for data: 222650152\r\nI1008 11:27:25.701598 11844 layer_factory.hpp:77] Creating layer inception_5b/pool\r\nI1008 11:27:25.701598 11844 net.cpp:84] Creating Layer inception_5b/pool\r\nI1008 11:27:25.701598 11844 net.cpp:406] inception_5b/pool <- inception_5a/output_inception_5a/output_0_split_3\r\nI1008 11:27:25.701598 11844 net.cpp:380] inception_5b/pool -> inception_5b/pool\r\nI1008 11:27:25.701598 11844 net.cpp:122] Setting up inception_5b/pool\r\nI1008 11:27:25.701598 11844 net.cpp:129] Top shape: 4 832 7 7 (163072)\r\nI1008 11:27:25.701598 11844 net.cpp:137] Memory required for data: 223302440\r\nI1008 11:27:25.701598 11844 layer_factory.hpp:77] Creating layer inception_5b/pool_proj\r\nI1008 11:27:25.701598 11844 net.cpp:84] Creating Layer inception_5b/pool_proj\r\nI1008 11:27:25.701598 11844 net.cpp:406] inception_5b/pool_proj <- inception_5b/pool\r\nI1008 11:27:25.701598 11844 net.cpp:380] inception_5b/pool_proj -> inception_5b/pool_proj\r\nI1008 11:27:25.702626 11844 net.cpp:122] Setting up inception_5b/pool_proj\r\nI1008 11:27:25.702626 11844 net.cpp:129] Top shape: 4 128 7 7 (25088)\r\nI1008 11:27:25.702626 11844 net.cpp:137] Memory required for data: 223402792\r\nI1008 11:27:25.704109 11844 layer_factory.hpp:77] Creating layer inception_5b/relu_pool_proj\r\nI1008 11:27:25.704109 11844 net.cpp:84] Creating Layer inception_5b/relu_pool_proj\r\nI1008 11:27:25.704109 11844 net.cpp:406] inception_5b/relu_pool_proj <- inception_5b/pool_proj\r\nI1008 11:27:25.704109 11844 net.cpp:367] inception_5b/relu_pool_proj -> inception_5b/pool_proj (in-place)\r\nI1008 11:27:25.704109 11844 net.cpp:122] Setting up inception_5b/relu_pool_proj\r\nI1008 11:27:25.704109 11844 net.cpp:129] Top shape: 4 128 7 7 (25088)\r\nI1008 11:27:25.704109 11844 net.cpp:137] Memory required for data: 223503144\r\nI1008 11:27:25.704109 11844 layer_factory.hpp:77] Creating layer inception_5b/output\r\nI1008 11:27:25.704109 11844 net.cpp:84] Creating Layer inception_5b/output\r\nI1008 11:27:25.704109 11844 net.cpp:406] inception_5b/output <- inception_5b/1x1\r\nI1008 11:27:25.704109 11844 net.cpp:406] inception_5b/output <- inception_5b/3x3\r\nI1008 11:27:25.704109 11844 net.cpp:406] inception_5b/output <- inception_5b/5x5\r\nI1008 11:27:25.704109 11844 net.cpp:406] inception_5b/output <- inception_5b/pool_proj\r\nI1008 11:27:25.704109 11844 net.cpp:380] inception_5b/output -> inception_5b/output\r\nI1008 11:27:25.704109 11844 net.cpp:122] Setting up inception_5b/output\r\nI1008 11:27:25.704109 11844 net.cpp:129] Top shape: 4 1024 7 7 (200704)\r\nI1008 11:27:25.704109 11844 net.cpp:137] Memory required for data: 224305960\r\nI1008 11:27:25.704109 11844 layer_factory.hpp:77] Creating layer pool5/7x7_s1\r\nI1008 11:27:25.704109 11844 net.cpp:84] Creating Layer pool5/7x7_s1\r\nI1008 11:27:25.704109 11844 net.cpp:406] pool5/7x7_s1 <- inception_5b/output\r\nI1008 11:27:25.704109 11844 net.cpp:380] pool5/7x7_s1 -> pool5/7x7_s1\r\nI1008 11:27:25.704109 11844 net.cpp:122] Setting up pool5/7x7_s1\r\nI1008 11:27:25.704109 11844 net.cpp:129] Top shape: 4 1024 1 1 (4096)\r\nI1008 11:27:25.704109 11844 net.cpp:137] Memory required for data: 224322344\r\nI1008 11:27:25.704109 11844 layer_factory.hpp:77] Creating layer pool5/drop_7x7_s1\r\nI1008 11:27:25.704109 11844 net.cpp:84] Creating Layer pool5/drop_7x7_s1\r\nI1008 11:27:25.704109 11844 net.cpp:406] pool5/drop_7x7_s1 <- pool5/7x7_s1\r\nI1008 11:27:25.705103 11844 net.cpp:367] pool5/drop_7x7_s1 -> pool5/7x7_s1 (in-place)\r\nI1008 11:27:25.705103 11844 net.cpp:122] Setting up pool5/drop_7x7_s1\r\nI1008 11:27:25.705103 11844 net.cpp:129] Top shape: 4 1024 1 1 (4096)\r\nI1008 11:27:25.705103 11844 net.cpp:137] Memory required for data: 224338728\r\nI1008 11:27:25.705103 11844 layer_factory.hpp:77] Creating layer loss3/SLclassifier\r\nI1008 11:27:25.705103 11844 net.cpp:84] Creating Layer loss3/SLclassifier\r\nI1008 11:27:25.705103 11844 net.cpp:406] loss3/SLclassifier <- pool5/7x7_s1\r\nI1008 11:27:25.705103 11844 net.cpp:380] loss3/SLclassifier -> loss3/SLclassifier\r\nI1008 11:27:25.705103 11844 net.cpp:122] Setting up loss3/SLclassifier\r\nI1008 11:27:25.705103 11844 net.cpp:129] Top shape: 4 7 (28)\r\nI1008 11:27:25.705103 11844 net.cpp:137] Memory required for data: 224338840\r\nI1008 11:27:25.705103 11844 layer_factory.hpp:77] Creating layer loss3/loss3\r\nI1008 11:27:25.705103 11844 net.cpp:84] Creating Layer loss3/loss3\r\nI1008 11:27:25.705103 11844 net.cpp:406] loss3/loss3 <- loss3/SLclassifier\r\nI1008 11:27:25.705103 11844 net.cpp:406] loss3/loss3 <- label_data_1_split_2\r\nI1008 11:27:25.705103 11844 net.cpp:380] loss3/loss3 -> loss3/loss3\r\nI1008 11:27:25.705103 11844 layer_factory.hpp:77] Creating layer loss3/loss3\r\nI1008 11:27:25.705103 11844 net.cpp:122] Setting up loss3/loss3\r\nI1008 11:27:25.705103 11844 net.cpp:129] Top shape: (1)\r\nI1008 11:27:25.705103 11844 net.cpp:132]     with loss weight 1\r\nI1008 11:27:25.706100 11844 net.cpp:137] Memory required for data: 224338844\r\nI1008 11:27:25.706100 11844 net.cpp:198] loss3/loss3 needs backward computation.\r\nI1008 11:27:25.706100 11844 net.cpp:198] loss3/SLclassifier needs backward computation.\r\nI1008 11:27:25.706100 11844 net.cpp:200] pool5/drop_7x7_s1 does not need backward computation.\r\nI1008 11:27:25.706100 11844 net.cpp:200] pool5/7x7_s1 does not need backward computation.\r\nI1008 11:27:25.706100 11844 net.cpp:200] inception_5b/output does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5b/relu_pool_proj does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5b/pool_proj does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5b/pool does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5b/relu_5x5 does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5b/5x5 does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5b/relu_5x5_reduce does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5b/5x5_reduce does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5b/relu_3x3 does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5b/3x3 does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5b/relu_3x3_reduce does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5b/3x3_reduce does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5b/relu_1x1 does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5b/1x1 does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5a/output_inception_5a/output_0_split does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5a/output does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5a/relu_pool_proj does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5a/pool_proj does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5a/pool does not need backward computation.\r\nI1008 11:27:25.706315 11844 net.cpp:200] inception_5a/relu_5x5 does not need backward computation.\r\nI1008 11:27:25.707311 11844 net.cpp:200] inception_5a/5x5 does not need backward computation.\r\nI1008 11:27:25.707311 11844 net.cpp:200] inception_5a/relu_5x5_reduce does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_5a/5x5_reduce does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_5a/relu_3x3 does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_5a/3x3 does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_5a/relu_3x3_reduce does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_5a/3x3_reduce does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_5a/relu_1x1 does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_5a/1x1 does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] pool4/3x3_s2_pool4/3x3_s2_0_split does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] pool4/3x3_s2 does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_4e/output does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_4e/relu_pool_proj does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_4e/pool_proj does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_4e/pool does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_4e/relu_5x5 does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_4e/5x5 does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_4e/relu_5x5_reduce does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_4e/5x5_reduce does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_4e/relu_3x3 does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_4e/3x3 does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_4e/relu_3x3_reduce does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_4e/3x3_reduce does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_4e/relu_1x1 does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:200] inception_4e/1x1 does not need backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:198] loss2/loss needs backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:198] loss2/SLclassifier needs backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:198] loss2/drop_fc needs backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:198] loss2/relu_fc needs backward computation.\r\nI1008 11:27:25.707370 11844 net.cpp:198] loss2/fc needs backward computation.\r\nI1008 11:27:25.708367 11844 net.cpp:200] loss2/relu_conv does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] loss2/conv does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] loss2/ave_pool does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4d/output_inception_4d/output_0_split does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4d/output does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4d/relu_pool_proj does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4d/pool_proj does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4d/pool does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4d/relu_5x5 does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4d/5x5 does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4d/relu_5x5_reduce does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4d/5x5_reduce does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4d/relu_3x3 does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4d/3x3 does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4d/relu_3x3_reduce does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4d/3x3_reduce does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4d/relu_1x1 does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4d/1x1 does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4c/output_inception_4c/output_0_split does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4c/output does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4c/relu_pool_proj does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4c/pool_proj does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4c/pool does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4c/relu_5x5 does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4c/5x5 does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4c/relu_5x5_reduce does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4c/5x5_reduce does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4c/relu_3x3 does not need backward computation.\r\nI1008 11:27:25.708405 11844 net.cpp:200] inception_4c/3x3 does not need backward computation.\r\nI1008 11:27:25.709403 11844 net.cpp:200] inception_4c/relu_3x3_reduce does not need backward computation.\r\nI1008 11:27:25.709403 11844 net.cpp:200] inception_4c/3x3_reduce does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4c/relu_1x1 does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4c/1x1 does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4b/output_inception_4b/output_0_split does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4b/output does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4b/relu_pool_proj does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4b/pool_proj does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4b/pool does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4b/relu_5x5 does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4b/5x5 does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4b/relu_5x5_reduce does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4b/5x5_reduce does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4b/relu_3x3 does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4b/3x3 does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4b/relu_3x3_reduce does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4b/3x3_reduce does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4b/relu_1x1 does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] inception_4b/1x1 does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:198] loss1/loss needs backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:198] loss1/SLclassifier needs backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:198] loss1/drop_fc needs backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:198] loss1/relu_fc needs backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:198] loss1/fc needs backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] loss1/relu_conv does not need backward computation.\r\nI1008 11:27:25.709452 11844 net.cpp:200] loss1/conv does not need backward computation.\r\nI1008 11:27:25.710448 11844 net.cpp:200] loss1/ave_pool does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_4a/output_inception_4a/output_0_split does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_4a/output does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_4a/relu_pool_proj does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_4a/pool_proj does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_4a/pool does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_4a/relu_5x5 does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_4a/5x5 does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_4a/relu_5x5_reduce does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_4a/5x5_reduce does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_4a/relu_3x3 does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_4a/3x3 does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_4a/relu_3x3_reduce does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_4a/3x3_reduce does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_4a/relu_1x1 does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_4a/1x1 does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] pool3/3x3_s2_pool3/3x3_s2_0_split does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] pool3/3x3_s2 does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_3b/output does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_3b/relu_pool_proj does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_3b/pool_proj does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_3b/pool does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_3b/relu_5x5 does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_3b/5x5 does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_3b/relu_5x5_reduce does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_3b/5x5_reduce does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_3b/relu_3x3 does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_3b/3x3 does not need backward computation.\r\nI1008 11:27:25.710480 11844 net.cpp:200] inception_3b/relu_3x3_reduce does not need backward computation.\r\nI1008 11:27:25.711477 11844 net.cpp:200] inception_3b/3x3_reduce does not need backward computation.\r\nI1008 11:27:25.711477 11844 net.cpp:200] inception_3b/relu_1x1 does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] inception_3b/1x1 does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] inception_3a/output_inception_3a/output_0_split does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] inception_3a/output does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] inception_3a/relu_pool_proj does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] inception_3a/pool_proj does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] inception_3a/pool does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] inception_3a/relu_5x5 does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] inception_3a/5x5 does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] inception_3a/relu_5x5_reduce does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] inception_3a/5x5_reduce does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] inception_3a/relu_3x3 does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] inception_3a/3x3 does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] inception_3a/relu_3x3_reduce does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] inception_3a/3x3_reduce does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] inception_3a/relu_1x1 does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] inception_3a/1x1 does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] pool2/3x3_s2_pool2/3x3_s2_0_split does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] pool2/3x3_s2 does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] conv2/norm2 does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] conv2/relu_3x3 does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] conv2/3x3 does not need backward computation.\r\nI1008 11:27:25.711526 11844 net.cpp:200] conv2/relu_3x3_reduce does not need backward computation.\r\nI1008 11:27:25.712524 11844 net.cpp:200] conv2/3x3_reduce does not need backward computation.\r\nI1008 11:27:25.712524 11844 net.cpp:200] pool1/norm1 does not need backward computation.\r\nI1008 11:27:25.713027 11844 net.cpp:200] pool1/3x3_s2 does not need backward computation.\r\nI1008 11:27:25.713027 11844 net.cpp:200] conv1/relu_7x7 does not need backward computation.\r\nI1008 11:27:25.713027 11844 net.cpp:200] conv1/7x7_s2 does not need backward computation.\r\nI1008 11:27:25.713027 11844 net.cpp:200] label_data_1_split does not need backward computation.\r\nI1008 11:27:25.713027 11844 net.cpp:200] data does not need backward computation.\r\nI1008 11:27:25.713027 11844 net.cpp:242] This network produces output loss1/loss1\r\nI1008 11:27:25.713027 11844 net.cpp:242] This network produces output loss2/loss1\r\nI1008 11:27:25.713027 11844 net.cpp:242] This network produces output loss3/loss3\r\nI1008 11:27:25.713027 11844 net.cpp:255] Network initialization done.\r\nI1008 11:27:25.714025 11844 solver.cpp:172] Creating test net (#0) specified by net file: .\\examples\\finetune_gesture_recognize\\net_1007.prototxt\r\nI1008 11:27:25.716019 11844 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data\r\nI1008 11:27:25.717016 11844 net.cpp:51] Initializing net from parameters:\r\nname: ""GoogleNet""\r\nstate {\r\n  phase: TEST\r\n  stage: ""1""\r\n}\r\nlayer {\r\n  name: ""data""\r\n  type: ""Data""\r\n  top: ""data""\r\n  top: ""label""\r\n  include {\r\n    phase: TEST\r\n    stage: ""1""\r\n  }\r\n  transform_param {\r\n    mirror: false\r\n    crop_size: 224\r\n    mean_file: "".\\\\examples\\\\finetune_gesture_recognize\\\\mean_origin.mean""\r\n  }\r\n  data_param {\r\n    source: "".\\\\examples\\\\finetune_gesture_recognize\\\\video\\\\test.txt""\r\n    batch_size: 1\r\n  }\r\n}\r\nlayer {\r\n  name: ""conv1/7x7_s2""\r\n  type: ""Convolution""\r\n  bottom: ""data""\r\n  top: ""conv1/7x7_s2""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    pad: 3\r\n    kernel_size: 7\r\n    stride: 2\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.1\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""conv1/relu_7x7""\r\n  type: ""ReLU""\r\n  bottom: ""conv1/7x7_s2""\r\n  top: ""conv1/7x7_s2""\r\n}\r\nlayer {\r\n  name: ""pool1/3x3_s2""\r\n  type: ""Pooling""\r\n  bottom: ""conv1/7x7_s2""\r\n  top: ""pool1/3x3_s2""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 2\r\n  }\r\n}\r\nlayer {\r\n  name: ""pool1/norm1""\r\n  type: ""LRN""\r\n  bottom: ""pool1/3x3_s2""\r\n  top: ""pool1/norm1""\r\n  lrn_param {\r\n    local_size: 5\r\n    alpha: 0.0001\r\n    beta: 0.75\r\n  }\r\n}\r\nlayer {\r\n  name: ""conv2/3x3_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""pool1/norm1""\r\n  top: ""conv2/3x3_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.1\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""conv2/relu_3x3_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""conv2/3x3_reduce""\r\n  top: ""conv2/3x3_reduce""\r\n}\r\nlayer {\r\n  name: ""conv2/3x3""\r\n  type: ""Convolution""\r\n  bottom: ""conv2/3x3_reduce""\r\n  top: ""conv2/3x3""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 192\r\n    pad: 1\r\n    kernel_size: 3\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""conv2/relu_3x3""\r\n  type: ""ReLU""\r\n  bottom: ""conv2/3x3""\r\n  top: ""conv2/3x3""\r\n}\r\nlayer {\r\n  name: ""conv2/norm2""\r\n  type: ""LRN""\r\n  bottom: ""conv2/3x3""\r\n  top: ""conv2/norm2""\r\n  lrn_param {\r\n    local_size: 5\r\n    alpha: 0.0001\r\n    beta: 0.75\r\n  }\r\n}\r\nlayer {\r\n  name: ""pool2/3x3_s2""\r\n  type: ""Pooling""\r\n  bottom: ""conv2/norm2""\r\n  top: ""pool2/3x3_s2""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 2\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3a/1x1""\r\n  type: ""Convolution""\r\n  bottom: ""pool2/3x3_s2""\r\n  top: ""inception_3a/1x1""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3a/relu_1x1""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3a/1x1""\r\n  top: ""inception_3a/1x1""\r\n}\r\nlayer {\r\n  name: ""inception_3a/3x3_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""pool2/3x3_s2""\r\n  top: ""inception_3a/3x3_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 96\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.09\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3a/relu_3x3_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3a/3x3_reduce""\r\n  top: ""inception_3a/3x3_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_3a/3x3""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3a/3x3_reduce""\r\n  top: ""inception_3a/3x3""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 128\r\n    pad: 1\r\n    kernel_size: 3\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3a/relu_3x3""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3a/3x3""\r\n  top: ""inception_3a/3x3""\r\n}\r\nlayer {\r\n  name: ""inception_3a/5x5_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""pool2/3x3_s2""\r\n  top: ""inception_3a/5x5_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 16\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.2\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3a/relu_5x5_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3a/5x5_reduce""\r\n  top: ""inception_3a/5x5_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_3a/5x5""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3a/5x5_reduce""\r\n  top: ""inception_3a/5x5""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 32\r\n    pad: 2\r\n    kernel_size: 5\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3a/relu_5x5""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3a/5x5""\r\n  top: ""inception_3a/5x5""\r\n}\r\nlayer {\r\n  name: ""inception_3a/pool""\r\n  type: ""Pooling""\r\n  bottom: ""pool2/3x3_s2""\r\n  top: ""inception_3a/pool""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 1\r\n    pad: 1\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3a/pool_proj""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3a/pool""\r\n  top: ""inception_3a/pool_proj""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 32\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.1\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3a/relu_pool_proj""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3a/pool_proj""\r\n  top: ""inception_3a/pool_proj""\r\n}\r\nlayer {\r\n  name: ""inception_3a/output""\r\n  type: ""Concat""\r\n  bottom: ""inception_3a/1x1""\r\n  bottom: ""inception_3a/3x3""\r\n  bottom: ""inception_3a/5x5""\r\n  bottom: ""inception_3a/pool_proj""\r\n  top: ""inception_3a/output""\r\n}\r\nlayer {\r\n  name: ""inception_3b/1x1""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3a/output""\r\n  top: ""inception_3b/1x1""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 128\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3b/relu_1x1""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3b/1x1""\r\n  top: ""inception_3b/1x1""\r\n}\r\nlayer {\r\n  name: ""inception_3b/3x3_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3a/output""\r\n  top: ""inception_3b/3x3_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 128\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.09\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3b/relu_3x3_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3b/3x3_reduce""\r\n  top: ""inception_3b/3x3_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_3b/3x3""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3b/3x3_reduce""\r\n  top: ""inception_3b/3x3""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 192\r\n    pad: 1\r\n    kernel_size: 3\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3b/relu_3x3""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3b/3x3""\r\n  top: ""inception_3b/3x3""\r\n}\r\nlayer {\r\n  name: ""inception_3b/5x5_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3a/output""\r\n  top: ""inception_3b/5x5_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 32\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.2\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3b/relu_5x5_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3b/5x5_reduce""\r\n  top: ""inception_3b/5x5_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_3b/5x5""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3b/5x5_reduce""\r\n  top: ""inception_3b/5x5""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 96\r\n    pad: 2\r\n    kernel_size: 5\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3b/relu_5x5""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3b/5x5""\r\n  top: ""inception_3b/5x5""\r\n}\r\nlayer {\r\n  name: ""inception_3b/pool""\r\n  type: ""Pooling""\r\n  bottom: ""inception_3a/output""\r\n  top: ""inception_3b/pool""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 1\r\n    pad: 1\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3b/pool_proj""\r\n  type: ""Convolution""\r\n  bottom: ""inception_3b/pool""\r\n  top: ""inception_3b/pool_proj""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.1\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_3b/relu_pool_proj""\r\n  type: ""ReLU""\r\n  bottom: ""inception_3b/pool_proj""\r\n  top: ""inception_3b/pool_proj""\r\n}\r\nlayer {\r\n  name: ""inception_3b/output""\r\n  type: ""Concat""\r\n  bottom: ""inception_3b/1x1""\r\n  bottom: ""inception_3b/3x3""\r\n  bottom: ""inception_3b/5x5""\r\n  bottom: ""inception_3b/pool_proj""\r\n  top: ""inception_3b/output""\r\n}\r\nlayer {\r\n  name: ""pool3/3x3_s2""\r\n  type: ""Pooling""\r\n  bottom: ""inception_3b/output""\r\n  top: ""pool3/3x3_s2""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 2\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4a/1x1""\r\n  type: ""Convolution""\r\n  bottom: ""pool3/3x3_s2""\r\n  top: ""inception_4a/1x1""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 192\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4a/relu_1x1""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4a/1x1""\r\n  top: ""inception_4a/1x1""\r\n}\r\nlayer {\r\n  name: ""inception_4a/3x3_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""pool3/3x3_s2""\r\n  top: ""inception_4a/3x3_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 96\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.09\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4a/relu_3x3_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4a/3x3_reduce""\r\n  top: ""inception_4a/3x3_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4a/3x3""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4a/3x3_reduce""\r\n  top: ""inception_4a/3x3""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 208\r\n    pad: 1\r\n    kernel_size: 3\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4a/relu_3x3""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4a/3x3""\r\n  top: ""inception_4a/3x3""\r\n}\r\nlayer {\r\n  name: ""inception_4a/5x5_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""pool3/3x3_s2""\r\n  top: ""inception_4a/5x5_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 16\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.2\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4a/relu_5x5_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4a/5x5_reduce""\r\n  top: ""inception_4a/5x5_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4a/5x5""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4a/5x5_reduce""\r\n  top: ""inception_4a/5x5""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 48\r\n    pad: 2\r\n    kernel_size: 5\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4a/relu_5x5""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4a/5x5""\r\n  top: ""inception_4a/5x5""\r\n}\r\nlayer {\r\n  name: ""inception_4a/pool""\r\n  type: ""Pooling""\r\n  bottom: ""pool3/3x3_s2""\r\n  top: ""inception_4a/pool""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 1\r\n    pad: 1\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4a/pool_proj""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4a/pool""\r\n  top: ""inception_4a/pool_proj""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.1\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4a/relu_pool_proj""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4a/pool_proj""\r\n  top: ""inception_4a/pool_proj""\r\n}\r\nlayer {\r\n  name: ""inception_4a/output""\r\n  type: ""Concat""\r\n  bottom: ""inception_4a/1x1""\r\n  bottom: ""inception_4a/3x3""\r\n  bottom: ""inception_4a/5x5""\r\n  bottom: ""inception_4a/pool_proj""\r\n  top: ""inception_4a/output""\r\n}\r\nlayer {\r\n  name: ""loss1/ave_pool""\r\n  type: ""Pooling""\r\n  bottom: ""inception_4a/output""\r\n  top: ""loss1/ave_pool""\r\n  pooling_param {\r\n    pool: AVE\r\n    kernel_size: 5\r\n    stride: 3\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss1/conv""\r\n  type: ""Convolution""\r\n  bottom: ""loss1/ave_pool""\r\n  top: ""loss1/conv""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 128\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.08\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss1/relu_conv""\r\n  type: ""ReLU""\r\n  bottom: ""loss1/conv""\r\n  top: ""loss1/conv""\r\n}\r\nlayer {\r\n  name: ""loss1/fc""\r\n  type: ""InnerProduct""\r\n  bottom: ""loss1/conv""\r\n  top: ""loss1/fc""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  propagate_down: false\r\n  inner_product_param {\r\n    num_output: 1024\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.02\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss1/relu_fc""\r\n  type: ""ReLU""\r\n  bottom: ""loss1/fc""\r\n  top: ""loss1/fc""\r\n}\r\nlayer {\r\n  name: ""loss1/drop_fc""\r\n  type: ""Dropout""\r\n  bottom: ""loss1/fc""\r\n  top: ""loss1/fc""\r\n  dropout_param {\r\n    dropout_ratio: 0.7\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss1/SLclassifier""\r\n  type: ""InnerProduct""\r\n  bottom: ""loss1/fc""\r\n  top: ""loss1/SLclassifier""\r\n  param {\r\n    lr_mult: 10\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 20\r\n    decay_mult: 0\r\n  }\r\n  inner_product_param {\r\n    num_output: 7\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.0009765625\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss1/loss""\r\n  type: ""SoftmaxWithLoss""\r\n  bottom: ""loss1/SLclassifier""\r\n  bottom: ""label""\r\n  top: ""loss1/loss1""\r\n  loss_weight: 0.3\r\n}\r\nlayer {\r\n  name: ""loss1/top-1""\r\n  type: ""Accuracy""\r\n  bottom: ""loss1/SLclassifier""\r\n  bottom: ""label""\r\n  top: ""loss1/top-1""\r\n  include {\r\n    phase: TEST\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss1/top-5""\r\n  type: ""Accuracy""\r\n  bottom: ""loss1/SLclassifier""\r\n  bottom: ""label""\r\n  top: ""loss1/top-5""\r\n  include {\r\n    phase: TEST\r\n  }\r\n  accuracy_param {\r\n    top_k: 5\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4b/1x1""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4a/output""\r\n  top: ""inception_4b/1x1""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 160\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4b/relu_1x1""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4b/1x1""\r\n  top: ""inception_4b/1x1""\r\n}\r\nlayer {\r\n  name: ""inception_4b/3x3_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4a/output""\r\n  top: ""inception_4b/3x3_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 112\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.09\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4b/relu_3x3_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4b/3x3_reduce""\r\n  top: ""inception_4b/3x3_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4b/3x3""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4b/3x3_reduce""\r\n  top: ""inception_4b/3x3""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 224\r\n    pad: 1\r\n    kernel_size: 3\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4b/relu_3x3""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4b/3x3""\r\n  top: ""inception_4b/3x3""\r\n}\r\nlayer {\r\n  name: ""inception_4b/5x5_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4a/output""\r\n  top: ""inception_4b/5x5_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 24\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.2\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4b/relu_5x5_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4b/5x5_reduce""\r\n  top: ""inception_4b/5x5_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4b/5x5""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4b/5x5_reduce""\r\n  top: ""inception_4b/5x5""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    pad: 2\r\n    kernel_size: 5\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4b/relu_5x5""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4b/5x5""\r\n  top: ""inception_4b/5x5""\r\n}\r\nlayer {\r\n  name: ""inception_4b/pool""\r\n  type: ""Pooling""\r\n  bottom: ""inception_4a/output""\r\n  top: ""inception_4b/pool""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 1\r\n    pad: 1\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4b/pool_proj""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4b/pool""\r\n  top: ""inception_4b/pool_proj""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.1\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4b/relu_pool_proj""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4b/pool_proj""\r\n  top: ""inception_4b/pool_proj""\r\n}\r\nlayer {\r\n  name: ""inception_4b/output""\r\n  type: ""Concat""\r\n  bottom: ""inception_4b/1x1""\r\n  bottom: ""inception_4b/3x3""\r\n  bottom: ""inception_4b/5x5""\r\n  bottom: ""inception_4b/pool_proj""\r\n  top: ""inception_4b/output""\r\n}\r\nlayer {\r\n  name: ""inception_4c/1x1""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4b/output""\r\n  top: ""inception_4c/1x1""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 128\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4c/relu_1x1""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4c/1x1""\r\n  top: ""inception_4c/1x1""\r\n}\r\nlayer {\r\n  name: ""inception_4c/3x3_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4b/output""\r\n  top: ""inception_4c/3x3_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 128\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.09\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4c/relu_3x3_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4c/3x3_reduce""\r\n  top: ""inception_4c/3x3_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4c/3x3""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4c/3x3_reduce""\r\n  top: ""inception_4c/3x3""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 256\r\n    pad: 1\r\n    kernel_size: 3\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4c/relu_3x3""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4c/3x3""\r\n  top: ""inception_4c/3x3""\r\n}\r\nlayer {\r\n  name: ""inception_4c/5x5_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4b/output""\r\n  top: ""inception_4c/5x5_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 24\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.2\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4c/relu_5x5_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4c/5x5_reduce""\r\n  top: ""inception_4c/5x5_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4c/5x5""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4c/5x5_reduce""\r\n  top: ""inception_4c/5x5""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    pad: 2\r\n    kernel_size: 5\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4c/relu_5x5""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4c/5x5""\r\n  top: ""inception_4c/5x5""\r\n}\r\nlayer {\r\n  name: ""inception_4c/pool""\r\n  type: ""Pooling""\r\n  bottom: ""inception_4b/output""\r\n  top: ""inception_4c/pool""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 1\r\n    pad: 1\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4c/pool_proj""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4c/pool""\r\n  top: ""inception_4c/pool_proj""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.1\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4c/relu_pool_proj""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4c/pool_proj""\r\n  top: ""inception_4c/pool_proj""\r\n}\r\nlayer {\r\n  name: ""inception_4c/output""\r\n  type: ""Concat""\r\n  bottom: ""inception_4c/1x1""\r\n  bottom: ""inception_4c/3x3""\r\n  bottom: ""inception_4c/5x5""\r\n  bottom: ""inception_4c/pool_proj""\r\n  top: ""inception_4c/output""\r\n}\r\nlayer {\r\n  name: ""inception_4d/1x1""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4c/output""\r\n  top: ""inception_4d/1x1""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 112\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4d/relu_1x1""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4d/1x1""\r\n  top: ""inception_4d/1x1""\r\n}\r\nlayer {\r\n  name: ""inception_4d/3x3_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4c/output""\r\n  top: ""inception_4d/3x3_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 144\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.09\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4d/relu_3x3_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4d/3x3_reduce""\r\n  top: ""inception_4d/3x3_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4d/3x3""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4d/3x3_reduce""\r\n  top: ""inception_4d/3x3""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 288\r\n    pad: 1\r\n    kernel_size: 3\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4d/relu_3x3""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4d/3x3""\r\n  top: ""inception_4d/3x3""\r\n}\r\nlayer {\r\n  name: ""inception_4d/5x5_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4c/output""\r\n  top: ""inception_4d/5x5_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 32\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.2\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4d/relu_5x5_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4d/5x5_reduce""\r\n  top: ""inception_4d/5x5_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4d/5x5""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4d/5x5_reduce""\r\n  top: ""inception_4d/5x5""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    pad: 2\r\n    kernel_size: 5\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4d/relu_5x5""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4d/5x5""\r\n  top: ""inception_4d/5x5""\r\n}\r\nlayer {\r\n  name: ""inception_4d/pool""\r\n  type: ""Pooling""\r\n  bottom: ""inception_4c/output""\r\n  top: ""inception_4d/pool""\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 3\r\n    stride: 1\r\n    pad: 1\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4d/pool_proj""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4d/pool""\r\n  top: ""inception_4d/pool_proj""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 64\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.1\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4d/relu_pool_proj""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4d/pool_proj""\r\n  top: ""inception_4d/pool_proj""\r\n}\r\nlayer {\r\n  name: ""inception_4d/output""\r\n  type: ""Concat""\r\n  bottom: ""inception_4d/1x1""\r\n  bottom: ""inception_4d/3x3""\r\n  bottom: ""inception_4d/5x5""\r\n  bottom: ""inception_4d/pool_proj""\r\n  top: ""inception_4d/output""\r\n}\r\nlayer {\r\n  name: ""loss2/ave_pool""\r\n  type: ""Pooling""\r\n  bottom: ""inception_4d/output""\r\n  top: ""loss2/ave_pool""\r\n  pooling_param {\r\n    pool: AVE\r\n    kernel_size: 5\r\n    stride: 3\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss2/conv""\r\n  type: ""Convolution""\r\n  bottom: ""loss2/ave_pool""\r\n  top: ""loss2/conv""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 128\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.08\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss2/relu_conv""\r\n  type: ""ReLU""\r\n  bottom: ""loss2/conv""\r\n  top: ""loss2/conv""\r\n}\r\nlayer {\r\n  name: ""loss2/fc""\r\n  type: ""InnerProduct""\r\n  bottom: ""loss2/conv""\r\n  top: ""loss2/fc""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  propagate_down: false\r\n  inner_product_param {\r\n    num_output: 1024\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.02\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss2/relu_fc""\r\n  type: ""ReLU""\r\n  bottom: ""loss2/fc""\r\n  top: ""loss2/fc""\r\n}\r\nlayer {\r\n  name: ""loss2/drop_fc""\r\n  type: ""Dropout""\r\n  bottom: ""loss2/fc""\r\n  top: ""loss2/fc""\r\n  dropout_param {\r\n    dropout_ratio: 0.7\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss2/SLclassifier""\r\n  type: ""InnerProduct""\r\n  bottom: ""loss2/fc""\r\n  top: ""loss2/SLclassifier""\r\n  param {\r\n    lr_mult: 10\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 20\r\n    decay_mult: 0\r\n  }\r\n  inner_product_param {\r\n    num_output: 7\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.0009765625\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss2/loss""\r\n  type: ""SoftmaxWithLoss""\r\n  bottom: ""loss2/SLclassifier""\r\n  bottom: ""label""\r\n  top: ""loss2/loss1""\r\n  loss_weight: 0.3\r\n}\r\nlayer {\r\n  name: ""loss2/top-1""\r\n  type: ""Accuracy""\r\n  bottom: ""loss2/SLclassifier""\r\n  bottom: ""label""\r\n  top: ""loss2/top-1""\r\n  include {\r\n    phase: TEST\r\n  }\r\n}\r\nlayer {\r\n  name: ""loss2/top-5""\r\n  type: ""Accuracy""\r\n  bottom: ""loss2/SLclassifier""\r\n  bottom: ""label""\r\n  top: ""loss2/top-5""\r\n  include {\r\n    phase: TEST\r\n  }\r\n  accuracy_param {\r\n    top_k: 5\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4e/1x1""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4d/output""\r\n  top: ""inception_4e/1x1""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 256\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.03\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4e/relu_1x1""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4e/1x1""\r\n  top: ""inception_4e/1x1""\r\n}\r\nlayer {\r\n  name: ""inception_4e/3x3_reduce""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4d/output""\r\n  top: ""inception_4e/3x3_reduce""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_mult: 0\r\n  }\r\n  convolution_param {\r\n    num_output: 160\r\n    kernel_size: 1\r\n    weight_filler {\r\n      type: ""xavier""\r\n      std: 0.09\r\n    }\r\n    bias_filler {\r\n      type: ""constant""\r\n      value: 0.2\r\n    }\r\n  }\r\n}\r\nlayer {\r\n  name: ""inception_4e/relu_3x3_reduce""\r\n  type: ""ReLU""\r\n  bottom: ""inception_4e/3x3_reduce""\r\n  top: ""inception_4e/3x3_reduce""\r\n}\r\nlayer {\r\n  name: ""inception_4e/3x3""\r\n  type: ""Convolution""\r\n  bottom: ""inception_4e/3x3_reduce""\r\n  top: ""inception_4e/3x3""\r\n  param {\r\n    lr_mult: 1\r\n    decay_mult: 1\r\n  }\r\n  param {\r\n    lr_mult: 2\r\n    decay_\r\nI1008 11:27:25.717016 11844 layer_factory.hpp:77] Creating layer data\r\n']",[],1,0
7,caffe,3239,closed,cuDNN v3 can be much slower than v2,"Running with the same model on the same dataset, the latest master with v3 took 25 minutes to finish 1000 iterations while v2 took 10 minutes. The kernels of the first three convolutional layers are of 9, 7 and 5 pixels. This problem was also [reported in a fork of Caffe](https://github.com/happynear/caffe-windows/issues/24) and [many other sources](https://www.google.co.in/?gws_rd=ssl#newwindow=1&q=cudnn+v3++slower).

Maybe cuDNN v3 only works well on the Maxwell architecture GPUs or just can't choose the most efficient convolution algorithm. The simplest solution is to revert to an older version of Caffe [since v2 was no longer supported](https://github.com/BVLC/caffe/pull/3218) before NVIDIA fix the problem. But we still want to keep Caffe up to date to experiment with some new features such as batch normalization. 

The second way is to specify the convolution algorithm explicitly which is not flexible enough for various model configurations. 

The last resort is to keep backwards compatibility with cuDNN v2 in Caffe.
",,"[""I've recently bumped into @jdemouth who appears to be one of the main devs of cuDNN, maybe he can tell us more.\n\nEDIT: I remember he told me there will be ways to make things faster, by using batches of 64 and by recoding some stuff...\n"", 'Hi, \n\nI\'d be happy to help if I can. I need to know the GPU that you are issues with and I need to know the layer size. CuDNN v3 adds new algorithms and there\'s a heuristic to select the ""best"" given a convolution size. The more we know, the more we can tune the heuristic to get good perf. \n\nIn general, a given algorithm is either as fast in v3 as it was in v2 or it is faster. No matter which GPU architecture you target. Of course, there may be counter examples but I\'m not aware of them. \n\nCheers,\nJulien\n', 'The GPU is K20. The convolutional layers are defined in Caffe proto format as shown in the snippet.\n\n```\nlayer {\n  name: ""conv1""\n  type: ""Convolution""\n  bottom: ""data""\n  top: ""conv1""\n  param {\n    lr_mult: 1\n    decay_mult: 1\n  }\n  param {\n    lr_mult: 2\n    decay_mult: 0\n  }\n  convolution_param {\n    num_output: 32\n    pad: 0\n    kernel_size: 9\n    stride: 1\n    weight_filler {\n      type: ""gaussian""\n      std: 0.0001\n    }\n    bias_filler {\n      type: ""constant""\n    }\n  }\n}\nlayer {\n  name: ""relu1""\n  type: ""ReLU""\n  bottom: ""conv1""\n  top: ""conv1""\n  relu_param {\n    negative_slope: 0.25\n  }\n}\nlayer {\n  name: ""norm1""\n  type: ""LRN""\n  bottom: ""conv1""\n  top: ""norm1""\n  lrn_param {\n    local_size: 3\n    alpha: 5e-05\n    beta: 0.75\n    norm_region: WITHIN_CHANNEL\n  }\n}\n\nlayer {\n  name: ""conv2""\n  type: ""Convolution""\n  bottom: ""norm1""\n  top: ""conv2""\n  param {\n    lr_mult: 1\n    decay_mult: 1\n  }\n  param {\n    lr_mult: 2\n    decay_mult: 0\n  }\n  convolution_param {\n    num_output: 96\n    pad: 0\n    kernel_size: 7\n    stride: 1\n    weight_filler {\n      type: ""gaussian""\n      std: 0.01\n    }\n    bias_filler {\n      type: ""constant""\n    }\n  }\n}\nlayer {\n  name: ""pool2""\n  type: ""Pooling""\n  bottom: ""conv2""\n  top: ""pool2""\n  pooling_param {\n    pool: MAX\n    kernel_size: 3\n    stride: 3\n  }\n}\nlayer {\n  name: ""relu2""\n  type: ""ReLU""\n  bottom: ""pool2""\n  top: ""pool2""\n  relu_param {\n    negative_slope: 0.25\n  }\n}\nlayer {\n  name: ""norm2""\n  type: ""LRN""\n  bottom: ""pool2""\n  top: ""norm2""\n  lrn_param {\n    local_size: 3\n    alpha: 5e-05\n    beta: 0.75\n    norm_region: WITHIN_CHANNEL\n  }\n}\n\n\nlayer {\n  name: ""conv3""\n  type: ""Convolution""\n  bottom: ""norm2""\n  top: ""conv3""\n  param {\n    lr_mult: 1\n    decay_mult: 1\n  }\n  param {\n    lr_mult: 2\n    decay_mult: 0\n  }\n  convolution_param {\n    num_output: 128\n    pad: 0\n    kernel_size: 5\n    stride: 1\n    weight_filler {\n      type: ""gaussian""\n      std: 0.01\n    }\n    bias_filler {\n      type: ""constant""\n    }\n  }\n}\nlayer {\n  name: ""relu3""\n  type: ""ReLU""\n  bottom: ""conv3""\n  top: ""conv3""\n  relu_param {\n    negative_slope: 0.25\n  }\n}\n```\n', 'The problem has been solved using the library released in 2015/08/21 . And I have updated my repo.\n']",[],[],1,1
8,caffe,6061,closed,"very low speed to train network, I have some time test.","It seems that the speed bottleneck is not the data... Why the training is too slow? There's two gtx1080 I use.


Here's the network
",,"[""You are probably not using any of the GTX's. Remember to either set the solver mode to GPU or explicitly pass `-gpu i` (where `i` is the index of a GPU which you want to use) for training and time measurements.\r\n\r\nPlease do not post usage, installation, or modeling questions, or other requests for help to Issues. Use the [caffe-users list][1] instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe. Please read the [guidelines for contributing][2] before submitting an issue or a pull request.\r\n\r\n [1]: https://groups.google.com/forum/#!forum/caffe-users\r\n [2]: https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md""]","['\r\n\r\nI1120 15:25:40.922173 32075 caffe.cpp:370] Testing for 10 iterations.\r\nI1120 15:26:54.087085 32075 caffe.cpp:398] Iteration: 1 forward-backward time: 73164 ms.\r\nI1120 15:28:07.840503 32075 caffe.cpp:398] Iteration: 2 forward-backward time: 73753 ms.\r\nI1120 15:29:20.321182 32075 caffe.cpp:398] Iteration: 3 forward-backward time: 72480 ms.\r\nI1120 15:30:33.230473 32075 caffe.cpp:398] Iteration: 4 forward-backward time: 72909 ms.\r\nI1120 15:31:46.027458 32075 caffe.cpp:398] Iteration: 5 forward-backward time: 72796 ms.\r\nI1120 15:32:58.718683 32075 caffe.cpp:398] Iteration: 6 forward-backward time: 72691 ms.\r\nI1120 15:34:11.214593 32075 caffe.cpp:398] Iteration: 7 forward-backward time: 72495 ms.\r\nI1120 15:35:26.520215 32075 caffe.cpp:398] Iteration: 8 forward-backward time: 75305 ms.\r\nI1120 15:36:40.403247 32075 caffe.cpp:398] Iteration: 9 forward-backward time: 73882 ms.\r\nI1120 15:37:53.523113 32075 caffe.cpp:398] Iteration: 10 forward-backward time: 73119 ms.\r\nI1120 15:37:53.523254 32075 caffe.cpp:401] Average time per layer:\r\nI1120 15:37:53.523264 32075 caffe.cpp:404] data\tforward: 4.248 ms.\r\nI1120 15:37:53.523275 32075 caffe.cpp:407] data\tbackward: 0.0009 ms.\r\nI1120 15:37:53.523284 32075 caffe.cpp:404] data_data_0_split\tforward: 0.0037 ms.\r\nI1120 15:37:53.523294 32075 caffe.cpp:407] data_data_0_split\tbackward: 0.002 ms.\r\nI1120 15:37:53.523303 32075 caffe.cpp:404] conv1_1\tforward: 2299.2 ms.\r\nI1120 15:37:53.523313 32075 caffe.cpp:407] conv1_1\tbackward: 1429.87 ms.\r\nI1120 15:37:53.523322 32075 caffe.cpp:404] relu1_1\tforward: 1704.39 ms.\r\nI1120 15:37:53.523334 32075 caffe.cpp:407] relu1_1\tbackward: 1124.62 ms.\r\nI1120 15:37:53.523344 32075 caffe.cpp:404] conv1_1_relu1_1_0_split\tforward: 0.0049 ms.\r\nI1120 15:37:53.523355 32075 caffe.cpp:407] conv1_1_relu1_1_0_split\tbackward: 0.0014 ms.\r\nI1120 15:37:53.523363 32075 caffe.cpp:404] conv1c_1\tforward: 12045.1 ms.\r\nI1120 15:37:53.523375 32075 caffe.cpp:407] conv1c_1\tbackward: 8624.17 ms.\r\nI1120 15:37:53.523386 32075 caffe.cpp:404] relu1c_1\tforward: 1195.17 ms.\r\nI1120 15:37:53.523396 32075 caffe.cpp:407] relu1c_1\tbackward: 1108.14 ms.\r\nI1120 15:37:53.523406 32075 caffe.cpp:404] conv1c_2\tforward: 8569.42 ms.\r\nI1120 15:37:53.523435 32075 caffe.cpp:407] conv1c_2\tbackward: 8681.32 ms.\r\nI1120 15:37:53.523447 32075 caffe.cpp:404] relu1c_2\tforward: 1183.97 ms.\r\nI1120 15:37:53.523458 32075 caffe.cpp:407] relu1c_2\tbackward: 1138.41 ms.\r\nI1120 15:37:53.523465 32075 caffe.cpp:404] res1\tforward: 411.52 ms.\r\nI1120 15:37:53.523473 32075 caffe.cpp:407] res1\tbackward: 14.937 ms.\r\nI1120 15:37:53.523480 32075 caffe.cpp:404] pool1\tforward: 654.194 ms.\r\nI1120 15:37:53.523486 32075 caffe.cpp:407] pool1\tbackward: 0.0012 ms.\r\nI1120 15:37:53.523491 32075 caffe.cpp:404] conv2_1\tforward: 2130.6 ms.\r\nI1120 15:37:53.523497 32075 caffe.cpp:407] conv2_1\tbackward: 2125.77 ms.\r\nI1120 15:37:53.523504 32075 caffe.cpp:404] relu2_1\tforward: 296.859 ms.\r\nI1120 15:37:53.523509 32075 caffe.cpp:407] relu2_1\tbackward: 283.548 ms.\r\nI1120 15:37:53.523514 32075 caffe.cpp:404] conv2_1_relu2_1_0_split\tforward: 0.0039 ms.\r\nI1120 15:37:53.523520 32075 caffe.cpp:407] conv2_1_relu2_1_0_split\tbackward: 0.0014 ms.\r\nI1120 15:37:53.523525 32075 caffe.cpp:404] conv2c_1\tforward: 2127.13 ms.\r\nI1120 15:37:53.523531 32075 caffe.cpp:407] conv2c_1\tbackward: 2128.01 ms.\r\nI1120 15:37:53.523538 32075 caffe.cpp:404] relu2c_1\tforward: 300.981 ms.\r\nI1120 15:37:53.523547 32075 caffe.cpp:407] relu2c_1\tbackward: 276.914 ms.\r\nI1120 15:37:53.523556 32075 caffe.cpp:404] conv2c_2\tforward: 2133.77 ms.\r\nI1120 15:37:53.523566 32075 caffe.cpp:407] conv2c_2\tbackward: 2134.1 ms.\r\nI1120 15:37:53.523574 32075 caffe.cpp:404] relu2c_2\tforward: 307.359 ms.\r\nI1120 15:37:53.523583 32075 caffe.cpp:407] relu2c_2\tbackward: 288.437 ms.\r\nI1120 15:37:53.523592 32075 caffe.cpp:404] res2\tforward: 118.188 ms.\r\nI1120 15:37:53.523600 32075 caffe.cpp:407] res2\tbackward: 3.7467 ms.\r\nI1120 15:37:53.523609 32075 caffe.cpp:404] pool2\tforward: 170.863 ms.\r\nI1120 15:37:53.523620 32075 caffe.cpp:407] pool2\tbackward: 0.0023 ms.\r\nI1120 15:37:53.523629 32075 caffe.cpp:404] conv3_1\tforward: 528.679 ms.\r\nI1120 15:37:53.523640 32075 caffe.cpp:407] conv3_1\tbackward: 1035.48 ms.\r\nI1120 15:37:53.523650 32075 caffe.cpp:404] relu3_1\tforward: 75.5047 ms.\r\nI1120 15:37:53.523661 32075 caffe.cpp:407] relu3_1\tbackward: 146.153 ms.\r\nI1120 15:37:53.523672 32075 caffe.cpp:404] conv3_1_relu3_1_0_split\tforward: 0.0035 ms.\r\nI1120 15:37:53.523681 32075 caffe.cpp:407] conv3_1_relu3_1_0_split\tbackward: 9.4383 ms.\r\nI1120 15:37:53.523691 32075 caffe.cpp:404] conv3c_1\tforward: 525.713 ms.\r\nI1120 15:37:53.523701 32075 caffe.cpp:407] conv3c_1\tbackward: 1039.7 ms.\r\nI1120 15:37:53.523708 32075 caffe.cpp:404] relu3c_1\tforward: 77.3526 ms.\r\nI1120 15:37:53.523715 32075 caffe.cpp:407] relu3c_1\tbackward: 147.349 ms.\r\nI1120 15:37:53.523721 32075 caffe.cpp:404] conv3c_2\tforward: 535.194 ms.\r\nI1120 15:37:53.523730 32075 caffe.cpp:407] conv3c_2\tbackward: 1023.16 ms.\r\nI1120 15:37:53.523739 32075 caffe.cpp:404] relu3c_2\tforward: 75.0913 ms.\r\nI1120 15:37:53.523771 32075 caffe.cpp:407] relu3c_2\tbackward: 144.48 ms.\r\nI1120 15:37:53.523780 32075 caffe.cpp:404] res3\tforward: 25.18 ms.\r\nI1120 15:37:53.523792 32075 caffe.cpp:407] res3\tbackward: 10.7973 ms.\r\nI1120 15:37:53.523799 32075 caffe.cpp:404] pool3\tforward: 50.9623 ms.\r\nI1120 15:37:53.523808 32075 caffe.cpp:407] pool3\tbackward: 10.4217 ms.\r\nI1120 15:37:53.523815 32075 caffe.cpp:404] conv4_3\tforward: 192.215 ms.\r\nI1120 15:37:53.523824 32075 caffe.cpp:407] conv4_3\tbackward: 371.715 ms.\r\nI1120 15:37:53.523833 32075 caffe.cpp:404] relu4_3\tforward: 20.6911 ms.\r\nI1120 15:37:53.523841 32075 caffe.cpp:407] relu4_3\tbackward: 39.9155 ms.\r\nI1120 15:37:53.523849 32075 caffe.cpp:404] conv4_3_relu4_3_0_split\tforward: 0.0028 ms.\r\nI1120 15:37:53.523859 32075 caffe.cpp:407] conv4_3_relu4_3_0_split\tbackward: 2.4546 ms.\r\nI1120 15:37:53.523867 32075 caffe.cpp:404] conv4c_1\tforward: 191.5 ms.\r\nI1120 15:37:53.523875 32075 caffe.cpp:407] conv4c_1\tbackward: 372.006 ms.\r\nI1120 15:37:53.523885 32075 caffe.cpp:404] relu4c_1\tforward: 20.9576 ms.\r\nI1120 15:37:53.523892 32075 caffe.cpp:407] relu4c_1\tbackward: 40.2641 ms.\r\nI1120 15:37:53.523900 32075 caffe.cpp:404] conv4c_2\tforward: 192.223 ms.\r\nI1120 15:37:53.523910 32075 caffe.cpp:407] conv4c_2\tbackward: 373.411 ms.\r\nI1120 15:37:53.523917 32075 caffe.cpp:404] relu4c_2\tforward: 20.5691 ms.\r\nI1120 15:37:53.523926 32075 caffe.cpp:407] relu4c_2\tbackward: 39.9445 ms.\r\nI1120 15:37:53.523934 32075 caffe.cpp:404] res4\tforward: 5.9342 ms.\r\nI1120 15:37:53.523942 32075 caffe.cpp:407] res4\tbackward: 2.8407 ms.\r\nI1120 15:37:53.523950 32075 caffe.cpp:404] res4_res4_0_split\tforward: 0.0033 ms.\r\nI1120 15:37:53.523959 32075 caffe.cpp:407] res4_res4_0_split\tbackward: 5.7272 ms.\r\nI1120 15:37:53.523967 32075 caffe.cpp:404] conv4_3_norm_mbox_loc_1\tforward: 152.878 ms.\r\nI1120 15:37:53.523977 32075 caffe.cpp:407] conv4_3_norm_mbox_loc_1\tbackward: 287.65 ms.\r\nI1120 15:37:53.523985 32075 caffe.cpp:404] conv4_3_norm_mbox_conf_1\tforward: 90.9539 ms.\r\nI1120 15:37:53.523994 32075 caffe.cpp:407] conv4_3_norm_mbox_conf_1\tbackward: 173.402 ms.\r\nI1120 15:37:53.524003 32075 caffe.cpp:404] conv4_3_norm_mbox_priorbox_1\tforward: 0.0489 ms.\r\nI1120 15:37:53.524010 32075 caffe.cpp:407] conv4_3_norm_mbox_priorbox_1\tbackward: 0.0015 ms.\r\nI1120 15:37:53.524019 32075 caffe.cpp:404] conv4_3_norm_mbox_loc_perm_1\tforward: 25.5833 ms.\r\nI1120 15:37:53.524029 32075 caffe.cpp:407] conv4_3_norm_mbox_loc_perm_1\tbackward: 24.8412 ms.\r\nI1120 15:37:53.524036 32075 caffe.cpp:404] conv4_3_norm_mbox_loc_flat_1\tforward: 0.0045 ms.\r\nI1120 15:37:53.524044 32075 caffe.cpp:407] conv4_3_norm_mbox_loc_flat_1\tbackward: 0.0013 ms.\r\nI1120 15:37:53.524052 32075 caffe.cpp:404] conv4_3_norm_mbox_conf_perm_1\tforward: 12.6727 ms.\r\nI1120 15:37:53.524061 32075 caffe.cpp:407] conv4_3_norm_mbox_conf_perm_1\tbackward: 12.4333 ms.\r\nI1120 15:37:53.524070 32075 caffe.cpp:404] conv4_3_norm_mbox_conf_flat_1\tforward: 0.0029 ms.\r\nI1120 15:37:53.524078 32075 caffe.cpp:407] conv4_3_norm_mbox_conf_flat_1\tbackward: 0.0015 ms.\r\nI1120 15:37:53.524085 32075 caffe.cpp:404] mbox_loss_1\tforward: 109.545 ms.\r\nI1120 15:37:53.524094 32075 caffe.cpp:407] mbox_loss_1\tbackward: 1.4616 ms.\r\nI1120 15:37:53.524108 32075 caffe.cpp:412] Average Forward pass: 38582.7 ms.\r\nI1120 15:37:53.524116 32075 caffe.cpp:414] Average Backward pass: 34677.3 ms.\r\nI1120 15:37:53.524123 32075 caffe.cpp:416] Average Forward-Backward: 73260.1 ms.\r\nI1120 15:37:53.524132 32075 caffe.cpp:418] Total Time: 732601 ms.\r\nI1120 15:37:53.524140 32075 caffe.cpp:419] *** Benchmark ends ***\r\n', '\r\n\r\nname: ""VGG_VOC0712_SSD_100x100_train""\r\nlayer {\r\nname: ""data""\r\ntype: ""AnnotatedData""\r\ntop: ""data""\r\ntop: ""label""\r\ninclude {\r\nphase: TRAIN\r\n}\r\ntransform_param {\r\nmirror: true\r\nmean_value: 127.5\r\nmean_value: 127.5\r\nmean_value: 127.5\r\nscale: 0.0078125\r\nresize_param {\r\nprob: 1.0\r\nresize_mode: WARP\r\nheight: 100\r\nwidth: 100\r\ninterp_mode: LINEAR\r\ninterp_mode: AREA\r\ninterp_mode: NEAREST\r\ninterp_mode: CUBIC\r\ninterp_mode: LANCZOS4\r\n}\r\nemit_constraint {\r\nemit_type: CENTER\r\n}\r\n#distort_param {\r\n# brightness_prob: 0.5\r\n# brightness_delta: 32.0\r\n# contrast_prob: 0.5\r\n# contrast_lower: 0.5\r\n# contrast_upper: 1.5\r\n# hue_prob: 0.5\r\n# hue_delta: 18.0\r\n# saturation_prob: 0.5\r\n# saturation_lower: 0.5\r\n# saturation_upper: 1.5\r\n# random_order_prob: 0.0\r\n#}\r\nexpand_param {\r\nprob: 0.5\r\nmax_expand_ratio: 4.0\r\n}\r\n}\r\ndata_param {\r\nsource: ""lmdb/voc_trainval_lmdb""\r\nbatch_size: 128\r\nbackend: LMDB\r\n}\r\nannotated_data_param {\r\nbatch_sampler {\r\nmax_sample: 1\r\nmax_trials: 1\r\n}\r\nbatch_sampler {\r\nsampler {\r\nmin_scale: 0.300000011921\r\nmax_scale: 1.0\r\nmin_aspect_ratio: 0.5\r\nmax_aspect_ratio: 2.0\r\n}\r\nsample_constraint {\r\nmin_jaccard_overlap: 0.10000000149\r\n}\r\nmax_sample: 1\r\nmax_trials: 50\r\n}\r\nbatch_sampler {\r\nsampler {\r\nmin_scale: 0.300000011921\r\nmax_scale: 1.0\r\nmin_aspect_ratio: 0.5\r\nmax_aspect_ratio: 2.0\r\n}\r\nsample_constraint {\r\nmin_jaccard_overlap: 0.300000011921\r\n}\r\nmax_sample: 1\r\nmax_trials: 50\r\n}\r\nbatch_sampler {\r\nsampler {\r\nmin_scale: 0.300000011921\r\nmax_scale: 1.0\r\nmin_aspect_ratio: 0.5\r\nmax_aspect_ratio: 2.0\r\n}\r\nsample_constraint {\r\nmin_jaccard_overlap: 0.5\r\n}\r\nmax_sample: 1\r\nmax_trials: 50\r\n}\r\nbatch_sampler {\r\nsampler {\r\nmin_scale: 0.300000011921\r\nmax_scale: 1.0\r\nmin_aspect_ratio: 0.5\r\nmax_aspect_ratio: 2.0\r\n}\r\nsample_constraint {\r\nmin_jaccard_overlap: 0.699999988079\r\n}\r\nmax_sample: 1\r\nmax_trials: 50\r\n}\r\nbatch_sampler {\r\nsampler {\r\nmin_scale: 0.300000011921\r\nmax_scale: 1.0\r\nmin_aspect_ratio: 0.5\r\nmax_aspect_ratio: 2.0\r\n}\r\nsample_constraint {\r\nmin_jaccard_overlap: 0.899999976158\r\n}\r\nmax_sample: 1\r\nmax_trials: 50\r\n}\r\nbatch_sampler {\r\nsampler {\r\nmin_scale: 0.300000011921\r\nmax_scale: 1.0\r\nmin_aspect_ratio: 0.5\r\nmax_aspect_ratio: 2.0\r\n}\r\nsample_constraint {\r\nmax_jaccard_overlap: 1.0\r\n}\r\nmax_sample: 1\r\nmax_trials: 50\r\n}\r\n}\r\n}\r\n\r\nlayer {\r\nname: ""conv1_1""\r\ntype: ""Convolution""\r\nbottom: ""data""\r\ntop: ""conv1_1""\r\nparam {\r\nlr_mult: 1.0\r\ndecay_mult: 1.0\r\n}\r\nparam {\r\nlr_mult: 2.0\r\ndecay_mult: 0.0\r\n}\r\nconvolution_param {\r\nnum_output: 64\r\npad: 1\r\nkernel_size: 3\r\nweight_filler {\r\ntype: ""msra""\r\n}\r\nbias_filler {\r\ntype: ""constant""\r\nvalue: 0.0\r\n}\r\n}\r\n}\r\nlayer {\r\nname: ""relu1_1""\r\ntype: ""PReLU""\r\nbottom: ""conv1_1""\r\ntop: ""conv1_1""\r\n}\r\n\r\nlayer {\r\nname: ""conv1c_1""\r\ntype: ""Convolution""\r\nbottom: ""conv1_1""\r\ntop: ""conv1c_1""\r\nparam {\r\nlr_mult: 1.0\r\ndecay_mult: 1.0\r\n}\r\nparam {\r\nlr_mult: 2.0\r\ndecay_mult: 0.0\r\n}\r\nconvolution_param {\r\nnum_output: 64\r\npad: 1\r\nkernel_size: 3\r\nweight_filler {\r\ntype: ""msra""\r\n}\r\nbias_filler {\r\ntype: ""constant""\r\nvalue: 0.0\r\n}\r\n}\r\n}\r\nlayer {\r\nname: ""relu1c_1""\r\ntype: ""PReLU""\r\nbottom: ""conv1c_1""\r\ntop: ""conv1c_1""\r\n}\r\n\r\nlayer {\r\nname: ""conv1c_2""\r\ntype: ""Convolution""\r\nbottom: ""conv1c_1""\r\ntop: ""conv1c_2""\r\nparam {\r\nlr_mult: 1.0\r\ndecay_mult: 1.0\r\n}\r\nparam {\r\nlr_mult: 2.0\r\ndecay_mult: 0.0\r\n}\r\nconvolution_param {\r\nnum_output: 64\r\npad: 1\r\nkernel_size: 3\r\nweight_filler {\r\ntype: ""msra""\r\n}\r\nbias_filler {\r\ntype: ""constant""\r\nvalue: 0.0\r\n}\r\n}\r\n}\r\nlayer {\r\nname: ""relu1c_2""\r\ntype: ""PReLU""\r\nbottom: ""conv1c_2""\r\ntop: ""conv1c_2""\r\n}\r\n\r\nlayer {\r\nbottom: ""conv1_1""\r\nbottom: ""conv1c_2""\r\ntop: ""res1""\r\nname: ""res1""\r\ntype: ""Eltwise""\r\neltwise_param {\r\noperation: SUM\r\n}\r\n}\r\n\r\nlayer {\r\nname: ""pool1""\r\ntype: ""Pooling""\r\nbottom: ""res1""\r\ntop: ""pool1""\r\npooling_param {\r\npool: MAX\r\nkernel_size: 2\r\nstride: 2\r\n}\r\n}\r\n\r\nlayer {\r\nname: ""conv2_1""\r\ntype: ""Convolution""\r\nbottom: ""pool1""\r\ntop: ""conv2_1""\r\nparam {\r\nlr_mult: 1.0\r\ndecay_mult: 1.0\r\n}\r\nparam {\r\nlr_mult: 2.0\r\ndecay_mult: 0.0\r\n}\r\nconvolution_param {\r\nnum_output: 64\r\npad: 1\r\nkernel_size: 3\r\nweight_filler {\r\ntype: ""msra""\r\n}\r\nbias_filler {\r\ntype: ""constant""\r\nvalue: 0.0\r\n}\r\n}\r\n}\r\nlayer {\r\nname: ""relu2_1""\r\ntype: ""PReLU""\r\nbottom: ""conv2_1""\r\ntop: ""conv2_1""\r\n}\r\n\r\nlayer {\r\nname: ""conv2c_1""\r\ntype: ""Convolution""\r\nbottom: ""conv2_1""\r\ntop: ""conv2c_1""\r\nparam {\r\nlr_mult: 1.0\r\ndecay_mult: 1.0\r\n}\r\nparam {\r\nlr_mult: 2.0\r\ndecay_mult: 0.0\r\n}\r\nconvolution_param {\r\nnum_output: 64\r\npad: 1\r\nkernel_size: 3\r\nweight_filler {\r\ntype: ""msra""\r\n}\r\nbias_filler {\r\ntype: ""constant""\r\nvalue: 0.0\r\n}\r\n}\r\n}\r\nlayer {\r\nname: ""relu2c_1""\r\ntype: ""PReLU""\r\nbottom: ""conv2c_1""\r\ntop: ""conv2c_1""\r\n}\r\n\r\nlayer {\r\nname: ""conv2c_2""\r\ntype: ""Convolution""\r\nbottom: ""conv2c_1""\r\ntop: ""conv2c_2""\r\nparam {\r\nlr_mult: 1.0\r\ndecay_mult: 1.0\r\n}\r\nparam {\r\nlr_mult: 2.0\r\ndecay_mult: 0.0\r\n}\r\nconvolution_param {\r\nnum_output: 64\r\npad: 1\r\nkernel_size: 3\r\nweight_filler {\r\ntype: ""msra""\r\n}\r\nbias_filler {\r\ntype: ""constant""\r\nvalue: 0.0\r\n}\r\n}\r\n}\r\nlayer {\r\nname: ""relu2c_2""\r\ntype: ""PReLU""\r\nbottom: ""conv2c_2""\r\ntop: ""conv2c_2""\r\n}\r\n\r\nlayer {\r\nbottom: ""conv2_1""\r\nbottom: ""conv2c_2""\r\ntop: ""res2""\r\nname: ""res2""\r\ntype: ""Eltwise""\r\neltwise_param {\r\noperation: SUM\r\n}\r\n}\r\n\r\nlayer {\r\nname: ""pool2""\r\ntype: ""Pooling""\r\nbottom: ""res2""\r\ntop: ""pool2""\r\npooling_param {\r\npool: MAX\r\nkernel_size: 2\r\nstride: 2\r\n}\r\npropagate_down: 0\r\n}\r\n\r\nlayer {\r\nname: ""conv3_1""\r\ntype: ""Convolution""\r\nbottom: ""pool2""\r\ntop: ""conv3_1""\r\nparam {\r\nlr_mult: 1.0\r\ndecay_mult: 1.0\r\n}\r\nparam {\r\nlr_mult: 2.0\r\ndecay_mult: 0.0\r\n}\r\nconvolution_param {\r\nnum_output: 64\r\npad: 1\r\nkernel_size: 3\r\nweight_filler {\r\ntype: ""msra""\r\n}\r\nbias_filler {\r\ntype: ""constant""\r\nvalue: 0.0\r\n}\r\n}\r\n}\r\nlayer {\r\nname: ""relu3_1""\r\ntype: ""PReLU""\r\nbottom: ""conv3_1""\r\ntop: ""conv3_1""\r\n}\r\n\r\nlayer {\r\nname: ""conv3c_1""\r\ntype: ""Convolution""\r\nbottom: ""conv3_1""\r\ntop: ""conv3c_1""\r\nparam {\r\nlr_mult: 1.0\r\ndecay_mult: 1.0\r\n}\r\nparam {\r\nlr_mult: 2.0\r\ndecay_mult: 0.0\r\n}\r\nconvolution_param {\r\nnum_output: 64\r\npad: 1\r\nkernel_size: 3\r\nweight_filler {\r\ntype: ""msra""\r\n}\r\nbias_filler {\r\ntype: ""constant""\r\nvalue: 0.0\r\n}\r\n}\r\n}\r\nlayer {\r\nname: ""relu3c_1""\r\ntype: ""PReLU""\r\nbottom: ""conv3c_1""\r\ntop: ""conv3c_1""\r\n}\r\n\r\nlayer {\r\nname: ""conv3c_2""\r\ntype: ""Convolution""\r\nbottom: ""conv3c_1""\r\ntop: ""conv3c_2""\r\nparam {\r\nlr_mult: 1.0\r\ndecay_mult: 1.0\r\n}\r\nparam {\r\nlr_mult: 2.0\r\ndecay_mult: 0.0\r\n}\r\nconvolution_param {\r\nnum_output: 64\r\npad: 1\r\nkernel_size: 3\r\nweight_filler {\r\ntype: ""msra""\r\n}\r\nbias_filler {\r\ntype: ""constant""\r\nvalue: 0.0\r\n}\r\n}\r\n}\r\nlayer {\r\nname: ""relu3c_2""\r\ntype: ""PReLU""\r\nbottom: ""conv3c_2""\r\ntop: ""conv3c_2""\r\n}\r\n\r\nlayer {\r\nbottom: ""conv3_1""\r\nbottom: ""conv3c_2""\r\ntop: ""res3""\r\nname: ""res3""\r\ntype: ""Eltwise""\r\neltwise_param {\r\noperation: SUM\r\n}\r\n}\r\n\r\nlayer {\r\nname: ""pool3""\r\ntype: ""Pooling""\r\nbottom: ""res3""\r\ntop: ""pool3""\r\npooling_param {\r\npool: MAX\r\nkernel_size: 2\r\nstride: 2\r\n}\r\n}\r\n\r\nlayer {\r\nname: ""conv4_3""\r\ntype: ""Convolution""\r\nbottom: ""pool3""\r\ntop: ""conv4_3""\r\nparam {\r\nlr_mult: 1.0\r\ndecay_mult: 1.0\r\n}\r\nparam {\r\nlr_mult: 2.0\r\ndecay_mult: 0.0\r\n}\r\nconvolution_param {\r\nnum_output: 64\r\npad: 1\r\nkernel_size: 3\r\nweight_filler {\r\ntype: ""msra""\r\n}\r\nbias_filler {\r\ntype: ""constant""\r\nvalue: 0.0\r\n}\r\n}\r\n}\r\nlayer {\r\nname: ""relu4_3""\r\ntype: ""PReLU""\r\nbottom: ""conv4_3""\r\ntop: ""conv4_3""\r\n}\r\n\r\nlayer {\r\nname: ""conv4c_1""\r\ntype: ""Convolution""\r\nbottom: ""conv4_3""\r\ntop: ""conv4c_1""\r\nparam {\r\nlr_mult: 1.0\r\ndecay_mult: 1.0\r\n}\r\nparam {\r\nlr_mult: 2.0\r\ndecay_mult: 0.0\r\n}\r\nconvolution_param {\r\nnum_output: 64\r\npad: 1\r\nkernel_size: 3\r\nweight_filler {\r\ntype: ""msra""\r\n}\r\nbias_filler {\r\ntype: ""constant""\r\nvalue: 0.0\r\n}\r\n}\r\n}\r\nlayer {\r\nname: ""relu4c_1""\r\ntype: ""PReLU""\r\nbottom: ""conv4c_1""\r\ntop: ""conv4c_1""\r\n}\r\n\r\nlayer {\r\nname: ""conv4c_2""\r\ntype: ""Convolution""\r\nbottom: ""conv4c_1""\r\ntop: ""conv4c_2""\r\nparam {\r\nlr_mult: 1.0\r\ndecay_mult: 1.0\r\n}\r\nparam {\r\nlr_mult: 2.0\r\ndecay_mult: 0.0\r\n}\r\nconvolution_param {\r\nnum_output: 64\r\npad: 1\r\nkernel_size: 3\r\nweight_filler {\r\ntype: ""msra""\r\n}\r\nbias_filler {\r\ntype: ""constant""\r\nvalue: 0.0\r\n}\r\n}\r\n}\r\nlayer {\r\nname: ""relu4c_2""\r\ntype: ""PReLU""\r\nbottom: ""conv4c_2""\r\ntop: ""conv4c_2""\r\n}\r\n\r\nlayer {\r\nbottom: ""conv4_3""\r\nbottom: ""conv4c_2""\r\ntop: ""res4""\r\nname: ""res4""\r\ntype: ""Eltwise""\r\neltwise_param {\r\noperation: SUM\r\n}\r\n}\r\n\r\nlayer {\r\nname: ""conv4_3_norm_mbox_loc_1""\r\ntype: ""Convolution""\r\nbottom: ""res4""\r\ntop: ""conv4_3_norm_mbox_loc""\r\nparam {\r\nlr_mult: 1.0\r\ndecay_mult: 1.0\r\n}\r\nparam {\r\nlr_mult: 2.0\r\ndecay_mult: 0.0\r\n}\r\nconvolution_param {\r\nnum_output: 48\r\npad: 1\r\nkernel_size: 3\r\nstride: 1\r\nweight_filler {\r\ntype: ""msra""\r\n}\r\nbias_filler {\r\ntype: ""constant""\r\nvalue: 0.0\r\n}\r\n}\r\n}\r\n\r\nlayer {\r\nname: ""conv4_3_norm_mbox_conf_1""\r\ntype: ""Convolution""\r\nbottom: ""res4""\r\ntop: ""conv4_3_norm_mbox_conf""\r\nparam {\r\nlr_mult: 1.0\r\ndecay_mult: 1.0\r\n}\r\nparam {\r\nlr_mult: 2.0\r\ndecay_mult: 0.0\r\n}\r\nconvolution_param {\r\nnum_output: 24\r\npad: 1\r\nkernel_size: 3\r\nstride: 1\r\nweight_filler {\r\ntype: ""msra""\r\n}\r\nbias_filler {\r\ntype: ""constant""\r\nvalue: 0.0\r\n}\r\n}\r\n}\r\n\r\nlayer {\r\nname: ""conv4_3_norm_mbox_priorbox_1""\r\ntype: ""PriorBox""\r\nbottom: ""res4""\r\nbottom: ""data""\r\ntop: ""conv4_3_norm_mbox_priorbox""\r\nprior_box_param {\r\nmin_size: 20.0\r\nmin_size: 40.0\r\nmax_size: 60.0\r\nmax_size: 80.0\r\naspect_ratio: 2.0\r\naspect_ratio: 3.0\r\nflip: true\r\nclip: false\r\nvariance: 0.10000000149\r\nvariance: 0.10000000149\r\nvariance: 0.20000000298\r\nvariance: 0.20000000298\r\noffset: 0.5\r\n}\r\n}\r\n\r\nlayer {\r\nname: ""conv4_3_norm_mbox_loc_perm_1""\r\ntype: ""Permute""\r\nbottom: ""conv4_3_norm_mbox_loc""\r\ntop: ""conv4_3_norm_mbox_loc_perm""\r\npermute_param {\r\norder: 0\r\norder: 2\r\norder: 3\r\norder: 1\r\n}\r\n}\r\nlayer {\r\nname: ""conv4_3_norm_mbox_loc_flat_1""\r\ntype: ""Flatten""\r\nbottom: ""conv4_3_norm_mbox_loc_perm""\r\ntop: ""conv4_3_norm_mbox_loc_flat""\r\nflatten_param {\r\naxis: 1\r\n}\r\n}\r\n\r\nlayer {\r\nname: ""conv4_3_norm_mbox_conf_perm_1""\r\ntype: ""Permute""\r\nbottom: ""conv4_3_norm_mbox_conf""\r\ntop: ""conv4_3_norm_mbox_conf_perm""\r\npermute_param {\r\norder: 0\r\norder: 2\r\norder: 3\r\norder: 1\r\n}\r\n}\r\nlayer {\r\nname: ""conv4_3_norm_mbox_conf_flat_1""\r\ntype: ""Flatten""\r\nbottom: ""conv4_3_norm_mbox_conf_perm""\r\ntop: ""conv4_3_norm_mbox_conf_flat""\r\nflatten_param {\r\naxis: 1\r\n}\r\n}\r\n\r\nlayer {\r\nname: ""mbox_loss_1""\r\ntype: ""MultiBoxLoss""\r\nbottom: ""conv4_3_norm_mbox_loc_flat""\r\nbottom: ""conv4_3_norm_mbox_conf_flat""\r\nbottom: ""conv4_3_norm_mbox_priorbox""\r\nbottom: ""label""\r\ntop: ""mbox_loss""\r\ninclude {\r\nphase: TRAIN\r\n}\r\npropagate_down: true\r\npropagate_down: true\r\npropagate_down: false\r\npropagate_down: false\r\nloss_param {\r\nnormalization: VALID\r\n}\r\nmultibox_loss_param {\r\nloc_loss_type: SMOOTH_L1\r\nconf_loss_type: SOFTMAX\r\nloc_weight: 1.0\r\nnum_classes: 2\r\nshare_location: true\r\nmatch_type: PER_PREDICTION\r\noverlap_threshold: 0.5\r\nuse_prior_for_matching: true\r\nbackground_label_id: 0\r\nuse_difficult_gt: true\r\nneg_pos_ratio: 3.0\r\nneg_overlap: 0.5\r\ncode_type: CENTER_SIZE\r\nignore_cross_boundary_bbox: false\r\nmining_type: MAX_NEGATIVE\r\n}\r\n}\r\n']",[],1,0
9,caffe,6065,closed,unable to reproduce accuracy of bvlc-alexnet,"### Issue summary
I use model definition(models/bvlc_alexnet/train_val.prototxt) and training protocol(models/bvlc_alexnet/solver.prototxt) provided by caffe to train alexnet on ImageNet.The only modification  I made is replacing mean.binaryproto with mean values computed by Facebook.And I have checked they are very close: 103.894,116.555,122.579 vs 103.94,116.78,123.68 .
But the accuracy on validation set I got is 55.06% which is observably low compared to the one reported by caffe comunity(57.1%,https://github.com/BVLC/caffe/tree/master/models/bvlc_alexnet).
The differences of mean values are tiny so I think there are other reasons making such a large drop in accuracy.
Then I use pre-trained caffemodel provided by caffe(http://dl.caffe.berkeleyvision.org/bvlc_alexnet.caffemodel) and get the accuracy.It still fall behind the reference accuracy, 55.9% vs 57.1%.
The imagenet lmdb dataset are created by script at  examples/imagenet/create_imagenet.sh with RESIZE=true.
Could anyone give some suggestions about this problem?
### Steps to reproduce
//train alexnet using caffe
./build/tools/caffe train -gpu 0 -solver models/bvlc_alexnet/solver.prototxt
//use pre-trained alexnet model
./build/tools/caffe test -gpu 0  -model models/bvlc_alexnet/train_val.prototxt -weights models/bvlc_alexnet.caffemodel
### Your system configuration
Operating system:Ubuntu 16.04
Compiler:nvcc-8,gcc-5.4.0
CUDA version (if applicable):CUDA8
CUDNN version (if applicable):cudnn515
BLAS:atlas ,cublas8.0
",,"['Please do not post usage, installation, or modeling questions, or other requests for help to Issues. Use the [caffe-users list][1] instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe. Please read the [guidelines for contributing][2] before submitting an issue or a pull request.\r\n\r\n [1]: https://groups.google.com/forum/#!forum/caffe-users\r\n [2]: https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md']",[],[],1,0
10,caffe,6450,open,OpenCL Speed Slower on Large Convolutions,"### Issue summary

I have evaluated the speed of OpenCL vs CUDA Caffe on the OpenPose Project. This is the OpenPose model:

https://raw.githubusercontent.com/CMU-Perceptual-Computing-Lab/openpose/master/models/pose/coco/pose_deploy_linevec.prototxt

It seems to be significantly slower (2x)

https://pastebin.com/14xzRi3z

Eg:

For example conv2_1 which takes in a 3x186x186 feature map and applies a convolution takes 2.5 milliseconds on OpenCL and 0.86 milliseconds in CUDA



### Steps to reproduce


### System configuration

* Operating system: 16.04 Ubuntu
* Compiler: GCC 5.4
* CUDA version (if applicable): 9.0 + OPENCL (GTX 1080TI)
* CUDNN version (if applicable): 
* BLAS: 
* Python version (if using pycaffe): 
* MATLAB version (if using matcaffe): 
",OpenCL,"[""Did you use cuDNN on CUDA and LibDNN on OpenCL? These are the currently fastest option.\r\nAnd if so, there's nothing we can currently do about it to match the performance of hand-tuned CUDA kernels. A lack of working profilers and kernel analyzers on nVidia, Intel and AMD's side make OpenCL kernel performance a black box in which you at most can try to get better performance with tuning parameter grid search in LibDNN."", 'I am using LibDNN\r\n\r\n""get better performance with tuning parameter grid search in LibDNN.""\r\n\r\nIc, what do you mean by this?\r\n\r\nAlso, would an equivalent AMD card have better performance then perhaps because it has better CL drivers?', ""@soulslicer LibDNN for both CUDA and OpenCL in your benchmark? If it's the same GPU, same driver, same library and the only difference in your test is CUDA or OpenCL, then the two following issues exist:\r\n- nVidia compiles equivalent kernels in OpenCL and CUDA differently\r\n- OpenCL may have slightly larger launch overheads. Test if you see a smaller performance difference when running the kernel not only for a batch size of 1, but for example a batch size of 128. This would make the launch time vanish against the actual compute time.\r\n- Yes, AMD cards tend to perform better on OpenCL than nVidia."", ""Well..for CUDA testing, I compiled the master branch, and for OpenCL I compiled the opencl branch.\r\n\r\nI don't think its the launch overhead. The above code measures per convolution performance and launch overhead should not affect this.\r\n\r\nYes I agree on the AMD part, is there any good benchmarks that show comparisons on OpenCL on NVIDIA vs AMD?"", ""Master branch with or without cuDNN? Sorry I need more precise details what you did to deduct what's going on. And yes, launch overhead can affect per-convolution performance, especially for such a small convolution (short time).""]",[],"['I0705 12:53:35.618479  3990 caffe.cpp:461]    conv2_1   forward: 2.51716 ms.            forward: 0.863448 ms.   I0705 12:55:39.772596  7677 caffe.cpp:400]    conv2_1', '\r\ncaffe time --model pose_deploy_linevec.prototxt -gpu=all']",1,0
11,caffe,3250,closed,Implementing gradient scaling with class frequencies on Softmax Loss Layer.,"Given a dataset with imbalanced class distribution learning a robust NN model is hard. In general, the network leads a bias toward the common classes and ignores the rare ones. For solving this issue, I target to rescale gradient signals regarding the class frequencies. I plan to follow these steps for the implementation;
- Compute class frequency coefficients which are less then or equal to 1 and 1 for the smallest class and  min_class_freq/class_freq for the other classes. These values are written to binary proto file as a list.
- I give an extra proto parameter to SoftmaxWithLoss layer as the file name of this freq. file similar to mean file used by the data layer.
- At the runtime, softmax layer read the file and define a blob including these freq values, at the setup.
- Then for each iteration I scale the gradient with corresponding frequency value indexed by the label value.

Here is the basic change on softmax_loss_layer.cu to perform the scaling.



Basically, I decoupled the GPU operations for a normal backpropagation and the scaled one and I scale the gradient value at SoftmaxLossBackwardGPU1.

Even I spend whole my week, I have a problem that cannot be solved. With any setting of learning rate, with this change, network ends up with exploding gradients after some iterations. However, it does not make sense since the frequency values are less then or equal to 1 then we should observe smaller gradients which might cause diminishing gradient but not explosion.

If someone can help me to point out the problem that would be great. I already asked this at the user forum but I could not get ans response. Sorry for the wrong platform for this question.
",,"['Closing as this does not belong here (as acknowledged by the poster!).\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']","['\ntemplate <typename Dtype>\n__global__ void SoftmaxLossBackwardGPU1(const int nthreads, const Dtype* top,\n          const Dtype* label, Dtype* bottom_diff, const int num, const int dim,\n          const int spatial_dim, const bool has_ignore_label_,\n          const int ignore_label_, Dtype* counts, Dtype* class_freqs) {\n  const int channels = dim / spatial_dim;\n\n  CUDA_KERNEL_LOOP(index, nthreads) {\n    const int n = index / spatial_dim;\n    const int s = index % spatial_dim;\n    const int label_value = static_cast<int>(label[n * spatial_dim + s]);\n\n    if (has_ignore_label_ && label_value == ignore_label_) {\n      for (int c = 0; c < channels; ++c) {\n        bottom_diff[n * dim + c * spatial_dim + s] = 0;\n      }\n      counts[index] = 0;\n    } else {\n      bottom_diff[n * dim + label_value * spatial_dim + s] -= 1;\n      bottom_diff[n * dim + label_value * spatial_dim + s] *= class_freqs[label_value];\n      counts[index] = 1;\n    }\n  }\n}\n\ntemplate <typename Dtype>\n__global__ void SoftmaxLossBackwardGPU2(const int nthreads, const Dtype* top,\n          const Dtype* label, Dtype* bottom_diff, const int num, const int dim,\n          const int spatial_dim, const bool has_ignore_label_,\n          const int ignore_label_, Dtype* counts) {\n  const int channels = dim / spatial_dim;\n\n  CUDA_KERNEL_LOOP(index, nthreads) {\n    const int n = index / spatial_dim;\n    const int s = index % spatial_dim;\n    const int label_value = static_cast<int>(label[n * spatial_dim + s]);\n\n    if (has_ignore_label_ && label_value == ignore_label_) {\n      for (int c = 0; c < channels; ++c) {\n        bottom_diff[n * dim + c * spatial_dim + s] = 0;\n      }\n      counts[index] = 0;\n    } else {\n      bottom_diff[n * dim + label_value * spatial_dim + s] -= 1;\n      counts[index] = 1;\n    }\n  }\n}\n\ntemplate <typename Dtype>\nvoid SoftmaxWithLossLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top,\n    const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {\n  if (propagate_down[1]) {\n    LOG(FATAL) << this->type()\n               << "" Layer cannot backpropagate to label inputs."";\n  }\n  if (propagate_down[0]) {\n    Dtype* bottom_diff = bottom[0]->mutable_gpu_diff();\n    const Dtype* prob_data = prob_.gpu_data();\n    const Dtype* top_data = top[0]->gpu_data();\n    caffe_gpu_memcpy(prob_.count() * sizeof(Dtype), prob_data, bottom_diff);\n    const Dtype* label = bottom[1]->gpu_data();\n    const int dim = prob_.count() / outer_num_;\n    const int nthreads = outer_num_ * inner_num_;\n    // Since this memory is never used for anything else,\n    // we use to to avoid allocating new GPU memory.\n    Dtype* counts = prob_.mutable_gpu_diff();\n    // NOLINT_NEXT_LINE(whitespace/operators)\n    if (class_freq_norm_){\n      Dtype* class_freqs = class_freqs_.mutable_gpu_data();\n      SoftmaxLossBackwardGPU1<Dtype><<<CAFFE_GET_BLOCKS(nthreads),\n          CAFFE_CUDA_NUM_THREADS>>>(nthreads, top_data, label, bottom_diff,\n          outer_num_, dim, inner_num_, has_ignore_label_, ignore_label_, counts, \n          class_freqs);\n    }else{\n      SoftmaxLossBackwardGPU2<Dtype><<<CAFFE_GET_BLOCKS(nthreads),\n          CAFFE_CUDA_NUM_THREADS>>>(nthreads, top_data, label, bottom_diff,\n          outer_num_, dim, inner_num_, has_ignore_label_, ignore_label_, counts);\n    }\n    const Dtype loss_weight = top[0]->cpu_diff()[0];\n    if (normalize_) {\n      Dtype count;\n      caffe_gpu_asum(nthreads, counts, &count);\n      caffe_gpu_scal(prob_.count(), loss_weight / count, bottom_diff);\n    } else {\n      caffe_gpu_scal(prob_.count(), loss_weight / outer_num_, bottom_diff);\n    }\n  }\n}\n']",[],1,0
12,caffe,4026,closed,Caffe memory leaks,"I posted this on the users group and a responder said it may be useful here.

valgrind will complete if leveldb is used instead of lmdb.

Compiled with GPU and run with GPU
==4315== LEAK SUMMARY:
==4315==    definitely lost: 96 bytes in 4 blocks
==4315==    indirectly lost: 0 bytes in 0 blocks
==4315==      possibly lost: 70,778,113 bytes in 20,095 blocks
==4315==    still reachable: 114,126,748 bytes in 153,749 blocks
==4315==         suppressed: 0 bytes in 0 blocks

Compiled with GPU and run as CPU
==5232== LEAK SUMMARY:
==5232==    definitely lost: 96 bytes in 4 blocks
==5232==    indirectly lost: 0 bytes in 0 blocks
==5232==      possibly lost: 70,775,503 bytes in 20,075 blocks
==5232==    still reachable: 114,116,564 bytes in 153,675 blocks
==5232==         suppressed: 0 bytes in 0 blocks

Compiled as CPU only
==12882== LEAK SUMMARY:
==12882==    definitely lost: 0 bytes in 0 blocks
==12882==    indirectly lost: 0 bytes in 0 blocks
==12882==      possibly lost: 86,909 bytes in 1,906 blocks
==12882==    still reachable: 552,984 bytes in 6,332 blocks
==12882==         suppressed: 0 bytes in 0 blocks

This valgrind page http://valgrind.org/docs/manual/faq.html#faq.deflost gives the following for 'possibly lost'.

""possibly lost"" means your program is leaking memory, unless you're doing unusual things with pointers that could cause them to point into the middle of an allocated block; see the user manual for some possible causes.

The mnist GPU run was repeated 273 times (just under 100 minutes) at which point the computer was freezing up from lack of memory. 'cat /proc/meminfo' was used to collect memory stats every 10 seconds during the sequence. Charts of the 42 stats in /proc/meminfo are combined on to a single page at https://github.com/neilnelson/misc/blob/master/meminfo.png. (Right click, select View Image, click on the image to expand.)

The interesting charts are
  MemFree declines to about zero (175372 bytes) at the 219 run.
  Buffers stays the same until MemFree gets to zero and then declines to zero
  Cached is similar to Buffers
  SwapFree declines (an increase in swap usage) when MemFree gets to zero.

Just before LEAK SUMMARY in the 'compiled with GPU and run as CPU' run instance is the following 'possibly lost' section.

==5232== 22,144,025 bytes in 2,207 blocks are possibly lost in loss record 2,543 of 2,544
==5232==    at 0x4C2AB80: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
==5232==    by 0x28E90F1D: ??? (in /usr/lib/x86_64-linux-gnu/libcuda.so.352.63)
==5232==    by 0x28E4134C: ??? (in /usr/lib/x86_64-linux-gnu/libcuda.so.352.63)
==5232==    by 0x28E5211F: ??? (in /usr/lib/x86_64-linux-gnu/libcuda.so.352.63)
==5232==    by 0x28F3FCCF: ??? (in /usr/lib/x86_64-linux-gnu/libcuda.so.352.63)
==5232==    by 0x28F3FFDF: ??? (in /usr/lib/x86_64-linux-gnu/libcuda.so.352.63)
==5232==    by 0xE43FD2C: ??? (in /usr/local/cuda-7.0/targets/x86_64-linux/lib/libcudnn.so.4)
==5232==    by 0xE432AAF: ??? (in /usr/local/cuda-7.0/targets/x86_64-linux/lib/libcudnn.so.4)
==5232==    by 0xE43EDB6: ??? (in /usr/local/cuda-7.0/targets/x86_64-linux/lib/libcudnn.so.4)
==5232==    by 0xE443570: ??? (in /usr/local/cuda-7.0/targets/x86_64-linux/lib/libcudnn.so.4)
==5232==    by 0xE4371DB: ??? (in /usr/local/cuda-7.0/targets/x86_64-linux/lib/libcudnn.so.4)
==5232==    by 0xE4256A1: ??? (in /usr/local/cuda-7.0/targets/x86_64-linux/lib/libcudnn.so.4)
==5232==    by 0xE458C9E: ??? (in /usr/local/cuda-7.0/targets/x86_64-linux/lib/libcudnn.so.4)
==5232==    by 0xE146C11: cudnnCreate (in /usr/local/cuda-7.0/targets/x86_64-linux/lib/libcudnn.so.4)
==5232==    by 0x51CE276: caffe::CuDNNConvolutionLayer<float>::LayerSetUp(std::vectorcaffe::Blob<float_, std::allocatorcaffe::Blob<float_> > const&, std::vectorcaffe::Blob<float_, std::allocatorcaffe::Blob<float_> > const&) (cudnn_conv_layer.cpp:53)
==5232==    by 0x518EC4B: caffe::Layer<float>::SetUp(std::vectorcaffe::Blob<float_, std::allocatorcaffe::Blob<float_> > const&, std::vectorcaffe::Blob<float_, std::allocatorcaffe::Blob<float_> > const&) (layer.hpp:71)
==5232==    by 0x51946E0: caffe::Net<float>::Init(caffe::NetParameter const&) (net.cpp:139)
==5232==    by 0x5192A76: caffe::Net<float>::Net(caffe::NetParameter const&, caffe::Net<float> const*) (net.cpp:27)
==5232==    by 0x516BB72: caffe::Solver<float>::InitTrainNet() (solver.cpp:105)
==5232==    by 0x516B395: caffe::Solver<float>::Init(caffe::SolverParameter const&) (solver.cpp:57)

This seems a little odd in that the 22,144,025 possibly lost bytes is related to Cuda libs out of caffe::CuDNNConvolutionLayer. That is, if the GPU is not being used in a CPU run, Cuda libs would not expected to be used as shown.

The 'possibly lost' figure of the 'Compiled as CPU only' LEAK SUMMARY is insignificant when compared to the figures from the Cuda compiled code.

The memory decline over the first 192 Cuda mnist runs averages to 59.8 megabytes per run. valgrind shows 67.5 megabytes 'possibly lost' for a single run.
",,"['> This seems a little odd in that the 22,144,025 possibly lost bytes is related to Cuda libs out of caffe::CuDNNConvolutionLayer. That is, if the GPU is not being used in a CPU run, Cuda libs would not expected to be used as shown.\n\nThis is probably related to #3953 \n', 'Update\n\nThis page http://stackoverflow.com/questions/20593450/valgrind-and-cuda-are-reported-leaks-real writes that valgrind gives false memory leaks for Cuda.\n\nThe ending mnist output for cuda-memcheck --leak-check full is\n\n========= Program hit cudaErrorCudartUnloading (error 29) due to ""driver shutting down"" on CUDA API call to cudaFree. \n=========     Saved host backtrace up to driver entry point at error\n=========     Host Frame:/usr/lib/x86_64-linux-gnu/libcuda.so.1 [0x2f31b3]\n=========     Host Frame:/usr/local/cuda-7.0/lib64/libcurand.so.7.0 [0xa0f76]\n=========     Host Frame:/usr/local/cuda-7.0/lib64/libcurand.so.7.0 (curandDestroyGenerator + 0x254) [0x234f4]\n=========     Host Frame:/mnt/Documents/caffe-master/.build_debug/tools/../lib/libcaffe.so.1.0.0-rc3 (_ZN5caffe5CaffeD2Ev + 0x100) [0x32d0ea]\n=========     Host Frame:/mnt/Documents/caffe-master/.build_debug/tools/../lib/libcaffe.so.1.0.0-rc3 (_ZN5boost19thread_specific_ptrIN5caffe5CaffeEE11delete_dataclEPv + 0x22) [0x32fa86]\n=========     Host Frame:/usr/lib/x86_64-linux-gnu/libboost_thread.so.1.55.0 (_ZN5boost6detail12set_tss_dataEPKvNS_10shared_ptrINS0_20tss_cleanup_functionEEEPvb + 0x41) [0xd021]\n=========     Host Frame:/mnt/Documents/caffe-master/.build_debug/tools/../lib/libcaffe.so.1.0.0-rc3 (_ZN5boost19thread_specific_ptrIN5caffe5CaffeEED1Ev + 0x33) [0x32fac9]\n=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__cxa_finalize + 0x9a) [0x3c5ea]\n\n# =========     Host Frame:/mnt/Documents/caffe-master/.build_debug/tools/../lib/libcaffe.so.1.0.0-rc3 [0x2661a3]\n\n========= LEAK SUMMARY: 0 bytes leaked in 0 allocations\n========= ERROR SUMMARY: 29 errors\n\ngiving 0 bytes leaked.\n\nThe linked page also gives a valgrind correction for Cuda with the ending mnist output\n\n==27444== LEAK SUMMARY:\n==27444==    definitely lost: 0 bytes in 0 blocks\n==27444==    indirectly lost: 0 bytes in 0 blocks\n==27444==      possibly lost: 86,935 bytes in 1,907 blocks\n==27444==    still reachable: 554,312 bytes in 6,338 blocks\n==27444==         suppressed: 85,794,483 bytes in 98,237 blocks\n\nThe \'possibly lost\' is quite low here.\n\nAt this point the issue is that I can document a memory leak of around 60 megabytes per mnist run by logging the memory stats every few seconds while repeating the mnist run until the computer runs out of memory and starts to freeze. Of course you only need to repeat the mnist run a dozen or so times while logging the computer\'s memory to see the effect and get a memory leak estimate.\n', ""Update\n\nThis page https://github.com/neilnelson/misc/blob/master/cuda_mnist_mem_used.png has a chart of the memory-used for a single Cuda mnist run. 'free' was recorded about every .01 seconds throughout the run (5000 observations over about 50 seconds). The 'used' value to the right of '-/+ buffers/cache:' and less the amount used (at each observation) by the ram disk containing the logging is the charted memory-used value.\n\nSeconds is zeroed at the first time reported in the Caffe run log. The Caffe run ends on the chart at the large drop in memory-used toward the right of the chart.\n\nThe memory-used shelf to the right after the Caffe run less the beginning memory-used is just over 60 megabytes.\n\nThe majority of memory is allocated in the first second that ends just before the second (and last) occurrence of 'Setting up ip1'. Given the size of the memory-used drop at the end of the run and that the majority of the memory allocation occurs in the first second, this argues (not certainly but as a reasonable direction) that the allocation resulting in the memory leak occurs in the first second.\n"", 'Could you share the command you are using to reproduce the bug?\n', 'This is an mnist run using Caffe compiled for debug. I noticed the memory leak using the standard Caffe install without debug. caffe-master has a README.md of Mar  9 13:42.\n\n/home/nnelson/Documents/caffe-master/.build_debug/tools/caffe train --solver=/voxforge/runs/test/solver.prototxt &> /voxforge/runs/test/cuda_speed_run5.log\n\n/voxforge is a 1 gig RAM disk where all the input is copied before the run and output is placed.\n\n/voxforge/runs/test/solver.prototxt contains\n`#` The train/test solver.prototxt net protocol buffer definition\n`#` net: ""/voxforge/mnist/train_val.prototxt""\n\ntrain_net: ""/voxforge/caffe/train.prototxt""\ntest_net: ""/voxforge/caffe/test.prototxt""\n\n`#` test_iter specifies how many forward passes the test should carry out.\n`#` In the case of MNIST, we have test batch size 100 and 100 test iterations,\n`#` covering the full 10,000 testing images.\ntest_iter: 100\n`#` Carry out testing every 25 training iterations.\ntest_interval: 25\n`#` The base learning rate, momentum and the weight decay of the network.\nbase_lr: 0.01\nmomentum: 0.9\nweight_decay: 0.0005\n`#` The learning rate policy\nlr_policy: ""inv""\ngamma: 0.0001\npower: 0.75\n`#` Display every 10 iterations\ndisplay: 10\n`#` The maximum number of iterations\nmax_iter: 200\n`#` snapshot intermediate results\n`#` snapshot: 5000\n`#` snapshot_prefix: ""/voxforge/mnist/lenet""\n`#` solver_mode: CPU or GPU\n', 'I see that the pound signs have made the text large and bold.\n', 'Use ``` before and after.\n', 'And you should share your prototxt on a GitHub repo, ideally with a script to run the test.\n', 'A detailed procedure to do an easy version of a memory leak test is at https://github.com/neilnelson/caffe_memory_test. \n', 'Even if there is a memory leak in the code, memory should be reclaimed when the process exits:\nhttp://stackoverflow.com/questions/2975831/is-leaked-memory-freed-up-when-the-program-exits\n\nSo, it seems you have a deeper problem, you should try to update your kernel and your drivers if possible.\n', 'I am running Ubuntu 14.04 and everything is kept up to date. I see that Xubuntu/Ubuntu 16.04 is out and I can upgrade to that.\n\nRunning the memory test at https://github.com/neilnelson/caffe_memory_test seems like an easy thing to do. You will either see that your equipment and software will show no leak or that what I have been writing is confirmed. The test here took just over 9 minutes.\n\nUbuntu 14.04.4 LTS\nkernel 3.13.0-85-generic\ngcc (Ubuntu 4.8.4-2ubuntu1~14.04.1) 4.8.4\nGeForce GT 720\nCuda compilation tools, release 7.0, V7.0.27\nlibatlas-base-dev 3.10.1-4\nlibblas-dev Version: 1.2.20110419-7\nlibboost1.55-all-dev\nprotobuf-compiler 2.5.0-9ubuntu1\npython-protobuf 2.5.0-9ubuntu1\nlibgoogle-glog-dev 0.3.3-1\npython-gflags 1.5.1-1build1\nlibhdf5-dev 1.8.11-5ubuntu7\nlibcudnn.so.4.0.4\nliblmdb-dev 0.9.16-1~ubuntu14.04.1\nlibleveldb-dev 1.15.0-2\nlibsnappy-dev 1.1.0-1ubuntu1\nlibopencv-dev 2.4.8+dfsg1-2ubuntu1\npython2.7 2.7.6-8ubuntu0.2\npython3 3.4.0-0ubuntu2\npython-numpy 1:1.8.2-0ubuntu0.1\npython3-numpy 1:1.8.2-0ubuntu0.1\n', ""I tried, I had no leak.\nYou didn't mention the version of your NVIDIA driver.\n"", 'Thank you for checking this out. To help me along, would you please post your mem_test.log from the test. Thank you.\n', 'Here is what mine looks like.\n\n```\n         total       used       free     shared    buffers     cached\n```\n\nMem:      16421400    3231908   13189492      19896     151992    1452364\n-/+ buffers/cache:    1627552   14793848\nSwap:     32767996          0   32767996\n1461465313\n1461465331\n1461465349\n1461465367\n1461465386\n1461465404\n1461465422\n1461465440\n1461465458\n1461465476\n1461465494\n1461465513\n1461465531\n1461465549\n1461465567\n1461465585\n1461465603\n1461465621\n1461465639\n1461465657\n1461465676\n1461465694\n1461465712\n1461465730\n1461465748\n1461465766\n1461465784\n1461465802\n1461465820\n1461465839\n1461465857\n             total       used       free     shared    buffers     cached\nMem:      16421400    4953212   11468188      20420     153432    1457144\n-/+ buffers/cache:    3342636   13078764\nSwap:     32767996          0   32767996\n', '[This github page](https://github.com/neilnelson/caffe_memory_test/blob/master/chart_100_per_second.md) provides detailed instructions to obtain the [single run Caffe mnist memory usage chart](https://github.com/neilnelson/caffe_memory_test/blob/master/usage_100.png), a procedure mentioned in a prior post above.\n\nI am doing this because I think Caffe is likely the best neural network software at the moment and am trying to correct an issue that hung my computer in a short period during small a inquiry I was performing.\n\nHaving detailed procedures giving clear output that may be repeated by anyone is basic to community progress. I hope to see output from others.\n', 'Here is the NVIDIA driver version.\n\ncat /proc/driver/nvidia/version\nNVRM version: NVIDIA UNIX x86_64 Kernel Module  352.63  Sat Nov  7 21:25:42 PST 2015\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.1)\n\nI read through http://stackoverflow.com/questions/2975831/is-leaked-memory-freed-up-when-the-program-exits and see that the memory should be freed, and the adjusted valgrind and cuda-memcheck above do not show any significant leaks. The tests I am providing here show that not all memory is freed.\n', ""@neilnelson,\n\nThanks for writing the test tools. We're also suspecting a memory leak in Caffe or one of its dependencies. I ran your test and got a similarly shaped curve for the memory usage and approx. 60 MB not freed up after the process terminates.\nWe have several users running experiments on the same server and it only takes a few days for the unclaimed RAM to make it very difficult to run anything on the machine without a system reboot.\n\nWe're running the latest on BVLC:master (commit 923e7e8b6337f610115ae28859408bc392d13136, Date: Wed May 25 18:11:15 2016 -0700), in GPU mode, with cuda 7.5\n\ncat /proc/driver/nvidia/version\nNVRM version: NVIDIA UNIX x86_64 Kernel Module  361.42  Tue Mar 22 18:10:58 PDT 2016\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.1)\n\nWe have another machine running a much older running off of NVIDIA Driver Version: 340.96 and cuda 6.5. It doesn't look like this one's affected by the leak. But can't tell for sure.\n\nAny ideas on where the leak could be coming from?\n\nThanks\n"", '@kashefy,\n\nI have been doing some Caffe memory usage tests these last two days and am currently installing the latest Cuda and Caffe software to avoid outdated software issues that might affect the result.\n\nOne idea that came to mind that might narrow down the search for source of the memory leak is to start by seeing if the\n\n`make runtest`\n\npart of the installation sequence, uses up memory. I suggest stacking ten or more of those runs in a bash file, much like [my first memory test using an mnist run](https://github.com/neilnelson/caffe_memory_test/blob/master/repeats_test.md) and using _free_ at the beginning and end to show how much, if any, memory was used.\n\nIf the average usage per run was significant, then there should be a way to run _free_ at the beginning of runtest and after each individual test. Since there are over 1,000 of these tests, with a little luck we may get fairly close to the problem area.\n\nI have seen after a test run that the `-/+ buffers/cache` figure from _free_ tends to settle a bit over about 15 seconds or so. Another item is that `test/get_memory_usage.php`, used in the second test, quickly ramps up to around a 4 megabyte memory use that closely accounts for the different estimates at the end of the pages for my two tests. This 4 megabyte memory is fairly flat after the initial ramp up and goes away after that php program ends.\n', ""@neilnelson, I think your idea to run the memory check around the individual unit tests is great to systematically isolate the leak. But as you pointed out, there are > 1,000 tests, so there'll be a bit of an effort in setting this up.\n\nI ran some more tests, I've uploaded all the data logged by mem_used.csv to [this sheet](https://docs.google.com/spreadsheets/d/1xOz9Vm1dg83SKf5O1LN1bu7A0vDxM-3SQZ94bS1eiYM/edit?usp=sharing):\n1. Running **only** your get_memory_usage.php for a longer duration shows a small gradual increase in memory. 7.5 MB in 240 sec.\n2. Training lenet for 20 iterations but leaving get_memory_usage.php on to see if the memory gets freed. Use memory doesn't return to the original level and is approx. 60 MB higher than before running caffe.\n3. Running multiple lenet experiments, each for a **single** iteration. We see approx. 80 MB RAM not being recovered after each iteration.\n4. Running a single lenet training for longer iterations. Approx. 60 MB RAM not recovered after process terminates.\n\nI don't think this has to with LMDB. I don't have anything quantitative for this, but I've had the same memory problem using HDF5 data. The amount of memory leaked seems independent from the number of iterations.\n\n**Preliminary**:\nI'm also seeing this with tensorflow, but not as consistently as with Caffe.\n1. I had TF's [cifar10_train.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_train.py) example running for max. 20 steps in parallel to `test/get_memory_usage.php` and found that approx. 250 MB RAM were not recovered after the training was finished.\n2. I had another run with longer steps and it looked like all the RAM was recovered.\n3. I repeatedly ran TF's cifar10 example with 20 steps and saw the 200 MB not being recovered after every run.\n\nI'm inclined to think this is a problem with the driver or CUDA toolkit. But not sure how to go about it. Maybe monitoring memory around each Caffe unit test is the way to go.\n"", ""@neilnelson,\nre-monitoring memory usage before+after caffe unit tests:\nTest test can be executed either through `cd ./build && make runtest` or `./build/test/test.testbin`. The former includes a cmake command and bulding the tests, so I recommend building once and then running the executable directly.\n\nJust from watching the memory row in `htop`, I could see both leaving 70-80 MB of RAM after execution.\n\nWe might not have to do such an exhaustive search after all, I limited the tests to those of the Im2colLayerTest test (limited to 8 tests with CPU<double> and 8 tests for GPU<float>) and could see approx. 70 MB RAM not getting freed after test execution. The choice of tests was arbitrary. this is the command I used to limit the execution to 8 tests:\n\n`./build/test/test.testbin --gtest_filter=*Im2colLayer*/*2*.*` Changing the 2 at the end to 1 switches the tests TypeParam from caffe::GPUDevice<float> to caffe::CPUDevice<double> \n\nCan narrow it down to even fewer tests. But if both CPU and GPU tests are leaking, it doesn't make sense to suspect the leak happening in CUDA or the NVIDIA driver, right?\n\nNarrowing it down to a **single** test:\n./build/test/test.testbin --gtest_filter=_Im2colLayer_/_1_._Setup_ # for CPU\nand\n./build/test/test.testbin --gtest_filter=_Im2colLayer_/_1_._Setup_ # for GPU\nIn `htop`, memory usage after test execution is still appprox. 70 MB higher than before test run.\n"", '@kashefy,\n\nThank you for your great progress on the memory leak issue. In order to remove execution of all the CUDA code Caffe has to be recompiled with the following lines in Makefile.config\n\n`# USE_CUDNN := 1`\n`CPU_ONLY := 1`\n\nfix42 commented above on this issue.\n\nMy guess is that this program is performing the test you have identified.\n\n`caffe-master/src/caffe/test/test_im2col_layer.cpp`\n\nThe syntax in your post\n\n`./build/test/test.testbin --gtest_filter=Im2colLayer/1.Setup # for GPU`\n\ntends toward the following code in the program. You may have a better idea.\n\n`template <typename TypeParam>`\n`class Im2colLayerTest : public MultiDeviceTest<TypeParam> {`\n`typedef typename TypeParam::Dtype Dtype;`\n`protected:`\n`Im2colLayerTest()`\n`: blob_bottom_(new Blob<Dtype>(2, 3, 6, 5)),`\n`blob_top_(new Blob<Dtype>()) {`\n`// fill the values`\n`Caffe::set_random_seed(1701);`\n`FillerParameter filler_param;`\n`GaussianFiller<Dtype> filler(filler_param);`\n`filler.Fill(this->blob_bottom_);`\n`blob_bottom_vec_.push_back(blob_bottom_);`\n`blob_top_vec_.push_back(blob_top_);`\n`}`\n`virtual ~Im2colLayerTest() { delete blob_bottom_; delete blob_top_; }`\n`Blob<Dtype>* const blob_bottom_;`\n`Blob<Dtype>* const blob_top_;`\n`vector<Blob<Dtype>*> blob_bottom_vec_;`\n`vector<Blob<Dtype>*> blob_top_vec_;`\n`};`\n\n`TYPED_TEST_CASE(Im2colLayerTest, TestDtypesAndDevices);`\n\n`TYPED_TEST(Im2colLayerTest, TestSetup) {`\n`typedef typename TypeParam::Dtype Dtype;`\n`LayerParameter layer_param;`\n`ConvolutionParameter* convolution_param =`\n`layer_param.mutable_convolution_param();`\n`vector<int> bottom_shape;`\n`bottom_shape.push_back(2);`\n`bottom_shape.push_back(3);`\n`bottom_shape.push_back(10);`\n`bottom_shape.push_back(11);`\n`this->blob_bottom_->Reshape(bottom_shape);`\n`convolution_param->add_kernel_size(3);`\n`convolution_param->add_stride(2);`\n`convolution_param->add_dilation(3);`\n`Im2colLayer<Dtype> layer(layer_param);`\n`layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);`\n`EXPECT_EQ(this->blob_top_->num(), 2);`\n`EXPECT_EQ(this->blob_top_->channels(), 27);`\n`EXPECT_EQ(this->blob_top_->height(), 2);`\n`EXPECT_EQ(this->blob_top_->width(), 3);`\n`}`\n\nGiven that just this test can be performed, the code here can be progressively truncated at the end (keep a backup copy) and recompiled and rerun until the memory leak disappears. At which point the last line or lines removed get closer to the cause.\n\n`Im2colLayer` comes from\n\n`caffe-master/src/caffe/layers/im2col_layer.cpp`\n\nalso note the _includes_ at the top of that file.\n\nI need to make headway on another project at the moment but am looking forward to your excellent progress.\n', ""@neilnelson, could you reopen the issue. Just to make it clear that the problem hasn't been resolved yet.\nI'm looking for a simpler test that reproduces the leak, will keep you posted on what I find.\n"", '@kashefy, The issue is now open. I closed it by mistake.\n', ""This post suggests the leak is coming from the NVIDIA dirvers. Link: http://superuser.com/questions/1062929/freeing-kernel-memory-leaked-by-nvidia-driver\nThe Latest **Long** Lived Branch version from NVIDIA's website for Linux 64-bit is currently at 361.45.11, which doesn't fix the leak. If you switch to the Latest **Short** Lived Branch version on this page from NVIDIA http://www.nvidia.com/object/unix.html, you can get something a bit more recent.\nFirst runs show that the **leak is gone**. Will keep you posted if anything changes and not sure how safe it is to use a driver outside of the long lived branch. But for now: Hurray!\n"", 'Thanks for the good news!\n', 'After running several iterations of the [memory leak test here](https://github.com/neilnelson/caffe_memory_test/blob/master/repeats_test.md), the conclusion is that given the inherent degree of error in the test, the hypothesis that software versions of the Caffe installation given below leaks memory is not supported.\n\nNVRM version: NVIDIA UNIX x86_64 Kernel Module  364.19  Tue Apr 19 14:44:55 PDT 2016\n&nbsp;&nbsp;&nbsp;&nbsp;http://www.nvidia.com/object/unix.html\n\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.3) \n&nbsp;&nbsp;&nbsp;&nbsp;Ubuntu 14.04.4 LTS\n\nCaffe 2016 May 30 18:04\n&nbsp;&nbsp;&nbsp;&nbsp;http://caffe.berkeleyvision.org/install_apt.html\n\nNVIDA CUDA 7.5 Tool Kit - cuda_7.5.18_linux.run\n&nbsp;&nbsp;&nbsp;&nbsp;https://developer.nvidia.com/cuda-downloads\n\nMany thanks to @kashefy and NVIDIA for identifying a solution.\n']",[],[],1,1
13,caffe,5051,closed,NaN loss when training MNIST LeNet in CPU mode,"### Issue summary

I just installed Caffe and tried to run the MNIST Lenet example on CPU only mode (changed solved_mode to CPU). And the loss is NAN from the first display. 

> I1202 07:38:36.619820 20673 caffe.cpp:251] Starting Optimization
> I1202 07:38:36.619825 20673 solver.cpp:279] Solving LeNet
> I1202 07:38:36.619829 20673 solver.cpp:280] Learning Rate Policy: inv
> I1202 07:38:36.620288 20673 solver.cpp:337] Iteration 0, Testing net (#0)
> I1202 07:38:40.081092 20673 solver.cpp:404]     Test net output #0: accuracy = 0.1034
> I1202 07:38:40.081132 20673 solver.cpp:404]     Test net output #1: loss = 71.5575 (* 1 = 71.5575 loss)
> I1202 07:38:40.133375 20673 solver.cpp:228] Iteration 0, loss = 68.1442
> I1202 07:38:40.133416 20673 solver.cpp:244]     Train net output #0: loss = 68.1442 (* 1 = 68.1442 loss)
> I1202 07:38:40.133440 20673 sgd_solver.cpp:106] Iteration 0, lr = 0.01
> I1202 07:38:45.040522 20673 solver.cpp:228] Iteration 100, loss = -nan
> I1202 07:38:45.040565 20673 solver.cpp:244]     Train net output #0: loss = -nan (* 1 = -nan loss)
> I1202 07:38:45.040580 20673 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
> I1202 07:38:49.861625 20673 solver.cpp:228] Iteration 200, loss = -nan
> I1202 07:38:49.861666 20673 solver.cpp:244]     Train net output #0: loss = -nan (* 1 = -nan loss)
> I1202 07:38:49.861677 20673 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258

If I change it back to GPU mode, it does not happen.

What can I do to train it in CPU mode ? 
Is there a stable release of Caffe that I should try ? 

Thanks

### Steps to reproduce

(HEAD 24d2f67173db3344141dce24b1008efffbfe1c7d)

git clone https://github.com/BVLC/caffe caffe
cd caffe
make all
./data/mnist/get_mnist.sh
./examples/mnist/create_mnist.sh
./examples/mnist/train_lenet.sh

### Your system configuration
Operating system: Gentoo
Compiler: G++ 4.9.3
CUDA version (if applicable): 7.5.18
BLAS: MKL",,['Closing as unusual and likely the result of a faulty BLAS. CPU-mode Caffe has solver tests and I have solved this example with CPU mode by OpenBLAS and MKL in the past.'],[],[],1,0
14,caffe,2624,closed,20% testing accuracy difference CPU and GPU in CIFAR10 dataset,"## CPU and GPU traning should have given the same result, but no!

I am training Cifar10 example with my own architecture shown below. I think it is suppose to be that CPU or GPU would give roughly the same accuracy and loss values.
With all other parameters being the same except CPU or GPU, my two experiment has much different test accuracy. 

GPU: 
I0619 12:18:22.621153 15991 solver.cpp:269] Iteration 5000, Testing net (#0)
I0619 12:18:22.898356 15991 solver.cpp:318]     Test net output #0: accuracy = 0.5712
I0619 12:18:22.898421 15991 solver.cpp:318]     Test net output #1: loss = 1.35011 (\* 1 = 1.35011 loss)

CPU:
I0619 12:28:27.662317 15616 solver.cpp:269] Iteration 5000, Testing net (#0)
I0619 12:28:31.197854 15616 solver.cpp:318]     Test net output #0: accuracy = 0.3764
I0619 12:28:31.197901 15616 solver.cpp:318]     Test net output #1: loss = 1.78204 (\* 1 = 1.78204 loss)
## Here is my solver.prototxt

net: ""examples/cifar10/cifar10_cs231n_train_test.prototxt""
test_iter: 100
test_interval: 500
base_lr: 0.0001
momentum: 0.9
weight_decay: 0.001
lr_policy: ""fixed""
display: 100
max_iter: 5000
snapshot: 500
snapshot_prefix: ""examples/cifar10/cifar10_cs231n""
solver_mode: GPU

---
## Here is my train_test.prototxt

name: ""CIFAR10_cs231n""
layers {
  name: ""cifar""
  type: DATA
  top: ""data""
  top: ""label""
  data_param {
    source: ""examples/cifar10/cifar10_train_lmdb""
    batch_size: 100
    backend: LMDB
  }
  transform_param {
    mean_file: ""examples/cifar10/mean.binaryproto""
  }
  include: { phase: TRAIN }
}
layers {
  name: ""cifar""
  type: DATA
  top: ""data""
  top: ""label""
  data_param {
    source: ""examples/cifar10/cifar10_test_lmdb""
    batch_size: 100
    backend: LMDB
  }
  transform_param {
    mean_file: ""examples/cifar10/mean.binaryproto""
  }
  include: { phase: TEST }
}
layers {
  name: ""conv1""
  type: CONVOLUTION
  bottom: ""data""
  top: ""conv1""
  blobs_lr: 1
  blobs_lr: 2
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: ""constant""
      value: 0.001
    }
    bias_filler {
      type: ""constant""
      value: 0.001
    }
  }
}
layers {
  name: ""relu1""
  type: RELU
  bottom: ""conv1""
  top: ""relu1""
}
layers {
  name: ""pool1""
  type: POOLING
  bottom: ""relu1""
  top: ""pool1""
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  name: ""ip1""
  type: INNER_PRODUCT
  bottom: ""pool1""
  top: ""ip1""
  blobs_lr: 1
  blobs_lr: 2
  inner_product_param {
    num_output: 10
    weight_filler {
      type: ""constant""
      value: 0.001
    }
    bias_filler {
      type: ""constant""
      value: 0.001
    }
  }
}
layers {
  name: ""accuracy""
  type: ACCURACY
  bottom: ""ip1""
  bottom: ""label""
  top: ""accuracy""
  include: { phase: TEST }
}
layers {
  name: ""loss""
  type: SOFTMAX_LOSS
  bottom: ""ip1""
  bottom: ""label""
  top: ""loss""
## }
",,"[""## Answer: Setting weight to constant values may not be read by GPU version\n\nIt seems that the problem is about setting weights and bias to constant value is not read by GPU version.\n\nAfter setting the weight to Gaussian with std 0.001, things solve. GPU and CPU now looks like previous GPU version's accuracy. Here it is.\n\nGPU:\nI0619 14:12:49.797749  2624 solver.cpp:251] Iteration 5000, loss = 0.853291\nI0619 14:12:49.797785  2624 solver.cpp:269] Iteration 5000, Testing net (#0)\nI0619 14:12:50.061450  2624 solver.cpp:318]     Test net output #0: accuracy = 0.5832\nI0619 14:12:50.061511  2624 solver.cpp:318]     Test net output #1: loss = 1.3164 (\\* 1 = 1.3164 loss)\nCPU:\nI0619 14:27:02.443125  8895 solver.cpp:251] Iteration 5000, loss = 0.855041\nI0619 14:27:02.443400  8895 solver.cpp:269] Iteration 5000, Testing net (#0)\nI0619 14:27:07.659747  8895 solver.cpp:318]     Test net output #0: accuracy = 0.5731\nI0619 14:27:07.659881  8895 solver.cpp:318]     Test net output #1: loss = 1.3771 (\\* 1 = 1.3771 loss)\n"", 'This tracker is basically used for reporting bugs and issues with caffe. To ask questions about implementations, please refer to the mail list: https://groups.google.com/forum/#!forum/caffe-users\n']",[],[],1,0
15,caffe,4416,closed,Loss stuck at 0,"Hello. New caffe-user here. 

I have been having this particularly annoying bug that I can't seem to solve.

I have a CNN that takes two images (one of them is the GT). When I start the training, the loss starts at 0 and stays there. 

I tried to play on the parameters of the solver to no avil. I also tried to change the parameters. 

The model is defined here: http://pastebin.com/t9Q7i0iZ 

An image of the model: http://imgur.com/RBBlvfb

The solver: http://pastebin.com/sUjg8mpe

And the command I used was:



And lastly the log: http://pastebin.com/B5DhJYVg

NOTE: I have been having this problem for a week and I did ask this question on stackoverflow, and on the google group (twice). I hope it is okay to ask it here.
",,"[""In general, I suggest visualizing the output (write a layer to print it out, or use the Python layer to inspect the results).  Chances are, your data and/or labels are bad somehow.  Sorry if you didn't get a response on the mailing list, but that doesn't change the fact that this isn't the right place to discuss modeling difficulties.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n""]",['\ncaffe train -solver solver.prototxt\n'],[],1,0
16,caffe,3907,closed,Caffe windows is slow.,"I built caffe windows successfully.
However, this is so slow compared with happynear's caffe-windows.
I did nothing with default props file except cudaArchitecture, means compiled with GPU enable and useCudnn.
My GPU is gtx 750 and it's cc is 50, so i changed cudaArchitecture like below <CudaArchitecture>compute_35,sm_35;compute_50,sm_50</CudaArchitecture>
I embedded cudnnv4. what's wrong?
Thanks in advance.
",windows,"[""What is slow, compile time or runtime?\n\nIn my experience Caffe on Windows and Linux has roughly the same performance on same hardware, so I don't see much room for improvement.\n"", ""I mean runtime, compile time does not matter.\nI was using the caffe-windows of happynear here https://github.com/happynear/caffe-windows.\nHe informed about this repo which is official, so i tried to train with this. but its' running time is slower in the same environment with happynear's caffe.\nI never tried to train in linux, so i can't compare this with linux version.\n"", ""I tried to find out the difference between two repos.\nhappynear also used cudnnv4, but it's different a bit with my cudnnv4 even though they are the same version.\nThis would be the factor to make difference speed?\nif you have time, would you check the speed difference between two repos and the reason?\nThanks in advance.\n"", 'Can you repro this perf regression on any standard/example training?\n', 'I think it does not related with specific example, thus you can repro with any example. like mnist\n', ""OK when I get time I'll try to compare two repos in respect to perf on mnist example, but there shouldn't be big difference.\n\nOn your side maybe you can try to use exactly the same cuDNN\n"", 'ok, i will let you know after i tested with same cuDNN.\nwhen you finish comparing, please let me know.\nThank you.\n', 'I compared two repos using the same cuDNN, so they are measured to same runtime.\nBut i have another problem, i made a dll using example/cpp_classification.\nI am using this dll in console program, but this dll gives an infinitive logs on exit in syncedmem.hpp like below.\ncheck failed: error = cudaSuccess(11 vs 0) invalid argument ... syncedmem.hpp\nI knew this is known side effect while googling.\nHow can i fix this problem? you can reproduce this error easily making a dll and using it in console main program.\nThanks.\n']",[],[],1,0
17,caffe,4038,closed,Low accuracy (11%) on mnist with gpu,"Hi everyone, I am new to caffe and I have already compiled the [Microsoft windows version](https://github.com/Microsoft/caffe) with VS2013 community, Matlab 2015a, CUDA 7.5 and cuDNN v4. My PC is Win10 with GTX 765M. The compilation is successful without error.

The problem is that when I try to run the mnist example, I can get reasonable accuracy with CPU training (0.97 accuracy after 500 iterations). However, when I turn to GPU mode, it only gives 0.11 accuracy even after 10000 iterations. This is the same whether I use bat and run caffe.exe or run the corresponding matlab wrapper.

In both Cpu and Gpu mode, the solver and network structure is just the lenet in /example/mnist/. The log file for gpu training is attched.

[log_gpu.txt](https://github.com/BVLC/caffe/files/233292/log_gpu.txt)

If anyone has encountered similar problem, please help me out. Thank you!
",windows,"[""I'm closing this since your issue is with Microsoft/caffe and not BVLC/caffe (this repository).\n""]",[],[],1,0
18,caffe,2895,closed,Incorrect gradient from a SoftmaxWithLossLayer with loss_weight 0,"I was debugging a network with two loss layers and wanted to disable one of them (a SoftmaxWithLossLayer), as such I set the loss_weight to 0. However, this does not do what I expected at all. The clearest way to explain this is probably using an example on how to reproduce it.

To reproduce one can take the examples/mnist/lenet_train_test.prototxt and add a second loss layer, with weight 0:



and then run this python script:



The diff for the split belonging to the SoftmaxWithLoss with loss_weight 0 will contain 64 (batchsize) values equal to the loss (NOT the gradient) for that input, and all the other elements will be 0. The other split will correctly contain all the diff values (64*10) for the loss with weight 1.

However, these two splits still get combined, creating the diff for 'ip2' for which the first 64 values are not comparable to the last 576. Am I wrong in how I tried to use the loss_weight or is this a bug? (It doesn't seem to be specific to SoftmaxWithLoss, though its most clear for this layer).
",JD bug,"[""This looks like a bug to me... try setting `force_backward: true` in your prototxt or setting the loss weight to a small nonzero value and see if the behavior changes. Here's what I think is happening: `SoftmaxWithLossLayer` uses its `diff` memory for temporary storage in forward, since backward will simply overwrite it with correct values (in this case, zeros). However, `Net` prunes the backward computation of this branch since the loss weight is set to zero, so the correct `diff` values never get set.\n\nThe easy solution (as the cost of some memory) is to outlaw writing to `diff` in forward.\n"", ""Any non-zero loss weight seems to work fine. Additionally, HingeLoss also uses its diff in the forward pass. I'd be happy with that solution, as it seems several other layers already use a `diff_` blob in their forward pass to store calculations for the backward pass.\n"", 'Another possible solution: if a backward step is skipped, and `diff` is allocated (this is important to check), then `diff` is set to 0.\n', 'Just got hit by this bug unfortunately. I think an intermediate situation would be to add a CHECK failure when the loss_weight is 0 for this layer. Otherwise, people will get incorrect results, and be optimizing a different objective than they write in a paper (!).\n', 'This bug also occurs when using python loss layers. In my case the presence of the second loss layer, with loss_weight: 0, causes the first few diff values of the first loss layer, with loss_weight: 1, to be overwritten, resulting in failed training. \n', ""Trapped by this bug, too. I've made a PR #3868 based on Sean's solution.\n""]","['\nlayer {\n name: ""bad_loss""\n type: ""SoftmaxWithLoss""\n bottom: ""ip2""\n bottom: ""label""\n top: ""bad_loss""\n loss_weight: 0\n}\n', "" python\ncaffe_root = '/roaming/nanne/caffe/' # Update this path to the correct path \nimport sys\nsys.path.insert(0, caffe_root + 'python')\nimport os\nos.chdir(caffe_root)\nimport caffe\nimport numpy as np\n\ncaffe.set_mode_gpu()\nsolver = caffe.SGDSolver(caffe_root + 'examples/mnist/lenet_solver.prototxt')\n\nsolver.step(1)\n\nprint solver.net.blobs['ip2_ip2_0_split_0'].diff.squeeze()[5:7, :]\nprint solver.net.blobs['ip2_ip2_0_split_1'].diff.squeeze()[5:7, :]\n\nprint solver.net.blobs['ip2'].diff.squeeze()[5:7, :]\n""]",[],1,1
19,caffe,2515,closed,Matcaffe: output score value is not between [0 and 1],"I recently started to use matcaffe and it seems the output value is not between [0 and 1] as the python caffe (after softmax). The output score of matcaffe could be minus or larger than one. 

I just used the default googlenet. 

Anyone experience the same issue?
",,"[""This should not have happened, even with the current matlab wrapper (which doesn't support ND-array #1970 ). There could be some bug. Could you paste here your code to reproduce this problem?\n"", ""Here is the matlab code (the input is three images (channels) per object, each image is a grayscale image)\n\nfunction [] = caffe_classify(inputFolder)\n\n```\n%% model\nuse_gpu = 1;\n\nmodel_folder = '/home/lh/Downloads/20150522-googlenet-single-70';\nmodel_file=[model_folder filesep 'snapshot_iter_163030.caffemodel'];\n\ndisp(model_folder);\nmodel_def_file=[model_folder filesep 'deploy.prototxt'];\nmatcaffe_init(use_gpu,model_def_file, model_file);\n% read image mean\nmodelmean=caffe('read_mean',[model_folder filesep 'mean.binaryproto']);\n% read labels\ntrainType = importdata([model_folder filesep 'labels.txt']);\n\n%% data\ninputFolder = '/media/test/data_single';\nflist = dir(inputFolder);\n\nch = 3;\nndef = 1;\npredict = [];\n\nfor i=3:numel(flist)\n    imgfile = dir([inputFolder filesep flist(i).name filesep '*.png']);\n    tic;\n    for j=1:numel(imgfile)\n        % prepare oversampled input\n        % input_data is Height x Width x Channel \n        for k=1:ch\n            im(:,:,k) = imread([inputFolder filesep flist(i).name filesep imgfile(j+k-1).name]);\n            imgs(:,:,k,1) = prepare_image(im(:,:,k),256,224,modelmean,1);\n        end\n        % do forward pass to get scores\n        scores = [];\n        for k=1:size(imgs,3)\n            s = caffe('forward',{imgs(:,:,k,1)});\n            scores(:,:,k) = s{1};    \n        end\n        scores = squeeze(scores);\n        sepScore{ndef} = scores;\n        score(i,:) = mean(scores,2)';\n        [~,maxlabel] = max(score(i,:));\n        predict(i)=trainType(maxlabel);\n\n        ndef = ndef + 1;\n    end % end loop image\nend % end \n```\n\nend\n\n% ------------------------------------------------------------------------\nfunction images = prepare_image(img,IMAGE_DIM,CROPPED_DIM,IMAGE_MEAN,nimg)\n    % ------------------------------------------------------------------------\n\n```\n% resize to fixed input size\n% transpose\nfor i=1:size(img,3)\n    im(:,:,i) = img(:,:,i)';\nend\nim = single(im);\nim = imresize(im, [IMAGE_DIM IMAGE_DIM], 'bilinear');\n% permute from RGB to BGR (IMAGE_MEAN is already BGR)\n\nim = im - IMAGE_MEAN;\n\nimages = zeros(CROPPED_DIM, CROPPED_DIM, 1, nimg, 'single');\nindices = [0 IMAGE_DIM-CROPPED_DIM] + 1;\nif nimg == 1\n    % center crop\n    border = fix((IMAGE_DIM-CROPPED_DIM )/2);\n    images = im(border:border+CROPPED_DIM-1, border:border+CROPPED_DIM-1, :);\n    return;\nend\n```\n\nend\n"", ""I suspect this is more likely to be an usage issue than a bug in Matcaffe. Your network is probably output something other than 'prob' produced by a Softmax layer, or having multiple output blobs and the first one is not 'prob'.\n\nYou should use BVLC's GoogLeNet model in `./models/bvlc_googlenet/deploy.prototxt` and `./models/bvlc_googlenet/bvlc_googlenet.caffemodel`. You can download it from Caffe's model zoo by running `python ./scripts/download_model_binary.py ./models/bvlc_googlenet/`, and see if you see run into this problem again.\n\nDuring initialization, you should see something like \n\n```\n...\nI0527 12:59:11.914986  6326 net.cpp:194] conv1/7x7_s2 does not need backward computation.\nI0527 12:59:11.915010  6326 net.cpp:235] This network produces output prob\nI0527 12:59:11.915289  6326 net.cpp:482] Collecting Learning Rate and Weight Decay.\n...\n```\n\noutputted to command line stderr to be sure the network is actually having one output blob 'prob'.\n\nI tried several times the following code.\n\n```\naddpath ./matlab/caffe\n\nmodel = './models/bvlc_googlenet/deploy.prototxt';\nweights = './models/bvlc_googlenet/bvlc_googlenet.caffemodel';\ncaffe('set_mode_gpu');\ncaffe('init', model, weights, 'test');\n\ndata = rand([224 224 3 10], 'single');\nres = caffe('forward', {data});\nprob = res{1};\n\nfprintf('prob min: %f, prob max: %f\\n', min(prob(:)), max(prob(:)));\n```\n\nand it always gives me prob between 0 and 1. I believe this is not a Matcaffe issue, but a usage issue. Usage issues should be asked at https://groups.google.com/forum/#!forum/caffe-users\n"", 'I found the issue. The network output loss1, loss2 and prob.\nInstead of using s{1}, the s{3} is the probability. \nThanks so much for fast response. \n\n![image](https://cloud.githubusercontent.com/assets/7299296/7829340/9f163094-03f5-11e5-8694-b6c53d45fe80.png)\n']",[],[],1,0
20,caffe,5845,closed,Prediction results different from DIGITS,"Hello everyone.
I've trained CNN to classify 7 type of classes. But during tests I noticed that for some images classification results via DIGITS GUI and via python interface are different. Can anyone please help me how can i get exact same results which produce by DIGITS.? Which is the best code to load DIGITS trained model and classify image.",,"['Most common source of discrepancies between Caffe predictions and those of DIGITS are due to preprocessing. I suggest you read DIGITS [inference code](https://github.com/NVIDIA/DIGITS/blob/master/digits/model/tasks/caffe_train.py#L1255) to see what happens there so you can reproduce its performance.\r\n\r\nPlease post usage, installation, or modeling questions, or other requests for help to the [caffe-users list][1] instead of Issues. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe. Please read the [guidelines for contributing][2] before submitting an issue or a pull request.\r\n\r\n [1]: https://groups.google.com/forum/#!forum/caffe-users\r\n [2]: https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md']",[],[],1,0
21,caffe,4950,closed,"Zero accuracy, loss not decreasing and layers have the same value for different inputs","### Issue summary
*Tried to ask this on googlegroup, didn't get a response that I had to post it here!*
I have a 50x50 image generated from a 1x2500 vector and I then generated HDF5 file from the images and feed it to caffeNet. My labels range from 0 to 255, so I am expecting 256 different classes. Below is my network prototxt and my solver. 
layer {
name: ""data""
type: ""HDF5Data""
top: ""X""
top: ""y""
hdf5_data_param{
source:""/Path/to/trainh5list.txt""
batch_size: 1
}
include{phase: TRAIN}
}
layer {
name: ""data""
type: ""HDF5Data""
top: ""X""
top: ""y""
hdf5_data_param{
source:""/Path/to/testh5list.txt""
batch_size: 1
}
include{phase: TEST}
}
....

layer {
name: ""accuracy""
type: ""Accuracy""
bottom: ""fc8""
bottom: ""y""
top: ""accuracy""
include {
phase: TEST
}
}
layer {
name: ""loss""
type: ""SoftmaxWithLoss""
bottom: ""fc8""
bottom: ""y""
top: ""loss""
}

Solver: 
net: ""/path/to/train_ntk.prototxt""
test_iter: 20
test_interval: 1000
base_lr: 0.001
lr_policy: ""step""
gamma: 0.1
stepsize: 10000
display: 1000
max_iter: 80000
momentum: 0.9
weight_decay: 0.0005
snapshot: 40000
snapshot_prefix: ""/path/to/model_""
solver_mode: GPU
#debug_info: true

While training in debug mode, 1. The accuracy layer has zero output all the time. 2. The fully connected layers seems to have the same result for all the inputs. 3. The loss doesn't decrease as the training goes on, it swings in some random value. I tried different batch size and learning rate, I don't seem to get it fixed. I also tried changing the data layer to ImageData layer, it didn't solve the issue. What can I do different to fix this issue?

Here is the training log: 
I1103 12:01:41.822055 108615 solver.cpp:337] Iteration 0, Testing net (#0)
I1103 12:01:41.849742 108615 solver.cpp:404]     Test net output #0: accuracy = 0
I1103 12:01:41.849761 108615 solver.cpp:404]     Test net output #1: loss = 6.02617 (* 1 = 6.02617 loss)
I1103 12:01:41.869380 108615 solver.cpp:228] Iteration 0, loss = 6.05644
I1103 12:01:41.869398 108615 solver.cpp:244]     Train net output #0: loss = 6.05644 (* 1 = 6.05644 loss)
I1103 12:01:41.869413 108615 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I1103 12:01:47.624855 108615 solver.cpp:228] Iteration 500, loss = 87.3365
I1103 12:01:47.624876 108615 solver.cpp:244]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
I1103 12:01:47.624882 108615 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I1103 12:01:53.290213 108615 solver.cpp:337] Iteration 1000, Testing net (#0)
I1103 12:01:53.299310 108615 solver.cpp:404]     Test net output #0: accuracy = 0
I1103 12:01:53.299327 108615 solver.cpp:404]     Test net output #1: loss = 87.3365 (* 1 = 87.3365 loss)
I1103 12:01:53.314584 108615 solver.cpp:228] Iteration 1000, loss = 87.3365
I1103 12:01:53.314615 108615 solver.cpp:244]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
I1103 12:01:53.314621 108615 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I1103 12:01:58.991268 108615 solver.cpp:228] Iteration 1500, loss = 87.3365
I1103 12:01:58.991315 108615 solver.cpp:244]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
I1103 12:01:58.991322 108615 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I1103 12:02:04.664419 108615 solver.cpp:337] Iteration 2000, Testing net (#0)
I1103 12:02:04.673518 108615 solver.cpp:404]     Test net output #0: accuracy = 0
I1103 12:02:04.673537 108615 solver.cpp:404]     Test net output #1: loss = 87.3365 (* 1 = 87.3365 loss)
I1103 12:02:04.690434 108615 solver.cpp:228] Iteration 2000, loss = 87.3365
I1103 12:02:04.690469 108615 solver.cpp:244]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
I1103 12:02:04.690481 108615 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I1103 12:02:10.373788 108615 solver.cpp:228] Iteration 2500, loss = 87.3365
I1103 12:02:10.373852 108615 solver.cpp:244]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
I1103 12:02:10.373859 108615 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I1103 12:02:16.047372 108615 solver.cpp:337] Iteration 3000, Testing net (#0)
I1103 12:02:16.056390 108615 solver.cpp:404]     Test net output #0: accuracy = 0
I1103 12:02:16.056407 108615 solver.cpp:404]     Test net output #1: loss = 87.3365 (* 1 = 87.3365 loss)
I1103 12:02:16.070235 108615 solver.cpp:228] Iteration 3000, loss = 87.3365
I1103 12:02:16.070261 108615 solver.cpp:244]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
I1103 12:02:16.070267 108615 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I1103 12:02:21.755348 108615 solver.cpp:228] Iteration 3500, loss = 87.3365
I1103 12:02:21.755369 108615 solver.cpp:244]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
 I1103 12:02:21.755375 108615 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
",,"['i get the same loss and accuracy values from training lenet with hdf5 data.\r\ni tried with 60 batch size and 0.001 and 0.0005 learning rate and nothing changed. did you fix the problem? ', 'Please ask your question on the [Caffe user mailing list](https://groups.google.com/forum/#!forum/caffe-users) or on another website, such as http://stackoverflow.com/.\r\n\r\n> Please use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) for usage, installation, or modeling questions, or other requests for help.\r\n> _Do not post such requests to Issues._ Doing so interferes with the development of Caffe.']",[],[],1,0
22,caffe,5212,closed,training loss always 6.9 when using my calculated mean file in ILSVRC12 data,"I follow all the steps of http://caffe.berkeleyvision.org/gathered/examples/imagenet.html.
the training loss is always 6.9 and accuracy is 0.001. 
I searched and found this issue https://github.com/BVLC/caffe/issues/4482
So I tried to download the hosted mean file and trained again. It's ok! I got accuracy of 58% after 450000 iteration.
it seems the problem is my calculated mean file(I tried many times with it to avoid  bad parameter initialization). What's wrong with it?  ",,"['From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\r\n\r\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\r\nUse the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.']",[],[],1,0
23,caffe,4700,closed,Loss goes to 0 for image data layer,"I am trying to run CaffeNet training based on the image_data_layer. I am seeing the following behaviour. The loss value is 7.5 in Iteration 0 and then goes to 0 immediately. Is this expected ?

I0909 20:42:33.842559 136906 solver.cpp:279] Solving CaffeNet
I0909 20:42:33.842563 136906 solver.cpp:280] Learning Rate Policy: step
I0909 20:42:34.010679 136906 solver.cpp:228] Iteration 0, loss = 7.56662
I0909 20:42:34.010716 136906 solver.cpp:244]     Train net output #0: loss = 7.56662 (\* 1 = 7.56662 loss)
I0909 20:42:34.010766 136906 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0909 20:42:34.430747 136906 solver.cpp:228] Iteration 1, loss = 0
I0909 20:42:34.430763 136906 solver.cpp:244]     Train net output #0: loss = 0 (\* 1 = 0 loss)
I0909 20:42:34.430768 136906 sgd_solver.cpp:106] Iteration 1, lr = 0.01
I0909 20:42:34.875175 136906 solver.cpp:228] Iteration 2, loss = 0
I0909 20:42:34.875191 136906 solver.cpp:244]     Train net output #0: loss = 0 (\* 1 = 0 loss)
I0909 20:42:34.875196 136906 sgd_solver.cpp:106] Iteration 2, lr = 0.01
I0909 20:42:34.875416 136906 blocking_queue.cpp:50] Data layer prefetch queue empty
I0909 20:42:35.293489 136906 solver.cpp:228] Iteration 3, loss = 0
I0909 20:42:35.293507 136906 solver.cpp:244]     Train net output #0: loss = 0 (\* 1 = 0 loss)
I0909 20:42:35.293512 136906 sgd_solver.cpp:106] Iteration 3, lr = 0.01
I0909 20:42:35.796902 136906 solver.cpp:228] Iteration 4, loss = 0
I0909 20:42:35.796919 136906 solver.cpp:244]     Train net output #0: loss = 0 (\* 1 = 0 loss)
I0909 20:42:35.796924 136906 sgd_solver.cpp:106] Iteration 4, lr = 0.01
I0909 20:42:36.378119 136906 solver.cpp:228] Iteration 5, loss = 0

The head of my prototxt file is:

name: ""CaffeNet""
layer {
  name: ""data""
  type: ""ImageData""
  top: ""data""
  top: ""label""
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: ""/users/xyz/projects/caffe/nvcaffe/caffe/data/ilsvrc12/imagenet_mean.binaryproto""
  }

  image_data_param {
    source: ""/users/xyz/projects/caffe/nvcaffe/caffe/train.txt""
    batch_size: 128
    new_height: 256
    new_width: 256
  }
}
layer {
  name: ""data""
  type: ""Data""
  top: ""data""
  top: ""label""
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: ""/users/xyz/projects/caffe/nvcaffe/caffe/data/ilsvrc12/imagenet_mean.binaryproto""
  }
  data_param {
    source: ""/lus/scratch/xyz/imagenet-on-lustre/examples/imagenet/ilsvrc12_val_lmdb""
    batch_size: 50
    backend: LMDB
  }
}
",,"['Please ask usage questions on the mailing list. (Loss of 0 is suspicious, and usually indicates some kind of data issue or overfitting.)\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],1,0
24,caffe,2783,closed,Caffe - inconsistency in the activation feature values - GPU mode,"Hi I am using **Caffe** on **Ubuntu 14.04
CUDA version 7.0 
cudnn version 2
GPU : NVIDIA GT 730**

In caffe first I get the initialization done and then I load the imagenet model (Alexnet). I also initialize the gpu using **set_mode_gpu()**
After that I take an image. Lets call the image as x.
I copy this image onto the caffe source blob. Then I perform a forward pass for this image by using : **net.forward(end='fc7')**
Then I extract the 4096 dimensional fc7 output.(the activation features of the fc7 layer)

The problem I am facing is that when I run the same code multiple times, everytime I obtain a different result. That is, in GPU mode, everytime the activation features are different for the same image. When I am using forward pass, the function of the network is supposed to be deterministic right ? So I should get the same output everytime for the same image. 
On the other hand, when I run caffe on cpu by using **set_mode_cpu()** everything works perfectly, i.e, I get the same output each time
The code used and the outputs obtained are shown below. I am not able to understand what the problem is. Is it that the problem is caused due to GPU rounding off ? But the errors are very large. Or is it due to some issues with the latest CUDNN version ? Or is it something else altogether ?

Following is the **CODE**
#1) IMPORT libraries


#2) IMPORT Caffe Models and define utility functions


#3) LOADING Image and setting constants


#4) Setting the source image and making the forward pass to obtain fc7 activation features



**FOLLOWING is the output that I obtained for 'print dst.data' when I ran the above code multiple times**
# output on 1st execution of code


# output on 2nd execution of code


# output on 3rd execution of code


# output on 4th execution of code


",,"[""I believe that you can't hold onto references the way you are right now.  Caffe copies to/from the GPU which makes old pointers to memory invalid after any calls to `forward` or `backward`.  Move the line `dst = net.blobs[end]` to after `net.forward`.\n\nAnother note: whenever grabbing results from a forward pass, make sure that you make a _copy_ of the data with `.copy()` (numpy method).  Otherwise, earlier results will become invalid/overwritten after any subsequent forward passes.\n"", 'Hi I made the changes you suggested above, but that issue still persists.\n\nI even ran the python script from ""caffe/examples/00-classification.ipynb""\nIn that when I run in gpu mode, even time the classification output is different.\nThe actual output is supposed to be :  ""Predicted class is 281.""\n\nbut in the GPU mode the output is arbitrary everytime.  Following are the outputs I get\n\n""Predicted class is 49855.""\n""Predicted class is 154.""\n""Predicted class is 594.""\n""Predicted class is 835.""\n""Predicted class is 49462.""\n\nI mean how does it give a value of 49462, I mean there are not even that many classes.\nI have installed caffe using the following blog https://github.com/tiangolo/caffe/blob/ubuntu-tutorial-b/docs/install_apt2.md\nI have installed cudnn v2. I read somewhere that it is not properly compatible with caffe. Is that the issue. Or is it something else ?\n\nFollowing is the code for ""caffe/examples/00-classification.ipynb""\n\n```\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Make sure that caffe is on the python path:\ncaffe_root = \'../\'  # this file is expected to be in {caffe_root}/examples\nimport sys\nsys.path.insert(0, caffe_root + \'python\')\n\nimport caffe\n\nplt.rcParams[\'figure.figsize\'] = (10, 10)\nplt.rcParams[\'image.interpolation\'] = \'nearest\'\nplt.rcParams[\'image.cmap\'] = \'gray\'\n\nimport os\nif not os.path.isfile(caffe_root + \'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel\'):\n    print(""Downloading pre-trained CaffeNet model..."")\n    !../scripts/download_model_binary.py ../models/bvlc_reference_caffenet\n\n\ncaffe.set_device(0)\ncaffe.set_mode_gpu()\n\nnet = caffe.Net(caffe_root + \'models/bvlc_reference_caffenet/deploy.prototxt\',\n            caffe_root + \'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel\',\n            caffe.TEST)\n\n# input preprocessing: \'data\' is the name of the input blob == net.inputs[0]\ntransformer = caffe.io.Transformer({\'data\': net.blobs[\'data\'].data.shape})\ntransformer.set_transpose(\'data\', (2,0,1))\ntransformer.set_mean(\'data\', np.load(caffe_root + \'python/caffe/imagenet/ilsvrc_2012_mean.npy\').mean(1).mean(1)) # mean pixel\ntransformer.set_raw_scale(\'data\', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\ntransformer.set_channel_swap(\'data\', (2,1,0))  # the reference model has channels in BGR order instead of RGB\n\n\nnet.blobs[\'data\'].reshape(50,3,227,227)\n\nnet.blobs[\'data\'].data[...] = transformer.preprocess(\'data\', caffe.io.load_image(caffe_root + \'examples/images/cat.jpg\'))\nout = net.forward()\nprint(""Predicted class is #{}."".format(out[\'prob\'].argmax()))\n```\n', ""Have you tried running without cuDNN?  I vaguely remember seeing somewhere that it's not always deterministic, but I could be wrong.\n"", ""The last line of your code is wrong: when you call argmax, you need to give it the correct axis (axis=1).  Otherwise, it is computing the argmax over a flattened version of the array, which is only meaningful if your batchsize is 1 -- but in your case the batchsize is 50.\n\nIf you're processing just one image, at a time (a single cat image), you should also set the batchsize to 1.  Right now you're making 50 copies of the input image and classifying all of them (since the assignment to `net.blobs['data'].data[...]` will broadcast along the first dimension).\n"", 'I tried making the changes you suggested, but it still gives the same error.\n\nWhen I run the above code in CPU mode, I always get the same output everytime. But when I run it in GPU mode, I get arbitrary values everytime. The problem seems to be related with the GPU.\n', '> I tried making the changes you suggested, but it still gives the same error.\n\nYou should at least be getting predicted class labels in the range [0, 1000) this time.\n\nAlso, does it work on the GPU without cuDNN?\n', ""Yes, the predicted classes are within [0,1000).\nAnother thing that I noticed is that many of the times when the output is wrong, the final prob layer contains many zero values. Though this doesnt happen everytime, but in lets say around 50% of the trials it contains of many zeros.\n\nI didnt quite understand what you meant by\n\n> Also, does it work on the GPU without cuDNN?\n\nDo you mean to say that I'll need to recompile caffe without using the cUDNN files, or is there a faster way to test that ?\n"", '> Do you mean to say that I\'ll need to recompile caffe without using the cUDNN files, or is there a faster way to test that ?\n\nYou could either recompile without cuDNN (disabling it in the Makefile), or you could insert ""engine: caffe"" inside the prototxt params for any layer that has a cuDNN version.  For example: https://gist.github.com/longjon/ac410cad48a088710872#file-fcn-32s-pascal-deploy-prototxt\n', 'Hi @seanbell .\nI compiled caffe with CUDNN disabled. Now I am getting the same output everytime. The error is now gone. Thanks a lot for your help and support.\nBut I have a small question. I am new to caffe and hence I have this confusion: When I am not using CUDNN, how does caffe still use GPU for its computation ? I thought it was through CUDNN that caffe used GPU. \nAnd also what are the drawbacks of using GPU without CUDNN ?\n', 'Please ask usage and system configuration questions on the mailing list. This seems to have the fault of an installation of cuDNN gone wrong.\r\n\r\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\r\n\r\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\r\nUse the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.']","['\nfrom cStringIO import StringIO\nimport numpy as np\nimport scipy.ndimage as nd\nimport PIL.Image\nfrom IPython.display import clear_output, Image, display\nfrom google.protobuf import text_format\nimport scipy\nimport matplotlib.pyplot as plt\nimport caffe\n', ""\nmodel_path = '../../../caffe/models/bvlc_alexnet/' \nnet_fn   = model_path + 'deploy.prototxt'\nparam_fn = model_path + 'bvlc_reference_caffenet.caffemodel'\n\nmodel = caffe.io.caffe_pb2.NetParameter()\ntext_format.Merge(open(net_fn).read(), model)\nmodel.force_backward = True\nopen('tmp.prototxt', 'w').write(str(model))\n\nnet = caffe.Classifier('tmp.prototxt', param_fn,\n                   mean = np.float32([104.0, 116.0, 122.0]), # ImageNet mean, training set dependent\n                   channel_swap = (2,1,0),# the reference model has channels in BGR order instead of RGB\n                  image_dims=(227, 227)) \n\ncaffe.set_mode_gpu()\n# caffe.set_mode_cpu()\n\n# a couple of utility functions for converting to and from Caffe's input image layout\ndef preprocess(net, img):\n    return np.float32(np.rollaxis(img, 2)[::-1]) - net.transformer.mean['data']\ndef deprocess(net, img):\n    return np.dstack((img + net.transformer.mean['data'])[::-1])\n"", ""\ntarget_img = PIL.Image.open('alpha.jpg')\ntarget_img = target_img.resize((227,227), PIL.Image.ANTIALIAS)\ntarget_img=np.float32(target_img)\ntarget_img=preprocess(net, target_img)\n\nend='fc7'\n"", ""\nsrc = net.blobs['data']\nsrc.reshape(1,3,227,227) # resize the network's input image size\nsrc.data[0] = target_img\ndst = net.blobs[end]\nnet.forward(end=end)\ntarget_data = dst.data[0]\nprint dst.data\n"", '\n[[-2.22313166 -1.66219997 -1.67641115 ..., -3.62765646 -2.78621101\n  -5.06158161]]\n', '\n[[ -82.72431946 -372.29296875 -160.5559845  ..., -367.49728394 -138.7151947\n  -343.32080078]]\n', '\n[[-10986.42578125 -10910.08105469 -10492.50390625 ...,  -8597.87011719\n   -5846.95898438  -7881.21923828]]\n', '\n[[-137360.3125     -130303.53125    -102538.78125    ...,  -40479.59765625\n    -5832.90869141   -1391.91259766]]\n']",[],1,0
25,caffe,2406,closed,PReLU is slow,"Did some benchmarking and found that Prelu is slower than conv layer in backpropagation

I0502 15:58:03.235862 19023 caffe.cpp:276]      conv1    forward: 23.0175 ms.
I0502 15:58:03.235872 19023 caffe.cpp:279]      conv1    backward: 26.5506 ms.
I0502 15:58:03.235882 19023 caffe.cpp:276]     prelu1    forward: 5.75406 ms.
I0502 15:58:03.235893 19023 caffe.cpp:279]     prelu1    backward: 111.537 ms.

https://groups.google.com/forum/#!topic/caffe-users/-xj7EaMrMGI

A small change in the prelu_layer.cu speeds up prelu 3-4 times

Change: CAFFE_GET_BLOCKS(count)



To: CAFFE_GET_BLOCKS(cdim)



I ran the caffe test after this and it passed.

Other than this I think the rest of the code can be optimized further because we do backpropagation 1 output at a time. Is someone working on that?
",JL enhancement,"[""Thanks for reporting the time comparisons, @mausoomsarkar! I actually never benchmarked the time. I made a PR #2414 to fix this problem. Fortunately this bug didn't hurt numerical results.\n\nYou also mentions about further optimization of PReLU backprop. The intention of the looped backward computation for each examples is to save temporary memory. It depends on which memory efficiency or speed people concern stronger. I took memory efficiency so that people who has less memory can use PReLU. If you have any better solution, creating a PR is welcome. Thanks!\n"", 'Just for reference. I made a PR #3185 to further speed-up PReLU without increasing memory footprint.\n']","[' jss\n      PReLUParamBackward<Dtype><<<CAFFE_GET_BLOCKS(count),\n          CAFFE_CUDA_NUM_THREADS>>>(\n          cdim, top_diff + top[0]->offset(n),\n          bottom_data + bottom[0]->offset(n), multiplier_.mutable_gpu_diff());\n', ' jss\n      PReLUParamBackward<Dtype><<<CAFFE_GET_BLOCKS(cdim),\n          CAFFE_CUDA_NUM_THREADS>>>(\n          cdim, top_diff + top[0]->offset(n),\n          bottom_data + bottom[0]->offset(n), multiplier_.mutable_gpu_diff());\n']",[],1,1
26,caffe,4072,closed,Fine Tunning of GoogLeNet Model,"I did the fine tunning but the results are not promising. I am only getting the accuracy of 50% after 1000 iterations. My training dataset has 3k images validation has 1k images and evaluation has 1k images. I set the base_lr to 0.001 and max_itr to 10000. Is this accuracy normal or did I do something wrong? I can also share what changes I did in the files, if needed. 
",,"['Closing since this is a usage/modeling question.  Please use the mailing list.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],1,0
27,caffe,5611,closed,Deconvolution initialisation,"Please use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) for usage, installation, or modeling questions, or other requests for help.
_Do not post such requests to Issues._ Doing so interferes with the development of Caffe.

Please read the [guidelines for contributing](https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md) before submitting this issue.

### Issue summary
Hi,
I am trying to fine tuning FCN32s network. However, I've inspected that my accuracies(overall accuracies, mean accuracies and mean IUs fluctuate in certain range and the values does not happy to increase at all).

In the paper, it described that ""Final layer deconvolutional filters are fixed to bilinear interpolation , while intermediate upsampling layers are intialised to bilinear upsampling, and then learned"", but in the train.prototxt the learning rate was set to 0 and there is only one deconvolution layer. I am a little bit confused here... 

It would be greatly appreciated if someone provide me with any insight of this issue.

Hanyi 

@shelhamer 

### Steps to reproduce

If you are having difficulty building Caffe or training a model, please ask the caffe-users mailing list. If you are reporting a build error that seems to be due to a bug in Caffe, please attach your build configuration (either Makefile.config or CMakeCache.txt) and the output of the make (or cmake) command.

### Your system configuration
Operating system:
Compiler:
CUDA version (if applicable):
CUDNN version (if applicable):
BLAS:
Python or MATLAB version (for pycaffe and matcaffe respectively):
",,[],[],[],1,0
28,caffe,6256,closed,training Googlenet from scratch got low accuracy,"Hi,
When I use models/bvlc_googlenet/train_val.prototxt and solver.prototxt to train googlenet from scratch on imagenet, I only got accuracy of 59% at top-1 and 83% at top-5 at max_iteration (10000000) . However, googlenet is claimed to achieve 68.9% and 89.04%. What accuracy did you get? Should I do some modifications to the prototxt files?
Thanks!
",,"['Please post usage, installation, or modeling questions, or other requests for help to the [caffe-users list][1] instead of Issues. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe. Please read the [guidelines for contributing][2] before submitting an issue or a pull request.\r\n\r\n [1]: https://groups.google.com/forum/#!forum/caffe-users\r\n [2]: https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md']",[],[],1,0
29,caffe,2681,closed,"convert_imageset is very slow, not normal?","Hi,

I realize it is very slow to convert data to lmdb using caffe toolkit convert_imageset. It tooks about 10 hours by converting 2 millions images with the size of 95*95. My friend's caffe is much faster (6 millions in 4 hours). He has similar computer configuration with me (CPU and hard drive). The weird thing is when I am converting, the tool does not use much memory and CPU. The only difference with my friend's is the version of caffe (I use the latest one he has a older version),and he use ATLAS and I use OpenBlas. Is there anyone know how to solve this problem?
",,"['And as more and more data being processed. The speed convert every 1000 images goes down. Is this the problem of overhead of writing disk?\n', 'Have you solved the problem? \n', 'Closing as irreproducible without further system detail.  This tool does not usually slow down during use.']",[],[],1,0
30,caffe,4730,open,Pycaffe slowing down CPU in GPU mode ,"I'm attempting use caffe and python to do real-time image classification. I'm using OpenCV to stream from my webcam in one process, and in a separate process, using caffe to perform image classification on the frames pulled from the webcam. Then I'm passing the result of the classification back to the main thread to caption the webcam stream.

The problem is that even though I have an NVIDIA GPU and am performing the caffe predictions on the GPU, the main thread gets slown down. Normally without doing any predictions, my webcam stream runs at 30 fps; however, with the predictions, my webcam stream gets at best 15 fps. 

I've verified that caffe is indeed using the GPU when performing the predictions, and that my GPU or GPU memory is not maxing out. I've also verified that my CPU cores are not getting maxed out at any point during the program. I'm wondering if I am doing something wrong or if there is no way to keep these 2 processes truly separate. Or if in fact this is a bug in caffe GPU mode. Any advice is appreciated. Here is my code for reference



I am pretty sure it is the caffe prediction slowing everything down, because when I comment out the prediction and pass dummy text back and forth between the processes, I get 30 fps again.



    def __init__(self, task_queue, result_queue):
        multiprocessing.Process.__init__(self)
        self.task_queue = task_queue
        self.result_queue = result_queue
        #other initialization stuff

    def run(self):
        caffe.set_mode_gpu()
        caffe.set_device(0)
        #Load caffe net -- code omitted
        while True:
            image = self.task_queue.get()
            #crop image -- code omitted
            #text = net.predict(image)
            text = ""dummy text""
            self.result_queue.put(text)

        return

import cv2
import caffe
import multiprocessing
import Queue 

tasks = multiprocessing.Queue()
results = multiprocessing.Queue()
consumer = Consumer(tasks,results)
consumer.start()

#Creating window and starting video capturer from camera
cv2.namedWindow(""preview"")
vc = cv2.VideoCapture(0)
#Try to get the first frame
if vc.isOpened():
    rval, frame = vc.read()
else:
    rval = False
frame_copy[:] = frame

while rval:
    if tasks.empty():
       tasks.put(frame_copy)
    else:
       text = tasks.get()
       #Add text to frame
       cv2.putText(frame,text)

    #Showing the frame with all the applied modifications
    cv2.imshow(""preview"", frame)

    #Getting next frame from camera
    rval, frame = vc.read()
    frame_copy[:] = frame
    #Getting keyboard input 
    key = cv2.waitKey(1)
    #exit on ESC
    if key == 27:
        break

`
",,"[""Wanted to bump this. Haven't figured out a solution. I've placed a 300 rep bounty on stackoverflow if anyone is interested in looking: http://stackoverflow.com/questions/39522693/python-real-time-image-classification-problems-with-neural-networks\n"", ""Aren't you directly causing a sequential dependency when doing this:\r\n```\r\n    if tasks.empty():\r\n       tasks.put(frame_copy)\r\n    else:\r\n       text = tasks.get()\r\n```\r\nthe point is, if you wait for the result, it will still be as if you wouldn't use multiprocessing at all.\r\nAlso, shouldn't it be `results.get()` instead of `tasks.get()` there?\r\nThe way to fix this is probably doing:\r\n- Main process grabs result as soon as it's available and displays it with text.\r\n- First worker process captures webcam images as fast as possible, and puts them into the queue, and pauses if the queue is too full (i.e. 100 frames ahead).\r\n- Second worker process consumes input image queue and produces the result (through Caffe) and puts everything in the result queue.\r\n\r\nCurrently you do the task of the main process and the first worker on the main process, which creates sequential dependencies on what the second worker is doing in between.\r\n\r\nThat way it wouldn't matter that the main process has to wait now and then to get the results, and the webcam grabbing process can go on as long as there are less than i.e. 100 images in the buffer queue.\r\n\r\nIt's in general a good idea to slow spinning threads/processes down a bit when a queue is currently empty or full..."", ""@naibaf7 I'm trying to ensure the prediction is as close to real-time as possible so I want to avoid overloading the queue with old data, but rather only send the child processes a frame when they are finished processing the current one (so that the next frame they process is the latest one from the camera)."", ""@pythonanonuser Then you can't get 30 FPS, because you wait sequentially on everything. You can still avoid having more than a few FPS lag by keeping all the queues short and/or reject a few queue elements if one of the processes lags behind too much (i.e. the Caffe process could skip a few images).\r\n\r\nBut to avoid pausing the webcam grabbing process while Caffe works, is to not wait on results in the same process that captures webcam images... I see how you structure the code in the hope to capture another frame while Caffe is working, but that's not a good code design."", ""@naibaf7 I don't think I explained myself well, my apologies. When I say FPS, I refer to OpenCV being able to grab camera frames and display them, which is happening in the main process. In parallel, caffe is performing predictions in the child processes. What is happening is that although my camera is a 30 fps one, OpenCV cannot grab frames at that rate. It reduces to about half that. The main process has no caffe predictions, it simply grabs frames and sends them to the child process to have predictions performed. It will then display the output of the child process if it is available (communicated via the results queue)."", 'Yeah I fully understand.\r\nThis is what slows you down:\r\n""It will then display the output of the child process if it is available (communicated via the results queue).""\r\nDon\'t do this as well as frame grabbing in the same process! It creates a sequential dependency on the Caffe predictions and cuts your FPS in half. Put the frame grabbing process in a separate worker!', ""@naibaf7 I will try it thank you, but just one clarification. It only displays the output if the queue has something on it (hence the `isEmpty()` check). If the caffe prediction isn't available, it just continues displaying the last caffe prediction it received. "", ""@pythonanonuser \r\nOk, yeah, just post the new code here if you need help. I can also test it on my system if you can give me the whole code. Let's see how we can get this working ;) Pretty sure it will be possible to run at full camera FPS.""]","['\n class Consumer(multiprocessing.Process):\n\n        def __init__(self, task_queue, result_queue):\n            multiprocessing.Process.__init__(self)\n            self.task_queue = task_queue\n            self.result_queue = result_queue\n            #other initialization stuff\n\n        def run(self):\n            caffe.set_mode_gpu()\n            caffe.set_device(0)\n            #Load caffe net -- code omitted \n            while True:\n                image = self.task_queue.get()\n                #crop image -- code omitted\n                text = net.predict(image)\n                self.result_queue.put(text)\n\n            return\n\n    import cv2\n    import caffe\n    import multiprocessing\n    import Queue \n\n    tasks = multiprocessing.Queue()\n    results = multiprocessing.Queue()\n    consumer = Consumer(tasks,results)\n    consumer.start()\n\n    #Creating window and starting video capturer from camera\n    cv2.namedWindow(""preview"")\n    vc = cv2.VideoCapture(0)\n    #Try to get the first frame\n    if vc.isOpened():\n        rval, frame = vc.read()\n    else:\n        rval = False\n    frame_copy[:] = frame\n    while rval:\n        if tasks.empty():\n           tasks.put(frame_copy)\n        else:\n           text = tasks.get()\n           #Add text to frame\n           cv2.putText(frame,text)\n\n        #Showing the frame with all the applied modifications\n        cv2.imshow(""preview"", frame)\n\n        #Getting next frame from camera\n        rval, frame = vc.read()\n        frame_copy[:] = frame\n        #Getting keyboard input \n        key = cv2.waitKey(1)\n        #exit on ESC\n        if key == 27:\n            break\n', '', '\n', '\n\nclass Consumer(multiprocessing.Process):\n\n', '\n\n']",[''],1,0
31,caffe,6780,open,getting loss of zero while training ssd 300x300 in kitti dataset,"Issue Summary 
![caffe_issue image](https://user-images.githubusercontent.com/34826390/58903355-dc5b5680-86ca-11e9-8651-ae10cb77e1c4.PNG)

I am not able to train ssd 300x300 in kitti dataset. The detection eval is zero while training.

",,[],[],[],1,0
32,caffe,3965,open,Caffe hang when creating data layer,"I created a simplest net to learn the division ""/"" function (input is A and B, label is A/B). However, when I try to run the trainer, it hang forever. If I do , I see that it's waiting for . Searched around and it was mentioned (didn't note down the source) that it might be caused by the training and testing phase sharing the same lmdb. So I copied the same data to separate training and testing folders, but the problem persists.

**Wondering why the hang, and how I should debug this problem?**

Here is the console output:



Here is my :



Here is my :



Here is how I generated the training and label data:


",,"['Problem appeared to be solved by adding ""batch_size: 1"" to both training and testing data.\n\nBut still not sure why adding this will prevent the hang. Any insight from you guys will be helpful!\n', ""`batch_size` should always be specified.  I'm not sure what it means to have a net without a batchsize specified.\n\nThat being said, a better user interface would be to have caffe raise an error instead of hang.  Feel free to PR this change.\n"", '@seanbell Sorry being a first timer on github: ""PR""?\n', 'It means to create a Pull Request.\n\nSome docs:\nhttps://help.github.com/articles/using-pull-requests/\nhttps://help.github.com/articles/creating-a-pull-request/\n', 'Can caffe report the reason e.g. `missing batch_size` in case of missing parameters required by caffe.proto? @seanbell \n']","['\n[tw-mbp-rshi playgit]$ caffe train --solver solver.prototxt\nI0408 21:57:11.489527 1949106944 caffe.cpp:178] Use CPU.\nI0408 21:57:11.493430 1949106944 solver.cpp:48] Initializing solver from parameters:\ntest_iter: 1\ntest_interval: 2\nbase_lr: 0.01\ndisplay: 1\nmax_iter: 100\nlr_policy: ""inv""\ngamma: 0.0001\npower: 0.75\nmomentum: 0.9\nweight_decay: 0.0005\nsnapshot: 5\nsnapshot_prefix: ""snapshot""\nsolver_mode: CPU\nnet: ""net.prototxt""\nI0408 21:57:11.494869 1949106944 solver.cpp:91] Creating training net from net file: net.prototxt\nI0408 21:57:11.495998 1949106944 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer testing\nI0408 21:57:11.496026 1949106944 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer testing_label\nI0408 21:57:11.496052 1949106944 net.cpp:49] Initializing net from parameters:\nstate {\n  phase: TRAIN\n}\nlayer {\n  name: ""training""\n  type: ""Data""\n  top: ""data""\n  include {\n    phase: TRAIN\n  }\n  data_param {\n    source: ""training""\n    backend: LMDB\n  }\n}\nlayer {\n  name: ""training_label""\n  type: ""Data""\n  top: ""label""\n  include {\n    phase: TRAIN\n  }\n  data_param {\n    source: ""training_label""\n    batch_size: 1\n    backend: LMDB\n  }\n}\nlayer {\n  name: ""full""\n  type: ""InnerProduct""\n  bottom: ""data""\n  top: ""full""\n  param {\n    lr_mult: 1\n    decay_mult: 1\n  }\n  param {\n    lr_mult: 2\n    decay_mult: 0\n  }\n  inner_product_param {\n    num_output: 1\n    weight_filler {\n      type: ""gaussian""\n      std: 0.01\n    }\n    bias_filler {\n      type: ""constant""\n      value: 0\n    }\n  }\n}\nlayer {\n  name: ""loss""\n  type: ""EuclideanLoss""\n  bottom: ""full""\n  bottom: ""label""\n  top: ""loss""\n}\nI0408 21:57:11.496322 1949106944 layer_factory.hpp:77] Creating layer training\nI0408 21:57:11.503118 1949106944 net.cpp:91] Creating Layer training\nI0408 21:57:11.503237 1949106944 net.cpp:399] training -> data\nI0408 21:57:11.504497 186691584 db_lmdb.cpp:38] Opened lmdb training\n*** Aborted at 1460178183 (unix time) try ""date -d @1460178183"" if you are using GNU date ***\nPC: @     0x7fff8f110136 __psynch_cvwait\n*** SIGTERM (@0x7fff8f110136) received by PID 6373 (TID 0x7fff742d0300) stack trace: ***\n    @     0x7fff89d17f1a _sigtramp\n    @     0x7fff5850c620 (unknown)\n    @        0x10784869b boost::condition_variable::wait()\n    @        0x107849687 caffe::BlockingQueue<>::peek()\n    @        0x1077b6f46 caffe::DataLayer<>::DataLayerSetUp()\n    @        0x1077a640e caffe::BasePrefetchingDataLayer<>::LayerSetUp()\n    @        0x1078148e7 caffe::Net<>::Init()\n    @        0x107813385 caffe::Net<>::Net()\n    @        0x10782f090 caffe::Solver<>::InitTrainNet()\n    @        0x10782e3e7 caffe::Solver<>::Init()\n    @        0x10782e0de caffe::Solver<>::Solver()\n    @        0x10783e8a8 caffe::SGDSolver<>::SGDSolver()\n    @        0x107844182 caffe::Creator_SGDSolver<>()\n    @        0x1076f3137 train()\n    @        0x1076f5721 main\n    @     0x7fff90c165c9 start\nTerminated: 15\n[tw-mbp-rshi playgit]$\n', '\n# The train/test net protocol buffer definition\nnet: ""net.prototxt""\n\n# test_iter specifies how many forward passes the test should carry out.\n# In the case of MNIST, we have test batch size 100 and 100 test iterations,\n# covering the full 10,000 testing images.\ntest_iter: 1\n\n# Carry out testing every 500 training iterations.\ntest_interval: 2\n\n# The base learning rate, momentum and the weight decay of the network.\nbase_lr: 0.01\nmomentum: 0.9\nweight_decay: 0.0005\n\n# The learning rate policy\nlr_policy: ""inv""\ngamma: 0.0001\npower: 0.75\n\n# Display every 100 iterations\ndisplay: 1\n\n# The maximum number of iterations\nmax_iter: 100\n\n# snapshot intermediate results\nsnapshot: 5\nsnapshot_prefix: ""snapshot""\n\n# solver mode: CPU or GPU\nsolver_mode: CPU\n', '\n\nlayer {\n  name: ""training""\n  type: ""Data""\n  top: ""data""\n  include {\n    phase: TRAIN\n  }\n  data_param {\n    source: ""training""\n    backend: LMDB\n  }\n}\n\nlayer {\n  name: ""testing""\n  type: ""Data""\n  top: ""data""\n  include {\n    phase: TEST\n  }\n  data_param {\n    source: ""testing""\n    backend: LMDB\n  }\n}\n\nlayer {\n  name: ""training_label""\n  type: ""Data""\n  top: ""label""\n  include {\n    phase: TRAIN\n  }\n  data_param {\n    source: ""training_label""\n    batch_size:1\n    backend: LMDB\n  }\n}\n\nlayer {\n  name: ""testing_label""\n  type: ""Data""\n  top: ""label""\n  include {\n    phase: TEST\n  }\n  data_param {\n    source: ""testing_label""\n    batch_size:1\n    backend: LMDB\n  }\n}\n\n\n\nlayer {\n  name: ""full""\n  type: ""InnerProduct""\n  # learning rate and decay multipliers for the weights\n  param { lr_mult: 1 decay_mult: 1 }\n  # learning rate and decay multipliers for the biases\n  param { lr_mult: 2 decay_mult: 0 }\n  inner_product_param {\n    num_output: 1\n    weight_filler {\n      type: ""gaussian""\n      std: 0.01\n    }\n    bias_filler {\n      type: ""constant""\n      value: 0\n    }\n  }\n  bottom: ""data""\n  top: ""full""\n}\n\n\n\nlayer {\n  name: ""loss""\n  type: ""EuclideanLoss""\n  bottom: ""full""\n  bottom: ""label""\n  top: ""loss""\n}\n', ""\nimport numpy as np\nimport lmdb\nimport caffe\nimport random\n\nN = 100\n\n# Let's pretend this is interesting data\nX = np.zeros((N, 2, 1, 1), dtype=np.float)\ny = np.zeros(N, dtype=np.float)\n\nrandom.seed(0)\n\nfor i in range(0, N):\n    X[i,0,0,0] = random.uniform(8, 10)\n    X[i,1,0,0] = random.uniform(6, 8)\n    y[i] = X[i,0,0,0] / X[i,1,0,0]\n\n\nwith lmdb.open('training', map_size=int(1e12)) as db:\n    with db.begin(write=True) as transaction:\n        for i in range(N):\n            datum = caffe.proto.caffe_pb2.Datum()\n            datum.channels = X.shape[1]\n            datum.height = X.shape[2]\n            datum.width = X.shape[3]\n            datum.data = X[i].tobytes()\n            str_id = '{:08}'.format(i)\n            #\n            # The encode is only essential in Python 3\n            transaction.put(str_id.encode('ascii'), datum.SerializeToString())\n\n\nwith lmdb.open('label', map_size=int(1e12)) as db:\n    with db.begin(write=True) as transaction:\n        for i in range(N):\n            datum = caffe.proto.caffe_pb2.Datum()\n            datum.channels = 1\n            datum.height = 1\n            datum.width = 1\n            datum.data = y[i].tobytes()\n            str_id = '{:08}'.format(i)\n            #\n            # The encode is only essential in Python 3\n            transaction.put(str_id.encode('ascii'), datum.SerializeToString())\n""]","['killall caffe', 'BlockingQueue', 'solver.prototxt', 'net.prototxt']",1,0
33,caffe,1856,closed,Gsoc 2015,"Are we interested in [GSOC 2015](https://www.google-melange.com/gsoc/homepage/google/gsoc2015)? Organization submission deadline is 20 Feb 2015.

/cc @shelhamer @longjon @jeffdonahue @sguada
",,"['I would be interested in doing something related to segmentation / scene parsing. Who would I talk to for this? In the unlikely case that there are no spare ideas floating around I could try to come up with a proposal, though I would need some time for that.\n', 'BVLC members need to apply the organization before 20th Feb 2015\n', ""@bhack This is a nice suggestion, and I agree wholeheartedly with the spirit of Google Summer of Code, but we cannot participate this year for lack of guaranteed mentoring time. We are beginning a pilot student mentoring program in the BVLC however, so we will keep GSoC in mind next year once we have more mentoring experience. This will furthermore make us a more capable mentoring organization by raising the number of hands on the project at Berkeley.\n\nThanks for bringing this up. I encourage students interested in open-source to try GSoC! (Even if Caffe can't take part this time.)\n"", 'Is caffe taking part in GSoC 2016?\n', '@bhack @Aravind-Suresh I am also interested :+1: \n', 'When will you be making a decision? (I am truly interested in, if Caffe can take part this year!)\n']",[],[],0,0
34,caffe,1843,closed,Stochastic pooling layer: using a multinomial distribution based on activation values instead of a uniform distribution,"As I have understood it the code for a stochastic pooling layer uses random sampling to select elements. Another approach would be to sample using a multinomial distribution with probabilities derived from the activation values. (normalized appropriately of course)

Reference: http://www.matthewzeiler.com/pubs/iclr2013/iclr2013.pdf

1)Am I right in about the pooling layer using random sampling?
2) Is there an existing way to do multinomial sampling?
2) If not this would be a good addition?
",,"[""1) Yes.\n2) No, but we certainly wouldn't mind having an implementation!\n\n@longjon Thoughts?\n"", ""I may be wrong, but isn't the second loop calculating the inverse over the un-normalized cumulative distribution using a random value in [0,sum_over_region]. If so, then they are using multinomial sampling rather than simple random sampling.\n"", 'Please use the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) list for discussion of algorithms and such (unless you are PRing them, of course). Thanks!\n']",[],[],0,0
35,caffe,5156,closed,GPU Device IDs Not Honored,"### Issue summary

Specifying --gpu=2,4,5,6 does not have the intended effect.  In the latest master, the code simply calls Caffe::SetDevice(gpus[0]) when testing, where the vector gpus = {2,4,5,6} and gpus[0] = 2, so only the first GPU in the list is used.  When training, the code also calls Caffe::set_solver_count(gpus.size()) which apparently allows the solver to create one worker per GPU, but the actual GPU device IDs are not propagated to the workers.

### Steps to reproduce

Run Caffe on a machine with at least 3 GPUs, and specify --gpu=N,M where M-N > 1 (i.e. do not specify consecutive GPUs).

### Your system configuration
Operating system: Ubuntu 14.04
Compiler: GCC 4.8.4
CUDA version (if applicable): 7.0, 7.5 and 8.0 tested
CUDNN version (if applicable): 4.0.7 and 5.1 tested
BLAS: Atlas and MKL tested
Python or MATLAB version (for pycaffe and matcaffe respectively): N/A
",,"[""Caffe cannot test in parallel, it's only used for training. It keeps getting requested, so we might look at that. For now I will put a warning."", ""Good to know regarding testing, as many of my colleagues were under the impression that Caffe can now test in parallel.  However, training still suffers from the issue that I described, where the actual GPU device ID numbers are not honored during training (only the first GPU device ID and the total number of requested GPUs is known to the Caffe solver).\r\n\r\nI should add that while CUDA's cudaSetDevice is thread-safe and is designed to set the device ID on a per-thread basis, Caffe::SetDevice is static and sets a single device ID in the calling thread.  It would be much better to have a per-instance device ID, where Caffe ultimately calls cudaSetDevice if necessary for each instance of a caffe::Net object (applies to both testing to training via caffe::Solver)."", 'During training it should work. Caffe::SetDevice is thread-local, so it should actually work the same way as cudaSetDevice.', 'You are absolutely correct.  It was an initial user error further compounded by looking at the code and believing incorrectly that I found a bug.  In that case, the only issue is the missing warning to make it clear that testing does not use multiple GPUs.  Of course, support for multiple GPUs during testing is more than welcome!']",[],[],0,0
36,caffe,2233,closed,"missing O_BINARY in ReadProtoFromBinaryFile(), io.cpp","In io.cpp, ReadProtoFromBinaryFile, the line::



should be:



Should I make a pull request or is this enough?
",,"['Closing as this does not seem correct; on Linux there is no `O_BINARY` flag. If this is a Windows issue, note that Windows is not supported by `master` at this time.\n']","['\nint fd = open(filename, O_RDONLY);\n', '\nint fd = open(filename, O_RDONLY | O_BINARY);\n']",[],0,0
37,caffe,423,closed,Hardware Recommendation and Choosing CPU Cluster or GPUs,"Hi all,

I'm new in this kind of deep learning algorithms and I would like to know other hardware specs beyond a powerful GPU? Specifically a powerful machine for training big models like the imagenet challenge and many others.
minimum RAM ?
minimum number of cores ?
minimum hdd ?

Thank you for sharing this valuable piece of code and create a active community!!!
",question,"['Hardware requirements really depend on many factors - if you just want to do a hobby project, a machine with 4-8G memory and a few cores would be sufficient. Any hard disk would do, and given the current low price you probably want to buy a big disk anyway.\n\nMy imagenet model is trained with an i5 4570 CPU and 4G memory, if that helps.\n', 'Dear all,\n\nI am going to conduct some experiments based on caffe for training up to 5 million images. I have a chance to apply access permission of hardware resources from our Lab. I have two options:\n\n(1) A 1000 core compute cluster comprising 25 nodes of 40 cores and 1 TB RAM each\n(2) HP Server with 2 TB RAM and 64 cores and NVIDIA Tesla K20X\n\nI can choose one of them, can you give me some suggestions regarding this problem from perspective of computing capability as well as the amount of configuration work? If I choose the first solution, how can I distribute my training work to different nodes ?\n\nThank you in advance !\n', 'Currently Caffe is not distributed, so getting to use multiple nodes will require some non-trivial extensions.\nIt will depend if you plan to train many different models in parallel or just one. For training multiple models you could use CPUs, but not sure how slow that would be. For training just one model GPU should be faster. \n', ""Thank you for your suggestions @sguada , It's very helpful!\n""]",[],[],0,0
38,caffe,6350,closed,Error saveFilter.m in MEX,"### Issue summary

I need to run  in MATLAB but this error appear:

GLIBCXX_3.4.21'
not found (required by /home/vicom/caffe/matlab/+caffe/private/caffe_.mexa64).

Error in caffe.reset_all (line 5)
caffe_('reset');

Error in saveFilters (line 1)
caffe.reset_all();
`

### System configuration

* Operating system: Ubuntu 16.06
* MATLAB: R2016b
",,"['Please read the checklist in the [issue template](https://github.com/BVLC/caffe/blob/master/.github/ISSUE_TEMPLATE.md) and complete your issue accordingly:\r\n>read the guidelines and remove the first paragraph\r\n>write a short summary and detailed steps to reproduce\r\n>explain how solutions to related problems failed (tick if found none)\r\n>fill system configuration\r\n>attach relevant logs/config files (tick if not applicable)', 'Closing due to lack of updates. Feel free to reopen when you complete the details requested in the previous post.']",[],"['saveFilter.m', '', ""\r\nInvalid MEX-file '/home/vicom/caffe/matlab/+caffe/private/caffe_.mexa64':\r\n/home/vicom/Documentos/MATLAB_R2016b/bin/glnxa64/../../sys/os/glnxa64/libstdc++.so.6: version "", '']",0,0
39,caffe,5790,closed,LD issue compiling the latest code,"Tried compiling the latest code with 
atlas on Centos machine  x86_64 GNU/Linux

But ""make all"" failed at 
/usr/bin/ld: cannot find -lcblas
/usr/bin/ld: cannot find -latlas

Makefile.config 
BLAS_LIB = /usr/lib64/atlas

The content of /usr/lib64/atlas
total 21304
lrwxrwxrwx 1 root root       17 Jul 21 16:28 libsatlas.so -> libsatlas.so.3.10
lrwxrwxrwx 1 root root       17 Oct  8  2016 libsatlas.so.3 -> libsatlas.so.3.10
-rwxr-xr-x 1 root root 10852104 Nov 20  2015 libsatlas.so.3.10
lrwxrwxrwx 1 root root       17 Jul 21 16:28 libtatlas.so -> libtatlas.so.3.10
lrwxrwxrwx 1 root root       17 Oct  8  2016 libtatlas.so.3 -> libtatlas.so.3.10
-rwxr-xr-x 1 root root 10959464 Nov 20  2015 libtatlas.so.3.10

However, then I used openblas and it just worked fine. 

http://caffe.berkeleyvision.org/install_yum.html has no instructions on ""cblas"" but when I see Makefile I see 
 ifeq ($(LINUX), 1)
                ifeq ($(BLAS), atlas)
                        # Linux simply has cblas and atlas
                        LIBRARIES += cblas atlas

Not sure 
",,[],[],[],0,0
40,caffe,2985,closed,"Matlab crashes upon calling ""caffe.reset_all()""","Hello,

My Matlab crashes after calling ""caffe.reset_all()"". Here is a snapshot of the crash:

![screenshot from 2015-08-27 05 24 09](https://cloud.githubusercontent.com/assets/2586855/9517271/c7cbe446-4c7c-11e5-9293-daf33a3c5df6.png)

I use Ubuntu 15.04 and my version of Matlab is R2014b. This issue happens every time I call ""caffe.reset_all()"" after I load and use the net but does not happen by calling ""caffe.reset_all()"" before loading and using the net. I did not have this problem in an older version of caffe from a few months ago calling caffe('reset'). Please help!

Thanks,
Ehsan
",Matlab,"['## Here is the crash dump file from Matlab:\n\n```\n          abort() detected at Thu Aug 27 06:03:46 2015\n```\n\n---\n\nConfiguration:\n  Crash Decoding     : Disabled\n  Current Visual     : None\n  Default Encoding   : UTF-8\n  GNU C Library      : 2.21 stable\n  MATLAB Architecture: glnxa64\n  MATLAB Root        : /usr/local/MATLAB/R2014b\n  MATLAB Version     : 8.4.0.150421 (R2014b)\n  Operating System   : Linux 3.19.0-26-generic #28-Ubuntu SMP Tue Aug 11 14:16:32 UTC 2015 x86_64\n  Processor ID       : x86 Family 6 Model 60 Stepping 3, GenuineIntel\n  Software OpenGL    : 0\n  Virtual Machine    : Java 1.7.0_11-b21 with Oracle Corporation Java HotSpot(TM) 64-Bit Server VM mixed mode\n  Window System      : No active display\n\nFault Count: 1\n\nAbnormal termination:\nabort()\n\nRegister State (from fault):\n  RAX = 0000000000000000  RBX = 00007f679596c6c0\n  RCX = ffffffffffffffff  RDX = 0000000000000006\n  RSP = 00007f68c5f181d8  RBP = 00007f68c5f18310\n  RSI = 0000000000002697  RDI = 0000000000002671\n\n   R8 = 000000000000ff08   R9 = 00007f67a4014fa0\n  R10 = 0000000000000008  R11 = 0000000000000206\n  R12 = 0000000000000003  R13 = 0000000000000000\n  R14 = 00007f67761ca800  R15 = 00007f67761ca598\n\n  RIP = 00007f68da467267  EFL = 0000000000000206\n\n   CS = 0033   FS = 0000   GS = 0000\n\nStack Trace (from fault):\n[  0] 0x00007f68da467267                    /lib/x86_64-linux-gnu/libc.so.6+00217703 gsignal+00000055\n[  1] 0x00007f68da468eca                    /lib/x86_64-linux-gnu/libc.so.6+00224970 abort+00000362\n[  2] 0x00007f6795745e7b             /usr/lib/x86_64-linux-gnu/libglog.so.0+00069243 _ZN6google22InstallFailureFunctionEPFvvE+00000000\n[  3] 0x00007f6795745ea4             /usr/lib/x86_64-linux-gnu/libglog.so.0+00069284 _ZN6google10LogMessage10SendToSinkEv+00000000\n[  4] 0x00007f6795745deb             /usr/lib/x86_64-linux-gnu/libglog.so.0+00069099 _ZN6google10LogMessage9SendToLogEv+00001247\n[  5] 0x00007f67957457bf             /usr/lib/x86_64-linux-gnu/libglog.so.0+00067519 _ZN6google10LogMessage5FlushEv+00000429\n[  6] 0x00007f6795748a35             /usr/lib/x86_64-linux-gnu/libglog.so.0+00080437 _ZN6google15LogMessageFatalD1Ev+00000025\n[  7] 0x00007f6795bf3bfd  /home/ehsan/Documents/caffe/build/lib/libcaffe.so+02489341 _ZN5caffe12SyncedMemoryD1Ev+00000445\n[  8] 0x00007f6795ab49e2  /home/ehsan/Documents/caffe/build/lib/libcaffe.so+01182178 _ZN5boost6detail17sp_counted_impl_pIN5caffe12SyncedMemoryEE7disposeEv+00000018\n[  9] 0x00007f6795b67712  /home/ehsan/Documents/caffe/build/lib/libcaffe.so+01914642 _ZN5caffe21CuDNNConvolutionLayerIfED1Ev+00001298\n[ 10] 0x00007f6795b679d9  /home/ehsan/Documents/caffe/build/lib/libcaffe.so+01915353 _ZN5caffe21CuDNNConvolutionLayerIfED0Ev+00000009\n[ 11] 0x00007f6795ba8441  /home/ehsan/Documents/caffe/build/lib/libcaffe.so+02180161 _ZN5caffe3NetIfED1Ev+00001009\n[ 12] 0x00007f6795ba8619  /home/ehsan/Documents/caffe/build/lib/libcaffe.so+02180633 _ZN5caffe3NetIfED0Ev+00000009\n[ 13] 0x00007f6796036ddd /home/ehsan/Documents/caffe/matlab/+caffe/private/caffe_.mexa64+00028125\n[ 14] 0x00007f679603483a /home/ehsan/Documents/caffe/matlab/+caffe/private/caffe_.mexa64+00018490\n[ 15] 0x00007f67960353f9 /home/ehsan/Documents/caffe/matlab/+caffe/private/caffe_.mexa64+00021497 mexFunction+00000178\n[ 16] 0x00007f68d0ffdc0a     /usr/local/MATLAB/R2014b/bin/glnxa64/libmex.so+00150538 mexRunMexFile+00000090\n[ 17] 0x00007f68d0ffa5c4     /usr/local/MATLAB/R2014b/bin/glnxa64/libmex.so+00136644\n[ 18] 0x00007f68d0ffb414     /usr/local/MATLAB/R2014b/bin/glnxa64/libmex.so+00140308\n[ 19] 0x00007f68d0332329 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_dispatcher.so+00791337 _ZN8Mfh_file11dispatch_fhEiPP11mxArray_tagiS2_+00000697\n[ 20] 0x00007f68cf3e6ef4 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+05996276\n[ 21] 0x00007f68cf3e8809 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+06002697\n[ 22] 0x00007f68cf3e903c /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+06004796\n[ 23] 0x00007f68cf25d1a3 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+04383139\n[ 24] 0x00007f68cf26a86e /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+04438126\n[ 25] 0x00007f68cf26a953 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+04438355\n[ 26] 0x00007f68cf3a2284 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+05714564\n[ 27] 0x00007f68cf1c126a /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+03744362\n[ 28] 0x00007f68cf23652e /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+04224302\n[ 29] 0x00007f68d0332329 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_dispatcher.so+00791337 _ZN8Mfh_file11dispatch_fhEiPP11mxArray_tagiS2_+00000697\n[ 30] 0x00007f68cfeeaca8  /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcos.so+02448552\n[ 31] 0x00007f68cfe827e2  /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcos.so+02021346\n[ 32] 0x00007f68cfe841ce  /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcos.so+02027982\n[ 33] 0x00007f68cfe89b70  /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcos.so+02050928\n[ 34] 0x00007f68cfe8558d  /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcos.so+02033037\n[ 35] 0x00007f68cfeece06  /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcos.so+02457094\n[ 36] 0x00007f68cff6c2ab  /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcos.so+02978475\n[ 37] 0x00007f68d02dde34 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_dispatcher.so+00446004 _ZN13Mfh_MATLAB_fn11dispatch_fhEiPP11mxArray_tagiS2_+00000244\n[ 38] 0x00007f68cff6bdd1  /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcos.so+02977233\n[ 39] 0x00007f68cf20cb70 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+04053872\n[ 40] 0x00007f68cf1bce02 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+03726850\n[ 41] 0x00007f68cf1bf022 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+03735586\n[ 42] 0x00007f68cf1c4f87 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+03760007\n[ 43] 0x00007f68cf1c06ff /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+03741439\n[ 44] 0x00007f68cf1c1334 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+03744564\n[ 45] 0x00007f68cf23652e /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+04224302\n[ 46] 0x00007f68d03324af /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_dispatcher.so+00791727 _ZN8Mfh_file11dispatch_fhEiPP11mxArray_tagiS2_+00001087\n[ 47] 0x00007f68cf1f4ff5 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+03956725\n[ 48] 0x00007f68cf1b6699 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+03700377\n[ 49] 0x00007f68cf1b2a87 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+03684999\n[ 50] 0x00007f68cf1b3143 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwm_interpreter.so+03686723\n[ 51] 0x00007f68d123e9dc /usr/local/MATLAB/R2014b/bin/glnxa64/libmwbridge.so+00223708\n[ 52] 0x00007f68d123f649 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwbridge.so+00226889 _Z8mnParserv+00000729\n[ 53] 0x00007f68db64ab7f   /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcr.so+00772991 _ZN11mcrInstance30mnParser_on_interpreter_threadEv+00000031\n[ 54] 0x00007f68db62b083   /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcr.so+00643203\n[ 55] 0x00007f68db62cd69   /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcr.so+00650601 _ZN5boost6detail11task_objectIvNS_3_bi6bind_tIvPFvRKNS_8functionIFvvEEEENS2_5list1INS2_5valueIS6_EEEEEEE6do_runEv+00000025\n[ 56] 0x00007f68db62d737   /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcr.so+00653111 _ZN5boost6detail9task_baseIvE3runEv+00000071\n[ 57] 0x00007f68db62d797   /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcr.so+00653207\n[ 58] 0x00007f68db628bca   /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcr.so+00633802\n[ 59] 0x00007f68ce56da46   /usr/local/MATLAB/R2014b/bin/glnxa64/libmwuix.so+00330310\n[ 60] 0x00007f68ce555ad2   /usr/local/MATLAB/R2014b/bin/glnxa64/libmwuix.so+00232146\n[ 61] 0x00007f68dbdeb00f /usr/local/MATLAB/R2014b/bin/glnxa64/libmwservices.so+02523151\n[ 62] 0x00007f68dbdeb17c /usr/local/MATLAB/R2014b/bin/glnxa64/libmwservices.so+02523516\n[ 63] 0x00007f68dbde707f /usr/local/MATLAB/R2014b/bin/glnxa64/libmwservices.so+02506879\n[ 64] 0x00007f68dbdec4b5 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwservices.so+02528437\n[ 65] 0x00007f68dbdec8e7 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwservices.so+02529511\n[ 66] 0x00007f68dbdecfc0 /usr/local/MATLAB/R2014b/bin/glnxa64/libmwservices.so+02531264 _Z25svWS_ProcessPendingEventsiib+00000080\n[ 67] 0x00007f68db629248   /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcr.so+00635464\n[ 68] 0x00007f68db629564   /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcr.so+00636260\n[ 69] 0x00007f68db615cdd   /usr/local/MATLAB/R2014b/bin/glnxa64/libmwmcr.so+00556253\n[ 70] 0x00007f68da8036aa              /lib/x86_64-linux-gnu/libpthread.so.0+00030378\n[ 71] 0x00007f68da538eed                    /lib/x86_64-linux-gnu/libc.so.6+01076973 clone+00000109\n\nThis error was detected while a MEX-file was running. If the MEX-file\nis not an official MathWorks function, please examine its source code\nfor errors. Please consult the External Interfaces Guide for information\non debugging MEX-files.\n\nIf this problem is reproducible, please submit a Service Request via:\n    http://www.mathworks.com/support/contact_us/\n\nA technical support engineer might contact you with further information.\n\nThank you for your help.\n', 'You might find this useful:\n\nhttp://www.mathworks.com/matlabcentral/answers/212716-how-do-i-troubleshoot-a-matlab-crash-associated-with-a-custom-mex-function\n', ""To get more detailed output, run Matlab from a terminal, and see the terminal output for detailed error message. \n\nThis issue is usually caused by one of the CHECK marcos failure in Caffe's internal.\n""]",[],[],0,0
41,caffe,4394,closed,finetuning glog linking error,"I got the following error building caffe and I was not able to fix it:

[ 78%] Linking CXX executable finetune_net
CMakeFiles/finetune_net.dir/finetune_net.cpp.o: In function google::LogMessageFatal::LogMessageFatal(char const_, int)'
/global/homes/m/mwdmaas/caffe/caffe_original/caffe/tools/finetune_net.cpp:(.text+0x47): undefined reference to google::LogMessageFatal::~LogMessageFatal()'
/global/homes/m/mwdmaas/caffe/caffe_original/caffe/tools/finetune_net.cpp:(.text+0x68): undefined reference to **sti**$E':
/global/homes/m/mwdmaas/caffe/caffe_original/caffe/tools/finetune_net.cpp:(.text+0x98): undefined reference to boost::system::generic_category()'
/global/homes/m/mwdmaas/caffe/caffe_original/caffe/tools/finetune_net.cpp:(.text+0xb0): undefined reference to finetune_net'
make[2]: *_\* [tools/finetune_net] Error 1
make[1]: **\* [tools/CMakeFiles/finetune_net.dir/all] Error 2
make: **\* [all] Error 2

I will add that the Makefile was created with:
cmake -DCPU_ONLY=ON -DBLAS=open -DUSE_LEVELDB=OFF -DUSE_OPENCV=OFF ..
",,[],[],"[""main':\n/global/homes/m/mwdmaas/caffe/caffe_original/caffe/tools/finetune_net.cpp:(.text+0x3e): undefined reference to"", ""google::LogMessage::stream()'\n/global/homes/m/mwdmaas/caffe/caffe_original/caffe/tools/finetune_net.cpp:(.text+0x5f): undefined reference to"", ""google::LogMessageFatal::~LogMessageFatal()'\nCMakeFiles/finetune_net.dir/finetune_net.cpp.o: In function"", ""boost::system::generic_category()'\n/global/homes/m/mwdmaas/caffe/caffe_original/caffe/tools/finetune_net.cpp:(.text+0xa4): undefined reference to"", ""boost::system::system_category()'\n/usr/bin/ld: link errors found, deleting executable""]",0,0
42,caffe,5258,closed,Is it possible build caffe static when just build a caffe-based predict single image program?,"**issue 1** Can build caffe as static library ? If positive, how to do it, and also how to set it in test single image program using c++ and cmake?

**issue 2** If I just build a program to predicting a image using c++, should it must build GPU version caffe?
Have anyone try above explorings, wish receive some help :)",,"['There is a basic C++ example [here](https://github.com/BVLC/caffe/tree/master/examples/cpp_classification), it requires some understanding of how caffe does image pre-processing.\r\nThere is more advanced example [here](https://github.com/NVIDIA/gpu-rest-engine), as an inference server.\r\n\r\nBoth of these codes can use the GPU, but none of them use caffe as a static library.\r\nHowever, using Docker like in my second link could be used instead of trying to use a static version of caffe.\r\n', 'Thanks for your advise! I think maybe I should try build caffe on Android or iOS.']",[],[],0,0
43,caffe,1727,closed,Why MemoryDataLayer can't be used in the TEST phase of solver?,"Hello, every author who contrbute to Caffe!  First I want to say thanks very much for your work, now I had a problem about the MemoryDataLayer. I can test a model in MemoryDataLayer, but when I train a model, it failed(I want to testing a model after training), I don't know why this happen, the reason why I post my question here is that I am not sure whether we need a new PR to solve this problem.  Thanks in advance!
",,['You have opened already a thread on the mailinglist. Use that.\n'],[],[],0,0
44,caffe,3039,closed,errors in detection ipython notebook,"I tried to execute the first cell of **detection.ipynb**. It has an error. It seems to be an simple error, but I do not know how to rectify it. Hope to see a patch soon.


",,"['See https://github.com/BVLC/caffe/pull/2984 (not yet merged) -- that should fix your problem.  Blobs used to be all 4D, and now they are general ND.\n', '@seanbell Thanks, I have the same answer after debugging. Wish to check the email earlier. I will close my report.\n', '@antran89 excuse me, I am a new user of caffe, and  I had same problem like you when I run the detection.ipynb. Can you tell me How can I fix this problem? Thanks for your enthusiasm.', '@antran89  and I pull the lastst code.']","['\nLoading input...\nselective_search_rcnn({\'/home/tranlaman/BLVC-caffe/examples/images/fish-bike.jpg\'}, \'/tmp/tmpB_NrWR.mat\')\nTraceback (most recent call last):\n  File ""../python/detect.py"", line 173, in <module>\n    main(sys.argv)\n  File ""../python/detect.py"", line 144, in main\n    detections = detector.detect_selective_search(inputs)\n  File ""/home/tranlaman/BLVC-caffe/python/caffe/detector.py"", line 123, in detect_selective_search\n    return self.detect_windows(zip(image_fnames, windows_list))\n  File ""/home/tranlaman/BLVC-caffe/python/caffe/detector.py"", line 86, in detect_windows\n    predictions = out[self.outputs[0]].squeeze(axis=(2, 3))\nValueError: \'axis\' entry 2 is out of bounds [-2, 2)\n']",[],0,0
45,caffe,6402,closed,pycaffe error: 'module' object has no attribute 'Layer',"I have changed ""WITH_PYTHON_LAYER := 1"",make pycaffe, abd add python path to /etc/profile so that I can import caffe successfully. 
But when I add new python layer like this:

it occured the error as follows:

I am really confused of this, and I found no solution to solve it on the Internet. 
Could you please tell me how to deal with it? Thanks in advance!",,"[""I recommend reading Rafael Padilha's guide on [Python layer](https://gist.github.com/rafaspadilha/a67008cc3bd93bc2c1fc368c363ee363), especially the prototxt example. If you're still finding problems, please ask on [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) posting the details of your issue, especially the prototxt (as this seems to be the root of your issue).""]","['\r\nimport caffe  \r\nimport numpy as np  \r\nfrom PIL import Image  \r\nimport random\r\nclass SBDDSegDataLayer(caffe.Layer):  \r\n    def setup(self, bottom, top):   \r\n', '\r\nI0521 17:35:15.180217 10861 layer_factory.hpp:77] Creating layer data\r\nTraceback (most recent call last):\r\n  File ""/mnt/data1/caffe/python/voc_layer.py"", line 8, in <module>\r\n    class SBDDSegDataLayer(caffe.Layer):\r\nAttributeError: \'module\' object has no attribute \'Layer\'\r\n']",[],0,0
46,caffe,949,closed,How to develop a new layer?,"Hi, 
I want to create a cumtom layer, that has number of output units n^2, where n is the number of input variables. unit(i,j)=f(inp(i),inp(j)). I want the unit(i,j) produces output according to input present at position i and j only. How can i create such a layer?
",,['See https://github.com/BVLC/caffe/wiki/Development-Hints#developing-new-layers and ask any questions on the\xa0[caffe-users mailing list](https://groups.google.com/forum/#!forum/caffe-users). Thanks!\n'],[],[],0,0
47,caffe,1499,closed,Crash when try the finetune tutorial on flicker data,"I compiled the dev branch without any error message and then tried the finetuning tutorial on ""flicker style"" data following the instructions provided on the Caffe website. The images were successfully downloaded, but when I run the finetuning, it crashes with the following error message:

F1128 13:34:59.766399 27222 net.cpp:712] Check failed: target_blobs[j]->channels() == source_layer.blobs(j).channels() (1 vs. 3) 
**\* Check failure stack trace: ***
    @     0x7ffe8c713b5d  google::LogMessage::Fail()
    @     0x7ffe8c717b77  google::LogMessage::SendToLog()
    @     0x7ffe8c7159f9  google::LogMessage::Flush()
    @     0x7ffe8c715cfd  google::LogMessageFatal::~LogMessageFatal()
    @           0x50f68c  caffe::Net<>::CopyTrainedLayersFrom()
    @           0x50f90a  caffe::Net<>::CopyTrainedLayersFrom()
    @           0x425f99  train()
    @           0x425b96  main
    @       0x308ba1ed5d  (unknown)
    @           0x422f19  (unknown)
Aborted

There are also some other error messages before this crash (edited to mask out my file system structure):

E1128 13:34:55.158053 27229 io.cpp:75] Could not open or find file /xxxxx/xxxxxx/xxxx/caffe-dev/data/flickr_style/images/9296163038_3009f6b805.jpg

But this file is indeed there (I used the script to download the files):

$ ls -lh /xxxxx/xxxxxx/xxxx/caffe-dev/data/flickr_style/images/9296163038_3009f6b805.jpg
-rw-r--r-- 1 abcd efg 121K Nov 28 13:21 /xxxxx/xxxxxx/xxxx/caffe-dev/data/flickr_style/images/9296163038_3009f6b805.jpg

BTW, I did the same finetuning tutorial on the master branch with no problem.  
",,"['> Check failed: target_blobs[j]->channels() == source_layer.blobs(j).channels() (1 vs. 3) \n\nThis is weird. It seems like your OpenCV is loading a given image as grayscale / single-channel instead of 3 channel BGR (the OpenCV default).\n', ""Thank you for the reply. I figure out the issue:\n\nI have two login sessions to a computer with a Titan Z GPU under screen. Under one of the session, I performed some finetuing using the master branch with success. Under the other login session, I performed the finetuning using the dev branch AFTER the finetuning on the first session finished, and I got the error as reported in my previous post. It turns out that when I change to use the first login session to do the finetuning using dev branch, it works fine. So my guess is that there may be something wrong with releasing the GPU resources after finetuning, This bug could be in the CUDA library, my system or Caffe, which unfortunately I don't have more information. But anyway for now I can proceed using the dev branch :)  \n""]",[],[],0,0
48,caffe,5839,closed,cd,"Please use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) for usage, installation, or modeling questions, or other requests for help.
_Do not post such requests to Issues._ Doing so interferes with the development of Caffe.

Please read the [guidelines for contributing](https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md) before submitting this issue.

### Issue summary


### Steps to reproduce

If you are having difficulty building Caffe or training a model, please ask the caffe-users mailing list. If you are reporting a build error that seems to be due to a bug in Caffe, please attach your build configuration (either Makefile.config or CMakeCache.txt) and the output of the make (or cmake) command.

### Your system configuration
Operating system:
Compiler:
CUDA version (if applicable):
CUDNN version (if applicable):
BLAS:
Python or MATLAB version (for pycaffe and matcaffe respectively):
",,"['Please use the [caffe-users list][1] for usage, installation, or modeling questions, or other requests for help.\r\nYou may also post questions on [stackoverflow][3], make sure you tag them with `caffe` tag.  \r\nDo not post such requests to Issues. Doing so interferes with the development of Caffe.\r\n\r\nPlease read the [guidelines for contributing][2] before submitting this issue.\r\n\r\n [1]: https://groups.google.com/forum/#!forum/caffe-users\r\n [2]: https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md\r\n [3]: http://stackoverflow.com/questions/tagged/caffe']",[],[],0,0
49,caffe,1859,closed,how to classify generic n-dimensional samples,"I'm pretty new to Caffe and deep learning. I have to questions about this library:
- is it possible to use Caffe for classification of data that is not image (generic vectors in n-dimensional space)? Are there examples?
- is Caffe compatible with hadoop or similar?
",,['[Off-the-shelf SGD for classification](http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/hdf5_classification.ipynb)\nUse Caffe as a generic SGD optimizer to train logistic regression on non-image HDF5 data\n\nis an example from the home page.\n\nAsk usage questions on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) group.\n'],[],[],0,0
50,caffe,390,closed,Two classes output only!,"I need a network with just two output classes A and B. I have tonnes of training data of images which either have A or B and are appropriately labelled. Once I have trained such a network, I wish to pass some images to test the network. Lets say I pass an image which contains neither A nor B. I understand that since the last layer is SOFTMAX it will still classify this image as either A or B with sum of probabilities of A and B equal to 1. Which means even if image does not have A it may still have a probability > 0.5 of carrying A according to the network.

Am I correct in my understanding? If yes, what kind of last layer should I use so that I can rely on a probability threshold to be able to reject such images which contain neither A not B.
",,[],[],[],0,0
51,caffe,5384,closed,Can I know what does the following error message mean?,"F0311 02:01:35.163677  6921 benchmark.cpp:92] Check failed: error == cudaSuccess (74 vs. 0)  misaligned address
*** Check failure stack trace: ***
    @     0x7f5f4aa0a5cd  google::LogMessage::Fail()
    @     0x7f5f4aa0c433  google::LogMessage::SendToLog()
    @     0x7f5f4aa0a15b  google::LogMessage::Flush()
    @     0x7f5f4aa0ce1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f5f4b09108a  caffe::Timer::MilliSeconds()
    @     0x7f5f4b0905ea  caffe::Timer::Seconds()
    @     0x7f5f4b018aed  caffe::Solver<>::Step()
    @     0x7f5f4b0194fa  caffe::Solver<>::Solve()
    @           0x40aeb4  train()
    @           0x4075a8  main
    @     0x7f5f491a1830  __libc_start_main
    @           0x407e79  _start
    @              (nil)  (unknown)
Aborted (core dumped)
",,"['name: ""VGG_ILSVRC_16_layers""\r\nlayers {\r\n  name: ""data""\r\n  type: DATA\r\n  include {\r\n    phase: TRAIN\r\n  }\r\n transform_param {\r\n    crop_size: 227\r\n    mean_file: ""/home/yxchng/learncaffe/input/mean.binaryproto""\r\n    mirror: true\r\n }\r\n data_param {\r\n    source: ""/home/yxchng/learncaffe/input/train_lmdb""\r\n    batch_size: 8\r\n    backend: LMDB\r\n  }\r\n  top: ""data""\r\n  top: ""label""\r\n}\r\nlayers {\r\n  name: ""data""\r\n  type: DATA\r\n  include {\r\n    phase: TEST\r\n  }\r\n transform_param {\r\n    crop_size: 227\r\n    mean_file: ""/home/yxchng/learncaffe/input/mean.binaryproto""\r\n    mirror: false\r\n }\r\n data_param {\r\n    source: ""/home/yxchng/learncaffe/input/validation_lmdb""\r\n    batch_size: 8\r\n    backend: LMDB\r\n  }\r\n  top: ""data""\r\n  top: ""label""\r\n}\r\nlayers {\r\n  bottom: ""data""\r\n  top: ""conv1_1""\r\n  name: ""conv1_1""\r\n  type: CONVOLUTION\r\n  convolution_param {\r\n    num_output: 16\r\n    pad: 1\r\n    kernel_size: 3\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""conv1_1""\r\n  top: ""conv1_1""\r\n  name: ""relu1_1""\r\n  type: RELU\r\n}\r\nlayers {\r\n  bottom: ""conv1_1""\r\n  top: ""conv1_2""\r\n  name: ""conv1_2""\r\n  type: CONVOLUTION\r\n  convolution_param {\r\n    num_output: 16\r\n    pad: 1\r\n    kernel_size: 3\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""conv1_2""\r\n  top: ""conv1_2""\r\n  name: ""relu1_2""\r\n  type: RELU\r\n}\r\nlayers {\r\n  bottom: ""conv1_2""\r\n  top: ""pool1""\r\n  name: ""pool1""\r\n  type: POOLING\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 2\r\n    stride: 2\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""pool1""\r\n  top: ""conv2_1""\r\n  name: ""conv2_1""\r\n  type: CONVOLUTION\r\n  convolution_param {\r\n    num_output: 32\r\n    pad: 1\r\n    kernel_size: 3\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""conv2_1""\r\n  top: ""conv2_1""\r\n  name: ""relu2_1""\r\n  type: RELU\r\n}\r\nlayers {\r\n  bottom: ""conv2_1""\r\n  top: ""conv2_2""\r\n  name: ""conv2_2""\r\n  type: CONVOLUTION\r\n  convolution_param {\r\n    num_output: 32\r\n    pad: 1\r\n    kernel_size: 3\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""conv2_2""\r\n  top: ""conv2_2""\r\n  name: ""relu2_2""\r\n  type: RELU\r\n}\r\nlayers {\r\n  bottom: ""conv2_2""\r\n  top: ""pool2""\r\n  name: ""pool2""\r\n  type: POOLING\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 2\r\n    stride: 2\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""pool2""\r\n  top: ""conv3_1""\r\n  name: ""conv3_1""\r\n  type: CONVOLUTION\r\n  convolution_param {\r\n    num_output: 64\r\n    pad: 1\r\n    kernel_size: 3\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""conv3_1""\r\n  top: ""conv3_1""\r\n  name: ""relu3_1""\r\n  type: RELU\r\n}\r\nlayers {\r\n  bottom: ""conv3_1""\r\n  top: ""conv3_2""\r\n  name: ""conv3_2""\r\n  type: CONVOLUTION\r\n  convolution_param {\r\n    num_output: 64\r\n    pad: 1\r\n    kernel_size: 3\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""conv3_2""\r\n  top: ""conv3_2""\r\n  name: ""relu3_2""\r\n  type: RELU\r\n}\r\nlayers {\r\n  bottom: ""conv3_2""\r\n  top: ""conv3_3""\r\n  name: ""conv3_3""\r\n  type: CONVOLUTION\r\n  convolution_param {\r\n    num_output: 64\r\n    pad: 1\r\n    kernel_size: 3\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""conv3_3""\r\n  top: ""conv3_3""\r\n  name: ""relu3_3""\r\n  type: RELU\r\n}\r\nlayers {\r\n  bottom: ""conv3_3""\r\n  top: ""pool3""\r\n  name: ""pool3""\r\n  type: POOLING\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 2\r\n    stride: 2\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""pool3""\r\n  top: ""conv4_1""\r\n  name: ""conv4_1""\r\n  type: CONVOLUTION\r\n  convolution_param {\r\n    num_output: 128\r\n    pad: 1\r\n    kernel_size: 3\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""conv4_1""\r\n  top: ""conv4_1""\r\n  name: ""relu4_1""\r\n  type: RELU\r\n}\r\nlayers {\r\n  bottom: ""conv4_1""\r\n  top: ""conv4_2""\r\n  name: ""conv4_2""\r\n  type: CONVOLUTION\r\n  convolution_param {\r\n    num_output: 128\r\n    pad: 1\r\n    kernel_size: 3\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""conv4_2""\r\n  top: ""conv4_2""\r\n  name: ""relu4_2""\r\n  type: RELU\r\n}\r\nlayers {\r\n  bottom: ""conv4_2""\r\n  top: ""conv4_3""\r\n  name: ""conv4_3""\r\n  type: CONVOLUTION\r\n  convolution_param {\r\n    num_output: 128\r\n    pad: 1\r\n    kernel_size: 3\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""conv4_3""\r\n  top: ""conv4_3""\r\n  name: ""relu4_3""\r\n  type: RELU\r\n}\r\nlayers {\r\n  bottom: ""conv4_3""\r\n  top: ""pool4""\r\n  name: ""pool4""\r\n  type: POOLING\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 2\r\n    stride: 2\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""pool4""\r\n  top: ""conv5_1""\r\n  name: ""conv5_1""\r\n  type: CONVOLUTION\r\n  convolution_param {\r\n    num_output: 128\r\n    pad: 1\r\n    kernel_size: 3\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""conv5_1""\r\n  top: ""conv5_1""\r\n  name: ""relu5_1""\r\n  type: RELU\r\n}\r\nlayers {\r\n  bottom: ""conv5_1""\r\n  top: ""conv5_2""\r\n  name: ""conv5_2""\r\n  type: CONVOLUTION\r\n  convolution_param {\r\n    num_output: 128\r\n    pad: 1\r\n    kernel_size: 3\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""conv5_2""\r\n  top: ""conv5_2""\r\n  name: ""relu5_2""\r\n  type: RELU\r\n}\r\nlayers {\r\n  bottom: ""conv5_2""\r\n  top: ""conv5_3""\r\n  name: ""conv5_3""\r\n  type: CONVOLUTION\r\n  convolution_param {\r\n    num_output: 128\r\n    pad: 1\r\n    kernel_size: 3\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""conv5_3""\r\n  top: ""conv5_3""\r\n  name: ""relu5_3""\r\n  type: RELU\r\n}\r\nlayers {\r\n  bottom: ""conv5_3""\r\n  top: ""pool5""\r\n  name: ""pool5""\r\n  type: POOLING\r\n  pooling_param {\r\n    pool: MAX\r\n    kernel_size: 2\r\n    stride: 2\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""pool5""\r\n  top: ""fc6""\r\n  name: ""fc6""\r\n  type: INNER_PRODUCT\r\n  inner_product_param {\r\n    num_output: 1024\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""fc6""\r\n  top: ""fc6""\r\n  name: ""relu6""\r\n  type: RELU\r\n}\r\nlayers {\r\n  bottom: ""fc6""\r\n  top: ""fc6""\r\n  name: ""drop6""\r\n  type: DROPOUT\r\n  dropout_param {\r\n    dropout_ratio: 0.8\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""fc6""\r\n  top: ""fc7""\r\n  name: ""fc7""\r\n  type: INNER_PRODUCT\r\n  inner_product_param {\r\n    num_output: 1024\r\n  }\r\n}\r\nlayers {\r\n  bottom: ""fc7""\r\n  top: ""fc7""\r\n  name: ""relu7""\r\n  type: RELU\r\n}\r\nlayers {\r\n  bottom: ""fc7""\r\n  top: ""fc7""\r\n  name: ""drop7""\r\n  type: DROPOUT\r\n  dropout_param {\r\n    dropout_ratio: 0.8\r\n  }\r\n}\r\nlayers {\r\n  name: ""fc8""\r\n  bottom: ""fc7""\r\n  top: ""fc8""\r\n  type: INNER_PRODUCT\r\n  inner_product_param {\r\n    num_output: 2\r\n  }\r\n}\r\nlayers {\r\n  name: ""loss""\r\n  type: SOFTMAX_LOSS\r\n  bottom: ""fc8""\r\n  bottom: ""label""\r\n  top: ""loss""\r\n}\r\nlayers {\r\n  name: ""accuracy""\r\n  type: ACCURACY\r\n  bottom: ""fc8""\r\n  bottom: ""label""\r\n  top: ""accuracy""\r\n  include {\r\n    phase: TEST\r\n  }\r\n}\r\n', ""This is the prototxt file. As you can see this is vgg16. The only difference from the original paper's configuration is on the output(number of filters). When I used back the original configuration, it can run but when I change to this, it can't. it doesn't make any sense. Anyone can help?"", 'make test and make runtest are all success so I wonder what is wrong', 'From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\r\n\r\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\r\nUse the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.', 'That guy has a legitimate issue. I\'m also haunted with these ""misaligned"" errors since spring. He sends you a replicable error report and you just close it?']",[],[],0,0
52,caffe,3030,closed,Solver Progress Plotting,"I've used gunplot to plot the accuracy of a solver over its epochs and was wondering whether this would be functionality Caffe would like to have built-in? I suppose it would add another optional dependancy, but I've found having a .png plot of my training really assists in gaining a higher-level perspective of how my model is performing, and gives greater insight into how the change of hyper parameters effects the curve of training.

Let me know if it would be considered a useful tool or not.
",,"['It is already there.\nHave a look at\nhttps://github.com/BVLC/caffe/blob/master/tools/extra/parse_log.py\nand\nhttps://github.com/BVLC/caffe/blob/master/tools/extra/plot_log.gnuplot.example\n\nI think there is no need for adding another dependency. You can just use a bash-script: \n\n```\n#!/bin/bash\nROOT=~/tools/caffe2/\n# name of logfile\nLOGNAME=examples/mnist/run.log\n\n# extract information\n~/tools/caffe2/tools/extra/parse_log.sh ""${ROOT}${LOGNAME}""\n\n# plot everything\ngnuplot <<- EOF\n  reset\n  set key right bottom\n  set style data lines\n  set font \'Consolas,10\'\n  set term png enhanced font \'Consolas,10\' size 800,400\n  set title ""Learning process ${LOGNAME}""\n  set xlabel ""Iterations""\n  set ylabel ""Loss""  tc rgb ""#009e73""\n  set y2label ""Accuracy"" tc rgb ""#7570b3""\n  set output ""run.png""\n  set border 11 back ls 80 lc -1\n  set mxtics 2\n  set grid mxtics\n  set ytics autofreq tc rgb ""#009e73""\n  set y2tics autofreq tc rgb ""#7570b3""\n  set grid xtics\n  set grid ytics\n\n  plot ""${ROOT}${LOGNAME}.train"" using 1:3 title ""training (loss)"" lt 2 lc rgb ""#aaaaaa"" axes x1y1,  \\\n  ""${ROOT}${LOGNAME}.test"" using 1:4 title ""test (loss)"" lt 2 lc rgb ""#009e73"" lw 2 axes x1y1  ,\\\n  ""${ROOT}${LOGNAME}.test"" using 1:3 title ""test (accuracy)"" lt 2 lc rgb ""#7570b3"" lw 2 axes x1y2 \nEOF\n\n```\n\n![preview](https://cloud.githubusercontent.com/assets/6756603/9715489/dbcdc044-5560-11e5-874a-5533cdb7b817.png)\n', ""@PatWie Thanks, that's perfect. \n""]",[],[],0,0
53,caffe,3242,closed,Normalization for convolution layer weights,"I have noticed that gradient w.r.t convolution layer parameters are summed over all pixel multiplications of previous layer feature image and next layer gradient image. However, feature image sizes (hidden layer images) change from layer to layer. 

So the gradient at each step is a sum of all gradients in the gradient image, without normalization. So, effectively, convolution layer weight-gradients used in stochastic-gradient-solver is using varying learning rates. Therefore, I think the backward methods require a normalization depending on the number of pixels in the gradient.
",,"['The expression that is computed in caffe is the correct gradient of the parameters with respect to the loss function.  What you\'re describing is using something other than the gradient to update the parameters.\n\nFor example, the RMSProp solver has a moving average that behaves a little bit like using only the sign of the gradient.  You can also interpret it as having a separate ""learning rate"" per parameter.\n\nWhat might be better is a count of the number of times a parameter is touched.  Then the solver could use this information and down-weight gradients by this value.   I think part of the reason why RNNs can be unstable to train is that some parameters accumulate way more terms than others, and this is why RMSprop works well for those models (my opinion, not experimentally verified).\n', ""I have a good understanding of how the gradient is back-propagated for inner product layers but I haven't read anything on convolution layers. Now I am planning to read on it :). \n\nBut I still think convolution weights have a learning rate that is the number-of-pixels-in-the-next-layer times more than it should be. My argument: normally each next-layer-pixel should be a node (unit) but their weights are shared across all the pixels so it boils down to convolution. Any weight gradient is: output-of-prev-layer times times gradient-of-next-layer. Since these weight gradients are different, to compute the update of a weight in the convolution we should average all gradients. Not accumulate them. Hence we are projecting the gradients to parameter sharing constraint. This accumulation is done via matrix multiplication in Caffe, and there is no normalization afterwards.\n\nSo, according to me, effectively convolution layer weights have a larger learning rate depending on the pixels in the next layers output. This might not necessarily be bad since convolution layers are generally earlier than inner product layers and so effectively inner product layer learning rates are smaller. This might help with our stochastic-wandering-around optimization since changing weights in the later layers might confuse our gradient directions in the earlier layers.\n\nI like your idea that the number of times a parameter is touched should effect the learning rate.\n"", ""I think you're confusing the concepts of gradient (derivative of loss with respect to parameter) with the optimal update for each parameter.  The expression in caffe is the correct gradient.  You can derive that you should sum (not average), using the chain rule from calculus.  Averaging would introduce make your gradient incorrect by a factor of _1/N_ where _N_ is the number of terms in the sum.\n\nIntuitively, each individual parameter gradient has _N_ times more items in the summation because it has _N_ times the effect on the loss output.\n"", 'Thanks for the reply. And I really hate taking your time but :)... And I know CNN BP is well established and as I now see, not just Caffe but everybody does it the same way via accumulation.\n\nI read the following tutorial: http://cogprints.org/5869/1/cnn_tutorial.pdf\n\nIn this tutorial it says in quote: ""Finally, the gradients for the kernel weights are computed using backpropagation, except in this case the same weights are shared across many connections. Well therefore sum the gradients for a given weight over all the connections that mention this weight, ...""\n\nFirst, each product of previous layer output and next layer gradient is the gradient of the weight. And to share the weights across all convolutions in an image, gradients are summed. I think this is the problem. This is a projection on to the weight-sharing-constraint and the way to do it is by averaging. Not summation. This effectively multiplies the corresponding learning rates for convolution layers in the network by N. \n', 'In the quote you mentioned ""Well therefore sum the gradients for a given weight over all the connections that mention this weight"", it makes it sound like a choice.  It\'s not.  It\'s what you get when you derive the gradient from the chain rule.\n\nConsider the loss function `L(f(x), g(x), h(x))` which depends on some parameter `x`.  The gradient for `x` is `dL/dx`, which is `dL/df * df/dx + dL/dg * dg/dx + dL/dh * dh/dx`.  Now consider the case where `f(x) = g(x) = h(x) = x`, i.e. the variable `x` is used multiple times inside `L`, and `f`, `g`, `h`, are just dummy wrapper functions.  Then `df/dx = dg/dx = dh/dx = 1` and we get the expression `dL/dx = dL/df + dL/dg + dL/dg`.  Each variable `f`, `g`, `h` corresponds to one place in which `x` was used inside `L`.  And the result is a sum, derived from first principles.  You should try deriving the expression yourself for the case of a convolution.\n\nShow me a derivation from first principles that arrives at using the average.\n', 'Sean, thanks for the reply. Last night, after replying to you, I wrote an email to Prof. Geoffrey Hinton describing what I have claimed above. And this is his reply: \n\n---\n\npeople are very well aware of this.\n\n##  Geoff\n\nA short one, but still he replied :)\n\nSo what I said was true and learning rate for convolution layer parameters is effectively N times larger, where N is the number of pixels in the next layer.\n\nTo respond to your argument, I have no problem with the chain rule. In fact the change rule says a single weight gradient is previous_layer_output \\* next_layer_gradient, just like it is with inner product. But there are not N of the same parameter in the equation. There are N different parameters and they are constrained to be equal that is what you are missing. I will try to explain more precisely below:\n\nTo get a convolution layer, think of each output pixel as a single unit in the next layer, but a ""locally"" connected one with the previous layer\'s units (pixels). So we have N of these units. And we can backpropagate and find the gradient for each weight in the local support for that next layer pixel. Let\'s say it is a 3x3 filter. So we can backpropagate and find 3x3=9 weight gradients for each N pixel (unit). But we want all of these N weights to be equal as we update via SGD. So we are going to start with the same initials and make their gradients equal. To do this, we must average them (as it is a projection operation on to an equality constraint). But in almost all implementations that I can see the N gradients are summed not averaged. And this effectively multiplies the corresponding weights by N.\n\nBut as I said earlier this may have helped in CNNs simply because as we go back in the network, gradients become smaller so we are scaling them up or changing later layers like inner-product layers slowly relative to convolution layer, stabilizes the convergence.\n\nBut I think this is still problematic. Because then the learning rate depends on the filter-mask size and padding which determines the number of pixels in the output. Also, pooling becomes a little confusing as the way it functions becomes complicated. Pooling not only functions its usual role but also effectively determines the learning rate. And I know learning rate is really important in training CNNs. I think this issue requires a good analysis and research. Maybe there is and I am not yet aware of. I think there is still a lot of room for improvement in SGD part.\n', ""You say:\n\n>  To do this, we must average them (as it is a projection operation on to an equality constraint). But in almost all implementations that I can see the N gradients are summed not averaged. And this effectively multiplies the corresponding weights by N.\n\nCan you derive how projecting onto an equality constraint results in the average?  I understand that intuitively it feels like the right choice, but I'm not aware of any theoretical justification for it.\n"", ""Let me write the optimization problem\n\nmin Loss(w1,w2) over w1, w2 such that w1 = w2\n\nWe need to find the gradient and project on to the constraint set successively (just like Bregman's algo).\n\nBy taking the derivative of the loss I can find delta_1 and delta_2 as derivative w.r.t to w_1 and w_2.  Let's call this d = [delta_1, delta_2]. And the constraint vector, I want to project onto is c=[1 1]. Hence linear projection operation based on Euclidean distance is (d^T*c/|c|) c/|c| which is [(delta_1 + delta_2)/2,  (delta_1 + delta_2)/2 ]. \n\nSo we keep iterating above computations.\n"", 'Hmm, I see what you mean.  You could also write it using a Lagrangian:\n`Loss(w1, w2) + lambda * ||w1 - w2||^2`\n\nHinton\'s ""Dark Knowledge"" method and some papers from LeCun\'s group propose methods somewhat like this, but where the constraints are across different CNNs and not within a CNN like what you are proposing.\n\nIt might do better or worse than SGD (which uses the gradient of `w` after collapsing `w = w1 = w2`).   Hard to say without trying it.  I can see it doing better if you leave all the variables separate and regularize them to be close to each other, since this introduces freedom in the optimization problem.\n\nFor standard CNNs (not RNNs), fancy update rules tend not to give much of a benefit compared to SGD+Momentum.  As far as I know, nothing beats well-tuned SGD+Momentum for non-recurrent CNNs.  For RNNs, it\'s a different story, and tracking the number of times that a variable is ""touched"" and scaling the update rule by that might give an improvement.  Learning for RNNs can be very unstable due to the massive amount of parameter sharing.\n', ""I don't think it is a good idea that we use regularization instead of constraints and divert away from convolution. Then we will be increasing the degrees of freedom (dof) by the number of pixels in the image, which is huge. I am happy with convolution layers at earlier stages and then switching to inner product layers when you want more connections between features to learn intricate relationships. And if I want more dof for my model, I would simply increase the number of features in the convolution layer, rather than letting filters change spatially. \n\nBut my point about this issue is important I think. If we do not average the gradients, then there is a big difference between the learning rate of convolution layer and inner product layers. And this difference depends on filter mask size, padding, number of pooling in between that is the network structure. Learning rate of layers changes by a big amount depending on the input image size. This is the reason why we have to choose a really small learning rate for bigger images. If updating convolution layers with a bigger rate is useful this should be done explicitly not behind our back.\n"", ""I'm closing as this is not a Caffe issue.  I'll echo @seanbell here -- at the end of the day, `Backward` has a simple mathematical definition: it computes the gradient of the error (i.e., the function computed by `Forward`) with respect to the parameters, and that's what Caffe does (modulo any actual bugs...). There might be good intuition here and it's possible this is in fact a better way of training, and I don't want to discourage @tarikarici or anyone else from giving it a shot*, but the behavior of Caffe's `Backward` is mathematically correct as is.\n\n*If you wanted to try this on an existing net, you could do so without modifying any code just by setting `param { lr_mult: x }`, where `x` is the appropriate scaling factor (maybe `x := kernel_size^(-2)` if I'm reading this correctly), in each `Convolution` layer. Or of course you could hack the `Convolution::Backward` code itself if you prefer.\n"", 'Actually my whole point was Backward is not computing the correct gradient but N times the correct gradient, and this N changes with the network.\n\nYes lr_mult can be used as you said to correct the problem via adjusting the learning rates.\n', ""I certainly encourage you to try using that as your update rule, but what is computed in caffe is the correct gradient (i.e. the derivative of the loss with respect to each free parameter).  You can test this with finite difference and you will see that the current code computes `dLoss / dw` for each paramter `w`.\n\nThat being said, you don't have to use the gradient to update the parameters.  You could scale the gradient based on the criteria that you're proposing, and it might do better as an update rule compared to the gradient.  If you think about optimization as point moving towards an optimum, in the worst case the gradient points at a 90 degree angle to the correct solution, and your re-scaling might reduce this angle.\n\nI think we're all in agreement that your update rule is different and is worth trying.\n"", 'I thought we agreed with you on the gradient :). Sum can not be the gradient. Probably the test also sums up all gradients and compares the sum. My guess...\n', ""If you're curious, this is the utility code that checks the gradient: https://github.com/BVLC/caffe/blob/master/include/caffe/test/test_gradient_check_util.hpp\n\nHere is one place where the gradient checker is instantiated for convolution layers:\nhttps://github.com/BVLC/caffe/blob/master/src/caffe/test/test_convolution_layer.cpp#L624\n\nThe gradient checker compares individual scalar values; there is nothing to sum up since you're comparing the change in one output (some value in a `top`) to the change in one parameter (some value in a parameter `blob`).\n""]",[],[],0,0
54,caffe,4009,closed,RuntimeWarning when loading the Python Caffe module ,"I got that warning message when I loaded the python caffe module. I got it just loading the module....

I'm using the last version of caffe (I updated yesterday) and python 2.7.3.  Thanks in advance!  


",duplicate,"['See #3944, #3866, and #3575.\n\nA proposed fix is here: #3960.\n']","['\n\n/source/caffe/1.2-CPU/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.\nfrom ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\n\n/source/caffe/1.2-CPU/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.\nfrom ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\n\n/source/caffe/1.2-CPU/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.\nfrom ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\n']",[],0,0
55,caffe,3816,closed,When dose caffe clear layers' bottom/top's diff?,"Hi all!
As we know we need to clear layer's parameters' diff and bottom/top's diff at each step when training a net. And I found that in  it has  to clear layer's parameters' diff, but when does caffe clear layers' bottom/top's diff?
",,['See #6202 and #6186 for discussion.'],[],"['solver.cpp', 'net_->ClearParamDiffs()']",0,0
56,caffe,460,closed,Feature Request: Multi-Label DataLayer and LevelDB converter,"Lots of visual recognition problems have a multi-label nature. That means an entry (Datum) will be assigned to multiple labels. Currently the DataLayer and LevelDB converter assume there is a single label assigned to every entry. 

Has anybody worked on that yet?

My suggestion is that we make an alternative ""label array"" \in {-1,0,1}^k where k is the number of possible labels and 

-1: label does not exist in the entry image
0: undefined/unknown/irrelevant label for the image
1: label exist in the entry image
",enhancement,"[""@azizpour I'm working on this, I will make it public after NIPS deadline when I have a bit more time\n\nI'm following the same convention\n-1: negative label\n0: undefined/unknown/irrelevant label for the image. Ignored in the loss\n1: positive label\n"", 'Closing since this will be addressed by #523 .\n']",[],[],0,0
57,caffe,2272,closed,"Java web service Call ""classify.py"" python script","I have written a java web service that call the ""classify.py"" in java using .getRuntime().exec. command

The problem is, every time I call the web service it will initialize the net model.

Would you please suggest me a way to go over this prob., 

Thanks 
",,"['Have you tried to pilot directly in java trough java-cpp caffe preset?\nPlease close this ticket and use mailing list or gitter channel for support.\n', ""Thank you\nNo I didn't try. I think I have to\n"", '@bhack \nsorry to reopen again.........\nBut would please advise me to sample code than I can start with?\nI am really very new to java-cpp preset and I feel lost already\n\nThanks in advance\n', 'See pom and a java example here https://github.com/bytedeco/javacpp-presets/tree/master/caffe.\nPlease close the ticket and use mailing list, gitter or continue the discussion you have already opened at https://github.com/bytedeco/javacpp-presets/issues/43\n']",[],[],0,0
58,caffe,4401,closed,matcaffe with octave,"hi,

I found that caffe support Octave interface https://github.com/BVLC/caffe/blob/master/matlab/CMakeLists.txt

I installed  and  and uncomment  in .

but it still said that it required matlab binary



Is that Octave interface still an ongoing feature?
",,"['While the CMake build mentions Octave in lieu of MATLAB, to my knowledge Caffe is only MATLAB compatible. However if you want to try with Octave you will need to build with CMake since the Makefile build only supports MATLAB.\n\nFor further installation help please post on the mailing list.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']","[""\n(caffe) tumh@tumh-Predator-G9-592:~/caffe$ make matcaffe\nmake: /usr/local/bin/mexext: Command not found\nMEX matlab/+caffe/private/caffe_.cpp\n/bin/sh: 1: /usr/local/bin/mex: not found\nMakefile:508: recipe for target 'matlab/+caffe/private/caffe_.' failed\n""]","['octave', 'liboctave-dev', 'MATLAB_DIR := /usr/local', 'Makefile.config']",0,0
59,caffe,1822,closed, error: When build the Caffe on Ubuntu 14.04 with GPU,"I get following errors: 

g++ .build_release/tools/dump_network.o .build_release/lib/libcaffe.a -o .build_release/tools/dump_network.bin -fPIC -DNDEBUG -O2 -DUSE_CUDNN -I/usr/include/python2.7 -I/usr/lib/python2.7/dist-packages/numpy/core/include -I/usr/local/include -I.build_release/src -I./src -I./include -I/usr/local/cuda/include -Wall -Wno-sign-compare -L/usr/lib -L/usr/local/lib -L/usr/lib -L/usr/local/cuda/lib64 -L/usr/local/cuda/lib -lcudart -lcublas -lcurand -lglog -lgflags -lprotobuf -lleveldb -lsnappy -llmdb -lboost_system -lhdf5_hl -lhdf5 -lopencv_core -lopencv_highgui -lopencv_imgproc -lpthread -lboost_thread -lcudnn -lcblas -latlas
/usr/lib/x86_64-linux-gnu/libgflags.so: undefined reference to `std::__throw_out_of_range_fmt(char const_, ...)@GLIBCXX_3.4.20'
collect2: error: ld returned 1 exit status
Makefile:494: recipe for target '.build_release/tools/dump_network.bin' failed
make: *_\* [.build_release/tools/dump_network.bin] Error 1

I am a beginner for the Caffe and Linux. I have no any idea. If anyone know how to solve this error, please help me! Thanks very much!
",,"[""How about trying 'make clean' and make sequence ??\n"", '@stray-leone Thanks a lot. I reinstall the libgflags-dev, then make it pass.\n']",[],[],0,0
60,caffe,1005,closed,make runtest core dumped,"make runtest

.build_release/test/test_all.testbin 0 --gtest_shuffle 
Cuda number of devices: 1
Setting to use device 0
Current device id: 0
Note: Randomizing tests' orders with a seed of 42484 .
[==========] Running 718 tests from 154 test cases.
[----------] Global test environment set-up.
[----------] 6 tests from SliceLayerTest/2, where TypeParam = caffe::FloatGPU
[ RUN      ] SliceLayerTest/2.TestGradientAcrossNum
F0829 15:41:50.183418  3050 math_functions.cu:81] Check failed: error == cudaSuccess (11 vs. 0)  invalid argument
**\* Check failure stack trace: ***
    @     0x2b96b5faadaa  (unknown)
    @     0x2b96b5faace4  (unknown)
    @     0x2b96b5faa6e6  (unknown)
    @     0x2b96b5fad687  (unknown)
    @           0x7374d2  caffe::caffe_gpu_memcpy()
    @           0x69eaea  caffe::SyncedMemory::mutable_gpu_data()
    @           0x72a9f1  caffe::Blob<>::mutable_gpu_data()
    @           0x754c8b  caffe::SliceLayer<>::Forward_gpu()
    @           0x4257bb  caffe::GradientChecker<>::CheckGradientSingle()
    @           0x46ddc9  caffe::GradientChecker<>::CheckGradientExhaustive()
    @           0x5d99e2  caffe::SliceLayerTest_TestGradientAcrossNum_Test<>::TestBody()
    @           0x6593bd  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @           0x651191  testing::Test::Run()
    @           0x651276  testing::TestInfo::Run()
    @           0x6513b7  testing::TestCase::Run()
    @           0x65170e  testing::internal::UnitTestImpl::RunAllTests()
    @           0x658f3d  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @           0x6507ee  testing::UnitTest::Run()
    @           0x4170cd  main
    @     0x2b96b8c48ec5  (unknown)
    @           0x41c891  (unknown)
    @              (nil)  (unknown)
make: **\* [runtest] Aborted (core dumped)

I run ""make runtest"" many times. Everytime it's core dumped at ""math_functions.cu""
I get this error on (Ubuntu14.04 x86_64) + (NVIDIA Driver Version: 340.32) + (CUDA: 6.0).
I suppose it may caused by cuda. Then I reinstall cuda6.5 to replace cuda6.0. But I still get this error.
",compatibility downstream problem?,"['Can anybody help me? How this error arose?\n', 'I am having the same problem .. I have NVIDIA GTX295 ... I have tried CUDA 5.0 and CUDA 6.0 with different drivers ... the deviceQuery detects the device but make runtest fails with this error .. help required \n', '@suffvaughn, I have NVIDIA GTS250. and tried CUDA6.0 + NVIDIA Driver 340.32, and CUDA6.5 + NVIDIA Driver 340.32. But runtest fails with the same error.\n', 'Running Caffe on GPUs with compute capability < 3.0 can be an adventure due\nto the hardware limitations. It can sometimes be done by tuning the CUDA\nkernel launch configurations but my best recommendation is to work on a GPU\nwith compute capability >= 3.0.\n\nOn Thu, Sep 4, 2014 at 6:07 PM, mender05 notifications@github.com wrote:\n\n> @suffvaughn https://github.com/suffvaughn, I have NVIDIA GTS250. and\n> tried CUDA6.0 + NVIDIA Driver 340.32, and CUDA6.5 + NVIDIA Driver 340.32.\n> But runtest fails with the same error.\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/1005#issuecomment-54566634.\n', 'Please continue your hardware / installation discussion on the [caffe-users mailing list](https://groups.google.com/forum/#!forum/caffe-users) according to our discussion policy -- we like to keep Issues for development. Thanks!\n']",[],[],0,0
61,caffe,4680,closed,Crash with cv::resize() and OpenCL,"Hi. I compile caffe and hav not any warning  , but in make runtest i have this problem
anyone can help ?
Nvidia GTX 1070
Cuda-8.0
ubuntu 16.04.1
.
.
[ RUN      ] ImageDataLayerTest/0.TestShuffle
[       OK ] ImageDataLayerTest/0.TestShuffle (61 ms)
[ RUN      ] ImageDataLayerTest/0.TestSpace
[       OK ] ImageDataLayerTest/0.TestSpace (21 ms)
[ RUN      ] ImageDataLayerTest/0.TestResize
**\* Aborted at 1472932722 (unix time) try ""date -d @1472932722"" if you are using GNU date ***
PC: @     0x7f79eb212d84 __GI___pthread_mutex_lock
**\* SIGSEGV (@0x3038) received by PID 10525 (TID 0x7f79f497c740) from PID 12344; stack trace: ***
    @     0x7f79eb21a3d0 (unknown)
    @     0x7f79eb212d84 __GI___pthread_mutex_lock
    @     0x7f79c27add98 (unknown)
    @     0x7f79c2863c41 (unknown)
    @     0x7f79c2863db5 (unknown)
    @     0x7f79c27b3ad4 (unknown)
    @     0x7f79c27b5327 (unknown)
    @     0x7f79c27894f6 (unknown)
    @     0x7f79c2688d7d (unknown)
    @     0x7f79c2688d18 (unknown)
    @     0x7f79d0142022 (unknown)
    @     0x7f79d0143d42 (unknown)
    @     0x7f79d01434d0 clGetPlatformIDs
    @     0x7f79ee8b98d5 (anonymous namespace)::opencl_fn3<>::switch_fn()
    @     0x7f79ee99ceea cv::ocl::haveOpenCL()
    @     0x7f79ee9ac288 cv::ocl::useOpenCL()
    @     0x7f79ece56a6c cv::resize()
    @     0x7f79ebaffb47 caffe::ReadImageToCVMat()
    @     0x7f79ebb8f12e caffe::ImageDataLayer<>::DataLayerSetUp()
    @     0x7f79ebbaa203 caffe::BasePrefetchingDataLayer<>::LayerSetUp()
    @           0x48ab2f caffe::Layer<>::SetUp()
    @           0x707fe7 caffe::ImageDataLayerTest_TestResize_Test<>::TestBody()
    @           0x917183 testing::internal::HandleExceptionsInMethodIfSupported<>()
    @           0x91079a testing::Test::Run()
    @           0x9108e8 testing::TestInfo::Run()
    @           0x9109c5 testing::TestCase::Run()
    @           0x911c9f testing::internal::UnitTestImpl::RunAllTests()
    @           0x911fc3 testing::UnitTest::Run()
    @           0x46d47d main
    @     0x7f79eae60830 __libc_start_main
    @           0x474ee9 _start
    @                0x0 (unknown)
Makefile:526: recipe for target 'runtest' failed
make: **\* [runtest] Segmentation fault (core dumped)
",,"['I think this is an OpenCV or OpenCL issue. Try setting the following environment variable to null: OPENCV_OPENCL_RUNTIME=\n', 'Agreed, this is not a core Caffe issue but a problem with OpenCV GPU usage.\n', 'I get exactly the same error when trying to run caffe, but running the core OpenCV tests gives no problems. Has this issue been resolved?\n', 'Setting **OPENCV_OPENCL_RUNTIME=** solves the problem for me.\r\nThanks to @stephenlombardi \r\nJust curious why this is.']",[],[],0,0
62,caffe,4869,closed,ImportError when implementing Python Layer in Caffe,"I'm trying to incorporate a custom python data layer to a network in . I have built  with  and have added the caffe python modules and the custom python data layer module to . However, when I try to run it, it gives the following error:
I1020 16:13:35.672911 24362 layer_factory.hpp:74]  
    ImportError: Import by filename is not supported.
    terminate called after throwing an instance of boost::python::error_already_set'
   **\* Aborted at 1476960215 (unix time) try ""date -d @1476960215"" if you are using GNU date ***
   PC: @     0x7fea94390c37 (unknown)     **\* SIGABRT (@0x3e800005f2a) received by PID 24362 (TID 0x7fea95db7a40)  from PID 24362; stack trace: ***
        @     0x7fea94390cb0 (unknown)
        @     0x7fea94390c37 (unknown)
        @     0x7fea94394028 (unknown)
        @     0x7fea94995535 (unknown)
        @     0x7fea949936d6 (unknown)
        @     0x7fea94993703 (unknown)
        @     0x7fea94993976 (unknown)
        @     0x7fea955ffe22 caffe::GetPythonLayer<>()
        @     0x7fea95616326 caffe::LayerRegistry<>::CreateLayer()
        @     0x7fea9561b4cc caffe::Net<>::Init()
        @     0x7fea9561d262 caffe::Net<>::Net()
        @     0x7fea955f9139 caffe::Solver<>::InitTrainNet()
        @     0x7fea955fa2f3 caffe::Solver<>::Init()
        @     0x7fea955fa4c6 caffe::Solver<>::Solver()
        @           0x40d030 caffe::GetSolver<>()
        @           0x407143 train()
        @           0x4056e1 main
        @     0x7fea9437bf45 (unknown)
        @           0x405c8d (unknown)
        @                0x0 (unknown)
        Aborted (core dumped)

Any idea why I'm running into this problem? Thanks in advance.
",,"['Check your value of `python_param { module: }`. It should be a module like `layers.my_layer`, not a file like `layers/my_layer.py`.\nhttps://gist.github.com/lukeyeager/5ae183044d96ef1540f2\n', 'Give you a example which is my implement, I input the audio and image data to the network,  https://github.com/saicoco/_practice/tree/master/pycaffe/example_bigbang/build\n', 'Thanks all for your responses. I was able to sort this out. My mistake was that I was giving the path to the module as well in `python_param { module: }` in the prototxt. However, this was not required. Just the module name  `python_param { module: }` which was in the `$PYTHONPATH` sufficed.\n', 'I reopen just to expand the question a bit further. Is there a way that we can point to the desired python module ""locally"", instead of setting $PYTHONPATH, which has quite a global effect on the whole system. ', '@lhoangan could you solve this problem. ', 'Hi, I am writing a python layer and it is used in train.prototxt file. Both files are present in same directory and here is the code used in \r\n\'layer {\r\n  name: ""data""\r\n  type: ""Python""\r\n  top: ""data""\r\n  top: ""label""\r\n\r\n  python_param {\r\n    module: ""seg_input""\r\n    layer: ""MySegDataLayer""\r\n    param_str:""{...}""\r\n    }\r\n }\r\n\'\r\nhowever it is not working and i am getting following message that ""seg_input"" module not found. ', ""@sajjo79 unfortunately that I didn't find any way to solve the issue in my question. I am still waiting for contribution and discussion. In my case, I had to manually set ```$PYTHONPATH``` to where my module was for the network to find it."", ""Hi, I am using pycharm to compile and run my project. Instead of running from command prompt i used following code:\r\n\r\n**> solver = None\r\n> solver = caffe.SGDSolver(solver_file)\r\n> for i in range(2):\r\n>     solver.step(2)\r\n> print 'done'**\r\nit recompiled the instructions and made my program to read seg_input file from current working directory. I think there is something wrong with compilation process. \r\nHowever this solution worked for me. \r\n"", '@sajjo79 Hi, what about the method compiled and run by pycharmcould you support a tutorial or guide for the details\r\n3ku']",[],"['caffe', 'caffe', 'WITH_PYTHON_LAYER=1', 'PYTHONPATH']",0,0
63,caffe,3374,closed,Is `if (this->phase_ == TRAIN) `  necessary in the backward computation of  dropout_layer implementation ?,"For example, in   
Function implementation:  
part of code is:



Backward pass is only present in the training stage. So, is this  necessary ? I think removing the conditional sentence still makes sense.
",,"[""It's necessary because you can still call `backward` for a `TEST` net, e.g. for any algorithm that uses both forward and backward at inference time.  Example: when reconstructing an image using the python interface.\n"", '@seanbell I see. Thank you very much~\n']","['\n    if (this->phase_ == TRAIN) {\n      const unsigned int* mask = rand_vec_.cpu_data();\n      const int count = bottom[0]->count();\n      for (int i = 0; i < count; ++i) {\n        bottom_diff[i] = top_diff[i] * mask[i] * scale_;\n      }\n    } else {\n      caffe_copy(top[0]->count(), top_diff, bottom_diff);\n']","['src/caffe/layers/dropout_layer.cpp', 'void DropoutLayer<Dtype>::Backward_cpu ()', 'if (this->phase_ == TRAIN) ... else ...']",0,0
64,caffe,4864,open,Mac import caffe error,"I finally install caffe on my Mac, without error for 'make pycaffe' and 'make distribute', so I got to \<caffe-root\>/python, and run python -c ""import caffe"", but I got some errors here, It seems it's the problem of protocol buffers, I am not sure:


I think that maybe gcc expected gcc code and it found clang code instead, and that the compiler is reporting not having found the gcc symbol, but mac use clang to compiler?

Because when I install the requirement.txt for pycaffe, I got some errors for gcc.

To install caffe is really headache, can someone give me a hand to tell me what happended???
Thanks in advance
",mac,"['I think the problem is because of when I run some python dependencies for pycaffe, they use pip, and I use anaconda pip, So I got some errors like this:\r\n```\r\nsnappy/snappy.cc -o build/temp.macosx-10.6-x86_64-2.7/./snappy/snappy.o -I./leveldb/include -I./leveldb -I./snappy -I. -fno-builtin-memcmp -O2 -fPIC -DNDEBUG -DSNAPPY -DOS_MACOSX -DLEVELDB_PLATFORM_POSIX -Wno-error=unused-command-line-argument-hard-error-in-future\r\n  cc1plus: warning: command line option \'-Wstrict-prototypes\' is valid for C/ObjC but not for C++\r\n  cc1plus: error: -Werror=unused-command-line-argument-hard-error-in-future: no option -Wunused-command-line-argument-hard-error-in-future\r\n  error: command \'gcc\' failed with exit status 1\r\n\r\n---\r\n\r\n  Failed building wheel for leveldb\r\n  Running setup.py clean for leveldb\r\nFailed to build leveldb\r\nInstalling collected packages: leveldb\r\n  Running setup.py install for leveldb ... error\r\n    Complete output from command /Users/junhao.wen/anaconda2/bin/python -u -c ""import setuptools, tokenize;**file**=\'/private/var/folders/5r/10gy0dnn1x1dykzyb4117pcc000hzl/T/pip-build-byQK6_/leveldb/setup.py\';exec(compile(getattr(tokenize, \'open\', open)(**file**).read().replace(\'\\r\\n\', \'\\n\'), **file**, \'exec\'))"" install --record /var/folders/5r/10gy0dnn1x1dykzyb4117pcc000hzl/T/pip-ECNpMF-record/install-record.txt --single-version-externally-managed --compile:\r\n    running install\r\n    running build\r\n    running build_ext\r\n    building \'leveldb\' extension\r\n    creating build\r\n    creating build/temp.macosx-10.6-x86_64-2.7\r\n    creating build/temp.macosx-10.6-x86_64-2.7/snappy\r\n    creating build/temp.macosx-10.6-x86_64-2.7/leveldb\r\n    creating build/temp.macosx-10.6-x86_64-2.7/leveldb/db\r\n    creating build/temp.macosx-10.6-x86_64-2.7/leveldb/table\r\n    creating build/temp.macosx-10.6-x86_64-2.7/leveldb/util\r\n    creating build/temp.macosx-10.6-x86_64-2.7/leveldb/port\r\n    gcc -fno-strict-aliasing -I/Users/junhao.wen/anaconda2/include -arch x86_64 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/junhao.wen/anaconda2/include/python2.7 -c ./snappy/snappy.cc -o build/temp.macosx-10.6-x86_64-2.7/./snappy/snappy.o -I./leveldb/include -I./leveldb -I./snappy -I. -fno-builtin-memcmp -O2 -fPIC -DNDEBUG -DSNAPPY -DOS_MACOSX -DLEVELDB_PLATFORM_POSIX -Wno-error=unused-command-line-argument-hard-error-in-future\r\n    cc1plus: warning: command line option \'-Wstrict-prototypes\' is valid for C/ObjC but not for C++\r\n    cc1plus: error: -Werror=unused-command-line-argument-hard-error-in-future: no option -Wunused-command-line-argument-hard-error-in-future\r\n    error: command \'gcc\' failed with exit status 1\r\n```\r\nSo how can I install pip leveldb within anaconda?\r\n', 'same error, any progress?']","['\r\npython -c \'import caffe\'\r\nTraceback (most recent call last):\r\n  File ""<string>"", line 1, in <module>\r\n  File ""caffe/**init**.py"", line 1, in <module>\r\n    from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver\r\n  File ""caffe/pycaffe.py"", line 15, in <module>\r\n    import caffe.io\r\n  File ""caffe/io.py"", line 8, in <module>\r\n    from caffe.proto import caffe_pb2\r\n  File ""caffe/proto/caffe_pb2.py"", line 7, in <module>\r\n    from google.protobuf import descriptor as _descriptor\r\n  File ""/Users/junhao.wen/anaconda2/lib/python2.7/site-packages/protobuf-3.1.0-py2.7-macosx-10.6-x86_64.egg/google/protobuf/descriptor.py"", line 46, in <module>\r\n    from google.protobuf.pyext import _message\r\nImportError: dlopen(/Users/junhao.wen/anaconda2/lib/python2.7/site-packages/protobuf-3.1.0-py2.7-macosx-10.6-x86_64.egg/google/protobuf/pyext/_message.so, 2): Symbol not found: __ZNK6google8protobuf10TextFormat17FieldValuePrinter10PrintBytesERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\r\n  Referenced from: /Users/junhao.wen/anaconda2/lib/python2.7/site-packages/protobuf-3.1.0-py2.7-macosx-10.6-x86_64.egg/google/protobuf/pyext/_message.so\r\n  Expected in: flat namespace\r\n in /Users/junhao.wen/anaconda2/lib/python2.7/site-package\r\nbut the _message.so file is there.\r\n']",[],0,0
65,caffe,3453,open,Any official plans of sync with cuDNN v4?,"Seems like CuDNN v4 is out in RC
https://developer.nvidia.com/cudnn

And it added some wonderful new features, 2D tiled FFT-conv, BN.
I think FFT-Conv is a great new feature.
So I wonder if there are any plans from the core dev team?

If not, may be we can make some contributions.
",,"[""I'm also curious about if there are any official plans.\n\nFor the BN part, current caffe implementation does not have scale and bias parameters in the batch norm layer, which is inconsistent with the cudnn interface. So I wonder if it is better to first implement the scale / bias, and then add the cudnn engine?\n"", ""I'm interested in this, too.\n"", 'ICYMI, you can extract it from the NVIDIA/Caffe 0.14 branch if you need it ASAP.\n', '@ajtulloch thanks a lot! I will check it out. Seems like they have promoted 0.14 branch to the master few days ago. Well, NVidia guys did a great job. :)\n']",[],[],0,0
66,caffe,6875,open,Check failed: error == cudaSuccess (63 vs. 0)  OS call failed or operation not supported on this OS,"when making runtest, I met the following problem, does anyone know how to solve it? 
![image](https://user-images.githubusercontent.com/56579909/70400771-83002580-1a67-11ea-8327-15f490632472.png)
",,[],[],[],0,0
67,caffe,4868,open,No support for unicode literals on caffe.Net,"Currently the pieces for caffe.Net will not accept unicode literals for the first and second arguments and generate cryptic messages about call signature for the underlying c++. I discovered this because I am in the habit of writing python2/3 compliant code so I always  in my code to get the really basic stuff out of the way. This however breaks the init method in the c++ code behind the Net class.

I have already gotten around this but it should be addressed in a further release.
",Python Python 3,[],[],"['from __future__ import unicode_literals, print_function, division']",0,0
68,caffe,5867,open,Crash in amdocl64.dll when Caffe calls clBuildProgram,"Ive compiled the OpenCL caffe branch on windows using the scripts/build_win.cmd. When running the classification example I get a crash when caffe tries to build a cl program:
e:\Work\Projects\VisualStudio\Viennacl-dev\viennacl-dev\viennacl\ocl\context.hpp:438
    if (!temp)
    {
      temp = clCreateProgramWithSource(h_.get(), 1, (const char **)&source_text, &source_size, &err);
      VIENNACL_ERR_CHECK(err);
    }
const char * options = build_options_.c_str();
->err = clBuildProgram(temp, 0, NULL, options, NULL, NULL);

Variables:
source_size	337011	unsigned __int64
source_text 	[source_text.cl.txt](https://github.com/BVLC/caffe/files/1244442/source_text.cl.txt)

Callstack:
>	classification-d.exe!viennacl::ocl::context::add_program(const std::basic_string<char,std::char_traits<char>,std::allocator<char> > & source, const std::basic_string<char,std::char_traits<char>,std::allocator<char> > & prog_name) Line 438	C++
 	classification-d.exe!caffe::RegisterKernels(viennacl::ocl::context * ctx) Line 5262	C++
 	classification-d.exe!caffe::device::SetProgram() Line 286	C++
 	classification-d.exe!caffe::device::Init() Line 67	C++
 	classification-d.exe!caffe::Caffe::SetDevices(std::vector<int,std::allocator<int> > device_ids) Line 531	C++
 	classification-d.exe!Classifier::Classifier(const std::basic_string<char,std::char_traits<char>,std::allocator<char> > & model_file, const std::basic_string<char,std::char_traits<char>,std::allocator<char> > & trained_file, const std::basic_string<char,std::char_traits<char>,std::allocator<char> > & mean_file, const std::basic_string<char,std::char_traits<char>,std::allocator<char> > & label_file) Line 72	C++
 	classification-d.exe!main(int argc, char * * argv) Line 269	C++

I am trying to run caffe on my AMD R9 270X GPU using opencl but it crashes in the C:\Windows\System32\amdocl64.dll. If I switch to using my other opencl device (Intel CPU) it compiles successfully. To be honest Im not sure if this should be reported here or to AMD support?

My machine specs:
Windows 10 64-bit
AMD Radeon R9 200 Series with latest drivers (17.7.2)
OpenCL Version: 22.19.662.4

Reproducible:
Ive also reproduced this issue by loading the generated cl program into the AMD APP SDK 2.9.1 HelloWorld.cpp example. 

I've made a few local modifications but I don't think these will cause any change in this behaviour:

diff --git a/scripts/build_win.cmd b/scripts/build_win.cmd
index f90306e3..49176291 100755
--- a/scripts/build_win.cmd
+++ b/scripts/build_win.cmd
@@ -68,7 +68,7 @@ if DEFINED APPVEYOR (
 ) else (
:: Change the settings here to match your setup
:: Change MSVC_VERSION to 12 to use VS 2013
-if NOT DEFINED MSVC_VERSION set MSVC_VERSION=14
+if NOT DEFINED MSVC_VERSION set MSVC_VERSION=12
:: Change to 1 to use Ninja generator (builds much faster)
if NOT DEFINED WITH_NINJA set WITH_NINJA=0
:: Change to 1 to build caffe without CUDA support
@@ -85,8 +85,8 @@ if DEFINED APPVEYOR (
:: Change to 3 if using python 3.5 (only 2.7 and 3.5 are supported)
if NOT DEFINED PYTHON_VERSION set PYTHON_VERSION=2
:: Change these options for your needs.
-if NOT DEFINED BUILD_PYTHON set BUILD_PYTHON=1
-if NOT DEFINED BUILD_PYTHON_LAYER set BUILD_PYTHON_LAYER=1
+if NOT DEFINED BUILD_PYTHON set BUILD_PYTHON=0
+if NOT DEFINED BUILD_PYTHON_LAYER set BUILD_PYTHON_LAYER=0
if NOT DEFINED BUILD_MATLAB set BUILD_MATLAB=0
:: If python is on your path leave this alone
if NOT DEFINED PYTHON_EXE set PYTHON_EXE=python

diff --git a/src/caffe/layers/libdnn_conv_layer.cpp b/src/caffe/layers/libdnn_conv_layer.cpp
index 451f1ef8..600bb6a8 100644
--- a/src/caffe/layers/libdnn_conv_layer.cpp
+++ b/src/caffe/layers/libdnn_conv_layer.cpp
@@ -63,7 +63,7 @@ void LibDNNConvolutionLayer<Dtype>::Reshape(
     config.bias_term = this->bias_term_;
     config.fast_unsafe_math = true;
     config.weights_backward = this->param_propagate_down_[0];
-config.bias_backward = this->param_propagate_down_[1];
+config.bias_backward = this->bias_term_ ? this->param_propagate_down_[1] : false;

if ((std::is_same<Dtype, float>::value

diff --git a/src/caffe/layers/libdnn_deconv_layer.cpp b/src/caffe/layers/libdnn_deconv_layer.cpp
index aacde554..0bc49ca7 100644
--- a/src/caffe/layers/libdnn_deconv_layer.cpp
+++ b/src/caffe/layers/libdnn_deconv_layer.cpp
@@ -59,7 +59,7 @@ void LibDNNDeconvolutionLayer<Dtype>::Reshape(
     config.bias_term = this->bias_term_;
     config.fast_unsafe_math = true;
     config.weights_backward = this->param_propagate_down_[0];
-config.bias_backward = this->param_propagate_down_[1];
+config.bias_backward = this->bias_term_ ? this->param_propagate_down_[1] : false;

// Atomic algorithm requirements:
// - Float & 32 bit atomics available

",windows,[],[],[],0,0
69,caffe,4304,open,OpenCL spatial convolution bug ,"Hardware: SKL i5-6600U - Intel GPU
OS: Ubuntu 16.04

Testing AlexNet (batch 128), as defined by soumith's convnet benchmarks. Also tried 32


",OpenCL bug,"[""@naibaf7, Relating to Intel's spatial convolution, how do you think about a functionality of either turning on or off this feature at compile time?\n\nIn case of Mac OS X, OpenCL driver does not support Intel's extension regardless of Iris graphics, I considered to check platform vendor at layer_factory.cpp. But, it is not a good idea because vieannaCL API only provides vendorID in digits.\n\nTo check actual platform vendor information, I have to call get_platforms(), compare platform_index() from ctx against a list of platforms and filter Apple label from info() string.\n\nDue to inefficiency, I just commented out [layer_factory's invocation](https://github.com/BVLC/caffe/blob/opencl/src/caffe/layer_factory.cpp#L78-81) and have used it until now.\n"", ""@cepiross \nGood point, we'll do that.\n\n@gongzg\nI was able to verify the bug here, seems like the new CPU verify_result() can segfault in some instances, for example when running: `./build/test/test_all.testbin --gtest_filter=*TestGradient_Spatial*`\n"", ""@cepiross @naibaf7  I agree. It's hard to determine whether the subgroup extension is supported by only check the vendor id. The best way to do this type of thing is the runtime library should provide correct extension strings, then we can check the extension string easily at runtime. But unfortunately, Intel OpenCL SDK doesn't export any of the subgroup extension string.\n\n@ngaloppo @naibaf7 I can't reproduce the bug at my side currently. But I do found some potential risk cases. I will submit a new PR latter, and please have a try to check whether it works at your side. Thanks. \n"", ""@naibaf7 @ngaloppo Could you try PR 4311 to verify whether it could fix this issue. It's caused by MKL has some issue in the verification code and lead to all kernel configuration fail the verification which trigger a bug in the verification function.\n"", ""@gongzg @naibaf7 @cepiross How about checking for the `cl_intel_subgroups` vendor extension string? Wouldn't that be the best way to check for support for the subgroup functionality? My driver supports this string. \n"", ""@ngaloppo At the beginning, I tried to use the extension string but failed. I just checked again with the current OpenCL SDK library and found the latest official OpenCL SDK already give the correct extension of cl_intel_subgroups and only the open source beignet driver doesn't provide correct extension string. That's not a big deal. I will contact beignet developer to fix this problem soon. After that, I will submit a new patch to use the extention to determine whether we use Intel Spatial. @naibaf7 @cepiross What do you think?\n"", '@ngaloppo @gongzg  if `cl_intel_subgroups` is presented correctly from extensions(), this is the best option. I definitely agree with you.\n\nAs soon as the patch is adapted, it is possible to withdraw `USE_INTEL_SPATIAL` option only if compatible kernel works well, I think. Another option is to make spatial convolution optional. It depends on your decision, @naibaf7.\n', ""@cepiross \nI am investigating methods to provide either a common interface for the convolution backends and/or a better backend selection logic. At the moment, the Intel spatial convolutions would also be selected for CPU devices from Intel using OpenCL. This is not intended either, so due to these behaviours I decided to make all convolution backends other than the Caffe default one optional.\n\nWhich is not a good solution since many will have sub-par performance if they don't know which backend (libdnn, conv spatial) they have to enable for their device. It gets even worse when multiple devices are present at the same time.\n""]","['\nViennaCL: Getting queue for device Intel(R) HD Graphics in context 0xbaa860\nViennaCL: Current queue id 0\nViennaCL: Setting handle kernel argument 0x10f22d0 at pos 0 for kernel U5_5_64_1_1_1_1_31_31_128_1_192_1_4_3_1_2\nViennaCL: Setting int precision kernel argument 0 at pos 1 for kernel U5_5_64_1_1_1_1_31_31_128_1_192_1_4_3_1_2\nViennaCL: Setting handle kernel argument 0x104e2d0 at pos 2 for kernel U5_5_64_1_1_1_1_31_31_128_1_192_1_4_3_1_2\nViennaCL: Setting int precision kernel argument 0 at pos 3 for kernel U5_5_64_1_1_1_1_31_31_128_1_192_1_4_3_1_2\nViennaCL: Setting handle kernel argument 0x2b48d80 at pos 4 for kernel U5_5_64_1_1_1_1_31_31_128_1_192_1_4_3_1_2\nViennaCL: Setting int precision kernel argument 0 at pos 5 for kernel U5_5_64_1_1_1_1_31_31_128_1_192_1_4_3_1_2\nViennaCL: Setting handle kernel argument 0x105ee20 at pos 6 for kernel U5_5_64_1_1_1_1_31_31_128_1_192_1_4_3_1_2\nViennaCL: Setting int precision kernel argument 17775936 at pos 7 for kernel U5_5_64_1_1_1_1_31_31_128_1_192_1_4_3_1_2\nViennaCL: Getting queue for device Intel(R) HD Graphics in context 0xbaa860\nViennaCL: Current queue id 0\nViennaCL: Getting current_context with id 0\nViennaCL: Getting queue for device Intel(R) HD Graphics in context 0xbaa860\nViennaCL: Current queue id 0\nViennaCL: Getting queue for device Intel(R) HD Graphics in context 0xbaa860\nViennaCL: Current queue id 0\nViennaCL: Getting queue for device Intel(R) HD Graphics in context 0xbaa860\nViennaCL: Current queue id 0\n*** Aborted at 1465841354 (unix time) try ""date -d @1465841354"" if you are using GNU date ***\nPC: @     0x7f2c735c1c03 caffe::ConvolutionLayerSpatial<>::verify_result()\n*** SIGSEGV (@0x275) received by PID 3065 (TID 0x7f2c73ad47c0) from PID 629; stack trace: ***\n    @     0x7f2c717f44a0 (unknown)\n    @     0x7f2c735c1c03 caffe::ConvolutionLayerSpatial<>::verify_result()\n    @     0x7f2c735c757b caffe::ConvolutionLayerSpatial<>::setup_convolution()\n    @     0x7f2c735c8170 caffe::ConvolutionLayerSpatial<>::Forward_gpu()\n    @     0x7f2c7334ce82 caffe::Net<>::ForwardFromTo()\n    @     0x7f2c7334cf87 caffe::Net<>::Forward()\n    @           0x41388e time()\n    @           0x40ebfb main\n    @     0x7f2c717df830 __libc_start_main\n    @           0x40f469 _start\n    @                0x0 (unknown)\nSegmentation fault (core dumped)\n']",[],0,0
70,caffe,3385,open,Always link to the local libcaffe.so under ./build/lib,"I was recently faced with a weird compilation error on my university's system, while trying to compile caffe on my home directory. The source of the error was that during the linking phase all files under the ""tools"" directory tried to link against an old caffe library installed system-wide in /usr/local/lib. To solve this issue I had to manually add ./build/lib to my Makefile.config's LIBRARY_DIRS variable, and make sure it was placed before /usr/local/lib.

While the above scenario might be very specific to my university, it still seems to be more correct to link against the local library of caffe under build/lib by default, either by changing Makefile.config.example or by changing the Makefile itself. I think the latter is the preferred option.
",,"['I have meet the same problem because I set the LD_LIBRARY_PATH which indicate to link old caffe library .Check your own system LD_LIBRARY_PATH,delete related may help...\n', ""The problem is that if caffe's library is installed in /usr/local/lib, and let's say you also work on a development version of caffe and you try to build any of the executables, then by default Caffe will link against the library in /usr/local/lib instead the local one in ./build/lib.\n"", ""Yeah, if libcaffe.so exist in /usr/local/lib, this problem may happen. When create libcaffe.so, system will search /usr/local/lib before the directory ./build/lib. Thus caffe's library (libcaffe.so) link wrong .\nI set this option LD_LIBRARY_PATH=${CAFFE_HOME}/.build/lib:$LD_LIBRARY_PATH ,all things down.\nMaybe you can also try to rename /usr/local/libcaffe.so to another name like /usr/local/libcaffe_bak.so then build your caffe. After that, rename /usr/local/libcaffe_bak.so back to /usr/local/libcaffe_bak.so .\n""]",[],[],0,0
71,caffe,5429,closed,make pycaffee error,"Please use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) for usage, installation, or modeling questions, or other requests for help.
_Do not post such requests to Issues._ Doing so interferes with the development of Caffe.

Please read the [guidelines for contributing](https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md) before submitting this issue.

### Issue summary


### Steps to reproduce

If you are having difficulty building Caffe or training a model, please ask the caffe-users mailing list. If you are reporting a build error that seems to be due to a bug in Caffe, please attach your build configuration (either Makefile.config or CMakeCache.txt) and the output of the make (or cmake) command.

### Your system configuration
Operating system:
Compiler:
CUDA version (if applicable):
CUDNN version (if applicable):
BLAS:
Python or MATLAB version (for pycaffe and matcaffe respectively):
",,"[""Hi, I have similar problem. I think it is some pathsetting issue. I have run successfully make all, make test, make runtest but when i run make pycaffe i get following error message to make pycaffee error \r\n\r\nyonatan@CECS4RMHRD2:~/Downloads/caffe-segnet-segnet-cleaned$ make pycaffe\r\nmake: *** No rule to make target 'include/caffe/layers/python_layer.hpp', needed by 'python/caffe/_caffe.so'.  Stop.\r\n\r\nany help"", 'From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\r\n\r\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\r\nUse the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.']",[],[],0,0
72,caffe,2307,closed,Unable to make caffe on MacOS 10.9,"MacOS 10.9, Cuda 6.5, Opencv 3.0, Anaconda
In Opencv 2.4.11 I was facing similar problem, solution was including library opencv_imgcodecs. But this was available only in opencv 3.0. But even after installing opencv 3.0.. I am getting same error, although in a different part. Any help appreciated.

It might seem there is a problem with leveldb, but all the environment variables in leveldb have -stdlib=libstdc++. So i can't figure out the problem.

PROTOC src/caffe/proto/caffe.proto
CXX src/caffe/blob.cpp
CXX src/caffe/common.cpp
CXX src/caffe/data_transformer.cpp
CXX src/caffe/internal_thread.cpp
CXX src/caffe/layer_factory.cpp
CXX src/caffe/layers/absval_layer.cpp
CXX src/caffe/layers/accuracy_layer.cpp
CXX src/caffe/layers/argmax_layer.cpp
CXX src/caffe/layers/base_conv_layer.cpp
CXX src/caffe/layers/base_data_layer.cpp
CXX src/caffe/layers/bnll_layer.cpp
CXX src/caffe/layers/concat_layer.cpp
CXX src/caffe/layers/contrastive_loss_layer.cpp
CXX src/caffe/layers/conv_layer.cpp
CXX src/caffe/layers/cudnn_conv_layer.cpp
CXX src/caffe/layers/cudnn_pooling_layer.cpp
CXX src/caffe/layers/cudnn_relu_layer.cpp
CXX src/caffe/layers/cudnn_sigmoid_layer.cpp
CXX src/caffe/layers/cudnn_softmax_layer.cpp
CXX src/caffe/layers/cudnn_tanh_layer.cpp
CXX src/caffe/layers/data_layer.cpp
CXX src/caffe/layers/deconv_layer.cpp
CXX src/caffe/layers/dropout_layer.cpp
CXX src/caffe/layers/dummy_data_layer.cpp
CXX src/caffe/layers/eltwise_layer.cpp
CXX src/caffe/layers/euclidean_loss_layer.cpp
CXX src/caffe/layers/exp_layer.cpp
CXX src/caffe/layers/flatten_layer.cpp
CXX src/caffe/layers/hdf5_data_layer.cpp
CXX src/caffe/layers/hdf5_output_layer.cpp
CXX src/caffe/layers/hinge_loss_layer.cpp
CXX src/caffe/layers/im2col_layer.cpp
CXX src/caffe/layers/image_data_layer.cpp
CXX src/caffe/layers/infogain_loss_layer.cpp
CXX src/caffe/layers/inner_product_layer.cpp
CXX src/caffe/layers/loss_layer.cpp
CXX src/caffe/layers/lrn_layer.cpp
CXX src/caffe/layers/memory_data_layer.cpp
CXX src/caffe/layers/multinomial_logistic_loss_layer.cpp
CXX src/caffe/layers/mvn_layer.cpp
CXX src/caffe/layers/neuron_layer.cpp
CXX src/caffe/layers/pooling_layer.cpp
CXX src/caffe/layers/power_layer.cpp
CXX src/caffe/layers/prelu_layer.cpp
CXX src/caffe/layers/relu_layer.cpp
CXX src/caffe/layers/sigmoid_cross_entropy_loss_layer.cpp
CXX src/caffe/layers/sigmoid_layer.cpp
CXX src/caffe/layers/silence_layer.cpp
CXX src/caffe/layers/slice_layer.cpp
CXX src/caffe/layers/softmax_layer.cpp
CXX src/caffe/layers/softmax_loss_layer.cpp
CXX src/caffe/layers/split_layer.cpp
CXX src/caffe/layers/tanh_layer.cpp
CXX src/caffe/layers/threshold_layer.cpp
CXX src/caffe/layers/window_data_layer.cpp
CXX src/caffe/net.cpp
CXX src/caffe/solver.cpp
CXX src/caffe/syncedmem.cpp
CXX src/caffe/util/benchmark.cpp
CXX src/caffe/util/cudnn.cpp
CXX src/caffe/util/db.cpp
CXX src/caffe/util/im2col.cpp
CXX src/caffe/util/insert_splits.cpp
CXX src/caffe/util/io.cpp
CXX src/caffe/util/math_functions.cpp
CXX src/caffe/util/upgrade_proto.cpp
NVCC src/caffe/layers/absval_layer.cu
NVCC src/caffe/layers/base_data_layer.cu
NVCC src/caffe/layers/bnll_layer.cu
NVCC src/caffe/layers/concat_layer.cu
NVCC src/caffe/layers/contrastive_loss_layer.cu
NVCC src/caffe/layers/conv_layer.cu
NVCC src/caffe/layers/cudnn_conv_layer.cu
NVCC src/caffe/layers/cudnn_pooling_layer.cu
NVCC src/caffe/layers/cudnn_relu_layer.cu
NVCC src/caffe/layers/cudnn_sigmoid_layer.cu
NVCC src/caffe/layers/cudnn_softmax_layer.cu
NVCC src/caffe/layers/cudnn_tanh_layer.cu
NVCC src/caffe/layers/deconv_layer.cu
NVCC src/caffe/layers/dropout_layer.cu
NVCC src/caffe/layers/eltwise_layer.cu
NVCC src/caffe/layers/euclidean_loss_layer.cu
NVCC src/caffe/layers/exp_layer.cu
NVCC src/caffe/layers/hdf5_data_layer.cu
NVCC src/caffe/layers/hdf5_output_layer.cu
NVCC src/caffe/layers/im2col_layer.cu
NVCC src/caffe/layers/inner_product_layer.cu
NVCC src/caffe/layers/lrn_layer.cu
NVCC src/caffe/layers/mvn_layer.cu
NVCC src/caffe/layers/pooling_layer.cu
NVCC src/caffe/layers/power_layer.cu
NVCC src/caffe/layers/prelu_layer.cu
NVCC src/caffe/layers/relu_layer.cu
NVCC src/caffe/layers/sigmoid_cross_entropy_loss_layer.cu
NVCC src/caffe/layers/sigmoid_layer.cu
NVCC src/caffe/layers/silence_layer.cu
NVCC src/caffe/layers/slice_layer.cu
NVCC src/caffe/layers/softmax_layer.cu
NVCC src/caffe/layers/softmax_loss_layer.cu
NVCC src/caffe/layers/split_layer.cu
NVCC src/caffe/layers/tanh_layer.cu
NVCC src/caffe/layers/threshold_layer.cu
NVCC src/caffe/util/im2col.cu
NVCC src/caffe/util/math_functions.cu
CXX tools/caffe.cpp
CXX tools/compute_image_mean.cpp
CXX tools/convert_imageset.cpp
CXX tools/device_query.cpp
CXX tools/extract_features.cpp
CXX tools/finetune_net.cpp
CXX tools/net_speed_benchmark.cpp
CXX tools/test_net.cpp
CXX tools/train_net.cpp
CXX tools/upgrade_net_proto_binary.cpp
CXX tools/upgrade_net_proto_text.cpp
CXX examples/cifar10/convert_cifar_data.cpp
CXX examples/mnist/convert_mnist_data.cpp
CXX examples/siamese/convert_mnist_siamese_data.cpp
CXX .build_release/src/caffe/proto/caffe.pb.cc
AR -o .build_release/lib/libcaffe.a
LD -o .build_release/lib/libcaffe.so
clang: warning: argument unused during compilation: '-pthread'
ld: warning: directory not found for option '-L/opt/intel/mkl/lib/intel64'
Undefined symbols for architecture x86_64:
  ""leveldb::DB::Open(leveldb::Options const&, std::string const&, leveldb::DB*_)"", referenced from:
      caffe::db::LevelDB::Open(std::string const&, caffe::db::Mode) in db.o
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: *_\* [.build_release/lib/libcaffe.so] Error 1
",,"['```\n# enable pretty build (comment to see full commands)\nQ ?= @\n```\n\nPlease comment/remove the above line in Makefile.config and compile again. It will show you the arguments and options you use in clang command.\n', '@tnarihi Thanks for the advice. \nAs I wasn\'t able to compile caffe with opencv 3. I reverted back to Opencv 2.4.11. And Cuda 7.0. Also all env flags have been reverted back to stdc++. Even now I am having similar problem. This is the command causing it-\n\n/usr/bin/clang++ -shared -o .build_release/lib/libcaffe.so .build_release/src/caffe/proto/caffe.pb.o .build_release/src/caffe/blob.o .build_release/src/caffe/common.o .build_release/src/caffe/data_transformer.o .build_release/src/caffe/internal_thread.o .build_release/src/caffe/layer_factory.o .build_release/src/caffe/layers/absval_layer.o .build_release/src/caffe/layers/accuracy_layer.o .build_release/src/caffe/layers/argmax_layer.o .build_release/src/caffe/layers/base_conv_layer.o .build_release/src/caffe/layers/base_data_layer.o .build_release/src/caffe/layers/bnll_layer.o .build_release/src/caffe/layers/concat_layer.o .build_release/src/caffe/layers/contrastive_loss_layer.o .build_release/src/caffe/layers/conv_layer.o .build_release/src/caffe/layers/cudnn_conv_layer.o .build_release/src/caffe/layers/cudnn_pooling_layer.o .build_release/src/caffe/layers/cudnn_relu_layer.o .build_release/src/caffe/layers/cudnn_sigmoid_layer.o .build_release/src/caffe/layers/cudnn_softmax_layer.o .build_release/src/caffe/layers/cudnn_tanh_layer.o .build_release/src/caffe/layers/data_layer.o .build_release/src/caffe/layers/deconv_layer.o .build_release/src/caffe/layers/dropout_layer.o .build_release/src/caffe/layers/dummy_data_layer.o .build_release/src/caffe/layers/eltwise_layer.o .build_release/src/caffe/layers/euclidean_loss_layer.o .build_release/src/caffe/layers/exp_layer.o .build_release/src/caffe/layers/flatten_layer.o .build_release/src/caffe/layers/hdf5_data_layer.o .build_release/src/caffe/layers/hdf5_output_layer.o .build_release/src/caffe/layers/hinge_loss_layer.o .build_release/src/caffe/layers/im2col_layer.o .build_release/src/caffe/layers/image_data_layer.o .build_release/src/caffe/layers/infogain_loss_layer.o .build_release/src/caffe/layers/inner_product_layer.o .build_release/src/caffe/layers/loss_layer.o .build_release/src/caffe/layers/lrn_layer.o .build_release/src/caffe/layers/memory_data_layer.o .build_release/src/caffe/layers/multinomial_logistic_loss_layer.o .build_release/src/caffe/layers/mvn_layer.o .build_release/src/caffe/layers/neuron_layer.o .build_release/src/caffe/layers/pooling_layer.o .build_release/src/caffe/layers/power_layer.o .build_release/src/caffe/layers/prelu_layer.o .build_release/src/caffe/layers/relu_layer.o .build_release/src/caffe/layers/sigmoid_cross_entropy_loss_layer.o .build_release/src/caffe/layers/sigmoid_layer.o .build_release/src/caffe/layers/silence_layer.o .build_release/src/caffe/layers/slice_layer.o .build_release/src/caffe/layers/softmax_layer.o .build_release/src/caffe/layers/softmax_loss_layer.o .build_release/src/caffe/layers/split_layer.o .build_release/src/caffe/layers/tanh_layer.o .build_release/src/caffe/layers/threshold_layer.o .build_release/src/caffe/layers/window_data_layer.o .build_release/src/caffe/net.o .build_release/src/caffe/solver.o .build_release/src/caffe/syncedmem.o .build_release/src/caffe/util/benchmark.o .build_release/src/caffe/util/cudnn.o .build_release/src/caffe/util/db.o .build_release/src/caffe/util/im2col.o .build_release/src/caffe/util/insert_splits.o .build_release/src/caffe/util/io.o .build_release/src/caffe/util/math_functions.o .build_release/src/caffe/util/upgrade_proto.o .build_release/cuda/src/caffe/layers/absval_layer.o .build_release/cuda/src/caffe/layers/base_data_layer.o .build_release/cuda/src/caffe/layers/bnll_layer.o .build_release/cuda/src/caffe/layers/concat_layer.o .build_release/cuda/src/caffe/layers/contrastive_loss_layer.o .build_release/cuda/src/caffe/layers/conv_layer.o .build_release/cuda/src/caffe/layers/cudnn_conv_layer.o .build_release/cuda/src/caffe/layers/cudnn_pooling_layer.o .build_release/cuda/src/caffe/layers/cudnn_relu_layer.o .build_release/cuda/src/caffe/layers/cudnn_sigmoid_layer.o .build_release/cuda/src/caffe/layers/cudnn_softmax_layer.o .build_release/cuda/src/caffe/layers/cudnn_tanh_layer.o .build_release/cuda/src/caffe/layers/deconv_layer.o .build_release/cuda/src/caffe/layers/dropout_layer.o .build_release/cuda/src/caffe/layers/eltwise_layer.o .build_release/cuda/src/caffe/layers/euclidean_loss_layer.o .build_release/cuda/src/caffe/layers/exp_layer.o .build_release/cuda/src/caffe/layers/hdf5_data_layer.o .build_release/cuda/src/caffe/layers/hdf5_output_layer.o .build_release/cuda/src/caffe/layers/im2col_layer.o .build_release/cuda/src/caffe/layers/inner_product_layer.o .build_release/cuda/src/caffe/layers/lrn_layer.o .build_release/cuda/src/caffe/layers/mvn_layer.o .build_release/cuda/src/caffe/layers/pooling_layer.o .build_release/cuda/src/caffe/layers/power_layer.o .build_release/cuda/src/caffe/layers/prelu_layer.o .build_release/cuda/src/caffe/layers/relu_layer.o .build_release/cuda/src/caffe/layers/sigmoid_cross_entropy_loss_layer.o .build_release/cuda/src/caffe/layers/sigmoid_layer.o .build_release/cuda/src/caffe/layers/silence_layer.o .build_release/cuda/src/caffe/layers/slice_layer.o .build_release/cuda/src/caffe/layers/softmax_layer.o .build_release/cuda/src/caffe/layers/softmax_loss_layer.o .build_release/cuda/src/caffe/layers/split_layer.o .build_release/cuda/src/caffe/layers/tanh_layer.o .build_release/cuda/src/caffe/layers/threshold_layer.o .build_release/cuda/src/caffe/util/im2col.o .build_release/cuda/src/caffe/util/math_functions.o -pthread -fPIC -DGTEST_USE_OWN_TR1_TUPLE=1 -DNDEBUG -O2 -DUSE_CUDNN -DWITH_PYTHON_LAYER -DUSE_MKL -I/Users/deepsamal/anaconda/include -I/Users/deepsamal/anaconda/include/python2.7 -I/Users/deepsamal/anaconda/lib/python2.7/site-packages/numpy/core/include -I/usr/local/include -I/Users/deepsamal/Desktop/Research/cudnn-6.5-osx-v2 -I.build_release/src -I./src -I./include -I/usr/local/cuda/include -I/opt/intel/mkl/include -Wall -Wno-sign-compare -Wno-unneeded-internal-declaration -L/Users/deepsamal/anaconda/lib -L/usr/local/lib -L/usr/lib -L/Users/deepsamal/Desktop/Research/cudnn-6.5-osx-v2 -L/usr/local/cuda/lib -L/opt/intel/mkl/lib -L.build_release/lib  -lcudart -lcublas -lcurand -lglog -lgflags -lprotobuf -lleveldb -lsnappy -llmdb -lboost_system -lhdf5_hl -lhdf5 -lm -lopencv_core -lopencv_highgui -lopencv_imgproc -lpthread -lboost_thread-mt -lcudnn -lboost_python -lpython2.7 -lmkl_rt -install_name @rpath/libcaffe.so\n\nclang: warning: argument unused during compilation: \'-pthread\'\nUndefined symbols for architecture x86_64:\n  ""google::protobuf::MessageLite::ParseFromString(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)"", referenced from:\n      caffe::DataLayer<float>::DataLayerSetUp(std::__1::vectorcaffe::Blob<float_, std::__1::allocatorcaffe::Blob<float_> > const&, std::__1::vectorcaffe::Blob<float_, std::__1::allocatorcaffe::Blob<float_> > const&) in data_layer.o\n      caffe::DataLayer<float>::InternalThreadEntry() in data_layer.o\n      caffe::DataLayer<double>::DataLayerSetUp(std::__1::vectorcaffe::Blob<double_, std::__1::allocatorcaffe::Blob<double_> > const&, std::__1::vectorcaffe::Blob<double_, std::__1::allocatorcaffe::Blob<double_> > const&) in data_layer.o\n      caffe::DataLayer<double>::InternalThreadEntry() in data_layer.o\n      caffe::Net<float>::Forward(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, float_) in net.o\n      caffe::Net<double>::Forward(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, double_) in net.o\n  ""google::protobuf::MessageFactory::InternalRegisterGeneratedFile(char const_, void (_)(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&))"", referenced from:\n      caffe::protobuf_AddDesc_caffe_2eproto() in caffe.pb.o\n  ""google::protobuf::internal::WireFormatLite::ReadString(google::protobuf::io::CodedInputStream_, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >_)"", referenced from:\n      caffe::FillerParameter::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream_) in caffe.pb.o\n      caffe::NetParameter::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream_) in caffe.pb.o\n      caffe::SolverParameter::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream_) in caffe.pb.o\n      caffe::SolverState::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream_) in caffe.pb.o\n      caffe::NetState::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream_) in caffe.pb.o\n      caffe::NetStateRule::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream_) in caffe.pb.o\n      caffe::ParamSpec::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream_) in caffe.pb.o\n      ...\n  ""google::protobuf::internal::WireFormatLite::WriteBytes(int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, google::protobuf::io::CodedOutputStream_)"", referenced from:\n      caffe::Datum::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream_) const in caffe.pb.o\n  ""google::protobuf::internal::WireFormatLite::WriteString(int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, google::protobuf::io::CodedOutputStream_)"", referenced from:\n      caffe::FillerParameter::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream_) const in caffe.pb.o\n      caffe::NetParameter::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream_) const in caffe.pb.o\n      caffe::SolverParameter::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream_) const in caffe.pb.o\n      caffe::SolverState::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream_) const in caffe.pb.o\n      caffe::NetState::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream_) const in caffe.pb.o\n      caffe::NetStateRule::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream_) const in caffe.pb.o\n      caffe::ParamSpec::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream_) const in caffe.pb.o\n      ...\n  ""google::protobuf::internal::WireFormatLite::ReadBytes(google::protobuf::io::CodedInputStream_, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >_)"", referenced from:\n      caffe::Datum::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream_) in caffe.pb.o\n  ""google::protobuf::internal::StringTypeHandlerBase::Delete(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >_)"", referenced from:\n      caffe::NetParameter::NetParameter(caffe::NetParameter const&) in caffe.pb.o\n      caffe::NetParameter::~NetParameter() in caffe.pb.o\n      caffe::SolverParameter::SolverParameter(caffe::SolverParameter const&) in caffe.pb.o\n      caffe::SolverParameter::~SolverParameter() in caffe.pb.o\n      caffe::NetState::NetState(caffe::NetState const&) in caffe.pb.o\n      caffe::NetState::~NetState() in caffe.pb.o\n      caffe::NetStateRule::NetStateRule(caffe::NetStateRule const&) in caffe.pb.o\n      ...\n  ""google::protobuf::MessageLite::SerializeToString(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >_) const"", referenced from:\n      caffe::Net<float>::Forward(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, float_) in net.o\n      caffe::Net<double>::Forward(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, double_) in net.o\n  ""google::protobuf::DescriptorPool::FindFileByName(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const"", referenced from:\n      caffe::protobuf_AssignDesc_caffe_2eproto() in caffe.pb.o\n  ""google::protobuf::Message::SerializeToOstream(std::__1::basic_ostream<char, std::__1::char_traits<char> >_) const"", referenced from:\n      caffe::WriteProtoToBinaryFile(google::protobuf::Message const&, char const_) in io.o\nld: symbol(s) not found for architecture x86_64\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\nmake: **\\* [.build_release/lib/libcaffe.so] Error 1\n.....................................................................................................................................................\n\nAlso I installed protobuf 2.5.0 instead of 2.6 in lieu with https://github.com/BVLC/caffe/issues/19 \nBut same error occurs. \nI also checked my /usr/local/lib/ for protobuf libraries, and these are the ones I could find-\nlibprotobuf-lite.8.dylib  libprotobuf-lite.dylib    libprotobuf.a             libprotoc.8.dylib         libprotoc.dylib  \nlibprotobuf-lite.a        libprotobuf.8.dylib       libprotobuf.dylib         libprotoc.a \n\nAny ideas if I am missing something?\n', ""@deepsamal \nYou revert back to libstdc++? Clang default option is libc++ in OS X 10.9+, and CUDA 7.0 now supports libc++, so I think you are recommended to compile with libc++ for all dependencies.\nThe last command you run doesn't include `-stdlib=` option (i.e. equivalent to with `-stdlib=libc++`) , so the problem seems that your protobuf library is compiled with libstdc++ rather than libc++.\n\nAccording to your log, your search paths of linked libraries are in order as below.\n\n```\n-L/Users/deepsamal/anaconda/lib -L/usr/local/lib -L/usr/lib -L/Users/deepsamal/Desktop/Research/cudnn-6.5-osx-v2 -L/usr/local/cuda/lib -L/opt/intel/mkl/lib -L.build_release/lib\n```\n\nAccordingly, locate protobuf libraries which you are linking to Caffe by using the following command.\n\n```\nlocate libprotobuf\n```\n\nThen,\n\n```\notool -L <path to libprotobuf which is found first in your search path>\n```\n\nI think this will show you which stdlib library you linked to libprotobuf (which you are trying to link to Caffe).\n\n#2286 #2258 #2018 I believe these are the same problem. The problem seems to be inconsistency related to libstdc++.\n"", ""@tnarihi Thanks a lot for the pointer. The issue was with protobuf. As I had installed a fresh copy of protobuf, one which didn't have ENV flags, I had assumed it will take the default flags i.e. clang and stdc++. But I had to add those lines mentioned in installation steps and change them to libc++.\nAlso there was one place in cuda.cmake where a variable use_stdcpp was set. So had to comment that.\nNow my make all, and make test are running fine. But getting segmentation fault in make runtest. \nBy running sudo make runtest... i get following output-\n.build_release/tools/caffe\ndyld: Library not loaded: @rpath/libcudart.7.0.dylib\n  Referenced from: /Users/deepsamal/Desktop/Research/caffe/.build_release/tools/caffe\n  Reason: image not found\nmake: **\\* [runtest] Trace/BPT trap: 5\n\nI know it might be unrelated, and therefore am closing this thread, but please inform me if you have any ideas on my problem. Thanks.\n"", 'I have the same problem. Here is the error message \n\n```\nUndefined symbols for architecture x86_64:\n  ""cv::imread(std::string const&, int)"", referenced from:\n      caffe::WindowDataLayer<float>::InternalThreadEntry() in window_data_layer.o\n      caffe::WindowDataLayer<double>::InternalThreadEntry() in window_data_layer.o\n      caffe::ReadImageToCVMat(std::string const&, int, int, bool) in io.o\n  ""cv::imencode(std::string const&, cv::_InputArray const&, std::vector<unsigned char, std::allocator<unsigned char> >&, std::vector<int, std::allocator<int> > const&)"", referenced from:\n      caffe::ReadImageToDatum(std::string const&, int, int, int, bool, std::string const&, caffe::Datum*) in io.o\n  ""google::protobuf::MessageLite::ParseFromString(std::string const&)"", referenced from:\n      caffe::DataLayer<float>::DataLayerSetUp(std::vector<caffe::Blob<float>*, std::allocator<caffe::Blob<float>*> > const&, std::vector<caffe::Blob<float>*, std::allocator<caffe::Blob<float>*> > const&) in data_layer.o\n      caffe::DataLayer<float>::InternalThreadEntry() in data_layer.o\n      caffe::DataLayer<double>::DataLayerSetUp(std::vector<caffe::Blob<double>*, std::allocator<caffe::Blob<double>*> > const&, std::vector<caffe::Blob<double>*, std::allocator<caffe::Blob<double>*> > const&) in data_layer.o\n      caffe::DataLayer<double>::InternalThreadEntry() in data_layer.o\n      caffe::Net<float>::Forward(std::string const&, float*) in net.o\n      caffe::Net<double>::Forward(std::string const&, double*) in net.o\n  ""google::protobuf::MessageFactory::InternalRegisterGeneratedFile(char const*, void (*)(std::string const&))"", referenced from:\n      caffe::protobuf_AddDesc_caffe_2eproto() in caffe.pb.o\n  ""google::protobuf::io::CodedOutputStream::WriteStringWithSizeToArray(std::string const&, unsigned char*)"", referenced from:\n      caffe::Datum::SerializeWithCachedSizesToArray(unsigned char*) const in caffe.pb.o\n      caffe::FillerParameter::SerializeWithCachedSizesToArray(unsigned char*) const in caffe.pb.o\n      caffe::NetParameter::SerializeWithCachedSizesToArray(unsigned char*) const in caffe.pb.o\n      caffe::SolverParameter::SerializeWithCachedSizesToArray(unsigned char*) const in caffe.pb.o\n      caffe::SolverState::SerializeWithCachedSizesToArray(unsigned char*) const in caffe.pb.o\n      caffe::NetState::SerializeWithCachedSizesToArray(unsigned char*) const in caffe.pb.o\n      caffe::NetStateRule::SerializeWithCachedSizesToArray(unsigned char*) const in caffe.pb.o\n      ...\n  ""google::protobuf::internal::WireFormatLite::ReadString(google::protobuf::io::CodedInputStream*, std::string*)"", referenced from:\n      caffe::FillerParameter::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in caffe.pb.o\n      caffe::NetParameter::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in caffe.pb.o\n      caffe::SolverParameter::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in caffe.pb.o\n      caffe::SolverState::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in caffe.pb.o\n      caffe::NetState::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in caffe.pb.o\n      caffe::NetStateRule::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in caffe.pb.o\n      caffe::ParamSpec::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in caffe.pb.o\n      ...\n  ""google::protobuf::internal::WireFormatLite::WriteString(int, std::string const&, google::protobuf::io::CodedOutputStream*)"", referenced from:\n      caffe::NetParameter::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in caffe.pb.o\n      caffe::SolverParameter::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in caffe.pb.o\n      caffe::NetState::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in caffe.pb.o\n      caffe::NetStateRule::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in caffe.pb.o\n      caffe::LayerParameter::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in caffe.pb.o\n      caffe::V1LayerParameter::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in caffe.pb.o\n  ""google::protobuf::internal::WireFormatLite::WriteBytesMaybeAliased(int, std::string const&, google::protobuf::io::CodedOutputStream*)"", referenced from:\n      caffe::Datum::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in caffe.pb.o\n  ""google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(int, std::string const&, google::protobuf::io::CodedOutputStream*)"", referenced from:\n      caffe::FillerParameter::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in caffe.pb.o\n      caffe::NetParameter::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in caffe.pb.o\n      caffe::SolverParameter::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in caffe.pb.o\n      caffe::SolverState::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in caffe.pb.o\n      caffe::ParamSpec::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in caffe.pb.o\n      caffe::LayerParameter::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in caffe.pb.o\n      caffe::TransformationParameter::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in caffe.pb.o\n      ...\n  ""google::protobuf::internal::WireFormatLite::ReadBytes(google::protobuf::io::CodedInputStream*, std::string*)"", referenced from:\n      caffe::Datum::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in caffe.pb.o\n  ""google::protobuf::internal::StringTypeHandlerBase::Delete(std::string*)"", referenced from:\n      caffe::NetParameter::NetParameter() in caffe.pb.o\n      caffe::NetParameter::NetParameter(caffe::NetParameter const&) in caffe.pb.o\n      caffe::NetParameter::~NetParameter() in caffe.pb.o\n      caffe::SolverParameter::SolverParameter() in caffe.pb.o\n      caffe::SolverParameter::SolverParameter(caffe::SolverParameter const&) in caffe.pb.o\n      caffe::SolverParameter::~SolverParameter() in caffe.pb.o\n      caffe::NetState::NetState() in caffe.pb.o\n      ...\n  ""leveldb::DB::Open(leveldb::Options const&, std::string const&, leveldb::DB**)"", referenced from:\n      caffe::db::LevelDB::Open(std::string const&, caffe::db::Mode) in db.o\n  ""google::protobuf::MessageLite::SerializeToString(std::string*) const"", referenced from:\n      caffe::Net<float>::Forward(std::string const&, float*) in net.o\n      caffe::Net<double>::Forward(std::string const&, double*) in net.o\n  ""google::protobuf::DescriptorPool::FindFileByName(std::string const&) const"", referenced from:\n      caffe::protobuf_AssignDesc_caffe_2eproto() in caffe.pb.o\n  ""google::protobuf::Message::SerializeToOstream(std::ostream*) const"", referenced from:\n      caffe::WriteProtoToBinaryFile(google::protobuf::Message const&, char const*) in io.o\nld: symbol(s) not found for architecture x86_64\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\nmake: *** [.build_release/lib/libcaffe.so] Error 1\nmake: *** Waiting for unfinished jobs....\n```\n\nI checked my `libprotobuf` @tnarihi \n\n```\n/usr/local/lib/libprotobuf.9.dylib:\n    /usr/local/lib/libprotobuf.9.dylib (compatibility version 10.0.0, current version 10.1.0)\n    /usr/lib/libz.1.dylib (compatibility version 1.0.0, current version 1.2.5)\n    /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 120.0.0)\n    /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1213.0.0)\n```\n\nIt seems already linked to libc++, not libstdc++.\nAny suggestions?\n', 'Seems I found the problem. Because my cuda7 was upgrade from cuda6.5 through system panel.\nnvcc -V still tell me 6.5\n', 'I have the same problem, I tried every method but it is no work; my error log as bellow:\r\nMacOS 10.12.6,  Opencv 2.7.14.0, Cuda and Anaconda is the latest version, I do not known how to \r\nget the Cuda and Anaconda version\r\n\r\n```\r\n  caffe git:(master) make all -j4\r\nPROTOC src/caffe/proto/caffe.proto\r\nCXX src/caffe/blob.cpp\r\nCXX src/caffe/common.cpp\r\nCXX src/caffe/data_transformer.cpp\r\nCXX src/caffe/internal_thread.cpp\r\nCXX src/caffe/layer.cpp\r\nCXX src/caffe/layer_factory.cpp\r\nCXX src/caffe/layers/absval_layer.cpp\r\nCXX src/caffe/layers/accuracy_layer.cpp\r\nCXX src/caffe/layers/argmax_layer.cpp\r\nCXX src/caffe/layers/base_conv_layer.cpp\r\nCXX src/caffe/layers/base_data_layer.cpp\r\nCXX src/caffe/layers/batch_norm_layer.cpp\r\nCXX src/caffe/layers/batch_reindex_layer.cpp\r\nCXX src/caffe/layers/bias_layer.cpp\r\nCXX src/caffe/layers/bnll_layer.cpp\r\nCXX src/caffe/layers/concat_layer.cpp\r\nCXX src/caffe/layers/contrastive_loss_layer.cpp\r\nCXX src/caffe/layers/conv_layer.cpp\r\nCXX src/caffe/layers/crop_layer.cpp\r\nCXX src/caffe/layers/cudnn_conv_layer.cpp\r\nCXX src/caffe/layers/cudnn_lcn_layer.cpp\r\nCXX src/caffe/layers/cudnn_lrn_layer.cpp\r\nCXX src/caffe/layers/cudnn_pooling_layer.cpp\r\nCXX src/caffe/layers/cudnn_relu_layer.cpp\r\nCXX src/caffe/layers/cudnn_sigmoid_layer.cpp\r\nCXX src/caffe/layers/cudnn_softmax_layer.cpp\r\nCXX src/caffe/layers/cudnn_tanh_layer.cpp\r\nCXX src/caffe/layers/data_layer.cpp\r\nCXX src/caffe/layers/deconv_layer.cpp\r\nCXX src/caffe/layers/dropout_layer.cpp\r\nIn file included from src/caffe/layers/crop_layer.cpp:10:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX src/caffe/layers/dummy_data_layer.cpp\r\nCXX src/caffe/layers/eltwise_layer.cpp\r\nCXX src/caffe/layers/elu_layer.cpp\r\nCXX src/caffe/layers/embed_layer.cpp\r\nCXX src/caffe/layers/euclidean_loss_layer.cpp\r\nCXX src/caffe/layers/exp_layer.cpp\r\nCXX src/caffe/layers/filter_layer.cpp\r\nCXX src/caffe/layers/flatten_layer.cpp\r\nCXX src/caffe/layers/hdf5_data_layer.cpp\r\nCXX src/caffe/layers/hdf5_output_layer.cpp\r\nCXX src/caffe/layers/hinge_loss_layer.cpp\r\nCXX src/caffe/layers/im2col_layer.cpp\r\nCXX src/caffe/layers/image_data_layer.cpp\r\nCXX src/caffe/layers/infogain_loss_layer.cpp\r\nCXX src/caffe/layers/inner_product_layer.cpp\r\nCXX src/caffe/layers/input_layer.cpp\r\nCXX src/caffe/layers/log_layer.cpp\r\nCXX src/caffe/layers/loss_layer.cpp\r\nCXX src/caffe/layers/lrn_layer.cpp\r\nCXX src/caffe/layers/lstm_layer.cpp\r\nCXX src/caffe/layers/lstm_unit_layer.cpp\r\nCXX src/caffe/layers/memory_data_layer.cpp\r\nCXX src/caffe/layers/multinomial_logistic_loss_layer.cpp\r\nIn file included from src/caffe/layers/lstm_layer.cpp:8:\r\nIn file included from ./include/caffe/layers/lstm_layer.hpp:11:\r\nIn file included from ./include/caffe/layers/recurrent_layer.hpp:11:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX src/caffe/layers/mvn_layer.cpp\r\nIn file included from src/caffe/layers/lstm_unit_layer.cpp:6:\r\nIn file included from ./include/caffe/layers/lstm_layer.hpp:11:\r\nIn file included from ./include/caffe/layers/recurrent_layer.hpp:11:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX src/caffe/layers/neuron_layer.cpp\r\nCXX src/caffe/layers/parameter_layer.cpp\r\nCXX src/caffe/layers/pooling_layer.cpp\r\nCXX src/caffe/layers/power_layer.cpp\r\nCXX src/caffe/layers/prelu_layer.cpp\r\nCXX src/caffe/layers/recurrent_layer.cpp\r\nCXX src/caffe/layers/reduction_layer.cpp\r\nCXX src/caffe/layers/relu_layer.cpp\r\nCXX src/caffe/layers/reshape_layer.cpp\r\nIn file included from src/caffe/layers/recurrent_layer.cpp:8:\r\nIn file included from ./include/caffe/layers/recurrent_layer.hpp:11:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX src/caffe/layers/rnn_layer.cpp\r\nCXX src/caffe/layers/scale_layer.cpp\r\nCXX src/caffe/layers/sigmoid_cross_entropy_loss_layer.cpp\r\nCXX src/caffe/layers/sigmoid_layer.cpp\r\nIn file included from src/caffe/layers/rnn_layer.cpp:8:\r\nIn file included from ./include/caffe/layers/rnn_layer.hpp:11:\r\nIn file included from ./include/caffe/layers/recurrent_layer.hpp:11:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX src/caffe/layers/silence_layer.cpp\r\nCXX src/caffe/layers/slice_layer.cpp\r\nCXX src/caffe/layers/softmax_layer.cpp\r\nCXX src/caffe/layers/softmax_loss_layer.cpp\r\nCXX src/caffe/layers/split_layer.cpp\r\nCXX src/caffe/layers/spp_layer.cpp\r\nCXX src/caffe/layers/tanh_layer.cpp\r\nCXX src/caffe/layers/threshold_layer.cpp\r\nCXX src/caffe/layers/tile_layer.cpp\r\nCXX src/caffe/layers/window_data_layer.cpp\r\nCXX src/caffe/net.cpp\r\nCXX src/caffe/parallel.cpp\r\nCXX src/caffe/solver.cpp\r\nCXX src/caffe/solvers/adadelta_solver.cpp\r\nIn file included from src/caffe/solvers/adadelta_solver.cpp:3:\r\nIn file included from ./include/caffe/sgd_solvers.hpp:7:\r\nIn file included from ./include/caffe/solver.hpp:7:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX src/caffe/solvers/adagrad_solver.cpp\r\nCXX src/caffe/solvers/adam_solver.cpp\r\nIn file included from src/caffe/solver.cpp:6:\r\nIn file included from ./include/caffe/solver.hpp:7:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX src/caffe/solvers/nesterov_solver.cpp\r\nIn file included from src/caffe/net.cpp:12:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\nsrc/caffe/net.cpp:557:3: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n  LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: Forward(bottom, loss) ""\r\n  ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n2 warnings generated.\r\nCXX src/caffe/solvers/rmsprop_solver.cpp\r\nIn file included from src/caffe/solvers/adagrad_solver.cpp:3:\r\nIn file included from ./include/caffe/sgd_solvers.hpp:7:\r\nIn file included from ./include/caffe/solver.hpp:7:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX src/caffe/solvers/sgd_solver.cpp\r\nIn file included from src/caffe/solvers/adam_solver.cpp:3:\r\nIn file included from ./include/caffe/sgd_solvers.hpp:7:\r\nIn file included from ./include/caffe/solver.hpp:7:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX src/caffe/syncedmem.cpp\r\nIn file included from src/caffe/solvers/nesterov_solver.cpp:3:\r\nIn file included from ./include/caffe/sgd_solvers.hpp:7:\r\nIn file included from ./include/caffe/solver.hpp:7:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX src/caffe/util/benchmark.cpp\r\nCXX src/caffe/util/blocking_queue.cpp\r\nIn file included from src/caffe/solvers/rmsprop_solver.cpp:3:\r\nIn file included from ./include/caffe/sgd_solvers.hpp:7:\r\nIn file included from ./include/caffe/solver.hpp:7:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX src/caffe/util/cudnn.cpp\r\nCXX src/caffe/util/db.cpp\r\nCXX src/caffe/util/db_leveldb.cpp\r\nCXX src/caffe/util/db_lmdb.cpp\r\nIn file included from src/caffe/solvers/sgd_solver.cpp:4:\r\nIn file included from ./include/caffe/sgd_solvers.hpp:7:\r\nIn file included from ./include/caffe/solver.hpp:7:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX src/caffe/util/hdf5.cpp\r\nCXX src/caffe/util/im2col.cpp\r\nCXX src/caffe/util/insert_splits.cpp\r\nsrc/caffe/util/blocking_queue.cpp:49:7: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n      LOG_EVERY_N(INFO, 1000)<< log_on_wait;\r\n      ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX src/caffe/util/io.cpp\r\nCXX src/caffe/util/math_functions.cpp\r\nCXX src/caffe/util/signal_handler.cpp\r\nCXX src/caffe/util/upgrade_proto.cpp\r\nCXX tools/caffe.cpp\r\nCXX tools/compute_image_mean.cpp\r\nIn file included from src/caffe/util/signal_handler.cpp:7:\r\nIn file included from ./include/caffe/util/signal_handler.h:5:\r\nIn file included from ./include/caffe/solver.hpp:7:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX tools/convert_imageset.cpp\r\nCXX tools/device_query.cpp\r\nCXX tools/extract_features.cpp\r\nCXX tools/finetune_net.cpp\r\nCXX tools/net_speed_benchmark.cpp\r\nIn file included from tools/caffe.cpp:15:\r\nIn file included from ./include/caffe/caffe.hpp:12:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX tools/test_net.cpp\r\nIn file included from tools/finetune_net.cpp:1:\r\nIn file included from ./include/caffe/caffe.hpp:12:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX tools/train_net.cpp\r\nIn file included from tools/extract_features.cpp:9:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX tools/upgrade_net_proto_binary.cpp\r\nIn file included from tools/net_speed_benchmark.cpp:1:\r\nIn file included from ./include/caffe/caffe.hpp:12:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX tools/upgrade_net_proto_text.cpp\r\nIn file included from tools/test_net.cpp:1:\r\nIn file included from ./include/caffe/caffe.hpp:12:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX tools/upgrade_solver_proto_text.cpp\r\nIn file included from tools/train_net.cpp:1:\r\nIn file included from ./include/caffe/caffe.hpp:12:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX examples/cifar10/convert_cifar_data.cpp\r\nIn file included from tools/upgrade_net_proto_binary.cpp:10:\r\nIn file included from ./include/caffe/caffe.hpp:12:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX examples/cpp_classification/classification.cpp\r\nIn file included from tools/upgrade_net_proto_text.cpp:10:\r\nIn file included from ./include/caffe/caffe.hpp:12:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX examples/mnist/convert_mnist_data.cpp\r\nCXX examples/siamese/convert_mnist_siamese_data.cpp\r\nIn file included from tools/upgrade_solver_proto_text.cpp:10:\r\nIn file included from ./include/caffe/caffe.hpp:12:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nCXX .build_release/src/caffe/proto/caffe.pb.cc\r\nIn file included from examples/cpp_classification/classification.cpp:1:\r\nIn file included from ./include/caffe/caffe.hpp:12:\r\n./include/caffe/net.hpp:41:5: warning: unused typedef \'INVALID_REQUESTED_LOG_SEVERITY\' [-Wunused-local-typedef]\r\n    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""\r\n    ^\r\n/Users/chenxingyi/anaconda2/include/glog/logging.h:943:30: note: expanded from macro \'LOG_EVERY_N\'\r\n                             INVALID_REQUESTED_LOG_SEVERITY);           \\\r\n                             ^\r\n1 warning generated.\r\nAR -o .build_release/lib/libcaffe.a\r\nLD -o .build_release/lib/libcaffe.so.1.0.0\r\nclang: warning: argument unused during compilation: \'-pthread\' [-Wunused-command-line-argument]\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn_conv_layer.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn_lcn_layer.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn_lrn_layer.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn_pooling_layer.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn_relu_layer.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn_sigmoid_layer.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn_softmax_layer.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn_tanh_layer.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(parallel.o) has no symbols\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn.o) has no symbols\r\nUndefined symbols for architecture x86_64:\r\n  ""cv::imread(cv::String const&, int)"", referenced from:\r\n      caffe::WindowDataLayer<float>::load_batch(caffe::Batch<float>*) in window_data_layer.o\r\n      caffe::WindowDataLayer<double>::load_batch(caffe::Batch<double>*) in window_data_layer.o\r\n      caffe::ReadImageToCVMat(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, int, bool) in io.o\r\n  ""cv::imdecode(cv::_InputArray const&, int)"", referenced from:\r\n      caffe::DecodeDatumToCVMatNative(caffe::Datum const&) in io.o\r\n      caffe::DecodeDatumToCVMat(caffe::Datum const&, bool) in io.o\r\n  ""cv::imencode(cv::String const&, cv::_InputArray const&, std::__1::vector<unsigned char, std::__1::allocator<unsigned char> >&, std::__1::vector<int, std::__1::allocator<int> > const&)"", referenced from:\r\n      caffe::ReadImageToDatum(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, int, int, bool, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, caffe::Datum*) in io.o\r\n  ""leveldb::DB::Open(leveldb::Options const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, leveldb::DB**)"", referenced from:\r\n      caffe::db::LevelDB::Open(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, caffe::db::Mode) in db_leveldb.o\r\nld: symbol(s) not found for architecture x86_64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nmake: *** [.build_release/lib/libcaffe.so.1.0.0] Error 1\r\nmake: *** Waiting for unfinished jobs....\r\n```\r\n\r\nAny one can help me ?', '@cxy200927099 I am having exactly the same issue. 10.11.5, Homebrew dependencies including ` opencv-3.4.0_1.el_capitan.bottle.tar.gz`\r\n\r\nA hint to the solution is given here: https://stackoverflow.com/a/27904334/173515\r\n\r\nAdd `OPENCV_VERSION` to your `Makefile.config`, e.g.:\r\n\r\n```\r\n...\r\n# uncomment to disable IO dependencies and corresponding data layers\r\n# USE_OPENCV := 0\r\nOPENCV_VERSION := 3\r\n...\r\n```\r\n\r\nThat fixed the link problem vs opencv for me.', '@toby5box thanks for reply, I use the docker on my macOS, And it works ']",[],[],0,0
73,caffe,351,closed,compling error of common.cpp in dev branch,"I don't have MKL so need to check the dev brach...
""Make"" gives this error:
/usr/bin/g++ src/caffe/common.cpp -pthread -fPIC -DNDEBUG -O2 -I/usr/local/include/python2.7 -I/usr/local/lib/python2.7/dist-packages/numpy/core/include -I/usr/local/include -Ibuild/src -I./src -I./include -I/usr/local/cuda/include -c -o build/src/caffe/common.o
src/caffe/common.cpp: In function const char\* caffe::curandGetErrorString(curandStatus_t):
src/caffe/common.cpp:178:8: error: CURAND_STATUS_DOUBLE_PRECISION_REQUIRED was not declared in this scope
make: **\* [build/src/caffe/common.o] Error 1

Anyone has a clue?
Thanks and regards
",,"['ok its a stupid question without googling\n', ""@naxingyu  Well, I met this problem and haven't found the solution after googling it...Could you please share your way to solve this problem?Thanks a lot!!\n"", ""@wusx11 My CUDA version is 3 and CURAND_STATUS_DOUBLE_PRECISION_REQUIRED is not declared. It should be defined in current versions, say 5.5 or 6. I don't know if you have the same issue.\n""]",[],[],0,0
74,caffe,58,closed,"Crash after the iteration 1620. Check failed,cublasSgemm","I  run with the caffe for training my dataset. But after the iteration 1620, the program crushed in the cublasSgemm. The log is listed as following, Can you give some advices for fixing this error? 

I0127 14:31:22.608165 19425 solver.cpp:204] Iteration 1580, lr = 0.01
I0127 14:31:22.609833 19425 solver.cpp:66] Iteration 1580, loss = 0.0217456
I0127 14:31:49.345432 19425 solver.cpp:204] Iteration 1600, lr = 0.01
I0127 14:31:49.347100 19425 solver.cpp:66] Iteration 1600, loss = 0.0122987
I0127 14:32:16.079083 19425 solver.cpp:204] Iteration 1620, lr = 0.01
I0127 14:32:16.080762 19425 solver.cpp:66] Iteration 1620, loss = 1.67767
F0127 14:32:39.484519 19425 math_functions.cpp:45] Check failed: (cublasSgemm_v2(Caffe::cublas_handle(), cuTransB, cuTransA, N, M, K, &alpha, B, ldb, A, lda, &beta, C, N)) == CUBLAS_STATUS_SUCCESS (14 vs. 0) 
**\* Check failure stack trace: ***
    @     0x7fa69de70b7d  google::LogMessage::Fail()
    @     0x7fa69de72c7f  google::LogMessage::SendToLog()
    @     0x7fa69de7076c  google::LogMessage::Flush()
    @     0x7fa69de7351d  google::LogMessageFatal::~LogMessageFatal()
    @           0x42ee79  caffe::caffe_gpu_gemm<>()
    @           0x45f7e2  caffe::ConvolutionLayer<>::Backward_gpu()
    @           0x42770b  caffe::Net<>::Backward()
    @           0x421278  caffe::Solver<>::Solve()
    @           0x40d055  main
",compatibility downstream problem? duplicate,"['Please let us know your OS, GPU, and CUDA version. We have not encountered such errors training on Titans and K20s.\n\nThis is a possible duplicate of #39 where the cublasSgemm check fails too.\n', 'My version is Ubuntu 12.04 LTS with GeForce GTX Titan, CUDA 5.5. Thanks a lot.\n', 'Based on similar issues, this is most likely a GPU configuration problem. Check your driver, bios, fan speed, etc. Good luck.\n']",[],[],0,0
75,caffe,54,closed,Implement Matrix class to abstract algorithms away from data storage details,"Currently, the algorithm codes are quite aware of the memory layout of the underlying data. Adding a Matrix class in-between helps separate concerns of different modules which is a good practice in software engineering. 

The biggest benefit is to simplify coding and improve the development productivity. It will also ease understanding of the existing and future algorithms. As a result, we will see accelerated development and adoption progresses.

The Matrix class is intended to be a view of 2D array contained in a Blob. Its main functionality is to provide high level wrappers of the common operations.



So that we can write like codes like the following snippets.
The convolution:



The fully connected layer:



The ReLU activation:



The Softmax activation



As you can see, the API is highly inspired by MATLAB which also motivates ArrayFire C++. But of course the snippets are only rough sketches. Many more details need to be considered. For example, if the performance price of boost move operations is too high, it could be replaced by shared_ptr which would complicate the user codes a little. Another question is should we pass in the shared_ptr of the result matrix instead of returning it. More importantly, the GPU codes may greatly differ from the CPU codes depending on whether CUDA can play well with the proposed API syntax. 

Therefore, this issue's scope is limited to the implementation of the Matrix classes for both kinds of devices. Porting algorithms should be put into independent issues until benchmark results show no performance gap between the low level API and the proposed high level API.

Welcome efforts to refine the API and help implement it.
",wontfix,"['I am in general against writing a matrix class, or using an existing matrix\nclass (in which case it would be very tricky to synchronize CPU and GPU\noperations). What we essentially should need is a Tensor class that\nachieves 4-dimensional array operations, but that involves some substantial\nchanges to more than half of the code.\n\nI am also a little against Matlab style implementations. For example, the\ncode:\n\nactivations = input.exp();\nprobs = activations.rdiv(activations.sum(dim));\n\neffectively allocates two arrays, activations and probs, and then discards\nthem on the fly. Of course this could be written in a more careful way by\npreallocating arrays, like exp(input, &activation), but it would introduce\ncareless codes more often. The current code actually requires you to\nexplicitly define such ""buffer"" blobs, which I believe is important in\nwriting effectively codes.\n\nI do like the idea of separating interface from actual implementations. The\nBlob class is sort of halfway here - I was in a fast iteration when writing\nall those codes, but one can imaging better separation between the blob\noperation interfaces and the actual blob implementations (e.g. do\nadd(blob1, blob2), or conv(blob1, blob2)), which is essentially what you\nare proposing here. At this stage, I don\'t think refactoring is an urgent\nissue though.\n\nYangqing\n\nOn Thu, Jan 23, 2014 at 9:20 PM, kloudkl notifications@github.com wrote:\n\n> Currently, the algorithm codes are quite aware of the memory layout of the\n> underlying data. Adding a Matrix class in-between helps seperate concerns\n> of different modules which is a good practice in software engineering.\n> \n> The biggest benefits is to simplify coding and improve the development\n> productivity. It will also ease understanding of the existing and future\n> algorithms. As a result, we will see accelerate the development and\n> adoption progress.\n> \n> The Matrix class is intended to be a view of 2D array contained in a Blob.\n> Its main functionality is to provide high level wrapper of the common\n> operations.\n> \n> using boost::move;\n> template<Dtype>class Matrix {public:\n>   Matrix();\n>   Matrix(shared_ptr<Blob<Dtype> > blob);\n>   Matrix<Dtype> mul(Matrix<Dtype>& that) {\n>     Matrix<Dtype> product;\n>     caffe_gpu_gemm(...);\n>     return move(product);\n>   }\n>   Matrix<Dtype> add(Matrix<Dtype>& that);\n>   minus, div, rdiv, sqr, pow, exp, conv, sum, max, min, mean, std, ones, zeros, rand, randn, size, rows, cols, row, col, roi, t/transpose, rot90, ...private:\n>   shared_ptr<Blob<Dtype> > blob_;\n>   size_t num_;\n>   size_t channel_;\n>   size_t offset_;}\n> \n> So that we can write like codes like the following snippets.\n> The convolution:\n> \n> output = image.conv(filter);\n> \n> The fully connected layer:\n> \n> output = weight.mul(input).add(bias);\n> \n> The ReLU activation:\n> \n> activation = input.max(0);\n> \n> The Softmax activation\n> \n> activations = input.exp();probs = activations.rdiv(activations.sum(dim));\n> \n> As you can see, the API is highly inspired by the MATLAB counterparts\n> which also motivates ArrayFire C++. But of course the snippets are only a\n> rough sketch. Many more details need to be considered. For example, if the\n> performance price of boost move operations is too high, it could be replace\n> by shared_ptr which would complicate the user codes a little. Another\n> question is should we pass in the shared_ptr of the result matrix instead\n> of returning it. More importantly, the GPU codes may greatly differ from\n> the CPU codes depending on whether CUDA can play well with the proposed API\n> syntax.\n> \n> Therefore, this issue\'s scope is limited to the implementation of the\n> Matrix classes for both kinds of devices. Porting algorithms should be\n> delayed until benchmark results shows no performance gap between the low\n> level API and the proposed high level ones.\n> \n> Welcome efforts to refine the APIs and help implement them.\n> \n> ## \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/BVLC/caffe/issues/54\n> .\n', ""Thanks for your suggestions! In a larger context of this proposal, I am wondering for a while what are the vision, scope, dos with priorities and dont's of Caffe? If you have a plan that can direct the community towards a shared destination, it would concentrate the limited resources out there and lead to more effective development and wider adoption in the near future.\n"", 'Closed per #85.\n']","[' cpp\nusing boost::move;\n\ntemplate<Dtype>\nclass Matrix {\npublic:\n  Matrix();\n  Matrix(shared_ptr<Blob<Dtype> > blob);\n  Matrix<Dtype> mul(Matrix<Dtype>& that) {\n    Matrix<Dtype> product;\n    caffe_gpu_gemm(...);\n    return move(product);\n  }\n  Matrix<Dtype> add(Matrix<Dtype>& that);\n  minus, div, rdiv, sqr, pow, exp, conv, sum, max, min, mean, std, ones, zeros, rand, randn, size, rows, cols, row, col, roi, t/transpose, rot90, ...\nprivate:  \n  shared_ptr<Blob<Dtype> > blob_;\n  size_t num_;\n  size_t channel_;\n  size_t offset_;\n}\n', ' cpp\noutput = image.conv(filter);\n', ' cpp\noutput = weight.mul(input).add(bias);\n', ' cpp\nactivation = input.max(0);\n', ' cpp\nactivations = input.exp();\nprobs = activations.rdiv(activations.sum(dim));\n']",[],0,0
76,caffe,6325,closed,"ERROR: Make all, CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD was not declared in this scope","
Please read the [guidelines for contributing](https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md) before submitting this issue.

### Issue summary
Error after: sudo make all -j8


###  System configuration
Operating system: Linux Mint (based on Ubuntu version 16.04)
Compiler:
CUDA version (if applicable): 8.0
CUDNN version (if applicable): 7.0",,"['This is weird. Your compiler version would be good to know, as well as detailed version of cuDNN (look for CUDNN_MAJOR, CUDNN_MINOR and CUDNN_PATCHLEVEL in the cudnn.h file). Also, please attach your Makefile.config.', '**Compiler version:**\r\n\r\n**#define CUDNN_MAJOR      4\r\n#define CUDNN_MINOR      0\r\n#define CUDNN_PATCHLEVEL 7**\r\n\r\n\r\n**Makefile.config:**\r\nhttps://pastebin.com/7SsZpuLc\r\n\r\n\r\n\r\nPS: I just followed the installation guide here. I installed caffe 8.0 instead of 9 because I want to copy what the tutorial did as much as possible. \r\nhttps://chunml.github.io/ChunML.github.io/project/Installing-Caffe-Ubuntu/', '- ii  g++                                         4:5.3.1-1ubuntu1                             amd64        GNU C++ compiler\r\n- ii  g++-5                                       5.4.0-6ubuntu1~16.04.9                       amd64        GNU C++ compiler\r\n- ii  gcc                                         4:5.3.1-1ubuntu1                             amd64        GNU C compiler\r\n- ii  gcc-5                                       5.4.0-6ubuntu1~16.04.9                       amd64        GNU C compiler\r\n- ii  gfortran                                    4:5.3.1-1ubuntu1                             amd64        GNU Fortran 95 compiler\r\n- ii  gfortran-5                                  5.4.0-6ubuntu1~16.04.9                       amd64        GNU Fortran compiler\r\n- ii  hardening-includes                          2.7ubuntu2                                   all          Makefile for enabling compiler flags for security hardening\r\n- ii  libllvm4.0:amd64                            1:4.0-1ubuntu1~16.04.2                       amd64        Modular compiler and toolchain technologies, runtime library\r\n- ii  libprotoc9v5:amd64                          2.6.1-1.3                                    amd64        protocol buffers compiler library\r\n- ii  libxkbcommon0:amd64                         0.5.0-1ubuntu2                               amd64        library interface to the XKB compiler - shared library\r\n- ii  protobuf-compiler                           2.6.1-1.3                                    amd64        compiler for protocol buffer definition files\r\n-\r\n\r\n\r\nIs my information enough? Thank you for your help. ', ""```\r\n#define CUDNN_MAJOR 4\r\n#define CUDNN_MINOR 0\r\n#define CUDNN_PATCHLEVEL 7\r\n```\r\nIt looks like you're not actually using cuDNN 7 - this header reports version 4.0.7; I recommend a full cuDNN update."", 'I downloaded cudnn-8.0 and installed it again. I checked the cudnn file and it is now updated. I got another error \r\n``.build_release/lib/libcaffe.so: undefined reference to `cv::imread(cv::String const&, int)``\r\n\r\nI resolved it by uncommenting the OPENCV 3.0 line in the Makeconfig file. \r\n\r\nI followed the instructions and I got it running!\r\nThank you so much. :)', 'Glad you managed to sort it out :)', ""I am gettign this error. I tried to uncomment the opencv 3.0 line and had tried to put 4 instead .\r\nbut nothing works\r\n\r\ncan somebody solve this problem..\r\n\r\nthanks in advance\r\n\r\nCXX/LD -o .build_release/tools/extract_features.bin\r\nCXX/LD -o .build_release/tools/caffe.bin\r\nCXX/LD -o .build_release/tools/upgrade_net_proto_binary.bin\r\nCXX/LD -o .build_release/tools/compute_image_mean.bin\r\n.build_release/lib/libcaffe.so: undefined reference to `cv::imread(cv::String const&, int)'\r\n.build_release/lib/libcaffe.so: undefined reference to `cv::String::allocate(unsigned long)'\r\n.build_release/lib/libcaffe.so: undefined reference to `cv::String::deallocate()'\r\n.build_release/lib/libcaffe.so: undefined reference to `cv::imencode(cv::String const&, cv::_InputArray const&, std::vector<unsigned char, std::allocator<unsigned char> >&, std::vector<int, std::allocator<int> > const&)'\r\ncollect2: error: ld returned 1 exit status\r\nMakefile:650: recipe for target '.build_release/tools/upgrade_net_proto_binary.bin' failed\r\nmake: *** [.build_release/tools/upgrade_net_proto_binary.bin] Error 1\r\nmake: *** Waiting for unfinished jobs....\r\n.build_release/lib/libcaffe.so: undefined reference to `cv::imread(cv::String const&, int)'\r\n.build_release/lib/libcaffe.so: undefined reference to `cv::String::allocate(unsigned long)'\r\n.build_release/lib/libcaffe.so: undefined reference to `cv::String::deallocate()'\r\n.build_release/lib/libcaffe.so: undefined reference to `cv::imencode(cv::String const&, cv::_InputArray const&, std::vector<unsigned char, std::allocator<unsigned char> >&, std::vector<int, std::allocator<int> > const&)'\r\ncollect2: error: ld returned 1 exit status\r\nMakefile:650: recipe for target '.build_release/tools/compute_image_mean.bin' failed\r\nmake: *** [.build_release/tools/compute_image_mean.bin] Error 1\r\n.build_release/lib/libcaffe.so: undefined reference to `cv::imread(cv::String const&, int)'\r\n.build_release/lib/libcaffe.so: undefined reference to `cv::String::allocate(unsigned long)'\r\n.build_release/lib/libcaffe.so: undefined reference to `cv::String::deallocate()'\r\n.build_release/lib/libcaffe.so: undefined reference to `cv::imencode(cv::String const&, cv::_InputArray const&, std::vector<unsigned char, std::allocator<unsigned char> >&, std::vector<int, std::allocator<int> > const&)'\r\ncollect2: error: ld returned 1 exit status\r\nMakefile:650: recipe for target '.build_release/tools/extract_features.bin' failed\r\nmake: *** [.build_release/tools/extract_features.bin] Error 1\r\n.build_release/lib/libcaffe.so: undefined reference to `cv::imread(cv::String const&, int)'\r\n.build_release/lib/libcaffe.so: undefined reference to `cv::String::allocate(unsigned long)'\r\n.build_release/lib/libcaffe.so: undefined reference to `cv::String::deallocate()'\r\n.build_release/lib/libcaffe.so: undefined reference to `cv::imencode(cv::String const&, cv::_InputArray const&, std::vector<unsigned char, std::allocator<unsigned char> >&, std::vector<int, std::allocator<int> > const&)'\r\ncollect2: error: ld returned 1 exit status\r\nMakefile:650: recipe for target '.build_release/tools/caffe.bin' failed\r\nmake: *** [.build_release/tools/caffe.bin] Error 1\r\n""]","[""\r\nsudo make all -j8\r\nPROTOC src/caffe/proto/caffe.proto\r\nNVCC src/caffe/util/im2col.cu\r\nNVCC src/caffe/util/math_functions.cu\r\nNVCC src/caffe/solvers/nesterov_solver.cu\r\nNVCC src/caffe/solvers/adadelta_solver.cu\r\nNVCC src/caffe/solvers/sgd_solver.cu\r\nNVCC src/caffe/solvers/adam_solver.cu\r\nNVCC src/caffe/solvers/adagrad_solver.cu\r\nNVCC src/caffe/solvers/rmsprop_solver.cu\r\nNVCC src/caffe/layers/swish_layer.cu\r\nNVCC src/caffe/layers/hdf5_output_layer.cu\r\nNVCC src/caffe/layers/eltwise_layer.cu\r\nNVCC src/caffe/layers/cudnn_conv_layer.cu\r\nNVCC src/caffe/layers/split_layer.cu\r\nNVCC src/caffe/layers/accuracy_layer.cu\r\nNVCC src/caffe/layers/silence_layer.cu\r\nNVCC src/caffe/layers/im2col_layer.cu\r\nNVCC src/caffe/layers/sigmoid_layer.cu\r\nNVCC src/caffe/layers/batch_reindex_layer.cu\r\nNVCC src/caffe/layers/power_layer.cu\r\nNVCC src/caffe/layers/elu_layer.cu\r\nNVCC src/caffe/layers/conv_layer.cu\r\nNVCC src/caffe/layers/cudnn_pooling_layer.cu\r\nNVCC src/caffe/layers/scale_layer.cu\r\nNVCC src/caffe/layers/inner_product_layer.cu\r\nNVCC src/caffe/layers/cudnn_tanh_layer.cu\r\nNVCC src/caffe/layers/bnll_layer.cu\r\nNVCC src/caffe/layers/pooling_layer.cu\r\nNVCC src/caffe/layers/batch_norm_layer.cu\r\nNVCC src/caffe/layers/cudnn_sigmoid_layer.cu\r\nNVCC src/caffe/layers/dropout_layer.cu\r\nNVCC src/caffe/layers/absval_layer.cu\r\nNVCC src/caffe/layers/deconv_layer.cu\r\nNVCC src/caffe/layers/cudnn_lrn_layer.cu\r\nNVCC src/caffe/layers/slice_layer.cu\r\nNVCC src/caffe/layers/lstm_unit_layer.cu\r\nNVCC src/caffe/layers/softmax_loss_layer.cu\r\nNVCC src/caffe/layers/recurrent_layer.cu\r\nNVCC src/caffe/layers/filter_layer.cu\r\nNVCC src/caffe/layers/base_data_layer.cu\r\nNVCC src/caffe/layers/reduction_layer.cu\r\nNVCC src/caffe/layers/crop_layer.cu\r\nNVCC src/caffe/layers/relu_layer.cu\r\nNVCC src/caffe/layers/embed_layer.cu\r\nNVCC src/caffe/layers/exp_layer.cu\r\nNVCC src/caffe/layers/mvn_layer.cu\r\nNVCC src/caffe/layers/cudnn_softmax_layer.cu\r\nNVCC src/caffe/layers/cudnn_deconv_layer.cu\r\nNVCC src/caffe/layers/tanh_layer.cu\r\nNVCC src/caffe/layers/softmax_layer.cu\r\nNVCC src/caffe/layers/cudnn_relu_layer.cu\r\nNVCC src/caffe/layers/tile_layer.cu\r\nNVCC src/caffe/layers/threshold_layer.cu\r\nNVCC src/caffe/layers/euclidean_loss_layer.cu\r\nNVCC src/caffe/layers/lrn_layer.cu\r\nNVCC src/caffe/layers/cudnn_lcn_layer.cu\r\nNVCC src/caffe/layers/bias_layer.cu\r\nNVCC src/caffe/layers/contrastive_loss_layer.cu\r\nNVCC src/caffe/layers/concat_layer.cu\r\nNVCC src/caffe/layers/sigmoid_cross_entropy_loss_layer.cu\r\nNVCC src/caffe/layers/hdf5_data_layer.cu\r\nNVCC src/caffe/layers/log_layer.cu\r\nNVCC src/caffe/layers/prelu_layer.cu\r\nCXX tools/extract_features.cpp\r\nCXX tools/upgrade_net_proto_binary.cpp\r\nCXX tools/upgrade_net_proto_text.cpp\r\nCXX tools/compute_image_mean.cpp\r\nCXX tools/caffe.cpp\r\nCXX tools/upgrade_solver_proto_text.cpp\r\nCXX tools/convert_imageset.cpp\r\nCXX examples/cifar10/convert_cifar_data.cpp\r\nCXX examples/cpp_classification/classification.cpp\r\nCXX examples/mnist/convert_mnist_data.cpp\r\nCXX examples/siamese/convert_mnist_siamese_data.cpp\r\nCXX .build_release/src/caffe/proto/caffe.pb.cc\r\nCXX src/caffe/layer.cpp\r\nCXX src/caffe/internal_thread.cpp\r\nCXX src/caffe/net.cpp\r\nCXX src/caffe/common.cpp\r\nCXX src/caffe/blob.cpp\r\nCXX src/caffe/data_transformer.cpp\r\nCXX src/caffe/layer_factory.cpp\r\nCXX src/caffe/util/math_functions.cpp\r\nCXX src/caffe/util/io.cpp\r\nCXX src/caffe/util/db_lmdb.cpp\r\nCXX src/caffe/util/im2col.cpp\r\nCXX src/caffe/util/insert_splits.cpp\r\nCXX src/caffe/util/db.cpp\r\nCXX src/caffe/util/upgrade_proto.cpp\r\nCXX src/caffe/util/blocking_queue.cpp\r\nCXX src/caffe/util/signal_handler.cpp\r\nCXX src/caffe/util/db_leveldb.cpp\r\nCXX src/caffe/util/benchmark.cpp\r\nCXX src/caffe/util/cudnn.cpp\r\nCXX src/caffe/util/hdf5.cpp\r\nCXX src/caffe/syncedmem.cpp\r\nCXX src/caffe/solvers/adadelta_solver.cpp\r\nCXX src/caffe/solvers/adam_solver.cpp\r\nCXX src/caffe/solvers/rmsprop_solver.cpp\r\nCXX src/caffe/solvers/nesterov_solver.cpp\r\nCXX src/caffe/solvers/sgd_solver.cpp\r\nCXX src/caffe/solvers/adagrad_solver.cpp\r\nCXX src/caffe/parallel.cpp\r\nCXX src/caffe/solver.cpp\r\nCXX src/caffe/layers/flatten_layer.cpp\r\nCXX src/caffe/layers/concat_layer.cpp\r\nCXX src/caffe/layers/crop_layer.cpp\r\nCXX src/caffe/layers/spp_layer.cpp\r\nCXX src/caffe/layers/multinomial_logistic_loss_layer.cpp\r\nCXX src/caffe/layers/prelu_layer.cpp\r\nCXX src/caffe/layers/lrn_layer.cpp\r\nCXX src/caffe/layers/neuron_layer.cpp\r\nCXX src/caffe/layers/sigmoid_cross_entropy_loss_layer.cpp\r\nCXX src/caffe/layers/loss_layer.cpp\r\nCXX src/caffe/layers/base_data_layer.cpp\r\nCXX src/caffe/layers/rnn_layer.cpp\r\nCXX src/caffe/layers/exp_layer.cpp\r\nCXX src/caffe/layers/lstm_layer.cpp\r\nCXX src/caffe/layers/cudnn_pooling_layer.cpp\r\nCXX src/caffe/layers/bias_layer.cpp\r\nCXX src/caffe/layers/memory_data_layer.cpp\r\nCXX src/caffe/layers/softmax_layer.cpp\r\nCXX src/caffe/layers/threshold_layer.cpp\r\nCXX src/caffe/layers/parameter_layer.cpp\r\nCXX src/caffe/layers/mvn_layer.cpp\r\nCXX src/caffe/layers/hinge_loss_layer.cpp\r\nCXX src/caffe/layers/cudnn_relu_layer.cpp\r\nCXX src/caffe/layers/absval_layer.cpp\r\nCXX src/caffe/layers/base_conv_layer.cpp\r\nCXX src/caffe/layers/dropout_layer.cpp\r\nCXX src/caffe/layers/tanh_layer.cpp\r\nCXX src/caffe/layers/dummy_data_layer.cpp\r\nCXX src/caffe/layers/silence_layer.cpp\r\nCXX src/caffe/layers/relu_layer.cpp\r\nCXX src/caffe/layers/contrastive_loss_layer.cpp\r\nCXX src/caffe/layers/cudnn_conv_layer.cpp\r\nCXX src/caffe/layers/sigmoid_layer.cpp\r\nCXX src/caffe/layers/eltwise_layer.cpp\r\nCXX src/caffe/layers/cudnn_deconv_layer.cpp\r\nCXX src/caffe/layers/bnll_layer.cpp\r\nCXX src/caffe/layers/cudnn_tanh_layer.cpp\r\nCXX src/caffe/layers/accuracy_layer.cpp\r\nCXX src/caffe/layers/softmax_loss_layer.cpp\r\nsrc/caffe/layers/cudnn_deconv_layer.cpp: In member function virtual void caffe::CuDNNDeconvolutionLayer<Dtype>::Reshape(const std::vector<caffe::Blob<Dtype>*>&, const std::vector<caffe::Blob<Dtype>*>&):\r\nsrc/caffe/layers/cudnn_deconv_layer.cpp:167:11: error: CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD was not declared in this scope\r\n           CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD,\r\n           ^\r\nMakefile:581: recipe for target '.build_release/src/caffe/layers/cudnn_deconv_layer.o' failed\r\nmake: *** [.build_release/src/caffe/layers/cudnn_deconv_layer.o] Error 1\r\nmake: *** Waiting for unfinished jobs....\r\n"", '\r\nsrc/caffe/layers/cudnn_deconv_layer.cpp:167:11: error: CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD was not declared in this scope\r\n           CUDNN_CONVOLUTION_FWD_ALGO_WINOGRAD,\r\n ']",[],0,0
77,caffe,6859,open,How to make LMDB using regression data (e.g.   0001.jpg 0.865),"## Important - read before submitting

*Please read the [guidelines for contributing](https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md) before submitting this issue!*

*Please do not post installation, build, usage, or modeling questions, or other requests for help to Issues.*
Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead.
This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.

### Issue summary


### Steps to reproduce


### Tried solutions


### System configuration

* Operating system: 
* Compiler: 
* CUDA version (if applicable): 
* CUDNN version (if applicable): 
* BLAS: 
* Python version (if using pycaffe): 
* MATLAB version (if using matcaffe): 

### Issue checklist

- [ ] read the guidelines and removed the first paragraph
- [ ] written a short summary and detailed steps to reproduce
- [ ] explained how solutions to related problems failed (tick if found none)
- [ ] filled system configuration
- [ ] attached relevant logs/config files (tick if not applicable)
",,[],[],[],0,0
78,caffe,6832,open,Check failed: axis_index < num_axes() (1 vs. 0) axis 1 out of range for 0-D Blob with shape (0),"When I run the code from GitHubwhich is Face_Alignment_Two_Stage_Re-initialization,I got the following error:
I0911 08:08:29.921020 12228 layer_factory.hpp:88] Creating layer input
I0911 08:08:29.922020 12228 net.cpp:100] Creating Layer input
I0911 08:08:29.922020 12228 net.cpp:418] input -> data
I0911 08:08:29.923020 12228 net.cpp:150] Setting up input
I0911 08:08:29.924021 12228 net.cpp:157] Top shape: 1 3 448 448 (602112)
I0911 08:08:29.927022 12228 net.cpp:165] Memory required for data: 2408448
I0911 08:08:29.927022 12228 layer_factory.hpp:88] Creating layer data_input_0_split
I0911 08:08:29.928025 12228 net.cpp:100] Creating Layer data_input_0_split
I0911 08:08:29.928025 12228 net.cpp:444] data_input_0_split <- data
I0911 08:08:29.929024 12228 net.cpp:418] data_input_0_split -> data_input_0_split_0
I0911 08:08:29.930024 12228 net.cpp:418] data_input_0_split -> data_input_0_split_1
I0911 08:08:29.930024 12228 net.cpp:150] Setting up data_input_0_split
I0911 08:08:29.930024 12228 net.cpp:157] Top shape: 1 3 448 448 (602112)
I0911 08:08:29.932025 12228 net.cpp:157] Top shape: 1 3 448 448 (602112)
I0911 08:08:29.932025 12228 net.cpp:165] Memory required for data: 7225344
I0911 08:08:29.932025 12228 layer_factory.hpp:88] Creating layer downsample_data
I0911 08:08:29.932025 12228 net.cpp:100] Creating Layer downsample_data
I0911 08:08:29.932025 12228 net.cpp:444] downsample_data <- data_input_0_split_0
I0911 08:08:29.932025 12228 net.cpp:418] downsample_data -> downsample_data
I0911 08:08:29.932025 12228 net.cpp:150] Setting up downsample_data
I0911 08:08:29.932025 12228 net.cpp:157] Top shape: (0)
I0911 08:08:29.932025 12228 net.cpp:165] Memory required for data: 7225344
I0911 08:08:29.933027 12228 layer_factory.hpp:88] Creating layer net1_conv1
I0911 08:08:29.933027 12228 net.cpp:100] Creating Layer net1_conv1
I0911 08:08:29.933027 12228 net.cpp:444] net1_conv1 <- downsample_data
I0911 08:08:29.933027 12228 net.cpp:418] net1_conv1 -> net1_conv1
F0911 08:08:29.933027 12228 blob.hpp:122] Check failed: axis_index < num_axes() (1 vs. 0) axis 1 out of range for 0-D Blob with shape (0)
*** Check failure stack trace: ***

The part of the deploy is as follows.

name: ""facial_point_net""
input: ""data""
input_dim: 1
input_dim: 3
input_dim: 448
input_dim: 448

layer {
  name: ""downsample_data""
  type: ""SubsamplePooling""
  bottom: ""data""
  top: ""downsample_data""
  subsample_pooling_param {
    output_H: 60
    output_W: 60
  }
}
##########################################
layer {
  name: ""net1_conv1""
  type: ""Convolution""
  bottom: ""downsample_data""
  top: ""net1_conv1""
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 20
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: ""gaussian""
      std: 0.01
    }
    bias_filler {
      type: ""constant""
      value: 0
    }
  }
}
layer {
  name: ""net1_PReLU1""
  type: ""PReLU""
  bottom: ""net1_conv1""
  top: ""net1_conv1""
}

layer {
  name: ""net1_pool1""
  type: ""Pooling""
  bottom: ""net1_conv1""
  top: ""net1_pool1""
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

Does anyone know what the problem is ?",,[],[],[],0,0
79,caffe,5589,open,why scale within transform_param of data layer used in MNIST example is not applied in ImageNet example?,"I try to train alexnet over ImageNet. I read its train_val.prototxt, its transform_param is as below:

transform_param {
    mirror: true
    crop_size: 227
    mean_file: ""data/ilsvrc12/imagenet_mean.binaryproto""
 }

But in the example of MNIST tutorial, there is a scale parameter to normalize the pixel value from [0, 255] to [0, 1], listed as below:

transform_param {
    scale: 0.00390625
 }

And I tried to add ""scale: 0.00390625"" in the transform_param in my case, the accuracy becomes very poor.

Is the lmdb data converted by ""build/tools/convert_imageset"" already normalized? I tried to trace the codes in ""tools/convert_imageset"" and I found the image is loaded by function ""ReadImageToDatum"". Then ReadFileToDatum is called in ReadImageToDatum. Finally in ReadFileToDatum, I still don's see any codes normalizing the pixel value.

Why scale: 0.00390625 is only available in MNIST example but not in other examples? If the lmdb data is normalized, when and where has the normalization been done? thanks",,"['Hi, have you found out why? Thanks.', ""Hi, when I checked convert_imageset.cpp, I can not find normalization parts. I guess, this tools won't normalize the data. \r\nAnd I remember the scale 0.00390625 is the same as 1/256.\r\nHope this clue helps you. "", 'http://ufldl.stanford.edu/tutorial/unsupervised/PCAWhitening/ said ""In detail, in order for PCA to work well, informally we require that (i) The features have approximately zero mean, and (ii) The different features have similar variances to each other. With natural images, (ii) is already satisfied even without variance normalization, and so we wont perform any variance normalization.""\r\n\r\nSo I think natural images doesn\'t need to use normalization, and using normalization will make grads smaller, therefore we may get a worse result.', '@hgffly \r\nThe example seems to be the implementation of the [AlexNet paper](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), which does state that it does only mean normalization on the raw RGB pixels.\r\nSo the question should really be why they are doing it in the AlexNet paper. I find it a bit strange that they do not do any scale normalization, seeing as how Hinton does emphasize the importance of scale normalization in some of his video lectures.\r\nCould be one of 2 possibilities:\r\n1. Scale normalization would actually give faster convergence.\r\n2. Something else is present in the network architecture that actually gives a similar effect to scale normalization (like perhaps the norm1 and norm2 layers).']",[],[],0,0
80,caffe,745,closed,Creating LevelDB in Python,"I am currently creating several million artificial data images in python, all of which I would like stored into LevelDB to be fed through caffe. 

At the moment I'm saving all of the images directly to file, and then using 'create_leveldb.sh' to create the LevelDB directories. This creates a problem as I  am having to save a couple million images to the HDD.

What I am trying to do is have python directly save the artificial images into LevelDB, and do so without having to save the image to file. Currently, my code is trying to emulate what happens in 'ReadImageToDatum' from io.cpp. 

The LevelDB created from my code matches the size (number of leveldb files) of the LevelDB created from  convert_imageset.bin; however, when I train caffe on my leveldb directory, both Test#1 and Test#2 get worse over time.

What I am suspecting is that I have missed something when converting the image into a string format, but I may have missed something completely different.


",,"[""Keep in mind that `data` needs to be one byte per channel, in row major order, with axes (channel, y, x). I haven't checked this, but I'm guessing that the axis order represented here is (y, x, channel). Also note that OpenCV likes BGR ordered channels (but if you're training from scratch, that shouldn't make a difference).\n"", ""I tried using the code below to flip the axes to (channel, y, x) but still getting the same problem when training. Possibly my reshaping of the axes is incorrect though?\n\n```\nimage = ndimage.imread(file, mode='RGB')\n\n# Reshape image to (channel, y, x)\ns = image.shape\nimage = image.reshape((s[2], s[0], s[1]))\n```\n\nI've also tried this with no success either.\n\n```\nimage = ndimage.imread(file, mode='RGB')\ns = image.shape\ntemp = np.zeros((s[2], s[0], s[1]), dtype=np.uint8)\ntemp[0, ..., ...] = image[..., ..., 0]\ntemp[1, ..., ...] = image[..., ..., 1]\ntemp[2, ..., ...] = image[..., ..., 2]\nimage = temp\n```\n"", 'You want `transpose`, not `reshape`. The second block looks like it ought to work, although you mean `:`, not `...`. \n\nYou might want to read `_Net_preprocess` in `python/caffe/pycaffe.py` for example code of this sort (although keep in mind that the preprocessing here is not exactly the same as that performed by `DataLayer`).\n\nYou can debug by loading both working and nonworking nets in Python and comparing the data blobs.\n', ""Nice suggestion longjon! The `_Net_preprocess` seems to be a step in the right direction. I was really hoping transpose would have fixed the problem.\n\nI've added the code below, still with the same results with training getting worse. I've also tried loading both working and nonworking networks in Python, however both nets have empty data blobs (all zeros).\n\n```\nimage = image[:, :, (2, 1, 0)]\nimage = image.transpose((2, 0, 1))\n```\n\nCleaning up a bit, here is my new code, still with the same problem as before though.\n\n```\ndb = plyvel.DB('train_leveldb/', create_if_missing=True, error_if_exists=True, write_buffer_size=268435456)\nwb = db.write_batch()\n\n...\n\nfor file in imageSet:\n    image = caffe.io.load_image(file)\n\n    # Reshape image\n    image = image[:, :, (2, 1, 0)]\n    image = image.transpose((2, 0, 1))\n    image = image.astype(np.uint8, copy=False)\n\n    # Load image into datum object\n    datum = caffe.io.array_to_datum(image, label)\n\n    wb.put('%08d_%s' % (count, file), datum.SerializeToString())\n\n    count = count + 1\n    if count % 1000 == 0:\n        # Write batch of images to database\n        wb.write()\n        del wb\n        wb = db.write_batch()\n        print 'Processed %i images.' % count\n\nif count % 1000 != 0:\n    # Write last batch of images\n    wb.write()\n    print 'Processed a total of %i images.' % count\nelse:\n    print 'Processed a total of %i images.' % count\n```\n"", 'When checking in Python, did you call `forward` to populate the blobs?\n\nYou can also check that the same data appear in both working and nonworking LevelDBs directly.\n\nAlso check that your labels are correct, and that you are shuffling them if you need to in order to balance classes in each batch.\n', ""Hi there, how quick is working your algorithm? I am also working with big database and process some artificial data increase. However in that way, even with batch mode, the process is dramatically slow especially for big images (3x101x101 in my case) and lead to reduce the pre-processing evaluation. Hence I have trying to parallelize  the process with one batch by core for the same database but it's lead to segmentation issue with plyvel and py-leveldb (but leveldb should support multi-thread acces to 1 db according to the docs...). Therefore I have segmented my testing database but the issue is still remaining for the training case. Do you use special implementation in python to avoid this point? By the way, must the batch size should be set to 1,000 or is it just an arbitrary choice?\nThx.\nHenri\n"", ""If preprocessing speed and input size are important you should prepare your\ndata in C++ in a similar scheme to out `convert_imageset` tool as defined\nin convert_imageset.cpp.\n\nOn Thu, Aug 21, 2014 at 8:58 AM, hnoel notifications@github.com wrote:\n\n> Hi there, how quick is working your algorithm? I am also working with big\n> database and process some artificial data increase. However in that way,\n> even with batch mode, the process is dramatically slow especially for big\n> images (3x101x101 in my case) and lead to reduce the pre-processing\n> evaluation. Hence I have trying to parallelize the process with one batch\n> by core for the same database but it's lead to segmentation issue with\n> plyvel and py-leveldb (but leveldb should support multi-thread acces to 1\n> db according to the docs...). Therefore I have segmented my testing\n> database but the issue is still remaining for the training case. Do you use\n> special implementation in python to avoid this point? Thx.\n> Henri\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/745#issuecomment-52941139.\n"", 'Thx @shelhamer . I will try to modify some io cpp method, it does not seem complicated. When I success I will do a PR for some classic artificial data increase (rotation, flip, scaling) that some are looking for in some other post. By the way why all the batch length must be inferior to 1,000 items ? Another question, is the key string important or can we put any string of 256 bits if all are different ? Finally have you ever tried multi-process access to a leveldb database in order to increase the speed ?\nThx Henri\n', 'Sounds good.\n\nleveldb is limited to single process access --  look at lmdb for\nmulti-processing.\n\nOn Thursday, August 21, 2014, hnoel notifications@github.com wrote:\n\n> Thx @shelhamer https://github.com/shelhamer . I will try to modify some\n> io cpp method, it does not seem complicated. When I success I will do a PR\n> for some classic artificial data increase (rotation, flip, scaling) that\n> some are looking for in some other post. By the way why all the batch\n> length must be inferior to 1,000 items ? Another question, is the key\n> string important or can we put any string of 256 bits? Finally have you\n> ever tried multi-process access to a leveldb database in order to increase\n> the speed ?\n> Thx Henri\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/745#issuecomment-52959324.\n', ""Hey all, my apologies for a late reply. I did solve my problem, in fact the reason why training was getting worse over time was due to two things.\n1. The image must be in BGR format rather than RGB and must be transposed to (channels, y, x)\n   \n   `image = image[:, :, (2, 1, 0)]`\n   `image = image.transpose((2, 0, 1))`\n2. The data must be shuffled **before** being stored in leveldb format. Storing a batch of 1000 images all with the same class doesn't work.\n\nFew answers to questions asked above:\n\n**_Why are all the images written to leveldb as batches of 1000 images? Is this significant?**_\n\nMy code tries to duplicate what happens in convert_imageset.cpp found below (specifically at line 183).\nhttps://github.com/BVLC/caffe/blob/master/tools/convert_imageset.cpp\n\nFrom what I tested, I didn't find the batch size to be significant in CNN training. A batch size of 100 or 10,000 shouldn't act much differently than a batch size of 1,000. The only caveat is that the batch should be representative all of image classes (randomly shuffled data).\n\n**_Is the key important when saving an image into leveldb?**_\n\n**Yes**. I found the format of the key to be extremely important.\nFor example the following works:\n\n```\nwb.put('%08d_%s' % (count, filename), datum.SerializeToString())\n```\n\nThe line below however doesn't work when caffe tries to load the data back out of leveldb for training.\n\n```\nwb.put('%06d_%s' % (count, filename), datum.SerializeToString())\n```\n\nMore precisely the key must be in the format of `'00000000_*'` where the first 8 characters of the string must be digits, followed by an underscore. The \\* can represent anything else you want (a unique image identify for example). I chose to give each image a describing 'file name'. A full key for me might look like:\n    '00000068_keyboard_rotated_90.jpg'\n"", ""- If you're training from scratch and not finetuning an existing network, the order of the channels shouldn't matter. \n- A batch size of N (in the context of putting together a leveldb folder) also shouldn't matter for training. It just means that you collect N data points in a buffer before writing them to disk, which can be faster than one write per datum.\n- What does matter is that when you sort your data by key, that it's in the sequence you want it to be in for training. Also each data point needs to have a unique key. If you had less than a million training images '%06d_%s' or '%06d%s' would work fine.\n"", ""Python module `leveldb` performs badly. But `plyvel` works well. Even for the same logic. For example:\n\n``` python\ndb = leveldb.LevelDB('mnist-%s-leveldb/' % name, create_if_missing=True, error_if_exists=True)\nfor im, lb in zip(imgs, lbls):\n    ......\n    db.Put('%08d' % count, datum.SerializeToString())\n```\n\nand\n\n``` python\ndb = plyvel.DB('mnist-%s-leveldb/' % name, create_if_missing=True, error_if_exists=True)\nfor im, lb in zip(imgs, lbls):\n    ......\n    db.put('%08d' % count, datum.SerializeToString())\n```\n\nHave anyone encountered this problem?\n"", 'One interesting thing about using plyvel. When I create DB without using write batch, compute_image_mean tool produces some wrong result.\nIf I put all writes in one batch, it works ok.\n\nI use the code, listed bellow. It just copies data from one DB to another.\n\n``` python\nimport caffe\nwb = db.write_batch()  # without batch binary mean is wrong\ndatum =  caffe.io.caffe_pb2.Datum()\nfor k, v in db_in:\n    wb.put(k,v)\nwb.write()  # without batch binary mean is wrong\n```\n\nWho knows why it happens?\n']","[""\ndb = plyvel.DB('train_leveldb/', create_if_missing=True, error_if_exists=True, write_buffer_size=268435456)\nwb = db.write_batch()\n\n...\n\nfor file in imageSet:\n    image = cv.LoadImageM(file, cv.CV_LOAD_IMAGE_COLOR)\n\n    # Load image into datum object\n    datum = caffe.proto.caffe_pb2.Datum()\n    datum.height = image.rows\n    datum.width = image.cols\n    datum.channels = 3\n    datum.label = label\n    datum.data = image.tostring()\n\n    wb.put('%08d_%s' % (count, file), datum.SerializeToString())\n\n    count = count + 1\n    if count % 1000 == 0:\n        # Write batch of images to database\n        wb.write()\n        del wb\n        wb = db.write_batch()\n        print 'Processed %i images.' % count\n\nif count % 1000 != 0:\n    # Write last batch of images\n    wb.write()\n    print 'Processed a total of %i images.' % count\nelse:\n    print 'Processed a total of %i images.' % count\n""]",[],0,0
81,caffe,2259,closed,Cudnn v2 with caffe on Jetson TK1,"I am having trouble compiling caffe on the Jetson TK1 board. I already have Cudnn v2 set up, but I am following the instructions to install caffe and when I get to the 'make -j 4 all' step, I execute that step, but during compilation, I get several errors about 'functions not being declared in this scope' or several other errors that terminate compilation. I know that caffe and cudnn v2 don't play well together (yet), but this version of caffe should. Any advice? Thanks!
",,"['what  do  you want  to  do  for  the  cudnn,I have  tried  the  cudnn V1,it  is  not  faster,I  do  not  know  why\n', 'I would like to use cudnn v2 with caffe. I downloaded cudnn on the Nvidia\nwebsite and the only version offered was cudnn v2. I want to use it for\nrobotics and general neural network stuff. Thanks!\n\nOn Mon, Apr 6, 2015 at 1:19 AM, wzq12138 notifications@github.com wrote:\n\n> what do you want to do for the cudnn,I have tried the cudnn V1,it is not\n> faster,I do not know why\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/2259#issuecomment-89943265.\n', 'Caffe is compatible with cuDNN v2 as of #2038 and #2211 which were merged once v2 was officially released.\n\nPlease discuss installation on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) group.\n']",[],[],0,0
82,caffe,6622,closed,../lib/libcaffe.so.1.0.0: undefined reference to `MPI_Type_get_envelope',"when i want to create a new type of  layer which need PCL , and add dependencies in cmake/Dependencies.cmake only with find_package line like this:

compile error with MPI xxxxxxx happend. if delete this line, everything's OK. 

building output as follow:
[  0%] Running C++/Python protocol buffer compiler on /home/dongxufu/Dev/caffe/src/caffe/proto/caffe.proto
Scanning dependencies of target caffeproto
[  1%] Building CXX object src/caffe/CMakeFiles/caffeproto.dir/__/__/include/caffe/proto/caffe.pb.cc.o
[  1%] Linking CXX static library ../../lib/libcaffeproto.a
[  1%] Built target caffeproto
Scanning dependencies of target caffe
[  1%] Building CXX object src/caffe/CMakeFiles/caffe.dir/solver.cpp.o
[  1%] Building CXX object src/caffe/CMakeFiles/caffe.dir/blob.cpp.o
[  3%] Building CXX object src/caffe/CMakeFiles/caffe.dir/data_transformer.cpp.o
[  3%] Building CXX object src/caffe/CMakeFiles/caffe.dir/syncedmem.cpp.o
[  4%] Building CXX object src/caffe/CMakeFiles/caffe.dir/parallel.cpp.o
[  4%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layer_factory.cpp.o
[  6%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layer.cpp.o
[  6%] Building CXX object src/caffe/CMakeFiles/caffe.dir/solvers/nesterov_solver.cpp.o
[  7%] Building CXX object src/caffe/CMakeFiles/caffe.dir/solvers/adagrad_solver.cpp.o
[  7%] Building CXX object src/caffe/CMakeFiles/caffe.dir/solvers/sgd_solver.cpp.o
[  9%] Building CXX object src/caffe/CMakeFiles/caffe.dir/solvers/adam_solver.cpp.o
[  9%] Building CXX object src/caffe/CMakeFiles/caffe.dir/solvers/rmsprop_solver.cpp.o
[ 10%] Building CXX object src/caffe/CMakeFiles/caffe.dir/solvers/adadelta_solver.cpp.o
[ 10%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/cudnn_relu_layer.cpp.o
[ 12%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/cudnn_softmax_layer.cpp.o
[ 12%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/rnn_layer.cpp.o
[ 14%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/lstm_layer.cpp.o
[ 14%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/cudnn_sigmoid_layer.cpp.o
[ 15%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/concat_layer.cpp.o
[ 15%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/mvn_layer.cpp.o
[ 17%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/cudnn_lrn_layer.cpp.o
[ 17%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/cudnn_conv_layer.cpp.o
[ 18%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/absval_layer.cpp.o
[ 18%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/input_layer.cpp.o
[ 20%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/silence_layer.cpp.o
[ 20%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/cudnn_tanh_layer.cpp.o
[ 21%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/recurrent_layer.cpp.o
[ 21%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/image_data_layer.cpp.o
[ 23%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/window_data_layer.cpp.o
[ 23%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/batch_reindex_layer.cpp.o
[ 25%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/accuracy_layer.cpp.o
[ 25%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/inner_product_layer.cpp.o
[ 26%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/argmax_layer.cpp.o
[ 26%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/relu_layer.cpp.o
[ 28%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/clip_layer.cpp.o
[ 28%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/neuron_layer.cpp.o
[ 29%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/spp_layer.cpp.o
[ 29%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/slice_layer.cpp.o
[ 31%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/flatten_layer.cpp.o
[ 31%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/lstm_unit_layer.cpp.o
[ 32%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/log_layer.cpp.o
[ 32%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/softmax_layer.cpp.o
[ 34%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/base_data_layer.cpp.o
[ 34%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/euclidean_loss_layer.cpp.o
[ 35%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/sigmoid_layer.cpp.o
[ 35%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/base_conv_layer.cpp.o
[ 37%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/loss_layer.cpp.o
[ 37%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/power_layer.cpp.o
[ 39%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/hdf5_output_layer.cpp.o
[ 39%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/crop_layer.cpp.o
[ 40%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/dropout_layer.cpp.o
[ 40%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/bias_layer.cpp.o
[ 42%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/conv_layer.cpp.o
[ 42%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/parameter_layer.cpp.o
[ 43%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/reduction_layer.cpp.o
[ 43%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/tanh_layer.cpp.o
[ 45%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/pooling_layer.cpp.o
[ 45%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/im2col_layer.cpp.o
[ 46%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/hinge_loss_layer.cpp.o
[ 46%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/sigmoid_cross_entropy_loss_layer.cpp.o
[ 48%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/prelu_layer.cpp.o
[ 48%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/contrastive_loss_layer.cpp.o
[ 50%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/cudnn_deconv_layer.cpp.o
[ 50%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/split_layer.cpp.o
[ 51%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/hdf5_data_layer.cpp.o
[ 51%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/threshold_layer.cpp.o
[ 53%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/cudnn_lcn_layer.cpp.o
[ 53%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/bnll_layer.cpp.o
[ 53%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/elu_layer.cpp.o
[ 54%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/cudnn_pooling_layer.cpp.o
[ 54%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/infogain_loss_layer.cpp.o
[ 56%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/deconv_layer.cpp.o
[ 56%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/eltwise_layer.cpp.o
[ 57%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/scale_layer.cpp.o
[ 57%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/softmax_loss_layer.cpp.o
[ 59%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/filter_layer.cpp.o
[ 59%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/dummy_data_layer.cpp.o
[ 60%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/lrn_layer.cpp.o
[ 60%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/tile_layer.cpp.o
[ 62%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/exp_layer.cpp.o
[ 62%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/data_layer.cpp.o
[ 64%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/memory_data_layer.cpp.o
[ 64%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/multinomial_logistic_loss_layer.cpp.o
[ 65%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/reshape_layer.cpp.o
[ 65%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/embed_layer.cpp.o
[ 67%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/swish_layer.cpp.o
[ 67%] Building CXX object src/caffe/CMakeFiles/caffe.dir/layers/batch_norm_layer.cpp.o
[ 68%] Building CXX object src/caffe/CMakeFiles/caffe.dir/util/im2col.cpp.o
[ 68%] Building CXX object src/caffe/CMakeFiles/caffe.dir/util/db_lmdb.cpp.o
[ 70%] Building CXX object src/caffe/CMakeFiles/caffe.dir/util/io.cpp.o
[ 70%] Building CXX object src/caffe/CMakeFiles/caffe.dir/util/signal_handler.cpp.o
[ 71%] Building CXX object src/caffe/CMakeFiles/caffe.dir/util/math_functions.cpp.o
[ 71%] Building CXX object src/caffe/CMakeFiles/caffe.dir/util/benchmark.cpp.o
[ 73%] Building CXX object src/caffe/CMakeFiles/caffe.dir/util/cudnn.cpp.o
[ 73%] Building CXX object src/caffe/CMakeFiles/caffe.dir/util/upgrade_proto.cpp.o
[ 75%] Building CXX object src/caffe/CMakeFiles/caffe.dir/util/insert_splits.cpp.o
[ 75%] Building CXX object src/caffe/CMakeFiles/caffe.dir/util/blocking_queue.cpp.o
[ 76%] Building CXX object src/caffe/CMakeFiles/caffe.dir/util/hdf5.cpp.o
[ 76%] Building CXX object src/caffe/CMakeFiles/caffe.dir/util/db.cpp.o
[ 78%] Building CXX object src/caffe/CMakeFiles/caffe.dir/util/db_leveldb.cpp.o
[ 78%] Building CXX object src/caffe/CMakeFiles/caffe.dir/net.cpp.o
[ 79%] Building CXX object src/caffe/CMakeFiles/caffe.dir/common.cpp.o
[ 79%] Building CXX object src/caffe/CMakeFiles/caffe.dir/internal_thread.cpp.o
[ 81%] Linking CXX shared library ../../lib/libcaffe.so
[ 81%] Built target caffe
Scanning dependencies of target upgrade_net_proto_text
[ 81%] Building CXX object tools/CMakeFiles/upgrade_net_proto_text.dir/upgrade_net_proto_text.cpp.o
[ 82%] Linking CXX executable upgrade_net_proto_text
../lib/libcaffe.so.1.0.0: undefined reference to ompi_mpi_comm_null'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Topo_test'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Type_create_subarray'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Comm_dup'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Get_count'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Graph_neighbors'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Comm_create'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Scan'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Test_cancelled'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Errhandler_free'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Group_incl'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Group_range_excl'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Comm_get_attr'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Type_get_contents'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Irsend'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Pack_external_size'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Sendrecv_replace'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Comm_remote_group'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Ssend_init'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Win_set_errhandler'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Win_start'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Comm_set_name'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Accumulate'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Initialized'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Graph_neighbors_count'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Probe'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Allgatherv'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Comm_disconnect'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Info_get'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Cancel'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Unpack_external'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Win_wait'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Send'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Type_size'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Allreduce'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Reduce_local'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Info_delete'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Exscan'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Status_set_cancelled'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Win_get_group'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Bsend'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Cartdim_get'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Win_lock'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Cart_coords'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Type_create_indexed_block'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Comm_free'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Type_dup'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Reduce'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Cart_rank'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Comm_delete_attr'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Wait'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Ibsend'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Type_create_resized'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Get_elements'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Op_create'
../lib/libcaffe.so.1.0.0: undefined reference to ompi_op_set_cxx_callback'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Pack_size'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Ssend'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Test'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Comm_spawn_multiple'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Win_delete_attr'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Type_set_attr'
../lib/libcaffe.so.1.0.0: undefined reference to MPI::Comm::Comm()'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Rsend_init'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Comm_test_inter'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Type_get_name'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Comm_spawn'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Win_set_name'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Cart_shift'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Status_set_elements'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Win_call_errhandler'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Win_get_errhandler'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Intercomm_merge'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Group_range_incl'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Group_free'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Cart_get'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Pack_external'
../lib/libcaffe.so.1.0.0: undefined reference to MPI::Win::Free()'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Win_unlock'
../lib/libcaffe.so.1.0.0: undefined reference to MPI_Alltoallw'
collect2: error: ld returned 1 exit status
tools/CMakeFiles/upgrade_net_proto_text.dir/build.make:132: recipe for target 'tools/upgrade_net_proto_text' failed
make[2]: *** [tools/upgrade_net_proto_text] Error 1
CMakeFiles/Makefile2:457: recipe for target 'tools/CMakeFiles/upgrade_net_proto_text.dir/all' failed
make[1]: *** [tools/CMakeFiles/upgrade_net_proto_text.dir/all] Error 2
Makefile:127: recipe for target 'all' failed
make: *** [all] Error 2

anybody knows why?",,[],['find_package(PCL 1.7 REQUIRED)'],"[""MPI_Type_get_envelope'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Abort'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Group_excl'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Win_get_name'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Graph_create'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Op_free'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Grequest_complete'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Win_test'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Graphdims_get'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Put'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Bsend_init'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Type_get_attr'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Op_commutative'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Reduce_scatter'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Info_get_valuelen'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Bcast'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Info_free'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Info_dup'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""ompi_mpi_cxx_op_intercept'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Alltoallv'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Scatter'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Cart_create'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Info_set'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Scatterv'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Request_get_status'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Iprobe'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Type_delete_attr'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Issend'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Win_set_attr'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Comm_group'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Cart_sub'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Comm_split'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Comm_get_errhandler'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Win_complete'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Graph_map'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Comm_remote_size'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI::Datatype::Free()'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Send_init'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Comm_set_errhandler'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Rsend'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Type_get_true_extent'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Get'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Irecv'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Type_contiguous'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Recv'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Win_fence'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Type_get_extent'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Group_rank'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Pack'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Gatherv'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Start'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Allgather'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Type_create_darray'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Type_create_hindexed'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Group_size'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Info_get_nthkey'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Request_free'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Comm_set_attr'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Unpack'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Intercomm_create'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Info_get_nkeys'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Recv_init'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Isend'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Type_create_hvector'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Win_post'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Type_vector'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Comm_get_name'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Type_set_name'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Alltoall'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Comm_accept'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Sendrecv'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Gather'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Comm_connect'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Comm_size'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Graph_get'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Type_indexed'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Barrier'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Type_commit'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Cart_map'\r\n../lib/libcaffe.so.1.0.0: undefined reference to "", ""MPI_Comm_rank'\r\n../lib/libcaffe.so.1.0.0: undefined reference to ""]",0,0
83,caffe,797,closed,Timer test always fails?,"I checked out the latest dev, but always seem to stuck on this test:



I'm running on a mid-2012 MBPr (compute_capability=3.0) so double precision GPU computation shouldn't be an issue here, could anyone offer any idea on this?

Thanks in advance!
",,"['It seems that the time check is too strict, so relaxing the threshold to like 0.31 should be fine. If you like, kindly send a pull request and I will merge it.\n', 'closing and moving to #807 \n']","['\n[----------] 5 tests from BenchmarkTest/3, where TypeParam = caffe::DoubleGPU\n[ RUN      ] BenchmarkTest/3.TestTimerConstructor\n[       OK ] BenchmarkTest/3.TestTimerConstructor (0 ms)\n[ RUN      ] BenchmarkTest/3.TestTimerSeconds\nsrc/caffe/test/test_benchmark.cpp:82: Failure\nExpected: (timer.Seconds()) <= (0.305), actual: 0.30509 vs 0.305\n[  FAILED  ] BenchmarkTest/3.TestTimerSeconds, where TypeParam = caffe::DoubleGPU (305 ms)\n']",[],0,0
84,caffe,1623,closed,Community issues and policy feedbacks,"In this issue i want to try to collect feedback and policy proposal by core developers and community contributors (we don't have a developer group like caffe-user). Please try to do it in a constructive and scalable prospection. The objective, with the proliferation of deep learning toolkit and research momentum, is to try attract more contributors in Caffe and to retain developers that already opened good  PR.
",community,"['cc: @mtamburrano\n', ""You need to get those in charge involved to have any real progress. `caffe` is run by a dictatorship (benevolent if you'd like), not a democracy.\n"", ""For ones that doesn't know what is the governance model that @netheril96 cited in the open source context can read [this](http://oss-watch.ac.uk/resources/benevolentdictatorgovernancemodel) and more generally on [governance models](http://oss-watch.ac.uk/resources/governancemodels) cc: @BVLC\n"", 'It has a little bit of lag but see also some statistics http://ghtorrent.org/pullreq-perf/BVLC-caffe/\n', 'cc: @sguada @shelhamer @longjon @sergeyk @Yangqing @jeffdonahue @kloudkl @qipeng @rbgirshick\n', 'Looks like nobody from core-developers cares for filter and other PRs from community(\nEven cool OpenMP branch https://github.com/BVLC/caffe/pull/439 still unmerged for months...\n', 'A free tool that could help project management integrated with github: https://www.zenhub.io\n', ""As I have suspected, the owners don't care about this at all. The only recourse is to split off in a different project, as have been done numerous times in the world of open source. Not sure how feasible that is, however.\n"", '@shelhamer Is there any sign of life?\n', 'Some thoughts on this:\n\nGiven our current limited resources, there is necessarily a tradeoff between ""high precision"" (confidence in the correctness of our code) and ""high recall"" (merging lots of code quickly). I think it\'s best for everybody to keep BVLC/caffe in the ""high precision"" regime, as one can always get higher recall with forks, branches, PRs, and so on, and git and GitHub make it pretty easy to keep all those things in the air at once.\n\nThat said, there are certainly ways we can improve the process. Foremost I think we can improve communication by:\n1. Keeping every PR tagged with its status (something we\'ve discussed but haven\'t yet implemented).\n2. Responding to every community PR promptly with prospects for merging, even if it\'s to say that something is low priority.\n\nWe could also take some technical steps to make it easier for code to live outside BVLC/caffe. We could:\n1. Create a contrib repo for extra layers and tools. We would provide Travis testing but otherwise leave merging decisions up to the community.\n2. Make it easier to link external layer code with Caffe, and provide a central place for layer libraries.\n\nComments on those ideas or other concrete suggestions are welcome.\n', 'For me the high precision is a concept of quality assurance of a distribution. If caffe with contrib, plugins system or whatever else become a distribution. \nWe have already experienced opencv-contrib on github with the opencv project adding testing infrastructure support for it. But  this doesn\'t seem to work fine. Without a governance model will not be clear how a contributed repository could scale, how we can limit duplicates proliferation, and bypass the bottleneck of core members limited time to review and maintain code.\nI think that we need to find a governance model and a clear review pipeline. \nThen if we want to maintain officially external code we need to do in a ""caffe distribution"" fashion.  \nSo we can have official maintainers for every contributed layers, loss or other components that could have a role for fixing bug, merge request maintain release compatibility of his components. If a maintainer is missing in action other maintainers or core members could superseded the maintainers role. If a layer, loss or other components are not maintained anymore (bugs are not fixed, api incompatibility with new releases, missing review of PR etc.) we could remove the code from the official ""caffe distribution"". So that caffe could maintain a general quality also with a modularity.\n\nBut for changes that are not isolated in a ""modular component"" we need to find a clear pipeline for every PR. I think also that every PR need to have a clear assigned reviewer. Other people can support, contribute and comment but the PR need to advance in a pipeline handled by the responsibility of the assigned core member. Because often contributors are very active to accept feedbacks from reviews but then core members are missing in action or change idea on what to do for a ""more ideally"" integration. We need to have clear feedbacks on what work is needed to do to let a PR merge.\n', ""@longjon \n\nI believe the problem is not what or how, but who. Your idea is nice, but I am afraid that it won't be implemented even if we all agree it is a good idea, simply because the maintainers are two few in number and in time.\n\n`caffe` has grown beyond a simple project that can be managed by a small panel of original developers. To scale up, the governance must be changed.\n"", ""Corporate contribution is possible. At least such ideas are being discussed/planned now. It could be paid full time developers' work. (@garybradski)\n"", 'I am personally more with the original maintainers of this project that we should keep this repository of ""high precision"" instead of focusing on fast development. Either as a developer or as an end user, I wouldn\'t want to see random stuff being merged into `master` or `dev` without thorough unit tests or handheld code review that might break other things or make my training/testing 10x slower. It can be crucial for a code base like Caffe itself, because we care a lot about correctness and efficiency as it\'s being used as benchmarks in many places now. Keeping `master` and `dev` slow but steady is a good idea, I think.\n\nThat being said, I do agree that an experimental (or contrib) branch / fork that\'s slightly more loosely managed by the community is a good idea, conditioned on there being responsible _and_ competent people in the ""governance loop"" that keeps the project relatively maintainable and of good quality. Otherwise something like Caffe that demands both engineering experiences and familiarity with academic materials could go bad very easily and very fast.\n', '@qipeng The problem is not that third party codes are not merged fast enough, but that _they are barely reviewed at all_. Many pull requests just sit there and rot, without review, feedback or action.\n', 'I think that nobody here want to lower the quality of the code. But actually it is clear that there is a scalability issue given by the actual contributors/core members availability ratio.\nMy issue, when I mentioned the opencv-contrib experience, is that proposing a contrib repository without a policy and governance don\'t solve the problem if we don\'t choice a governance that can scale and maintain a good quality assurance. Every project that have scaled have one. I generally like meritocracy and clear responsibility by team or individuals for user contributed modules (layers, loss or every other modularity you can find in caffe) to maintain a good level of QA of the whole ""caffe distribution"". I suggest to everyone that want to contribute to this discussion to read the governance models link I\'ve posted. Putting user code in an easy mergiable (or simply API compliant) ""trash sandbox"" is not the solution to scale with quality and minimizing duplication and fragmentation trends. We need to enlarge trusted responsibility to let emerge  new members by meritocracy whatever community governance we choice.\n', ""@netheril96 I agree that that's happening to some extent. But still I think @bhack 's idea about opening a separate contrib repo would be great, where we can get more community developers involved in the governance and make things scale faster. And eventually, the core members might choose to talk to the community leaders and port back some high quality code from that repo.\n"", 'See also [updated stats](http://ghtorrent.org/pullreq-perf/BVLC-caffe/)\n', '> one can always get higher recall with forks, branches, PRs, and so on, and git and GitHub make it pretty easy to keep all those things in the air at once.\n\n@longjon has this exactly right. We can keep BVLC/caffe in a high precision regime while everyone shares whatever code they like in forks and branches. It\'s important to keep Caffe correct and efficient since it has both research and industrial purposes.\n\nAt the same time a dedicated ""contrib"" repo could be a gathering place to collect code like this to later be accepted into BVLC/caffe as @bhack and @qipeng mentioned.\n\n> Otherwise something like Caffe that demands both engineering experiences and familiarity with academic materials could go bad very easily and very fast.\n\n@qipeng this is of course what needs to be guarded against.\n\n@bhack thanks for the graph -- too bad the format makes it hard to read the counts. Deadlines aside, it looks like there is a steady rate or merged and closed PRs... not that there couldn\'t be more of course.\n\n> The problem is not that third party codes are not merged fast enough, but that they are barely reviewed at all\n\n@netheril96 to be fair there are ~300 commits by 40+ contributors (in master alone) so community PRs are reviewed and merged. It can take time but the only projects without open PRs are dead ones. Often old PRs are likewise long and complicated and these are correlated for a reason. For sustainability it\'s important to keep code not only correct and efficient, but to keep as little code around as possible.\n', '@shelhamer You can reproduce [raw data](https://github.com/gousiosg/pullreqs/blob/master/README.md) if you are interested. IMHO PRs merging deadline are very slow for an ""active project"" and things was going  slower in last months. From the last graph I also see an high fork/""contrib back"" ratio. Generally it is not a good signal. Why people fork Caffe more with less PR? They do it for personal hosting nets experiments on github? Or whatever? They don\'t want invest time to contribute back code because get too time?\nYou have also not commented the governance model you like to implement also if we want to modularize in contrib. \nA contrib without governance (or with only test coverage like opencv-contrib) will become quickly a trash sandbox. If we need to offload core members reviews ""on contrib"" who can we trust?\n', 'Please take a look also to [this paper](http://repository.tudelft.nl/view/ir/uuid:757f9888-abf4-4dd5-a734-d5280e189a67/) or more generally on some pull request ecosystem studies [in this list](https://scholar.google.it/scholar?as_ylo=2014&hl=it&as_sdt=2005&sciodt=0,5&cites=8987012180748448806&scipsc=)\n', '@Nerei I have opened a similar issue on opencv-contrib because it has similar problems (and i know well because my team have mentored different opencv gsoc projects and trying to maintain tracking api) https://github.com/Itseez/opencv_contrib/issues/149\n', 'Other the zenhub.io core members could try also [waffle](https://waffle.io/BVLC/caffe) that is open source.\n', '@longjon We need to do something to go ahead. New tickets are full of support requests noise. PR and really issues are lacking of BVLC activity. Only cross core members PRs  are quite active and have rapid feedback and merge.\n', 'Updated stats at http://ghtorrent.org/pullreq-perf/BVLC-caffe/\n', 'Closing as development is diffusing more into the community through inviting contributorswhose help is very much appreciatedand delegation of community branches like OpenCL and Windowswhich have been regularly improved by their leaders.']",[],[],0,0
85,caffe,5892,closed,/usr/bin/ld: cannot find -l -llmdb,"make clean
make all
![screenshot from 2017-09-04 17-41-59](https://user-images.githubusercontent.com/11031352/30026018-c033518e-9198-11e7-8e74-4d4b85ceb0d6.png)


AR -o .build_release/lib/libcaffe.a
LD -o .build_release/lib/libcaffe.so.1.0.0
/usr/bin/ld: cannot find -l -llmdb
collect2: error: ld returned 1 exit status
Makefile:575: recipe for target '.build_release/lib/libcaffe.so.1.0.0' failed
make: *** [.build_release/lib/libcaffe.so.1.0.0] Error 1
any one have solution thank you",,"['It seems you raised the same issue (#5891) twice. Please close either of them.\r\n\r\nDid you install lmdb? Seems it was unable to link against lmdb.', 'Please stop making spam comments. It rather interferes developers.', "" yes i did this\r\ngit clone https://github.com/LMDB/lmdb\r\nCloning into 'lmdb'...\r\n\r\nremote: Counting objects: 7816, done.\r\nremote: Total 7816 (delta 0), reused 0 (delta 0), pack-reused 7815\r\nReceiving objects: 100% (7816/7816), 1.70 MiB | 190.00 KiB/s, done.\r\nResolving deltas: 100% (3361/3361), done.\r\nChecking connectivity... done.\r\nroot@esense9:~/.local/install/caffe# \r\nroot@esense9:~/.local/install/caffe# cd lmdb/libraries/liblmdb\r\nroot@esense9:~/.local/install/caffe/lmdb/libraries/liblmdb# \r\nroot@esense9:~/.local/install/caffe/lmdb/libraries/liblmdb# make && make installgcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   -c mdb.c\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   -c midl.c\r\nar rs liblmdb.a mdb.o midl.o\r\nar: creating liblmdb.a\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized  -fPIC  -c mdb.c -o mdb.lo\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized  -fPIC  -c midl.c -o midl.lo\r\ngcc  -pthread -shared -o liblmdb.so mdb.lo midl.lo \r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   -c mdb_stat.c\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   mdb_stat.o liblmdb.a  -o mdb_stat\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   -c mdb_copy.c\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   mdb_copy.o liblmdb.a  -o mdb_copy\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   -c mdb_dump.c\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   mdb_dump.o liblmdb.a  -o mdb_dump\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   -c mdb_load.c\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   mdb_load.o liblmdb.a  -o mdb_load\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   -c mtest.c\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   mtest.o liblmdb.a  -o mtest\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   -c mtest2.c\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   mtest2.o liblmdb.a  -o mtest2\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   -c mtest3.c\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   mtest3.o liblmdb.a  -o mtest3\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   -c mtest4.c\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   mtest4.o liblmdb.a  -o mtest4\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   -c mtest5.c\r\ngcc -pthread -O2 -g -W -Wall -Wno-unused-parameter -Wbad-function-cast -Wuninitialized   mtest5.o liblmdb.a  -o mtest5\r\nmkdir -p /usr/local/bin\r\nmkdir -p /usr/local/lib\r\nmkdir -p /usr/local/include\r\nmkdir -p /usr/local/share/man/man1\r\nfor f in mdb_stat mdb_copy mdb_dump mdb_load; do cp $f /usr/local/bin; done\r\nfor f in liblmdb.a liblmdb.so; do cp $f /usr/local/lib; done\r\nfor f in lmdb.h; do cp $f /usr/local/include; done\r\nfor f in mdb_stat.1 mdb_copy.1 mdb_dump.1 mdb_load.1; do cp $f /usr/local/share/man/man1; done\r\nroot@esense9:~/.local/install/caffe/lmdb/libraries/liblmdb# cd ..\r\nroot@esense9:~/.local/install/caffe/lmdb/libraries# cd ..\r\nroot@esense9:~/.local/install/caffe/lmdb# cd ..\r\nroot@esense9:~/.local/install/caffe# make clean\r\nroot@esense9:~/.local/install/caffe# make all\r\nPROTOC src/caffe/proto/caffe.proto\r\nCXX .build_release/src/caffe/proto/caffe.pb.cc\r\nCXX src/caffe/solver.cpp\r\nCXX src/caffe/net.cpp\r\nCXX src/caffe/internal_thread.cpp\r\nCXX src/caffe/syncedmem.cpp\r\nCXX src/caffe/solvers/adagrad_solver.cpp\r\nCXX src/caffe/solvers/nesterov_solver.cpp\r\nCXX src/caffe/solvers/adam_solver.cpp\r\nCXX src/caffe/solvers/sgd_solver.cpp\r\nCXX src/caffe/solvers/rmsprop_solver.cpp\r\nCXX src/caffe/solvers/adadelta_solver.cpp\r\nCXX src/caffe/layer_factory.cpp\r\nCXX src/caffe/layer.cpp\r\nCXX src/caffe/blob.cpp\r\nCXX src/caffe/common.cpp\r\nCXX src/caffe/data_transformer.cpp\r\nCXX src/caffe/parallel.cpp\r\nCXX src/caffe/util/signal_handler.cpp\r\nCXX src/caffe/util/benchmark.cpp\r\nCXX src/caffe/util/im2col.cpp\r\nCXX src/caffe/util/db_leveldb.cpp\r\nCXX src/caffe/util/db_lmdb.cpp\r\nCXX src/caffe/util/cudnn.cpp\r\nCXX src/caffe/util/io.cpp\r\nCXX src/caffe/util/insert_splits.cpp\r\nCXX src/caffe/util/blocking_queue.cpp\r\nCXX src/caffe/util/hdf5.cpp\r\nCXX src/caffe/util/math_functions.cpp\r\nCXX src/caffe/util/upgrade_proto.cpp\r\nCXX src/caffe/util/db.cpp\r\nCXX src/caffe/layers/eltwise_layer.cpp\r\nCXX src/caffe/layers/hdf5_output_layer.cpp\r\nCXX src/caffe/layers/cudnn_relu_layer.cpp\r\nCXX src/caffe/layers/softmax_layer.cpp\r\nCXX src/caffe/layers/multinomial_logistic_loss_layer.cpp\r\nCXX src/caffe/layers/im2col_layer.cpp\r\nCXX src/caffe/layers/batch_norm_layer.cpp\r\nCXX src/caffe/layers/power_layer.cpp\r\nCXX src/caffe/layers/loss_layer.cpp\r\nCXX src/caffe/layers/neuron_layer.cpp\r\nCXX src/caffe/layers/cudnn_sigmoid_layer.cpp\r\nCXX src/caffe/layers/input_layer.cpp\r\nCXX src/caffe/layers/recurrent_layer.cpp\r\nCXX src/caffe/layers/absval_layer.cpp\r\nCXX src/caffe/layers/softmax_loss_layer.cpp\r\nCXX src/caffe/layers/concat_layer.cpp\r\nCXX src/caffe/layers/cudnn_pooling_layer.cpp\r\nCXX src/caffe/layers/slice_layer.cpp\r\nCXX src/caffe/layers/sigmoid_layer.cpp\r\nCXX src/caffe/layers/memory_data_layer.cpp\r\nCXX src/caffe/layers/rnn_layer.cpp\r\nCXX src/caffe/layers/window_data_layer.cpp\r\nCXX src/caffe/layers/lstm_layer.cpp\r\nCXX src/caffe/layers/accuracy_layer.cpp\r\nCXX src/caffe/layers/relu_layer.cpp\r\nCXX src/caffe/layers/hinge_loss_layer.cpp\r\nCXX src/caffe/layers/crop_layer.cpp\r\nCXX src/caffe/layers/log_layer.cpp\r\nCXX src/caffe/layers/infogain_loss_layer.cpp\r\nCXX src/caffe/layers/data_layer.cpp\r\nCXX src/caffe/layers/flatten_layer.cpp\r\nCXX src/caffe/layers/filter_layer.cpp\r\nCXX src/caffe/layers/reduction_layer.cpp\r\nCXX src/caffe/layers/lstm_unit_layer.cpp\r\nCXX src/caffe/layers/split_layer.cpp\r\nCXX src/caffe/layers/cudnn_conv_layer.cpp\r\nCXX src/caffe/layers/deconv_layer.cpp\r\nCXX src/caffe/layers/inner_product_layer.cpp\r\nCXX src/caffe/layers/lrn_layer.cpp\r\nCXX src/caffe/layers/bnll_layer.cpp\r\nCXX src/caffe/layers/hdf5_data_layer.cpp\r\nCXX src/caffe/layers/base_data_layer.cpp\r\nCXX src/caffe/layers/cudnn_lcn_layer.cpp\r\nCXX src/caffe/layers/pooling_layer.cpp\r\nCXX src/caffe/layers/cudnn_softmax_layer.cpp\r\nCXX src/caffe/layers/cudnn_lrn_layer.cpp\r\nCXX src/caffe/layers/threshold_layer.cpp\r\nCXX src/caffe/layers/batch_reindex_layer.cpp\r\nCXX src/caffe/layers/sigmoid_cross_entropy_loss_layer.cpp\r\nCXX src/caffe/layers/conv_layer.cpp\r\nCXX src/caffe/layers/elu_layer.cpp\r\nCXX src/caffe/layers/embed_layer.cpp\r\nCXX src/caffe/layers/euclidean_loss_layer.cpp\r\nCXX src/caffe/layers/tile_layer.cpp\r\nCXX src/caffe/layers/cudnn_tanh_layer.cpp\r\nCXX src/caffe/layers/silence_layer.cpp\r\nCXX src/caffe/layers/dummy_data_layer.cpp\r\nCXX src/caffe/layers/scale_layer.cpp\r\nCXX src/caffe/layers/prelu_layer.cpp\r\nCXX src/caffe/layers/bias_layer.cpp\r\nCXX src/caffe/layers/dropout_layer.cpp\r\nCXX src/caffe/layers/exp_layer.cpp\r\nCXX src/caffe/layers/contrastive_loss_layer.cpp\r\nCXX src/caffe/layers/reshape_layer.cpp\r\nCXX src/caffe/layers/base_conv_layer.cpp\r\nCXX src/caffe/layers/mvn_layer.cpp\r\nCXX src/caffe/layers/spp_layer.cpp\r\nCXX src/caffe/layers/image_data_layer.cpp\r\nCXX src/caffe/layers/tanh_layer.cpp\r\nCXX src/caffe/layers/argmax_layer.cpp\r\nCXX src/caffe/layers/parameter_layer.cpp\r\nAR -o .build_release/lib/libcaffe.a\r\nLD -o .build_release/lib/libcaffe.so.1.0.0\r\n/usr/bin/ld: cannot find -l -llmdb\r\ncollect2: error: ld returned 1 exit status\r\nMakefile:575: recipe for target '.build_release/lib/libcaffe.so.1.0.0' failed\r\nmake: *** [.build_release/lib/libcaffe.so.1.0.0] Error 1\r\nroot@esense9:~/.local/install/caffe# \r\n\r\nAR -o .build_release/lib/libcaffe.a\r\nLD -o .build_release/lib/libcaffe.so.1.0.0\r\n/usr/bin/ld: cannot find -l -llmdb\r\ncollect2: error: ld returned 1 exit status\r\nMakefile:575: recipe for target '.build_release/lib/libcaffe.so.1.0.0' failed\r\nmake: *** [.build_release/lib/libcaffe.so.1.0.0] Error 1\r\n"", ""Seems there was nothing wrong. In case you're using [Ubuntu](http://caffe.berkeleyvision.org/install_apt.html), have you tried installing with pre-compiled caffe, or installing lmdb with apt?"", ""error gone llmdb but new error are came \r\naR -o .build_release/lib/libcaffe.a\r\nLD -o .build_release/lib/libcaffe.so.1.0.0\r\n/usr/bin/ld: cannot find -lhdf5_hl\r\n/usr/bin/ld: cannot find -lhdf5\r\ncollect2: error: ld returned 1 exit status\r\nMakefile:572: recipe for target '.build_release/lib/libcaffe.so.1.0.0' failed\r\nmake: *** [.build_release/lib/libcaffe.so.1.0.0] Error 1\r\n"", 'Try\r\n\r\n```bash\r\napt-get install libhdf5 libhdf5-dev\r\n```', 'If you are working with Ubuntu, you may want to check this [issue  #156](https://github.com/NVIDIA/DIGITS/issues/156#issuecomment-219089383). \r\n\r\nThis worked for me. Add the following lines in MakeFile.config `INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial/` and `LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu/hdf5/serial/`', 'Please do not post usage, installation, or modeling questions, or other requests for help to Issues. Use the [caffe-users list][1] instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe. Please read the [guidelines for contributing][2] before submitting an issue or a pull request.\r\n\r\nQuestions about missing libraries have been asked multiple times. Please research the meaning of `/usr/bin/ld: cannot find -l<library>` message and how to install missing libraries.\r\n\r\n [1]: https://groups.google.com/forum/#!forum/caffe-users\r\n [2]: https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md', ""/usr/bin/ld: cannot find -l -llmdb\r\nI have the same problem,installing lmdb with apt don't work"", '`/usr/bin/ld:  -l -llmdb`\r\n\r\nSo what is the solution?', 'the solution is that use your pip to install lmdb\r\nfor example:\r\npip3 install lmdb']",[],[],0,0
86,caffe,3053,closed,Error with cudaFreeHost(ptr) in syncedmem.hpp:30,"In my case, when caffe model finishs predicting an image. There is the below error:

F0910 15:09:52.590445 21913 syncedmem.hpp:30] Check failed: error == cudaSuccess (11 vs. 0)  invalid argument
**\* Check failure stack trace: ***
Aborted

It comes from CUDA_CHECK(cudaFreeHost(ptr));  in syncedmem.hpp.
Everything else works well. Any ideas for fixing this? I use latest code in the master.

I'm using Ubuntu 14.04, NVIDIA driver 352.41, Cuda 7.5 and CuDNN v2.
",,"[""I get the same error in Python 2.7:\n\n```\nimport caffe\n#standard bvlc_alexnet\nnet = caffe.Net('deploy.prototxt', 'bvlc_alexnet.caffemodel', caffe.TEST)\ncaffe.set_mode_gpu()\nexit\n```\n\nOn Ubuntu 14.04, NVIDIA 346.82, Cuda 7. The error is encountered after the exit command. \n"", ""I've seen this before as well as a crash whenever a net is deleted after a predict. This not guaranteed to help you immediately, but you may want to try to get your Caffe tree back to one of these two commits and try your code again:\n- 0dfc5dac3d8bf17f833e21ae6ce7bc3ea19a03fa\n- d2f045768cba7d494abb4d168fc366d6fce80b85\n\nHopefully, one of the versions above will work for you, thus helping to pinpoint the issue.\n\nEDIT: d2f045768cba7d494abb4d168fc366d6fce80b85 that activates pinned memory is crashing some of my setups at Net destruction, and this looks similar to the problem reported in this issue. Reverting the commit clears the bug.\n"", ""I think we have a bug here. I'll try to look into this today.\n"", ""@hberntsen @beniz I just took a look today. Can you reproduce the same error if you run `caffe.set_mode_gpu()` **before** creating your net? That is, \n\n```\nimport caffe\n#standard bvlc_alexnet\ncaffe.set_mode_gpu()\nnet = caffe.Net('deploy.prototxt', 'bvlc_alexnet.caffemodel', caffe.TEST)\nexit\n```\n\nRight now the mode is not (but actually should be) an attribute of the net that is set up during creation (just like phase), since in CPU mode `malloc` is used while in GPU mode `cudaMallocHost` is used (introduced in #2903). So, if you run `caffe.set_mode_gpu()` after creating a net, caffe will allocate CPU memory using `malloc` (since it is CPU mode during net construction) and try to use `cudaFreeHost` instead of `free` to free memory allocated by `malloc` when destroying a net, resulting in this error.\n"", 'One solution is to always use `cudaMallocHost` to allocate host memory unless using CPU_ONLY build. @shelhamer do you agree? Some docs regarding this function:\n\n> The cudaMallocHost operation under the hood is doing something like a malloc plus additional OS functions to ""pin"" each page associated with the allocation (making cudaMemcpy faster). These additional OS operations take extra time, as compared to just doing a malloc. And note that as the size of the allocation increases, the registration (""pinning"") cost will generally increase as well.\n\nAlternatively, we can also add mode to be an attribute of net, but that involves more hacking at the cost of interface change and at risk of introducing new mistakes.\n', ""@ronghanghu I believe this is indeed a good catch, thanks for the quick reaction! Though I cannot test-run immediately, my code appears to be calling `set_mode_gpu` after Net creation.\n\n> Alternatively, we can also add mode to be an attribute of net, but that involves more hacking at the cost of interface change and at risk of introducing new mistakes.\n\nIf this gives the ability to have multiple nets in memory, some using CPU, some using GPU, as a user of the caffelib, I would rate it as a very good feature to conserve (since as far as I understand, this was working prior enforcing the use of `cudaMallocHost').\n"", ""> If this gives the ability to have multiple nets in memory, some using CPU, some using GPU, as a user of the caffelib, I would rate it as a very good feature to conserve (since as far as I understand, this was working prior enforcing the use of `cudaMallocHost').\n\nEventually we would like to give mode and device to net and layers, in the spirit of #1500. ~~But it seems like a short-term fix to always use `cudaMallocHost` to allocate cpu memory regardless of the mode of the net to avoid this crash.~~ `cudaMallocHost` seems to assume at least one GPU is there (I don't know why). seem to be running into the same issue as mentioned in 46a431a\n\nHowever, although mode/device is right now not a member of Net and Layer and thus changable in runtime, it is better to set them in advance and not change them during a lifecycle of a net.\n"", '@ronghanghu In that case the error is does not appear. So setting the mode to GPU before loading the net circumvents the error. \n', 'I use caffe.Classifier to contruct the net, not caffe.Net. So when I use\n\n```\nself.net = caffe.Classifier(MODEL_FILE, PRETRAINED) \ncaffe.set_mode_gpu()\n```\n\nor \n\n```\ncaffe.set_mode_gpu()\nself.net = caffe.Classifier(MODEL_FILE, PRETRAINED)\n```\n\nthis error is still there.\n\nI will try suggested commits above. Thanks.\n', 'I also test on GPUs with and without connected monitor to see if it is the problem of freeing in-use GPU memory. Still got the error.\n', ""@LiberiFatali I could not reproduce your mistake (here is the code snap I used).\n\n```\nimport caffe\ncaffe.set_mode_gpu()\n\nmodel   = './caffe/models/bvlc_reference_caffenet/deploy.prototxt'\nweights = './caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\nnet = caffe.Classifier(model, weights)\n\nimpath = './caffe/examples/images/cat.jpg'\nim = caffe.io.load_image(impath)\nprobs = net.predict([im])\n```\n\nIt doesn't produce any error on a BVLC machine. Can you try out this code snap on your machine?\n"", '@ronghanghu Above codes work well on my machine. Setting mode gpu before creating the net solves it now.\n', 'I have exactly the same issue when cleaning up network instances in Matlab with call to `caffe.reset_all()`. Placing `caffe.set_mode_gpu();` before loading the model also solved it.\n', 'I put the setmode before net creation. But i got this error still.\nHow can i solve this problem?\nThanks.\n', '@cheer37 ,have you fix the problem ,i did not use the latest PR of caffe,and i get the same error \nCheck failed: error == cudaSuccess (29 vs. 0) driver shutting down\nhow did you solve this problem ?\nthanks.\n', '@ucasqcz have you fix the problem, i get the same error\r\nCheck failed: error == cudaSuccess (29 vs. 0) driver shutting down\r\nhow did you solve this problem ?']",[],[],0,0
87,caffe,6740,closed,nvcc fatal   : A single input file is required for a non-link phase when an outputfile is specified,"
### Issue summary
PROTOC src/caffe/proto/caffe.proto
CXX .build_debug/src/caffe/proto/caffe.pb.cc
CXX src/caffe/util/upgrade_proto.cpp
CXX src/caffe/util/signal_handler.cpp
CXX src/caffe/util/math_functions.cpp
CXX src/caffe/util/io.cpp
CXX src/caffe/util/insert_splits.cpp
CXX src/caffe/util/im2col.cpp
CXX src/caffe/util/hdf5.cpp
CXX src/caffe/util/db_lmdb.cpp
CXX src/caffe/util/db_leveldb.cpp
CXX src/caffe/util/db.cpp
CXX src/caffe/util/cudnn.cpp
CXX src/caffe/util/blocking_queue.cpp
CXX src/caffe/util/benchmark.cpp
CXX src/caffe/solvers/sgd_solver.cpp
CXX src/caffe/solvers/rmsprop_solver.cpp
CXX src/caffe/solvers/nesterov_solver.cpp
CXX src/caffe/solvers/adam_solver.cpp
CXX src/caffe/solvers/adagrad_solver.cpp
CXX src/caffe/solvers/adadelta_solver.cpp
CXX src/caffe/layers/window_data_layer.cpp
CXX src/caffe/layers/tile_layer.cpp
CXX src/caffe/layers/threshold_layer.cpp
CXX src/caffe/layers/tanh_layer.cpp
CXX src/caffe/layers/swish_layer.cpp
CXX src/caffe/layers/spp_layer.cpp
CXX src/caffe/layers/split_layer.cpp
CXX src/caffe/layers/softmax_loss_layer.cpp
CXX src/caffe/layers/softmax_layer.cpp
CXX src/caffe/layers/slice_layer.cpp
CXX src/caffe/layers/silence_layer.cpp
CXX src/caffe/layers/sigmoid_layer.cpp
CXX src/caffe/layers/sigmoid_cross_entropy_loss_layer.cpp
CXX src/caffe/layers/scale_layer.cpp
CXX src/caffe/layers/rnn_layer.cpp
CXX src/caffe/layers/reshape_layer.cpp
CXX src/caffe/layers/relu_layer.cpp
CXX src/caffe/layers/reduction_layer.cpp
CXX src/caffe/layers/recurrent_layer.cpp
CXX src/caffe/layers/prelu_layer.cpp
CXX src/caffe/layers/power_layer.cpp
CXX src/caffe/layers/pooling_layer.cpp
CXX src/caffe/layers/parameter_layer.cpp
CXX src/caffe/layers/neuron_layer.cpp
CXX src/caffe/layers/mvn_layer.cpp
CXX src/caffe/layers/multinomial_logistic_loss_layer.cpp
CXX src/caffe/layers/memory_data_layer.cpp
CXX src/caffe/layers/lstm_unit_layer.cpp
CXX src/caffe/layers/lstm_layer.cpp
CXX src/caffe/layers/lrn_layer.cpp
CXX src/caffe/layers/loss_layer.cpp
CXX src/caffe/layers/log_layer.cpp
CXX src/caffe/layers/input_layer.cpp
CXX src/caffe/layers/inner_product_layer.cpp
CXX src/caffe/layers/infogain_loss_layer.cpp
CXX src/caffe/layers/image_data_layer.cpp
CXX src/caffe/layers/im2col_layer.cpp
CXX src/caffe/layers/hinge_loss_layer.cpp
CXX src/caffe/layers/hdf5_output_layer.cpp
CXX src/caffe/layers/hdf5_data_layer.cpp
CXX src/caffe/layers/flatten_layer.cpp
CXX src/caffe/layers/filter_layer.cpp
CXX src/caffe/layers/exp_layer.cpp
CXX src/caffe/layers/euclidean_loss_layer.cpp
CXX src/caffe/layers/embed_layer.cpp
CXX src/caffe/layers/elu_layer.cpp
CXX src/caffe/layers/eltwise_layer.cpp
CXX src/caffe/layers/dummy_data_layer.cpp
CXX src/caffe/layers/dropout_layer.cpp
CXX src/caffe/layers/deconv_layer.cpp
CXX src/caffe/layers/data_layer.cpp
CXX src/caffe/layers/cudnn_tanh_layer.cpp
CXX src/caffe/layers/cudnn_softmax_layer.cpp
CXX src/caffe/layers/cudnn_sigmoid_layer.cpp
CXX src/caffe/layers/cudnn_relu_layer.cpp
CXX src/caffe/layers/cudnn_pooling_layer.cpp
CXX src/caffe/layers/cudnn_lrn_layer.cpp
CXX src/caffe/layers/cudnn_lcn_layer.cpp
CXX src/caffe/layers/cudnn_deconv_layer.cpp
CXX src/caffe/layers/cudnn_conv_layer.cpp
CXX src/caffe/layers/crop_layer.cpp
CXX src/caffe/layers/conv_layer.cpp
CXX src/caffe/layers/contrastive_loss_layer.cpp
CXX src/caffe/layers/concat_layer.cpp
CXX src/caffe/layers/clip_layer.cpp
CXX src/caffe/layers/bnll_layer.cpp
CXX src/caffe/layers/bias_layer.cpp
CXX src/caffe/layers/batch_reindex_layer.cpp
CXX src/caffe/layers/batch_norm_layer.cpp
CXX src/caffe/layers/base_data_layer.cpp
CXX src/caffe/layers/base_conv_layer.cpp
CXX src/caffe/layers/argmax_layer.cpp
CXX src/caffe/layers/accuracy_layer.cpp
CXX src/caffe/layers/absval_layer.cpp
CXX src/caffe/syncedmem.cpp
CXX src/caffe/solver.cpp
CXX src/caffe/parallel.cpp
CXX src/caffe/net.cpp
CXX src/caffe/layer_factory.cpp
CXX src/caffe/layer.cpp
CXX src/caffe/internal_thread.cpp
CXX src/caffe/data_transformer.cpp
CXX src/caffe/common.cpp
CXX src/caffe/blob.cpp
NVCC src/caffe/util/math_functions.cu
nvcc fatal   : A single input file is required for a non-link phase when an outputfile is specified
make: *** [.build_debug/cuda/src/caffe/util/math_functions.o] Error 1

### System configuration

* Operating system: Linux
* Compiler: gcc 4.8.5
* CUDA version (if applicable):  CUDA 10 / CUDA 9 all tried
* CUDNN version (if applicable):  7.4.1
* BLAS:  open
* Python version (if using pycaffe):  2.7

### Tried solutions
I tried use CUDA9 and 10 but all failed. It's strange there is only nvcc fatal ... but no more information. I don't know how to continue. Can anyone help me? Thank you !!!

",,"['OK everyoneI slove this problem.\r\nMy GPU is GTX1080Ti\r\nSo the former CUDA_ARCH in Makefile.config\r\nCUDA_ARCH := -gencode arch=compute_20,code=sm_20 \\\r\n\t\t-gencode arch=compute_20,code=sm_21 \\\r\n\t\t-gencode arch=compute_30,code=sm_30 \\\r\n\t\t-gencode arch=compute_35,code=sm_35 \\\r\n\t\t-gencode arch=compute_50,code=sm_50 \\\r\n\t\t-gencode arch=compute_52,code=sm_52 \\\r\n\t\t-gencode arch=compute_60,code=sm_60 \\\r\n\t\t-gencode arch=compute_61,code=sm_61 \\\r\n\t\t-gencode arch=compute_61,code=compute_61\r\n \r\nshould be modified like this:\r\n\r\nCUDA_ARCH := -gencode arch=compute_61,code=sm_61 \\\r\n\t\t-gencode arch=compute_61,code=compute_61\r\n']",[],[],0,0
88,caffe,920,closed,Why use leveldb and DataLayer i.s.o. ImageDataLayer ?,"When training the imagenet set (1.2M images, 1K classes) using an ImageDataLayer, I get approximately the same (<5% diff) performance as when using leveldb+DataLayer. What is the use of the leveldb then?

fwiw: 36 secs / 20 iterations (5,120 images). Testing: 123 secs / validation set (50,000 images) on a GTX760/4GB and i5-4590
",,"['Please continue the discussion on the\xa0[caffe-users mailing list](https://groups.google.com/forum/#!forum/caffe-users). As of the latest release we prefer to keep issues reserved for Caffe development. Thanks!\n', 'Glad to know that ImageDataLayer is only 5% slower, while require much less\ndisk space.\n\nSergio\n\n2014-08-13 6:31 GMT-07:00 bhack notifications@github.com:\n\n> Please continue the discussion on the caffe-users mailing list\n> https://groups.google.com/forum/#!forum/caffe-users. As of the latest\n> release we prefer to keep issues reserved for Caffe development. Thanks!\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/920#issuecomment-52047764.\n', ""@sguada the difference might show up more plainly on faster hardware or longer training. 5% of ImageNet time is still hours. A Titan has a training iter time of 26s instead of 36s and more importantly once parallelism is up we'll presumably need fast IO too.\n\nWorth benchmarking when we come to it.\n\n@develaya make future posts to the mailing list: https://groups.google.com/forum/m/#!forum/caffe-users\n""]",[],[],0,0
89,caffe,6153,open,"mex: compile of ' ""matlab/+caffe/private/caffe_.cpp""' failed.","Hi:

I am trying to build **matcaffe** with matlab 2015a with gcc-4.7.4. (Ubuntu 16.04)

And I have succeed in compilng caffe for python already.

However, I met this ""caffe_.cpp"" issue and tried several solutions online does not know the best way to fix this. Could anyone help me on this?

Please use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) for usage, installation, or modeling questions, or other requests for help.
_Do not post such requests to Issues._ Doing so interferes with the development of Caffe.

Please read the [guidelines for contributing](https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md) before submitting this issue.

### Issue summary


### Steps to reproduce

If you are having difficulty building Caffe or training a model, please ask the caffe-users mailing list. If you are reporting a build error that seems to be due to a bug in Caffe, please attach your build configuration (either Makefile.config or CMakeCache.txt) and the output of the make (or cmake) command.

### Your system configuration
Operating system:
Compiler:
CUDA version (if applicable):
CUDNN version (if applicable):
BLAS:
Python or MATLAB version (for pycaffe and matcaffe respectively):
",Matlab,"['Add ""CXXFLAGS += -std=c++11"" in Makefile, as follows:\r\n![image](https://user-images.githubusercontent.com/26788824/38469160-e1e9b9c8-3b82-11e8-93cd-7c35a37f7173.png)\r\n']","['\r\n make matcaffe\r\nPROTOC src/caffe/proto/caffe.proto\r\nCXX .build_release/src/caffe/proto/caffe.pb.cc\r\nCXX src/caffe/parallel.cpp\r\nCXX src/caffe/solvers/adam_solver.cpp\r\nCXX src/caffe/solvers/adagrad_solver.cpp\r\nCXX src/caffe/solvers/sgd_solver.cpp\r\nCXX src/caffe/solvers/rmsprop_solver.cpp\r\nCXX src/caffe/solvers/adadelta_solver.cpp\r\nCXX src/caffe/solvers/nesterov_solver.cpp\r\nCXX src/caffe/common.cpp\r\nCXX src/caffe/blob.cpp\r\nCXX src/caffe/layers/scale_layer.cpp\r\nCXX src/caffe/layers/exp_layer.cpp\r\nCXX src/caffe/layers/loss_layer.cpp\r\nCXX src/caffe/layers/batch_reindex_layer.cpp\r\nCXX src/caffe/layers/crop_layer.cpp\r\nCXX src/caffe/layers/input_layer.cpp\r\nCXX src/caffe/layers/cudnn_lcn_layer.cpp\r\nCXX src/caffe/layers/im2col_layer.cpp\r\nCXX src/caffe/layers/tile_layer.cpp\r\nCXX src/caffe/layers/cudnn_sigmoid_layer.cpp\r\nCXX src/caffe/layers/parameter_layer.cpp\r\nCXX src/caffe/layers/accuracy_layer.cpp\r\nCXX src/caffe/layers/power_layer.cpp\r\nCXX src/caffe/layers/contrastive_loss_layer.cpp\r\nCXX src/caffe/layers/multinomial_logistic_loss_layer.cpp\r\nCXX src/caffe/layers/sigmoid_layer.cpp\r\nCXX src/caffe/layers/reshape_layer.cpp\r\nCXX src/caffe/layers/conv_layer.cpp\r\nCXX src/caffe/layers/embed_layer.cpp\r\nCXX src/caffe/layers/cudnn_softmax_layer.cpp\r\nCXX src/caffe/layers/recurrent_layer.cpp\r\nCXX src/caffe/layers/image_data_layer.cpp\r\nCXX src/caffe/layers/cudnn_lrn_layer.cpp\r\nCXX src/caffe/layers/base_conv_layer.cpp\r\nCXX src/caffe/layers/prelu_layer.cpp\r\nCXX src/caffe/layers/cudnn_tanh_layer.cpp\r\nCXX src/caffe/layers/lstm_layer.cpp\r\nCXX src/caffe/layers/eltwise_layer.cpp\r\nCXX src/caffe/layers/cudnn_pooling_layer.cpp\r\nCXX src/caffe/layers/dropout_layer.cpp\r\nCXX src/caffe/layers/flatten_layer.cpp\r\nCXX src/caffe/layers/batch_norm_layer.cpp\r\nCXX src/caffe/layers/argmax_layer.cpp\r\nCXX src/caffe/layers/euclidean_loss_layer.cpp\r\nCXX src/caffe/layers/tanh_layer.cpp\r\nCXX src/caffe/layers/lstm_unit_layer.cpp\r\nCXX src/caffe/layers/sigmoid_cross_entropy_loss_layer.cpp\r\nCXX src/caffe/layers/elu_layer.cpp\r\nCXX src/caffe/layers/concat_layer.cpp\r\nCXX src/caffe/layers/hdf5_data_layer.cpp\r\nCXX src/caffe/layers/softmax_layer.cpp\r\nCXX src/caffe/layers/pooling_layer.cpp\r\nCXX src/caffe/layers/relu_layer.cpp\r\nCXX src/caffe/layers/rnn_layer.cpp\r\nCXX src/caffe/layers/spp_layer.cpp\r\nCXX src/caffe/layers/hinge_loss_layer.cpp\r\nCXX src/caffe/layers/memory_data_layer.cpp\r\nCXX src/caffe/layers/window_data_layer.cpp\r\nCXX src/caffe/layers/filter_layer.cpp\r\nCXX src/caffe/layers/softmax_loss_layer.cpp\r\nCXX src/caffe/layers/deconv_layer.cpp\r\nCXX src/caffe/layers/bias_layer.cpp\r\nCXX src/caffe/layers/bnll_layer.cpp\r\nCXX src/caffe/layers/hdf5_output_layer.cpp\r\nCXX src/caffe/layers/threshold_layer.cpp\r\nCXX src/caffe/layers/reduction_layer.cpp\r\nCXX src/caffe/layers/absval_layer.cpp\r\nCXX src/caffe/layers/neuron_layer.cpp\r\nCXX src/caffe/layers/log_layer.cpp\r\nCXX src/caffe/layers/cudnn_relu_layer.cpp\r\nCXX src/caffe/layers/silence_layer.cpp\r\nCXX src/caffe/layers/infogain_loss_layer.cpp\r\nCXX src/caffe/layers/inner_product_layer.cpp\r\nCXX src/caffe/layers/cudnn_conv_layer.cpp\r\nCXX src/caffe/layers/slice_layer.cpp\r\nCXX src/caffe/layers/dummy_data_layer.cpp\r\nCXX src/caffe/layers/data_layer.cpp\r\nCXX src/caffe/layers/base_data_layer.cpp\r\nCXX src/caffe/layers/mvn_layer.cpp\r\nCXX src/caffe/layers/lrn_layer.cpp\r\nCXX src/caffe/layers/split_layer.cpp\r\nCXX src/caffe/util/db_leveldb.cpp\r\nCXX src/caffe/util/upgrade_proto.cpp\r\nCXX src/caffe/util/cudnn.cpp\r\nCXX src/caffe/util/im2col.cpp\r\nCXX src/caffe/util/db_lmdb.cpp\r\nCXX src/caffe/util/db.cpp\r\nCXX src/caffe/util/insert_splits.cpp\r\nCXX src/caffe/util/benchmark.cpp\r\nCXX src/caffe/util/blocking_queue.cpp\r\nCXX src/caffe/util/hdf5.cpp\r\nCXX src/caffe/util/io.cpp\r\nCXX src/caffe/util/signal_handler.cpp\r\nCXX src/caffe/util/math_functions.cpp\r\nCXX src/caffe/syncedmem.cpp\r\nCXX src/caffe/solver.cpp\r\nCXX src/caffe/net.cpp\r\nCXX src/caffe/internal_thread.cpp\r\nCXX src/caffe/layer.cpp\r\nCXX src/caffe/layer_factory.cpp\r\nCXX src/caffe/data_transformer.cpp\r\nAR -o .build_release/lib/libcaffe.a\r\nMEX matlab/+caffe/private/caffe_.cpp\r\nWarning: Legacy MEX infrastructure is provided for compatibility; it will be removed in a future version of MATLAB. For more information, consult the MEX release notes http://www.mathworks.com/help/matlab/release-notes.html.\r\nmatlab/+caffe/private/caffe_.cpp: In function void delete_solver(int, mxArray**, int, const mxArray**):\r\nmatlab/+caffe/private/caffe_.cpp:208:3: warning: lambda expressions only available with -std=c++11 or -std=gnu++11 [enabled by default]\r\nmatlab/+caffe/private/caffe_.cpp:208:4: error: no matching function for call to remove_if(std::vector<boost::shared_ptr<caffe::Solver<float> > >::iterator, std::vector<boost::shared_ptr<caffe::Solver<float> > >::iterator, delete_solver(int, mxArray**, int, const mxArray**)::<lambda(const boost::shared_ptr<caffe::Solver<float> >&)>)\r\nmatlab/+caffe/private/caffe_.cpp:208:4: note: candidate is:\r\nIn file included from /usr/include/c++/4.7/algorithm:63:0,\r\n                 from ./include/caffe/blob.hpp:4,\r\n                 from ./include/caffe/caffe.hpp:7,\r\n                 from matlab/+caffe/private/caffe_.cpp:18:\r\n/usr/include/c++/4.7/bits/stl_algo.h:1166:5: note: template<class _FIter, class _Predicate> _FIter std::remove_if(_FIter, _FIter, _Predicate)\r\nmatlab/+caffe/private/caffe_.cpp:208:4: error: template argument for template<class _FIter, class _Predicate> _FIter std::remove_if(_FIter, _FIter, _Predicate) uses local type delete_solver(int, mxArray**, int, const mxArray**)::<lambda(const boost::shared_ptr<caffe::Solver<float> >&)>\r\nmatlab/+caffe/private/caffe_.cpp:208:4: error:   trying to instantiate template<class _FIter, class _Predicate> _FIter std::remove_if(_FIter, _FIter, _Predicate)\r\nmatlab/+caffe/private/caffe_.cpp: In function void delete_net(int, mxArray**, int, const mxArray**):\r\nmatlab/+caffe/private/caffe_.cpp:293:3: warning: lambda expressions only available with -std=c++11 or -std=gnu++11 [enabled by default]\r\nmatlab/+caffe/private/caffe_.cpp:293:4: error: no matching function for call to remove_if(std::vector<boost::shared_ptr<caffe::Net<float> > >::iterator, std::vector<boost::shared_ptr<caffe::Net<float> > >::iterator, delete_net(int, mxArray**, int, const mxArray**)::<lambda(const boost::shared_ptr<caffe::Net<float> >&)>)\r\nmatlab/+caffe/private/caffe_.cpp:293:4: note: candidate is:\r\nIn file included from /usr/include/c++/4.7/algorithm:63:0,\r\n                 from ./include/caffe/blob.hpp:4,\r\n                 from ./include/caffe/caffe.hpp:7,\r\n                 from matlab/+caffe/private/caffe_.cpp:18:\r\n/usr/include/c++/4.7/bits/stl_algo.h:1166:5: note: template<class _FIter, class _Predicate> _FIter std::remove_if(_FIter, _FIter, _Predicate)\r\nmatlab/+caffe/private/caffe_.cpp:293:4: error: template argument for template<class _FIter, class _Predicate> _FIter std::remove_if(_FIter, _FIter, _Predicate) uses local type delete_net(int, mxArray**, int, const mxArray**)::<lambda(const boost::shared_ptr<caffe::Net<float> >&)>\r\nmatlab/+caffe/private/caffe_.cpp:293:4: error:   trying to instantiate template<class _FIter, class _Predicate> _FIter std::remove_if(_FIter, _FIter, _Predicate)\r\n\r\n    mex: compile of \' ""matlab/+caffe/private/caffe_.cpp""\' failed.\r\n\r\nMakefile:522: recipe for target \'matlab/+caffe/private/caffe_.mexa64\' failed\r\nmake: *** [matlab/+caffe/private/caffe_.mexa64] Error 255\r\n\r\n']",[],0,0
90,caffe,5639,closed,OpenCL branch: runtest fails NetTest/0 on CPUDevice<float>,"### Issue summary
I ran ""make -j8 runtest"" and noticed that a single test out of 2000 or so fails. This is a CPU test. There seems to be a slight difference in the numerical output, by eye it seems less than <0.001. The error persists if I use openBlas instead of Atlas (using update-alternatives).

### Steps to reproduce
 

Final output:


### Your system configuration
Operating system: linux mint (similar to Ubuntu 16.04 with custom kernel 4.10)
Compiler: gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4) 
CUDA version (if applicable): no
CUDNN version (if applicable): no
BLAS: ATLAS 
Python or MATLAB version (for pycaffe and matcaffe respectively):

I suppose it shouldn't change anything, but the CPU is a Ryzen 1700X and my compilation flags are:
CFLAGS=-O2 -mprefer-avx128 -mavx2 -mcx16 -mmovbe -mf16c -mpopcnt -mbmi -mbmi2 -mclflushopt -fomit-frame-pointer
CXXFLAGS= the same

",,"['This is ok, just the precision is slightly lower than expected. You can safely ignore this, especially if you plan to use GPUs anyways.', 'OK, thanks!']","['\r\n----------] 26 tests from NetTest/0, where TypeParam = caffe::CPUDevice<float>\r\n[ RUN      ] NetTest/0.TestReshape\r\n[       OK ] NetTest/0.TestReshape (1 ms)\r\n[ RUN      ] NetTest/0.TestAllInOneNetDeploy\r\n[       OK ] NetTest/0.TestAllInOneNetDeploy (0 ms)\r\n[ RUN      ] NetTest/0.TestUnsharedWeightsDataNet\r\n[       OK ] NetTest/0.TestUnsharedWeightsDataNet (0 ms)\r\n[ RUN      ] NetTest/0.TestSharedWeightsDataNet\r\n[       OK ] NetTest/0.TestSharedWeightsDataNet (1 ms)\r\n[ RUN      ] NetTest/0.TestComboLossWeight\r\n[       OK ] NetTest/0.TestComboLossWeight (2 ms)\r\n[ RUN      ] NetTest/0.TestFromTo\r\n[       OK ] NetTest/0.TestFromTo (2 ms)\r\n[ RUN      ] NetTest/0.TestBottomNeedBackward\r\n[       OK ] NetTest/0.TestBottomNeedBackward (0 ms)\r\n[ RUN      ] NetTest/0.TestLossWeight\r\n[       OK ] NetTest/0.TestLossWeight (3 ms)\r\n[ RUN      ] NetTest/0.TestLossWeightMidNet\r\n[       OK ] NetTest/0.TestLossWeightMidNet (3 ms)\r\n[ RUN      ] NetTest/0.TestUnsharedWeightsDiffNet\r\n[       OK ] NetTest/0.TestUnsharedWeightsDiffNet (1 ms)\r\n[ RUN      ] NetTest/0.TestBottomNeedBackwardEuclideanForce\r\n[       OK ] NetTest/0.TestBottomNeedBackwardEuclideanForce (0 ms)\r\n[ RUN      ] NetTest/0.TestSharedWeightsUpdate\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 15.553734\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 15.553722\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 6.0058942\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 6.0058975\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 13.251015\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 13.251003\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 13.776414\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 13.776409\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 3.7031746\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 3.7031784\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 11.618912\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 11.618902\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 14.129814\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 14.129803\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 14.655213\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 14.655209\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 4.5819745\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 4.5819778\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 13.396614\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 13.396606\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 9.9528046\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 9.9527969\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 0.40497398\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 0.40497208\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 6.8997421\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 6.8997383\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 7.425149\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 7.4251442\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: -2.6480846\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: -2.6480865\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 14.29718\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 14.297173\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 8.3312454\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 8.331234\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 8.8566446\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 8.8566399\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: -1.216589\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: -1.2165909\r\nsrc/caffe/test/test_net.cpp:1282: Failure\r\nValue of: shared_params.cpu_diff()[i]\r\n  Actual: 7.9619598\r\nExpected: ip1_weights->cpu_diff()[i] + ip2_weights->cpu_diff()[i]\r\nWhich is: 7.9619541\r\n[  FAILED  ] NetTest/0.TestSharedWeightsUpdate, where TypeParam = caffe::CPUDevice<float> (2 ms)\r\n\r\n']","['[----------] Global test environment tear-down\r\n[==========] 2066 tests from 274 test cases ran. (1821400 ms total)\r\n[  PASSED  ] 2065 tests.\r\n[  FAILED  ] 1 test, listed below:\r\n[  FAILED  ] NetTest/0.TestSharedWeightsUpdate, where TypeParam = caffe::CPUDevice<float>\r\n\r\n 1 FAILED TEST\r\n*** Aborted at 1495549404 (unix time) try ""date -d @1495549404"" if you are using GNU date ***\r\nPC: @     0x7fd64b48c68f caffe::SyncedMemory::~SyncedMemory()\r\n*** SIGSEGV (@0x0) received by PID 9535 (TID 0x7fd64da47ac0) from PID 0; stack trace: ***\r\n    @     0x7fd64a9a0390 (unknown)\r\n    @     0x7fd64b48c68f caffe::SyncedMemory::~SyncedMemory()\r\n    @           0x48c2d2 boost::detail::sp_counted_impl_p<>::dispose()\r\n    @           0x48050a boost::detail::sp_counted_base::release()\r\n    @           0x482862 boost::detail::sp_counted_impl_p<>::dispose()\r\n    @     0x7fd64b294361 boost::detail::sp_counted_impl_p<>::dispose()\r\n    @     0x7fd64b2920a8 std::vector<>::~vector()\r\n    @     0x7fd64a60036a __cxa_finalize\r\n    @     0x7fd64b22fe63 (unknown)\r\nMakefile:672: recipe for target \'runtest\' failed\r\nmake: *** [runtest] Segmentation fault\r\n']",0,0
91,caffe,2357,closed,Regression for a 2d signal in caffe,"Hi

I am trying to do some regression for audio signals. My training signal is a big spectrogram which I am feeding in as data of size 513 x num_frames. I want my loss to be computed based on this signal and another spectrogram of the same dimensions. I am using 2d convolution for this and am feeding in the data to the first data blob in HDF5 format as 1 1 513 num_frames. I adjusted the padding according to the kernel size at each layer to keep this dimensionality consistent. At the loss layer (using eucledian distance), I have 1 1 513 num_frames but caffe doesn't let me feed in the label as more than 2d (though my data is 4d as mentioned). It gives me an error: Check failed: ndims <= max_dim (4 vs. 2) 

I tried feeding in an extra input to the first data layer of 1 1 513 num_frames as well along with data and label. But I get the error: ExactNumTopBlobs() == top.size() (2 vs. 3) HDF5_DATA Layer produces 2 top blob(s) as output.

I need my labels to be in the format 1 1 513 num_frames. Could you help me with this?
",,"['Please ask modeling questions on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) group. `EuclideanLossLayer` accepts predictions and truth of any dimension (as long as they match, of course) if it is given the input in the right way.\n', ""But the input it can take is the output from the previous CONV layer and the label from the intial blob input. The data blob layer won't let me give a label input greater than 2d, I need 4d. I posted in the caffe users group as well:\nhttps://groups.google.com/forum/#!topic/caffe-users/xjJqwauvBMQ\n"", ""Continued in the Caffe users thread.\n\nOn Mon, Apr 27, 2015 at 8:43 AM, vinaymaddali notifications@github.com\nwrote:\n\n> But the input it can take is the output from the previous CONV layer and\n> the label from the intial blob input. The data blob layer won't let me give\n> a label input greater than 2d, I need 4d. I posted in the caffe users group\n> as well:\n> https://groups.google.com/forum/#!topic/caffe-users/xjJqwauvBMQ\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/2357#issuecomment-96717032.\n""]",[],[],0,0
92,caffe,393,closed,nan issue with CIFAR10 example when running on CPU only,"Hi everyone,
I'm trying to run the CIFAR10  example(train_full.sh), which seems to work on the GPU (at least here I don't get the same issue, I'm not sure yet to what value it converges). In any case the problem I'm having is that after the first forward-backward pass somewhere in the pipeline there's a _nan_ introduced. This is not an issue related to the learning rate being to big, as I can even set the lr to 0 and have the same problem.
I tried to figure out what the problem was, but without any success yet. 

First of all, I wanted to ask if anyone else is having the same issues. It would be great if someone could confirm, that something is going wrong here.

What I found out so far is, that this might be related to the LRN layer, because after removal the issue disappears. However it might also be due to the interaction between some of the other layers, I'm not sure. If anyone else has some insight in this, it would be greatly appreciated.
",,"[""Interesting -- how many iterations does it take to see the nan? I swapped out the original ACROSS_CHANNELS pooling for WITHIN_CHANNEL pooling\\* and I never ran it on CPU because it is painfully slow, so you're likely right about the bug being there. \n\n*The two pooling region types get pretty much equal accuracy, but I wanted to use the exact architecture Alex Krizhevsky used in his cuda-convnet cifar-18pct example.  But if the WITHIN_CHANNEL isn't working you could try swapping the CROSS_CHANNEL back into the train/val prototxts if that satisfies whatever you're doing.\n"", ""I reproduced this; changing to `device_id: 0` and adding `random_seed: 1701` to the bottom of cifar10_full_solver.prototxt gives this result:\n\n```\nI0506 11:27:40.389626  6796 data_layer.cpp:117] Restarting data prefetching from start.\nI0506 11:27:41.909649  6533 solver.cpp:160] Test score #0: 0.1163\nI0506 11:27:41.909716  6533 solver.cpp:160] Test score #1: 2.3026\nI0506 11:27:42.676936  6533 softmax_loss_layer.cpp:58] Accuracy: 0.12\nI0506 11:31:17.406493  6533 solver.cpp:261] Iteration 1, lr = 0.001\nI0506 11:31:17.422197  6533 solver.cpp:105] Iteration 1, loss = 2.30258\nI0506 11:35:01.583555  6533 softmax_loss_layer.cpp:58] Accuracy: 0.08\nI0506 11:42:08.900871  6533 solver.cpp:261] Iteration 2, lr = 0.001\nI0506 11:42:08.955682  6533 solver.cpp:105] Iteration 2, loss = nan\n```\n\nThanks for reporting; for now I've added a note to the bottom of cifar10_full_solver.prototxt (pushed to latest dev) that there seems to be a bug with CPU training and a suggestion to change pooling to ACROSS_CHANNELS for CPU training.\n"", ""great, thanks for confirming. Any ideas about why it might fail on the CPU when using WITHIN_CHANNEL?\nWhat's weird is that as far as I can tell the GPU code for WITHIN_CHANNEL is using the CPU code. (WithinChannelForward being called within Forward_gpu). So to me it doesn't make much sense that it's working on one architecture but not the other.\n"", '@jeffdonahue was this fixed with whatever numerical stability update you made related to this at some point? #1095 Seems to say there is still an issue lurking somewhere.\n', ""@shelhamer it should be fixed yeah; I just tested train_full for 1000 iterations on GPU and 200 iterations on CPU and didn't get a NaN.  The fix isn't in master though -- not sure which one @YutingZhang is using.\n\n(Did find out that the cifar scripts hadn't been updated to be run from Caffe root though, which I just pushed a fix to dev for -- probably would be good to put that in the RC)\n"", '@jeffdonahue thanks for the script fix -- if you uncover other issues in the RC you should push / PR them to master and not dev so that they can be included now then back-merged to dev. Remember the new PR workflow with fixes to master.\n\nClosing since should be fixed in the latest release (and in dev for some time now).\n', ""Sorry, I forgot that was the new workflow.  Is it worth me cherry-picking to master now (causing a duplicate commit in dev whenever the next back-merge happens)?  It was actually a little worse than that the scripts hadn't been updated to run from root -- they'd been partially updated (I think just the net proto path in the solver proto, but not any of the paths in the scripts) such that it worked from neither the CIFAR directory nor from root.\n"", ""A cherry-pick and resolving the next back-merge should be fine. I'm\ncurrently feeling two-ways about back-merges so do the back-merge whenever\nyou feel like, whether after each individual change or letting a few fixes\nbatch up in master first. Seems less noisy to me to batch but it does leave\ndev unchanged in the interim (in the usual case where the PR / push was to\nmaster).\n\nOn Sun, Sep 21, 2014 at 3:10 PM, Jeff Donahue notifications@github.com\nwrote:\n\n> Sorry, I forgot that was the new workflow. Is it worth me cherry-picking\n> to master now (causing a duplicate commit in dev whenever the next\n> back-merge happens)? It was actually a little worse than that the scripts\n> hadn't been updated to run from root -- they'd been partially updated (I\n> think just the net proto path in the solver proto, but not any of the paths\n> in the scripts) such that it worked from neither the CIFAR directory nor\n> from root.\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/393#issuecomment-56314669.\n"", ""Ok, cherry-picked to master. I definitely don't think this case needs an immediate backmerge since the diff would literally be 0 bytes; in general I think we could just do it whenever the change in question seems substantial enough to backmerge (e.g. always on a bug fix, but never on docs changes), and then any minor ones in the interim get batched together with the substantial one.\n"", ""Deal. Reasonable and low-effort policy.\n\nOn Sun, Sep 21, 2014 at 4:06 PM, Jeff Donahue notifications@github.com\nwrote:\n\n> Ok, cherry-picked to master. I definitely don't think this case needs an\n> immediate backmerge since the diff would literally be 0 bytes; in general I\n> think we could just do it whenever the change in question seems substantial\n> enough to backmerge (e.g. always on a bug fix, but never on docs changes),\n> and then any minor ones in the interim get batched together with the\n> substantial one.\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/393#issuecomment-56316203.\n""]",[],[],0,0
93,caffe,5197,closed,Unable to compile caffe on CentOS 7 (cannot find -lsnappy),"I am trying to make caffe on CentOS 7. I am pretty sure all the required depedencies are installed.

This is Makefile.config:


the command  gives me the error:


I am sure I have snappy installed. _libsnappy.so.1_ and _libsnappy.so.1.1.4_ are in _/usr/lib64_.

What is the problem? Any kind of help is appreciated.
",,"['From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\r\n\r\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\r\nUse the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.']","['\r\nUSE_CUDNN := 1\r\nCUSTOM_CXX := g++\r\nCUDA_DIR := /usr/local/cuda\r\nCUDA_ARCH := -gencode arch=compute_20,code=sm_20 \\\r\n\t\t-gencode arch=compute_20,code=sm_21 \\\r\n\t\t-gencode arch=compute_30,code=sm_30 \\\r\n\t\t-gencode arch=compute_35,code=sm_35 \\\r\n\t\t-gencode arch=compute_50,code=sm_50 \\\r\n\t\t-gencode arch=compute_50,code=compute_50\r\nBLAS := open\r\nPYTHON_INCLUDE := /usr/include/python2.7 \\\r\n\t\t/usr/lib/python2.7/dist-packages/numpy/core/include\r\nPYTHON_LIB := /usr/lib\r\nWITH_PYTHON_LAYER := 1\r\nINCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include\r\nLIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib\r\nBUILD_DIR := build\r\nDISTRIBUTE_DIR := distribute\r\nTEST_GPUID := 0\r\nQ ?= @\r\n', ""\r\ntyphoon [166]% make all\r\nPROTOC src/caffe/proto/caffe.proto\r\nCXX .build_release/src/caffe/proto/caffe.pb.cc\r\nCXX src/caffe/blob.cpp\r\nCXX src/caffe/parallel.cpp\r\nCXX src/caffe/common.cpp\r\nCXX src/caffe/solver.cpp\r\nCXX src/caffe/layers/input_layer.cpp\r\nCXX src/caffe/layers/accuracy_layer.cpp\r\nCXX src/caffe/layers/flatten_layer.cpp\r\nCXX src/caffe/layers/dropout_layer.cpp\r\nCXX src/caffe/layers/tanh_layer.cpp\r\nCXX src/caffe/layers/recurrent_layer.cpp\r\nCXX src/caffe/layers/cudnn_pooling_layer.cpp\r\nCXX src/caffe/layers/bias_layer.cpp\r\nCXX src/caffe/layers/cudnn_lcn_layer.cpp\r\nCXX src/caffe/layers/embed_layer.cpp\r\nCXX src/caffe/layers/cudnn_lrn_layer.cpp\r\nCXX src/caffe/layers/cudnn_tanh_layer.cpp\r\nCXX src/caffe/layers/hdf5_output_layer.cpp\r\nCXX src/caffe/layers/argmax_layer.cpp\r\nCXX src/caffe/layers/reshape_layer.cpp\r\nCXX src/caffe/layers/cudnn_softmax_layer.cpp\r\nCXX src/caffe/layers/filter_layer.cpp\r\nCXX src/caffe/layers/absval_layer.cpp\r\nCXX src/caffe/layers/rnn_layer.cpp\r\nCXX src/caffe/layers/unpooling_layer.cpp\r\nCXX src/caffe/layers/batch_reindex_layer.cpp\r\nCXX src/caffe/layers/euclidean_loss_layer.cpp\r\nCXX src/caffe/layers/concat_layer.cpp\r\nCXX src/caffe/layers/infogain_loss_layer.cpp\r\nCXX src/caffe/layers/eltwise_layer.cpp\r\nCXX src/caffe/layers/deconv_layer.cpp\r\nCXX src/caffe/layers/memory_data_layer.cpp\r\nCXX src/caffe/layers/parameter_layer.cpp\r\nCXX src/caffe/layers/contrastive_loss_layer.cpp\r\nCXX src/caffe/layers/power_layer.cpp\r\nCXX src/caffe/layers/sigmoid_layer.cpp\r\nCXX src/caffe/layers/image_data_layer.cpp\r\nCXX src/caffe/layers/dummy_data_layer.cpp\r\nCXX src/caffe/layers/prelu_layer.cpp\r\nCXX src/caffe/layers/lstm_layer.cpp\r\nCXX src/caffe/layers/reduction_layer.cpp\r\nCXX src/caffe/layers/batch_norm_layer.cpp\r\nCXX src/caffe/layers/tile_layer.cpp\r\nCXX src/caffe/layers/data_layer.cpp\r\nCXX src/caffe/layers/lrn_layer.cpp\r\nCXX src/caffe/layers/slice_layer.cpp\r\nCXX src/caffe/layers/loss_layer.cpp\r\nCXX src/caffe/layers/base_data_layer.cpp\r\nCXX src/caffe/layers/bnll_layer.cpp\r\nCXX src/caffe/layers/softmax_loss_layer.cpp\r\nCXX src/caffe/layers/cudnn_sigmoid_layer.cpp\r\nCXX src/caffe/layers/window_data_layer.cpp\r\nCXX src/caffe/layers/softmax_layer.cpp\r\nCXX src/caffe/layers/elu_layer.cpp\r\nCXX src/caffe/layers/threshold_layer.cpp\r\nCXX src/caffe/layers/inner_product_layer.cpp\r\nCXX src/caffe/layers/relu_layer.cpp\r\nCXX src/caffe/layers/base_conv_layer.cpp\r\nCXX src/caffe/layers/im2col_layer.cpp\r\nCXX src/caffe/layers/hdf5_data_layer.cpp\r\nCXX src/caffe/layers/conv_layer.cpp\r\nCXX src/caffe/layers/mvn_layer.cpp\r\nCXX src/caffe/layers/lstm_unit_layer.cpp\r\nCXX src/caffe/layers/log_layer.cpp\r\nCXX src/caffe/layers/crop_layer.cpp\r\nCXX src/caffe/layers/neuron_layer.cpp\r\nCXX src/caffe/layers/cudnn_relu_layer.cpp\r\nCXX src/caffe/layers/split_layer.cpp\r\nCXX src/caffe/layers/cudnn_conv_layer.cpp\r\nCXX src/caffe/layers/exp_layer.cpp\r\nCXX src/caffe/layers/scale_layer.cpp\r\nCXX src/caffe/layers/pooling_layer.cpp\r\nCXX src/caffe/layers/spp_layer.cpp\r\nCXX src/caffe/layers/hinge_loss_layer.cpp\r\nCXX src/caffe/layers/sigmoid_cross_entropy_loss_layer.cpp\r\nCXX src/caffe/layers/silence_layer.cpp\r\nCXX src/caffe/layers/multinomial_logistic_loss_layer.cpp\r\nCXX src/caffe/net.cpp\r\nCXX src/caffe/layer_factory.cpp\r\nCXX src/caffe/layer.cpp\r\nCXX src/caffe/data_reader.cpp\r\nCXX src/caffe/internal_thread.cpp\r\nCXX src/caffe/syncedmem.cpp\r\nCXX src/caffe/solvers/sgd_solver.cpp\r\nCXX src/caffe/solvers/adagrad_solver.cpp\r\nCXX src/caffe/solvers/adam_solver.cpp\r\nCXX src/caffe/solvers/rmsprop_solver.cpp\r\nCXX src/caffe/solvers/nesterov_solver.cpp\r\nCXX src/caffe/solvers/adadelta_solver.cpp\r\nCXX src/caffe/data_transformer.cpp\r\nCXX src/caffe/util/db_lmdb.cpp\r\nCXX src/caffe/util/math_functions.cpp\r\nCXX src/caffe/util/io.cpp\r\nCXX src/caffe/util/insert_splits.cpp\r\nCXX src/caffe/util/cudnn.cpp\r\nCXX src/caffe/util/im2col.cpp\r\nCXX src/caffe/util/blocking_queue.cpp\r\nCXX src/caffe/util/hdf5.cpp\r\nCXX src/caffe/util/upgrade_proto.cpp\r\nCXX src/caffe/util/benchmark.cpp\r\nCXX src/caffe/util/signal_handler.cpp\r\nCXX src/caffe/util/db_leveldb.cpp\r\nCXX src/caffe/util/db.cpp\r\nNVCC src/caffe/layers/concat_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/cudnn_conv_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/silence_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/scale_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/cudnn_pooling_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/unpooling_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/cudnn_relu_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/cudnn_softmax_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/cudnn_tanh_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/mvn_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/eltwise_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/absval_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/sigmoid_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/cudnn_lcn_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/im2col_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/bnll_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/bias_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/dropout_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/base_data_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/lstm_unit_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/threshold_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/log_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/softmax_loss_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/cudnn_sigmoid_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/sigmoid_cross_entropy_loss_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/embed_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/filter_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/batch_reindex_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/softmax_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/reduction_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/conv_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/tanh_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/relu_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/pooling_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/tile_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/deconv_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/split_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/hdf5_output_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/contrastive_loss_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/slice_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/cudnn_lrn_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/inner_product_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/prelu_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/elu_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/euclidean_loss_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/lrn_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/batch_norm_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/recurrent_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/power_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/exp_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/hdf5_data_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/layers/crop_layer.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/solvers/adam_solver.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/solvers/sgd_solver.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/solvers/rmsprop_solver.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/solvers/adadelta_solver.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/solvers/adagrad_solver.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/solvers/nesterov_solver.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/util/math_functions.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nNVCC src/caffe/util/im2col.cu\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nnvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\nAR -o .build_release/lib/libcaffe.a\r\nLD -o .build_release/lib/libcaffe.so.1.0.0-rc3\r\n/bin/ld: cannot find -lsnappy\r\ncollect2: error: ld returned 1 exit status\r\nmake: *** [.build_release/lib/libcaffe.so.1.0.0-rc3] Error 1\r\n""]",['make all'],0,0
94,caffe,6131,open,DataParameter field 'mean_file' should be deprecated?,"### Issue summary
I wondered, what is the use of mean_file param under data_param. If it is deprecated, I didn't found any comments in the proto file indicating that. Apparently, it didn't work like its literal meaning. 

### Steps to reproduce

I was using googlenet to do classifications. I got high validation accuracy  during training. Unfortunately, I got weird low test accuracy during testing. I tried to many things like adjusting train sets, modifying learning rate, gamma and so on, I got totally different results even if the modifications were very subtle.

At last, I found that I used the 'mean_file' param under 'data_param' in data layer instead of in 'transform_param'. And it was the cause of weird output of testing. In fact, during initialization of network, it didn't load the mean_file param if it was under the data_param.

And I looked into the caffe.proto file and indeed there is a mean_file param in data_param. That's why no  error raised. But still it seems that it is of no use.

### Your system configuration
Operating system:
Compiler:
CUDA version (if applicable):
CUDNN version (if applicable):
BLAS:
Python or MATLAB version (for pycaffe and matcaffe respectively):
",documentation question,"['Interesting. Initially `mean_file` and similar parameters were fields of a `DataParameter` message and the `DataLayer` handled all preprocessing. Then (#954) the code was refactored into the `Transformer` class with its own `TransformerParameter` message that took over `mean_file` and other preprocessing fields. Later (#963) the fields were brought back for compatibility reasons, and finally (#995) the preprocessing was entirely moved to the `Transformer`. Legacy proto definitions are upgraded using the `upgrade_proto.cpp` utility which [moves](https://github.com/BVLC/caffe/blob/a19357a190664b1ea99d18e14eedc27e43ebed42/src/caffe/util/upgrade_proto.cpp#L409) any `mean_file` passed as `data_param` into the `transform_param` - but indeed it seems that `caffe.proto` is not very clear about this fact:  \r\n```\r\n  // DEPRECATED. See TransformationParameter. For data pre-processing, we can do\r\n  // simple scaling and subtracting the data mean, if provided. Note that the\r\n  // mean subtraction is always carried out before scaling.\r\n  optional float scale = 2 [default = 1];\r\n  optional string mean_file = 3;\r\n```\r\n([lines 657-661](https://github.com/BVLC/caffe/blob/7e970675c41f897a05fe1a944d754bd899fbff0e/src/caffe/proto/caffe.proto#L657-L661))\r\n\r\n@shelhamer Would it be a right thing to do to add `// DEPRECATED` comment above the `mean_file` line?']",[],[],0,0
95,caffe,6744,open,"why i can not open the fold""Windows caffe /Prebuilt binaries""?","why i can not open the fold""Windows caffe /Prebuilt binaries""?",,"['if you need a prebuilt binary feel free to grab the one i posted, windows64x py27']",[],[],0,0
96,caffe,6811,open,About flownet codes` problem,"Run-flownet. py when I run flownet's program: usage: run-flownet.py [-h] [--gpu gpu] [--verbose]
Caffemodel deployproto img0 img1 out
Run-flownet. py: error: too few arguments
An exception has occurred, use % TB to see the full traceback.

SystemExit: 2
What should I do?
Anybody know what's going on? Can some bodies help me to solve it for me",,[],[],[],0,0
97,caffe,5944,open,make: *** [runtest] Segmentation fault CentOS ,"Please have a look at this 
https://pastebin.com/vCNr36dh
make runtest fails with the following error:


Please suggest fixes.",,[],"['\r\n[----------] Global test environment tear-down\r\n[==========] 1106 tests from 150 test cases ran. (45090 ms total)\r\n[  PASSED  ] 1106 tests.\r\n*** Aborted at 1506305570 (unix time) try ""date -d @1506305570"" if you are using GNU date ***\r\nPC: @           0x5bdc08 std::vector<>::~vector()\r\n*** SIGSEGV (@0x1c) received by PID 5238 (TID 0x7f9f4836ca00) from PID 28; stack trace: ***\r\n    @     0x7f9f4039a5e0 (unknown)\r\n    @           0x5bdc08 std::vector<>::~vector()\r\n    @     0x7f9f40000dda __cxa_finalize\r\n    @     0x7f9f45adbcf3 (unknown)\r\nmake: *** [runtest] Segmentation fault\r\n']",[],0,0
98,caffe,6758,open,sudo rm -rf .nv/,"In win10 operating system , how can I solve this problem? Thank you. ",,"[""don't use `rm -rf`"", ""> don't use `rm -rf`\r\n\r\nThank you. I need a scheme to solve this problem in win10 operating system, I write the script by notepad++ in win10, so I can't use 'rm -tf' . Would you give me a concrete scheme ?"", 'you can edit `*.bat` file to batch process files.\r\n\r\nand you can use this line to get what you want:\r\n```windows\r\ndel x:\\y\\*.*\r\n# x: is your drive and y is your files\r\n```']",[],[],0,0
99,caffe,6731,open,Unknown layer type: Warping,"### Issue summary
I got the latest version caffe and set WITH_PYTHON_LAYER := 1 in makefile.config. However, I still get the following error:

------
F0325 16:49:50.756420  6840 layer_factory.hpp:81] Check failed: registry.count(type) == 1 (0 vs. 1) Unknown layer type: Warping (known types: AbsVal, Accuracy, ArgMax, BNLL, BatchNorm, BatchReindex, Bias, Clip, Concat, ContrastiveLoss, Convolution, Crop, Data, Deconvolution, Dropout, DummyData, ELU, Eltwise, Embed, EuclideanLoss, Exp, Filter, Flatten, HDF5Data, HDF5Output, HingeLoss, Im2col, ImageData, InfogainLoss, InnerProduct, Input, LRN, LSTM, LSTMUnit, Log, MVN, MemoryData, MultinomialLogisticLoss, PReLU, Parameter, Pooling, Power, Python, RNN, ReLU, Reduction, Reshape, SPP, Scale, Sigmoid, SigmoidCrossEntropyLoss, Silence, Slice, Softmax, SoftmaxWithLoss, Split, Swish, TanH, Threshold, Tile, WindowData)
*** Check failure stack trace: ***
    @     0x7fb0d2d7f5cd  google::LogMessage::Fail()
    @     0x7fb0d2d81433  google::LogMessage::SendToLog()
    @     0x7fb0d2d7f15b  google::LogMessage::Flush()
    @     0x7fb0d2d81e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fb0d33cf46c  caffe::Net<>::Init()
    @     0x7fb0d33d0b7e  caffe::Net<>::Net()
    @     0x7fb0d352f22a  caffe::Solver<>::InitTrainNet()
    @     0x7fb0d35306f5  caffe::Solver<>::Init()
    @     0x7fb0d3530a0f  caffe::Solver<>::Solver()
    @     0x7fb0d33a1b21  caffe::Creator_AdamSolver<>()
    @           0x40a778  train()
    @           0x407568  main
    @     0x7fb0d1522830  __libc_start_main
    @           0x407e39  _start
    @              (nil)  (unknown)
train_resnet_50by2_pool_tvl1.sh: line 8:  6840 Aborted                 (core dumped) $TOOLS/caffe train --solver=solver_resnet50by2_pooladam_tvl1.prototxt --gpu=0,1,2,3 --log_dir=logs/
------
Is there anything I missed? Thanks.",,"['> ### Issue summary\r\n> I got the latest version caffe and set WITH_PYTHON_LAYER := 1 in makefile.config. However, I still get the following error:\r\n> \r\n> ## F0325 16:49:50.756420 6840 layer_factory.hpp:81] Check failed: registry.count(type) == 1 (0 vs. 1) Unknown layer type: Warping (known types: AbsVal, Accuracy, ArgMax, BNLL, BatchNorm, BatchReindex, Bias, Clip, Concat, ContrastiveLoss, Convolution, Crop, Data, Deconvolution, Dropout, DummyData, ELU, Eltwise, Embed, EuclideanLoss, Exp, Filter, Flatten, HDF5Data, HDF5Output, HingeLoss, Im2col, ImageData, InfogainLoss, InnerProduct, Input, LRN, LSTM, LSTMUnit, Log, MVN, MemoryData, MultinomialLogisticLoss, PReLU, Parameter, Pooling, Power, Python, RNN, ReLU, Reduction, Reshape, SPP, Scale, Sigmoid, SigmoidCrossEntropyLoss, Silence, Slice, Softmax, SoftmaxWithLoss, Split, Swish, TanH, Threshold, Tile, WindowData)\r\n> *** Check failure stack trace: ***\r\n> @ 0x7fb0d2d7f5cd google::LogMessage::Fail()\r\n> @ 0x7fb0d2d81433 google::LogMessage::SendToLog()\r\n> @ 0x7fb0d2d7f15b google::LogMessage::Flush()\r\n> @ 0x7fb0d2d81e1e google::LogMessageFatal::~LogMessageFatal()\r\n> @ 0x7fb0d33cf46c caffe::Net<>::Init()\r\n> @ 0x7fb0d33d0b7e caffe::Net<>::Net()\r\n> @ 0x7fb0d352f22a caffe::Solver<>::InitTrainNet()\r\n> @ 0x7fb0d35306f5 caffe::Solver<>::Init()\r\n> @ 0x7fb0d3530a0f caffe::Solver<>::Solver()\r\n> @ 0x7fb0d33a1b21 caffe::Creator_AdamSolver<>()\r\n> @ 0x40a778 train()\r\n> @ 0x407568 main\r\n> @ 0x7fb0d1522830 __libc_start_main\r\n> @ 0x407e39 _start\r\n> @ (nil) (unknown)\r\n> train_resnet_50by2_pool_tvl1.sh: line 8: 6840 Aborted (core dumped) $TOOLS/caffe train --solver=solver_resnet50by2_pooladam_tvl1.prototxt --gpu=0,1,2,3 --log_dir=logs/\r\n> Is there anything I missed? Thanks.\r\n\r\ni get the same errorss,and i also change WITH_PYTHON_LAYER,but it failed ,did you solver it ?thank you so much\r\n', '@kspeng did you solve it ?can you help me answer this question?thank you  so much', '@cqray1990 Sorry, I gave it up and used other way.']",[],[],0,0
100,caffe,2495,open,Provide a summary of available backends/engines/devices,"When building applications around caffe, it's critical to know whether caffe was built with CUDA or in CPU-only mode. It's not acceptable to just try running it with the  flag and detecting whether an error was thrown or not:

> Cannot use GPU in CPU-only Caffe: check mode

Can we add a command like  or  to actually be able to check the mode, as suggested? I'd like to know about:
- CUDA
- cuDNN
- OpenCL (#2195)

---

~~Relatedly, can someone explain to me (or point me to an explanation) why you can't run caffe on the CPU if it was built with CUDA? It seems to me that I should be able to build caffe with CUDA support, and still choose later whether I want to use it or not. More generally,~~

I'd like to be able to build caffe on one machine with support for CUDA, cuDNN and OpenCL, then distribute that binary to another system that may or may not have them installed. Then there would be three states for each of the acceleration libraries:


",compatibility enhancement,"[':+1: \n', ""> Relatedly, can someone explain to me (or point me to an explanation) why you can't run caffe on the CPU if it was built with CUDA?\n\nAs @flx42 reminded me, you can set the mode in the solver. So nevermind about that.\n""]",['\n$ caffe mode\nCUDA:       Available\ncuDNN:      Not Found\nOpenCL:     Not Built\n'],"['-gpu', 'caffe buildinfo', 'caffe mode']",0,0
101,caffe,5632,open,cuda error when running caffe ,"
### Issue summary
I was trying to run a FCN for Semantic Segmentation on caffe, but then i encounter with this problem. Could anyone know how to solve it ?

F0519 13:47:44.378706 22962 math_functions.cu:79] Check failed: error == cudaSuccess (4 vs. 0)  unspecified launch failure
*** Check failure stack trace: ***
Aborted (core dumped)

I was running this with GPU TiTAN X with CUDA 8.0 on Ubuntu 16.04.
",,[],[],[],0,0
102,caffe,6535,open,PoolingParameter_RoundMode does not name a type,"## Important - read before submitting

*Please read the [guidelines for contributing](https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md) before submitting this issue!*

*Please do not post installation, build, usage, or modeling questions, or other requests for help to Issues.*
Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead.
This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.

### Issue summary


### Steps to reproduce


### Tried solutions


### System configuration

* Operating system: 
* Compiler: 
* CUDA version (if applicable): 
* CUDNN version (if applicable): 
* BLAS: 
* Python version (if using pycaffe): 
* MATLAB version (if using matcaffe): 

### Issue checklist

- [ ] read the guidelines and removed the first paragraph
- [ ] written a short summary and detailed steps to reproduce
- [ ] explained how solutions to related problems failed (tick if found none)
- [ ] filled system configuration
- [ ] attached relevant logs/config files (tick if not applicable)
",,"[""CXX src/caffe/layers/relu_layer.cpp\r\nIn file included from ./include/caffe/layers/cudnn_pooling_layer.hpp:10:0,\r\n                 from src/caffe/layers/cudnn_pooling_layer.cpp:4:\r\n./include/caffe/layers/pooling_layer.hpp:54:3: error: PoolingParameter_RoundMode does not name a type\r\n   PoolingParameter_RoundMode round_mode_;\r\n   ^\r\nMakefile:503: recipe for target '.build_release/src/caffe/layers/cudnn_pooling_layer.o' failed\r\nmake: *** [.build_release/src/caffe/layers/cudnn_pooling_layer.o] Error 1\r\nmake: *** ....\r\n"", 'The same question with you. My cudnn version is 7.1.4 for cuda 8.0. Have you solved this?', "" Try to  update the caffe/src/caffe/proto/caffe.proto in your project as the new caffe's .proto file, this maybe effective."", '']",[],[],0,0
103,caffe,3420,open,Is this a BUG in blob->offset(n) ?,"Say the input shape is 10 \* 192 \* 32 \* 32.
Then:



There isn't bottom[0]->offset(11) .

The last one in a batch is in offset(9) because we start at zero. So,  I think there shouldn't be offset(10). 
If we read bottom[0]->cpu_data()[1966080], the code will exit without any error prompt.

In the file ,  offset() is defined as:



is   better?  I'm not sure if what I've found is a problem.
",bug,"[""Yes, this is a bug and it should be `CHECK_LT(n, num())`.  However, in order to fix this, you will need to also fix a few other places that depend on the current behavior of `offset`.  While this bug has been pointed out many times, this is the reason why it's not yet fixed.  Also note that the `CHECK_GE` checks should be `CHECK_GE(c, 0)` and not `CHECK_GE(channels(), 0)`, etc.\n\nSee #792, #1681, #2835.\n"", '@seanbell This is a big project and needs programmers to well understand how layers work. I just found this bug by reading ""prelu_layer.cu"". By the way, could you tell me how you track issues and quickly know what issues are related to the current issue and should be referred? Because #792, #1681, #2835 you listed are very helpful to me. Thank you ~~\n', '@Coldmooon I just searched the project for issues, using the builtin GitHub search.  I forget what search terms I used.\n', '@seanbell Very helpful~Thanks~\n', 'There are two open PRs which aim to fix this: #2835 and #6021. There was also #792 which IMHO was better as it also checked `>=0` (currently the check is placed on the blob dimensions instead of arguments, which I think is a mistake).  \r\nBoth open PRs contain an identical patch, which does not pass the tests. Turns out that other code depends on this broken behaviour and the change is not as simple as that.']","['\nbottom[0]->offset(0)   will be 0.\nbottom[0]->offset(1)   will be 196608.\nbottom[0]->offset(2)   will be 393216.\n...\nbottom[0]->offset(9)   will be 1769472.\nbottom[0]->offset(10)  will be 1966080.\n', '\n  inline int offset(const int n, const int c = 0, const int h = 0,\n      const int w = 0) const {\n    CHECK_GE(n, 0);\n    CHECK_LE(n, num());\n    CHECK_GE(channels(), 0);\n    CHECK_LE(c, channels());\n    CHECK_GE(height(), 0);\n    CHECK_LE(h, height());\n    CHECK_GE(width(), 0);\n    CHECK_LE(w, width());\n    return ((n * channels() + c) * height() + h) * width() + w;\n  }\n']","['blob.hpp', 'CHECK_LE(n, num() - 1)']",0,0
104,caffe,6654,open,"when i order build_win.cmd in cmd, there is an error MSB6006","C:\Program Files (x86)\MSBuild\Microsoft.Cpp\v4.0\V140\Microsoft.CppCommon.targets(171,5): error MSB6006: cmd.exe 
 1 [D:\projects\caffe\build\src\caffe\caffe.vcxproj]
D:\projects\caffe\build\src\caffe\caffe.vcxproj() - 

D:\projects\caffe\build\ALL_BUILD.vcxproj() - 




D:\projects\caffe\build\ALL_BUILD.vcxproj() (1) ->
D:\projects\caffe\build\src\caffe\caffe.vcxproj() (3) ->
(CustomBuild ) ->
  C:\Program Files (x86)\MSBuild\Microsoft.Cpp\v4.0\V140\Microsoft.CppCommon.targets(171,5): error MSB6006: cmd.exe 
 1 [D:\projects\caffe\build\src\caffe\caffe.vcxproj]

    0 
    1 
",,"[""i find it's the problem of CUDA's version, first when i use CUDA10 to build, it generate the error targets(171,5): error MSB6006, and then i use CUDA8 ,it works welland this error cost my a few days, mom damn eggs\r\nCUDA10CUDA8cuDNN"", 'cuda9.28']",[],[],0,0
105,caffe,6534,open,compile caffe on centos6.5 got DSO error,"Sorry, I can't log in google, But the question has always disturb me. So I come here for help!
When I compile caffe on my centos6.5 machine, I got the following error, I don't know what's the meaning by such info, please help me, thanks!

the error info is:
CXX/LD -o .build_release/examples/siamese/convert_mnist_siamese_data.bin
/usr/local/bin/ld: .build_release/examples/mnist/convert_mnist_data.o: undefined reference to symbol 'strlen@@GLIBC_2.2.5'
/lib64/libc.so.6: error adding symbols: DSO missing from command line",,[],[],[],0,0
106,caffe,2015,open,In-place computation can break gradient computation,"For instance, MVNLayer reads data from its top blob during the backward pass, under the assumption that this data is exactly the same as the output it created.  If it's been modified by a later layer that does in-place computation, the gradient will be computed incorrectly.

In general, caffe should not rely on the user to know under what circumstances a layer can safely be done in-place.  
",bug,"['Note: you may want to coordinate with #1979 which fixes some bugs in MVNLayer.\n', 'According to @mfigurnov, cuDNN max pooling is also a layer that requires its top data during backward.\n', ""It's probably worth adding a mechanism to each layer that says whether it (a) does in-place computation and (b) can support the next layer doing in-place computation.  Then, the net could check that all of the layers are compatible upon startup.\n"", ""Further thoughts from Sean Bell in #2853:\r\n\r\n> My understanding is that right now there is no specification -- you basically need to study the layer implementation to decide whether or not you can put an in-place layer after it. Getting it wrong will lead to incorrect results, but you won't get any error or warning about it.\r\n> \r\n> A better solution would be to have each layer declare whether or not it allows for in-place computation, as well as whether the next layer can have in-place computation. Then, caffe could check these flags and raise errors as necessary. This isn't implemented, but it would be great if someone did.""]",[],[],0,0
107,caffe,1918,open,Layers with heterogeneous data types,"It currently doesn't seem to be possible to define layers with  and  of different data types. I noticed @jeffdonahue's  (#1872) which works around this by casting floating point inputs to . Specifically, I was hoping to implement a layer that encodes DNA sequence in 1-of-n encoding using  as  and  as . This doesn't seem possible with the current architecture so I'll probably have to work around it by pre-encoding all my data. However, maybe it will be possible to make the architecture flexible enough to allow this sort of thing.
",ES JD JL enhancement,[],[],"['bottom', 'top', 'EmbedLayer', 'int', 'Blob<char>', 'bottom', 'Blob<dtype>', 'top']",0,0
108,caffe,4288,open,test_benchmark.cpp failed and uses boost::this_thread::sleep which was deprecated in 1.53.0 for removal in 1.56.0,"On a current build of Caffe against Cuda 7.5 and CuDNN 4 on Visual Studio 2013, all tests pass except those for the timer class - where 4 tests of  test_benchmark.cpp fail (more details including output can be found in closed issue BenchmarkTest fails #4280). Inspection shows that the tests use  
which has been deprecated since 1.53 and withdrawn after 1.56. 
a suitable replacement could be:


However making such a replacement does not in itself fix the errors completely. Is the underlying timer used in the timer class updated when the thread is asleep? The timer reporting the times of the tests seems accurate!
",windows,"['On further investigation there is a subtle timing bug in benchmark.cpp. With the following change all GPU based timer tests pass on my setup. The stop code synchronizes stop_gpu_ **but the start code does not**. This has been noted as causing trouble in other contexts(http://stackoverflow.com/questions/31046158/cudaeventrecord-does-not-time-correctly-on-visual-studio-cpu-code). I guess the issue shows itself in the test_benchmark because the CPU might sleep before the start_gpu is set? Why it seems reproducible on windows and not on unix I have no idea.\n\nFrom benchmark.cpp:\n\n```\nvoid Timer::Start() {\n  if (!running()) {\n    if (Caffe::mode() == Caffe::GPU) {\n#ifndef CPU_ONLY\n      CUDA_CHECK(cudaEventRecord(start_gpu_, 0));\n      // [TJL]\n      // Next line required but missing\n      CUDA_CHECK(cudaEventSynchronize(start_gpu_));\n      // [TJL]\n#else\n      NO_GPU;\n#endif\n    } else {\n      start_cpu_ = boost::posix_time::microsec_clock::local_time();\n    }\n    running_ = true;\n    has_run_at_least_once_ = true;\n  }\n}\n\nvoid Timer::Stop() {\n  if (running()) {\n    if (Caffe::mode() == Caffe::GPU) {\n#ifndef CPU_ONLY\n      CUDA_CHECK(cudaEventRecord(stop_gpu_, 0));\n      CUDA_CHECK(cudaEventSynchronize(stop_gpu_));\n#else\n      NO_GPU;\n#endif\n    } else {\n      stop_cpu_ = boost::posix_time::microsec_clock::local_time();\n    }\n    running_ = false;\n  }\n}\n```\n', 'I am seeing the same problem in the latest revision of the Windows branch. This is on Windows 10 with VS2015.\n', 'I realize it works in Linux without synchronizing start_gpu_, but if Linux still works with the cudaEventSynchronize(start_gpu_) call then I think a pull request should be done for this. Terrylyons, if you do a PR on the main branch, it will not be approved if this is known to fail in Linux, but in the event that it is approved, I think it is very useful for us Windows users.\n']",[],"['boost::this_thread::sleep', 'boost::this_thread::sleep_for(boost::chrono::milliseconds(300));']",0,0
109,caffe,6686,open,Make runtest fails ubuntu 18.04 cuda 9.1 ,"### Issue summary
I passed make -j8 all and make -j8 test but make -j8 runtest gives me the following error : 

### Tested solutions 

Tried adding -G to NVCC in Debugging section of  Makefile then Make clean Make -j8 all make -j8 test make -j8 runtest. Get the same error.

### System configuration
Python 3.6
* Operating system: Ubuntu 18.04
* Compiler: gcc 7.3
* CUDA version (if applicable): 9.1
* CUDNN version (if applicable): 7.1
* BLAS: atlas
* Python version (if using pycaffe): 3.6
* MATLAB version (if using matcaffe): 

",,"['Have you solved it ? I have the same error', 'sudo make runtestusr/lib/x86-64gxlnlibcaffe.so.1.0.0', '> sudo make runtestusr/lib/x86-64gxlnlibcaffe.so.1.0.0\r\n\r\n~']","[""\r\n.build_release/tools/caffe: symbol lookup error: .build_release/tools/caffe: undefined symbol: _ZN5caffe3NetIfE21CopyTrainedLayersFromERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\r\nMakefile:543: recipe for target 'runtest' failed\r\nmake: *** [runtest] Error 127\r\n""]",[],0,0
110,caffe,6175,open,Some installation instructions for msys2,"Hi,

Few days ago I found myself on a quest to get a working minimal caffe build on windows/msys2. I thought it was going to be easy (haha). It ended up a lot more hellish than I thought. Long story short, there are some broken packages out there and a few hard-to-dig answers on stackoverflow, and it can take a really long time for a newcomer to put it all together, especially when you don't know much about msys.

Somehow managed to work through the issues as far as my requirements are concerned and came up with this build: [mingw-caffe](https://github.com/lemonsqueeze/mingw-caffe).

I don't want to go through this again, and really don't wish it to anyone else either.
I understand msys is not in the officially supported platforms and that's perfectly fine, but a version of me from the past and i'm sure many others in a similar situation would appreciate a pointer in the [installation](http://caffe.berkeleyvision.org/installation.html) section (also right now there's only one entry for Windows and it points to the windows branch, which is deliciously confusing).

I'm sure this can be improved, but it's much better than nothing.
If someone tells me this has already been done i kill him.",,[],[],[],0,0
111,caffe,6745,open,Source file directory not found--,"I used the command ""sudo apt install caffe-cuda"" to complete the installation of Caffe on Ubuntu 18.04, which can be used directly. Now I need to modify the source code or add a layer. But I can only find the usr/bin/caffe shared library through ""which caffe, where is caffe"", and I can't find the source code. I can't thank you enough for your advice.ubuntu18.04sudo apt install caffe-cudacaffewhich caffewhereis caffeusr/bin/caffe",,[],[],[],0,0
112,caffe,6724,open,_No module named _caffe.so,"I make caffe with cmake. However I can't find _caffe.so  in my python directory.So when I import caffe, I get the error:_No module named _caffe.so. How can I fix it?",,"['Hello,\r\n\r\nI found that I needed to run `cmake` with `-DBUILD_python=ON` to generate this .so\r\n\r\nI also had to do `make pycaffe python` to get the module built.']",[],[],0,0
113,caffe,6881,open,A bug in pooling_layer.cpp?,"@csukuangfj  @Noiredd
### Issue summary
A bug in pooling_layer.cpp?
### **original code:**
  if (pad_h_ || pad_w_) {
    // If we have padding, ensure that the last pooling starts strictly
    // inside the image (instead of at the padding); otherwise clip the last.`
    if ((pooled_height_ - 1) * stride_h_ >= height_ + pad_h_) {
      --pooled_height_;
    }
    if ((pooled_width_ - 1) * stride_w_ >= width_ + pad_w_) {
      --pooled_width_;
    }
    CHECK_LT((pooled_height_ - 1) * stride_h_, height_ + pad_h_);
    CHECK_LT((pooled_width_ - 1) * stride_w_, width_ + pad_w_);
  }
    **I think that if (pad_h_ || pad_w_)  should be removed**

   For example
       Input feature map = hi*wi= 6*6kernel=1stride=2pad=0round_mode=CEIL;
       ho=ceil_div((6+2*0-1) ,2)+1=4
       (ho-1)*stride=(4-1)*2=6=hi+pad=6+0
   In this case, the 4th output point is out side of the input map, ho/wo must be decreased by 1!

   So, if (pad_h_ || pad_w_)  should be removed

",,"[""https://github.com/BVLC/caffe/blob/04ab089db018a292ae48d51732dd6c66766b36b6/src/caffe/layers/pooling_layer.cpp#L107-L118\r\n\r\n> I think that if (pad_h_ || pad_w_)  should be removed\r\n\r\nYou'll fail at line 116\r\nhttps://github.com/BVLC/caffe/blob/04ab089db018a292ae48d51732dd6c66766b36b6/src/caffe/layers/pooling_layer.cpp#L116\r\n\r\n> In this case, the 4th output point is out side of the input map, ho/wo must be decreased by 1!\r\n\r\nPleas read the code further:\r\nhttps://github.com/BVLC/caffe/blob/04ab089db018a292ae48d51732dd6c66766b36b6/src/caffe/layers/pooling_layer.cpp#L168-L175\r\n\r\nAt line 175, `h < hend` will be false and the for loop is not executed."", ""> https://github.com/BVLC/caffe/blob/04ab089db018a292ae48d51732dd6c66766b36b6/src/caffe/layers/pooling_layer.cpp#L107-L118\r\n> \r\n> > I think that if (pad_h_ || pad_w_)  should be removed\r\n> \r\n> You'll fail at line 116\r\n> https://github.com/BVLC/caffe/blob/04ab089db018a292ae48d51732dd6c66766b36b6/src/caffe/layers/pooling_layer.cpp#L116\r\n> \r\n> > In this case, the 4th output point is out side of the input map, ho/wo must be decreased by 1!\r\n> \r\n> Pleas read the code further:\r\n> https://github.com/BVLC/caffe/blob/04ab089db018a292ae48d51732dd6c66766b36b6/src/caffe/layers/pooling_layer.cpp#L168-L175\r\n> \r\n> At line 175, `h < hend` will be false and the for loop is not executed.\r\n----------------------------------------------------------------------------------------------------------------\r\n----------------------------------------------------------------------------------------------------------------\r\n**if (pad_h_ || pad_w_)  should be removedYou'll fail at line 116**\r\n-----I think that line 116 will not fail, because pooled_height_/pooled_height_ is already decreased by 1, so, (pooled_height_ - 1) * stride_h_ must be less than height_ + pad_h_  at line 116;\r\n\r\n**At line 175, `h < hend` will be false and the for loop is not executed.**\r\n----- Yes, this loop will not be executed, but the number of output has been identified in the following below:https://github.com/BVLC/caffe/blob/04ab089db018a292ae48d51732dd6c66766b36b6/src/caffe/layers/pooling_layer.cpp#L107-L118\r\n\r\nIn this case, you will find that the data at the boundary(the most right/bottom) are invalid(AVE:0.0; MAX:-FLT_MAX).\r\nIn order to drop the invalid data, a slice layer must be added behind the pool layer, but if if (pad_h_ || pad_w_)  is removed, the output of pool layer can be used by next layer without inserting slice layer!\r\n\r\n\r\n\r\n""]",[],[],0,0
114,caffe,6691,open,there is no caffe.bin,"hello
I've installed caffe on windows 
I followed up instructions in [README.md](https://github.com/BVLC/caffe/tree/windows) and there was no error in running build-win.cmd

in demo.py  in [here](https://github.com/suyogduttjain/pixelobjectness) I have to mention the path of caffe.bin in caffe_binary = './deeplab-public/distribute/bin/caffe.bin'  but I don't have such file neither in that path nor any other paths where caffe is installed.

I appreciate any help.",,"['Hi,\r\nHave you found any solution to the problem? I am facing a similar issue and unable to find anything about it over the internet. Please let me know if anything worked for you at the earliest. Thank you. ']",[],[],0,0
115,caffe,4607,open,"loading any network results in Jupyter kernel crash because of lack of CUDA device, set_mode_cpu fails as well.","I get thrown out of Jupyter after importing any model, even after calling set_mode_cpu(), because caffe fails to find any CUDA device (which is shouldn't).

here's my input:



This results in the following error message:



The kernel is not dead yet, now I try this:



This is the response I get:



followed by the text in 
followed by:



I'm running on a laptop with no GPU, so it makes sense it doesn't find any CUDA-capable device, but why is it ignoring my request to use the CPU?

My docker has CUDA drivers installed on it (for when I do want to run in GPU mode) - is that a problem?
Here's my Dockerfile:

[Dockerfile.txt](https://github.com/BVLC/caffe/files/426713/Dockerfile.txt)
",,"['@Motherboard \nI have two suggestions for you:\n- Compile Caffe as CPU_ONLY for your laptop\n- Use OpenCL Caffe to get acceleration on your onboard GPU or CPU, if you want: https://github.com/BVLC/caffe/tree/opencl and compile this without CUDA support, but with OpenCL/GreenTea support enabled.\n\nI think the code isolation has an issue when using set_mode_cpu() while it is compiled with CUDA enabled, and no GPU present.\n', ""Indeed, if you compiled with GPU support, caffe will try to create cublas/curand handles even if you use CPU mode afterwards.\n\nPlease don't install the NVIDIA drivers inside the container, look at what we do in [nvidia-docker](https://github.com/nvidia/nvidia-docker) instead.\n"", 'Hii I have gpu in my lap-top, still my kernal is shutting down when I load a model. I am new to caffe. Please let me know how to proceed. Thanks in advance!!']","['\nimport caffe        \ncaffe.set_mode_cpu()\n\n', ""\nmodprobe: ERROR: ../libkmod/libkmod.c:556 kmod_search_moddep() could not open moddep file '/lib/modules/4.4.0-34-generic/modules.dep.bin'\nWARNING: Logging before InitGoogleLogging() is written to STDERR\nE0819 09:26:41.096457   117 common.cpp:113] Cannot create Cublas handle. Cublas won't be available.\nmodprobe: ERROR: ../libkmod/libkmod.c:556 kmod_search_moddep() could not open moddep file '/lib/modules/4.4.0-34-generic/modules.dep.bin'\nE0819 09:26:41.107548   117 common.cpp:120] Cannot create Curand generator. Curand won't be available.\n\n"", ""\nnet = caffe.Net('test.prototxt',0,weights = 'VGG_FACE.caffemodel')     \n"", ""\nmodprobe: ERROR: ../libkmod/libkmod.c:556 kmod_search_moddep() could not open moddep file '/lib/modules/4.4.0-34-generic/modules.dep.bin'\nWARNING: Logging before InitGoogleLogging() is written to STDERR\nE0818 22:53:36.252074   107 common.cpp:113] Cannot create Cublas handle. Cublas won't be available.\nmodprobe: ERROR: ../libkmod/libkmod.c:556 kmod_search_moddep() could not open moddep file '/lib/modules/4.4.0-34-generic/modules.dep.bin'\nE0818 22:53:36.266199   107 common.cpp:120] Cannot create Curand generator. Curand won't be available.\nI0818 22:53:36.267086   107 net.cpp:58] Initializing net from parameters: \nstate {\n  phase: TRAIN\n  level: 0\n}\n\n"", '\nI0818 22:53:36.269408   107 layer_factory.hpp:77] Creating layer data\nI0818 22:53:36.269502   107 net.cpp:100] Creating Layer data\nI0818 22:53:36.269577   107 net.cpp:408] data -> data\nI0818 22:53:36.269659   107 net.cpp:408] data -> label\nI0818 22:53:36.269723   107 image_data_layer.cpp:38] Opening file transformed_train.txt\nI0818 22:53:36.269836   107 image_data_layer.cpp:58] A total of 1000 images.\nI0818 22:53:36.433357   107 image_data_layer.cpp:85] output data size: 50,3,227,227\nF0818 22:54:04.128543   107 internal_thread.cpp:26] Check failed: error == cudaSuccess (38 vs. 0)  no CUDA-capable device is detected\n\n']",['test.prototxt'],0,0
116,caffe,5695,open,could caffe add ROI settings for convolution?,"sometimes, we only need to detect objects inside 1-2 ROIs in the whole image, but we have to do the conv/pool etc on the whole image, for example, if we use vgg on a HD image, the performance is really bad. my question is, do you have plan to add ROI settings for Conv settings(list of rectangles)?",,"['You might be interested in something like [Faster-RCNN](https://github.com/rbgirshick/py-faster-rcnn). We have a PR pending review with some features that would allow something this: #4163.\r\n\r\nHowever, if all that you want to do is to cut a RoI at a specific location in your image, you can do it already using the [Crop](http://caffe.help/manual/layers/crop.html) layer. See [this SO answer](https://stackoverflow.com/a/38591769/6919631) for more information. The drawback is that you specify the crop offset once, but this is done statically and you cannot change it later when your network runs.']",[],[],0,0
117,caffe,4706,open,Facing issue with bringing up the flash server (web demo),"Sry if this is something I missed to read in the documentation but I'm facing this issue. Any help is really appreciated. Thanks in advance.

I followed the installation and complication steps. 

ran make test with following pass results: 



Verified all followed exist as mentioned in the web demo setup steps but start web app failed with import caffe error:


",,"['Ok. Good News. I resolved all the environment/setup issues. Now just left on the final issue. And I guess its something related to something specific to code:\n\n```\nFile ""examples/web_demo/app.py"", line 99, in <module>\n    class ImagenetClassifier(object):\n  File ""examples/web_demo/app.py"", line 115, in ImagenetClassifier\n    ""File for {} is missing. Should be at: {}"".format(key, val))\nException: File for class_labels_file is missing. Should be at: /Users/joswal/gitRepo/imageClassification/blvc/caffe/data/ilsvrc12/synset_words.txt\n```\n', 'Not sure if I was suppose to copy over the txt file but I did that. And now the error is following:\n\n```\njos:caffe$ python examples/web_demo/app.py\nTraceback (most recent call last):\n  File ""examples/web_demo/app.py"", line 99, in <module>\n    class ImagenetClassifier(object):\n  File ""examples/web_demo/app.py"", line 115, in ImagenetClassifier\n    ""File for {} is missing. Should be at: {}"".format(key, val))\nException: File for pretrained_model_file is missing. Should be at: /Users/joswal/gitRepo/imageClassification/blvc/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel\n```\n']","['\n[----------] Global test environment tear-down\n[==========] 1096 tests from 150 test cases ran. (42825 ms total)\n[  PASSED  ] 1096 tests.\n', '\njos:caffe joswal$ ./scripts/\nbuild_docs.sh                deploy_docs.sh               gather_examples.sh\ncopy_notebook.py             download_model_binary.py     travis/\ncpp_lint.py                  download_model_from_gist.sh  upload_model_to_gist.sh\n\njos:caffe joswal$ ./scripts/download_model_binary.py models/\nbvlc_alexnet/                 bvlc_reference_caffenet/      finetune_flickr_style/\nbvlc_googlenet/               bvlc_reference_rcnn_ilsvrc13/\n\njos:caffe joswal$ python examples/web_demo/app.py\n\nTraceback (most recent call last):\n  File ""examples/web_demo/app.py"", line 18, in <module>\n    import caffe\nImportError: No module named caffe\n']",[],0,0
118,caffe,6816,open,Recognition on Image itself,"## Important - read before submitting

*Please read the [guidelines for contributing](https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md) before submitting this issue!*

*Please do not post installation, build, usage, or modeling questions, or other requests for help to Issues.*
Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead.
This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.

### Issue summary



### Steps to reproduce


### Tried solutions


### System configuration

* Operating system: 
* Compiler: 
* CUDA version (if applicable): 
* CUDNN version (if applicable): 
* BLAS: 
* Python version (if using pycaffe): 
* MATLAB version (if using matcaffe): 

### Issue checklist

- [ ] read the guidelines and removed the first paragraph
- [ ] written a short summary and detailed steps to reproduce
- [ ] explained how solutions to related problems failed (tick if found none)
- [ ] filled system configuration
- [ ] attached relevant logs/config files (tick if not applicable)

Hi 

Is this repo giving face recognition on images or terminal. Like in Davidberg Repo, Face recognition is done on terminal rather than on images. I want on images. will it do? If yes, I will pursue.

Thanks
",,[],[],[],0,0
119,caffe,6375,open,problem encountered when train with multiple GPUs in caffe,"### Issue summary
I installed caffe on ubuntu16.04 with cuda8.0 and cudnn5.0. Installation is very normal, and when using  single GPU caffe can run very smoothly, but when i use the command -gpu all to use multiple GPU, the terminal just keep unchanged as you can seehowever it doesn't report a mistake. I have to use 'sudo kill -9 PID' to stop the process. what's the problem? anyone can help me?

### Steps to reproduce
![image](https://user-images.githubusercontent.com/35474700/39393837-9b94f9ea-4afc-11e8-99ef-cbfe08844fe8.png)
![image](https://user-images.githubusercontent.com/35474700/39393848-bcf8a26c-4afc-11e8-93d8-773671ebb935.png)


### Tried solutions
reinstall NCCL and recompile caffe but it doesn't help 

### System configuration

* Operating system: ubuntu
* Compiler: gcc 5.4.0
* CUDA version (if applicable): cuda_8.0.44_linux
* CUDNN version (if applicable): cudnn-8.0-linux-x64-v5.1
* BLAS: OpenBLAS-0.2.20
* Python version (if using pycaffe): python2.7
* MATLAB version (if using matcaffe): 

### Issue checklist
",multi-GPU,[],[],[],0,0
120,caffe,6377,open,Caffe+NCCL : Check failed: result == ncclSuccess (13 vs. 0) invalid data type,"I try to train a ResNet to do image classification on multiple GPU card. But I encountered error at the training/test beginning:

My environment is Tesla M40 x 4, Ubuntu 16.04, CUDA 9.1, CUDNN v7.1, NCCL 2.1.15.
And I test many times this network can be successfully trained on one GPU card.",multi-GPU,"['@zhonhel \r\n\r\nCan you show a minimal example to reproduce this issue?', ""@twmht \r\n\r\nI used this repo's resnet-18 train prototxt.\r\nhttps://github.com/antingshen/resnet-protofiles\r\n\r\nThen I encountered this problem.\r\n\r\nAnd I can successfully trained on one M40 GPU, but when I wanted to train it on multiple GPUs, it appeared this error at the training beginning."", '@zhonhel \r\n\r\nHow do you train this model?\r\n\r\nFor example,\r\n\r\n```\r\n./build/tools/caffe --train ...\r\n```', '@twmht \r\n\r\nYes, just simply\r\n\r\n `{xxx}/caffe train --solver=""solver.prototxt"" --gpu=0,1`\r\n', 'Hi, @zhonhel. Have you solved this issue?', ""  @Huddolly \r\nNo, I don't solve it after that time."", 'nccl need to be included and linked when compiling caffe.', '@Tonyfy  @zhonhel  @Huddolly  Have you solved the problem? I meet it again.', 'I back the version of nccl to 1.2.3.1 and with cuda8, then this error disappeared.']",['\r\nI0501 03:45:00.237848 55609 net.cpp:255] Network initialization done.\r\nI0501 03:45:00.238184 55609 solver.cpp:57] Solver scaffolding done.\r\nI0501 03:45:00.244508 55609 caffe.cpp:239] Starting Optimization\r\nI0501 03:45:01.672870 55669 solver.cpp:190] Creating test net (#0) specified by net file: ./ResNet_18_train_val.prototxt\r\nF0501 03:45:02.284466 55609 parallel.cpp:195] Check failed: result == ncclSuccess (13 vs. 0) invalid data type\r\n*** Check failure stack trace: ***\r\nF0501 03:45:02.284466 55669 parallel.cpp:195] Check failed: result == ncclSuccess (13 vs. 0) invalid data type\r\n*** Check failure stack trace: ***\r\n@ 0x7f38606845cd google::LogMessage::Fail()\r\n@ 0x7f38606845cd google::LogMessage::Fail()\r\n@ 0x7f3860686433 google::LogMessage::SendToLog()\r\n@ 0x7f386068415b google::LogMessage::Flush()\r\n@ 0x7f3860686433 google::LogMessage::SendToLog()\r\n@ 0x7f3860686e1e google::LogMessageFatal::~LogMessageFatal()\r\n@ 0x7f386068415b google::LogMessage::Flush()\r\n@ 0x7f3860e73eca caffe::NCCL<>::Broadcast()\r\n@ 0x7f3860686e1e google::LogMessageFatal::~LogMessageFatal()\r\n@ 0x7f3860e771bf caffe::NCCL<>::Run()\r\n@ 0x40d84f train()\r\n@ 0x40a497 main\r\n@ 0x7f3860e73eca caffe::NCCL<>::Broadcast()\r\n@ 0x7f385f5f4830 __libc_start_main\r\n@ 0x40ae39 _start\r\n@ (nil) (unknown)\r\nAborted (core dumped)\r\n'],[],0,0
121,caffe,6687,open,There is a problem about convergence of the networks,"When i train my image use this Code,there is a problem about convergence: Training results shows that the 'total loss' is fluctuate around 2 ,and did not decrease anymore; Second, the 'loss_box' always decay to zero and it will rise a little only; Third, the training is always cut off, no reason; Fourth, the candidate boxes are generally small than the fact; Fifth, when i run the demo there are no object has been detected. So, what happen to my project, please reply to me as soon as possible,thank U!",,[],[],[],0,0
122,caffe,4772,open,make runtest segfaulting,"I'm not sure what might be causing this, but here's what I'm seeing when I run  on a checkout of master. I'm running on Debian Jessie, with GCC 4.9 and CUDA 8 RC. The only interesting thing about this machine is that it has 4x GTX 1080.



EDIT: I'm compiling with CuDNN enabled, but turning it off doesn't seem to make a difference.
",multi-GPU testing,"['ran into exactly the same problem today with Ubuntu 16.04, 4 X K80, CUDA 8 RC, and GCC-5.3. \nAdvice highly appreciated!\n', 'This may be unrelated, but as an extra datapoint, I also get a segfault if\nI import pycaffe and theano in the same file and the try to do anything\nwith caffe. Let me know if I can provide any extra info!\n\nOn Tue, 27 Sep 2016, 22:47 ruonanl, notifications@github.com wrote:\n\n> ran into exactly the same problem today with Ubuntu 16.04, 4 X K80, CUDA 8\n> RC, and GCC-5.3.\n> Advice highly appreciated!\n> \n> \n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/BVLC/caffe/issues/4772#issuecomment-250008887, or mute\n> the thread\n> https://github.com/notifications/unsubscribe-auth/ACYqiCs5Z-Kv08RXj7FJyxBSQaG5R-Reks5quY8HgaJpZM4KF9-e\n> .\n', 'An extra bit of observation: segfaults appear in several ""SolverTest"", but all share the same stack trace:\nstd::vector<>::_M_erase()\ncaffe::DevicePair::compute()\ncaffe::P2PSync<>::Prepare()\ncaffe::P2PSync<>::Run()\ncaffe::GradientBasedSolverTest<>::TestLeastSquaresUpdate()\n', 'Same here.\nTitan X (Pascal)_6+K80_2+GTX1080*1 + Ubuntu 16.04 + cudnn v5.1 + cuda 8 + GCC-5.4.\n\n[----------] 12 tests from SGDSolverTest/2, where TypeParam = caffe::GPUDevice<float>\n[ RUN      ] SGDSolverTest/2.TestLeastSquaresUpdateWithWeightDecay\n**\\* Aborted at 1475986823 (unix time) try ""date -d @1475986823"" if you are using GNU date ***\nPC: @     0x7f13e92fd512 (unknown)\n**\\* SIGSEGV (@0x19ae2000) received by PID 14082 (TID 0x7f13f0ac7ac0) from PID 430841856; stack trace: ***\n    @     0x7f13e958a3d0 (unknown)\n    @     0x7f13e92fd512 (unknown)\n    @     0x7f13e9eae280 std::vector<>::_M_erase()\n    @     0x7f13e9eac494 caffe::DevicePair::compute()\n    @     0x7f13e9eb1d50 caffe::P2PSync<>::Prepare()\n    @     0x7f13e9eb285e caffe::P2PSync<>::Run()\n    @           0x5b409e caffe::GradientBasedSolverTest<>::TestLeastSquaresUpdate()\n    @           0x5b49ff caffe::SGDSolverTest_TestLeastSquaresUpdateWithWeightDecay_Test<>::TestBody()\n    @           0x91ad53 testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @           0x91436a testing::Test::Run()\n    @           0x9144b8 testing::TestInfo::Run()\n    @           0x914595 testing::TestCase::Run()\n    @           0x91586f testing::internal::UnitTestImpl::RunAllTests()\n    @           0x915b93 testing::UnitTest::Run()\n    @           0x46d9ed main\n    @     0x7f13e91d0830 __libc_start_main\n    @           0x475459 _start\n    @                0x0 (unknown)\nMakefile:526: recipe for target \'runtest\' failed\nmake: **\\* [runtest] Segmentation fault (core dumped)\n', 'I suspect it is a bug of multi-GPU support.\nI tried to use ""export CUDA_VISIBLE_DEVICES=0"" to make only 1 GPU visible to Caffe, and then I can successfully pass all the tests.\n\n[==========] 2081 tests from 277 test cases ran. (353009 ms total)\n[  PASSED  ] 2081 tests.\n', '@nitbix \r\n\r\n> This may be unrelated, but as an extra datapoint, I also get a segfault if\r\nI import pycaffe and theano in the same file and the try to do anything\r\nwith caffe. Let me know if I can provide any extra info!\r\n\r\nThis was fixed in theano in commit bb170f4fb201109f88b95da282ed3a21b5021c13 (23 Sep 2016). It was calling cudaThreadExit on shutdown which then caused a segfault when Caffe subsequently called cublasDestroy on cleanup', 'Dear All, \r\n\r\nPlease advice how you solve this issue as I have the same problem. Any answer is highly appreciated. \r\n![problem 1](https://cloud.githubusercontent.com/assets/25819990/23685259/05e35f44-039b-11e7-8acb-c0c3e0a04239.png)\r\n', 'Hi all\r\nI have the same problem in ubuntu 16.4\r\n![screenshot from 2017-03-23 14-06-46](https://cloud.githubusercontent.com/assets/6255436/24241302/fce29d7c-0fd1-11e7-9545-56bf708848e8.png)\r\nAny answer is highly appreciated. Thank you \r\n\r\n @RuaYahya Did you solve issue? ', 'Hi ,\r\nThe proplem in my case is that my labtop does not have a Nvidia card . Check whether your graphical processing unit is nvidia or not.  It works fine when I try another laptop. \r\nThanks', ""@RuaYahya \r\n*** SIGABRT (@0x113c) received by PID 4412 (TID 0x7f64016a5b00) from PID 4412; stack trace: ***\r\n    @     0x7f63ffd094b0 (unknown)\r\n    @     0x7f63ffd09428 gsignal\r\n    @     0x7f63ffd0b02a abort\r\n    @     0x7f63ffd4b7ea (unknown)\r\n    @     0x7f63ffd53e0a (unknown)\r\n    @     0x7f63ffd5798c cfree\r\n    @     0x7f64008878af google::protobuf::internal::DestroyDefaultRepeatedFields()\r\n    @     0x7f6400886b3b google::protobuf::ShutdownProtobufLibrary()\r\n    @     0x7f63e98c6329 (unknown)\r\n    @     0x7f64015a2c17 (unknown)\r\n    @     0x7f63ffd0dff8 (unknown)\r\n    @     0x7f63ffd0e045 exit\r\n    @     0x7f63ffcf4837 __libc_start_main\r\n    @           0x4077c9 _start\r\n    @                0x0 (unknown)\r\nMakefile:532: recipe for target 'runtest' failed\r\n\r\nI have the same problem in ubuntu 16.4.Did you solve issue?"", ""@Mehuli-Ruh11 \r\nI believe he would simply include it  before the command, like this `export CUDA_VISIBLE_DEVICES=0 make runtest`. This fixed the error for me, it's related to this line in _Makefile.config_\r\n`# The ID of the GPU that 'make runtest' will use to run unit tests.`\r\n`TEST_GPUID := 0`"", '@denru01 \r\nI had a similar problem with you.\r\nI had a boost python package installed through conda, it has a different version with the one in my system. If you are using Anaconda, just uninstall the boost python package(conda uninstall boost)\r\nThat might fix the problem.', ""did someone find a solution ? I have the same problem and I'm running on ubuntu16.04 with only one gpu (gtx1080) and cuda8.  "", '@FangbRen \r\ncaffe\r\n\r\n\r\n', 'i solved this issue   by the command : make runtest -j export CUDA_VISIBLE_DEVICES=0 ', 'I have the same problem, but it only like this. I use  Ubuntu 16.04, CUDA=9.0 and cudnn=7.0 with 2080Ti.\r\nAny answer is highly appreciated.\r\n\r\n![image](https://user-images.githubusercontent.com/65346642/124062092-b861cf00-da62-11eb-8e3a-b45e9d55288a.png)\r\n']","['\n[----------] 2 tests from HingeLossLayerTest/2, where TypeParam = caffe::GPUDevice<float>\n[ RUN      ] HingeLossLayerTest/2.TestGradientL2\n[       OK ] HingeLossLayerTest/2.TestGradientL2 (6 ms)\n[ RUN      ] HingeLossLayerTest/2.TestGradientL1\n[       OK ] HingeLossLayerTest/2.TestGradientL1 (6 ms)\n[----------] 2 tests from HingeLossLayerTest/2 (12 ms total)\n\n[----------] 9 tests from AdaGradSolverTest/2, where TypeParam = caffe::GPUDevice<float>\n[ RUN      ] AdaGradSolverTest/2.TestLeastSquaresUpdateWithEverythingAccumShare\n[       OK ] AdaGradSolverTest/2.TestLeastSquaresUpdateWithEverythingAccumShare (12 ms)\n[ RUN      ] AdaGradSolverTest/2.TestAdaGradLeastSquaresUpdateWithEverythingShare\n*** Aborted at 1474827886 (unix time) try ""date -d @1474827886"" if you are using GNU date ***\nPC: @     0x7fbbf4951e2d (unknown)\n*** SIGSEGV (@0x1451f000) received by PID 23925 (TID 0x7fbc03491a00) from PID 340914176; stack trace: ***\n    @     0x7fbbf4bd38d0 (unknown)\n    @     0x7fbbf4951e2d (unknown)\n    @     0x7fbbf5496350 std::vector<>::_M_erase()\n    @     0x7fbbf549427d caffe::DevicePair::compute()\n    @     0x7fbbf5499123 caffe::P2PSync<>::Prepare()\n    @     0x7fbbf54997a0 caffe::P2PSync<>::Run()\n    @           0x6af00e caffe::GradientBasedSolverTest<>::RunLeastSquaresSolver()\n    @           0x6c2d2f caffe::GradientBasedSolverTest<>::TestLeastSquaresUpdate()\n    @           0x6c31b0 caffe::AdaGradSolverTest_TestAdaGradLeastSquaresUpdateWithEverythingShare_Test<>::TestBody()\n    @           0x8ff553 testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @           0x8f7eca testing::Test::Run()\n    @           0x8f8018 testing::TestInfo::Run()\n    @           0x8f80f5 testing::TestCase::Run()\n    @           0x8f8a28 testing::internal::UnitTestImpl::RunAllTests()\n    @           0x8f8d03 testing::UnitTest::Run()\n    @           0x46e9df main\n    @     0x7fbbf483ab45 (unknown)\n    @           0x4764e9 (unknown)\n    @                0x0 (unknown)\nMakefile:526: recipe for target \'runtest\' failed\nmake: *** [runtest] Segmentation fault\n']",['make runtest'],0,0
123,caffe,6822,open,How is caffe resizing my images for training in transform_param,"So, I want to understand is caffe losing the detail of my high-resolution image while resizing to 300x300?

There could be two cases while resizing the image to 300x300 my 1200x990 image:
1) Cropping
2) Squishing 

In the first case i.e. cropping it's loosing details of my actual labelled image

In the second case i.e. Squishing my original high-resolution image is squished to a small size which also means it's a waste to pass high-resolution image

Now, I saw the source and ***train.prototxt***

    transform_param {
        resize_param {
              resize_mode: WARP
              height: 300
              width: 300
        }
    }

then I saw CPP code for wrap & found

Link to cpp code [here][1]



and the actual logic



now I understand Cplusplus but what I don't understand is what is bbox? and what's the logic for WRAP mode?

Can someone please explain to me what's happening with my 1200x900 image. Thanks




  [1]: https://github.com/intel/caffe/blob/master/src/caffe/util/im_transforms.cpp",,[],"['\r\nvoid UpdateBBoxByResizePolicy(const ResizeParameter& param,\r\n                              const int old_width, const int old_height,\r\n                              NormalizedBBox* bbox) {\r\n  float new_height = param.height();\r\n  float new_width = param.width();\r\n  float orig_aspect = static_cast<float>(old_width) / old_height;\r\n  float new_aspect = new_width / new_height;\r\n\r\n  float x_min = bbox->xmin() * old_width;\r\n  float y_min = bbox->ymin() * old_height;\r\n  float x_max = bbox->xmax() * old_width;\r\n  float y_max = bbox->ymax() * old_height;\r\n.....\r\n.....\r\n', '\r\n  switch (param.resize_mode()) {\r\n    case ResizeParameter_Resize_mode_WARP:\r\n      x_min = std::max(0.f, x_min * new_width / old_width);\r\n      x_max = std::min(new_width, x_max * new_width / old_width);\r\n      y_min = std::max(0.f, y_min * new_height / old_height);\r\n      y_max = std::min(new_height, y_max * new_height / old_height);\r\n      break;\r\n']",[],0,0
124,caffe,4255,open,Cannot do a second net.forward() with Input layer,"I have a forloop in which I load different data into the layer and runs forward. It crashes my Nvidia driver. I found that this net can only do a forward once, and on the second  it crashes, giving unspecified launch failure. But if I load the net again in the forloop, it works fine.

I did not have this problem before, not sure why this shows up now. I tried different versions of Nvidia driver and it's the same.


",,"['Hi @kevin-li, Did you solve this?\r\n\r\nI have the same issue, what is the best way to run the same net on multiple incoming images?\r\nps. I know about the batch option, but it needs the images to be already present', 'hi @shelhamer, any suggestion on this topic? thanks', ""I don't remember exactly, but I was using the Windows version. Try smaller batches, it worked for me for  `cudaSuccess(4 vs. 0)`. I think it was my CUDA problem and I had to reinstall it the hard way..."", 'hi @kevin-w-li\r\nthanks for the comment. I use batch_size 1, I still get the error message Check failed: status == CUDNN_STATUS_SUCCESS (4 vs. 0)  CUDNN_STATUS_INTERNAL_ERROR for some networks.\r\n\r\nFor example for fcn8s, in this case I should reload the caffe.Net(deploy_file,caffemodel, caffe.TEST) for each image to get it working.\r\n\r\nfor other nets such as alexnet it works nicely just by loading the net once and using it for multiple images!\r\n\r\nif anyone has an idea, please comment \r\n\r\nI am using ubuntu 14, and cuda 7.5+cudnn 5', 'As an update, I installed cuda 8.0 and libcudnn5-dev_5.1.10\r\n\r\nI still get the same error ...', ""You said it works for AlexNet. Could you paste your net definition here? Or try reduce the net size...? Sorry I don't really know the problem."", 'Hi,\r\n\r\nI double checked, this problem only exist for the latest version of NV-caffe and not for the BVLC/caffe\r\n\r\nso I will report a bug on nv-caffe.\r\n\r\ncheers!\r\n', 'problem solved for nv-caffe in here \r\nhttps://github.com/NVIDIA/caffe/issues/299\r\n\r\nmaybe this issue can be closed.']","[""\nfor i in fvs:\n    batch_image = batch_images[i]\n    net.blobs['data'].reshape(*batch_image.shape)\n    net.blobs['data'].data[...] = batch_image-115\n    output = net.forward() # crashes on the second iteration\n    probs = output['prob'][:,1]\n\n""]","['Input', 'net.forward()', 'error == cudaSuccess (4 vs. 0)']",0,0
125,caffe,6882,open,Unsupported gpu architecture 'compute_481',"Unsupported gpu architecture 'compute_481'
py3.5
gtx1660ti
cuda10.0",,[],[],[],0,0
126,caffe,6642,open,make runtest error,"


*** Error in `.build_release/tools/caffe': free(): invalid pointer: 0x0000000001f342c0 ***
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f6d7e4387e5]
/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f6d7e44137a]
/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f6d7e44553c]
/usr/lib/x86_64-linux-gnu/libprotobuf.so.9(_ZN6google8protobuf8internal28DestroyDefaultRepeatedFieldsEv+0x1f)[0x7f6d7f74f8af]
/usr/lib/x86_64-linux-gnu/libprotobuf.so.9(_ZN6google8protobuf23ShutdownProtobufLibraryEv+0x8b)[0x7f6d7f74eb3b]
/usr/lib/x86_64-linux-gnu/libmirprotobuf.so.3(+0x233b9)[0x7f6d4bb8d3b9]
/lib64/ld-linux-x86-64.so.2(+0x10de7)[0x7f6d80ef3de7]
/lib/x86_64-linux-gnu/libc.so.6(+0x39ff8)[0x7f6d7e3faff8]
/lib/x86_64-linux-gnu/libc.so.6(+0x3a045)[0x7f6d7e3fb045]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf7)[0x7f6d7e3e1837]
.build_release/tools/caffe[0x4080b9]
======= Memory map: ========
00400000-00418000 r-xp 00000000 08:18 659239                             /home/csy/caffe/.build_release/tools/caffe.bin
00618000-00619000 r--p 00018000 08:18 659239                             /home/csy/caffe/.build_release/tools/caffe.bin
00619000-0061a000 rw-p 00019000 08:18 659239                             /home/csy/caffe/.build_release/tools/caffe.bin
01f22000-02191000 rw-p 00000000 00:00 0                                  [heap]
7f6d38000000-7f6d38021000 rw-p 00000000 00:00 0 
7f6d38021000-7f6d3c000000 ---p 00000000 00:00 0 
7f6d3fb87000-7f6d3fb88000 ---p 00000000 00:00 0 
7f6d3fb88000-7f6d40388000 rw-p 00000000 00:00 0 
7f6d46388000-7f6d46389000 ---p 00000000 00:00 0 
7f6d46389000-7f6d46b89000 rw-p 00000000 00:00 0 
7f6d46b89000-7f6d46b8a000 ---p 00000000 00:00 0 
7f6d46b8a000-7f6d4738a000 rw-p 00000000 00:00 0 
7f6d4738a000-7f6d4738b000 ---p 00000000 00:00 0 
7f6d4738b000-7f6d47b8b000 rw-p 00000000 00:00 0 
7f6d47b8b000-7f6d47b8e000 r-xp 00000000 08:16 1447018                    /lib/x86_64-linux-gnu/libkeyutils.so.1.5
7f6d47b8e000-7f6d47d8d000 ---p 00003000 08:16 1447018                    /lib/x86_64-linux-gnu/libkeyutils.so.1.5
7f6d47d8d000-7f6d47d8e000 r--p 00002000 08:16 1447018                    /lib/x86_64-linux-gnu/libkeyutils.so.1.5
7f6d47d8e000-7f6d47d8f000 rw-p 00003000 08:16 1447018                    /lib/x86_64-linux-gnu/libkeyutils.so.1.5
7f6d47d8f000-7f6d47d99000 r-xp 00000000 08:16 3417915                    /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1
7f6d47d99000-7f6d47f98000 ---p 0000a000 08:16 3417915                    /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1
7f6d47f98000-7f6d47f99000 r--p 00009000 08:16 3417915                    /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1
7f6d47f99000-7f6d47f9a000 rw-p 0000a000 08:16 3417915                    /usr/lib/x86_64-linux-gnu/libkrb5support.so.0.1
7f6d47f9a000-7f6d47f9d000 r-xp 00000000 08:16 1446966                    /lib/x86_64-linux-gnu/libcom_err.so.2.1
7f6d47f9d000-7f6d4819c000 ---p 00003000 08:16 1446966                    /lib/x86_64-linux-gnu/libcom_err.so.2.1
7f6d4819c000-7f6d4819d000 r--p 00002000 08:16 1446966                    /lib/x86_64-linux-gnu/libcom_err.so.2.1
7f6d4819d000-7f6d4819e000 rw-p 00003000 08:16 1446966                    /lib/x86_64-linux-gnu/libcom_err.so.2.1
7f6d4819e000-7f6d481ca000 r-xp 00000000 08:16 3417905                    /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1
7f6d481ca000-7f6d483c9000 ---p 0002c000 08:16 3417905                    /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1
7f6d483c9000-7f6d483cb000 r--p 0002b000 08:16 3417905                    /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1
7f6d483cb000-7f6d483cc000 rw-p 0002d000 08:16 3417905                    /usr/lib/x86_64-linux-gnu/libk5crypto.so.3.1
7f6d483cc000-7f6d483cd000 rw-p 00000000 00:00 0 
7f6d483cd000-7f6d48490000 r-xp 00000000 08:16 3417913                    /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3
7f6d48490000-7f6d48690000 ---p 000c3000 08:16 3417913                    /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3
7f6d48690000-7f6d4869d000 r--p 000c3000 08:16 3417913                    /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3
7f6d4869d000-7f6d4869f000 rw-p 000d0000 08:16 3417913                    /usr/lib/x86_64-linux-gnu/libkrb5.so.3.3
7f6d4869f000-7f6d486b1000 r-xp 00000000 08:16 1447001                    /lib/x86_64-linux-gnu/libgpg-error.so.0.17.0
7f6d486b1000-7f6d488b1000 ---p 00012000 08:16 1447001                    /lib/x86_64-linux-gnu/libgpg-error.so.0.17.0
7f6d488b1000-7f6d488b2000 r--p 00012000 08:16 1447001                    /lib/x86_64-linux-gnu/libgpg-error.so.0.17.0
7f6d488b2000-7f6d488b3000 rw-p 00013000 08:16 1447001                    /lib/x86_64-linux-gnu/libgpg-error.so.0.17.0
7f6d488b3000-7f6d488d4000 r-xp 00000000 08:16 3417698                    /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0
7f6d488d4000-7f6d48ad3000 ---p 00021000 08:16 3417698                    /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0
7f6d48ad3000-7f6d48ad4000 r--p 00020000 08:16 3417698                    /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0
7f6d48ad4000-7f6d48ad5000 rw-p 00021000 08:16 3417698                    /usr/lib/x86_64-linux-gnu/libgomp.so.1.0.0
7f6d48ad5000-7f6d48afc000 r-xp 00000000 08:16 3408053                    /usr/lib/x86_64-linux-gnu/libkj-0.5.3.so
7f6d48afc000-7f6d48cfc000 ---p 00027000 08:16 3408053                    /usr/lib/x86_64-linux-gnu/libkj-0.5.3.so
7f6d48cfc000-7f6d48cfd000 r--p 00027000 08:16 3408053                    /usr/lib/x86_64-linux-gnu/libkj-0.5.3.so
7f6d48cfd000-7f6d48cfe000 rw-p 00028000 08:16 3408053                    /usr/lib/x86_64-linux-gnu/libkj-0.5.3.so
7f6d48cfe000-7f6d48d04000 r-xp 00000000 08:16 3417408                    /usr/lib/x86_64-linux-gnu/libdatrie.so.1.3.3
7f6d48d04000-7f6d48f04000 ---p 00006000 08:16 3417408                    /usr/lib/x86_64-linux-gnu/libdatrie.so.1.3.3
7f6d48f04000-7f6d48f05000 r--p 00006000 08:16 3417408                    /usr/lib/x86_64-linux-gnu/libdatrie.so.1.3.3
7f6d48f05000-7f6d48f06000 rw-p 00007000 08:16 3417408                    /usr/lib/x86_64-linux-gnu/libdatrie.so.1.3.3
7f6d48f06000-7f6d48f2a000 r-xp 00000000 08:16 3417714                    /usr/lib/x86_64-linux-gnu/libgraphite2.so.3.0.1
7f6d48f2a000-7f6d49129000 ---p 00024000 08:16 3417714                    /usr/lib/x86_64-linux-gnu/libgraphite2.so.3.0.1
7f6d49129000-7f6d4912b000 r--p 00023000 08:16 3417714                    /usr/lib/x86_64-linux-gnu/libgraphite2.so.3.0.1
7f6d4912b000-7f6d4912c000 rw-p 00025000 08:16 3417714                    /usr/lib/x86_64-linux-gnu/libgraphite2.so.3.0.1
7f6d4912c000-7f6d4913d000 r-xp 00000000 08:16 3418331                    /usr/lib/x86_64-linux-gnu/libtasn1.so.6.5.1
7f6d4913d000-7f6d4933d000 ---p 00011000 08:16 3418331                    /usr/lib/x86_64-linux-gnu/libtasn1.so.6.5.1
7f6d4933d000-7f6d4933e000 r--p 00011000 08:16 3418331                    /usr/lib/x86_64-linux-gnu/libtasn1.so.6.5.1
.....
@1544933246"" if you are using GNU date ***
PC: @     0x7f28a54fa428 gsignal
*** SIGABRT (@0x426f) received by PID 17007 (TID 0x7f28a80f7b00) from PID 17007; stack trace: ***
    @     0x7f28a54fa4b0 (unknown)
    @     0x7f28a54fa428 gsignal
    @     0x7f28a54fc02a abort
    @     0x7f28a553c7ea (unknown)
    @     0x7f28a554537a (unknown)
    @     0x7f28a554953c cfree
    @     0x7f28a68538af google::protobuf::internal::DestroyDefaultRepeatedFields()
    @     0x7f28a6852b3b google::protobuf::ShutdownProtobufLibrary()
    @     0x7f2872c913b9 (unknown)
    @     0x7f28a7ff7de7 (unknown)
    @     0x7f28a54feff8 (unknown)
    @     0x7f28a54ff045 exit
    @     0x7f28a54e5837 __libc_start_main
    @           0x4080b9 _start
    @                0x0 (unknown)
Makefile:526: recipe for target 'runtest' failed
",,"['hi guys,i have this problem.how to solve this: -(', 'i met the same error,did you fix it?', '> i met the same error,did you fix it?\r\n\r\nyes.i have solved it.cause i lack of some libs ', '> > i met the same error,did you fix it?\r\n> \r\n> yes.i have solved it.cause i lack of some libs\r\n\r\nHeybut i  used BLAS := open  installed in other machine,it worked', ""> > > i met the same error,did you fix it?\r\n> > \r\n> > \r\n> > yes.i have solved it.cause i lack of some libs\r\n> \r\n> Heybut i used BLAS := open installed in other machine,it worked\r\n#5282 \r\nthe best way is running\r\napt-get remove libgtk-3-dev\r\nif u installed opencv,please uninstall and reinstall it.\r\nThis assumes that you have already installed libgtk2.0-dev.\r\nThe basic problem is that when you install both gtk3 and gtk2, and then install opencv, gtk3 takes up caffe's protobuf and opencv's protobuf threads.\r\n""]",[],[],0,0
127,caffe,5661,open,pycaffe occupy all gpus avaliables,"Using code in line 19 of the notebook example in [http://nbviewer.jupyter.org/github/BVLC/caffe/blob/master/examples/01-learning-lenet.ipynb](url), i created a python code to create and run caffe model.

But, when i call method by IPython, even if i specified which gpu it want to use, caffe occupy all gpus avaliables.

My code is:



### Your system configuration
Operating system: Ubuntu 14.04
caffe version: 0.15.13
Python: 2.7.6 ",,"['Just a clarification:\r\nPyCaffe seems to allocate in all GPUs ~112 Mb and in the gpu specified by my code its allocate all work, as seen by nvidia-smi call:\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 361.93.02              Driver Version: 361.93.02                 |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla M40           On   | 0000:03:00.0     Off |                    0 |\r\n|  0%   40C    P0    66W / 250W |    299MiB / 11448MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla M40           On   | 0000:04:00.0     Off |                    0 |\r\n|  0%   43C    P0   158W / 250W |    468MiB / 11448MiB |     90%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla M40           On   | 0000:82:00.0     Off |                    0 |\r\n|  0%   29C    P0    66W / 250W |    114MiB / 11448MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla M40           On   | 0000:83:00.0     Off |                    0 |\r\n|  0%   30C    P0    65W / 250W |    114MiB / 11448MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID  Type  Process name                               Usage      |\r\n|=============================================================================|\r\n|    0      1811    C   /usr/bin/python                                106MiB |\r\n|    0     99066    C   /usr/bin/python                                188MiB |\r\n|    1     99066    C   /usr/bin/python                                466MiB |\r\n|    2     99066    C   /usr/bin/python                                112MiB |\r\n|    3     99066    C   /usr/bin/python                                112MiB |\r\n+-----------------------------------------------------------------------------+\r\n```\r\n\r\nIs it be considered as bug? or is it normal?\r\n\r\n']","['\r\ndef run(solver_config_path, num_gpu=1 ):\r\n\tcaffe.set_mode_gpu()\r\n\tcaffe.set_device( num_gpu )\r\n\r\n\tsolver_config = caffe_pb2.SolverParameter()\r\n\twith open(solver_config_path) as f:\r\n\t\ttext_format.Merge(str(f.read()), solver_config)\r\n\r\n\tsolver = None  \r\n\tsolver = caffe.get_solver(solver_config_path)\r\n\r\n\tniter = solver_config.max_iter  # EDIT HERE increase to train for longer\r\n\ttest_interval = solver_config.test_interval\r\n\ttrain_loss = np.zeros(niter)\r\n\ttest_loss = np.zeros(int(np.ceil(niter / test_interval)))\r\n\tfor it in range(niter):\r\n            .....\r\n            .....\r\n']",[],0,0
128,caffe,5641,open,VERION,"https://github.com/BVLC/caffe/search?utf8=%E2%9C%93&q=VERION&type=

should be VERSION, shouldn't it?",style,[],[],[],0,0
129,caffe,5422,open,parse_log.sh and plot_training_log.py broken by log format,"#Iters Seconds TrainingLoss LearningRate
0      60.772177    60.7705s/100  0.0001
100    96.870289    36.0956s/100  0.0001
200    133.719327   36.8478s/100  0.0001
300    170.667324   36.946s/100   0.0001
400    207.608621   36.9394s/100  0.0001
500    244.500362   36.89s/100    0.0001
600    281.548364   37.0463s/100  0.0001
700    318.434129   36.8841s/100  0.0001
800    355.580382   37.1446s/100  0.0001
900    392.528603   36.9466s/100  0.0001
1000   429.473415   36.9432s/100  0.0001
1100   466.495543   37.0206s/100  0.0001
1200   503.244692   36.7477s/100  0.0001
1300   540.270175   37.0241s/100  0.0001
1400   577.266514   36.995s/100   0.0001
1500   614.206808   36.9389s/100  0.0001
1600   651.201857   36.9936s/100  0.0001
1700   688.026594   36.8234s/100  0.0001
1800   725.065849   37.0379s/100  0.0001
1900   761.979795   36.9126s/100  0.0001
2000   859.710876   97.7279s/100  0.0001
2100   896.690779   36.9773s/100  0.0001
2200   933.594652   36.9026s/100  0.0001
2300   970.522537   36.9266s/100  0.0001
2400   1007.543336  37.0196s/100  0.0001
2500   1044.460583  36.916s/100   0.0001
2600   1081.500929  37.0391s/100  0.0001
2700   1118.330184  36.8281s/100  0.0001
2800   1155.352403  37.021s/100   0.0001
2900   1192.409225  37.0556s/100  0.0001
3000   1229.340137  36.9297s/100  0.0001
3100   1266.362365  37.0211s/100  0.0001
3200   1303.306361  36.9428s/100  0.0001
3300   1340.233099  36.9256s/100  0.0001
...

The training loss here is time per 100 iteration.",bug,"['<img width=""990"" alt=""screen shot 2017-03-18 at 10 51 28 am"" src=""https://cloud.githubusercontent.com/assets/10518587/24068408/dcf946bc-0bc8-11e7-98ae-f5279062bc4d.png"">\r\n\r\nI think this is the part that causes the problem. Why is the log format not consistent?', 'And also why is their two losses for training when I only define one?\r\n\r\n1) Iteration ..... , loss = ...\r\n2) Train net output ... : loss = ...\r\n\r\nand these 2 losses are of different values.', 'I met this problem,  I changed the parse_log.sh, and it worked\r\n\r\n**before**\r\n`grep \', loss = \' $1 | awk \'{print $9}\' > aux1.txt\r\n`\r\n**after changed**\r\n` grep \', loss = \' $1 | awk -F = \'{print $2}\' > aux1.txt\r\n`\r\nI use ""="" to help find the right position of loss, I hope it can help you.', '@cypof this issue and #5361 seem to be caused by 3ba20549b7f49a76cd023d19f781a6891b2c2122 since the solver logging was altered. See https://github.com/BVLC/caffe/blob/master/src/caffe/solver.cpp#L220-L221\r\n\r\nCould you fix the tools? (Bonus: add simple tests, like for draw_net.py, or else this will keep breaking accidentally.)', 'thks @fangbinwei your fix works. #5514 The python parser looks ok.\r\n\r\n@yxchng iteration loss is snoothed, c.f. solfver_param.average_loss.  ', '> And also why is their two losses for training when I only define one?\r\n> \r\n>     1. Iteration ..... , loss = ...\r\nThis value is the average over the last `average_loss`  iterations as specified in the `solver.prototxt` parameter. \r\nhttps://github.com/BVLC/caffe/wiki/Solver-Prototxt\r\n\r\n> \r\n>     2. Train net output ... : loss = ...\r\n> \r\nThis value is the loss for that specific iteration\r\n']",[],[],0,0
130,caffe,4309,open,will there be some examples for the new lstm layers?,"will there be some examples for the new lstm layer?
",,"['I am looking for it\n', 'Did you ever figure this out? LSTM on caffe does not seem to work']",[],[],0,0
131,caffe,5566,open,Any interface to clear to intermediate variables generated by network forward in test phase?,"Seems I googled around for a while and found no interface to reset the network to its status as newly loaded in test phase.

I mean the memory used can only increase but not decrease.

The problem is that say, I have 3 separate alg worker process that are in the algorithm chain.

Suppose A/B/C have similar memory usage above, and my GPU is 8GB.
It's clear where the problem appears. It will say  while forwarding in .

One embarrass solution is copy output from alg and then  and  the net to keep ~400MB memory usage. And continue with the next alg.
Under production, this is a stupid solution that will waste a lot of time on  and  (file reading IO).
So, can we supply an interface to free all the appropriate variables that will lead the  fresh new as just loaded?

I found the most possible API in [ApolloCaffe](https://github.com/Russell91/apollocaffe). But the author seemed not maintaining the repo. @Russell91 


Code from google snapshot of http://apollocaffe.com/",,"[""Caffe resize blobs on each `forward()` so the memory occupied will gradually increase.\r\n\r\nYou should know that allocating and freeing chunks of memory are also time-consuming. Beside the time costs born by device synchronizing between CPU and GPU, it has to IO weights and other layer information between CPU, RAM and your hard drive as well. I don't think it could get any better if the feature you asked is implemented.\r\n\r\nAnyway, the posted workflow could be done step-by-step, run all `alg1` before `alg2` might be a solution. If it doesn't suit your need, you need a better video card with larger VRAM with it."", 'I don\'t know if this feature is worth to be implemented.\r\n\r\nI finally solved my embarrass situation by `reload` the net after each `forward pass` which is like the code below:\r\n```python\r\nnet = caffe.Net(...) # let\'s say it uses 400MB memory.\r\nnet.blobs[""data""].data[...] = img # In theory, this operation should only increase memory usage by a few MB.\r\nresult = net.forward()[""output""] # Seems the memory usage up to ~3GB in my practical situation.\r\nnet = caffe.Net(...) # Reload to free the ~3GB memory used to ~400MB.\r\n```\r\nI use this same approach to alg A/B/C, so that the memory peak would be only ~3GB rather than 9GB before. This solved my problem, but, lead to `50% extra executing time`.']","['python\r\nnet = caffe.Net(...) # let\'s say it uses 400MB memory.\r\nnet.blobs[""data""].data[...] = img # In theory, this operation should only increase memory usage by a few MB.\r\nresult = net.forward()[""output""] # Seems the memory usage up to ~3GB in my practical situation.\r\n', '\r\nInput Image -> alg A -> alg B -> alg C -> output\r\n', ""python\r\n# /path/to/apollo/examples/apollocaffe/simple.py\r\nimport apollocaffe\r\nfrom apollocaffe.layers import NumpyData, Convolution, EuclideanLoss\r\nimport numpy as np\r\n\r\nnet = apollocaffe.ApolloNet()\r\nfor i in range(1000):\r\n    example = np.array(np.random.random()).reshape((1, 1, 1, 1))\r\n    net.clear_forward()\r\n    net.f(NumpyData('data', example))\r\n    net.f(NumpyData('label', example*3))\r\n    net.f(Convolution('conv', (1,1), 1, bottoms=['data']))\r\n    net.f(EuclideanLoss('loss', bottoms=['conv', 'label']))\r\n    net.backward()\r\n    net.update(lr=0.1)\r\n    if i % 100 == 0:\r\n        print net.loss\r\n""]","['out of memory', 'alg C', 'reload', 're-initialized', 'delete', 'reload', 'net']",0,0
132,caffe,6685,open, boost,"## Important - read before submitting

*Please read the [guidelines for contributing](https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md) before submitting this issue!*

*Please do not post installation, build, usage, or modeling questions, or other requests for help to Issues.*
Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead.
This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.

### Issue summary


### Steps to reproduce


### Tried solutions


### System configuration

* Operating system: 
* Compiler: 
* CUDA version (if applicable): 
* CUDNN version (if applicable): 
* BLAS: 
* Python version (if using pycaffe): 
* MATLAB version (if using matcaffe): 

### Issue checklist

- [ ] read the guidelines and removed the first paragraph
- [ ] written a short summary and detailed steps to reproduce
- [ ] explained how solutions to related problems failed (tick if found none)
- [ ] filled system configuration
- [ ] attached relevant logs/config files (tick if not applicable)
",,[],[],[],0,0
133,caffe,3331,open,how  could weight_diff of a conv layer become so large?,"cccp5
top data[max:105.422 min:-123.697 mean:-1.9735]

bottom data[max:96.133 min:-0 mean:0.000809771]

top diff[max1.35333e-08 min:-1.33265e-08 mean:-1.96833e-16]

bottom diff[max:0.000116085 min:-0.000235484 mean:-2.54426e-16]

weight diff[max:1.17238e+06 min:-0.770284 mean:10107.5]

weight[max:0.177044 min:-0.202771 mean:-0.000405207]

i print the information of a conv layer,the top diff and bottom data is small,why weight diff became so big???  since we know weight diff depends on the value of top diff and bottom data.

code:
if (this->param_propagate_down_[0]) {
          this->weight_cpu_gemm(bottom_data + n \* this->bottom_dim_,
              top_diff + n \* this->top_dim_, weight_diff);
}
",,"[""From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n\nAre you running this for multiple iterations (gradient accumulation with `iter_size` in solver)?\n\nDo you think that you've found a bug?  Or are you just surprised that your particular problem is unstable?\n"", 'is there a iter_size in solver? i could not find it.\ni am not sure whether it is bug or not,but it was strange that weight diff became so large since we how to compute the weight diff from top diff and bottom data.\n']",[],[],0,0
134,caffe,5954,open,Caffe got stuck halfway when training imagenet dataset,"Please use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) for usage, installation, or modeling questions, or other requests for help.
_Do not post such requests to Issues._ Doing so interferes with the development of Caffe.

Please read the [guidelines for contributing](https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md) before submitting this issue.

### Issue summary
I'm training imagenet dataset using inception v3. Everything was fine in the first two days, but then caffe was stuck since yesterday.  The log hasn't been updated for 24 hours, but when I check cpu and gpu, it seems that caffe in still runing. Does anyone know what's going on? Thanks a lot!


### nvidia-smi output:

### log
",,"['@liangshuang1993 Have you managed to resolve this issue?\r\n\r\nI am experiencing the same problem with the latest code on master branch cloned with git yesterday.\r\n\r\nIn my case, the training reaches around 23000 iterations and then hangs. Once it hangs there is no logs anymore. I am using a combination of lmdb layer and MemoryDataLayer. \r\n\r\nIf it helps, I am calling solver->Step(1) for multiple iterations because the size of data is too large to store in hard drive (as a lmdb file) or in RAM, so the MemoryDataLayer takes new input from RAM in each iteration. \r\n\r\nThe configuration of 02 data layers of my model, if that helps:\r\n\r\nname: ""MyNet""\r\nlayer {\r\n    name: ""lowlevel_db""\r\n    type: ""Data""\r\n    top: ""lowdata""\r\n    top: ""label""\r\n    transform_param {\r\n\t    mirror: false\r\n    } \r\n    data_param {\r\n        source: ""train_lowDB""\r\n        backend: LMDB\r\n        batch_size: 100\r\n    }\r\n}\r\nlayer {\r\n  name: ""highlevel_db""\r\n  type: ""MemoryData""\r\n  top: ""conv5_3""\r\n  top: ""fakelabel""\r\n  transform_param {\r\n\tmirror: false\r\n  }\r\n  memory_data_param {\r\n\tbatch_size: 100\r\n\tchannels: 512\r\n\theight: 14\r\n\twidth: 14\r\n  }\r\n}\r\n']","['\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           On   | 0000:08:00.0     Off |                    0 |\r\n| N/A   51C    P0   124W / 149W |  10200MiB / 11439MiB |     88%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K80           On   | 0000:09:00.0     Off |                    0 |\r\n| N/A   67C    P0   134W / 149W |   6412MiB / 11439MiB |     80%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla K80           On   | 0000:83:00.0     Off |                    0 |\r\n| N/A   53C    P0   136W / 149W |   6412MiB / 11439MiB |     92%      Default |\r\n', '\r\n...\r\n0: I0928 08:55:50.993021 58717 sgd_solver.cpp:105] Iteration 113320, lr = 0.0088668\r\n0: I0928 08:56:26.529989 58717 solver.cpp:218] Iteration 113360 (1.12558 iter/s, 35.5371s/40 iters), loss = 0.529116\r\n0: I0928 08:56:26.530251 58717 solver.cpp:237]     Train net output #0: loss1/loss1 = 1.59655 (* 0.3 = 0.478965 loss)\r\n0: I0928 08:56:26.530263 58717 sgd_solver.cpp:105] Iteration 113360, lr = 0.0088664\r\n0: I0928 08:57:02.026926 58717 solver.cpp:218] Iteration 113400 (1.12686 iter/s, 35.4968s/40 iters), loss = 0.559563\r\n0: I0928 08:57:02.027178 58717 solver.cpp:237]     Train net output #0: loss1/loss1 = 1.18278 (* 0.3 = 0.354835 loss)\r\n0: I0928 08:57:02.027192 58717 sgd_solver.cpp\r\n']",[],0,0
135,caffe,86,closed,Add python script to plot the training log,,interface,"['Would be good to have. One can better formulate the solver messages or potentially have the solver write the key parameters like current loss to a separate log file so further scripts could analyze it more easily.\n', 'I have a bash script that extracts the relevant information from the log,\nwhich later can be easily plotted with python, gnuplot, matlab, ...\nI can share or simply add it to the code base see #89.\n\n2014-02-08 kloudkl notifications@github.com:\n\n> ## \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/BVLC/caffe/issues/86\n> .\n', '@sguada, thanks for sharing your script in #89 and #90!  I am inspired a lot. \n\nDue to the diversified requirements of the users of Caffe, the best we can do is to provide a sample python script as the basis for various customizations. To this end, data extraction and plotting should be separated as you have done. For benchmarking purpose, results of multiple experiments often need to be plotted in one chart.\n\nBased on the information present in the current version of training log, possible useful plots are summarized as follows. In the future, this script should be synchronized with the changes of the training log format such as adding training or validation accuracy.\n1. Test accuracy (test score 0)  vs. training iterations / time;\n2. Test loss (test score 1) vs. training iterations / time;\n3. Training loss vs. training iterations / time;\n4. Learning rate vs. training iterations / time;\n', 'Good job everyone. This is done with #89 #90 #91 .\n']",[],[],0,0
136,caffe,703,closed,Problem while importing caffe in Python,"When I try to import caffe from the terminal in Ubuntu by the command python -c ""import caffe"", I get the following error :

GLIBC_2.15' not found (required by /usr/lib/x86_64-linux-gnu/libvorbis.so.0)
`

Could anyone assist here ?
",,"[""I've seen this as well; looks like it's a bug in a recent anaconda release. You can work around it by temporarily renaming libm.so and libm.so.6 in your anaconda lib directory.\n\nSee https://groups.google.com/a/continuum.io/forum/#!topic/anaconda/-DLG2ZdTkw0.\n"", 'Now I am confused by this ImportError; is there some wrong ?\n @sayanghosh if you have solved this problem ,please let me know ,thank you very much\n', ""I am getting this error as well, but can't seem to figure out how to solve it.  Doing a `locate libm.so.6` I see this:\n\n```\n/home/dreed/anaconda/lib/libm.so.6\n/home/dreed/anaconda/pkgs/system-5.8-1/lib/libm.so.6\n/lib/x86_64-linux-gnu/libm.so.6\n```\n\nIsn't this correct?\n""]",[],"['', '\nTraceback (most recent call last):\n  File ""<string>"", line 1, in <module>\n  File ""/home/sghosh/mnt/Sayancode/caffe/caffe/distribute/python/caffe/__init__.py"", line 1, in <module>\n    from .pycaffe import Net, SGDSolver\n  File ""/home/sghosh/mnt/Sayancode/caffe/caffe/distribute/python/caffe/pycaffe.py"", line 10, in <module>\n    from ._caffe import Net, SGDSolver\nImportError: /home/sghosh/anaconda/bin/../lib/libm.so.6: version ', '']",0,0
137,caffe,101,closed,Establish Development and Contribution Guidelines,"This is a request for comments on the Caffe development model and contribution protocol. These aren't draconian laws so much as guidelines so we can all happily brew Caffe. Establishing protocols is only a side effect of having such thriving development, so it's a lovely problem we have.

Development workflow proposal:
-  is golden.
- work is done in feature branches. These should be rebased to the tip of  to avoid driftand this is required for merge.
-  is the branching point for features, and the target of pull requests for merge.
- contributions are shepherded from  to   by the project maintainers after integration and testing via merge.
- the history of  is not rewritten. accidents are fixed by reverts.
- ""releases"" are marked with tags

Contributions/Issues/PR proposal: see https://github.com/BVLC/caffe/issues/101#issuecomment-35349256.

The closer your contribution follows these suggestions, the less friction for merging.
",,"['sounds good to me. Will help avoiding problems in #100 :)\n\nYangqing\n\nOn Wed, Feb 12, 2014 at 5:40 PM, Evan Shelhamer notifications@github.comwrote:\n\n> How about making a dev branch to use as the default target for pull\n> requests? Once there has been review and testing and the development of a\n> particular change has quieted down we can merge to master.\n> \n> ## \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/BVLC/caffe/issues/101\n> .\n', 'Done, with a draft contributing guide in README too. 59cdf127c28df07369ca8d2d1ba6f87d21c75972\n', 'Let\'s try the `dev` model.\n\nIf the overhead of having `dev` proves annoying, we could keep up our active development in `master` but tag whenever we have anything ""stable"" enough for cloning.\n', ""Yeah, I'm not sure what is the best way to go. Having two parallel branches could be annoying to keep in sync but could allow to try more things. Maybe we should have someone assigned to do a code review before any pull request is merged in master.\n"", ""Based on today's d339d242b43ec5bec9dceb657ee0d665d524b1eb breaking master (sorry everybody!) I think `dev` is worth the slight overhead. There are tricks to keep the integration work down.\n\nI volunteer to handle `dev` for now and I'll write up a guide on working with it without headaches.\n"", '@shelhamer I have created my first PR #125 against `dev` instead of master, I hope this will work. \n', ""Here's a sketch of my proposal for a contribution protocol:\n- 0. make issues for bugs (label: bug) , tentative proposals, and questions (label: question).\n- 1a. make PRs _as soon as development begins_. create a feature branch, make your initial commit, push, and PR to let everyone know you are working on it and let discussion guide development instead of review development after-the-fact.\n- 1b. As soon as a proposal from step 0 earns enough interest to warrant development, make a PR, and reference + close the old issue to direct the conversation to the PR.\n- 2. when a PR is ready, comment to sign off on it and let maintainers know.\n"", '@shelhamer, I opened PR #126 to follow the clause 1a of your protocol. I believe that it will improve the development speed and the quality of the final algorithm.\n', '@shelhamer attaching a pull request to an issue is possible with some shell scripts. http://stackoverflow.com/questions/4528869/how-do-you-attach-a-new-pull-request-to-an-existing-issue-on-github\n', 'Yes, you can attach a _new_ PR to an issue by many ways: the API, referring\nto the issue number in commits (like in my custom merges), and so on. What\nI am trying to avoid is a proliferation of PRs and issues when one would\nsuffice, and the API does not yet support updating _existing_ PRs.\n\nThank you for the script pointer though, and being conscientious in your\nown work to link follow-up issues and PRs to avoid losing the thread.\n\nLe mardi 18 fvrier 2014, Lin Min notifications@github.com a crit :\n\n> @shelhamer https://github.com/shelhamer attaching a pull request to an\n> issue is possible with some shell scripts.\n> http://stackoverflow.com/questions/4528869/how-do-you-attach-a-new-pull-request-to-an-existing-issue-on-github\n> \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/BVLC/caffe/issues/101#issuecomment-35455511\n> .\n', ""P.S. hub is wonderful and everyone should use it.\n\nLe mardi 18 fvrier 2014, Evan Shelhamer shelhamer@imaginarynumber.net a\ncrit :\n\n> Yes, you can attach a _new_ PR to an issue by many ways: the API,\n> referring to the issue number in commits (like in my custom merges), and so\n> on. What I am trying to avoid is a proliferation of PRs and issues when one\n> would suffice, and the API does not yet support updating _existing_ PRs.\n> \n> Thank you for the script pointer though, and being conscientious in your\n> own work to link follow-up issues and PRs to avoid losing the thread.\n> \n> Le mardi 18 fvrier 2014, Lin Min <notifications@github.com<javascript:_e(%7B%7D,'cvml','notifications@github.com');>>\n> a crit :\n> \n> > @shelhamer https://github.com/shelhamer attaching a pull request to an\n> > issue is possible with some shell scripts.\n> > http://stackoverflow.com/questions/4528869/how-do-you-attach-a-new-pull-request-to-an-existing-issue-on-github\n> > \n> > \n> > Reply to this email directly or view it on GitHubhttps://github.com/BVLC/caffe/issues/101#issuecomment-35455511\n> > .\n"", 'I will add a ""contributing"" doc page as part of #151 \n', 'The README now has contributing, documentation, and branching sections and the documentation has [development guidelines](http://caffe.berkeleyvision.org/development.html). This issue is solved, and further work can refine these guides.\n']",[],"['master', 'dev', 'dev', 'dev', 'master', 'dev']",0,0
138,caffe,626,closed,Getting invalid device function error while trying to make runtest in Ubuntu 14.04 with Cuda 6.0,"Hi,

I have installed and compiled caffe successfully (I mean I ran 'make all' and 'make test' without any error). While running 'make runtest' I'm getting an ""invalid device function error"". The full log is given below. I'm using cuda 6.0 in Ubuntu 14.04 LTS. The gcc/g++ version is 4.6 and I installed and changed the make files as described in 'https://github.com/BVLC/caffe/issues/337' by weinman. I had to install gcc/g++ 4.6 as I was having an error as described in the above link while using gcc/g++ 4.8
Any help will be highly appreciated

The log is below:::
[ RUN      ] StochasticPoolingLayerTest/1.TestGradientGPU
F0705 07:26:44.199472 14804 pooling_layer.cu:186] Check failed: error == cudaSuccess (8 vs. 0)  invalid device function 
**\* Check failure stack trace: ***
    @     0x2ad77f5559fd  google::LogMessage::Fail()
    @     0x2ad77f55789d  google::LogMessage::SendToLog()
    @     0x2ad77f5555ec  google::LogMessage::Flush()
    @     0x2ad77f5581be  google::LogMessageFatal::~LogMessageFatal()
    @           0x610fba  caffe::PoolingLayer<>::Forward_gpu()
    @           0x431c58  caffe::GradientChecker<>::CheckGradientSingle()
    @           0x474124  caffe::StochasticPoolingLayerTest_TestGradientGPU_Test<>::TestBody()
    @           0x55b30d  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @           0x553131  testing::Test::Run()
    @           0x553216  testing::TestInfo::Run()
    @           0x553357  testing::TestCase::Run()
    @           0x5536ae  testing::internal::UnitTestImpl::RunAllTests()
    @           0x55ae8d  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @           0x55278e  testing::UnitTest::Run()
    @           0x4120dd  main
    @     0x2ad7818ffec5  (unknown)
    @           0x416e57  (unknown)
make: **\* [runtest] Aborted (core dumped)

Thanks,
Abir
",,"['https://github.com/BVLC/caffe/search?q=invalid+device+function+&ref=cmdform&type=Issues\n', ""@dasabir Hello dasabir, have you solved your problem now? I'm stuck in the same problem with yours...And I haven't found solution from the page of kloudkl. Could you please share your way to solve the problem?\n"", 'Hi @wusx11 , I should say I could solve the problem. Though I have done a fresh re-install of Ubuntu 14.04, yet I think last time I was making a mistake in the Makefile.config file. For cuda 6.0 I was uncommenting line 14 and 15 as instructed. But I was not putting an escape character () at the end of line 13. Could you please try it? If that resolves the problem, then this issue can also be closed.\n', ""Hi @dasabir , I hadn't put an escape character at the end of the line 13 as well... And after I did that, it works well! Thank you so much!\n"", ""Hi @wusx11, I'm glad that the issue was resolved. I think its time to close the ticket. Also I would request the contributors to add a flag in the comment section of the makefile.config in this regard.\n"", ""Hi @dasabir & @wusx11, \n\nCould you give me a bit more detail on this bug? I'm running 12.04 and Cuda-5.5 and getting the exact error. My line 13/14 is just commented so I'm unclear on your fix. \n"", 'And uncomment the line 24/25 for CUDA 6.0 is necessary.\n', ""@dasabir  Hmm.... i'm unclear too... _\nCan you show me example what you said...\n\nthanks\n"", 'I face the same issue, and i solved it successfully.\nfirstly, you need to open the file Makefile.config in you caffe directory\nyou can see the line like below:\n\nCUDA_ARCH := -gencode arch=compute_20,code=sm_20 \\\n                -gencode arch=compute_20,code=sm_21 \\\n                -gencode arch=compute_30,code=sm_30 \\\n                -gencode arch=compute_35,code=sm_35 \n              #  -gencode=arch=compute_50,code=sm_50 \\\n              #   -gencode=arch=compute_50,code=compute_50\n\nuncomment the last two lines \nthen you also need to add "" \\"" at the end of \n\n -gencode arch=compute_35,code=sm_35 \n\nafter these you need to    make     again  \n good luck!\n', ""I'm running this error with\n\n```\n$ docker run -ti caffe:gpu caffe --version\nlibdc1394 error: Failed\ncaffe version 1.0.0-rc3\n```\n\nand\n\n```\n$ nvidia-smi\nTue Oct 25 15:08:35 2016       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 370.28                 Driver Version: 370.28                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1080    Off  | 0000:01:00.0      On |                  N/A |\n|  0%   48C    P8     7W / 200W |     62MiB /  8105MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GTX 1080    Off  | 0000:02:00.0     Off |                  N/A |\n|  0%   38C    P8     7W / 200W |      1MiB /  8113MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1241    G   /usr/lib/xorg/Xorg                              60MiB |\n+-----------------------------------------------------------------------------+\n```\n\nand\n\n```\n$ nvcc --version\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2016 NVIDIA Corporation\nBuilt on Sun_Sep__4_22:14:01_CDT_2016\nCuda compilation tools, release 8.0, V8.0.44\n```\n"", ""I am facing a similar error.  using latest CUDA version (8.0) with enabled GPU Nvidia Geforce 820M Ubuntu 16.04. How to change the CUDA arch.\r\n\r\n[ RUN ] TanHLayerTest/2.TestTanH\r\nF0310 07:19:41.605973 3025 tanh_layer.cu:26] Check failed: error == cudaSuccess (8 vs. 0) invalid device function\r\n*** Check failure stack trace: ***\r\n@ 0x7f5cb33b75cd google::LogMessage::Fail()\r\n@ 0x7f5cb33b9433 google::LogMessage::SendToLog()\r\n@ 0x7f5cb33b715b google::LogMessage::Flush()\r\n@ 0x7f5cb33b9e1e google::LogMessageFatal::~LogMessageFatal()\r\n@ 0x7f5cb162f2aa caffe::TanHLayer<>::Forward_gpu()\r\n@ 0x481379 caffe::Layer<>::Forward()\r\n@ 0x7b1320 caffe::TanHLayerTest<>::TestForward()\r\n@ 0x8e1cb3 testing::internal::HandleExceptionsInMethodIfSupported<>()\r\n@ 0x8db2ca testing::Test::Run()\r\n@ 0x8db418 testing::TestInfo::Run()\r\n@ 0x8db4f5 testing::TestCase::Run()\r\n@ 0x8dc7cf testing::internal::UnitTestImpl::RunAllTests()\r\n@ 0x8dcaf3 testing::UnitTest::Run()\r\n@ 0x46693d main\r\n@ 0x7f5cb0d3b830 __libc_start_main\r\n@ 0x46dfd9 _start\r\n@ (nil) (unknown)\r\nMakefile:532: recipe for target 'runtest' failed\r\nmake: *** [runtest] Aborted (core dumped)"", '@vamsus have you been able to solve the problem?', '@TheShadow29  I solved CUDA 8.0 installation. By disabling CUDNN support. As Nvidia 820M compute capability is 2.1. To support CUDNN compute capability should be more than 3.0.\r\n\r\n(https://developer.nvidia.com/cuda-gpus) u can check your GPU compute capability. Disable it by commenting line in the makefile.\r\n\r\nIf u face same error then follow this installation guide link. (http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#axzz4ajfl49uf).']",[],[],0,0
139,caffe,5606,closed,Cmake build with malab,"### Issue summary
I tried to compile caffe and matcaffe but i get the following error


### Steps to reproduce
Build commands



### system configuration
Operating system: Arch Linux
CUDA version : 8.0.61
CUDNN version : 6.0.21
BLAS: OpenBlas
Matlab : R2017a
",,"['Some include paths in CMakeLists.txt are missing:\r\n- <source_root>/include\r\n- \\<cuda>/include\r\n\r\nI (dirty) fixed it by including this into the CMakeLists.txt:\r\n``set (cflags ${cflags} -I${Caffe_INCLUDE_DIR} -I/usr/local/cuda/include)``', ""I'm encountering the same problem. Has anyone come up with a solution other than Joe136 is suggesting."", 'Has anyone come up with a solution other than Joe136 is suggesting?', 'andreanicastro,Have you solved the problem?Can you share your solution with me?', 'Solution by Joe136 is ok, you have to add the missing include files.\r\nYou have to edit ../matlab/CMakeLists.txt', 'I added this line as Joe136 said : \r\n# prepare linker flag lists\r\nstring(REPLACE "";"" "";-L"" link_folders ""-L${folders}"")\r\nstring(REPLACE "";"" "":""  rpath_folders   ""${folders}"")\r\n\r\nif(build_using MATCHES ""Matlab"")\r\n  set(libflags -lcaffe${Caffe_POSTFIX} ${libflags}) # Matlab R2014a complans for -Wl,--whole-archive\r\n  **set (cflags ${cflags} -I${Caffe_INCLUDE_DIR} -I/usr/local/cuda/include) #add this line!!!!** \r\n  caffe_fetch_and_set_proper_mexext(Matlab_caffe_mex)\r\n  add_custom_command(OUTPUT ${Matlab_caffe_mex} COMMAND ${Matlab_mex}\r\n      ARGS -output ${Matlab_caffe_mex} ${Matlab_srcs} ${cflags} ${link_folders} ${libflags}\r\n      DEPENDS caffe COMMENT ""Building Matlab interface: ${Matlab_caffe_mex}"" VERBATIM)\r\n  add_custom_target(matlab ALL DEPENDS ${Matlab_caffe_mex} SOURCES ${Matlab_srcs})\r\n\r\nAnd works!!! Thank you!']","['\r\n[100%] Building Matlab interface: /home/an4915/software/caffe/matlab/+caffe/private/caffe_.mexa64\r\nBuilding with \'g++-4.9\'.\r\n/home/an4915/software/caffe/matlab/+caffe/private/caffe_.cpp:18:27: fatal error: caffe/caffe.hpp: No such file or directory\r\n #include ""caffe/caffe.hpp""\r\n                           ^\r\ncompilation terminated.\r\n\r\nmake[2]: *** [matlab/CMakeFiles/matlab.dir/build.make:61: ../matlab/+caffe/private/caffe_.mexa64] Error 255\r\nmake[1]: *** [CMakeFiles/Makefile2:1173: matlab/CMakeFiles/matlab.dir/all] Error 2\r\nmake: *** [Makefile:130: all] Error 2\r\n\r\n']","['cmake  -DCUDA_HOST_COMPILER:STRING=gcc-5 -DBUILD_matlab=ON ..', 'make -j ']",0,0
140,caffe,4289,closed,Undefined function 'caffe_' for input arguments of type 'char',"Hi all. I am trying to run the classification_demo. I have completed the steps stated at https://github.com/BVLC/caffe/tree/windows. I only have Matlab enabled to true. My code is extremely simple

im = imread('cat.jpg');
[score, class] = classification_demo(im, 0);

But when I run it I get the following error. Undefined function 'caffe_' for input arguments of type 'char'
Can anyone help me on this ?
",,"['Please ask usage/installation questions on the mailing list.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
141,caffe,4577,closed,Caffe installation failing on OS X 10.11 - Undefined symbols for architecture x86_64:,"Hi

I see ""Undefined symbols for architecture x86_64:""  error when i try to build Caffe on Mac which has OS X version 10.11.6 running on it. 
I did follow the instructions mentioned here : http://caffe.berkeleyvision.org/install_osx.html, however i still see the error. I even downgraded the version of Xcode from 7.3 to 7.0 as was suggested in one of the blogposts i encountered.

I have the following dependencies installed and I have Cuda version 7.5 installed.
snappy-1.1.3 
leveldb-1.18 
gflags-2.1.2 
glog-0.3.4 
szip-2.1 
lmdb-0.9.14 
homebrew/science/opencv-2.4.13 
protobuf-2.6.1

_I have attached the Makefile and Makefile.config with this email._

> brew install --build-from-source --fresh -vd boost boost-python 
> /usr/local/Library/Homebrew/brew.rb (Formulary::FormulaLoader): loading /usr/local/Library/Taps/homebrew/homebrew-core/Formula/boost.rb
> /usr/local/Library/Homebrew/brew.rb (Formulary::FormulaLoader): loading /usr/local/Library/Taps/homebrew/homebrew-core/Formula/boost-python.rb
> Warning: boost-1.61.0 already installed
> Warning: boost-python-1.61.0 already installed

====================================== make all output ============================================
MacBook-Pro-3:caffe praveenbodigutla$ make all
CXX .build_release/src/caffe/proto/caffe.pb.cc
CXX src/caffe/blob.cpp
CXX src/caffe/common.cpp
CXX src/caffe/data_reader.cpp
CXX src/caffe/data_transformer.cpp
CXX src/caffe/internal_thread.cpp
CXX src/caffe/layer.cpp
CXX src/caffe/layer_factory.cpp
CXX src/caffe/layers/absval_layer.cpp
CXX src/caffe/layers/accuracy_layer.cpp
CXX src/caffe/layers/argmax_layer.cpp
CXX src/caffe/layers/base_conv_layer.cpp
CXX src/caffe/layers/base_data_layer.cpp
CXX src/caffe/layers/batch_norm_layer.cpp
CXX src/caffe/layers/batch_reindex_layer.cpp
CXX src/caffe/layers/bias_layer.cpp
CXX src/caffe/layers/bnll_layer.cpp
CXX src/caffe/layers/concat_layer.cpp
CXX src/caffe/layers/contrastive_loss_layer.cpp
CXX src/caffe/layers/conv_layer.cpp
CXX src/caffe/layers/crop_layer.cpp
In file included from src/caffe/layers/crop_layer.cpp:10:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
1 warning generated.
CXX src/caffe/layers/cudnn_conv_layer.cpp
CXX src/caffe/layers/cudnn_lcn_layer.cpp
CXX src/caffe/layers/cudnn_lrn_layer.cpp
CXX src/caffe/layers/cudnn_pooling_layer.cpp
CXX src/caffe/layers/cudnn_relu_layer.cpp
CXX src/caffe/layers/cudnn_sigmoid_layer.cpp
CXX src/caffe/layers/cudnn_softmax_layer.cpp
CXX src/caffe/layers/cudnn_tanh_layer.cpp
CXX src/caffe/layers/data_layer.cpp
CXX src/caffe/layers/deconv_layer.cpp
CXX src/caffe/layers/dropout_layer.cpp
CXX src/caffe/layers/dummy_data_layer.cpp
CXX src/caffe/layers/eltwise_layer.cpp
CXX src/caffe/layers/elu_layer.cpp
CXX src/caffe/layers/embed_layer.cpp
CXX src/caffe/layers/euclidean_loss_layer.cpp
CXX src/caffe/layers/exp_layer.cpp
CXX src/caffe/layers/filter_layer.cpp
CXX src/caffe/layers/flatten_layer.cpp
CXX src/caffe/layers/hdf5_data_layer.cpp
CXX src/caffe/layers/hdf5_output_layer.cpp
CXX src/caffe/layers/hinge_loss_layer.cpp
CXX src/caffe/layers/im2col_layer.cpp
CXX src/caffe/layers/image_data_layer.cpp
CXX src/caffe/layers/infogain_loss_layer.cpp
CXX src/caffe/layers/inner_product_layer.cpp
CXX src/caffe/layers/input_layer.cpp
CXX src/caffe/layers/log_layer.cpp
CXX src/caffe/layers/loss_layer.cpp
CXX src/caffe/layers/lrn_layer.cpp
CXX src/caffe/layers/lstm_layer.cpp
In file included from src/caffe/layers/lstm_layer.cpp:8:
In file included from ./include/caffe/layers/lstm_layer.hpp:11:
In file included from ./include/caffe/layers/recurrent_layer.hpp:11:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
1 warning generated.
CXX src/caffe/layers/lstm_unit_layer.cpp
In file included from src/caffe/layers/lstm_unit_layer.cpp:6:
In file included from ./include/caffe/layers/lstm_layer.hpp:11:
In file included from ./include/caffe/layers/recurrent_layer.hpp:11:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
1 warning generated.
CXX src/caffe/layers/memory_data_layer.cpp
CXX src/caffe/layers/multinomial_logistic_loss_layer.cpp
CXX src/caffe/layers/mvn_layer.cpp
CXX src/caffe/layers/neuron_layer.cpp
CXX src/caffe/layers/parameter_layer.cpp
CXX src/caffe/layers/pooling_layer.cpp
CXX src/caffe/layers/power_layer.cpp
CXX src/caffe/layers/prelu_layer.cpp
CXX src/caffe/layers/recurrent_layer.cpp
In file included from src/caffe/layers/recurrent_layer.cpp:8:
In file included from ./include/caffe/layers/recurrent_layer.hpp:11:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
1 warning generated.
CXX src/caffe/layers/reduction_layer.cpp
CXX src/caffe/layers/relu_layer.cpp
CXX src/caffe/layers/reshape_layer.cpp
CXX src/caffe/layers/rnn_layer.cpp
In file included from src/caffe/layers/rnn_layer.cpp:8:
In file included from ./include/caffe/layers/rnn_layer.hpp:11:
In file included from ./include/caffe/layers/recurrent_layer.hpp:11:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
1 warning generated.
CXX src/caffe/layers/scale_layer.cpp
CXX src/caffe/layers/sigmoid_cross_entropy_loss_layer.cpp
CXX src/caffe/layers/sigmoid_layer.cpp
CXX src/caffe/layers/silence_layer.cpp
CXX src/caffe/layers/slice_layer.cpp
CXX src/caffe/layers/softmax_layer.cpp
CXX src/caffe/layers/softmax_loss_layer.cpp
CXX src/caffe/layers/split_layer.cpp
CXX src/caffe/layers/spp_layer.cpp
CXX src/caffe/layers/tanh_layer.cpp
CXX src/caffe/layers/threshold_layer.cpp
CXX src/caffe/layers/tile_layer.cpp
CXX src/caffe/layers/window_data_layer.cpp
CXX src/caffe/net.cpp
In file included from src/caffe/net.cpp:12:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
src/caffe/net.cpp:580:3: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
  LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: Forward(bottom, loss) ""
  ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
2 warnings generated.
CXX src/caffe/parallel.cpp
In file included from src/caffe/parallel.cpp:12:
In file included from ./include/caffe/caffe.hpp:12:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
1 warning generated.
CXX src/caffe/solver.cpp
In file included from src/caffe/solver.cpp:6:
In file included from ./include/caffe/solver.hpp:7:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
1 warning generated.
CXX src/caffe/solvers/adadelta_solver.cpp
In file included from src/caffe/solvers/adadelta_solver.cpp:3:
In file included from ./include/caffe/sgd_solvers.hpp:7:
In file included from ./include/caffe/solver.hpp:7:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
1 warning generated.
CXX src/caffe/solvers/adagrad_solver.cpp
In file included from src/caffe/solvers/adagrad_solver.cpp:3:
In file included from ./include/caffe/sgd_solvers.hpp:7:
In file included from ./include/caffe/solver.hpp:7:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
1 warning generated.
CXX src/caffe/solvers/adam_solver.cpp
In file included from src/caffe/solvers/adam_solver.cpp:3:
In file included from ./include/caffe/sgd_solvers.hpp:7:
In file included from ./include/caffe/solver.hpp:7:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
1 warning generated.
CXX src/caffe/solvers/nesterov_solver.cpp
In file included from src/caffe/solvers/nesterov_solver.cpp:3:
In file included from ./include/caffe/sgd_solvers.hpp:7:
In file included from ./include/caffe/solver.hpp:7:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
1 warning generated.
CXX src/caffe/solvers/rmsprop_solver.cpp
In file included from src/caffe/solvers/rmsprop_solver.cpp:3:
In file included from ./include/caffe/sgd_solvers.hpp:7:
In file included from ./include/caffe/solver.hpp:7:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
1 warning generated.
CXX src/caffe/solvers/sgd_solver.cpp
In file included from src/caffe/solvers/sgd_solver.cpp:4:
In file included from ./include/caffe/sgd_solvers.hpp:7:
In file included from ./include/caffe/solver.hpp:7:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^

1 warning generated.
CXX src/caffe/syncedmem.cpp
CXX src/caffe/util/benchmark.cpp
CXX src/caffe/util/blocking_queue.cpp
In file included from src/caffe/util/blocking_queue.cpp:6:
In file included from ./include/caffe/parallel.hpp:13:
In file included from ./include/caffe/solver.hpp:7:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
src/caffe/util/blocking_queue.cpp:50:7: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
      LOG_EVERY_N(INFO, 1000)<< log_on_wait;
      ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
2 warnings generated.
CXX src/caffe/util/cudnn.cpp
CXX src/caffe/util/db.cpp
CXX src/caffe/util/db_leveldb.cpp
CXX src/caffe/util/db_lmdb.cpp
CXX src/caffe/util/hdf5.cpp
CXX src/caffe/util/im2col.cpp
CXX src/caffe/util/insert_splits.cpp
CXX src/caffe/util/io.cpp
CXX src/caffe/util/math_functions.cpp
CXX src/caffe/util/signal_handler.cpp
In file included from src/caffe/util/signal_handler.cpp:7:
In file included from ./include/caffe/util/signal_handler.h:5:
In file included from ./include/caffe/solver.hpp:7:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
1 warning generated.
CXX src/caffe/util/upgrade_proto.cpp
AR -o .build_release/lib/libcaffe.a
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn_conv_layer.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn_lcn_layer.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn_lrn_layer.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn_pooling_layer.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn_relu_layer.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn_sigmoid_layer.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn_softmax_layer.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn_tanh_layer.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: .build_release/lib/libcaffe.a(cudnn.o) has no symbols
LD -o .build_release/lib/libcaffe.so.1.0.0-rc3
clang: warning: argument unused during compilation: '-pthread'
CXX tools/caffe.cpp
In file included from tools/caffe.cpp:15:
In file included from ./include/caffe/caffe.hpp:12:
./include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
1 warning generated.
CXX/LD -o .build_release/tools/caffe.bin
clang: warning: argument unused during compilation: '-pthread'
Undefined symbols for architecture x86_64:
  ""caffe::Net<float>::Forward(float_)"", referenced from:
      test() in caffe.o
      time() in caffe.o
  ""caffe::Net<float>::Net(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, caffe::Phase, int, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const_, caffe::Net<float> const_)"", referenced from:
      test() in caffe.o
      time() in caffe.o
  ""caffe::P2PSync<float>::Run(std::__1::vector<int, std::__1::allocator<int> > const&)"", referenced from:
      train() in caffe.o
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: *_\* [.build_release/tools/caffe.bin] Error 1

_Even when i tried using cmake i get the following error:_

In file included from /Volumes/Data/caffe/src/caffe/util/signal_handler.cpp:7:
In file included from /Volumes/Data/caffe/include/caffe/util/signal_handler.h:5:
In file included from /Volumes/Data/caffe/include/caffe/solver.hpp:7:
/Volumes/Data/caffe/include/caffe/net.hpp:42:5: warning: unused typedef 'INVALID_REQUESTED_LOG_SEVERITY' [-Wunused-local-typedef]
    LOG_EVERY_N(WARNING, 1000) << ""DEPRECATED: ForwardPrefilled() ""
    ^
/usr/local/include/glog/logging.h:917:30: note: expanded from macro 'LOG_EVERY_N'
                             INVALID_REQUESTED_LOG_SEVERITY);           \
                             ^
/usr/local/include/glog/logging.h:912:73: note: expanded from macro 'GOOGLE_GLOG_COMPILE_ASSERT'
  typedef google::glog_internal_namespace_::CompileAssert<(bool(expr))> msg[bool(expr) ? 1 : -1]
                                                                        ^
1 warning generated.
[ 82%] Building CXX object src/caffe/CMakeFiles/caffe.dir/util/upgrade_proto.cpp.o
[ 82%] Linking CXX shared library ../../lib/libcaffe.dylib
ld: framework not found vecLib
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[2]: **\* [lib/libcaffe.1.0.0-rc3.dylib] Error 1
make[1]: **\* [src/caffe/CMakeFiles/caffe.dir/all] Error 2
make: **\* [all] Error 2

At this point I am not sure how to proceed or debug the issue from here. Thanks for any help.

Regards
Praveen
",,"['Hi, \nI am getting the same error. Where you able to solve it?\n', 'I got this error while trying to compile release candidate 3. I ended up cloning the latest master branch (as of Aug 11th) and was able to compile that successfully.\n', ""Please ask installation questions on the mailing list. If you're having trouble, you might want to try the Caffe [Dockerfile](https://github.com/BVLC/caffe/tree/master/docker) to take care of installation for you.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n""]",[],[],0,0
142,caffe,151,closed,Assemble all docs and examples from gh-pages and wiki into docs/ directory,"It's frustrating that to write docs, one needs to switch into gh-pages branch (or have a separate filesystem folder with that branch checked out). We propose to have all docs in Markdown format in new docs/ directory, with a script to push the contents to gh-pages.

After this is done, we will disable the github wiki.
",,"[""For contributing, just take what's in the README for now then I'll follow up on #101 with more details.\n"", 'Done.\n']",[],[],0,0
143,caffe,4164,closed,cafe_intsall.caffe 36 error,"I am trying caffe on Centos Server. 

I wrote 
# glog

wget https://google-glog.googlecode.com/files/glog-0.3.3.tar.gz
tar zxvf glog-0.3.3.tar.gz
cd glog-0.3.3
./configure
make && make install
# gflags

wget https://github.com/schuhschuh/gflags/archive/master.zip
unzip master.zip
cd gflags-master
mkdir build && cd build
export CXXFLAGS=""-fPIC"" && cmake .. && make VERBOSE=1
make && make install
.
I received cafe_intsall.caffe 36 error.

What is problem. Could you please say a solution
",,"['Please ask installation questions on the mailing list.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
144,caffe,2487,closed,Simple C++ prediction example,"Hi,

I want to contribute a simple C++ prediction example to the codebase, is this something you are interested in adding? If yes, what kind of features would you like to see in this sample app?

From my point of view, I think the sample application should take as input the following files: deploy file, trained weights, labels, mean file and input image to classify.
It would be nice to be able to use file  as-is, without requiring to add an extra layer for preprocessing (like cropping, resizing, mean subtraction), so I think the processing should be done from the sample app after probing the network for the dimensions of its input layer. This way, the app should hopefully work with caffenet and MNIST by just changing the input files (and those files are either already present in the repo, or are downloadable through a provided script).

What do you think? Any other feature request? I'm already excluding features like image batching or oversampling from the list, for the sake of readability.
",,"['Feel free to add it [here](https://github.com/boaz001/caffe-cpp-examples) if you like.\n', 'I think such code should be part of the main project since the C++ API is the ""original"" API. I just sent a PR, comments welcomed!\n']",[],['models/bvlc_reference_caffenet/deploy.prototxt'],0,0
145,caffe,4508,closed,the error is CXX/LD -o .build_release/test/test_all.testbin src/caffe/test/test_caffe_main.cpp .build_release/lib/libcaffe.so: undefined reference to `fLS::FLAGS_step' collect2: error: ld returned 1 exit statuswhat should i do,,,"[""Please ask installation questions on the mailing list. If you're having trouble, you might want to try the Caffe [Dockerfile](https://github.com/BVLC/caffe/tree/master/docker) to take care of installation for you.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n""]",[],[],0,0
146,caffe,1967,closed,issue in pycaffe,"Hi, all,

I had followed the install steps in page, the caffe library can run successfully, but fpycaffeor  , I came across the following issue. Did someone come across this issue before and how to fix it?  THX!
My system is  ubuntu 12.04 64bit, I had installed anacorda, and set $PYTHONPATH as:
export PYTHONPATH=""$CAFFE_ROOT/python:$PYTHONPATH""
# 

root@milton-Desktop:~# python ~/Downloads/caffe-public-bvlc_googlenet/python/classify.py
Traceback (most recent call last):
  File ""/root/Downloads/caffe-public-bvlc_googlenet/python/classify.py"", line 14, in <module>
    import caffe
  File ""/root/Downloads/caffe-public-bvlc_googlenet/python/caffe/**init**.py"", line 1, in <module>
    from .pycaffe import Net, SGDSolver
  File ""/root/Downloads/caffe-public-bvlc_googlenet/python/caffe/pycaffe.py"", line 10, in <module>
    from ._caffe import Net, SGDSolver
ImportError: /root/anaconda/bin/../lib/libm.so.6: version `GLIBC_2.15' not found (required by /usr/lib/libopencv_core.so.2.3)
root@milton-Desktop:~# 
# 
",,"[""Hi,\ni used to have the same issue on Debian and the solution was to add an additionnal library link : ldl\nIn Makefile.config, add\n'''\nLDFLAGS := $(LDFLAGS) -ldl\n'''\nhope it helps\n"", 'Please ask usage questions on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) list. Thanks!\n']",[],[],0,0
147,caffe,1294,closed,Testcase failed during make runtest,"Hi, I am trying execute ""make runtest"" and met some problems.
The caffe is successfully compiled on Ubuntu12.04 with CPU only.
When executing the testcases, it shows like this:

src/caffe/test/test_math_functions.cpp:109: Failure
Value of: x[i] < 0 ? 1 : 0
  Actual: 1
Expected: signbits[i]
Which is: 512
..................
[  PASSED  ] 450 tests.
[  FAILED  ] 7 tests, listed below:
[  FAILED  ] MathFunctionsTest/0.TestSgnbitCPU, where TypeParam = float
[  FAILED  ] MathFunctionsTest/1.TestSgnbitCPU, where TypeParam = double
[  FAILED  ] MathFunctionsTest/1.TestHammingDistanceCPU, where TypeParam = double
[  FAILED  ] EltwiseLayerTest/0.TestProd, where TypeParam = caffe::FloatCPU
[  FAILED  ] EltwiseLayerTest/0.TestSum, where TypeParam = caffe::FloatCPU
[  FAILED  ] EltwiseLayerTest/1.TestProd, where TypeParam = caffe::DoubleCPU
[  FAILED  ] EltwiseLayerTest/1.TestSum, where TypeParam = caffe::DoubleCPU

I am a new learner of linux and caffe. Great thanks for any help.
",,"['I have the similar problem:\n[  FAILED  ] 2 tests, listed below:\n[  FAILED  ] PoolingLayerTest/1.TestGPUGradientMax, where TypeParam = double\n[  FAILED  ] MathFunctionsTest/1.TestFabsGPU, where TypeParam = double\n\nalso seeking help now~~ \n', 'Same issue as for @moegitree. Did you find any causes?\n', 'The signbits bug should have been fixed by #1264 . Are you using the master branch or the dev branch? If you still encounter bugs after running the dev head, kindly let us know. Please attach the full make runtest result so we can see what went wrong.\n', ""The full runtest log is here: https://gist.github.com/anonymous/1783e785315e63f380b4\nAfter switching to dev branch there are only 5 test failures. Those with signbits are OK now. \n\nIt seems there are some precision issues:\n\n```\n[ RUN      ] EltwiseLayerTest/0.TestSum\nsrc/caffe/test/test_eltwise_layer.cpp:102: Failure\nValue of: in_data_a[i] + in_data_b[i] + in_data_c[i]\n  Actual: 1.47906\nExpected: data[i]\nWhich is: 1.47907\n```\n\n```\n[ RUN      ] EltwiseLayerTest/0.TestProd\nsrc/caffe/test/test_eltwise_layer.cpp:83: Failure\nValue of: in_data_a[i] * in_data_b[i] * in_data_c[i]\n  Actual: 0.00427637\nExpected: data[i]\nWhich is: 0.00427638\n```\n\nThough in case of the following failures, I even can't find what's wrong, because expected and actual data seems to be equal. Or may be it is printed with some rounding.\n\n```\n[  FAILED  ] EltwiseLayerTest/1.TestProd, where TypeParam = caffe::DoubleCPU\n[  FAILED  ] EltwiseLayerTest/1.TestSum, where TypeParam = caffe::DoubleCPU\n```\n\nAlso something is wrong with `caffe_cpu_hamming_distance`:\n\n```\n[ RUN      ] MathFunctionsTest/1.TestHammingDistanceCPU\nsrc/caffe/test/test_math_functions.cpp:79: Failure\nValue of: caffe_cpu_hamming_distance<TypeParam>(n, x, y)\n  Actual: 717829\nExpected: this->ReferenceHammingDistance(n, x, y)\nWhich is: 1422821\n```\n\nI compiled caffe with `CPU_ONLY := 1` and `BLAS := open`\n"", ""Hi,\n\nI just want to update on the failed test, I got these 2 failures when run 'make runtest' :\n\n[----------] 8 tests from CuDNNNeuronLayerTest/1, where TypeParam = double\n[ RUN      ] CuDNNNeuronLayerTest/1.TestSigmoidGradientCuDNN\n[       OK ] CuDNNNeuronLayerTest/1.TestSigmoidGradientCuDNN (16 ms)\n[ RUN      ] CuDNNNeuronLayerTest/1.TestReLUGradientWithNegativeSlopeCuDNN\n[       OK ] CuDNNNeuronLayerTest/1.TestReLUGradientWithNegativeSlopeCuDNN (20 ms)\n[ RUN      ] CuDNNNeuronLayerTest/1.TestTanHCuDNN\n[       OK ] CuDNNNeuronLayerTest/1.TestTanHCuDNN (1 ms)\n[ RUN      ] CuDNNNeuronLayerTest/1.TestReLUCuDNN\n[       OK ] CuDNNNeuronLayerTest/1.TestReLUCuDNN (0 ms)\n[ RUN      ] CuDNNNeuronLayerTest/1.TestReLUGradientCuDNN\n[       OK ] CuDNNNeuronLayerTest/1.TestReLUGradientCuDNN (16 ms)\n[ RUN      ] CuDNNNeuronLayerTest/1.TestTanHGradientCuDNN\n[       OK ] CuDNNNeuronLayerTest/1.TestTanHGradientCuDNN (22 ms)\n[ RUN      ] CuDNNNeuronLayerTest/1.TestReLUWithNegativeSlopeCuDNN\nsrc/caffe/test/test_neuron_layer.cpp:455: Failure\nExpected: (top_data[i]) >= (0.), actual: -0.0122354 vs 0\nsrc/caffe/test/test_neuron_layer.cpp:456: Failure\nValue of: top_data[i] == 0 || top_data[i] == bottom_data[i]\n  Actual: false\nExpected: true\n......\n\n[----------] 8 tests from CuDNNNeuronLayerTest/0, where TypeParam = float\n[ RUN      ] CuDNNNeuronLayerTest/0.TestReLUCuDNN\n[       OK ] CuDNNNeuronLayerTest/0.TestReLUCuDNN (0 ms)\n[ RUN      ] CuDNNNeuronLayerTest/0.TestReLUGradientWithNegativeSlopeCuDNN\n[       OK ] CuDNNNeuronLayerTest/0.TestReLUGradientWithNegativeSlopeCuDNN (15 ms)\n[ RUN      ] CuDNNNeuronLayerTest/0.TestReLUWithNegativeSlopeCuDNN\nsrc/caffe/test/test_neuron_layer.cpp:455: Failure\nExpected: (top_data[i]) >= (0.), actual: -0.0122354 vs 0\nsrc/caffe/test/test_neuron_layer.cpp:456: Failure\nValue of: top_data[i] == 0 || top_data[i] == bottom_data[i]\n  Actual: false\nExpected: true\n....\n\nThe full log of these 2 errors is at http://pastebin.com/QD679cGj.\n\nMy system is Ubuntu 14.04, CUDA 6.5, cuDNN 6.5, opencv 2.4.9 and caffe dev branch\n"", 'OK, whoever wrote that TestReLUWithNegativeSlopeCuDNN function should be more careful... The test case was clearly wrong :(\n\nI am going to fix it with a quick PR.\n', 'Fixed.\n', 'exactly the same issue as observed in @stas-sl . the two sgnbit error disappear when switch to dev branch. ,@stas-sl, did you find he reason for the issue? BTW, I used Ubuntu 12, 32 bit. Is this cause the problem? \n\n[----------] Global test environment tear-down\n[==========] 457 tests from 98 test cases ran. (67848 ms total)\n[  PASSED  ] 450 tests.\n[  FAILED  ] 7 tests, listed below:\n[  FAILED  ] EltwiseLayerTest/0.TestProd, where TypeParam = caffe::FloatCPU\n[  FAILED  ] EltwiseLayerTest/0.TestSum, where TypeParam = caffe::FloatCPU\n[  FAILED  ] EltwiseLayerTest/1.TestProd, where TypeParam = caffe::DoubleCPU\n[  FAILED  ] EltwiseLayerTest/1.TestSum, where TypeParam = caffe::DoubleCPU\n[  FAILED  ] MathFunctionsTest/0.TestSgnbitCPU, where TypeParam = float\n[  FAILED  ] MathFunctionsTest/1.TestHammingDistanceCPU, where TypeParam = double\n[  FAILED  ] MathFunctionsTest/1.TestSgnbitCPU, where TypeParam = double\n', 'Full log please? I think most likely it is some numerical precision problems.\n', ""@cmis91, yes, I also have 32-bit Ubuntu. I didn't find the reason, but I didn't have any convergence issues because of that.\n"", 'hi, when i run make runtest on my computer (ubuntu12.04) I get this long\n\n[ RUN      ] MemoryDataLayerTest/0.TestSetBatchSize\nOpenCV Error: Assertion failed (k == STD_VECTOR_MAT) in getMat, file /build/buildd/opencv-2.3.1/modules/core/src/matrix.cpp, line 918\nunknown file: Failure\nC++ exception with description ""/build/buildd/opencv-2.3.1/modules/core/src/matrix.cpp:918: error: (-215) k == STD_VECTOR_MAT in function getMat\n"" thrown in the test body.\n[  FAILED  ] MemoryDataLayerTest/0.TestSetBatchSize, where TypeParam = caffe::FloatCPU (1 ms)\n[ RUN      ] MemoryDataLayerTest/0.AddMatVectorDefaultTransform\nOpenCV Error: Assertion failed (k == STD_VECTOR_MAT) in getMat, file /build/buildd/opencv-2.3.1/modules/core/src/matrix.cpp, line 918\nunknown file: Failure\nC++ exception with description ""/build/buildd/opencv-2.3.1/modules/core/src/matrix.cpp:918: error: (-215) k == STD_VECTOR_MAT in function getMat\n"" thrown in the test body.\n[  FAILED  ] MemoryDataLayerTest/0.AddMatVectorDefaultTransform, where TypeParam = caffe::FloatCPU (1 ms)\n[----------] 5 tests from MemoryDataLayerTest/0 (21 ms total)\n\n[----------] 3 tests from ThresholdLayerTest/1, where TypeParam = caffe::DoubleCPU\n', ""Hi, I have the same problem that stas-si, when I do make runtest I've got this http://pastebin.com/KvubSdsP\nand for eltwise_layer it's a little bit weird http://pastebin.com/kEjHmZ3p the values are exactly the same...\nI'm using a 32 bits debian testing\nAnyone can help me ? Thx !!\n"", 'I met some problems when trying execute ""make runtest"" . The caffe is compiled on Ubuntu12.04 with CPU only. Detail just listed below\n\nOpenCV Error: Assertion failed (k == STD_VECTOR_MAT) in getMat, file /build/buildd/opencv-2.3.1/modules/core/src/matrix.cpp, line 918\nunknown file: Failure\nC++ exception with description ""/build/buildd/opencv-2.3.1/modules/core/src/matrix.cpp:918: error: (-215) k == STD_VECTOR_MAT in function getMat\n\n[  FAILED  ] 12 tests, listed below:\n[  FAILED  ] IOTest.TestDecodeDatumToCVMat\n[  FAILED  ] IOTest.TestDecodeDatumToCVMatContent\n[  FAILED  ] IOTest.TestDecodeDatumToCVMatContentNative\n[  FAILED  ] IOTest.TestDecodeDatum\n[  FAILED  ] IOTest.TestDecodeDatumToCVMatNativeGray\n[  FAILED  ] IOTest.TestDecodeDatumToCVMatNative\n[  FAILED  ] IOTest.TestDecodeDatumNative\n[  FAILED  ] IOTest.TestDecodeDatumNativeGray\n[  FAILED  ] MemoryDataLayerTest/0.AddMatVectorDefaultTransform, where TypeParam = caffe::FloatCPU\n[  FAILED  ] MemoryDataLayerTest/0.TestSetBatchSize, where TypeParam = caffe::FloatCPU\n[  FAILED  ] MemoryDataLayerTest/1.AddMatVectorDefaultTransform, where TypeParam = caffe::DoubleCPU\n[  FAILED  ] MemoryDataLayerTest/1.TestSetBatchSize, where TypeParam = caffe::DoubleCPU\n12 FAILED TESTS\nmake: **\\* [runtest] Error 1\nMany thanks for any help.\n', '@shuimulinxi\nI met some problems when trying execute ""make runtest"" . The caffe is compiled on Ubuntu12.04 with CPU only.\n\nOpenCV Error: Assertion failed (k == STD_VECTOR_MAT) in getMat, file /build/buildd/opencv-2.3.1/modules/core/src/matrix.cpp, line 918\nunknown file: Failure\nC++ exception with description ""/build/buildd/opencv-2.3.1/modules/core/src/matrix.cpp:918: error: (-215) k == STD_VECTOR_MAT in function getMat\n\nI chage the Makefile.config\nPYTHON_LIB := /usr/lib               ""replace with""              PYTHON_LIB := usr/local/lib\n\nSuccesful!!!\n\nnotes: when you compile once again, please execute ""make clean"" first\n', '[----------] 5 tests from ImageDataLayerTest/1, where TypeParam = caffe::CPUDevice<double>\n[ RUN      ] ImageDataLayerTest/1.TestReshape\n[       OK ] ImageDataLayerTest/1.TestReshape (46 ms)\n[ RUN      ] ImageDataLayerTest/1.TestShuffle\n[       OK ] ImageDataLayerTest/1.TestShuffle (106 ms)\n[ RUN      ] ImageDataLayerTest/1.TestRead\n[       OK ] ImageDataLayerTest/1.TestRead (103 ms)\n[ RUN      ] ImageDataLayerTest/1.TestResize\n[       OK ] ImageDataLayerTest/1.TestResize (122 ms)\n[ RUN      ] ImageDataLayerTest/1.TestSpace\n[       OK ] ImageDataLayerTest/1.TestSpace (63 ms)\n[----------] 5 tests from ImageDataLayerTest/1 (440 ms total)\n\n[----------] Global test environment tear-down\n[==========] 1096 tests from 150 test cases ran. (68513 ms total)\n[  PASSED  ] 1095 tests.\n[  FAILED  ] 1 test, listed below:\n[  FAILED  ] NeuronLayerTest/0.TestPReLUForward, where TypeParam = caffe::CPUDevice<float>\n\n 1 FAILED TEST\nmake[3]: **\\* [src/caffe/test/CMakeFiles/runtest] Error 1\nmake[2]: **\\* [src/caffe/test/CMakeFiles/runtest.dir/all] Error 2\nmake[1]: **\\* [src/caffe/test/CMakeFiles/runtest.dir/rule] Error 2\nmake: **\\* [runtest] Error 2\n\nwhy this error?\n']",[],[],0,0
148,caffe,3522,closed,"matlab interface use my train_caffemodel for image classification!""Check failed: target_blobs[j]->num() == source_layer.blobs(j).num() (96 vs. 0)""","first I use the imagenet framework to train my dataset, the data have 11 classes, so I change the output_num and the corresponding path , the result of training-processing is done with none error. 
Then I use the  caffenet_train_iter_6000.caffemodelmean.binaryprotodeploy.prototxt to initial the 
caffe.There is a error come out after ""Network initialization done. Memory required data:62433600. ""
The error is :
""Check failed: target_blobs[j]->num() == source_layer.blobs(j).num() (96 vs. 0)""

If I use the ""bvlc_reference_caffenet.caffemodel"" and change the output_num , the classify is success!

How can I do with the error?
",,"['I retrain my model , get a new caffemodel, then everything is well!\n', 'From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
149,caffe,1513,closed,Allow no label setting for HDF5DataLayer,"As I try to define a autoencoder by using my custom data loaded in to HDF5, I see that we must define top: ""label"" in any way so it forces you to define a dummy set of label values for instances. Although, it does not cause any problem in optimization, it causes very disturbing set of console outputs as 

Train net output #1: label=0
Train net output #2: label=0
Train net output #3: label=0
Train net output #4: label=0
... (goes to number of your data dimension)

I solved this by only inserting this to data_layers.hpp line 184

virtual inline bool AutoTopBlobs() const { return true; }

I don't know whether it is acceptable solution but in practice it is pretty fine. If it is not a convenient solution please make HDF5DataLayer able to accept no label configuration.
",,"['Use Silence layer.\n', 'The current dev version of HDF5DataLayer uses the HDF5 dataset names, any of which you may omit (including ""label"").\n']",[],[],0,0
150,caffe,2549,closed,Preset Convergence Criteria,"In the training examples provided with Caffe (imagenet or cifar), is there a way to stop the training based on some preset convergence criteria like value of the loss function or accuracy on validation data ? How and where to specify these threshold in the prototxt files ?
",,['This tracker is for issues and bugs with Caffe. Please ask usage questions on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) list. Thanks!\n'],[],[],0,0
151,caffe,3269,closed,how does the solver execute iteration?,"I have a question:
Assume my dataset has 10000 images and I set the value of 'batch_size' as 100. Then after 100 iterations, all images in the dataset has been used to update net weights. But the value of 'max_iter' is set as a bigger number, e.g. max_iter = 200. I want to know how does the solver choose images to update weights during iteration from 101 to 200.
Is anyone knowing about this?
thx~~
",,"['1. Before training, caffe will skip a numer of images randomly of which the max value  can be set by ""data_param{ rand_skip = ***}"" in your prototxt of net defination, using a pointer, namely, ""shared_ptrdb::Cursor Datalayer<Dtype>::cursor"", pointed to your db(leveldb or lmdb) files that is converted from your 10000 images. (For this, you can read ""DataLayer<Dtype>::DataLayerSetUp()"" method in src/data_layer.cpp file.) And that pointer records the positon that the datalayer reads from your image sequence in your db files. \n2. During training, the pointer keeps using ""cursor_->Next()"" to read the following images and it will use ""cursor_->valid()"" to judge whether it has reached the last image of you db files. If it is, ""cursor_->SeekToFirst()"" will make the pointer back to the first image of your db files after it reads the last one. (For this, you can read ""DataLayer<Dtype>::InternalThreadEntry()"" in the same .cpp file.).\n3. Circulates as step 2.\n   So, images of the 101st to 200th iterations  should be exactly the same with those of the 1st to 100th iterations if you set ""data_param{ rand_skip = 0}"".\n', 'thx for ur explaining! it helps me a lot. @DaleSong89\n', 'Closing as a request for help. Please keep these conversations to caffe-users.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
152,caffe,4181,closed,failed to start training from snapshot,"i run a training for about 40k iterations.
than i stopped it and tried to train again (with lower lr) from snapshot of iteration 17k.

command :


i used the same solver.prototxt i used in the first training phase, except for changing base_lr from 0.001 to 0.0001 (lr_policy: ""fixed"").

I get the following error :


my suspect is that caffe can't find the "".solverstate"" file, although it's there right next to the "".caffemodel"" snapshot file.
",,"['See our command line interface examples: http://caffe.berkeleyvision.org/tutorial/interfaces.html . The `--snapshot` arg takes the `.solverstate`.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n', ""Oops, my mistake.\nI will just use this opportunity and ask to add input arguments\ndocumentation when typing 'caffe train'.\n\nOn Thu, May 19, 2016, 19:31 Evan Shelhamer notifications@github.com wrote:\n\n> See our command line interface examples:\n> http://caffe.berkeleyvision.org/tutorial/interfaces.html . The --snapshot\n> arg takes the .solverstate.\n> \n> From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n> \n> _Please do not post usage, installation, or modeling questions, or other\n> requests for help to Issues._\n> Use the caffe-users list\n> https://groups.google.com/forum/#!forum/caffe-users instead. This helps\n> developers maintain a clear, uncluttered, and efficient view of the state\n> of Caffe.\n> \n> \n> You are receiving this because you authored the thread.\n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/4181#issuecomment-220379249\n""]",[],"['$CAFFE_ROOT/build/tools/caffe train --solver ../../nets/net1/solver.prototxt --snapshot ../../nets-weights/net1/net__iter_17000.caffemodel', 'I0519 19:16:09.539479 23277 caffe.cpp:209] Resuming from ../../nets-weights/net1-data02_160x064/net__iter_17000.caffemodel\nF0519 19:16:09.551967 23277 sgd_solver.cpp:316] Check failed: state.history_size() == history_.size() (0 vs. 14) Incorrect length of history blobs.\n']",0,0
153,caffe,896,closed,Unexpected results while running classify.py,"I am trying to use classify.py to classify a test image. However, irrespective of the image or model used, the predictions output always has max. prob for class index 111. The probability values keep changing but out of 1000 classes, the prediction always seem to contain max. prob for array index 111. I am not sure why this is happening. Has anyone come across an issue like this before?
",,"['`classify.py` has several arguments for input preprocessing since different models expect different inputs. For the ImageNet reference model, it requires the raw input to be in the range [0, 255] instead of [0, 1] so you need to set the `--raw_scale=255` argument and call it like so:\n\n```\n./python/classify.py --raw_scale=255 examples/images/cat.jpg  out.npy\n```\n\nNote the other arguments take Caffe reference ImageNet model default values. I just made `raw_scale` take the default of 255.0 in dev at f8b612d.\n']",[],[],0,0
154,caffe,1908,closed,Can I use IMAGE_DATA as input when training GoogleNet?,"Hi all, I just want to train the [googleNet](https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet) and using the image data as input data type (giving the path of the training and validation txt file). I failed to train it because I encountered the following problem: the loss becomes 'nan' from the 80th iteration.



Here is the data layer



Then I turned to Leveldb, everything is OK.  



Did I make any mistakes?
",,"['You could try decreasing the learning rate. A learning rate which is too high can blow up the loss.\n\nHowever, please ask usage questions on [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) -- the issues tracker is primarily for Caffe development discussion. Thanks!\n']","['\nI0219 15:15:29.717862 14350 solver.cpp:161] Learning Rate Policy: step\nI0219 15:15:31.617120 14350 solver.cpp:209] Iteration 0, loss = 11.0746\nI0219 15:15:31.617197 14350 solver.cpp:224]     Train net output #0: loss1/loss1 = 6.89612 (* 0.3 = 2.06884 loss)\nI0219 15:15:31.617211 14350 solver.cpp:224]     Train net output #1: loss2/loss1 = 6.90393 (* 0.3 = 2.07118 loss)\nI0219 15:15:31.617223 14350 solver.cpp:224]     Train net output #2: loss3/loss3 = 6.93463 (* 1 = 6.93463 loss)\nI0219 15:15:31.617297 14350 solver.cpp:445] Iteration 0, lr = 0.01\nI0219 15:17:06.672966 14350 solver.cpp:209] Iteration 40, loss = 1.54674\nI0219 15:17:06.681916 14350 solver.cpp:224]     Train net output #0: loss1/loss1 = 32.7512 (* 0.3 = 9.82536 loss)\nI0219 15:17:06.681941 14350 solver.cpp:224]     Train net output #1: loss2/loss1 = 32.7512 (* 0.3 = 9.82536 loss)\nI0219 15:17:06.681954 14350 solver.cpp:224]     Train net output #2: loss3/loss3 = 32.7512 (* 1 = 32.7512 loss)\nI0219 15:17:06.681965 14350 solver.cpp:445] Iteration 40, lr = 0.01\nI0219 15:18:47.157843 14350 solver.cpp:209] Iteration 80, loss = nan\nI0219 15:18:47.158116 14350 solver.cpp:224]     Train net output #0: loss1/loss1 = nan (* 0.3 = nan loss)\nI0219 15:18:47.158138 14350 solver.cpp:224]     Train net output #1: loss2/loss1 = nan (* 0.3 = nan loss)\nI0219 15:18:47.158149 14350 solver.cpp:224]     Train net output #2: loss3/loss3 = nan (* 1 = nan loss)\nI0219 15:18:47.158161 14350 solver.cpp:445] Iteration 80, lr = 0.01\nI0219 15:20:27.284762 14350 solver.cpp:209] Iteration 120, loss = nan\nI0219 15:20:27.285017 14350 solver.cpp:224]     Train net output #0: loss1/loss1 = nan (* 0.3 = nan loss)\nI0219 15:20:27.285038 14350 solver.cpp:224]     Train net output #1: loss2/loss1 = nan (* 0.3 = nan loss)\nI0219 15:20:27.285051 14350 solver.cpp:224]     Train net output #2: loss3/loss3 = nan (* 1 = nan loss)\n', '\nlayers {\n  top: ""data""\n  top: ""label""\n  name: ""data""\n  type: IMAGE_DATA\n  image_data_param {\n    source: ""/scratch/train_new.txt""\n    batch_size: 32\n    new_height: 256\n    new_width: 256\n  }\n  include {\n    phase: TRAIN\n  }\n  transform_param {\n    mirror: true\n    crop_size: 224\n    mean_file: ""./data/ilsvrc12/imagenet_mean.binaryproto""\n    # mean_value: 104\n    # mean_value: 117\n    # mean_value: 123\n  }\n}\nlayers {\n  top: ""data""\n  top: ""label""\n  name: ""data""\n  type: IMAGE_DATA\n  image_data_param {\n    source: ""/scratch/val_new.txt""\n    batch_size: 50\n    new_height: 256\n    new_width: 256\n  }\n  include {\n    phase: TEST\n  }\n  transform_param {\n    mirror: false\n    crop_size: 224\n    mean_file: ""./data/ilsvrc12/imagenet_mean.binaryproto""\n    # mean_value: 104\n    # mean_value: 117\n    # mean_value: 123\n  }\n}\n', '\nI0219 15:30:47.000522 15901 solver.cpp:209] Iteration 0, loss = 11.0459\nI0219 15:30:47.000571 15901 solver.cpp:224]     Train net output #0: loss1/loss1 = 6.91178 (* 0.3 = 2.07353 loss)\nI0219 15:30:47.000584 15901 solver.cpp:224]     Train net output #1: loss2/loss1 = 6.90464 (* 0.3 = 2.07139 loss)\nI0219 15:30:47.000596 15901 solver.cpp:224]     Train net output #2: loss3/loss3 = 6.90094 (* 1 = 6.90094 loss)\nI0219 15:30:47.000650 15901 solver.cpp:445] Iteration 0, lr = 0.01\nI0219 15:32:00.073784 15901 solver.cpp:209] Iteration 40, loss = 10.2859\nI0219 15:32:00.074018 15901 solver.cpp:224]     Train net output #0: loss1/loss1 = 6.20014 (* 0.3 = 1.86004 loss)\nI0219 15:32:00.074033 15901 solver.cpp:224]     Train net output #1: loss2/loss1 = 6.45299 (* 0.3 = 1.9359 loss)\nI0219 15:32:00.074044 15901 solver.cpp:224]     Train net output #2: loss3/loss3 = 5.91532 (* 1 = 5.91532 loss)\nI0219 15:32:00.074056 15901 solver.cpp:445] Iteration 40, lr = 0.01\nI0219 15:33:13.134585 15901 solver.cpp:209] Iteration 80, loss = 9.53847\nI0219 15:33:13.134856 15901 solver.cpp:224]     Train net output #0: loss1/loss1 = 5.88969 (* 0.3 = 1.76691 loss)\nI0219 15:33:13.134889 15901 solver.cpp:224]     Train net output #1: loss2/loss1 = 5.97238 (* 0.3 = 1.79171 loss)\nI0219 15:33:13.134910 15901 solver.cpp:224]     Train net output #2: loss3/loss3 = 5.75969 (* 1 = 5.75969 loss)\nI0219 15:33:13.134930 15901 solver.cpp:445] Iteration 80, lr = 0.01\nI0219 15:34:26.195854 15901 solver.cpp:209] Iteration 120, loss = 9.31518\nI0219 15:34:26.196168 15901 solver.cpp:224]     Train net output #0: loss1/loss1 = 5.76563 (* 0.3 = 1.72969 loss)\nI0219 15:34:26.196200 15901 solver.cpp:224]     Train net output #1: loss2/loss1 = 5.80312 (* 0.3 = 1.74094 loss)\nI0219 15:34:26.196221 15901 solver.cpp:224]     Train net output #2: loss3/loss3 = 5.72176 (* 1 = 5.72176 loss)\n']",[],0,0
155,caffe,6137,closed,"m,,,,..//","Please use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) for usage, installation, or modeling questions, or other requests for help.
_Do not post such requests to Issues._ Doing so interferes with the development of Caffe.

Please read the [guidelines for contributing](https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md) before submitting this issue.

### Issue summary


### Steps to reproduce

If you are having difficulty building Caffe or training a model, please ask the caffe-users mailing list. If you are reporting a build error that seems to be due to a bug in Caffe, please attach your build configuration (either Makefile.config or CMakeCache.txt) and the output of the make (or cmake) command.

### Your system configuration
Operating system:
Compiler:
CUDA version (if applicable):
CUDNN version (if applicable):
BLAS:
Python or MATLAB version (for pycaffe and matcaffe respectively):
",,[],[],[],0,0
156,caffe,3509,closed,How to set learning rate in a big net for fine-tuning?,"I have a big net with many layers. I add a new full-connection layer in the net and want to do a fine-tuning. However, it's so difficult to set lr_mult=0 in every layer except the new one, since there are many layers in the net. If there is a good way to solve these problem?

Thanks.
",,"[""Try [caffe-users mailing list](https://groups.google.com/forum/#!forum/caffe-users). Close this issue as this isn't the right forum for it.\n"", 'From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
157,caffe,3092,closed,Caffe Makefile Command line tools version 7,"On MacOS 10.10.3 

I had to change 6 for 7 in : 



since pkgutil --pkg-info=com.apple.pkg.CLTools_Executables was giving : 

package-id: com.apple.pkg.CLTools_Executables
version: 7.0.0.0.1.1441394355
volume: /
location: /
install-time: 1442705061
groups: com.apple.FindSystemFiles.pkg-group com.apple.DevToolsBoth.pkg-group com.apple.DevToolsNonRelocatableShared.pkg-group 
",build compatibility,['Thanks for reporting -- see #3093.\n'],"[""\n           #10.10 has accelerate while 10.9 has veclib\n            XCODE_CLT_VER := $(shell pkgutil --pkg-info=com.apple.pkg.CLTools_Executables | grep -o 'version: 7')\n            ifneq (,$(findstring version: 7,$(XCODE_CLT_VER)))\n                    BLAS_INCLUDE ?= /System/Library/Frameworks/Accelerate.framework/Versions/Current/Frameworks/vecLib.framework/Headers/\n                    LDFLAGS += -framework Accelerate\n            else\n                    BLAS_INCLUDE ?= /System/Library/Frameworks/vecLib.framework/Versions/Current/Headers/\n                    LDFLAGS += -framework vecLib\n            endif\n""]",[],0,0
158,caffe,6368,closed,ModuleNotFoundError: No module named '_caffe' ,"### I use anaconda3 to install caffe by comand: conda install caffe in virtual env named : myenv with python 3.6.5
When i try  import caffe  in pytnon interpreter i have error: 

>  import caffe
> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
>   File ""/opt/DL/caffe-ibm/python/caffe/__init__.py"", line 1, in <module>
>     from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropS olver, AdaDeltaSolver, AdamSolver, NCCL, Timer
>   File ""/opt/DL/caffe-ibm/python/caffe/pycaffe.py"", line 13, in <module>
>     from _caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
> ModuleNotFoundError: No module named '_caffe
> 

my ~/.bashrc file looks like :
#.bashrc
#Source global definitions
rt PATH=""/home/prztszeliga/anaconda3/bin:$PATH""
if [ -f /etc/bashrc ]; then
        . /etc/bashrc
fi

#Uncomment the following line if you don't like systemctl's auto-paging feature:
#export SYSTEMD_PAGER=
#User specific aliases and functions
#added by Anaconda3 installer
export PATH=""/home/prztszeliga/anaconda3/bin:$PATH""
export CAFFE_ROOT=""/home/prztszeliga/anaconda3/envs/myenv/lib/python3.6/site-packages/caffe""
export PYTHONPATH=""anaconda3/envs/myenv/lib/python3.6""",,"['Please post usage, installation, or modeling questions, or other requests for help to the [caffe-users list][1] instead of Issues. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe. Please read the [guidelines for contributing][2] before submitting an issue or a pull request.\r\n\r\n [1]: https://groups.google.com/forum/#!forum/caffe-users\r\n [2]: https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md']",[],[],0,0
159,caffe,115,closed,network structure definition,"Caffe is a really good and simple deep neural network framework. I think its config file can support other type neural network, such as deep feed-forward neural network. 

Can anyone give me some examples for that? for example. I want to build a deep feed-forward neural network. It's structure is data input - 2000 - 1000 - 500 - 128 - 64 output, the inner hidden layers are sigmoid or relu. 

Thanks for your help :)
",question,"[""take example/imagenet as example, this CONV1's botton is data layer. What's the top: conv1 mean? \n\nPerhaps I understand this network structure. The simple process is as following:\n\npad2\nnorm1\npool1\nconv1 -- with relu1( use relu to restrict this output, so input and output are both conv1)\ndata\n\nso, if I want modify this network into pure deep nn. I just replace the conv1 and it's pool layers with sigmoid layer. \n\n...\nnorm2\nsigmoid2 --- with relu2\nnorm1 \nsigmoid1 --- with relu1\ndata\n\nso my question is :\n1) what's the padding layer useage? just resize the image for next layer input?\n2) I change the network, it throw an error, net.cpp: 73, unknow blob inpit sigmoid1 to layer0. wanna help :)\n"", 'Please refer to the [Caffe presentation](http://caffe.berkeleyvision.org/caffe-presentation.pdf), the models/imagenet.prototxt example, and [defining the LeNet/MNIST model](http://caffe.berkeleyvision.org/mnist_prototxt.html) for pointers.\n']",[],[],0,0
160,caffe,1485,closed,Can Caffe run several parallel processing task on one GPU?,"Suppose I have 1 GPU and light network.
Is it possible to process several pictures in parallel in test phase on one GPU?
",,"['Yeah Caffe can process over 300 images per second in test mode in a good\nGPU.\n\nOn Wednesday, November 26, 2014, geffy notifications@github.com wrote:\n\n> Suppose I have 1 GPU and light network.\n> Is it possible to process several pictures in parallel in test phase on\n> one GPU?\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/1485.\n\n## \n\nSergio\n', 'But this 300 images processed sequentially, right?\n', 'No all the images in a batch are processed in parallel. So if you want to\nprocess less just specify batch_size: 128 or the desired value. The upper\nlimit depends in the memory available.\n\nSergio\n\n2014-11-27 0:26 GMT-08:00 geffy notifications@github.com:\n\n> But this 300 images processed sequentially, right?\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/1485#issuecomment-64759020.\n', 'So if I want to use a lot of workers to process images, I should start one instance of Caffe per worker and they would be working reasonably fast on the same GPU? \n', 'It will depend how many images each worker wants to process, there will be communication bottlenecks and computation bottlenecks. \nSince Caffe does a good use of the GPU, one or two workers could saturate the GPU if they feed enough images per second.\n\nPlease ask modeling questions on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) mailing list. Issues are for development discussion. Thanks!\n', 'hey I am trying to run batch processing using caffe with c++ but it seems that it runs the images sequentally rather then parallely ? can u help ?']",[],[],0,0
161,caffe,2050,closed,"How to save training loss, training accuracy and test accuracy into .txt files?","Caffe just outputs these results on the screen, but I don't know how to save these results into files for further use.
",,"['The simple method is to use tee:\ncaffe train --solver=$solver_file 2>&1 | tee log.txt\nIn log.txt, you will find all the info which is the same as the screen print. The you can use grep/awk/seed to extract the loss/accuracy. Have a look at this post: http://fastml.com/how-to-run-external-programs-from-python-and-capture-their-output/\n\nIf you are working in Windows, there is wtee.exe.\n', ""@ChenglongChen  Thanks ChenglongI'm bohan, and is a phd candidate. weixin: 13840980753, maybe we can help with each other in research! \n""]",[],[],0,0
162,caffe,5175,closed,Build succeed but cannot run because of an issue with the shared object,"### Issue summary

The shared object seems to be not correctly linked or does not find a symbol after it has been compiled successfully.

### Steps to reproduce

compile it using cmake:

copy the python code into its include path so it is visible to applications


### Your system configuration
Operating system: CentOS 6
Compiler: gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-17)
",,"['From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\r\n\r\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\r\nUse the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.']","['\r\nTraceback (most recent call last):\r\n  File ""file.py"", line 17, in <module>\r\n    import caffe\r\n  File ""/usr/local/lib/python3.6/site-packages/caffe/__init__.py"", line 1, in <module>\r\n    from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver\r\n  File ""/usr/local/lib/python3.6/site-packages/caffe/pycaffe.py"", line 13, in <module>\r\n    from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\r\nImportError: /usr/local/lib/python3.6/site-packages/caffe/_caffe.so: undefined symbol: _ZN5boost6python6detail11init_moduleER11PyModuleDefPFvvE\r\n', '\r\ncmake .. -Dpython_version=3.6 -DBOOST_INCLUDEDIR=/usr/include/boost148/ -DBOOST_LIBRARYDIR=/usr/lib64/boost148/ -DPYTHON_LIBRARIES=/usr/local/lib/python3.6/ -DPYTHON_EXECUTABLE=/usr/local/bin/python3.6 -DCMAKE_INSTALL_PREFIX:PATH=/usr\r\n', '\r\n-- ******************* Caffe Configuration Summary *******************\r\n-- General:\r\n--   Version           :   1.0.0-rc3\r\n--   Git               :   1.0.0-rc4-2-g365ac88-dirty\r\n--   System            :   Linux\r\n--   C++ compiler      :   /usr/bin/c++\r\n--   Release CXX flags :   -O3 -DNDEBUG -fPIC -Wall -Wno-sign-compare -Wno-uninitialized\r\n--   Debug CXX flags   :   -g -fPIC -Wall -Wno-sign-compare -Wno-uninitialized\r\n--   Build type        :   Release\r\n-- \r\n--   BUILD_SHARED_LIBS :   ON\r\n--   BUILD_python      :   ON\r\n--   BUILD_matlab      :   OFF\r\n--   BUILD_docs        :   ON\r\n--   CPU_ONLY          :   ON\r\n--   USE_OPENCV        :   ON\r\n--   USE_LEVELDB       :   ON\r\n--   USE_LMDB          :   ON\r\n--   ALLOW_LMDB_NOLOCK :   OFF\r\n-- \r\n-- Dependencies:\r\n--   BLAS              :   Yes (Atlas)\r\n--   Boost             :   Yes (ver. 1.48)\r\n--   glog              :   Yes\r\n--   gflags            :   Yes\r\n--   protobuf          :   Yes (ver. 2.3.0)\r\n--   lmdb              :   Yes (ver. 0.9.18)\r\n--   LevelDB           :   Yes (ver. 1.7)\r\n--   Snappy            :   Yes (ver. 1.1.0)\r\n--   OpenCV            :   Yes (ver. 2.4.13.2)\r\n--   CUDA              :   No\r\n-- \r\n-- Python:\r\n--   Interpreter       :   /usr/local/bin/python3.6 (ver. 3.6)\r\n--   Libraries         :   /usr/local/lib/libpython3.6m.a (ver 3.6.0)\r\n--   NumPy             :   /usr/local/lib/python3.6/site-packages/numpy/core/include (ver 1.11.3)\r\n-- \r\n-- Documentaion:\r\n--   Doxygen           :   No\r\n--   config_file       :   \r\n-- \r\n-- Install:\r\n--   Install path      :   /usr\r\n-- \r\n-- Configuring done\r\n-- Generating done\r\n-- Build files have been written to: /root/caffe/build\r\n']",[],0,0
163,caffe,2525,closed,Implement Cross Input Neighbourhood differences Layer for Reidentification,"Hi All,
We are trying to implement the Cross Input Neighbourhood difference layer as described in http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Ahmed_An_Improved_Deep_2015_CVPR_paper.pdf in caffe.

Two input blobs (features from two different images generated by conv and pooling) are used to compute this feature. A 5x5 neighbourhood of one pixel (f) channel (for each pixel) is subtracted from  the corresponding channel from the other blob (g). To subtract the 5x5 pixels form f the corresponding g pixel value is repeated in a 5x5 patch. This outputs a 5x5 patch for each input pixel. Thereafter the role of f and g are reversed and the operation is repeated and concatenated in the channel dimension. Hence for two WxHxC images the output is of the size 5Wx5Hx2C, where W, H and C are width, height and channels respectively. 

For simplicity the following is the corresponding matlab code for the operation
[inputs : f, g each of which are of size MxMxC, for simplicity C=1]
image_size=size(f);
kernel_size=5;
pad_size=floor((kernel_size-1)/2);

G=padarray(g,[pad_size,pad_size],'replicate');
F=padarray(f,[pad_size,pad_size],'replicate');
%%%%%%%%%%%%%%%%%%%%%%%%%%
%im2col to get neighbouring kernels into a matrix
%%%%%%%%%%%%%%%%%%%%%%%%%%

fcol=im2col(F,[kernel_size,kernel_size],'sliding');
gcol=im2col(G,[kernel_size,kernel_size],'sliding');

%%%%%%%%%%%%%%%%%%%%%%%%%%
%Each pixel is repeated to the size of the Kernel 
%%%%%%%%%%%%%%%%%%%%%%%%%%

fres=repmat(reshape(f,[1,image_size_image_size]),[kernel_size_kernel_size,1]);
gres=repmat(reshape(g,[1,image_size_image_size]),[kernel_size_kernel_size,1]);

%%%%%%%%%%%%%%%%%%%%
%Subtract g neighbourhoods from f
%%%%%%%%%%%%%%%%%%%%

c1=fres-gcol;
Res2(:,:,1)=col2im(c1,[kernel_size,kernel_size],[image_size_kernel_size,image_size_kernel_size],'distinct');

%%%%%%%%%%%%%%%%%%%%
%Subtract f neighbourhoods from g
%%%%%%%%%%%%%%%%%%%%

c2=gres-fcol;
Res2(:,:,2)=col2im(c2,[kernel_size,kernel_size],[image_size_kernel_size,image_size_kernel_size],'distinct');

%Res2 is the output

While this is straigtforward in matlab, we were wondering how to implement the repmat in caffe. Furthermore since the layer has no parameters, it will not have any diffs. However for the backward pass how do we propagate the gradients from the layers that follow to the layers that preceed it. This layer has proven to be very useful for person reidentification and it might be used in future for new face verification networks as well. 
",,['This tracker is for issues and bugs with Caffe. Please ask usage and modeling questions on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) list. Thanks!\n'],[],[],0,0
164,caffe,4598,closed,Nuget doesn't work,"I'm using Visual Studio 2013 Community to build caffe-windows, I'm not using MATLAB support, Python support, cuDNN. The building process just stuck with the Nuget Package Manager.
I've installed CUDA-7.5 properly.
",windows,['Further detailed in #4649.\n'],[],[],0,0
165,caffe,3340,closed,Issue in compiling Matlab wrapper,"Compiling with R2015b and Apple LLVM version 7.0.0 (clang-700.1.76) gives the following error during linking, anyone else facing the same issue?


",,"['Do anybody resolve this issue. I also come across this problem on MacOs.\n', 'See https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/caffe-users/1sVAqSDLvpk/r9LMUXp7EgAJ\n', 'also needed to add /usr/local/lib /Applications/MATLAB_R2015b.app/bin/maci64 in LIBRARY_DIRS in Makefile.config\n\n```\nLIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /Applications/MATLAB_R2015b.app/bin/maci64 /usr/lib\n```\n\nthanks @ronghanghu for your help.\n']","['\nUndefined symbols for architecture x86_64:\n  ""_mxArrayToString"", referenced from:\n      get_solver(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      solver_restore(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      get_net(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      net_copy_from(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      net_save(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      read_mean(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      write_mean(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      ...\n  ""_mxCreateCellMatrix_700"", referenced from:\n      str_vec_to_mx_strcell(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) in caffe_.o\n  ""_mxCreateDoubleMatrix_700"", referenced from:\n      net_get_attr(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      blob_get_shape(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n  ""_mxCreateDoubleScalar"", referenced from:\n      get_solver(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      solver_get_attr(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      solver_get_iter(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      get_net(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      net_get_attr(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      get_init_key(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      mxArray_tag* ptr_vec_to_handle_vec<caffe::Blob<float> >(std::__1::vector<boost::shared_ptr<caffe::Blob<float> >, std::__1::allocator<boost::shared_ptr<caffe::Blob<float> > > > const&) in caffe_.o\n      ...\n  ""_mxCreateNumericArray_700"", referenced from:\n      blob_to_mx_mat(caffe::Blob<float> const*, WhichMemory) in caffe_.o\n  ""_mxCreateNumericMatrix_700"", referenced from:\n      get_solver(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      solver_get_attr(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      get_net(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      net_get_attr(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      mxArray_tag* ptr_vec_to_handle_vec<caffe::Blob<float> >(std::__1::vector<boost::shared_ptr<caffe::Blob<float> >, std::__1::allocator<boost::shared_ptr<caffe::Blob<float> > > > const&) in caffe_.o\n  ""_mxCreateString"", referenced from:\n      layer_get_type(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      str_vec_to_mx_strcell(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) in caffe_.o\n  ""_mxCreateStructMatrix_700"", referenced from:\n      get_solver(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      solver_get_attr(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      get_net(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      net_get_attr(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      layer_get_attr(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      mxArray_tag* ptr_vec_to_handle_vec<caffe::Blob<float> >(std::__1::vector<boost::shared_ptr<caffe::Blob<float> >, std::__1::allocator<boost::shared_ptr<caffe::Blob<float> > > > const&) in caffe_.o\n  ""_mxFree"", referenced from:\n      get_solver(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      solver_restore(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      get_net(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      net_copy_from(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      net_save(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      read_mean(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      write_mean(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      ...\n  ""_mxGetData"", referenced from:\n      get_solver(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      solver_get_attr(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      get_net(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      net_get_attr(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      caffe::Solver<float>* handle_to_ptr<caffe::Solver<float> >(mxArray_tag const*) in caffe_.o\n      caffe::Net<float>* handle_to_ptr<caffe::Net<float> >(mxArray_tag const*) in caffe_.o\n      mxArray_tag* ptr_vec_to_handle_vec<caffe::Blob<float> >(std::__1::vector<boost::shared_ptr<caffe::Blob<float> >, std::__1::allocator<boost::shared_ptr<caffe::Blob<float> > > > const&) in caffe_.o\n      ...\n  ""_mxGetDimensions_700"", referenced from:\n      write_mean(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n  ""_mxGetField_700"", referenced from:\n      caffe::Solver<float>* handle_to_ptr<caffe::Solver<float> >(mxArray_tag const*) in caffe_.o\n      caffe::Net<float>* handle_to_ptr<caffe::Net<float> >(mxArray_tag const*) in caffe_.o\n      caffe::Layer<float>* handle_to_ptr<caffe::Layer<float> >(mxArray_tag const*) in caffe_.o\n      caffe::Blob<float>* handle_to_ptr<caffe::Blob<float> >(mxArray_tag const*) in caffe_.o\n  ""_mxGetNumberOfDimensions_700"", referenced from:\n      write_mean(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n  ""_mxGetNumberOfElements"", referenced from:\n      blob_reshape(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      mx_mat_to_blob(mxArray_tag const*, caffe::Blob<float>*, WhichMemory) in caffe_.o\n  ""_mxGetPr"", referenced from:\n      net_get_attr(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      blob_get_shape(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      blob_reshape(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n  ""_mxGetScalar"", referenced from:\n      solver_step(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      set_device(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      caffe::Solver<float>* handle_to_ptr<caffe::Solver<float> >(mxArray_tag const*) in caffe_.o\n      caffe::Net<float>* handle_to_ptr<caffe::Net<float> >(mxArray_tag const*) in caffe_.o\n      caffe::Layer<float>* handle_to_ptr<caffe::Layer<float> >(mxArray_tag const*) in caffe_.o\n      caffe::Blob<float>* handle_to_ptr<caffe::Blob<float> >(mxArray_tag const*) in caffe_.o\n  ""_mxIsChar"", referenced from:\n      get_solver(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      solver_restore(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      get_net(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      net_copy_from(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      net_save(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      read_mean(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      write_mean(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      ...\n  ""_mxIsDouble"", referenced from:\n      solver_step(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      blob_reshape(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      set_device(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n  ""_mxIsSingle"", referenced from:\n      blob_set_data(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      blob_set_diff(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      write_mean(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n  ""_mxIsStruct"", referenced from:\n      solver_get_attr(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      solver_get_iter(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      solver_restore(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      solver_solve(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      solver_step(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      net_get_attr(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      net_forward(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      ...\n  ""_mxIsUint64"", referenced from:\n      caffe::Solver<float>* handle_to_ptr<caffe::Solver<float> >(mxArray_tag const*) in caffe_.o\n      caffe::Net<float>* handle_to_ptr<caffe::Net<float> >(mxArray_tag const*) in caffe_.o\n      caffe::Layer<float>* handle_to_ptr<caffe::Layer<float> >(mxArray_tag const*) in caffe_.o\n      caffe::Blob<float>* handle_to_ptr<caffe::Blob<float> >(mxArray_tag const*) in caffe_.o\n  ""_mxSetCell_700"", referenced from:\n      str_vec_to_mx_strcell(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&) in caffe_.o\n  ""_mxSetField_700"", referenced from:\n      get_solver(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      solver_get_attr(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      get_net(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      net_get_attr(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      layer_get_attr(int, mxArray_tag**, int, mxArray_tag const**) in caffe_.o\n      mxArray_tag* ptr_vec_to_handle_vec<caffe::Blob<float> >(std::__1::vector<boost::shared_ptr<caffe::Blob<float> >, std::__1::allocator<boost::shared_ptr<caffe::Blob<float> > > > const&) in caffe_.o\nld: symbol(s) not found for architecture x86_64\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\n\nmake: *** [matlab/+caffe/private/caffe_.mexmaci64] Error 255\n']",[],0,0
166,caffe,938,closed,Boost Python Problem on import caffe,"Hello,

Thanks for the great library. I have trying to run filter_visualization.py however importing caffe module has been raising problems. Boost has been built, pycaffe compiled properly and all other examples are running smoothly. However, I am getting the following error related to boostpython:

ImportError: ../python/caffe/_caffe.so: undefined symbol: _ZN5boost6python6detail12gcc_demangleEPKc

Thanks
Nate
",,['Are you on OS X 10.9 and if so did you compile with libstdc++ instead of libc++?\n\nPlease follow-up with installation questions on the\xa0[caffe-users mailing list](https://groups.google.com/forum/#!forum/caffe-users). As of the latest release we prefer to keep issues reserved for Caffe development. Thanks!\n'],[],[],0,0
167,caffe,962,closed,how to use customized loss function and modify trainning procedure in caffe,"May i know if it is possible to use customized loss function in caffe? Also, if I want to change the formula of weight update in the backpropagation, is this allowed in caffe? Could you please give some hints about this? Thanks a lot! 
",question,"['Please ask questions on the\xa0[caffe-users mailing list](https://groups.google.com/forum/#!forum/caffe-users). As of the latest release we prefer to keep issues reserved for Caffe development. Thanks!\n\nFor how to develop a new layer, including a new loss layer, see https://github.com/BVLC/caffe/wiki/Development-Hints#developing-new-layers\n']",[],[],0,0
168,caffe,3110,closed,Data accessing based on key value from Caffe::DB,"Hello everyone,

I have saved some features in Caffe::DB (database type does not matter) for a number of images, and features for each image are saved with a different key. While retrieving the features from database, I am able to get the data sequentially, but I was wondering if there is a method to randomly access the data corresponding to a specific key. I looked in to the source code for Caffe::DB and Caffe::DB::Cursor, but couldn't find any method for random access of database entries. The cursor can only be placed either to the first entry of database, or to the next. Should not there be a method where one can access database entries with any key??

Thanks! 
",,"[""Closing as this looks like a request for help. (Though note that while key-based access is something you'll find discussed elsewhere on the GitHub, that sort of thing is generally done externally or through a Python layer.)\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n""]",[],[],0,0
169,caffe,5096,closed,getting AttributeError: 'LayerParameter' object has no attribute 'weight_filter',"### Issue summary
I am just running pycaffe lenet example code (https://github.com/BVLC/caffe/blob/master/examples/01-learning-lenet.ipynb) , and getting 

**[AttributeError: 'LayerParameter' object has no attribute 'weight_filter']**

My code is exactly same with _2. Creating the net - in[4]_ for net part, slightly different for 1. Setup part because of caffe path.

I've found few similar issues and tried with ""convolution_param=dict(weight_filter...)"" thing (someone said it is a quick fix) then I got another error, [AttributeError: 'ConvolutionParameter' object has no attribute 'weight_filter']


_Trace as follows:_
$ python ex_classification.py 
Traceback (most recent call last):
  File ""ex_classification.py"", line 37, in <module>
    lenet('mnist/mnist_train_lmdb', 64)
  File ""ex_classification.py"", line 35, in lenet
    return n.to_proto()
  File ""/home/sunyou/Downloads/caffe-master/python/caffe/net_spec.py"", line 189, in to_proto
    top._to_proto(layers, names, autonames)
  File ""/home/sunyou/Downloads/caffe-master/python/caffe/net_spec.py"", line 97, in _to_proto
    return self.fn._to_proto(layers, names, autonames)
  File ""/home/sunyou/Downloads/caffe-master/python/caffe/net_spec.py"", line 158, in _to_proto
    assign_proto(layer, k, v)
  File ""/home/sunyou/Downloads/caffe-master/python/caffe/net_spec.py"", line 64, in assign_proto
    is_repeated_field = hasattr(getattr(proto, name), 'extend')
AttributeError: 'LayerParameter' object has no attribute 'weight_filter'

running on Ubuntu 14.04 LTS with Python 2.7.6.
caffe-master from git repo, libprotobuf-dev from apt-get (2.5.0-9ubuntu1)",,"[""I'm so sorry. It was totally my bad(typo)"", 'I got the same problem these days. I did know why?', ""It's called `weight_filler`, double L, not `filter`.""]",[],[],0,0
170,caffe,5379,closed,feature_extraction_net (core dumped) Error,"Please use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) for usage, installation, or modeling questions, or other requests for help.
_Do not post such requests to Issues._ Doing so interferes with the development of Caffe.

Please read the [guidelines for contributing](https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md) before submitting this issue.

### Issue summary
In our .cpp file, we invoked the feature_extraction_net(proto, caffe::Phase::TEST) in which the proto is the full path of the proto file. However, it ends up with an error as following:
I0303 20:38:16.966768 11556 net.cpp:110] Creating Layer volleyball_level2
I0303 20:38:16.966792 11556 net.cpp:433] volleyball_level2 -> data
I0303 20:38:16.966830 11556 net.cpp:433] volleyball_level2 -> label
F0303 20:38:16.970520 11581 db_leveldb.cpp:16] Check failed: status.ok() Failed to open leveldb examples/deep-activity-rec/ibrahim16-cvpr/p4-network2/trainval-leveldb
Invalid argument: examples/deep-activity-rec/ibrahim16-cvpr/p4-network2/trainval-leveldb: does not exist (create_if_missing is false)
*** Check failure stack trace: ***
    @     0x7f4c1d646daa  (unknown)
    @     0x7f4c1d646ce4  (unknown)
    @     0x7f4c1d6466e6  (unknown)
    @     0x7f4c1d649687  (unknown)
    @     0x7f4c1dd62d07  caffe::db::LevelDB::Open()
    @     0x7f4c1dd16463  caffe::DataReader::Body::InternalThreadEntry()
    @     0x7f4c1dd7fcc5  caffe::InternalThread::entry()
    @     0x7f4c118b7a4a  (unknown)
    @     0x7f4c0fb87184  start_thread
    @     0x7f4c1c47137d  (unknown)
    @              (nil)  (unknown)
Aborted (core dumped)

We notice that there were others asked a similar question before (Feature Extractor Error #3505).

### Steps to reproduce

If you are having difficulty building Caffe or training a model, please ask the caffe-users mailing list. If you are reporting a build error that seems to be due to a bug in Caffe, please attach your build configuration (either Makefile.config or CMakeCache.txt) and the output of the make (or cmake) command.

### Your system configuration
Operating system: Ubuntu 14.04 (64bit)
Compiler: gcc
CUDA version (if applicable): cuda8.0
CUDNN version (if applicable):
BLAS: atlas
Python or MATLAB version (for pycaffe and matcaffe respectively): python 2.7
",,[],[],[],0,0
171,caffe,1125,closed,Conflicting Parameters in WindowDataLayer,"In #995, the data layers are re-arranged into a hierarchical structure. After this modification, the WindowDataLayer has conflicting parameters in TransformationParameter and in WindowDataParameter:



and        



Parameters such as  and  appear twice, which cause serious problems and break down the finetune-pascal example. Currently WindowDataParameter is using  from TransformationParameter, ,  and  from WindowDataParameter. Especially, the  in TransformationParameter is used, while it is specified in WindowDataParameter in finetune-pascal example and in the R. Girshick's R-CNN repo).

I found my experimental result these days so weird and I later found that the WindowDataLayer is not working at all due to this issue. I am going to make a pull request to resolve it.

We should also add unit test for WindowDataLayer.
",,"['Could you try #1070 and if it solves the problem?\n\nOn Sunday, September 21, 2014, Ronghang Hu notifications@github.com wrote:\n\n> In #995 https://github.com/BVLC/caffe/pull/995, the data layers are\n> re-arranged into a hierarchical structure. After this modification, the\n> WindowDataLayer has conflicting parameters in TransformationParameter and\n> in WindowDataParameter:\n> \n> message TransformationParameter {\n>   // For data pre-processing, we can do simple scaling and subtracting the\n>   // data mean, if provided. Note that the mean subtraction is always carried\n>   // out before scaling.\n>   optional float scale = 1 [default = 1];\n>   // Specify if we want to randomly mirror data.\n>   optional bool mirror = 2 [default = false];\n>   // Specify if we would like to randomly crop an image.\n>   optional uint32 crop_size = 3 [default = 0];\n>   optional string mean_file = 4;\n> }\n> \n> and\n> \n> message WindowDataParameter {\n>   // Specify the data source.\n>   optional string source = 1;\n>   // For data pre-processing, we can do simple scaling and subtracting the\n>   // data mean, if provided. Note that the mean subtraction is always carried\n>   // out before scaling.\n>   optional float scale = 2 [default = 1];\n>   optional string mean_file = 3;\n>   // Specify the batch size.\n>   optional uint32 batch_size = 4;\n>   // Specify if we would like to randomly crop an image.\n>   optional uint32 crop_size = 5 [default = 0];\n>   // Specify if we want to randomly mirror data.\n>   optional bool mirror = 6 [default = false];\n>   // Foreground (object) overlap threshold\n>   optional float fg_threshold = 7 [default = 0.5];\n>   // Background (non-object) overlap threshold\n>   optional float bg_threshold = 8 [default = 0.5];\n>   // Fraction of batch that should be foreground objects\n>   optional float fg_fraction = 9 [default = 0.25];\n>   // Amount of contextual padding to add around a window\n>   // (used only by the window_data_layer)\n>   optional uint32 context_pad = 10 [default = 0];\n>   // Mode for cropping out a detection window\n>   // warp: cropped window is warped to a fixed size and aspect ratio\n>   // square: the tightest square around the window is cropped\n>   optional string crop_mode = 11 [default = ""warp""];\n> }\n> \n> Parameters such as scale and mean_file appear twice, which cause serious\n> problems and break down the finetune-pascal example (the mean_file in\n> TransformationParameter is used, while it is specified in\n> WindowDataParameter in finetune-pascal example and in the R-CNN repo.\n> \n> I found my experimental result these days so weird and I later found that\n> the WindowDataLayer is not working at all due to this issue. I am going to\n> make a pull request to resolve it.\n> \n> We should also add unit test for WindowDataLayer.\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/1125.\n\n## \n\nSergio\n', ""@sguada I haven't tried yet, but I really think we should keep a consistent inferface for data layers, and it is changing a bit too often recently. Otherwise, all models in model zoo, and other software like R-CNN may all break down.\n"", ""In theory this change should  be transparent to existing data layers in\nmodels or rcnn.\nBut I also share your concerns.\n\nOn Sunday, September 21, 2014, Ronghang Hu notifications@github.com wrote:\n\n> @sguada https://github.com/sguada I haven't tried yet, but I really\n> think we should keep a consistent inferface for data layers, and it is\n> changing a bit too often recently. Otherwise, all models in model zoo, and\n> other software like R-CNN may all break down.\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/1125#issuecomment-56300414.\n\n## \n\nSergio\n"", ""The point of keeping the old fields was that they are needed for\nbackwards-compatibility. All the actual code should refer to the\ntransformation params and not the old layer params because the old params\nare automatically / manually upgradeable.\n\nI'll take another look at this too and would appreciate testing. The\nduplicated fields are needed for now though for upgradability.\n\nOn Sunday, September 21, 2014, Sergio Guadarrama notifications@github.com\nwrote:\n\n> In theory this change should be transparent to existing data layers in\n> models or rcnn.\n> But I also share your concerns.\n> \n> On Sunday, September 21, 2014, Ronghang Hu <notifications@github.com\n> <javascript:_e(%7B%7D,'cvml','notifications@github.com');>> wrote:\n> \n> > @sguada https://github.com/sguada I haven't tried yet, but I really\n> > think we should keep a consistent inferface for data layers, and it is\n> > changing a bit too often recently. Otherwise, all models in model zoo,\n> > and\n> > other software like R-CNN may all break down.\n> > \n> > \n> > Reply to this email directly or view it on GitHub\n> > https://github.com/BVLC/caffe/issues/1125#issuecomment-56300414.\n> \n> ## \n> \n> Sergio\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/1125#issuecomment-56302440.\n\n## \n\nEvan Shelhamer\n"", '@ronghanghu I have traced the problem to the data parameter upgrade skipping WindowDataLayer: https://github.com/BVLC/caffe/blob/master/src/caffe/util/upgrade_proto.cpp#L509-L527\n\nCould you check my fix in #1126?\n\nI agree that WindowDataLayer needs tests to protect against issues while the data layer design is improved. If you could PR tests that would be very helpful.\n', '#1126 fixes the parameterization and #1136 adds tests.\n']","['\nmessage TransformationParameter {\n  // For data pre-processing, we can do simple scaling and subtracting the\n  // data mean, if provided. Note that the mean subtraction is always carried\n  // out before scaling.\n  optional float scale = 1 [default = 1];\n  // Specify if we want to randomly mirror data.\n  optional bool mirror = 2 [default = false];\n  // Specify if we would like to randomly crop an image.\n  optional uint32 crop_size = 3 [default = 0];\n  optional string mean_file = 4;\n}\n', '\nmessage WindowDataParameter {\n  // Specify the data source.\n  optional string source = 1;\n  // For data pre-processing, we can do simple scaling and subtracting the\n  // data mean, if provided. Note that the mean subtraction is always carried\n  // out before scaling.\n  optional float scale = 2 [default = 1];\n  optional string mean_file = 3;\n  // Specify the batch size.\n  optional uint32 batch_size = 4;\n  // Specify if we would like to randomly crop an image.\n  optional uint32 crop_size = 5 [default = 0];\n  // Specify if we want to randomly mirror data.\n  optional bool mirror = 6 [default = false];\n  // Foreground (object) overlap threshold\n  optional float fg_threshold = 7 [default = 0.5];\n  // Background (non-object) overlap threshold\n  optional float bg_threshold = 8 [default = 0.5];\n  // Fraction of batch that should be foreground objects\n  optional float fg_fraction = 9 [default = 0.25];\n  // Amount of contextual padding to add around a window\n  // (used only by the window_data_layer)\n  optional uint32 context_pad = 10 [default = 0];\n  // Mode for cropping out a detection window\n  // warp: cropped window is warped to a fixed size and aspect ratio\n  // square: the tightest square around the window is cropped\n  optional string crop_mode = 11 [default = ""warp""];\n}\n']","['scale', 'mean_file', 'mean_file', 'scale', 'crop_size', 'mirror', 'mean_file']",0,0
172,caffe,3803,closed,make: *** No rule to make target `matcaffe'.  Stop.,"Hi,

I succeed at compiling Caffe with Matlab but I get this error when I try to call any function of the caffe api inside Matlab.

I guess everything is okay since the ""caffe_.mexa64"" is generated.
This is my CMake output:

-- Boost version: 1.55.0
-- Found the following Boost libraries:
--   system
--   thread
--   filesystem
-- Found gflags  (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libgflags.so)
-- Found glog    (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libglog.so)
-- Found PROTOBUF Compiler: /usr/bin/protoc
-- Found lmdb    (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/liblmdb.so)
-- Found LevelDB (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libleveldb.so)
-- Found Snappy  (include: /usr/include, library: /usr/lib/libsnappy.so)
-- CUDA detected: 7.5
-- Found cuDNN: ver. 4.0.7 found (include: /usr/local/include, library: /usr/local/lib/libcudnn.so)
-- Added CUDA NVCC flags for: sm_52 sm_50
-- Cuda + Boost 1.55: Applying noinline work around
-- OpenCV found (/usr/local/share/OpenCV)
-- Found Atlas (include: /usr/include, library: /usr/lib/libatlas.so)
-- NumPy ver. 1.8.2 found (include: /usr/lib/python2.7/dist-packages/numpy/core/include)
-- Boost version: 1.55.0
-- Found the following Boost libraries:
--   python
## -- Could NOT find Doxygen (missing:  DOXYGEN_EXECUTABLE) 

-- ******************\* Caffe Configuration Summary *******************
-- General:
--   Version           :   1.0.0-rc3
--   Git               :   rc2-878-gbe163be-dirty
--   System            :   Linux
--   C++ compiler      :   /usr/bin/c++
--   Release CXX flags :   -O3 -DNDEBUG -fPIC -Wall -Wno-sign-compare -Wno-uninitialized
--   Debug CXX flags   :   -g -fPIC -Wall -Wno-sign-compare -Wno-uninitialized
## --   Build type        :   Release

--   BUILD_SHARED_LIBS :   ON
--   BUILD_python      :   ON
--   BUILD_matlab      :   ON
--   BUILD_docs        :   ON
--   CPU_ONLY          :   OFF
--   USE_OPENCV        :   ON
--   USE_LEVELDB       :   ON
--   USE_LMDB          :   ON
## --   ALLOW_LMDB_NOLOCK :   OFF

-- Dependencies:
--   BLAS              :   Yes (Atlas)
--   Boost             :   Yes (ver. 1.55)
--   glog              :   Yes
--   gflags            :   Yes
--   protobuf          :   Yes (ver. 2.5.0)
--   lmdb              :   Yes (ver. 0.9.10)
--   LevelDB           :   Yes (ver. 1.15)
--   Snappy            :   Yes (ver. 1.1.0)
--   OpenCV            :   Yes (ver. 3.1.0)
## --   CUDA              :   Yes (ver. 7.5)

-- NVIDIA CUDA:
--   Target GPU(s)     :   Auto
--   GPU arch(s)       :   sm_52 sm_50
## --   cuDNN             :   Yes (ver. 4.0.7)

-- Python:
--   Interpreter       :   /usr/bin/python2.7 (ver. 2.7.6)
--   Libraries         :   /usr/lib/x86_64-linux-gnu/libpython2.7.so (ver 2.7.6)
## --   NumPy             :   /usr/lib/python2.7/dist-packages/numpy/core/include (ver 1.8.2)

-- Matlab:
--   Matlab            :   Yes (/usr/local/MATLAB/R2014b/bin/mex, /usr/local/MATLAB/R2014b/bin/mexext
## --   Octave            :   No

-- Documentaion:
--   Doxygen           :   No
## --   config_file       :   

-- Install:
## --   Install path      :   /home/eriba/software/caffe/build/install

-- Configuring done
-- Generating done
-- Build files have been written to: /home/eriba/software/caffe/build
",,"[""Same issue. I've only got a mex64 file in install/caffe generated after the compilation.\n\nHave you figured out the matcaffe thing ?\n"", 'nope\n', 'I have the same problem..\n', 'I believe this target is now just called matlab. If you are using CMake, the BUILD_matlab flag must be on.\n', 'The answer of @scott-vsi is correct. The target is now just called matlab.\n']",[],[],0,0
173,caffe,3141,closed,make all errors,"ubuntu 12.04 
caffe
cudnn-v2

when I run ""sudo make all -j8"" in caffe got error logs like this:


",,['Closing as this looks like a cuDNN installation issue; check that you are doing a clean build with the latest release of cuDNN v2.\n\nAnd please do not ever build Caffe as `root`.\n'],"[' java\nPROTOC src/caffe/proto/caffe.proto\nCXX src/caffe/data_transformer.cpp\nCXX src/caffe/layer_factory.cpp\nCXX src/caffe/syncedmem.cpp\nCXX src/caffe/blob.cpp\nCXX src/caffe/common.cpp\nCXX src/caffe/layers/cudnn_relu_layer.cpp\nCXX src/caffe/layers/conv_layer.cpp\nCXX src/caffe/layers/image_data_layer.cpp\nIn file included from ./include/caffe/util/device_alternate.hpp:40:0,\n                 from ./include/caffe/common.hpp:18,\n                 from src/caffe/syncedmem.cpp:3:\n./include/caffe/util/cudnn.hpp:60:32: error: variable or field createTensor4dDesc declared void\n inline void createTensor4dDesc(cudnnTensor4dDescriptor_t* desc) {\n                                ^\n./include/caffe/util/cudnn.hpp:60:32: error: cudnnTensor4dDescriptor_t was not declared in this scope\n./include/caffe/util/cudnn.hpp:60:59: error: desc was not declared in this scope\n inline void createTensor4dDesc(cudnnTensor4dDescriptor_t* desc) {\n                                                           ^\n./include/caffe/util/cudnn.hpp:65:29: error: variable or field setTensor4dDesc declared void\n inline void setTensor4dDesc(cudnnTensor4dDescriptor_t* desc,  \n                     ^\n']",[],0,0
174,caffe,1602,closed,Non-existent IMAGE_DATA source file causes segmentation fault in caffe::ImageDataLayer<float>::DataLayerSetUp,"I copied the solver.prototxt and train_val.prototxt files from models/bvlc_reference_caffenet, modified the latter to use IMAGE_DATA layers, and then attempted to run caffe, but my train.prototxt contained an error -- the source file specified (file_list.txt) did not exist. It crashes with an uncaught segfault instead of properly reporting the error. The only hint was the ""A total of 0 images."" message.

Below are machine details, gdb backtrace, and command and log output:

Machine: MacBook Pro Retina Late 2013, Mac OS X 10.10.1, 16GB RAM




",,"[""had the same problem recently, it's taken care of here #1551\n"", 'Fixed in #1551.\n']","['\nProgram received signal SIGSEGV, Segmentation fault.\n0x0000000100074fbd in caffe::ImageDataLayer<float>::DataLayerSetUp(std::vector<caffe::Blob<float>*, std::allocator<caffe::Blob<float>*> > const&, std::vector<caffe::Blob<float>*, std::allocator<caffe::Blob<float>*> >*) ()\n(gdb) bt\n#0  0x0000000100074fbd in caffe::ImageDataLayer<float>::DataLayerSetUp(std::vector<caffe::Blob<float>*, std::allocator<caffe::Blob<float>*> > const&, std::vector<caffe::Blob<float>*, std::allocator<caffe::Blob<float>*> >*) ()\n#1  0x000000010005979e in caffe::BaseDataLayer<float>::LayerSetUp(std::vector<caffe::Blob<float>*, std::allocator<caffe::Blob<float>*> > const&, std::vector<caffe::Blob<float>*, std::allocator<caffe::Blob<float>*> >*) ()\n#2  0x000000010005aede in caffe::BasePrefetchingDataLayer<float>::LayerSetUp(std::vector<caffe::Blob<float>*, std::allocator<caffe::Blob<float>*> > const&, std::vector<caffe::Blob<float>*, std::allocator<caffe::Blob<float>*> >*) ()\n#3  0x00000001000964fe in caffe::Net<float>::Init(caffe::NetParameter const&) ()\n#4  0x000000010009578b in caffe::Net<float>::Net(caffe::NetParameter const&) ()\n#5  0x00000001000ac4e8 in caffe::Solver<float>::InitTrainNet() ()\n#6  0x00000001000abf4f in caffe::Solver<float>::Init(caffe::SolverParameter const&) ()\n#7  0x00000001000abdfc in caffe::Solver<float>::Solver(caffe::SolverParameter const&) ()\n#8  0x0000000100003e60 in caffe::Solver<float>* caffe::GetSolver<float>(caffe::SolverParameter const&) ()\n#9  0x000000010000183e in train() ()\n#10 0x0000000100003871 in main ()\n', '\n> caffe train --solver=solver.prototxt --snapshot=train_10000.solverstate\nI1219 23:05:39.339426 2052915968 caffe.cpp:103] Use CPU.\nI1219 23:05:39.340448 2052915968 caffe.cpp:107] Starting Optimization\nI1219 23:05:39.340461 2052915968 solver.cpp:32] Initializing solver from parameters: \ntest_iter: 1000\ntest_interval: 1000\nbase_lr: 0.01\ndisplay: 20\nmax_iter: 450000\nlr_policy: ""step""\ngamma: 0.1\nmomentum: 0.9\nweight_decay: 0.0005\nstepsize: 100000\nsnapshot: 10000\nsnapshot_prefix: ""train_snap""\nsolver_mode: CPU\nnet: ""train.prototxt""\nI1219 23:05:39.340579 2052915968 solver.cpp:67] Creating training net from net file: train.prototxt\nI1219 23:05:39.342327 2052915968 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data\nI1219 23:05:39.342564 2052915968 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy\nI1219 23:05:39.342572 2052915968 net.cpp:39] Initializing net from parameters: \nname: ""NationalDataScienceBowl""\nlayers {\n  top: ""data""\n  top: ""label""\n  name: ""data""\n  type: IMAGE_DATA\n  image_data_param {\n    source: ""file_list.txt""\n    batch_size: 50\n    new_height: 64\n    new_width: 64\n  }\n  include {\n    phase: TRAIN\n  }\n  transform_param {\n    mirror: true\n    crop_size: 60\n    mean_file: ""average.png""\n  }\n}\nlayers {\n  bottom: ""data""\n  top: ""conv1""\n  name: ""conv1""\n  type: CONVOLUTION\n  blobs_lr: 1\n  blobs_lr: 2\n  weight_decay: 1\n  weight_decay: 0\n  convolution_param {\n    num_output: 96\n    kernel_size: 11\n    stride: 4\n    weight_filler {\n      type: ""gaussian""\n      std: 0.01\n    }\n    bias_filler {\n      type: ""constant""\n      value: 0\n    }\n  }\n}\nlayers {\n  bottom: ""conv1""\n  top: ""conv1""\n  name: ""relu1""\n  type: RELU\n}\nlayers {\n  bottom: ""conv1""\n  top: ""pool1""\n  name: ""pool1""\n  type: POOLING\n  pooling_param {\n    pool: MAX\n    kernel_size: 3\n    stride: 2\n  }\n}\nlayers {\n  bottom: ""pool1""\n  top: ""norm1""\n  name: ""norm1""\n  type: LRN\n  lrn_param {\n    local_size: 5\n    alpha: 0.0001\n    beta: 0.75\n  }\n}\nlayers {\n  bottom: ""norm1""\n  top: ""conv2""\n  name: ""conv2""\n  type: CONVOLUTION\n  blobs_lr: 1\n  blobs_lr: 2\n  weight_decay: 1\n  weight_decay: 0\n  convolution_param {\n    num_output: 256\n    pad: 2\n    kernel_size: 5\n    group: 2\n    weight_filler {\n      type: ""gaussian""\n      std: 0.01\n    }\n    bias_filler {\n      type: ""constant""\n      value: 1\n    }\n  }\n}\nlayers {\n  bottom: ""conv2""\n  top: ""conv2""\n  name: ""relu2""\n  type: RELU\n}\nlayers {\n  bottom: ""conv2""\n  top: ""pool2""\n  name: ""pool2""\n  type: POOLING\n  pooling_param {\n    pool: MAX\n    kernel_size: 3\n    stride: 2\n  }\n}\nlayers {\n  bottom: ""pool2""\n  top: ""norm2""\n  name: ""norm2""\n  type: LRN\n  lrn_param {\n    local_size: 5\n    alpha: 0.0001\n    beta: 0.75\n  }\n}\nlayers {\n  bottom: ""norm2""\n  top: ""conv3""\n  name: ""conv3""\n  type: CONVOLUTION\n  blobs_lr: 1\n  blobs_lr: 2\n  weight_decay: 1\n  weight_decay: 0\n  convolution_param {\n    num_output: 384\n    pad: 1\n    kernel_size: 3\n    weight_filler {\n      type: ""gaussian""\n      std: 0.01\n    }\n    bias_filler {\n      type: ""constant""\n      value: 0\n    }\n  }\n}\nlayers {\n  bottom: ""conv3""\n  top: ""conv3""\n  name: ""relu3""\n  type: RELU\n}\nlayers {\n  bottom: ""conv3""\n  top: ""conv4""\n  name: ""conv4""\n  type: CONVOLUTION\n  blobs_lr: 1\n  blobs_lr: 2\n  weight_decay: 1\n  weight_decay: 0\n  convolution_param {\n    num_output: 384\n    pad: 1\n    kernel_size: 3\n    group: 2\n    weight_filler {\n      type: ""gaussian""\n      std: 0.01\n    }\n    bias_filler {\n      type: ""constant""\n      value: 1\n    }\n  }\n}\nlayers {\n  bottom: ""conv4""\n  top: ""conv4""\n  name: ""relu4""\n  type: RELU\n}\nlayers {\n  bottom: ""conv4""\n  top: ""conv5""\n  name: ""conv5""\n  type: CONVOLUTION\n  blobs_lr: 1\n  blobs_lr: 2\n  weight_decay: 1\n  weight_decay: 0\n  convolution_param {\n    num_output: 256\n    pad: 1\n    kernel_size: 3\n    group: 2\n    weight_filler {\n      type: ""gaussian""\n      std: 0.01\n    }\n    bias_filler {\n      type: ""constant""\n      value: 1\n    }\n  }\n}\nlayers {\n  bottom: ""conv5""\n  top: ""conv5""\n  name: ""relu5""\n  type: RELU\n}\nlayers {\n  bottom: ""conv5""\n  top: ""pool5""\n  name: ""pool5""\n  type: POOLING\n  pooling_param {\n    pool: MAX\n    kernel_size: 3\n    stride: 2\n  }\n}\nlayers {\n  bottom: ""pool5""\n  top: ""fc6""\n  name: ""fc6""\n  type: INNER_PRODUCT\n  blobs_lr: 1\n  blobs_lr: 2\n  weight_decay: 1\n  weight_decay: 0\n  inner_product_param {\n    num_output: 4096\n    weight_filler {\n      type: ""gaussian""\n      std: 0.005\n    }\n    bias_filler {\n      type: ""constant""\n      value: 1\n    }\n  }\n}\nlayers {\n  bottom: ""fc6""\n  top: ""fc6""\n  name: ""relu6""\n  type: RELU\n}\nlayers {\n  bottom: ""fc6""\n  top: ""fc6""\n  name: ""drop6""\n  type: DROPOUT\n  dropout_param {\n    dropout_ratio: 0.5\n  }\n}\nlayers {\n  bottom: ""fc6""\n  top: ""fc7""\n  name: ""fc7""\n  type: INNER_PRODUCT\n  blobs_lr: 1\n  blobs_lr: 2\n  weight_decay: 1\n  weight_decay: 0\n  inner_product_param {\n    num_output: 4096\n    weight_filler {\n      type: ""gaussian""\n      std: 0.005\n    }\n    bias_filler {\n      type: ""constant""\n      value: 1\n    }\n  }\n}\nlayers {\n  bottom: ""fc7""\n  top: ""fc7""\n  name: ""relu7""\n  type: RELU\n}\nlayers {\n  bottom: ""fc7""\n  top: ""fc7""\n  name: ""drop7""\n  type: DROPOUT\n  dropout_param {\n    dropout_ratio: 0.5\n  }\n}\nlayers {\n  bottom: ""fc7""\n  top: ""fc8""\n  name: ""fc8""\n  type: INNER_PRODUCT\n  blobs_lr: 1\n  blobs_lr: 2\n  weight_decay: 1\n  weight_decay: 0\n  inner_product_param {\n    num_output: 1000\n    weight_filler {\n      type: ""gaussian""\n      std: 0.01\n    }\n    bias_filler {\n      type: ""constant""\n      value: 0\n    }\n  }\n}\nlayers {\n  bottom: ""fc8""\n  bottom: ""label""\n  top: ""loss""\n  name: ""loss""\n  type: SOFTMAX_LOSS\n}\nstate {\n  phase: TRAIN\n}\nI1219 23:05:39.343217 2052915968 net.cpp:67] Creating Layer data\nI1219 23:05:39.343228 2052915968 net.cpp:356] data -> data\nI1219 23:05:39.343250 2052915968 net.cpp:356] data -> label\nI1219 23:05:39.343260 2052915968 net.cpp:96] Setting up data\nI1219 23:05:39.343267 2052915968 image_data_layer.cpp:30] Opening file file_list.txt\nI1219 23:05:39.343286 2052915968 image_data_layer.cpp:45] A total of 0 images.\nzsh: segmentation fault  caffe train --solver=solver.prototxt --snapshot=train_10000.solverstate\n']",[],0,0
175,caffe,5254,closed,error make pytest," when I want to make pyest error after already successfully done with the all, test, runtest and pycaffe, and something went wrong as below:
cd python; python -m unittest discover -s caffe/test
EEEEEEEE
======================================================================
ERROR: test_coord_map (unittest.loader.ModuleImportFailure)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_coord_map
Traceback (most recent call last):
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 254, in _find_tests
    module = self._get_module_from_name(name)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 232, in _get_module_from_name
    __import__(name)
  File ""/Users/yolanda/caffe/python/caffe/test/test_coord_map.py"", line 6, in <module>
    import caffe
  File ""caffe/__init__.py"", line 1, in <module>
    from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer
  File ""caffe/pycaffe.py"", line 13, in <module>
    from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
ImportError: dlopen(caffe/_caffe.so, 2): Library not loaded: @rpath/libopencv_imgcodecs.3.2.dylib
  Referenced from: /Users/yolanda/caffe/python/caffe/_caffe.so
  Reason: image not found


======================================================================
ERROR: test_io (unittest.loader.ModuleImportFailure)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_io
Traceback (most recent call last):
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 254, in _find_tests
    module = self._get_module_from_name(name)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 232, in _get_module_from_name
    __import__(name)
  File ""/Users/yolanda/caffe/python/caffe/test/test_io.py"", line 4, in <module>
    import caffe
  File ""caffe/__init__.py"", line 1, in <module>
    from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer
  File ""caffe/pycaffe.py"", line 13, in <module>
    from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
ImportError: dlopen(caffe/_caffe.so, 2): Library not loaded: @rpath/libopencv_imgcodecs.3.2.dylib
  Referenced from: /Users/yolanda/caffe/python/caffe/_caffe.so
  Reason: image not found


======================================================================
ERROR: test_layer_type_list (unittest.loader.ModuleImportFailure)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_layer_type_list
Traceback (most recent call last):
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 254, in _find_tests
    module = self._get_module_from_name(name)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 232, in _get_module_from_name
    __import__(name)
  File ""/Users/yolanda/caffe/python/caffe/test/test_layer_type_list.py"", line 3, in <module>
    import caffe
  File ""caffe/__init__.py"", line 1, in <module>
    from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer
  File ""caffe/pycaffe.py"", line 13, in <module>
    from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
ImportError: dlopen(caffe/_caffe.so, 2): Library not loaded: @rpath/libopencv_imgcodecs.3.2.dylib
  Referenced from: /Users/yolanda/caffe/python/caffe/_caffe.so
  Reason: image not found


======================================================================
ERROR: test_net (unittest.loader.ModuleImportFailure)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_net
Traceback (most recent call last):
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 254, in _find_tests
    module = self._get_module_from_name(name)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 232, in _get_module_from_name
    __import__(name)
  File ""/Users/yolanda/caffe/python/caffe/test/test_net.py"", line 8, in <module>
    import caffe
  File ""caffe/__init__.py"", line 1, in <module>
    from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer
  File ""caffe/pycaffe.py"", line 13, in <module>
    from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
ImportError: dlopen(caffe/_caffe.so, 2): Library not loaded: @rpath/libopencv_imgcodecs.3.2.dylib
  Referenced from: /Users/yolanda/caffe/python/caffe/_caffe.so
  Reason: image not found


======================================================================
ERROR: test_net_spec (unittest.loader.ModuleImportFailure)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_net_spec
Traceback (most recent call last):
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 254, in _find_tests
    module = self._get_module_from_name(name)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 232, in _get_module_from_name
    __import__(name)
  File ""/Users/yolanda/caffe/python/caffe/test/test_net_spec.py"", line 3, in <module>
    import caffe
  File ""caffe/__init__.py"", line 1, in <module>
    from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer
  File ""caffe/pycaffe.py"", line 13, in <module>
    from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
ImportError: dlopen(caffe/_caffe.so, 2): Library not loaded: @rpath/libopencv_imgcodecs.3.2.dylib
  Referenced from: /Users/yolanda/caffe/python/caffe/_caffe.so
  Reason: image not found


======================================================================
ERROR: test_python_layer (unittest.loader.ModuleImportFailure)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_python_layer
Traceback (most recent call last):
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 254, in _find_tests
    module = self._get_module_from_name(name)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 232, in _get_module_from_name
    __import__(name)
  File ""/Users/yolanda/caffe/python/caffe/test/test_python_layer.py"", line 6, in <module>
    import caffe
  File ""caffe/__init__.py"", line 1, in <module>
    from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer
  File ""caffe/pycaffe.py"", line 13, in <module>
    from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
ImportError: dlopen(caffe/_caffe.so, 2): Library not loaded: @rpath/libopencv_imgcodecs.3.2.dylib
  Referenced from: /Users/yolanda/caffe/python/caffe/_caffe.so
  Reason: image not found


======================================================================
ERROR: test_python_layer_with_param_str (unittest.loader.ModuleImportFailure)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_python_layer_with_param_str
Traceback (most recent call last):
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 254, in _find_tests
    module = self._get_module_from_name(name)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 232, in _get_module_from_name
    __import__(name)
  File ""/Users/yolanda/caffe/python/caffe/test/test_python_layer_with_param_str.py"", line 6, in <module>
    import caffe
  File ""caffe/__init__.py"", line 1, in <module>
    from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer
  File ""caffe/pycaffe.py"", line 13, in <module>
    from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
ImportError: dlopen(caffe/_caffe.so, 2): Library not loaded: @rpath/libopencv_imgcodecs.3.2.dylib
  Referenced from: /Users/yolanda/caffe/python/caffe/_caffe.so
  Reason: image not found


======================================================================
ERROR: test_solver (unittest.loader.ModuleImportFailure)
----------------------------------------------------------------------
ImportError: Failed to import test module: test_solver
Traceback (most recent call last):
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 254, in _find_tests
    module = self._get_module_from_name(name)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/unittest/loader.py"", line 232, in _get_module_from_name
    __import__(name)
  File ""/Users/yolanda/caffe/python/caffe/test/test_solver.py"", line 7, in <module>
    import caffe
  File ""caffe/__init__.py"", line 1, in <module>
    from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer
  File ""caffe/pycaffe.py"", line 13, in <module>
    from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
ImportError: dlopen(caffe/_caffe.so, 2): Library not loaded: @rpath/libopencv_imgcodecs.3.2.dylib
  Referenced from: /Users/yolanda/caffe/python/caffe/_caffe.so
  Reason: image not found

and when I try importing caffe in shell I got the error as below:
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""caffe/__init__.py"", line 1, in <module>
    from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver, NCCL, Timer
  File ""caffe/pycaffe.py"", line 13, in <module>
    from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
ImportError: dlopen(caffe/_caffe.so, 2): Library not loaded: @rpath/libopencv_imgcodecs.3.2.dylib
  Referenced from: /Users/yolanda/caffe/python/caffe/_caffe.so
  Reason: image not found

but when I use 'otool -L python/caffe/_caffe.so' it shows as below which contains libopencv_imgcodecs:
python/caffe/_caffe.so:
	python/caffe/_caffe.so (compatibility version 0.0.0, current version 0.0.0)
	@rpath/libcaffe.so.1.0.0-rc3 (compatibility version 0.0.0, current version 0.0.0)
	/usr/local/opt/glog/lib/libglog.0.dylib (compatibility version 1.0.0, current version 1.0.0)
	/usr/local/opt/gflags/lib/libgflags.2.2.dylib (compatibility version 2.2.0, current version 2.2.0)
	/usr/local/opt/protobuf/lib/libprotobuf.12.dylib (compatibility version 13.0.0, current version 13.0.0)
	/usr/local/opt/leveldb/lib/libleveldb.1.dylib (compatibility version 0.0.0, current version 0.0.0)
	/usr/local/opt/snappy/lib/libsnappy.1.dylib (compatibility version 5.0.0, current version 5.1.0)
	/usr/local/opt/lmdb/lib/liblmdb.dylib (compatibility version 0.0.0, current version 0.0.0)
	/usr/local/opt/boost/lib/libboost_system.dylib (compatibility version 0.0.0, current version 0.0.0)
	/usr/local/opt/hdf5/lib/libhdf5_hl.10.dylib (compatibility version 12.0.0, current version 12.1.0)
	/usr/local/opt/hdf5/lib/libhdf5.10.dylib (compatibility version 13.0.0, current version 13.1.0)
	@rpath/libopencv_imgcodecs.3.2.dylib (compatibility version 3.2.0, current version 3.2.0)
	@rpath/libopencv_highgui.3.2.dylib (compatibility version 3.2.0, current version 3.2.0)
	@rpath/libopencv_imgproc.3.2.dylib (compatibility version 3.2.0, current version 3.2.0)
	@rpath/libopencv_core.3.2.dylib (compatibility version 3.2.0, current version 3.2.0)
	/usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1238.0.0)
	/usr/local/opt/boost/lib/libboost_filesystem.dylib (compatibility version 0.0.0, current version 0.0.0)
	/usr/local/opt/boost/lib/libboost_thread-mt.dylib (compatibility version 0.0.0, current version 0.0.0)
	/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib (compatibility version 1.0.0, current version 1.0.0)
	/usr/local/opt/boost-python/lib/libboost_python.dylib (compatibility version 0.0.0, current version 0.0.0)
	/System/Library/Frameworks/Python.framework/Versions/2.7/Python (compatibility version 2.7.0, current version 2.7.10)
	/usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 307.4.0)

when I check the opencv lib there doesn't exist this library.
Do I need to download that and install path?



### Your system configuration
Operating system: Mac OS sierra 10.12.3
[CMakeLists.txt](https://github.com/BVLC/caffe/files/752340/CMakeLists.txt)",,"['From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\r\n\r\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\r\nUse the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.', 'hi,i have the same problem .have you solved it ?', 'me too']",[],[],0,0
176,caffe,2455,closed,Compilation error when using caffe on Ubuntu 14.04,"I am trying to install and build Caffe along with its dependencies. After going through all the prerequisite when I run 'make all' I get this:
CXX src/caffe/net.cpp
In file included from src/caffe/net.cpp:8:0:
./include/caffe/common.hpp:5:27: fatal error: gflags/gflags.h: No such file or directory
 #include <gflags/gflags.h>
                           ^
compilation terminated.
make: **\* [.build_release/src/caffe/net.o] Error 1

Please help in resolving it.
",,['Please ask usage and installation questions on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) list. Thanks!\n'],[],[],0,0
177,caffe,3530,closed,error during make pycaffe,"It runs until

CXX src/caffe/solvers/sgd_solver.cpp

then fails with the following error:

In file included from src/caffe/solvers/sgd_solver.cpp:5:0:
./include/caffe/util/hdf5.hpp:6:18: fatal error: hdf5.h: No such file or directory
compilation terminated.
Makefile:552: recipe for target '.build_release/src/caffe/solvers/sgd_solver.o' failed
make: **\* [.build_release/src/caffe/solvers/sgd_solver.o] Error 1

Any ideas?
",,"[' FIX:\n\noseiskar commented on Jul 4, 2015\nTo get the build to pass on Debian Jessie, I had to (in addition to the above)\n\nmodify INCLUDE_DIRS in Makefile.config\n\nINCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial/\ncreate symlinks as instructed here\n\ncd /usr/lib/x86_64-linux-gnu\nsudo ln -s libhdf5_serial.so.8.0.2 libhdf5.so\nsudo ln -s libhdf5_serial_hl.so.8.0.2 libhdf5_hl.so\nWork around #337 by installing g++-4.6 from the Wheezy repo and adding to Makefile.config:\n\nCUSTOM_CXX := g++-4.6\n', 'for the error that comes after\n\nhttps://github.com/BVLC/caffe/issues/2690\n']",[],[],0,0
178,caffe,312,closed,Segmentation fault (core dumped) when training and CommonTest Failed,"Hi. I just train my model. It seems everything goes well. But when testing the net. it outputs Segmentation fault. I don't know what's the problem. Thanks.

I0410 19:44:32.296176 26997 solver.cpp:36] Solver scaffolding done.
I0410 19:44:32.296200 26997 solver.cpp:47] Solving CaffeNet
I0410 19:49:34.169067 26997 solver.cpp:208] Iteration 500, lr = 0.01
I0410 19:49:34.172401 26997 solver.cpp:65] Iteration 500, loss = 0
I0410 19:54:43.192100 26997 solver.cpp:208] Iteration 1000, lr = 0.01
I0410 19:54:43.195472 26997 solver.cpp:65] Iteration 1000, loss = 0
I0410 19:54:43.195485 26997 solver.cpp:87] Iteration 1000, Testing net
Segmentation fault (core dumped)
",downstream problem?,['#278 makes it easier to debug CUDA related failures. Please pull the latest code. Also check whether your problem is the same with #264.\n'],[],[],0,0
179,caffe,3078,closed,Problem creating LMDB from Matlab,"Hello,

I need to call the convert_imageset function for converting a database into LMDB format from inside Matlab. 

I am using Linux, and I have created a shell (.sh) script with the needed parameters for running the conversion. Here is an example of how does my shell file look like:

> GLOG_logtostderr=1 /usr/local/caffe-master2/build/tools/convert_imageset -resize_height=256 -resize_width=256 images_folder data_split/train.txt data_split/dataCNN_train_lmdb

When I simply run my script from the terminal like this:

> ./example_shell.sh

it works without any problem. 
But when I try to do it from Matlab using the system() function:

> system('./example_shell.sh')

it seems it is not able to open/find my files, rising the following error for each image in train.txt:

> I0917 18:15:13.637830  8605 convert_imageset.cpp:82] A total of 68175 images.
> I0917 18:15:13.638947  8605 db.cpp:34] Opened lmdb data_split/dataCNN_train_lmdb
> E0917 18:15:13.639143  8605 io.cpp:77] Could not open or find file ...
> E0917 18:15:13.639143  8605 io.cpp:77] Could not open or find file ...
> E0917 18:15:13.639143  8605 io.cpp:77] Could not open or find file ...

Thank you,
Marc
",,"['Please do not post usage, installation, or modeling questions, or other requests for help to Issues.\nUse the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
180,caffe,1160,closed,Can't run the tests in caffe-parallel version,"Hello!, every body.  I had tried to compile the parallel version of caffe, but I found that it can make all and make test, but can't run the make runtest. The error info is that error while loading shared libraries:libcudart.so.6.5: cannot open shared object file: No shuch file or directory. I had installed the cuDNN version caffe and common caffe, they are both ok and not appear this error. Can any expert help me? Thanks in advance!
",downstream problem?,"['Add /usr/local/cuda-6.5 to your LD_LIBRARY_PATH.\n\nPlease ask installation issue on caffe user mailing list: https://groups.google.com/forum/#!forum/caffe-users\n', 'The error still occurs, even though I run: make clean; make all; make test; make runtest. The former three command runs OK, but the forth stopped by that error:error while loading shared libraries:libcudart.so.6.5: cannot open shared object file: No shuch file or directory. And I followed your suggestion add the /usr/local/cuda-6.5 to your LD_LIBRARY_PATH by open the /etc/profile, after this I also run source /etc/profile to make this change works. But the error happen again, really strange!\n', 'Check for any Makefile differences between the parallel and dev branches and double-check your configuration.\n\nPlease ask installation questions on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) mailing list. Thanks!\n']",[],[],0,0
181,caffe,6279,closed,please delete,"please delete
",,[],[],[],0,0
182,caffe,4376,closed,make runtest error,"GTX970 Cuda7.0 cudnn4.0 opencv2.4.12
I don't know how to solve this problem!
**\* Aborted at 1467078048 (unix time) try ""date -d @1467078048"" if you are using GNU date ***
PC: @     0x2b3690e4b897 cudnnAddTensor
**\* SIGSEGV (@0x703105204) received by PID 31656 (TID 0x2b3682bce3c0) from PID 51401220; stack trace: ***
    @     0x2b3689a1f340 (unknown)
    @     0x2b3690e4b897 cudnnAddTensor
    @     0x2b3688de8463 caffe::CuDNNConvolutionLayer<>::Forward_gpu()
    @           0x48df76 caffe::Layer<>::Forward()
    @           0x93bd0f caffe::CuDNNConvolutionLayerTest_TestSimpleConvolutionCuDNN_Test<>::TestBody()
    @           0x9a4e53 testing::internal::HandleExceptionsInMethodIfSupported<>()
    @           0x99bb37 testing::Test::Run()
    @           0x99bbde testing::TestInfo::Run()
    @           0x99bce5 testing::TestCase::Run()
    @           0x99f028 testing::internal::UnitTestImpl::RunAllTests()
    @           0x99f2b7 testing::UnitTest::Run()
    @           0x473c7f main
    @     0x2b3689c4eec5 __libc_start_main
    @           0x47ca69 (unknown)
make: **\* [runtest] Segmentation fault (core dumped)
",,"['any people can help me?\n@_@\n', 'I met the same problem like you.Hope someone can help..\n', 'Having the same problem. Was anyone able to solve this one? \n', 'From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\r\n\r\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\r\nUse the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.']",[],[],0,0
183,caffe,1143,closed,Am I right ? when I use the cuDNN....,"I am a recruit, so I am sorry to my foolish question.
When I use the cuDNN to the Caffe-master, I get the same result without cuDNN.

My PC is i7-4770k and GTX 770, CUDA 6.5
The running time on MNIST is all 150s, and the cifar10_full is 62s / 1000 Iteration.

I set "" USE_CUDNN :=1"", and copy ""cudnn.h"" to ""/usr/local/include"", copy ""libcudnn.so, libcudnn.so.6.5, libcudnn.so.6.5.18, libcudnn_static.a"" to ""/usr/local/lib"".

Am I right? 
It seems not work.
Help me, thank you!
",,"['All questions about usage, installation, code, and applications should be searched for and asked on the [caffe-users mailing list](https://groups.google.com/forum/#!forum/caffe-users).\n', ""@bhack I am sorry, we can't visit most google site like www.google.com, docs.google, groups.google...in China for some unknown reason.\n"", ""You have to re-compile after setting the cuDNN switch:\n\n```\nmake clean\n```\n\n.   make\n\nto enable cuDNN.\n\nOn Tuesday, September 23, 2014, Xinyu Ou notifications@github.com wrote:\n\n> @bhack https://github.com/bhack I am sorry, we can't visit most google\n> site like www.google.com, docs.google, groups.google...in China for some\n> unknown reason.\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/1143#issuecomment-56519228.\n\n## \n\nEvan Shelhamer\n""]",[],[],0,0
184,caffe,4205,closed,Cmake regex error in dependencies with python 3,"Hi,

I am trying to build caffe with python 3.4 on ubuntu 14.04 but I keep having a issue with python : 

I installed : 
- OpenCV 3 with python 3 support (it worked nicely)
- Protobuf v3 beta

But still : 



and : 



I tried adding in ~/.bashrc : 



But it didn't work any better

Here is the full cmake log : 


",,['Solved my issue !\n\nUpgraded cmake 2.8 to 3.2\n'],"['\n-- Could NOT find PythonLibs (missing:  PYTHON_LIBRARIES PYTHON_INCLUDE_DIRS) (Required is at least version ""3.0"")\n', '\nCMake Error at cmake/Dependencies.cmake:117 (STRING):\n  string sub-command REGEX, mode REPLACE needs at least 6 arguments total to\n  command.\n', ' sh\nexport PYTHON_LIBRARIES=/usr/lib/x86_64-linux-gnu\nexport PYTHON_INCLUDE_DIRS=/usr/include/python3.4\n', ' sh\ncmake -DUSE_OPENCV=ON \\\n>           -DUSE_LMDB=ON \\\n>           -DUSE_LEVELDB=ON \\\n>           -Dpython_version=3 \\\n>           ..\n-- The C compiler identification is GNU 4.8.4\n-- The CXX compiler identification is GNU 4.8.4\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Boost version: 1.54.0\n-- Found the following Boost libraries:\n--   system\n--   thread\n--   filesystem\n-- Looking for include file pthread.h\n-- Looking for include file pthread.h - found\n-- Looking for pthread_create\n-- Looking for pthread_create - not found\n-- Looking for pthread_create in pthreads\n-- Looking for pthread_create in pthreads - not found\n-- Looking for pthread_create in pthread\n-- Looking for pthread_create in pthread - found\n-- Found Threads: TRUE\n-- Found GFlags: /usr/include\n-- Found gflags  (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libgflags.so)\n-- Found Glog: /usr/include\n-- Found glog    (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libglog.so)\n-- Found PROTOBUF: /usr/local/lib/libprotobuf.so\n-- Found PROTOBUF Compiler: /usr/local/bin/protoc\n-- Found HDF5: /usr/lib/x86_64-linux-gnu/libhdf5_hl.so;/usr/lib/x86_64-linux-gnu/libhdf5.so\n-- Found LMDB: /usr/include\n-- Found lmdb    (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/liblmdb.so)\n-- Found LevelDB: /usr/include\n-- Found LevelDB (include: /usr/include, library: /usr/lib/x86_64-linux-gnu/libleveldb.so)\n-- Found Snappy: /usr/include\n-- Found Snappy  (include: /usr/include, library: /usr/lib/libsnappy.so)\n-- CUDA detected: 7.5\n-- Found cuDNN: ver. 5.0.5 found (include: /usr/local/cuda-7.5/include, library: /usr/local/cuda-7.5/lib64/libcudnn.so)\n-- Added CUDA NVCC flags for: sm_30\n-- OpenCV found (/usr/local/share/OpenCV)\n-- Found Atlas: /usr/include\n-- Found Atlas (include: /usr/include, library: /usr/lib/libatlas.so)\n-- Found PythonInterp: /usr/bin/python3 (found suitable version ""3.4.3"", minimum required is ""3.0"")\n-- Could NOT find PythonLibs (missing:  PYTHON_LIBRARIES PYTHON_INCLUDE_DIRS) (Required is at least version ""3.0"")\n-- Found NumPy: /usr/lib/python3/dist-packages/numpy/core/include (found suitable version ""1.8.2"", minimum required is ""1.7.1"")\n-- NumPy ver. 1.8.2 found (include: /usr/lib/python3/dist-packages/numpy/core/include)\nCMake Error at cmake/Dependencies.cmake:117 (STRING):\n  string sub-command REGEX, mode REPLACE needs at least 6 arguments total to\n  command.\nCall Stack (most recent call first):\n  CMakeLists.txt:43 (include)\n\n\n-- Could NOT find Boost\n-- Boost version: 1.54.0\n-- Found the following Boost libraries:\n--   python\n-- Could NOT find Doxygen (missing:  DOXYGEN_EXECUTABLE)\n-- Python interface is disabled or not all required dependencies found. Building without it...\n-- Found Git: /usr/bin/git (found version ""1.9.1"")\n--\n-- ******************* Caffe Configuration Summary *******************\n-- General:\n--   Version           :   1.0.0-rc3\n--   Git               :   rc2-951-g234fcbe\n--   System            :   Linux\n--   C++ compiler      :   /usr/bin/c++\n--   Release CXX flags :   -O3 -DNDEBUG -fPIC -Wall -Wno-sign-compare -Wno-uninitialized\n--   Debug CXX flags   :   -g -fPIC -Wall -Wno-sign-compare -Wno-uninitialized\n--   Build type        :   Release\n--\n--   BUILD_SHARED_LIBS :   ON\n--   BUILD_python      :   ON\n--   BUILD_matlab      :   OFF\n--   BUILD_docs        :   ON\n--   CPU_ONLY          :   OFF\n--   USE_OPENCV        :   ON\n--   USE_LEVELDB       :   ON\n--   USE_LMDB          :   ON\n--   ALLOW_LMDB_NOLOCK :   OFF\n--\n-- Dependencies:\n--   BLAS              :   Yes (Atlas)\n--   Boost             :   Yes (ver. 1.54)\n--   glog              :   Yes\n--   gflags            :   Yes\n--   protobuf          :   Yes (ver. 3.0.0)\n--   lmdb              :   Yes (ver. 0.9.10)\n--   LevelDB           :   Yes (ver. 1.15)\n--   Snappy            :   Yes (ver. 1.1.0)\n--   OpenCV            :   Yes (ver. 3.1.0)\n--   CUDA              :   Yes (ver. 7.5)\n--\n-- NVIDIA CUDA:\n--   Target GPU(s)     :   Auto\n--   GPU arch(s)       :   sm_30\n--   cuDNN             :   Yes (ver. 5.0.5)\n--\n-- Documentaion:\n--   Doxygen           :   No\n--   config_file       :\n--\n-- Install:\n--   Install path      :   /home/ubuntu/py-faster-rcnn/caffe/build/install\n--\n-- Configuring incomplete, errors occurred!\n']",[],0,0
185,caffe,5910,closed,create_cifar10.sh: 13: create_cifar10.sh: ./build/examples/cifar10/convert_cifar_data.bin: not found,"Hello there! I was trying to run the cifar10 caffar10 example, the implementation of create_cifar10.sh regardless of the caffe directory or in the caffe / examples / cifar10 directory implementation, the system is always error: ./ build / examples / cifar10 / convert_cifar_data. bin: not found. Please help the big god to help doubts.
",,"['Have you compiled caffe tools (`make tools`)?\r\n\r\nPlease use the [caffe-users list][1] for usage, installation, or modeling questions, or other requests for help.\r\nYou may also post questions on [stackoverflow][3], make sure you tag them with `caffe` tag.  \r\nDo not post such requests to Issues. Doing so interferes with the development of Caffe.\r\n\r\nPlease read the [guidelines for contributing][2] before submitting this issue.\r\n\r\n [1]: https://groups.google.com/forum/#!forum/caffe-users\r\n [2]: https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md\r\n [3]: http://stackoverflow.com/questions/tagged/caffe']",[],[],0,0
186,caffe,6311,closed,failed to make all,"
### Your system configuration
Operating system:ubuntu16.04
Compiler:
CUDA version (if applicable):8.0
CUDNN version (if applicable):7.0.5
BLAS:
Python or MATLAB version (for pycaffe and matcaffe respectively):2.7(anaconda3)


Hope somebody could help me.Thank you!",,"['This issue has appeared on [CUDA developer forum](https://devtalk.nvidia.com/default/topic/1025801/cuda-setup-and-installation/cudnn-test-did-not-pass/) with a solution - have you tried it? Did it work for you?', 'Closing as abandoned. If the issue persists, please reopen with a status update.', 'Had the same problem, and it did work using the CUDA developer forum solution.']","[""\r\nCXX src/caffe/util/cudnn.cpp\r\nIn file included from /usr/local/cuda/include/channel_descriptor.h:62:0,\r\n                 from /usr/local/cuda/include/cuda_runtime.h:90,\r\n                 from /usr/include/cudnn.h:64,\r\n                 from ./include/caffe/util/cudnn.hpp:5,\r\n                 from src/caffe/util/cudnn.cpp:2:\r\n/usr/local/cuda/include/cuda_runtime_api.h:1628:101: error: use of enum cudaDeviceP2PAttr without previous declaration\r\n extern __host__ __cudart_builtin__ cudaError_t CUDARTAPI cudaDeviceGetP2PAttribute(int *value, enum cudaDeviceP2PAttr attr, int srcDevice, int dstDevice);\r\n                                                                                                     ^\r\nIn file included from /usr/local/cuda/include/channel_descriptor.h:62:0,\r\n                 from /usr/local/cuda/include/cuda_runtime.h:90,\r\n                 from /usr/include/cudnn.h:64,\r\n                 from ./include/caffe/util/cudnn.hpp:5,\r\n                 from src/caffe/util/cudnn.cpp:2:\r\n/usr/local/cuda/include/cuda_runtime_api.h:5382:92: error: use of enum cudaMemoryAdvise without previous declaration\r\n extern __host__ cudaError_t CUDARTAPI cudaMemAdvise(const void *devPtr, size_t count, enum cudaMemoryAdvise advice, int device);\r\n                                                                                            ^\r\n/usr/local/cuda/include/cuda_runtime_api.h:5438:98: error: use of enum cudaMemRangeAttribute without previous declaration\r\n extern __host__ cudaError_t CUDARTAPI cudaMemRangeGetAttribute(void *data, size_t dataSize, enum cudaMemRangeAttribute attribute, const void *devPtr, size_t count);\r\n                                                                                                  ^\r\n/usr/local/cuda/include/cuda_runtime_api.h:5474:102: error: use of enum cudaMemRangeAttribute without previous declaration\r\n extern __host__ cudaError_t CUDARTAPI cudaMemRangeGetAttributes(void **data, size_t *dataSizes, enum cudaMemRangeAttribute *attributes, size_t numAttributes, const void *devPtr, size_t count);\r\n                                                                                                      ^\r\nMakefile:582: recipe for target '.build_release/src/caffe/util/cudnn.o' failed\r\nmake: *** [.build_release/src/caffe/util/cudnn.o] Error 1\r\nmake: *** Waiting for unfinished jobs....\r\n""]",[],0,0
187,caffe,3546,closed,Caffe Crashes when HDF5 data used on multi GPU system.,"Sorry false issue. 
",,['@ashwinnair14 \r\nI happened the same issue. How do you solve the issue?'],[],[],0,0
188,caffe,3667,closed,caffe.Classifier() and caffe.Net() have different class predictions for same image?,"Is there a difference in the way the predictions work in the case of caffe.Classifier() and caffe.Net()? I have an image (linked below) that when run in the caffe-example (classification.ipynb) gives a prediction of class 287 (net.predict([img]).argmax()). However, if I use this image in the another example (filter_visualization.ipynb) the class probabilites (net.blobs['prob'].argmax()) comes out to be 2! Is there something trivial that I am missing or this really shouldn't be happening? Which of these is the correct classification if at all one is correct (I have tweaked the cat image a little bit to see what are the effects on classification)?

I am using the bvlc_reference_caffenet.caffemodel and the corresponding deploy.prototxt with the imagenet mean image provided in caffe as default (ilsvrc12). 

Sample cat image : ![advr_out](https://cloud.githubusercontent.com/assets/5744373/13016016/419b72b0-d1e2-11e5-9019-2a1791c56ad4.jpg)
",,"['Yes, the two are very different, and you should expect different answers.  Look at the code -- `Classifier.predict` does oversampling and calls `Net.forward_all`:  https://github.com/BVLC/caffe/blob/master/python/caffe/classifier.py#L47\n\nAlso, in the future please ask for usage help on the mailing list.  From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
189,caffe,2566,closed,caffe make error,"I get the following errors when doing make all in Caffe. I have these packages installed already.
/usr/bin/ld: cannot find -lleveldb
/usr/bin/ld: cannot find -lsnappy
/usr/bin/ld: cannot find -lboost_system
Any suggestions will be helpful,
Thanks
LM
",,['Please ask usage and installation questions on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) list. Thanks!\n'],[],[],0,0
190,caffe,3246,closed,[test] support several types of TEST input at one prototxt model,"Hi,

I am new to CAFFE. For training phase, it makes sense that only one type is supported. Because we mostly pre-process the training images. But for testing phase, sometimes we want to validate ImageNet accuracy, and this is suitable for ""data"" input. Sometimes, I also want to use the same prototxt model to predict one single raw image, and this needs the input type is ""imagedata"". 

I know Pycaffe can easily handle this, which is shown in the 00-example. I don't know whether CPP interface already supports this. Otherwise, I would like to modify caffe.cpp to support this. My idea is to add another input TEST layer in the prototxt model.  And Only one input layer is selected by command line.Or maybe you guys have better solutions? :) 

Thanks a lot in advance.  
",,"['Closing as this looks like a request for help.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
191,caffe,3833,closed,The bias is not learnt in the 1x1 conv layer,"Hi there,

I don't whether I make a mistake or not, I found that the bias in the 1x1 conv layer is not learnt (which is exactly the initialization value) in the latest version of caffe, even if I double check that the second mult_lr is set as 2.0 in my prototxt. Could anyone help to load their google net and check the bias value of some 1x1 layers, such as ""conv2/3x3_reduce""? Apologize if I make something wrong. :)
",,"[""- I'm not sure I understand the problem.  You're saying that the gradient for a layer is nonzero and yet the weights are never updated?  Is the update (gradient \\* learning rate) large enough to make a difference? (e.g. adding 1e-400 to a value won't change it)\n- Can you provide a minimal failing example?  That is, the simplest possible setup that shows the issue?\n""]",[],[],0,0
192,caffe,2661,closed,Specify Per Layer CPU or GPU,"Is there a way to specify a specific layer to run on the cpu rather than the gpu, but still let the other layers run on the gpu? I'm trying to run SoftmaxWithLossLayer on the cpu since we are getting issues with running it on the gpu. It would be a nice feature to have if it doesn't exist already.
",,['Per-layer device placement is not currently possible nor planned but see #1500 for a gradual diffusion of mode and device.'],[],[],0,0
193,caffe,2506,closed,Pretrain a model using caffe,"Hello guys, I wanna ask can I use caffe to pretrain a model, and then use the papameters of this model to initialize another model ?
If it can, can anyone teach me how to do it? Thank you.
",,['This tracker is for issues and bugs with Caffe. Please ask usage questions on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) list. Thanks!\n'],[],[],0,0
194,caffe,2362,closed,Caffe and CUDA 1.1,"Hi,

I have an older  MacBook Pro (2009) with:
NVIDIA GeForce 9600M GT
NVIDIA GeForce 9400M
CUDA Driver Version: 6.5.14

Mathematica, Matlab,  and Theano can't use the GPU.
I've read that cuDNN requires CUDA 3.0 (or greater).
Can Caffe run with CUDA 1.1?

Thanks in advance!
",,['Please ask hardware questions on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) group and see the [hardware section of the installation guide](http://caffe.berkeleyvision.org/installation.html#hardware).\n'],[],[],0,0
195,caffe,2584,closed,Unit-Tests do not use custom parameters,"Running



in  makes no difference.
",,"['Right. That issue was discussed in [1938](https://github.com/BVLC/caffe/issues/1938) and before that in [1355](https://github.com/BVLC/caffe/pull/1355). We should be using \n\n```\nCHECK(google::protobuf::TextFormat::ParseFromString(""mvn_param{normalize_variance: false}"", &layer_param));\n```\n\ninstead. In the code you show, LayerParameter::ParseFromString is failing but the failure goes undetected since we ignore the return value. I think it fails because it expects a binary-serialized object as its argument. \n\nIf you change to using the correct ParseFromString, you will see a number of the MvnLayer tests are failing. I think [PR 1979](https://github.com/BVLC/caffe/pull/1979) fixes those problems.\n', 'This seems to be a general problem in each unit test for each layer using `ParseFromString`.\nIt does not expect a binary-serialized object. Its definition is:\n\n```\n ParseFromString(const string & input, Message * output)\n```\n', ""> This seems to be a general problem in each unit test for each layer using ParseFromString.\n\nThe only test that doesn't use `TextFormat::ParseFromString` is `MVNLayerTest`. So I don't think it is a general problem. DBTest also uses Message::ParseFromString but its usage is correct because it is parsing a binarized protobuff message.\n\n> It does not expect a binary-serialized object. \n\nThe member function Message::ParseFromString expects a binarized message. The string `input` is a buffer for it. Static function TextFormat::ParseFromString is the one that parses human-readable message.\n""]","['\nLayerParameter layer_param;\nlayer_param.ParseFromString(""mvn_param{normalize_variance: false}"");\nstd::cout << layer_param.mvn_param().normalize_variance()<<std::endl;\nLayerParameter layer_param2;\nlayer_param2.ParseFromString(""mvn_param{normalize_variance: true}"");\nstd::cout << layer_param2.mvn_param().normalize_variance()<<std::endl;\n']",['src/caffe/test/test_mvn_layer.cpp'],0,0
196,caffe,849,closed,How to resume training ImageNet model?,"I wanna know how to resume training ImageNet model with ""caffe_reference_imagenet_model"". As far as I am concert, to resume training needs the *.solverstate file not a model file.
Could I download the  ""caffe_reference_imagenet_model.solverstate"" somewhere?
Or how to transform "" caffe_reference_imagenet_model"" to  "" caffe_reference_imagenet_model.solverstate""?
",question,"['It looks like issue #607 will get me a favor.\n', 'You can either resume training by a solver state or finetune a model from pretrained weights.\n']",[],[],0,0
197,caffe,284,closed,Non-square inputs - tested and supported?,"Has this system been tested on inputs that have unequal width and height?  If I use the provided DataLayer with both mirroring and cropping disabled on portrait inputs, the first convolution layer quickly tends towards (usually within the first 500 iterations) a set of filters with horizontal bands.  Sometimes the loss goes to nan (and many of the parameters in the first convolution layer have gone to nan).

I wrote a separate data layer that replaces cropsize with crop_height and crop_width so that I could manually specify a rectangular crop.  I've tried setting crop_height == crop_width and so far the issue hasn't shown up, but I haven't spent much time training (but still much longer than the rectangular cases).  If I set the aspect ratio to something other than 1, then the bands do appear and their width seems to depend on the aspect ratio of the crop.

I'm using the imagenet architecture applied to a different dataset.  The inputs from leveldb are 264x105x3 and the cropped inputs to the network are 220x88x3.

The issue is reproducible with both solver mode 0 and 1.
",bug,"['The loss sometimes becomes nan when the samples in a mini-batch are of the same class. Enabling data shuffling to make the batches as diverse as possible would prevent this.\n\nThe ImageDataLayer automatically resizes the input images to be square. An example of it can be found in `example/feature_extraction/imagenet_val.prototxt`.\n\n```\nlayers {\n  name: ""data""\n  type: IMAGE_DATA\n  top: ""data""\n  top: ""label""\n  image_data_param {\n    source: ""$CAFFE_DIR/examples/_temp/file_list.txt""\n    mean_file: ""$CAFFE_DIR/data/ilsvrc12/imagenet_mean.binaryproto""\n    batch_size: 50\n    crop_size: 227\n    mirror: false\n    new_height: 256\n    new_width: 256\n    shuffle: true\n  }\n}\n```\n', 'https://github.com/kmatzen/caffe/blob/master/src/caffe/util/im2col.cu#L32\n\nI think someone swapped height and width on this bounds check.\n\n```\n*data_col = (h >= 0 && w >= 0 && h < width && w < height) ?\n            data_im[i * width + j] : 0;\n```\n', ""Oh wow, nice find.  I don't know of anybody spending much time doing things with non-square inputs so it's not altogether shocking we have a bug (being optimistic with my use of the singular).  Please do send a PR with the fix if you get a chance.  @shelhamer we may want to fix this in master?\n\n(Also got scared because git blame points to my massive lint change but the diff shows that bug was there already, whew.)\n"", 'Agreed on PR to `master` or at least cherry-picking the bug fix. This is a specific fix without side effects, so straight to master it goes.\n\nThanks for the find @kmatzen!\n', 'Fixed in `dev` by #298 and fix cherry-picked to master in https://github.com/BVLC/caffe/commit/5528f5e.\n']",[],[],0,0
198,caffe,4067,closed,Does the new release verify the MultiGPU Caffe?,"The new release of multiGPU Caffe may not correct. But it is quite different from NVCaffe.
",,"['Can you be more specific?\n', ""Maybe the information you're looking for is the fact that NVcaffe uses strong scaling for multi-GPU training, whereas BVLC/Caffe uses weak scaling. We divide the batch size by the number of GPUs.\n\nPull request: https://github.com/NVIDIA/caffe/pull/78\nRelease notes: https://github.com/NVIDIA/caffe/releases/tag/v0.14.0-rc.3\n"", 'This is another minor bug hidden inside the forwardbackward. it is fixed now.\n']",[],[],0,0
199,caffe,3727,closed,No non-linearity after conv layers in MNIST example,"Could it be that there is a mistake in the MNIST example: https://github.com/BVLC/caffe/blob/master/examples/mnist/lenet_train_test.prototxt . 

The conv layers are not followed by any non-linearities. In the original paper they were followed by sigmoids. 

In this tutorial here http://caffe.berkeleyvision.org/gathered/examples/mnist.html, it is written that the sigmoids are replaced by ReLUs. However, there is only one ReLU after the FC layer. 

What is even more confusing to me, is that the network without the non-linearities still seems to perform extremely well on the classification... Any idea why that is? 
",,"['Max pooling is nonlinear.\n', 'In general, please ask modeling questions on the mailing list. From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
200,caffe,5680,closed,Problem in training process,"After hundreds iterations,it crashed.And the nvidia-smi reveal ""The GPU is lost.Reboot the system to recover the GPU"",and this situation just happened when I use the hdf5 data to train model.
",,"[""Please post usage, installation, or modeling questions, or other requests for help to the [caffe-users list][1] instead of Issues. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe. Please read the [guidelines for contributing][2] before submitting an issue or a pull request.\r\n\r\nWhen describing your issue, please give us more information to work with. Are you using the newest release of Caffe (or if not - which version is it), what's your software/hardware configuration, what network are you running, what exact error message are you getting etc.\r\n\r\n [1]: https://groups.google.com/forum/#!forum/caffe-users\r\n [2]: https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md""]",[],[],0,0
201,caffe,1127,closed,pretrained imagnet model: not doing cropping and reflections at test time,"Hi, good job, I'm a big fan.

I'm using the pretrained CaffeNet model. **At test time** I don't want the model to do the 10 different cropping and reflections. I only want the model to scale my image to 224 x 224 and compute the result. (I will then pickup the  features.)

Is there a way to do this without retraining?
",question,"[""Usage questions should be asked on the [caffe-users mailing list](https://groups.google.com/forum/#!forum/caffe-users) and not posted as Issues, which are for development.\n\nRunning the net on the image without oversampling is trivial through data layer configuration like [caffenet's TEST data layer](https://github.com/BVLC/caffe/blob/master/models/bvlc_reference_caffenet/train_val.prototxt#L18-L32) or our matlab and python wrappers.\n""]",[],['fc7'],0,0
202,caffe,3142,closed,src/caffe/data_transformer.cpp:229: error: invalid use of incomplete type const struct cv::Mat,,,"[""Closing as this is not a coherent report of an issue. If you think there is a bug in `master` Caffe, you're welcome to open a new issue explaining how to reproduce it. See our [contributing guide](https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md).\n\nThanks!\n""]",[],[],0,0
203,caffe,4462,closed,Nondeterministic crashes with PythonLayer,"When I run my network with a simple dummy Python layer it terminates after some hundred cycles. The displayed errors always point into cuda code. This error occured after i changed the label size from a large size (1x480x640) to (1x1x1).

Some system information:













[reproduce.zip](https://github.com/BVLC/caffe/files/364050/reproduce.zip)
[fail.txt](https://github.com/BVLC/caffe/files/364052/fail.txt)
",,['After further investigation it seems to be a problem with Cuda 7.5. Cuda 7.0 runs stable without any errors/crashes.\n'],"['\n$ nvcc --version\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2015 NVIDIA Corporation\nBuilt on Tue_Aug_11_14:27:32_CDT_2015\nCuda compilation tools, release 7.5, V7.5.17\n', '\n$ nvidia-smi\nThu Jul 14 16:52:34 2016       \n+------------------------------------------------------+                       \n| NVIDIA-SMI 352.93     Driver Version: 352.93         |                       \n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX TITAN   Off  | 0000:01:00.0      On |                  N/A |\n| 56%   79C    P0   142W / 250W |    209MiB /  6140MiB |     96%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1460    G   /usr/bin/X                                      48MiB |\n|    0     19677    C   /home/jvosteen/caffe/build/tools/caffe.bin     143MiB |\n+-----------------------------------------------------------------------------+\n', '\n$ git rev-parse HEAD\nc2a1ecd4b2362db5f77fb9bf574d3770f0204a54\n', ""\n$ git status \nOn branch master\nYour branch is up-to-date with 'origin/master'.\n\nnothing to commit, working directory clean\n"", '\n$ ldd ~/caffe/build/tools/caffe.bin \n    linux-vdso.so.1 =>  (0x00007fffeb970000)\n    libcaffe.so.1.0.0-rc3 => /home/jvosteen/caffe/build/tools/../lib/libcaffe.so.1.0.0-rc3 (0x00007fe19dddc000)\n    libcudart.so.7.5 => /usr/local/cuda-7.5/lib64/libcudart.so.7.5 (0x00007fe19db7e000)\n    libglog.so.0 => /usr/lib/x86_64-linux-gnu/libglog.so.0 (0x00007fe19d946000)\n    libgflags.so.2 => /usr/lib/x86_64-linux-gnu/libgflags.so.2 (0x00007fe19d726000)\n    libprotobuf.so.8 => /usr/lib/x86_64-linux-gnu/libprotobuf.so.8 (0x00007fe19d424000)\n    libboost_system.so.1.54.0 => /usr/lib/x86_64-linux-gnu/libboost_system.so.1.54.0 (0x00007fe19d220000)\n    libstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007fe19cf1c000)\n    libboost_python-py27.so.1.54.0 => /usr/lib/x86_64-linux-gnu/libboost_python-py27.so.1.54.0 (0x00007fe19cccf000)\n    libpython2.7.so.1.0 => /usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0 (0x00007fe19c76b000)\n    libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007fe19c555000)\n    libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007fe19c190000)\n    libcublas.so.7.5 => /usr/local/cuda-7.5/lib64/libcublas.so.7.5 (0x00007fe19a8b1000)\n    libcurand.so.7.5 => /usr/local/cuda-7.5/lib64/libcurand.so.7.5 (0x00007fe197049000)\n    libhdf5_hl.so.7 => /usr/lib/x86_64-linux-gnu/libhdf5_hl.so.7 (0x00007fe196e19000)\n    libhdf5.so.7 => /usr/lib/x86_64-linux-gnu/libhdf5.so.7 (0x00007fe19697d000)\n    libleveldb.so.1 => /usr/lib/x86_64-linux-gnu/libleveldb.so.1 (0x00007fe196730000)\n    liblmdb.so.0 => /usr/lib/x86_64-linux-gnu/liblmdb.so.0 (0x00007fe19651e000)\n    libopencv_core.so.2.4 => /usr/lib/x86_64-linux-gnu/libopencv_core.so.2.4 (0x00007fe1960e7000)\n    libopencv_highgui.so.2.4 => /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4 (0x00007fe195e9c000)\n    libopencv_imgproc.so.2.4 => /usr/lib/x86_64-linux-gnu/libopencv_imgproc.so.2.4 (0x00007fe195a0c000)\n    libboost_thread.so.1.54.0 => /usr/lib/x86_64-linux-gnu/libboost_thread.so.1.54.0 (0x00007fe1957f6000)\n    libcudnn.so.5 => /usr/lib/x86_64-linux-gnu/libcudnn.so.5 (0x00007fe191cab000)\n    libcblas.so.3 => /usr/lib/libcblas.so.3 (0x00007fe191a8a000)\n    libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007fe191784000)\n    libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fe191566000)\n    libdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007fe191362000)\n    librt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007fe19115a000)\n    libunwind.so.8 => /usr/lib/x86_64-linux-gnu/libunwind.so.8 (0x00007fe190f3f000)\n    libz.so.1 => /lib/x86_64-linux-gnu/libz.so.1 (0x00007fe190d26000)\n    /lib64/ld-linux-x86-64.so.2 (0x00007fe19ebfa000)\n    libutil.so.1 => /lib/x86_64-linux-gnu/libutil.so.1 (0x00007fe190b23000)\n    libsnappy.so.1 => /usr/lib/libsnappy.so.1 (0x00007fe19091d000)\n    libGL.so.1 => /usr/lib/nvidia-352/libGL.so.1 (0x00007fe1905ed000)\n    libtbb.so.2 => /usr/lib/libtbb.so.2 (0x00007fe1903b9000)\n    libjpeg.so.8 => /usr/lib/x86_64-linux-gnu/libjpeg.so.8 (0x00007fe190164000)\n    libpng12.so.0 => /lib/x86_64-linux-gnu/libpng12.so.0 (0x00007fe18ff3e000)\n    libtiff.so.5 => /usr/lib/x86_64-linux-gnu/libtiff.so.5 (0x00007fe18fccc000)\n    libjasper.so.1 => /usr/lib/x86_64-linux-gnu/libjasper.so.1 (0x00007fe18fa75000)\n    libIlmImf.so.6 => /usr/lib/x86_64-linux-gnu/libIlmImf.so.6 (0x00007fe18f7c6000)\n    libHalf.so.6 => /usr/lib/x86_64-linux-gnu/libHalf.so.6 (0x00007fe18f583000)\n    libgtk-x11-2.0.so.0 => /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0 (0x00007fe18ef46000)\n    libgdk-x11-2.0.so.0 => /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0 (0x00007fe18ec93000)\n    libgobject-2.0.so.0 => /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0 (0x00007fe18ea42000)\n    libglib-2.0.so.0 => /lib/x86_64-linux-gnu/libglib-2.0.so.0 (0x00007fe18e73a000)\n    libgtkglext-x11-1.0.so.0 => /usr/lib/libgtkglext-x11-1.0.so.0 (0x00007fe18e536000)\n    libgdkglext-x11-1.0.so.0 => /usr/lib/libgdkglext-x11-1.0.so.0 (0x00007fe18e2d2000)\n    libdc1394.so.22 => /usr/lib/x86_64-linux-gnu/libdc1394.so.22 (0x00007fe18e05e000)\n    libv4l1.so.0 => /usr/lib/x86_64-linux-gnu/libv4l1.so.0 (0x00007fe18de58000)\n    libavcodec.so.54 => /usr/lib/x86_64-linux-gnu/libavcodec.so.54 (0x00007fe18d104000)\n    libavformat.so.54 => /usr/lib/x86_64-linux-gnu/libavformat.so.54 (0x00007fe18cde2000)\n    libavutil.so.52 => /usr/lib/x86_64-linux-gnu/libavutil.so.52 (0x00007fe18cbbd000)\n    libswscale.so.2 => /usr/lib/x86_64-linux-gnu/libswscale.so.2 (0x00007fe18c976000)\n    libatlas.so.3 => /usr/lib/libatlas.so.3 (0x00007fe18c3e3000)\n    libgfortran.so.3 => /usr/lib/x86_64-linux-gnu/libgfortran.so.3 (0x00007fe18c0c9000)\n    liblzma.so.5 => /lib/x86_64-linux-gnu/liblzma.so.5 (0x00007fe18bea7000)\n    libnvidia-tls.so.352.93 => /usr/lib/nvidia-352/tls/libnvidia-tls.so.352.93 (0x00007fe18bca4000)\n    libnvidia-glcore.so.352.93 => /usr/lib/nvidia-352/libnvidia-glcore.so.352.93 (0x00007fe189210000)\n    libX11.so.6 => /usr/lib/x86_64-linux-gnu/libX11.so.6 (0x00007fe188edb000)\n    libXext.so.6 => /usr/lib/x86_64-linux-gnu/libXext.so.6 (0x00007fe188cc9000)\n    libjbig.so.0 => /usr/lib/x86_64-linux-gnu/libjbig.so.0 (0x00007fe188abb000)\n    libIex.so.6 => /usr/lib/x86_64-linux-gnu/libIex.so.6 (0x00007fe18889d000)\n    libIlmThread.so.6 => /usr/lib/x86_64-linux-gnu/libIlmThread.so.6 (0x00007fe188697000)\n    libgmodule-2.0.so.0 => /usr/lib/x86_64-linux-gnu/libgmodule-2.0.so.0 (0x00007fe188493000)\n    libpangocairo-1.0.so.0 => /usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so.0 (0x00007fe188286000)\n    libXfixes.so.3 => /usr/lib/x86_64-linux-gnu/libXfixes.so.3 (0x00007fe188080000)\n    libatk-1.0.so.0 => /usr/lib/x86_64-linux-gnu/libatk-1.0.so.0 (0x00007fe187e5e000)\n    libcairo.so.2 => /usr/lib/x86_64-linux-gnu/libcairo.so.2 (0x00007fe187b53000)\n    libgdk_pixbuf-2.0.so.0 => /usr/lib/x86_64-linux-gnu/libgdk_pixbuf-2.0.so.0 (0x00007fe187932000)\n    libgio-2.0.so.0 => /usr/lib/x86_64-linux-gnu/libgio-2.0.so.0 (0x00007fe1875bf000)\n    libpangoft2-1.0.so.0 => /usr/lib/x86_64-linux-gnu/libpangoft2-1.0.so.0 (0x00007fe1873aa000)\n    libpango-1.0.so.0 => /usr/lib/x86_64-linux-gnu/libpango-1.0.so.0 (0x00007fe18715d000)\n    libfontconfig.so.1 => /usr/lib/x86_64-linux-gnu/libfontconfig.so.1 (0x00007fe186f21000)\n    libXrender.so.1 => /usr/lib/x86_64-linux-gnu/libXrender.so.1 (0x00007fe186d17000)\n    libXinerama.so.1 => /usr/lib/x86_64-linux-gnu/libXinerama.so.1 (0x00007fe186b14000)\n    libXi.so.6 => /usr/lib/x86_64-linux-gnu/libXi.so.6 (0x00007fe186904000)\n    libXrandr.so.2 => /usr/lib/x86_64-linux-gnu/libXrandr.so.2 (0x00007fe1866fa000)\n    libXcursor.so.1 => /usr/lib/x86_64-linux-gnu/libXcursor.so.1 (0x00007fe1864f0000)\n    libXcomposite.so.1 => /usr/lib/x86_64-linux-gnu/libXcomposite.so.1 (0x00007fe1862ed000)\n    libXdamage.so.1 => /usr/lib/x86_64-linux-gnu/libXdamage.so.1 (0x00007fe1860ea000)\n    libffi.so.6 => /usr/lib/x86_64-linux-gnu/libffi.so.6 (0x00007fe185ee2000)\n    libpcre.so.3 => /lib/x86_64-linux-gnu/libpcre.so.3 (0x00007fe185ca4000)\n    libGLU.so.1 => /usr/lib/x86_64-linux-gnu/libGLU.so.1 (0x00007fe185a36000)\n    libXmu.so.6 => /usr/lib/x86_64-linux-gnu/libXmu.so.6 (0x00007fe18581d000)\n    libpangox-1.0.so.0 => /usr/lib/x86_64-linux-gnu/libpangox-1.0.so.0 (0x00007fe1855fe000)\n    libraw1394.so.11 => /usr/lib/x86_64-linux-gnu/libraw1394.so.11 (0x00007fe1853f0000)\n    libusb-1.0.so.0 => /lib/x86_64-linux-gnu/libusb-1.0.so.0 (0x00007fe1851d9000)\n    libv4l2.so.0 => /usr/lib/x86_64-linux-gnu/libv4l2.so.0 (0x00007fe184fcb000)\n    libxvidcore.so.4 => /usr/lib/x86_64-linux-gnu/libxvidcore.so.4 (0x00007fe184c8d000)\n    libx264.so.142 => /usr/lib/x86_64-linux-gnu/libx264.so.142 (0x00007fe1848f7000)\n    libvpx.so.1 => /usr/lib/x86_64-linux-gnu/libvpx.so.1 (0x00007fe184518000)\n    libvorbisenc.so.2 => /usr/lib/x86_64-linux-gnu/libvorbisenc.so.2 (0x00007fe184049000)\n    libvorbis.so.0 => /usr/lib/x86_64-linux-gnu/libvorbis.so.0 (0x00007fe183e1c000)\n    libtheoraenc.so.1 => /usr/lib/x86_64-linux-gnu/libtheoraenc.so.1 (0x00007fe183bdc000)\n    libtheoradec.so.1 => /usr/lib/x86_64-linux-gnu/libtheoradec.so.1 (0x00007fe1839c3000)\n    libspeex.so.1 => /usr/lib/x86_64-linux-gnu/libspeex.so.1 (0x00007fe1837aa000)\n    libschroedinger-1.0.so.0 => /usr/lib/x86_64-linux-gnu/libschroedinger-1.0.so.0 (0x00007fe1834e6000)\n    libopus.so.0 => /usr/lib/x86_64-linux-gnu/libopus.so.0 (0x00007fe18329e000)\n    libopenjpeg.so.2 => /usr/lib/x86_64-linux-gnu/libopenjpeg.so.2 (0x00007fe18307c000)\n    libmp3lame.so.0 => /usr/lib/x86_64-linux-gnu/libmp3lame.so.0 (0x00007fe182def000)\n    libgsm.so.1 => /usr/lib/x86_64-linux-gnu/libgsm.so.1 (0x00007fe182be1000)\n    libva.so.1 => /usr/lib/x86_64-linux-gnu/libva.so.1 (0x00007fe1829cb000)\n    librtmp.so.0 => /usr/lib/x86_64-linux-gnu/librtmp.so.0 (0x00007fe1827b1000)\n    libgnutls.so.26 => /usr/lib/x86_64-linux-gnu/libgnutls.so.26 (0x00007fe1824f3000)\n    libbz2.so.1.0 => /lib/x86_64-linux-gnu/libbz2.so.1.0 (0x00007fe1822e3000)\n    libquadmath.so.0 => /usr/lib/x86_64-linux-gnu/libquadmath.so.0 (0x00007fe1820a7000)\n    libxcb.so.1 => /usr/lib/x86_64-linux-gnu/libxcb.so.1 (0x00007fe181e88000)\n    libfreetype.so.6 => /usr/lib/x86_64-linux-gnu/libfreetype.so.6 (0x00007fe181be5000)\n    libpixman-1.so.0 => /usr/lib/x86_64-linux-gnu/libpixman-1.so.0 (0x00007fe18193d000)\n    libxcb-shm.so.0 => /usr/lib/x86_64-linux-gnu/libxcb-shm.so.0 (0x00007fe18173a000)\n    libxcb-render.so.0 => /usr/lib/x86_64-linux-gnu/libxcb-render.so.0 (0x00007fe181531000)\n    libselinux.so.1 => /lib/x86_64-linux-gnu/libselinux.so.1 (0x00007fe18130e000)\n    libresolv.so.2 => /lib/x86_64-linux-gnu/libresolv.so.2 (0x00007fe1810f3000)\n    libharfbuzz.so.0 => /usr/lib/x86_64-linux-gnu/libharfbuzz.so.0 (0x00007fe180e9e000)\n    libthai.so.0 => /usr/lib/x86_64-linux-gnu/libthai.so.0 (0x00007fe180c95000)\n    libexpat.so.1 => /lib/x86_64-linux-gnu/libexpat.so.1 (0x00007fe180a6b000)\n    libXt.so.6 => /usr/lib/x86_64-linux-gnu/libXt.so.6 (0x00007fe180805000)\n    libudev.so.1 => /lib/x86_64-linux-gnu/libudev.so.1 (0x00007fe1805f4000)\n    libv4lconvert.so.0 => /usr/lib/x86_64-linux-gnu/libv4lconvert.so.0 (0x00007fe18037b000)\n    libogg.so.0 => /usr/lib/x86_64-linux-gnu/libogg.so.0 (0x00007fe180172000)\n    liborc-0.4.so.0 => /usr/lib/x86_64-linux-gnu/liborc-0.4.so.0 (0x00007fe17fef0000)\n    libgcrypt.so.11 => /lib/x86_64-linux-gnu/libgcrypt.so.11 (0x00007fe17fc70000)\n    libtasn1.so.6 => /usr/lib/x86_64-linux-gnu/libtasn1.so.6 (0x00007fe17fa5c000)\n    libp11-kit.so.0 => /usr/lib/x86_64-linux-gnu/libp11-kit.so.0 (0x00007fe17f81a000)\n    libXau.so.6 => /usr/lib/x86_64-linux-gnu/libXau.so.6 (0x00007fe17f616000)\n    libXdmcp.so.6 => /usr/lib/x86_64-linux-gnu/libXdmcp.so.6 (0x00007fe17f410000)\n    libgraphite2.so.3 => /usr/lib/x86_64-linux-gnu/libgraphite2.so.3 (0x00007fe17f1ea000)\n    libdatrie.so.1 => /usr/lib/x86_64-linux-gnu/libdatrie.so.1 (0x00007fe17efe3000)\n    libSM.so.6 => /usr/lib/x86_64-linux-gnu/libSM.so.6 (0x00007fe17eddb000)\n    libICE.so.6 => /usr/lib/x86_64-linux-gnu/libICE.so.6 (0x00007fe17ebbf000)\n    libcgmanager.so.0 => /lib/x86_64-linux-gnu/libcgmanager.so.0 (0x00007fe17e9a4000)\n    libnih.so.1 => /lib/x86_64-linux-gnu/libnih.so.1 (0x00007fe17e78c000)\n    libnih-dbus.so.1 => /lib/x86_64-linux-gnu/libnih-dbus.so.1 (0x00007fe17e582000)\n    libdbus-1.so.3 => /lib/x86_64-linux-gnu/libdbus-1.so.3 (0x00007fe17e33d000)\n    libgpg-error.so.0 => /lib/x86_64-linux-gnu/libgpg-error.so.0 (0x00007fe17e138000)\n    libuuid.so.1 => /lib/x86_64-linux-gnu/libuuid.so.1 (0x00007fe17df33000)\n', '\n$ lsb_release -a\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 14.04.4 LTS\nRelease:    14.04\nCodename:   trusty\n']",[],0,0
204,caffe,4634,closed,A demo question about gpu,,,[],[],[],0,0
205,caffe,4276,closed,AttributeError: 'module' object has no attribute 'Net',"i meet a strange question:
when i defines a net using caffe.Net, there is an error:
AttributeError: 'module' object has no attribute 'Net'

> > > import caffe
> > > net=caffe.Net()
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > > AttributeError: 'module' object has no attribute 'Net'

And there is another one:
python /././caffe/python/classify.py --model ./bvlc_reference_caffenet/deploy.prototxt --weights ./bvlc_reference_caffenet/bvlc-reference_caffenet.caffemodel --gpu

Failed to include caffe_pb2, things might go wrong!
Traceback (most recent call last):
  File ""/usr/local/lib/python3.4/dist-packages/google/protobuf/internal/python_message.py"", line 1091, in MergeFromString
    if self._InternalParse(serialized, 0, length) != length:
  File ""/usr/local/lib/python3.4/dist-packages/google/protobuf/internal/python_message.py"", line 1113, in InternalParse
    (tag_bytes, new_pos) = local_ReadTag(buffer, pos)
  File ""/usr/local/lib/python3.4/dist-packages/google/protobuf/internal/decoder.py"", line 181, in ReadTag
    while six.indexbytes(buffer, pos) & 0x80:
TypeError: unsupported operand type(s) for &: 'str' and 'int'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/ndscbigdata/caffe/python/classify.py"", line 14, in <module>
    import caffe
  File ""/home/ndscbigdata/caffe/python/caffe/**init**.py"", line 4, in <module>
    from .proto.caffe_pb2 import TRAIN, TEST
  File ""/home/ndscbigdata/caffe/python/caffe/proto/caffe_pb2.py"", line 799, in <module>
    options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), '\020\001')),
  File ""/usr/local/lib/python3.4/dist-packages/google/protobuf/descriptor.py"", line 845, in _ParseOptions
    message.ParseFromString(string)
  File ""/usr/local/lib/python3.4/dist-packages/google/protobuf/message.py"", line 185, in ParseFromString
    self.MergeFromString(serialized)
  File ""/usr/local/lib/python3.4/dist-packages/google/protobuf/internal/python_message.py"", line 1097, in MergeFromString
    raise message_mod.DecodeError('Truncated message.')
google.protobuf.message.DecodeError: Truncated message.
",,"['This looks like caffe was incorrectly installed.  Please follow up on the mailing list for installation questions.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
206,caffe,1993,closed,Error: (unix time) try if you are using GNU date,"Hi,

When I tried to train the model of bvlc_reference_caffenet by my own data set, I have a problem: can anyone tell me how to fix it?

![screen shot 2015-02-26 at 11 18 01 pm](https://cloud.githubusercontent.com/assets/11225386/6409029/76ee1e34-be12-11e4-8e3c-4be0f42a528c.png)
",,"['If this is of any help, the same error can be obtained just by running the tests. I recompiled caffe to use cuDNN, and wanted to run the tests: obtained this: (I skipped all the passing tests before)\n\n```\n[----------] 1 test from GaussianFillerTest/1, where TypeParam = double\n[ RUN      ] GaussianFillerTest/1.TestFill\n*** Aborted at 1425466715 (unix time) try ""date -d @1425466715"" if you are using GNU date ***\nPC: @           0x50efd4 caffe::GaussianFillerTest_TestFill_Test<>::TestBody()\n*** SIGSEGV (@0x6e0a000) received by PID 6705 (TID 0x2b18bebb3900) from PID 115384320; stack trace: ***\n    @     0x2b18c4e9fd40 (unknown)\n    @           0x50efd4 caffe::GaussianFillerTest_TestFill_Test<>::TestBody()\n    @           0x70aa63 testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @           0x7016a7 testing::Test::Run()\n    @           0x70174e testing::TestInfo::Run()\n    @           0x701855 testing::TestCase::Run()\n    @           0x704b98 testing::internal::UnitTestImpl::RunAllTests()\n    @           0x704e27 testing::UnitTest::Run()\n    @           0x4449fa main\n    @     0x2b18c4e8aec5 (unknown)\n    @           0x449b19 (unknown)\n    @                0x0 (unknown)\nmake: *** [runtest] Segmentation fault (core dumped)\n```\n\nAnything I can do to help?\n', ""I tried to start bisecting to identify where this bug could have come from but after a make clean and a reinstall, I can't reproduce anymore.\n@ShijianTang , might want to try to do that if you're still having this problem.\n"", 'Hi,\n\nThanks for your help.\n\nNow, I have solved this problem. The problem is that the the format of train.txt file for generating the lmdb   is in incorrect format.\n', 'having same problem in caffe test when doing: make runtest\n\n[----------] 1 test from LayerFactoryTest/0, where TypeParam = N5caffe8FloatCPUE\n[ RUN      ] LayerFactoryTest/0.TestCreateLayer\n**\\* Aborted at 1426466145 (unix time) try ""date -d @1426466145"" if you are using GNU date ***\nPC: @        0x10af701b7 caffe::CuDNNConvolutionLayer<>::~CuDNNConvolutionLayer()\n**\\* SIGSEGV (@0x0) received by PID 15366 (TID 0x7fff7eb7b300) stack trace: ***\n    @     0x7fff93fcdf1a _sigtramp\n    @        0x10b432b26 fatbinData\n    @        0x10af7039f caffe::CuDNNConvolutionLayer<>::~CuDNNConvolutionLayer()\n    @        0x10acfb314 caffe::LayerFactoryTest_TestCreateLayer_Test<>::TestBody()\n    @        0x10aefe4fc testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @        0x10aeeda9a testing::Test::Run()\n    @        0x10aeee892 testing::TestInfo::Run()\n    @        0x10aeeefa0 testing::TestCase::Run()\n    @        0x10aef4b17 testing::internal::UnitTestImpl::RunAllTests()\n    @        0x10aefed54 testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @        0x10aef4829 testing::UnitTest::Run()\n    @        0x10ab8432d main\n    @     0x7fff902365c9 start\n    @                0x3 (unknown)\n/bin/sh: line 1: 15366 Segmentation fault: 11  .build_release/test/test_all.testbin 0 --gtest_shuffle\nmake: **\\* [runtest] Error 139\n', 'redid a:\nmake clean\nmake test\nmake runtest\n\nprevious failed test ran OK but,\n[----------] 3 tests from SplitLayerTest/0, where TypeParam = N5caffe8FloatCPUE\n[ RUN      ] SplitLayerTest/0.Test\n[       OK ] SplitLayerTest/0.Test (0 ms)\n[ RUN      ] SplitLayerTest/0.TestSetup\n[       OK ] SplitLayerTest/0.TestSetup (0 ms)\n[ RUN      ] SplitLayerTest/0.TestGradient\n[       OK ] SplitLayerTest/0.TestGradient (5 ms)\n[----------] 3 tests from SplitLayerTest/0 (5 ms total)\n\nthis on failed:\n[----------] 1 test from LayerFactoryTest/1, where TypeParam = N5caffe9DoubleCPUE\n[ RUN      ] LayerFactoryTest/1.TestCreateLayer\n**\\* Aborted at 1426468417 (unix time) try ""date -d @1426468417"" if you are using GNU date ***\nPC: @        0x11479b13e cudnnDestroy\n**\\* SIGSEGV (@0x30) received by PID 25063 (TID 0x7fff7eb7b300) stack trace: ***\n    @     0x7fff93fcdf1a _sigtramp\n    @     0x7fff5128dd62 (unknown)\n    @        0x10ed611e8 caffe::CuDNNPoolingLayer<>::~CuDNNPoolingLayer()\n    @        0x10ed6122f caffe::CuDNNPoolingLayer<>::~CuDNNPoolingLayer()\n    @        0x10eae8cf4 caffe::LayerFactoryTest_TestCreateLayer_Test<>::TestBody()\n    @        0x10ecec4fc testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @        0x10ecdba9a testing::Test::Run()\n    @        0x10ecdc892 testing::TestInfo::Run()\n    @        0x10ecdcfa0 testing::TestCase::Run()\n    @        0x10ece2b17 testing::internal::UnitTestImpl::RunAllTests()\n    @        0x10ececd54 testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @        0x10ece2829 testing::UnitTest::Run()\n    @        0x10e97232d main\n    @     0x7fff902365c9 start\n    @                0x3 (unknown)\n/bin/sh: line 1: 25063 Segmentation fault: 11  .build_release/test/test_all.testbin 0 --gtest_shuffle\nmake: **\\* [runtest] Error 139\n', 'I am encountering the same problem when using IMAGE_DATA layers:\n\n```\nI0426 16:48:21.890173 23626 layer_factory.hpp:74] Creating layer data\nI0426 16:48:21.890197 23626 net.cpp:84] Creating Layer data\nI0426 16:48:21.890213 23626 net.cpp:338] data -> data\nI0426 16:48:21.890239 23626 net.cpp:338] data -> label\nI0426 16:48:21.890254 23626 net.cpp:113] Setting up data\nI0426 16:48:21.890269 23626 image_data_layer.cpp:36] Opening file \nI0426 16:48:21.890297 23626 image_data_layer.cpp:51] A total of 0 images.\n*** Aborted at 1430081301 (unix time) try ""date -d @1430081301"" if you are using GNU date ***\nPC: @     0x7f70e1333090 (unknown)\n*** SIGSEGV (@0x0) received by PID 23626 (TID 0x7f70e224aa40) from PID 0; stack trace: ***\n    @     0x7f70e0cced40 (unknown)\n    @     0x7f70e1333090 (unknown)\n    @     0x7f70e1b1c95c std::operator+<>()\n    @     0x7f70e1b7a465 caffe::ImageDataLayer<>::DataLayerSetUp()\n    @     0x7f70e1b4e986 caffe::BaseDataLayer<>::LayerSetUp()\n    @     0x7f70e1b4ea89 caffe::BasePrefetchingDataLayer<>::LayerSetUp()\n    @     0x7f70e1b97432 caffe::Net<>::Init()\n    @     0x7f70e1b98ef2 caffe::Net<>::Net()\n    @     0x7f70e1bd8260 caffe::Solver<>::InitTrainNet()\n    @     0x7f70e1bd9373 caffe::Solver<>::Init()\n    @     0x7f70e1bd9546 caffe::Solver<>::Solver()\n    @           0x40c4b0 caffe::GetSolver<>()\n    @           0x406481 train()\n    @           0x404a21 main\n    @     0x7f70e0cb9ec5 (unknown)\n    @           0x404fcd (unknown)\nSegmentation fault (core dumped)\n```\n\nCompiling with `#USE_CUDNN := 1` and `USE_CUDNN := 1` both produced the error.\n', 'anyone found a workaround ?\n', '+1 same issue here\n', 'I did a bit of digging and it seems to me that this the ""Error: (unix time) try if you are using GNU date"" is unrelated to Caffe and the problem that you are encountering.\n\nSee [here](https://google-glog.googlecode.com/svn/trunk/doc/glog.html), it appears this is just a result of the logging library (glog) that shows this when a failure happens. So all the problems that are posted here are unrelated.\n\nIf you get this error, you should look at the stacktrace provided instead of the unix time thing.\nThis issue should be closed because it doesn\'t reflect an error in caffe.\n', 'Hi guys, I have the same problem, someone managed to solve?\n', ""@bunelr is quite right, there are many different unrelated errors here. The text which titles this issue is just a helpful hint for parsing the log message. You're welcome to open new tickets for specific, reproducible errors in `master` with `DEBUG` enabled.\n"", ""I think most of this problem is due to the mis-use of cpu_data() mode and gpu_data() mode. I have encountered this problem while debugging something and I find that I should use cpu_data() instead of gpu_data(). The error is reasonable since the pointer to a gpu location doesn't mean anything in CPU. Data is in GPU. Hope this will help.\n"", 'I got the same error. But after the following steps, everything is good:\nmake clean\nmake all\nmake test\nmake runtest\n', 'I got this problem, because i use OpenBlas on Cents6.5,when i changed Atlas , make runtest successed.\n', '@ShijianTang , Hi\nWhat was the issue? I have the same errors as on your screeenshot.\nWhat is train.txt? Maybe you meant train.prototxt ? \n', 'I have this same issue - the SERIOUS one \n\nLayerFactoryTest/1.TestCreateLayer\ntest_all.testbin(5455,0x7fff7788a000) malloc: **\\* error for object 0x206800000000: pointer being freed was not allocated\n\nI am on cuda 7.5 on os/x\n', 'I have the same issue \n`*** Aborted at 1458527401 (unix time) try ""date -d @1458527401"" if you are using GNU date ***\nPC: @     0x7f15b49464b3 std::operator+<>()\n*** SIGSEGV (@0x8) received by PID 3284 (TID 0x7f15b4f37740) from PID 8; stack trace: ***\n    @     0x7f15b30862f0 (unknown)\n    @     0x7f15b49464b3 std::operator+<>()\n    @     0x7f15b4a76936 caffe::ImageDataLayer<>::DataLayerSetUp()\n    @     0x7f15b49d15ea caffe::BasePrefetchingDataLayer<>::LayerSetUp()\n    @     0x7f15b49ab11c caffe::Net<>::Init()\n    @     0x7f15b49ac961 caffe::Net<>::Net()\n    @     0x7f15b494a0fa caffe::Solver<>::InitTrainNet()\n    @     0x7f15b494b477 caffe::Solver<>::Init()\n    @     0x7f15b494b81a caffe::Solver<>::Solver()\n    @     0x7f15b493fee3 caffe::Creator_SGDSolver<>()\n    @           0x40a028 train()\n    @           0x4070e8 main\n    @     0x7f15b3071a40 __libc_start_main\n    @           0x407859 _start\n    @                0x0 (unknown)\nSegmentation fault (core dumped)\n`\n', ""I met the problem too. It's very confusing since the same network, if I use database1, everything is ok, but database2, the error occured. \n"", ""I  was facing the same issue. Even though I recompiled the issue still exists. \nMy system has multiple GPUs and I fixed the problem by explicitly making only one GPU visible. You can do this by setting the environment variable(export CUDA_VISIBLE_DEVICES=0). give the current GPU number instead of '0' \n"", '@sruthikesh-MU is right. It seems that the multiple GPUs trigger `GNU date issue`\n- Checking the current GPU devices\n\n```\n$ nvidia-smi\nMon Sep 26 18:01:53 2016       \n+------------------------------------------------------+                       \n| NVIDIA-SMI 352.63     Driver Version: 352.63         |                       \n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla K40c          Off  | 0000:02:00.0     Off |                    0 |\n| 31%   69C    P0    74W / 235W |    150MiB / 11519MiB |     66%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  GeForce GT 610      Off  | 0000:81:00.0     N/A |                  N/A |\n| 40%   43C    P8    N/A /  N/A |    277MiB /  1023MiB |     N/A      Default |\n+-------------------------------+----------------------+----------------------+\n|   2  Tesla K40c          Off  | 0000:82:00.0     Off |                    0 |\n| 30%   65C    P0    68W / 235W |    113MiB / 11519MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n```\n- Selec two of them works fine.\n\n```\nexport CUDA_VISIBLE_DEVICES=0 # only one K40c\nexport CUDA_VISIBLE_DEVICES=0,1 # one K40c + GT610\nexport CUDA_VISIBLE_DEVICES=0,2 # two K40c together\n```\n- Result\n\n```\n[----------] Global test environment tear-down\n[==========] 2081 tests from 277 test cases ran. (577020 ms total)\n[  PASSED  ] 2081 tests.\n[100%] Built target runtest\n```\n', '> Now, I have solved this problem. The problem is that the the format of train.txt file for generating the lmdb is in incorrect format.\r\n\r\n@ShijianTang what was the issue with the train.txt format in your case?\r\n\r\nI fixed the same issue by fixing my `lmdb` which I thought was created correctly while it was actually corrupted. ', '@alexeystrakh How did you check your `lmdb` file ? \r\nI met this problem too, but I do not know whether my `lmdb` file is corrupted. I used my `lmdb` file in another workstation and it workd fine, I transferred it to my current workstation by ftp. Was there anything wrong when transferred by ftp?', 'For me, the problem was caused by not assigning value to  `stepsize` in `solver.prototxt`.', 'My OS is CentOS 7.4.1708 and Python is Anaconda 3 5.0.1.\r\nI got the same error when I ran ```make runtest``` in caffe compilation process:\r\n```\r\nmake clean\r\nmake all\r\nmake test\r\nmake runtest\r\n```\r\nMy problem seems to be related to linker use the boost libraries under the Anaconda installation, e.g., /opt/anaconda3/lib.\r\nI solve the problem by removing Anaconda paths from PYTHON_LIB in Makefile.config.\r\n  ', 'Hi!\r\nI have the similar error.\r\nI0704 14:48:50.318994 27276 net.cpp:380] data -> label\r\nterminate called after throwing an instance of \'boost::python::error_already_set\'\r\n*** Aborted at 1530708530 (unix time) try ""date -d @1530708530"" if you are using GNU date ***\r\nPC: @     0x7ff1636b9fcf gsignal\r\n*** SIGABRT (@0x36b700006a8c) received by PID 27276 (TID 0x7ff1498ec9c0) from PID 27276; stack trace: ***\r\n    @     0x7ff1854840c0 (unknown)\r\n    @     0x7ff1636b9fcf gsignal\r\n    @     0x7ff1636bb3fa abort\r\n    @     0x7ff163ddbd6d __gnu_cxx::__verbose_terminate_handler()\r\n    @     0x7ff163dd9d36 __cxxabiv1::__terminate()\r\n    @     0x7ff163dd9d81 std::terminate()\r\n    @     0x7ff163dd9f98 __cxa_throw\r\n    @     0x7ff163ef8532 boost::python::throw_error_already_set()\r\n    @     0x7ff11895ad11 boost::python::api::object_operators<>::operator()<>()\r\n    @     0x7ff11895af28 caffe::PythonLayer<>::LayerSetUp()\r\n    @     0x7ff185c2c828 caffe::Net<>::Init()\r\n    @     0x7ff185c2deee caffe::Net<>::Net()\r\n    @     0x7ff185c39c47 caffe::Solver<>::InitTrainNet()\r\n    @     0x7ff185c3a215 caffe::Solver<>::Init()\r\n    @     0x7ff185c3a4ff caffe::Solver<>::Solver()\r\n    @     0x7ff185c57231 caffe::Creator_SGDSolver<>()\r\n    @           0x40ca7a train()\r\n    @           0x4087d3 main\r\n    @     0x7ff1636a72b1 __libc_start_main\r\n    @           0x4092ca _start\r\nAborted\r\nCan you help me?\r\n', ""> I think most of this problem is due to the mis-use of cpu_data() mode and gpu_data() mode. I have encountered this problem while debugging something and I find that I should use cpu_data() instead of gpu_data(). The error is reasonable since the pointer to a gpu location doesn't mean anything in CPU. Data is in GPU. Hope this will help.\r\n\r\nyou are right! variables are used in CUDA_KERNEL_LOOP must be gpu_data(). However, if you make for() {} youself, you should keep corresponding variables as cpu_data().  Exciting!"", 'Come to the same problem with current version 04ab089db018a292ae48d51732dd6c66766b36b6\r\n\r\n## steps\r\n\r\n```\r\nmake all\r\nmake runtest\r\n```\r\n\r\n## trace\r\n\r\n```\r\n7ffe50bda000-7ffe50bdc000 r-xp 00000000 00:00 0                          [vdso]\r\nffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]\r\n*** Aborted at 1561115206 (unix time) try ""date -d @1561115206"" if you are using GNU date ***\r\nPC: @     0x7fd8cf719428 gsignal\r\n*** SIGABRT (@0x65b8) received by PID 26040 (TID 0x7fd8d67a6740) from PID 26040; stack trace: ***\r\n    @     0x7fd8cfabf390 (unknown)\r\n    @     0x7fd8cf719428 gsignal\r\n    @     0x7fd8cf71b02a abort\r\n    @     0x7fd8cf75b7ea (unknown)\r\n    @     0x7fd8cf76437a (unknown)\r\n    @     0x7fd8cf76853c cfree\r\n    @           0x652d17 caffe::MakeTempDir()\r\n    @           0x687049 caffe::GradientBasedSolverTest<>::TestLeastSquaresUpdate()\r\n    @           0x688b47 caffe::RMSPropSolverTest_TestRMSPropLeastSquaresUpdateWithRmsDecay_Test<>::TestBody()\r\n    @           0x8eabb3 testing::internal::HandleExceptionsInMethodIfSupported<>()\r\n    @           0x8e41ca testing::Test::Run()\r\n    @           0x8e4318 testing::TestInfo::Run()\r\n    @           0x8e43f5 testing::TestCase::Run()\r\n    @           0x8e56cf testing::internal::UnitTestImpl::RunAllTests()\r\n    @           0x8e59f3 testing::UnitTest::Run()\r\n    @           0x46c1ed main\r\n    @     0x7fd8cf704830 __libc_start_main\r\n    @           0x473389 _start\r\n    @                0x0 (unknown)\r\nMakefile:542: recipe for target \'runtest\' failed\r\nmake: *** [runtest] Aborted (core dumped)\r\n```\r\n\r\n## with gpu enabled\r\n```\r\nCUDA 8.0\r\nNVIDIA-SMI 384.130\r\nTesla P100\r\n```\r\n']",[],[],0,0
207,caffe,5173,closed,vmware ubuntu16 undefined issue,"the step make all, the following error

build_release/lib/libcaffe.sojpeg_CreateCompress
.build_release/lib/libcaffe.sogoogle::protobuf::DescriptorPool::FindFileByName(std::string const&) const
.build_release/lib/libcaffe.soImf_2_2::OutputFile::~OutputFile()
.build_release/lib/libcaffe.sogoogle::protobuf::internal::WireFormatLite::ReadBytes(google::protobuf::io::CodedInputStream*, std::string*)   (  undefine ref  )
.build_release/lib/libcaffe.sopng_create_info_struct
.build_release/lib/libcaffe.sojpeg_std_error
.build_release/lib/libcaffe.sogoogle::protobuf::Message::InitializationErrorString() const
.build_release/lib/libcaffe.sopng_set_compression_level
collect2: error: ld returned 1 exit status
Makefile:620: recipe for target '.build_release/tools/compute_image_mean.bin' failed
make: *** [.build_release/tools/compute_image_mean.bin] Error 1


",,"['From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\r\n\r\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\r\nUse the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.']",[],[],0,0
208,caffe,2078,closed,cmake with -DBUILD_matlab=ON fails,"Hello, I suspect that this might be a bug introduced after the commit 3d30510 (PR #2059). 

The environment with which I've tested is: Mac OS X 10.10. I haven't tested with Ubuntu, since I don't have any Linux machine with matlab installed as of now.



However, building matcaffe fails with the message .



Let's see the command line argument passed (absolute paths were replaced by ).
There are python-related link flags,  and , which were added from 



The reason why  fails might be that the ordering of link flags ( and ) has changed in the internal invocation, and thus it was not able to link the  dynamic module.



This build step with cmake, succeeds prior to 3d30510.

As I am doubtful these flags (e.g. ) are necessary to build matlab targets, these flags could be removed when building matlab bindings so that the build could be successful out-of-box. Currently, I tried a workaround setting  to , but after inspection to find better solution, I think I could submit a PR to fix this. Thanks.
",Matlab build,"[""I am experiencing the same issue (but on Scientific Linux 6.6 with the g++ compiler). From what I can tell, the issue is that the compilation line is using `-lpython2` instead of the actual Python version, such as `-lpython2.7`\n\nThe flag `-lpython2` tells the linker to look for a library file named `libpython2.so`. As far as I can tell, no version of Python has shipped such a file for ages.\n\nIt's possible to work around this by manually changing that flag to `-lpython2.7`. You can also create a symlink from `libpython2.so` to `libpython2.7.so` (although that's a nasty hack).\n\n**Because python doesn't need to be linked here, the cleanest would be to remove the `-lpython2` from the Matlab build line.** I'm submitting a pull request with the change.\n"", 'See https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/caffe-users/1sVAqSDLvpk/r9LMUXp7EgAJ\n', 'Just for completeness, this answer (http://stackoverflow.com/a/35286218/424986) solves the problem of missing `lbypthon2` library with Matlab by updating the CMake rules.\n']","['\n$ cd build\n$ cmake .. -DBUILD_matlab=ON && make -j4\n', ""\n[100%] Building Matlab interface: ${CAFFE_ROOT}/matlab/caffe/caffe.mexmaci64\nBuilding with 'Xcode Clang++'.\nld: library not found for -lpython2\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\n"", '\n/Applications/MATLAB_R2014b.app/bin/mex -output ${CAFFE_ROOT}/matlab/caffe/caffe.mexmaci64 ${CAFFE_ROOT}/matlab/caffe/matcaffe.cpp -DCPU_ONLY -DWITH_PYTHON_LAYER -DGTEST_USE_OWN_TR1_TUPLE -I${CAFFE_ROOT}/src -I/usr/local/include -I${CAFFE_ROOT}/build/include -I/usr/local/include/opencv -I/System/Library/Frameworks/Accelerate.framework/Versions/Current/Frameworks/vecLib.framework/Versions/Current/Headers -I/System/Library/Frameworks/Python.framework/Headers -I/usr/local/lib/python2.7/site-packages/numpy/core/include -I${CAFFE_ROOT}/include -I${CAFFE_ROOT}/build -L${CAFFE_ROOT}/build/lib -L/usr/local/lib -L/usr/local/lib -L/usr/local/lib -L/usr/local/lib -L/usr/lib -lcaffe -lboost_system-mt -lboost_thread-mt -lglog -lgflags -lhdf5_hl -lhdf5 -llmdb -lleveldb -lsnappy -lopencv_core -lopencv_highgui -lopencv_imgproc -lcblas -lpython2  -lboost_python-mt -lprotobuf -v\n', '\n... (omitted) ...\n/usr/bin/xcrun -sdk macosx10.9 (..omitted...)\n-lcaffe  -lboost_system-mt  -lboost_thread-mt  -lglog  -lgflags -lhdf5_hl  -lhdf5  -llmdb  -lleveldb  -lsnappy  -lopencv_core  -lopencv_highgui  -lopencv_imgproc  -lcblas  -lpython2  -lboost_python-mt  -lprotobuf   -L${CAFFE_ROOT}/build/lib  -L/usr/local/lib  -L/usr/local/lib  -L/usr/local/lib  -L/usr/local/lib  -L/usr/lib  -L""/Applications/MATLAB_R2014b.app/bin/maci64"" -lmx -lmex -lmat -o ""${CAFFE_ROOT}matlab/caffe/caffe.mexmaci64\n']","['ld: library not found for -lpython2', '${CAFFE_ROOT}', '-lpython2', '-lboost_python-mt', '${PYTHON_LIBRARIES}', 'ld', '-L', '-l', 'python2', '-lpython', 'BUILD_python_layer', 'OFF']",0,0
209,caffe,2792,closed,CUDA Compilation issue on MacBook,"I am installing Caffe on a Mac Book. I am able to get it to compile and run in CPU only mode, but cannot get it to compile for the GPU. I have followed the [installation instructions](http://caffe.berkeleyvision.org/installation.html) and am not sure what to do next.

This is a Mac Book Pro running OS X 10.10.4. The graphics card is an Intel Iris Pro GPU. I am using Python from the Anaconda distribution.

I installed dependencies as outlined on the [""OS X Installation"" page](http://caffe.berkeleyvision.org/install_osx.html) via Homebrew.  I installed CUDA 7 for Mac OS from the [CUDA website](https://developer.nvidia.com/cuda-downloads).  The CUDA tools are installed beneath /usr/local/cuda.

I cloned the Caffe distribution from https://github.com/BVLC/caffe. I am on commit 247d6d66 from July 15, 2015.

In Makefile.config I uncommented the Python Anaconda include lines but otherwise left things the same.

make clean;make all builds a lot of .cpp files but fails the first time it tries to use the NVCC compiler



sp_counted_base_clang.hpp looks fine to me. Line 27 is the first line that is neither an include or namespace statement. The only two includes preceding it are



Maybe there is something wrong with my Boost configuration, although I was able to install Boost via Homebrew without a problem.

If I uncomment ""CPU_ONLY := 1"" in Makefile.config and do another clean build, I do not get any compiler errors.

(When I try to run the tests I have the problem described in issue  https://github.com/BVLC/caffe/issues/1737. I work around this by soft linking my libhdf58 libraries to libhdf9 and specifying the hdf5 headers from /usr/local/include/ in the COMMON_FLAGS in Makefile. I do not think this this is related to my CUDA compilation issue.)

Do you have any ideas why the CUDA code is not compiling for me?
",,"[""I think I have a pretty good idea. A Macbook or for that matter any computer, is compatible with CUDA only if it has NVIDIA GPU's. They won't work with Intel Iris Prof. Hard luck.\n"", 'Well, the CUDA build should work with or without a compatible GPU. However, please ask installation questions on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) list. Thanks!\n']","['\nNVCC src/caffe/layers/absval_layer.cu\n/usr/local/include/boost/smart_ptr/detail/sp_counted_base_clang.hpp(27): error: expected a "";""\n....\nmany errors follow\n.....\n', '\n#include <boost/detail/sp_typeinfo.hpp>\n#include <boost/cstdint.hpp>\n']",[],0,0
210,caffe,5783,closed,error while make runtest  about layerfactorytest,"[----------] 8 tests from SliceLayerTest/2 (465 ms total)

[----------] Global test environment tear-down
[==========] 2101 tests from 277 test cases ran. (279573 ms total)
[  PASSED  ] 2097 tests.
[  FAILED  ] 4 tests, listed below:
[  FAILED  ] LayerFactoryTest/0.TestCreateLayer, where TypeParam = caffe::CPUDevice<float>
[  FAILED  ] LayerFactoryTest/1.TestCreateLayer, where TypeParam = caffe::CPUDevice<double>
[  FAILED  ] LayerFactoryTest/2.TestCreateLayer, where TypeParam = caffe::GPUDevice<float>
[  FAILED  ] LayerFactoryTest/3.TestCreateLayer, where TypeParam = caffe::GPUDevice<double>

 4 FAILED TESTS
Makefile:534: recipe for target 'runtest' failed
make: *** [runtest] Error 1

",,['I met the same issue. Did you solve the problem?'],[],[],0,0
211,caffe,3467,closed,network.save() of very large network Seg Faults,"I have been trying to train a siamese CNN where each branch is VGG, and transfer learn it from VGG-16.. the problem is when I try to save the network after copying the W,b over at each layer, the network.save('.caffemodel') Seg faults and does not save the model correctly. I believe it is because the network is too big? Is there any way to get around this? Here is the gist: 

https://gist.github.com/Fchaubard/b40ccfe7b76043060e2f

and if you simply do..
model_path = '/some_path/siamese_vgg.prototxt'
network = caffe.Net(model_path, caffe.TEST)
network.save('/some_path/siamese_vgg.caffemodel')
you will get a ""Segmentation fault (core dumped)""

I removed the weight sharing in each layer to ensure it was the size and not something involving the shared params. I also tried doing a forward backward to see if it was a lazy instantiation issue. To no avail.  

-- UPDATE --
I just attempted on a different server and it seemed to work. Trying to track down the reason... the .caffemodel is 1.1 GB. And I have more than that available on the original server so I am not sure what the reason for this discrepancy in functionality.
",,"['For large models >2 gb you can save the network as `hdf5` instead of `binaryproto`.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
212,caffe,4060,closed, undefined reference to `lzma_index_end@XZ_5.0',"/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_index_size@XZ_5.0'
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_stream_footer_decode@XZ_5.0'
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_index_uncompressed_size@XZ_5.0'
collect2: error: ld returned 1 exit status
tools/CMakeFiles/finetune_net.dir/build.make:133: recipe for target 'tools/finetune_net' failed
make[2]: **\* [tools/finetune_net] Error 1
CMakeFiles/Makefile2:435: recipe for target 'tools/CMakeFiles/finetune_net.dir/all' failed
make[1]: **\* [tools/CMakeFiles/finetune_net.dir/all] Error 2
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_index_size@XZ_5.0'
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_stream_footer_decode@XZ_5.0'
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_index_uncompressed_size@XZ_5.0'
collect2: error: ld returned 1 exit status
tools/CMakeFiles/net_speed_benchmark.dir/build.make:133: recipe for target 'tools/net_speed_benchmark' failed
make[2]: **\* [tools/net_speed_benchmark] Error 1
CMakeFiles/Makefile2:625: recipe for target 'tools/CMakeFiles/net_speed_benchmark.dir/all' failed
make[1]: **\* [tools/CMakeFiles/net_speed_benchmark.dir/all] Error 2
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_index_size@XZ_5.0'
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_stream_footer_decode@XZ_5.0'
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_index_uncompressed_size@XZ_5.0'
collect2: error: ld returned 1 exit status
tools/CMakeFiles/train_net.dir/build.make:133: recipe for target 'tools/train_net' failed
make[2]: **\* [tools/train_net] Error 1
CMakeFiles/Makefile2:511: recipe for target 'tools/CMakeFiles/train_net.dir/all' failed
make[1]: **\* [tools/CMakeFiles/train_net.dir/all] Error 2
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_index_size@XZ_5.0'
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_stream_footer_decode@XZ_5.0'
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_index_uncompressed_size@XZ_5.0'
collect2: error: ld returned 1 exit status
tools/CMakeFiles/test_net.dir/build.make:133: recipe for target 'tools/test_net' failed
make[2]: **\* [tools/test_net] Error 1
CMakeFiles/Makefile2:549: recipe for target 'tools/CMakeFiles/test_net.dir/all' failed
make[1]: **\* [tools/CMakeFiles/test_net.dir/all] Error 2
[ 90%] Linking CXX executable extract_features
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_stream_footer_decode@XZ_5.0'
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_stream_buffer_decode@XZ_5.0'
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_index_end@XZ_5.0'
collect2: error: ld returned 1 exit status
tools/CMakeFiles/extract_features.dir/build.make:133: recipe for target 'tools/extract_features' failed
make[2]: **\* [tools/extract_features] Error 1
CMakeFiles/Makefile2:701: recipe for target 'tools/CMakeFiles/extract_features.dir/all' failed
make[1]: **\* [tools/CMakeFiles/extract_features.dir/all] Error 2
[ 90%] Linking CXX executable caffe
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_stream_footer_decode@XZ_5.0'
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_stream_buffer_decode@XZ_5.0'
/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to lzma_index_end@XZ_5.0'
collect2: error: ld returned 1 exit status
tools/CMakeFiles/caffe.bin.dir/build.make:133: recipe for target 'tools/caffe' failed
make[2]: **\* [tools/caffe] Error 1
CMakeFiles/Makefile2:587: recipe for target 'tools/CMakeFiles/caffe.bin.dir/all' failed
make[1]: **\* [tools/CMakeFiles/caffe.bin.dir/all] Error 2
Makefile:127: recipe for target 'all' failed
make: **\* [all] Error 2
",,"[""From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> When reporting a bug, it's most helpful to provide the following information, where applicable:\n> - What steps reproduce the bug?\n> - Can you reproduce the bug using the latest [master](https://github.com/BVLC/caffe/tree/master), compiled with the `DEBUG` make option?\n> - What hardware and operating system/distribution are you running?\n> - If the bug is a crash, provide the backtrace (usually printed by Caffe; always obtainable with `gdb`).\n"", 'as we know we could build caffe with two different option, one is make, another is cmake. In my problem, I always use cmake, and the problem have not solved in the end. Before I give up, I have used the make build, it have succeed.  Is it the problem of CMAKE configuration. Hope someone could answer this. \n', ""I face the same issue, albeit few nuances in the error message. \n\n```\n\n//usr/lib/x86_64-linux-gnu/libavcodec-ffmpeg.so.56: undefined reference to `lzma_end@XZ_5.0'\ncollect2: error: ld returned 1 exit status\ntools/CMakeFiles/upgrade_solver_proto_text.dir/build.make:128: recipe for target 'tools/upgrade_solver_proto_text' failed\nmake[2]: *** [tools/upgrade_solver_proto_text] Error 1\nCMakeFiles/Makefile2:473: recipe for target 'tools/CMakeFiles/upgrade_solver_proto_text.dir/all' failed\nmake[1]: *** [tools/CMakeFiles/upgrade_solver_proto_text.dir/all] Error 2\nMakefile:127: recipe for target 'all' failed\nmake: *** [all] Error 2\n```\n\nI am using CMAKE. I have used the latest master. Unfortunately, I do not have debug enabled!\n"", 'From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\r\n\r\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\r\nUse the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.']",[],"[""lzma_index_end@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_index_buffer_decode@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_stream_buffer_decode@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_index_end@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_index_buffer_decode@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_stream_buffer_decode@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_index_end@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_index_buffer_decode@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_stream_buffer_decode@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_index_end@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_index_buffer_decode@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_stream_buffer_decode@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_index_size@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_index_uncompressed_size@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_index_buffer_decode@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_index_size@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_index_uncompressed_size@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to"", ""lzma_index_buffer_decode@XZ_5.0'\n/usr/lib/x86_64-linux-gnu/libunwind.so.8: undefined reference to""]",0,0
213,caffe,1862,closed,Want to share codes shuffling the order of images in training/testing for DataLayer (with LMDB) ,"Hi :) I wrote a code to shuffle the order of images when caffe use DataLayer (esp. LMDB). 

This set of codes are very simple, so I think there are many people who have their own code for them. However, I think this implementation will be helpful to others who are not familiar with caffe implementation. 

I'm not familiar with how I can share the code in this caffe repository. I would appreciate if you let me know how to share it.

Thanks :) 
",,"[""Glad to hear you'd like to contribute!\n\nThe best place to read up on our workflow is here: http://caffe.berkeleyvision.org/development.html\n\nAfter that, just make a pull request with your changes and one of us will be around to review it. :)\n"", 'One more thing: you may want to wait until after #1849 is merged. I think there will be a lot of changes, and the workflow will change too, so it may be easier to contribute after that goes through!\n', '@lim0606 Where is your code???']",[],[],0,0
214,caffe,188,closed,Examples of unsupervised feature learning?,"e.g. auto-encoder, predictive sparse decomposition.
They would be very insightful for a newbie.
Thanks. 
",,['There is a sparse auto-encoder example in the dev branch in examples/mnist. See #330.\n'],[],[],0,0
215,caffe,824,closed,Invalid MEX-file '/path/to/rcnn/external/caffe/matlab/caffe/caffe.mexa64': libcudart.so.6.0: cannot open shared object file: No such file or directory,"I have CUDA 5.5 and CUDA 6.0 installed in /usr/local/, and the LD_LIBRARY_PATH to libcudart.so.6.0 is correct.
I run ""make runtest"" and it passed, but failed to run /caffe.mexa64.
Actually when I run sudo ldd ./caffe.mexa64, it said libcudart.so.6.0 not found.
Should I uninstall CUDA 5.5 first? Any suggestion?
FYI, after I mv /usr/local/cuda-5.5 away, I can't make caffe successfully because libopencv_core.so need the libcudart.so.5.5
",downstream problem?,"['/path/to/ means your own paht. You must replace it with your own path.\n', 'I\'ve experienced similar situation, finally I found out that the setting of ""LD_LIBRARY_PATH"" didn\'t work in some case after I look up the value of ""LD_LIBRARY_PATH"".\nI think the command \nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/path/to/libcudart\nmight be working in this case.\n', ""It's important to make sure your compilation and runtime paths are the same by properly setting your `Makefile.config` include and library paths along with your environments `LD_LIBRARY_PATH`.\n\nPlease ask any follow-up questions on the [caffe-users mailing list](https://groups.google.com/forum/#!forum/caffe-users). As of the latest release we prefer to keep issues reserved for Caffe development. Thanks!\n"", 'Hi, I just have one question. Where can I find LD_LIBRARY_PATH and PATH variables?\n', ""Please ask usage questions to the [caffe-users mailing list](https://groups.google.com/forum/#!forum/caffe-users).\n\nThat being said, here's a tutorial on linux variables like PATH: http://www.linfo.org/path_env_var.html\n""]",[],[],0,0
216,caffe,3405,closed,Cross-Validation is a Bad idea in Deep Learning?,"Hi guys,

I'm trying do cross-validation in caffe because I've a small set of images 3K, I'm do it this way:

split my train images in 10 subsets, then I generate the lmdb files, after this I train in subsets 1 to 9 and validation in 10, after this I finetuning this trained network in subsets 2 to 10 an validate in subset 1, and subsequently until pass for all subsets.

The problem is which the network suffers of overfiting because when I do finetuning my subset of validation already exposed to training phase.

So what I'm doing wrong? Is this way which do cross-validation in caffe?

I read about this in some places like github and here in caffe user too, but isn't clear.

If anyone help me I really thanks, I've lost a week on this and the problem persist.

Thanks guys. 
",,"[""This is a general machine-learning question, not a caffe question.  If I'm understanding your description correctly, you're not doing cross-validation correctly, and you've contaminated training and validation sets.  That won't cause overfitting (and it won't prevent it either) -- it just means your validation error is meaningless.\n\nYou probably just want to freeze the lower layers (set learning rate to 0) and only learn the last 1-3 layers (for example).  That's a better solution to overfitting than your scheme (which doesn't make sense).\n\nAlso, from https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n""]",[],[],0,0
217,caffe,6094,closed,"The function ""bool ReadProtoFromTextFile(const char* filename, Message* proto)"" in util/io.cpp, what if given a bad filename parameter, the function will not return false?","### Issue summary
The function below in io.cpp, while function open() return -1, that means given a bad filename parameter, it will not return false but just give a log message. Will that cause crash? 

bool ReadProtoFromTextFile(const char* filename, Message* proto) {
  int fd = open(filename, O_RDONLY);
  CHECK_NE(fd, -1) << ""File not found: "" << filename;
  FileInputStream* input = new FileInputStream(fd);
  bool success = google::protobuf::TextFormat::Parse(input, proto);
  delete input;
  close(fd);
  return success;
}

bool ReadProtoFromBinaryFile(const char* filename, Message* proto) {
  int fd = open(filename, O_RDONLY);
  CHECK_NE(fd, -1) << ""File not found: "" << filename;
  ZeroCopyInputStream* raw_input = new FileInputStream(fd);
  CodedInputStream* coded_input = new CodedInputStream(raw_input);
  coded_input->SetTotalBytesLimit(kProtoReadBytesLimit, 536870912);

  bool success = proto->ParseFromCodedStream(coded_input);

  delete coded_input;
  delete raw_input;
  close(fd);
  return success;
}

",,"[""CHECK_NE (and all CHECK, CHECK_xx expressions) act as assertions that terminate the execution if the condition is not met - not just log a failure. So we don't have to care about what the function outputs - the whole program is stopped at this point.""]",[],[],0,0
218,caffe,1983,closed,MemoryDataLayer performs transformations inconsistently,"in MemoryDataLayer
  top[0]->Reshape(batch_size_, channels_, height_, width_);
  top[1]->Reshape(batch_size_, 1, 1, 1);
  added_data_.Reshape(batch_size_, channels_, height_, width_);
  added_label_.Reshape(batch_size_, 1, 1, 1);

in ImageDataLayer
  if (crop_size > 0) {
    top[0]->Reshape(batch_size, channels, crop_size, crop_size);
    this->prefetch_data_.Reshape(batch_size, channels, crop_size, crop_size);
    this->transformed_data_.Reshape(1, channels, crop_size, crop_size);
  } else {
    top[0]->Reshape(batch_size, channels, height, width);
    this->prefetch_data_.Reshape(batch_size, channels, height, width);
    this->transformed_data_.Reshape(1, channels, height, width);
  }
When crop is used in MemoryDataLayer the result is wrong
",bug,"[""Thanks for the report; there is a known issue that `MemoryDataLayer` only sometimes performs transformations, which I'll now generalize this issue to.\n"", 'Actually, this is #1784, so continue any discussion there.\n']",[],[],0,0
219,caffe,1917,closed,Problem with dynamic loading and caffe.proto,"After switching to the current caffe version today, dynamic loading of several libraries, which contain different classifiers for specific tasks, does not work anymore. We've got the following error message:

[libprotobuf ERROR google/protobuf/descriptor_database.cc:57] File already exists in database: caffe.proto

Furthermore we are using Ubuntu 14.04 and the following version of libprotobuf:

 /usr/lib/x86_64-linux-gnu/libprotobuf.so.8
/usr/lib/x86_64-linux-gnu/libprotobuf.so.8.0.0

Before updating caffe everything was fine and allows for loading of more than one library containing a caffe net. Seems as if the part of building the caffe specific proto header and cc-file has changed. Is there any conncetion to our problem? And how can we fix our problem?

Best, Tom
",JL,"[""There is a known issue with protobuf in loading dynamically linked libraries that all link to protobuf: https://code.google.com/p/protobuf/issues/detail?id=128. @longjon may be able to comment from his experience on this. A possible workaround is to combine your separate library-classifier combinations into a single library-classifiers arrangement with different calls for each model -- but in my own work I've only worked with a single `libcaffe.so` linked library that may execute different models depending on the calling code.\n"", 'Well, the point is, that it works fine until I\'ve updated the caffe version yesterday and checked out the latest master (because of the modification of the net-constructor!). Even with the same protobuf version our implementation works with an older version of caffe on other 14.04 ubuntu systems we have. But this is a caffe version, we checked out by means of a snapshot (zip-file) more than half a year ago, so unfortunately we don\'t have any version number! But I already used a newer version, that also works in our framework with dynamic loading. Unfortunately I removed this trunk (before I checked out the current version) and thus I don\'t know its exact version.\n\nWe found out, that in the new caffe version, the CMakeList files and structure changed for building the protobuf files and part, respectively (in comparison to our old caffe snapshot!). So it seems, that these changes cause our trouble. I would like to test the last 2-3 caffe master versions. Is there a way to check out these older versions?\n\nOne more issue: Handling different classifiers in different libraries is  a perfect way to allow for a flexible system structure, which is essential for a modular system concept. But even in this dynamic framework we only load ""libcaffe.so"" once which is a part of the main application. This is the usual way to handle shared objects.\n', '> Is there a way to check out these older versions?\n\nYou can check out _any version of the project_ since it is versioned through git. You can also look at [our releases](https://github.com/BVLC/caffe/releases) and pick a favorite.\n\n> CMakeList files and structure changed\n\n#1667 overhauled the CMake build.\n\n> One more issue: Handling different classifiers in different libraries is a perfect way to allow for a flexible system structure, which is essential for a modular system concept. But even in this dynamic framework we only load ""libcaffe.so"" once which is a part of the main application. This is the usual way to handle shared objects.\n\nRight, that\'s sensible and fine -- what I was trying to say and why I linked the protobuf issue is that multiple libraries linked to protobuf (like Caffe classifiers) can conflict if they have a shared message. The protobuf issue suggests statically linking your classifier modules to libprotobuf. Earlier the whole Caffe project was static linked but we\'ve switched to dynamic linking.\n', ""You may want to try the `Makefile`/`Makefile.config` build; at present the CMake build is still community-supported, so I can't offer specific help with that.\n\nThe error you're getting does suggest that `libcaffe` is being loaded twice. You may want to check this with `LD_DEBUG`.\n\nIf you can produce a minimal non-working example using the `Makefile` build, I may be able to look into the issue.\n"", 'Thanks for you fast replies. We solved our problem, which was caused by linking the ""libproto.a"" to our dynamic libraries. This causes the above error and is not necessary anymore with the new caffe version. Now everything is fine and works. :-)\n\nThank you for your great support & best regards, Tom\n', 'Yep, linking caffe against libprotobuf.a instead of libprotobuf.so could solve this issue.\n', '@tianzhi0549 Can you show in details how to link caffe against libprotobuf.a instead of libprotobuf.so. Thank you so much.\n', ""@denny1108 I changed caffe's Makefile. Specifically, I added `-Wl,-Bstatic -lprotobuf -Wl,-Bdynamic` to `LDFLAGS` and removed `protobuf` from `LIBRARIES`.\n\nI have uploaded my Makefile to gist(https://gist.github.com/tianzhi0549/773c8dbc383c0cb80e7b). You could check it out to see what changes I made (Line 172 and 369).\n"", ""@tianzhi0549 Changing the Makefile gives:\n\nLD -o .build_debug/lib/libcaffe.so\n/usr/bin/ld: /usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libprotobuf.a(common.o): relocation R_X86_64_32S against `_ZTVN6google8protobuf7ClosureE' can not be used when making a shared object; recompile with -fPIC\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libprotobuf.a: error adding symbols: Bad value\ncollect2: error: ld returned 1 exit status\n\nANy ideas on how to solve this?\n"", '@nbubis Try to run `make clean` before running `make`.\n', 'This is after make clean.\nOn Jan 27, 2016 18:22, ""Tian Zhi"" notifications@github.com wrote:\n\n> @nbubis https://github.com/nbubis Try to run make clean before running\n> make.\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/1917#issuecomment-175720631.\n', ""@nbubis Sorry for that. \nI find [this issue](https://github.com/rbenv/ruby-build/issues/690) is similar to yours. You could give it a try. It seems that protobuf isn't installed correctly. Thank you:-).\n"", '@tianzhi0549 thank you so much. At the end, I uninstall the old protobuf and install a new version, which solve my problem. It seems that the old protobuf on my machine can only generate one network instance for caffe. \n', '@denny1108 Can you please tell me which version of protobuf worked for you. I am also facing this issue. Basically when I run MATLAB + caffe code for this first time, it works fine. But rerunning the same code crashes. If I restart MATLAB, the same code runs fine again. Its painful to restart MATLAB everytime I need to rerun. (will be helpful if you could share URL/details what exactly you did to fix this issue). \n', '@puneetdabulya  & whoever else runs into this issue:\n\nThe issue seems to be memory deallocation by the caffe code. Using a static version of protobuf therefore solves the issue, since the protobuf lib is loaded separately by each instance of caffe.\n\nTo solve:\n\nUninstall any protobuf compilers you currently may have on your system.\nDownload the protobuf C++ source code (v3 beta worked) from github.\nConfigure protobuf with ./configure --disable-shared, and then build & install as usual.\nRebuild caffe with the corrected makefile posted above by @tianzhi0549.\n\nGood luck!\n', ""@nbubis Thank you for the instructions. Those who are stuck at after following the above instructions.\n\nLD -o .build_debug/lib/libcaffe.so\n/usr/bin/ld: /usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libprotobuf.a(common.o): relocation R_X86_64_32S against `_ZTVN6google8protobuf7ClosureE' can not be used when making a shared object; recompile with -fPIC\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libprotobuf.a: error adding symbols: Bad value\ncollect2: error: ld returned 1 exit status\n\nWhile installing protobuf, edit src/Makefile, in CXXFLAGS add -fPIC and recompile. It would fix this error.\n"", 'I have do as the instruction as above, but a new problem is: when I do ""make matcaffe"", there is something wrong,\nkaffe@kaffe:~/Documents/wmm/mat_faster_rcnn-master/external/caffe$ make matcaffeMEX matlab/+caffe/private/caffe_.cpp\nBuilding with \'g++\'.\n/home/kaffe/Documents/wmm/mat_faster_rcnn-master/external/caffe/matlab/+caffe/private/caffe_.cpp:21:35:*\\* fatal error: include/caffe/caffe.hpp: No such file or directory**\ncompilation terminated.\n\nmake: **\\* [matlab/+caffe/private/caffe_.mexa64] Error 255\nbut I have found caffe.hpp in the include/caffe/ , \nPlease help me with this!\n@puneetdabulya @nbubis @tianzhi0549 \n', 'Hi,\nI did the things mentioned by nbubis but still matlab crashes after the first run :(\n', 'Hello,\n\nAfter downloading protobuf C++ source code, configure, make and install, and recompiling Caffe, everything worked fine in Matlab (i.e. matcaffe), but pycaffe does not!\nI get an error while importing caffe in my python code:\nfrom google.protobuf import symbol_database as _symbol_database\nImportError: cannot import name symbol_database\n\nDoes anyone had a problem like this? What do you thing I can do to fix it?\n\nThanks.\n', 'I installed pycaffe recently. Most protobuf related issues can be solved by\ninstalling tensorflow using pip. First install pip and then search for how\nto install tensorflow.\n\nHope it works.\n\nThanks\n\nOn Tuesday, March 8, 2016, NoaArbel notifications@github.com wrote:\n\n> Hello,\n> \n> After downloading protobuf C++ source code, configure, make and install,\n> and recompiling Caffe, everything worked fine in Matlab (i.e. matcaffe),\n> but pycaffe does not!\n> I get an error while importing caffe in my python code:\n> from google.protobuf import symbol_database as _symbol_database\n> ImportError: cannot import name symbol_database\n> \n> Does anyone had a problem like this? What do you thing I can do to fix it?\n> \n> Thanks.\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/1917#issuecomment-193828243.\n\n## \n\n--Puneet\n', 'It worked!\nThanks @puneetdabulya\n', ""I'm facing with this problem. Even though I reinstalled the latest protobuf, my matlab program also crashes in second time. Please help me to resolve this error. Thank you very much!\n"", 'The root cause is some 3rd party library, such as opencv, are built with caffe.proto\n\nThe opencv-contrib-dnn module should be disabled for my case.\n', '@raingo \nWould you share that How to disable opencv-contrib-dnn module ?\nI am currently facing the similar problem... \n', '@KentChun33333 `cmake -D BUILD_opencv_dnn=OFF`\n', '@raingo works for me, thanks!\n\n@KentChun33333 you could remove dnn directory from opencv_contrib/modules, and re-compile opencv with opencv_contrib again.\n', '@raingo workaround worked also for me, thanks!\n\nSo, is this a problem on protobuf? on caffe? or in opencv?\nWe should report it where it belongs in order to be properly fixed... right? ;-)\n', ""@agilmor It's a problem on the third part module of opencv named dnn, I think. \n"", ""Hello,\r\nI'm having a similar problem but I've traced the root of the problem to a ros install.\r\nI have a program that loads an interface for caffe via a dynamically loaded plugin as well as an interface for ROS via another plugin.  Only one of these plugins can be loaded at a time.\r\nI used LD_DEBUG=libs which revealed that the ROS plugin is only loading libprotobuf.so not caffe's libproto.a.  To me this indicates that it's not just an issue with loading libproto.a, but it's an issue of anything linking protobuf.\r\n\r\nThe exact error is:\r\n[libprotobuf ERROR google/protobuf/descriptor_database.cc:57] File already exists in database: caffe.proto\r\n[libprotobuf FATAL google/protobuf/descriptor.cc:1018] CHECK failed: generated_database_->Add(encoded_file_descriptor, size): \r\nterminate called after throwing an instance of 'google::protobuf::FatalException'\r\n  what():  CHECK failed: generated_database_->Add(encoded_file_descriptor, size): \r\n\r\nIt does work correctly if I build against a static libprotobuf.a.\r\n"", 'I run ""make clean"", after that run ""make"". This problem is solved. ', 'another possibility is that you messed up the bashrc file (when you have multiple caffe versions)', 'I find the above instruction not worked and I configure protobuf with ./configure --enable-shared --with-pic, then it works.', '@dtmoodie, i have the same error, can you please elaborate me the solution. Where i have to used  LD_DEBUG=libs??', '@TomKae please guide me to solve the error. ', 'Sorry, we do not use caffe anymore and I do not remember how we solved \nthe problem. It was a long time ago!\n\nBest regards,\n\nThomas\n\nAm 24.08.2017 um 12:57 schrieb sainisanjay:\n>\n> @TomKae <https://github.com/tomkae> please guide me to solve the error.\n>\n> \n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub \n> <https://github.com/BVLC/caffe/issues/1917#issuecomment-324603126>, or \n> mute the thread \n> <https://github.com/notifications/unsubscribe-auth/AKYAEpgK8bS_doDeG0cUUlxUiw0Hivb3ks5sbVcVgaJpZM4DjT5Y>.\n>\n\n\n-- \nDr. Thomas Kster\n\nDeep Learning Laboratory\nInstitut fr Neuro- und Bioinformatik\nUniversitt zu Lbeck\nRatzeburger Allee 160 (Geb. 64, Raum 18)\nD-23562 Lbeck\n  \nTel.:    +49 451 8836818\nFax:     +49 451 8836819\n\n', 'My solution can be found here: https://github.com/dtmoodie/docker_scripts/blob/master/deploy/Dockerfile\r\n\r\nI compile protobuf from source with the correct flags and then compile Cafe against a static protobuf.', 'Thanks @TomKae @dtmoodie For your response. However, my problem is exactly solved by using following link solution.\r\nhttps://xiaobai1217.github.io/2017/08/07/fast_rcnn/#more\r\n ', ""My solution way is that:\r\n`Rebuilding opencv with -D BUILD_opencv_dnn=OFF and then rebuilding caffe solved the issue. `\r\nLike this link:\r\n[https://stackoverflow.com/questions/43661767/raspberry-pi-2-with-caffe-protobuf-error](url)\r\nThe premise is that I have already done these operations\r\n`added -Wl,-Bstatic -lprotobuf -Wl,-Bdynamic to LDFLAGS and removed protobuf from LIBRARIES.`\r\nMaybe don't need these operations!\r\n""]",[],[],0,0
220,caffe,1861,closed,caffe on jetson tk1,"Got an error during runtest
F0213 10:25:10.921640  9387 db.hpp:109] Check failed: mdb_status == 0 (-30792 vs. 0) MDB_MAP_FULL: Environment mapsize limit reached
**\* Check failure stack trace: ***
    @ 0x44a85060  (unknown)
    @ 0x44a84f5c  (unknown)
    @ 0x44a84b78  (unknown)
    @ 0x44a86f98  (unknown)
    @   0x265ec2  caffe::db::LMDBTransaction::Put()
    @   0x21b932  caffe::DBTest_TestWrite_Test<>::TestBody()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()



Aborted
make: **\* [runtest] Error 134
I followed the install instruction mostly from http://petewarden.com/2014/10/25/how-to-run-the-caffe-deep-learning-vision-library-on-nvidias-jetson-mobile-gpu-board/ , except for that I installed some newer version stuff.
Anyone know how to solve this?
Great THX in advance!
",,"[""You could try enabling the DEBUG flag in Makefile.config and see if you get any more useful information.\n\nUnfortunately, we have little experience running on this hardware, so we can't provide support here. You may have better luck asking on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) mailing list.\n"", 'A link to a write-up on an updated install: http://jetsonhacks.com/2015/01/17/nvidia-jetson-tk1-caffe-deep-learning-framework/\n', 'Great THX to Jetsonhaks providing a very nice and easy solution! Thx to erictzeng for advice too!\n', ""@kaaicheung What solved the problem for you? @jetsonhacks do you have any thoughts? I'm building master at 543afd36b769675b6de113b3903aaa9866d517d0 and getting the following from `make runtest` on my Jetson:\n\n```\n[----------] 5 tests from DBTest/1, where TypeParam = caffe::TypeLMDB\n[ RUN      ] DBTest/1.TestWrite\nF0614 22:42:15.186868 10357 db.hpp:109] Check failed: mdb_status == 0 (-30792 vs. 0) MDB_MAP_FULL: Environment mapsize limit reached\n*** Check failure stack trace: ***\n    @ 0x432cd060  (unknown)\n    @ 0x432ccf5c  (unknown)\n    @ 0x432ccb78  (unknown)\n    @ 0x432cef98  (unknown)\n    @ 0x43be9450  caffe::db::LMDBTransaction::Put()\n    @   0x20c0d2  caffe::DBTest_TestWrite_Test<>::TestBody()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\n    @   0x2b3700  testing::internal::HandleExceptionsInMethodIfSupported<>()\nmake: *** [runtest] Aborted\n```\n\nThings seem to be working otherwise; is the problem local to `lmdb` components?\n"", ""@erictzeng I think this issue is due to the Jetson being a 32-bit (ARM) device, and the constant `LMDB_MAP_SIZE` in `src/caffe/util/db.cpp` being too big for it to understand. Here's the whole line:\n\n```\nconst size_t LMDB_MAP_SIZE = 1099511627776;  // 1 TB\n```\n\nThe solution [suggested](https://groups.google.com/forum/#!searchin/caffe-users/MDB_MAP_FULL/caffe-users/V9nE6tChaOQ/469dwRs06CoJ) by   of using 2^29 (`536870912`) instead works at least well enough to get all the tests to run successfully.\n\nI'm not at all sure that this is the best solution; another value might be better, or some other workaround for 32-bit systems; I'm not sure. Maybe there's a way to add a setting in `Makefile.configure` so that this can be adjusted without hand-editing the source.\n\nFixing this would be really great; small systems like the Jetson are super fun places to run Caffe and it would be nice if it installed easily there.\n\n@erictzeng would you consider re-opening this issue and suggesting some preferable solution along the lines of the above?\n\nI'll try to reply to the [two](https://groups.google.com/forum/#!searchin/caffe-users/MDB_MAP_FULL/caffe-users/V9nE6tChaOQ/469dwRs06CoJ) [threads](https://groups.google.com/forum/#!searchin/caffe-users/MDB_MAP_FULL/caffe-users/_6e5i9s-62w/2f9u4JSuKnQJ) on the email list where this has come up.\n\nThanks @erictzeng @kaaicheung @jetsonhacks!\n"", 'Argh; I\'m afraid the ""fix"" was not as successful as I had hoped. While `make runtest` works just fine, I\'m still unable to run the MNIST LeNet example using LMDB. If I switch over to LevelDB it seems to work though, so I have that workaround for the moment.\n', '@ajschumacher That was a good catch on the 32 bit issue. I guess there will always be a tension between the 64 bit unconstrained implementation versus the 32 bit with more limited resources.\n', 'Thanks @jetsonhacks - credit due to  on the mailing list.\n\nI also wrote up more about my setup efforts here: http://planspace.org/20150614-the_nvidia_jetson_tk1_with_caffe_on_mnist/\n', 'To get the LMDB portion of tests to work, make sure to also update `examples/mnist/convert_mnist_data.cpp` as well:\n\n``` C++\nexamples/mnist/convert_mnist_data.cpp:89:56: warning: large integer implicitly truncated to unsigned type [-Woverflow]\n     CHECK_EQ(mdb_env_set_mapsize(mdb_env, 1099511627776), MDB_SUCCESS)  // 1TB\n                                                        ^\n```\n\nHere is the end of my run:\n\n``` javascript\n$ make runtest\n\n[...]\n\n[----------] Global test environment tear-down\n[==========] 1209 tests from 210 test cases ran. (4425801 ms total)\n[  PASSED  ] 1209 tests.\n\n  YOU HAVE 2 DISABLED TESTS\n```\n', ""I tried to change the LMDB_MAP_SIZE to 536870912 and my second try is 268435456\nI use create_imagenet.sh\nI think the convert_mnist_data.cpp doesn't have connection to create_imagenet.sh... but I change it also in the second try to 268435456\nBoth are failed in the same position....\nBelow is the error\nAny idea?\n\nE1209 10:04:34.680079  4314 convert_imageset.cpp:143] Processed 5475000 files.\nE1209 10:04:37.770831  4314 convert_imageset.cpp:143] Processed 5476000 files.\nF1209 10:04:39.165669  4314 db.hpp:109] Check failed: mdb_status == 0 (-30792 vs. 0) MDB_MAP_FULL: Environment mapsize limit reached\n**\\* Check failure stack trace: ***\n    @     0x7f9970dc2daa  (unknown)\n    @     0x7f9970dc2ce4  (unknown)\n    @     0x7f9970dc26e6  (unknown)\n    @     0x7f9970dc5687  (unknown)\n    @     0x7f99711bc9c0  caffe::db::LMDBTransaction::Put()\n    @           0x403802  main\n    @     0x7f996ffd2ec5  (unknown)\n    @           0x40431c  (unknown)\n    @              (nil)  (unknown)\nAborted (core dumped)\n\nFYI, I use amazon web service with ubuntu14.04 64bit. I put image data into other partition and I put the lmdb file to another partition.\n"", ""Update for my problem,\nfinally I made it.\nI increase the LMDB_MAP_SIZE to 2TB (2^31 or twice the original 1TB)\nand I used to forget to make all the caffe, so it was not affecting anything without make all the caffe (newbie's mistake haha)\n"", ""Hello, I am having a problem going form lmdb files generated on my mac (64-bit) to the jetson tx1 (32-bit)\n\nAfter a full day of trouble shooting, I've come to the conclusion that lmdb files that work on my TX1 dont work on my mac, and lmdb files that work on my mac don t work on my TX1.  I am creating my lmdb files from my mac, and using an external drive to bring them over to the TX1.  Does anyone know how I could convert my lmdb file from the 64-bit format to the 32 bit format??\n\nEverything else works smoothly.. for now ^^\n\nThanks\n\nJ\n""]",['\n@   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()\n@   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()\n@   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()\n@   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()\n@   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()\n@   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()\n@   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()\n@   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()\n@   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()\n@   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()\n@   0x230568  testing::internal::HandleExceptionsInMethodIfSupported<>()\n'],[],0,0
221,caffe,1169,closed,"Modular model definitions: network layer, layer modules, and protobuf generation","Does anyone see any value in a new layer type that is itself a network? This would allow a recursive inclusion of networks within networks. 

The inception module used in GoogLeNet is an example of a network-in-network. I provided an implementation of GoogLeNet's Inception ""module"" in [this](https://github.com/BVLC/caffe/issues/1106). With Caffe as it is, if you want to build GoogLeNet, you would have to copy all those Inception module layers 9 times thereby duplicating the same thing many times, changing the names of layers and top and bottom blobs to be unique within the net. By contrast, if we have a Network layer type, then each Inception module  would appear as a single layer instance of type NETWORK (perhaps). It would refer to the network's prototxt somehow, and specify values for the the things that are distinctive about each instance of the Inception module (such as the number of output channels of each of the convolutions and the pool).  And also the bottom and top blob names. 

Am I on my own if I want this implemented? Anyone already working something like this? I wouldn't want to duplicate effort.
",enhancement,"[""A compositional way to define networks is desirable and has been discussed, but I don't know of any concrete efforts underway right now (correct me if you know otherwise).\n\nThis could be done the way you describe, with a layer type that actually inserts a sequence of layers defined by another prototxt, or it could be done in many other ways.\n\nPersonally I'm partial to the idea that we need a better language for defining nets, which supports composition in a simple and natural way. In particular, it might not be too hard to make it possible to generate net definitions from Python code. I might work on this, but not right away.\n\n(The language has gotten rather convoluted here. This is not recursion; it's simple composition of functions. Notwithstanding the name network-in-network, let me make it clear to those reading that we are still talking about DAGs of layers, nothing more complicated.)\n"", ""Thanks for the reply @longjon. \n\nJust one point of confusion I have in case it implies some profound error on my part. Regarding this:\n\n> This is not recursion; it's simple composition of functions. Notwithstanding the name network-in-network, let me make it clear to those reading that we are still talking about DAGs of layers, nothing more complicated.\n\nMaybe I'm missing some subtle distinction here. If there were a layer type for a network, and that network can also include layers of type network, then it seems to me one needs to recursively parse included networks and their layers of type NETWORK in order to instantiate the DAG that one ultimately ends up with. So I don't see how the design approach isn't both recursive and still ultimately producing a DAG of non-network layer instances. Don't see how they are incompatible as your comment suggests. But I'm from an engineering background not CS so maybe I'm missing your point.\n\nRegarding generation of net definitions from Python code: I'm not warm to that idea, not being a Python person. I rather like the protobuf-based definitions. Guess I'd have to see how it works. Not that my opinion should count much on the matter.\n"", '@jyegerlehner, I think your understanding is correct. To be clear: the network is a function written in the prototxt language, and that function is not recursive. (In particular, we are not talking about recurrent nets here.) Caffe parses that definition using some code written in C++, which very well might be recursive.\n\n(To me, ""recursive inclusion"" suggests including a network within _itself_, which is not what we are talking about here. And the neologism ""network-in-network"" suggests a broader space of possible nets, but this is purely about notation.)\n\nRest assured, the protobuf definitions are not going anywhere. But they are just data, and we may gain some new ways to manipulate that data.\n', ""If you're interested in generating protobufs for networks such as these in python, I have an example you can use.\nhttps://github.com/kmatzen/caffe/blob/inception_plan/python/inception_plan.py\n"", '@longjon Thanks for the followup reply, and it explaining it to me slowly so I can understand. I see my use of ""recursive"" was confusing/wrong.\n\n@kmatzen Nice python code! Thanks for sharing that. I guess that might be the kind of thing longjon was referring to above when he said generate net definitions from python code.\n\nLooking at your example makes me wonder if perhaps we just want to keep the prototxt for a net flat like it is now, and not add in a ""network in network"" kind of module composability. Whenever we need to include a module such as the inception module in our net, then we just write a script that generates the flattened prototxt. On the other hand we might want to see the original structure showing the modules. If we generate prototxt as in your example, the modules have all been flattened, and the composition of the modules is no longer visible. I\'m writing a utility that generates a graphviz dot file from prototxt, and it would be good to have the option of seeing the modules in the graph instead of only just the flattened net. \n', '> @kmatzen Nice python code! Thanks for sharing that.\n\nAgreed! Really well-written Python module for building GoogLeNet and a great example of using the Pycaffe proto library to generate nets (which I think is underutilized due to lack of examples, including by myself). Well done and thanks for sharing @kmatzen.\n\nI haven\'t actually tried running it, but assuming it really does generate the GoogLeNet architecture as described in the [paper](http://arxiv.org/abs/1409.4842), I think it would be a very useful example to have in Caffe, if you\'d be willing to contribute it.\n\n> Looking at your example makes me wonder if perhaps we just want to keep the prototxt for a net flat like it is now, and not add in a ""network in network"" kind of module composability. Whenever we need to include a module such as the inception module in our net, then we just write a script that generates the flattened prototxt.\n\nI think this is a pretty reasonable option. I\'ve actually never used caffe_pb2 in Python, I\'ve just written my own hacky Python scripts which themselves generate the model prototxt as text, and both options seem to work well enough.  But I don\'t doubt there are better ways of doing these things as @longjon describes.\n\nIt could be possible to add something to the NetParameter to let you define named ""modules"", which are each essentially a mini-net (e.g. an ""inception"" module from googlenet) with inputs and a series of layers and some outputs.  Then instead of a `type:` one could specify a `module:` (as a string, referring to one of the defined module names).\n', '> Well done and thanks for sharing @kmatzen.\n\nYeah, thanks @kmatzen!\n\n> It could be possible to add something to the NetParameter to let you define named ""modules"", which are each essentially a mini-net (e.g. an ""inception"" module from googlenet) with inputs and a series of layers and some outputs. Then instead of a type: one could specify a module: (as a string, referring to one of the defined module names).\n\nI like this line of thought, but haven\'t worked it out fully as far as what `Net::Init` should do and how it should be defined in proto. For instance, multi-scale models have weight shared modules that are identical models with different bottoms and tops within the module. Defining a `module` instead of `type` that is itself a collection of layers but keeping the `bottoms` and `tops` of the layer definition could override the inputs and outputs of the module. Defining a `ModuleParameter` to hold mini-nets like @jeffdonahue suggested should work in this scheme. It would be nice to reconcile weight sharing with this too, so that one could have distinct or shared modules.\n\nBarring that, keeping a flat net definition certainly works, and the better one scripts the more expressive the models can be -- nevertheless it would be nice to include modularity into the model schema itself.\n', '@kmatzen, indeed, this is how you get net protobufs from Python.\n\nIn fact I have in mind something a bit more generic and succinct... essentially a little library to let you write down a function in more-or-less natural Python code while actually constructing a net protobuf.\n\n@jeffdonahue @shelhamer, indeed, specifying composition within the net protobuf might be useful as well...\n\n@jyegerlehner, indeed, one may want to see the net at different levels of abstraction (just as, when using a generic compiler, sometimes one wants to see source code, or an AST, or assembly, or some intermediate form.) In any case our visualization tool `python/draw_net.py` could certainly use some improvements...\n', '@longjon \n\n> our visualization tool python/draw_net.py could certainly use some improvements...\n\nI had no idea draw_net.py existed. I was doing something redundant. Sigh. What does it need by way of improvements?\n', '@shelhamer,\n\n> Defining a module instead of type that is itself a collection of layers but keeping the bottoms and tops of the layer definition could override the inputs and outputs of the module.\n\nJust to make sure I\'m following: you\'re suggesting that rather than have a layer type called  MODULE, one would either specify a type for the layer, or a module, but not both. \n\n> I like this line of thought, but haven\'t worked it out fully as far as what Net::Init should do and how it >should be defined in proto. \n\nI have a few embryonic ideas in that direction, from just perusing the `Net::Init` code. Perhaps the `module` layers (as opposed to layers with a `type`) could be expanded in the `Net::FilterNet` method, which is the first thing `Net::Init()` does. All the work of in-lining the modules could be in `Net::FilterNet`. So by the time we get to the rest of `Net::Init`, the modules have already been expanded, or in-lined, and all that\'s seen is a flat DAG without any `module` layers left. So (knock on wood) no other code in `Net::Init` would have to change, perhaps?\n\nAnother thing I think would need to happen in `Net::FilterNet` is that as one instantiates the `module` layers in a net, is to qualify the names of the layers that get produced with the name of the parent module layer. So for example say we had a net that has an Inception module, and a couple layers that instantiate the module:\n\n``` protobuf\nname: ""GoogLeNet""\n\nmodules {\n  name: ""Inception""\n  ... other layers...\n  layers {\n    name: ""1x1_relu""\n    type: RELU\n    bottom: ""1x1_conv""\n    top: ""1x1_relu""\n  }\n  ... other layers...\n}\n\n... other layers\n\nlayers {\n  name: ""inception3a""\n  module: ""Inception""\n  ... stuff omitted, such as naming of top and bottom blobs\n}\n\nlayers {\n  name: ""inception3b""\n  module: ""Inception""\n  ... stuff omitted, such as naming of top and bottom blobs\n}\n```\n\nThen after `Net::FilterNet` finishes inlining the `module` layers, `1x1_relu` layer of the module would be qualified with its parent layer\'s name resulting in two corresponding instances, one named `inception3a::1x1_relu` and another `inception3b::1x1_relu`. Same thing for the blobs. So after `Net::FilterNet` is done, the inlined prototxt would contain:\n\n``` protobuf\nname: ""GoogLeNet""\n\n... other layers\n\nlayers {\n  name: ""inception3a::1x1_relu""\n  type: RELU\n  bottom: ""inception3a::1x1_conv""\n  top: ""inception3a::1x1_relu""\n}\n\n...other layers\n\nlayers {\n  name: ""inception3b::1x1_relu""\n  type: RELU\n  bottom: ""inception3b::1x1_conv""\n  top: ""inception3b::1x1_relu""\n}\n```\n\nInception modules are also parameterized by numbers of filters of various layers. For example the 3x3 convolution layer\'s num_output is 128 in inception 3a, and different values in other instances of the inception module. There would need to be some mechanism for the module to declare what parameters need to be specified when it is included in a net, and check that those are all supplied at the instantiating site.\n\n> It would be nice to reconcile weight sharing with this too, so that one could have distinct or shared modules.\n\nRegarding this, perhaps a module could specify a .caffemodel from which to copy its weights, if what is desired is shared weights everytime the module is instantiated. Or in the case like GoogLeNet where each inception module has its own weight shapes and values, that would all be handled like normal since only the inlined, or flattened, net would ever be serialized/deserialized, and all the layers have unique names by that time.\n\nSo does this sound like a plausible approach? Fatal flaws? Better ideas?\n', 'For weight sharing all the module needs is to set the right `param` fields, just as its `bottoms` and `tops` need to be hooked into the flat definition. The issue is how to define in the proto which param names to assign to which module layers. A preliminary solution could be a flag to either (1) do the module + layer name mangling as @jyegerlehner suggested for layer names and connections for no sharing, or (2) preserve the `param` fields defined in the module for weight sharing among all instantiations of a given module.\n', ""@jyegerlehner yup, that's pretty much what I had in mind.  I'd suggest a minor design change though: rather than adding it to `FilterNet`, create a separate method to do the module inlining only, and then another method that calls both `FilterNet` and the new module inlining method (maybe called `FlattenNet`).\n"", '> create a separate method to do the module inlining only, and then another method that calls both FilterNet and the new module inlining method (maybe called FlattenNet).\n\nAgreed. The module inlining should follow the filtering since modules could follow all the same rules for layers.\n', 'Thanks for the comments all.  \n\nStarting to develop this and hope it will culminate in a PR as soon as I have something working. If you think of anything else I need to consider please pass it on. \n', ""I'll just add: it may be a while. The day job, and all that. If someone else is working on this or wants to collaborate please let me know. I can try to commit more incrementally and give permissions to my feature branch.\n"", 'How much memory does this model require? Its huge memory demand probably will stop it from running on GPU. The distributed training #1148 is a prerequisite to use this huge net. It is doubtful whether it is worthwhile to not use the VGG model if the dataset has only a few millions of images.\n', ""Minibatch size of 256 -> 13.1469 GB.\n\nEdit: Unless I defined GoogLeNet incorrectly.  The dot visualization looks correct and the dimensions match up, but I haven't actually trained it to verify correctness.\n"", 'For the training of memory-hungry models see https://github.com/BVLC/caffe/issues/1242#issuecomment-59580344.\n\n@kloudkl not so. cuDNN or shared column buffers #1291 reduce memory usage, most importantly one can decouple the learning batch size from the computation / data batch size by accumulating gradients.\n\n@kmatzen your calculation sounds right -- I did not check it -- but accumulating gradients can drive this down as you like. Note too that you do not necessarily want a batch size of 256 for GoogLeNet.\n', 'I just got #1290 to pass, it lets you import a net as a layer. It was used initially for siamese nets, but the mechanism is generic.\n', '@cypof Thanks that\'s interesting. It looks similar to what I was doing. I like the simplicity of the variable configuration via string replace; I had been going down the route of using protocol buffer\'s reflection API. \n\nLooks like your implementation forces a module to be in another file. My preference is to modify the Net proto to allow it to contain Modules as well as Layers (Modules containing Layers). Then a layer (of type IMPORT in your scheme) would merely refer to the module by name. So it can all be in one protobuf file, and not force modules into separate files. But that would be a straightforward extension to what you\'ve already got that I or we can add later.\n\nWould you be averse to changing IMPORT enum to MODULE? ""Import"" seems to suggest that a separate file is being imported, whereas it would be good to leave the door open to Modules defined in the same Net protobuf file that they are instantiated in.\n\nI\'ll suspend working on my feature branch in anticipation of your PR getting merged, at least until we get some indication from the maintainers. In the meantime I\'ll grab your feature branch and give it a whirl.\n', ""It's astonishingly simple to [define the GoogLeNet inception model module by module in Torch7](https://github.com/nagadomi/kaggle-cifar10-torch7/blob/f70fac78c4a1a37df15183e5d711dc0e0b1b254b/inception_model.lua). There must be something wrong with it.\n"", '@futurely it seems they just defined an inception template -- nothing wrong with that. In @kmatzen has linked his Python + Caffe inception generator earlier in this thread https://github.com/BVLC/caffe/issues/1169#issuecomment-57834743:\n\nhttps://github.com/kmatzen/caffe/blob/inception_plan/python/inception_plan.py#L477-L610\n\nExpect more Pythonified Caffe tools shortly for defining and experimenting with networks.\n', ""I used the generator to get a 2000+ lines of prototxt. That's why I was shocked by the extreme conciseness of Torch7.\n"", 'BTW, that torch implementation is missing the auxiliary classifiers, although it would still be more concise after they are added.\n\nI typically hate defaults, but needing to specify all of your connections in caffe does get a bit old after awhile.\n', 'Developer time is much more expensive than machine time.\n', 'Take a look to #1518 \n']",[],[],0,0
222,caffe,5077,closed,make runtest failed,"I have the following error while running the 'make runtest'. I have tried with cpu flag enabled and disabled both, same error.

",,"[""What's your operating system? Ubuntu devel seems to suffer from a similar problem.\r\n\r\nhttps://launchpadlibrarian.net/298212926/buildlog_ubuntu-zesty-amd64.caffe_1.0.0~rc3+20161127-g24d2f67-4_BUILDING.txt.gz"", 'I am using kubuntu 16.10\n\nOn 16 Dec 2016 02:18, ""L. Zhou"" <notifications@github.com> wrote:\n\n> What\'s your operating system? Ubuntu devel seems to suffer from a similar\n> problem.\n>\n> https://launchpadlibrarian.net/298212926/buildlog_ubuntu-\n> zesty-amd64.caffe_1.0.0~rc3+20161127-g24d2f67-4_BUILDING.txt.gz\n> <https://launchpadlibrarian.net/298212926/buildlog_ubuntu-zesty-amd64.caffe_1.0.0%7Erc3+20161127-g24d2f67-4_BUILDING.txt.gz>\n>\n> \n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/BVLC/caffe/issues/5077#issuecomment-267492285>, or mute\n> the thread\n> <https://github.com/notifications/unsubscribe-auth/AH_dXyuJKIfFjQfHQKQklEM7PubSEYf1ks5rIebQgaJpZM4LIYwD>\n> .\n>\n', 'I also have ubuntu 16.10, no cpu.\r\n\r\nI have the same issue too, although:\r\n- Pycaffe runs ok\r\n- lenet runs ok\r\n\r\nAfter I set DEBUG=1, and I ran:\r\n\r\nprotoc src/caffe/proto/caffe.proto --cpp_out=.\r\nmkdir include/caffe/proto\r\nmv src/caffe/proto/caffe.pb.h include/caffe/proto\r\n\r\nbecause I had issues with caffe.pb.h,\r\n\r\nruntest  fails after a while when running:\r\nmake runtest\r\n\r\nI get  (excluding some needless lines):\r\n.build_debug/tools/caffe\r\n.build_debug/test/test_all.testbin 0 --gtest_shuffle --gtest_filter=""-*GPU*""\r\nNote: Google Test filter = -*GPU*\r\nNote: Randomizing tests\' orders with a seed of 77085 .\r\n\r\nMany test pass but then:\r\n[----------] 5 tests from ImageDataLayerTest/1, where TypeParam = caffe::CPUDevice<double>\r\n[ RUN      ] ImageDataLayerTest/1.TestRead\r\n[       OK ] ImageDataLayerTest/1.TestRead (84 ms)\r\n[ RUN      ] ImageDataLayerTest/1.TestResize\r\n*** Aborted at 1481935191 (unix time) try ""date -d @1481935191"" if you are using GNU date ***\r\nPC: @     0x7f14a0c870ba (unknown)\r\n*** SIGSEGV (@0xfffffffffffffff7) received by PID 16487 (TID 0x7f14871f2700) from PID 18446744073709551607; stack trace: ***\r\n    @     0x7f14a2152630 (unknown)\r\n    @     0x7f14a0c870ba (unknown)\r\n    @     0x7f14a0c8718b (unknown)\r\n    @     0x7f14a0c88ce8 (unknown)\r\n    @     0x7f14a0c87692 (unknown)\r\n    @     0x7f14a0c82020 (unknown)\r\n    @     0x7f14a0c80165 tbb::internal::allocate_root_with_context_proxy::allocate()\r\n    @     0x7f14a3e50e22 cv::parallel_for_()\r\n    @     0x7f14a3737b2a (unknown)\r\n    @     0x7f14a3734bb7 cv::resize()\r\n    @     0x7f14a2c093dd caffe::ReadImageToCVMat()\r\n    @     0x7f14a2d0694c caffe::ImageDataLayer<>::load_batch()\r\n    @     0x7f14a2c9037c caffe::BasePrefetchingDataLayer<>::InternalThreadEntry()\r\n    @     0x7f14a2c2e19b caffe::InternalThread::entry()\r\n    @     0x7f14a2c307d1 boost::_mfi::mf5<>::operator()()\r\n    @     0x7f14a2c306a9 boost::_bi::list6<>::operator()<>()\r\n    @     0x7f14a2c3059e boost::_bi::bind_t<>::operator()()\r\n    @     0x7f14a2c30550 boost::detail::thread_data<>::run()\r\n    @     0x7f14a33f7596 (unknown)\r\n    @     0x7f14a21486ca start_thread\r\n    @     0x7f14a1e820af clone\r\n    @                0x0 (unknown)\r\nSegmentation fault (core dumped)\r\n\r\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nMy config file:\r\n\r\n# USE_CUDNN := 1\r\n\r\n# CPU-only switch (uncomment to build without GPU support).\r\n CPU_ONLY := 1\r\n\r\n# uncomment to disable IO dependencies and corresponding data layers\r\n #USE_OPENCV := 1\r\n #USE_LEVELDB := 1\r\n #USE_LMDB := 0\r\n\r\n\r\n\r\n\r\n# ALLOW_LMDB_NOLOCK := 1\r\n\r\n# Uncomment if you\'re using OpenCV 3\r\n# OPENCV_VERSION := 3\r\n\r\n# To customize your choice of compiler, uncomment and set the following.\r\n# N.B. the default for Linux is g++ and the default for OSX is clang++\r\n# CUSTOM_CXX := g++\r\n\r\n# CUDA directory contains bin/ and lib/ directories that we need.\r\nCUDA_DIR := /usr/local/cuda\r\n# On Ubuntu 14.04, if cuda tools are installed via\r\n# ""sudo apt-get install nvidia-cuda-toolkit"" then use this instead:\r\n# CUDA_DIR := /usr\r\n\r\n# CUDA architecture setting: going with all of them.\r\n# For CUDA < 6.0, comment the *_50 lines for compatibility.\r\nCUDA_ARCH := -gencode arch=compute_20,code=sm_20 \\\r\n\t\t-gencode arch=compute_20,code=sm_21 \\\r\n\t\t-gencode arch=compute_30,code=sm_30 \\\r\n\t\t-gencode arch=compute_35,code=sm_35 \\\r\n\t\t-gencode arch=compute_50,code=sm_50 \\\r\n\t\t-gencode arch=compute_50,code=compute_50\r\n\r\n# BLAS choice:\r\n# atlas for ATLAS (default)\r\n# mkl for MKL\r\n# open for OpenBlas\r\nBLAS := atlas\r\n# Custom (MKL/ATLAS/OpenBLAS) include and lib directories.\r\n# Leave commented to accept the defaults for your choice of BLAS\r\n# (which should work)!\r\n# BLAS_INCLUDE := /path/to/your/blas\r\n# BLAS_LIB := /path/to/your/blas\r\n\r\n# Homebrew puts openblas in a directory that is not on the standard search path\r\n# BLAS_INCLUDE := $(shell brew --prefix openblas)/include\r\n# BLAS_LIB := $(shell brew --prefix openblas)/lib\r\n\r\n# This is required only if you will compile the matlab interface.\r\n# MATLAB directory should contain the mex binary in /bin.\r\n# MATLAB_DIR := /usr/local\r\n# MATLAB_DIR := /Applications/MATLAB_R2012b.app\r\n\r\n# NOTE: this is required only if you will compile the python interface.\r\n# We need to be able to find Python.h and numpy/arrayobject.h.\r\n#PYTHON_INCLUDE := /usr/include/python2.7 \\\r\n#\t\t/usr/lib/python2.7/dist-packages/numpy/core/include\r\n\r\n\r\n# Anaconda Python distribution is quite popular. Include path:\r\n# Verify anaconda location, sometimes it\'s in root.\r\n# ANACONDA_HOME := $(HOME)/anaconda\r\n PYTHON_INCLUDE :=  /home/steliox/anaconda2/include/python2.7 \\\r\n  /home/steliox/anaconda2/include \\\r\n\t\t /home/steliox/anaconda2/lib/python2.7/site-packages/numpy/core/include \\\r\n\r\n\r\n\r\n# Uncomment to use Python 3 (default is Python 2)\r\n# PYTHON_LIBRARIES := boost_python3 python3.5m\r\n# PYTHON_INCLUDE := /usr/include/python3.5m \\\r\n#                 /usr/lib/python3.5/dist-packages/numpy/core/include\r\n\r\n# We need to be able to find libpythonX.X.so or .dylib.\r\n#PYTHON_LIB := /usr/lib\r\n PYTHON_LIB := /home/steliox/anaconda2/lib\r\n\r\n\r\n# Homebrew installs numpy in a non standard path (keg only)\r\n# PYTHON_INCLUDE += $(dir $(shell python -c \'import numpy.core; print(numpy.core.__file__)\'))/include\r\n# PYTHON_LIB += $(shell brew --prefix numpy)/lib\r\n\r\n# Uncomment to support layers written in Python (will link against Python libs)\r\nWITH_PYTHON_LAYER := 1\r\n\r\n\r\n# Whatever else you find you need goes here.\r\nINCLUDE_DIRS :=  /usr/local/include /usr/include/hdf5/serial/\r\nLIBRARY_DIRS :=  /usr/local/lib /usr/lib  /usr/lib/x86_64-linux-gnu/ /usr/lib/x86_64-linux-gnu/hdf5/serial/\r\n\r\n\r\n# If Homebrew is installed at a non standard location (for example your home directory) and you use it for general dependencies\r\n# INCLUDE_DIRS += $(shell brew --prefix)/include\r\n# LIBRARY_DIRS += $(shell brew --prefix)/lib\r\n\r\n# Uncomment to use `pkg-config` to specify OpenCV library paths.\r\n# (Usually not necessary -- OpenCV libraries are normally installed in one of the above $LIBRARY_DIRS.)\r\n# USE_PKG_CONFIG := 1\r\n\r\n# N.B. both build and distribute dirs are cleared on `make clean`\r\nBUILD_DIR := build\r\nDISTRIBUTE_DIR := distribute\r\n\r\n# Uncomment for debugging. Does not work on OSX due to https://github.com/BVLC/caffe/issues/171\r\n DEBUG := 1\r\n\r\n# The ID of the GPU that \'make runtest\' will use to run unit tests.\r\nTEST_GPUID := 0\r\n\r\n# enable pretty build (comment to see full commands)\r\nQ ?= @\r\n\r\n', 'Hi,\r\nI would like to know, Is your problem solved? when I run `make runset`,I have got a same issue on ubuntu 16.04! could you please help me?', '@mohammad-py   It still fails in the same way exactly as mentioned above...\r\nI just cloned the latest caffe git repo + I have been updating my ubuntu system normally, running v17 now:\r\nI made the same procedure, but....\r\nwhen I tried \r\nmake runtest\r\nthe same things happen.', 'I get Check failed: error == cudaSuccess (35 vs. 0)\r\nCUDA driver version is insufficient for CUDA runtime version\r\nUbuntu 16.10 (Mint), gcc5, CUDA 8, Driver 378\r\n', "" I installed boost1.58 and added linked library and include path in bashrc.\r\nThen I had an error running make runtest', and finally I found that I made a tiny mistake in bashrc.\r\n\r\nThe boost lib should be added to LD_LIBRARY, rather than LIBRARY..."", 'Hi Guys,\r\n\r\nI started using https://github.com/BVLC/caffe/tree/opencl\r\n\r\nand now I am able to successfully execute make runtest. I am using opencl mode. I havent tried CPU only mode but if you have AMD this will work provided you have successfully installed AMD graphic card. I had to downgrade to 14.04 to install AMD graphic card.', 'From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\r\n\r\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\r\nUse the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.', ""hello all\r\ni have issued this today, and finally i've solved this by changing libtbb2 version\r\ni'm using Ubuntu 16.04 and it uses libtbb2 (4.4~20160526-0ubuntu1) [universe] as default\r\nfrom belowlink i found that there is a bug in pre-build package\r\nhttps://software.intel.com/en-us/forums/intel-threading-building-blocks/topic/636519\r\nso i changed to a new libtbb2 package as follow:\r\nlibtbb2 (4.4~20151115-0ubuntu3) [universe]  http://packages.ubuntu.com/xenial/libtbb2\r\nthis solved my problem\r\nregards!""]",[],"['----------] 5 tests from ImageDataLayerTest/1, where TypeParam = caffe::CPUDevice<double>\r\n[ RUN      ] ImageDataLayerTest/1.TestReshape\r\n[       OK ] ImageDataLayerTest/1.TestReshape (30 ms)\r\n[ RUN      ] ImageDataLayerTest/1.TestShuffle\r\n[       OK ] ImageDataLayerTest/1.TestShuffle (113 ms)\r\n[ RUN      ] ImageDataLayerTest/1.TestRead\r\n[       OK ] ImageDataLayerTest/1.TestRead (114 ms)\r\n[ RUN      ] ImageDataLayerTest/1.TestResize\r\n*** Aborted at 1481237980 (unix time) try ""date -d @1481237980"" if you are using GNU date ***\r\nPC: @     0x7ffb7938b0ba (unknown)\r\n*** SIGSEGV (@0xfffffffffffffff7) received by PID 5373 (TID 0x7ffb62eaa700) from PID 18446744073709551607; stack trace: ***\r\n    @     0x7ffb8254d670 (unknown)\r\n    @     0x7ffb7938b0ba (unknown)\r\n    @     0x7ffb7938b18b (unknown)\r\n    @     0x7ffb7938cce8 (unknown)\r\n    @     0x7ffb7938b692 (unknown)\r\n    @     0x7ffb79386020 (unknown)\r\n    @     0x7ffb79384165 tbb::internal::allocate_root_with_context_proxy::allocate()\r\n    @     0x7ffb80db6e22 cv::parallel_for_()\r\n    @     0x7ffb8117ab2a (unknown)\r\n    @     0x7ffb81177bb7 cv::resize()\r\n    @     0x7ffb83061997 caffe::ReadImageToCVMat()\r\n    @     0x7ffb82f708bb caffe::ImageDataLayer<>::load_batch()\r\n    @     0x7ffb82efc906 caffe::BasePrefetchingDataLayer<>::InternalThreadEntry()\r\n    @     0x7ffb82984596 (unknown)\r\n    @     0x7ffb8254370a start_thread\r\n    @     0x7ffb801b40af clone\r\n    @                0x0 (unknown)\r\nSegmentation fault (core dumped)\r\nsrc/caffe/test/CMakeFiles/runtest.dir/build.make:57: recipe for target \'src/caffe/test/CMakeFiles/runtest\' failed\r\n']",0,0
223,caffe,3841,closed,"Caffe Makefile Command line tools, and paths in El Capitan","Two intertwined issues

related to #3092

The caffe makefile produces

No receipt for 'com.apple.pkg.CLTools_Executables' found

when following the Atlas BLAS path on OS X 10.11

This can be fixed by changing : 

pkgutil --pkg-info=com.apple.pkg.CLTools_Executables

to 

pkgutil --pkg-info=com.apple.pkg.Xcode

Once that is taken care of, on machines with virgin installs of El Capitan, the /System/Library/Frameworks tree no-longer contains the Accelerate/veclib headers, and these have instead moved to a SDK tree under the Xcode app itself.

As a result, the line for BLAS_INCLUDE needs to be changes from:

BLAS_INCLUDE ?= /System/Library/Frameworks/Accelerate.framework/Versions/Current/Frameworks/vecLib.framework/Headers/

to

BLAS_INCLUDE ?= /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk/System/Library/Frameworks/Accelerate.framework//Vers\
ions/A/Frameworks/vecLib.framework/Versions/A/Headers/
",build,"['Thanks for reporting. The BLAS default dir is fixed in #4604, but the issue with the command line tools (`CLTools_Executables`) vs. Xcode is configured as desired if I recall correctly in that we prefer for the command line tools alone to suffice for compiling Caffe. If that is not working as expected, please comment.\n']",[],[],0,0
224,caffe,1549,closed,ImportError cannot import name BytesIO when import caffe on ubuntu,"I am trying to make [caffe](http://caffe.berkeleyvision.org/) running on my machine equipped with Ubuntu 12.04LTS. 
After finishing all the steps on the [Installation page](http://caffe.berkeleyvision.org/installation.html), I trained the LeNet model successfully and tried to use it as the tutorial from [here](http://radar.oreilly.com/2014/07/how-to-build-and-run-your-first-deep-learning-network.html). Then I got the following error:



I set the  in  file before I did the above.
What is the problem? Could anyone give some hint? I am really confused. 
",,"['This issue was also posted as a [question on Stack Overflow](http://stackoverflow.com/questions/27396664/importerror-cannot-import-name-bytesio-when-import-caffe-on-ubuntu); it looks like you set your `PYTHONPATH` to include `${HOME}/path/to/caffe/python/caffe` rather than `""${HOME}/path/to/caffe/python` (note the lack of the last `caffe` part in that).\n', 'Thanks, @mjpieters ! I adopted your suggestion and it works! \n']","['\nTraceback (most recent call last): \n    File ""<string>"", line 1, in <module>\nImportError: No module named caffe\nError in sys.excepthook:\nTraceback (most recent call last):\n    File ""/usr/lib/python2.7/dist-packages/apport_python_hook.py"", line 66, in apport_excepthook\n      from apport.fileutils import likely_packaged, get_recent_crashes\n    File ""/usr/lib/python2.7/dist-packages/apport/__init__.py"", line 1, in <module>\n      from apport.report import Report\n    File ""/usr/lib/python2.7/dist-packages/apport/report.py"", line 18, in <module>\n      import problem_report\n    File ""/usr/lib/python2.7/dist-packages/problem_report.py"", line 14, in <module>\n      import zlib, base64, time, sys, gzip, struct, os\n    File ""/usr/lib/python2.7/gzip.py"", line 10, in <module>\n      import io\n    File ""${HOME}/path/to/caffe/python/caffe/io.py"", line 2, in <module>\n      import skimage.io\n    File ""/usr/local/lib/python2.7/dist-packages/skimage/io/__init__.py"", line 11, in <module>\n      from ._io import *\n    File ""/usr/local/lib/python2.7/dist-packages/skimage/io/_io.py"", line 1, in <module>\n      from io import BytesIO\nImportError: cannot import name BytesIO\n\nOriginal exception was:\nTraceback (most recent call last): \n    File ""<string>"", line 1, in <module>\nImportError: No module named caffe\n']","['PYTHONPATH', '.bashrc']",0,0
225,caffe,1676,closed,Siamese network with RGB image,"Hi all,

The current example of siamese network uses two gray images as a channel of the data blob. How one should create a data blob for a pair of RGB images ?

Best regards
",,"['I managed to do what I want by using the slicing_point parameters.\n', '@jrabary how do you make db with RGB images? could you post it?\n', 'if I want to use RGB image dirctly with the layer( LayerType: IMAGE_DATA ), how to write the source param (source: name of a text file, with each line giving an image filename and label)? \n', '@jrabary could you tell us how you did it?\n']",[],[],0,0
226,caffe,296,closed,ImageNet LRN/MaxPool ordering,"I don't think it's explicitly stated anywhere that the ImageNet example is supposed to be an exact reimplementation of the Krizhevsky 2012 architecture, but if it is, then the order of the LRN and max pool layers in Caffe's implementation seems to be backwards.

This network uses conv -> max pool -> LRN.
https://github.com/BVLC/caffe/blob/master/examples/imagenet/imagenet_train.prototxt#L48

This text suggests that he used conv -> LRN -> max pool.
""Response-normalization layers follow the rst and second convolutional layers. Max-pooling layers, of the kind described in Section 3.4, follow both response-normalization layers as well as the fth convolutional layer.""

Either ordering seems to get good results, but for people reimplementing papers that say Krizhevsky's architecture was used, then it might be worthwhile to make sure your implementation matches his paper.
",,"[""Huh, looks like you're correct - interesting that nobody else has ever pointed this out after 8+ months of us using this reimplementation of the architecture (first in cuda-convnet, then decaf, now caffe).\n\nFeel free to send a PR with a note in the documentation that our implementation differs from Krizhevsky's published architecture in this way.  (And if someone from Berkeley cares to train an instance of the corrected version and finds it matches or outperforms the reference model, we could replace it.  It does seem more natural to normalize then max-pool.)\n\nEdit: actually we probably don't want to ever actually 'replace' the current reference model at this point as it's been used in many results that have already been disseminated in various forms, but we could (and probably will) have additional reference model(s).\n"", 'I\'m happy to re-train. What should we do with the result? The caffe_reference_imagenet_model is already in use, so it shouldn\'t be replaced outright.\n\n@jeffdonahue\'s suggestion of caffe_reference_alexnet_model should work fine. Note that for further exactness we should train with ""relighting"" or state more obviously that we train without it.\n\nLe dimanche 6 avril 2014, Jeff Donahue notifications@github.com a crit :\n\n> Huh, looks like you\'re correct - interesting that nobody else has ever\n> pointed this out after 8+ months of us using this reimplementation of the\n> architecture (first in cuda-convnet, then decaf, now caffe).\n> \n> Feel free to send a PR with a note in the documentation that our\n> implementation differs from Krizhevsky\'s published architecture in this\n> way. (And if someone from Berkeley cares to train an instance of the\n> corrected version and finds it matches or outperforms the reference model,\n> we could replace it. It does seem more natural to normalize then max-pool.)\n> \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/BVLC/caffe/issues/296#issuecomment-39686496\n> .\n\n## \n\nEvan Shelhamer\n', ""Yeah, sounds good - maybe you could change 'imagenet' to 'alexnet' or some other descriptive name to make it clear it's a different architecture.\n"", ""If the model is going to be re-trained, why don't we choose the ZeilerNet (#33) that outperformed the AlexNet last year?\n"", ""@Yangqing our Caffe reference ImageNet model LRN -> Max instead of Max -> LRN as in the Krizhevsky architecture.\n\nI'm training now. I'll check back with AlexNet model results later this week and we can decide exactly how to package it.\n\n@kloudkl we plan to release a ZF model too, but https://github.com/BVLC/caffe/pull/33#issuecomment-33152193 still needs implementing to do it exactly right.\n"", '@shelhamer I will do a small test to check if the order is likely to affect the results. What I can tell you is that it increase the memory consumption by at least 1Gb. \nAlso we train with data warped to fit 256x256 instead of resize-crop as stated in the paper.\n\nMaybe we should differentiate more explicitly caffe_reference_model and alexnet_reference_model.\n', ""I'm already running the training.\n\nUpdate: after three days the loss is ~1.8 and val accuracy is ~54% at 170,000 or so iterations.\n"", ""The AlexNet / Krizhevsky '12 architecture model was released in #327. Follow-up there for the details of training (and note that there are small differences from the training regime described in the paper).\n"", 'I am into hardware acceleration for CNN inference, and come across this when I compared google net with Alexnet, GoogleNet does the LRN after pooling, which is efficient from computation point of view. From the intent of the LRN layer I  feel LRN should be done before max pool, because the LRN done first can have a impact on the max pooling decisions.']",[],[],0,0
227,caffe,261,closed,Dimension mismatch training with my own model / why does training give the same prediction for all inputs?,"Hi,

I gave up on wrapper.py as there seemed to be a bug where it was sending the wrong type to Pycaffe (which attempts to call .size on a list and gets 0). 

However, a short (the simplest possible?) prediction script causes the same error:

F0326 09:37:00.348891 2102817152 pycaffe.cpp:127] Check failed: len(bottom) == input_blobs.size() (1 vs. 0) 

This is the script:



Is it me?

Any help gratefully received.

Best regards
John
",question,"[""Re: wrapper.py please try detector.py instead. Note that _caffe.cpp and pycaffe.py are the actual core wrapper files (and pycaffe.py isn't something you run directly; it's part of the module). I hope to update the python wrapper documentation and examples shortly.\n"", 'You may also want to check that your `train.prototxt` is compatible with `examples/imagenet/imagenet_deploy.prototxt`; the error suggests that your net is missing its input definition. (In fact, the name `train.prototxt` suggests that your net might be reading from a DATA layer instead of defining input; compare `examples/imagenet/imagenet_train.prototxt` to `examples/imagenet/imagenet_deploy.prototxt`.)\n', ""Thanks for helping.\n\nI realised this yesterday and changed the prototxt and now it happens to be exactly the same as your imagenet_deploy_prototxt.\n\nBut now I get this error:\nF0329 12:43:10.181525 2102817152 net.cpp:277] Check failed: target_blobs[j]->width() == source_layer.blobs(j).width() (9216 vs. 4096)\n\nI have no idea where the 9216 comes from. It doesn't explicitly appear anywhere in my setup, but it is 2.25*4096 (a weird product). \n\nIs there something wrong with my model? How can I tell? Any ideas welcome! :-)\n\nThanks\nJohn\n\nOn 28 Mar 2014, at 23:18, longjon notifications@github.com wrote:\n\n> You may also want to check that your train.prototxt is compatible with examples/imagenet/imagenet_deploy.prototxt; the error suggests that your net is missing its input definition. (In fact, the name train.prototxt suggests that your net might be reading from a DATA layer instead of defining input; compare examples/imagenet/imagenet_train.prototxt to examples/imagenet/imagenet_deploy.prototxt.)\n> \n> \n> Reply to this email directly or view it on GitHub.\n"", ""Thanks for the heads up.\n\nI gave up on wrapper.py a couple of days ago and began using this simple script:\n\n```\nfrom caffe import imagenet\n# from matplotlib import pyplot\n# Set the right path to your model file, pretrained model,\n# and the image you would like to classify.\nMODEL_FILE = 'deploy.prototxt'\nPRETRAINED = 'train_iter_10000'\nIMAGE_FILE = 'image.jpg'\n\nnet = imagenet.ImageNetClassifier(\n    MODEL_FILE, PRETRAINED)\nnet.caffenet.set_phase_test()\nnet.caffenet.set_mode_cpu()\n# net.caffenet.set_mode_gpu()\n\nprediction = net.predict(IMAGE_FILE)\nprint '\\nprediction:'\nprint prediction\nprint '\\n\\nprediction shape:', prediction.shape\npyplot.plot(prediction)\n```\n\nHowever, I now get the error I mentioned earlier:\n`F0329 12:43:10.181525 2102817152 net.cpp:277] Check failed: target_blobs[j]->width() == source_layer.blobs(j).width() (9216 vs. 4096)`\n"", '9216 (= 256 \\* 6 \\* 6) is the dimension of the pool5 layer - your deploy.prototxt probably outputs pool5 rather than fc6 or fc7 (which are both 4096 dimensional).\n', 'Thanks for the suggestion. However my deploy.prototxt is the same as imagenet_deploy.prototxt - it outputs from fc8.\n\nThe weird thing about the 9216 is that it changes depending on the initial image dimensions declared in the prototxt:\n\n```\ninput: ""data""\ninput_dim: 10\ninput_dim: 3\ninput_dim: 256\ninput_dim: 256\n\nF0330 04:12:29.781913 2102817152 net.cpp:277] Check failed: target_blobs[j]->width() == source_layer.blobs(j).width() \n(12544 vs. 4096) \n```\n\n```\ninput: ""data""\ninput_dim: 10\ninput_dim: 3\ninput_dim: 129\ninput_dim: 129\n\nF0330 04:17:28.552000 2102817152 net.cpp:277] Check failed: target_blobs[j]->width() == source_layer.blobs(j).width() \n(2304 vs. 4096)\n```\n\n```\ninput: ""data""\ninput_dim: 10\ninput_dim: 3\ninput_dim: 227\ninput_dim: 227\nF0330 04:56:54.609980 2102817152 net.cpp:277] Check failed: target_blobs[j]->width() == source_layer.blobs(j).width() \n(9216 vs. 4096) \n```\n\nAnd sometimes it just decides to check the resolution and fail there:\n\n```\ninput: ""data""\ninput_dim: 10\ninput_dim: 3\ninput_dim: 140\ninput_dim: 140\n\nI0330 04:07:07.771034 2102817152 net.cpp:156] Network initialization done.\nF0330 04:07:08.374914 2102817152 pycaffe.cpp:118] Check failed: dims[2] == blob->height() \n(227 vs. 140) \n```\n\nThe pictures are 256x256, but the original imagenet prototxt declares them as 227x227 and crops them to 140x140.\n\nI also tried detector.py but got exactly the same error.\n\nNot sure what to do now. I think I may redo the model, but I\'m not sure what to do differently.\n\nThanks\nJohn\n', 'If this is a deployment net, and not for training, try deleting the fillers\n(bias and weight initializers) from the prototxt. Let us know what happens.\nThis could be related to a prior issue seen in the MATLAB wrapper.\n\nLe dimanche 30 mars 2014, John Swan notifications@github.com a crit :\n\n> Thanks for the suggestion. However my deploy.prototxt is the same as\n> imagenet_deploy.prototxt - it outputs from fc8.\n> \n> The weird thing about the 4096 is that it changes depending on the initial\n> image dimensions declared in the prototxt:\n> \n> input: ""data""\n> input_dim: 10\n> input_dim: 3\n> input_dim: 256\n> input_dim: 256\n> \n> F0330 04:12:29.781913 2102817152 net.cpp:277] Check failed: target_blobs[j]->width() == source_layer.blobs(j).width()\n> (12544 vs. 4096)\n> \n> input: ""data""\n> input_dim: 10\n> input_dim: 3\n> input_dim: 129\n> input_dim: 129\n> \n> F0330 04:17:28.552000 2102817152 net.cpp:277] Check failed: target_blobs[j]->width() == source_layer.blobs(j).width()\n> (2304 vs. 4096)\n> \n> input: ""data""\n> input_dim: 10\n> input_dim: 3\n> input_dim: 227\n> input_dim: 227\n> F0330 04:56:54.609980 2102817152 net.cpp:277] Check failed: target_blobs[j]->width() == source_layer.blobs(j).width()\n> (9216 vs. 4096)\n> \n> And sometimes it just decides to check the resolution and fail there:\n> \n> input: ""data""\n> input_dim: 10\n> input_dim: 3\n> input_dim: 140\n> input_dim: 140\n> \n> I0330 04:07:07.771034 2102817152 net.cpp:156] Network initialization done.\n> F0330 04:07:08.374914 2102817152 pycaffe.cpp:118] Check failed: dims[2] == blob->height()\n> (227 vs. 140)\n> \n> The pictures are 256x256, but the original imagenet prototxt declares them\n> as 227x227 and crops them to 140x140.\n> \n> I also tried detector.py but got exactly the same error.\n> \n> Not sure what to do now. I think I may redo the model, but I\'m not sure\n> what to do differently.\n> \n> Thanks\n> John\n> \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/BVLC/caffe/issues/261#issuecomment-39041101\n> .\n', ""Hi,\n\nThanks for the input. I deleted all the bias and weight initialisers, but unfortunately it made no difference. Exactly the same results as before.\n\nAs I mentioned last time, if I set the image dimensions to 140, then I get a different error:\n\n```\nF0331 08:42:01.496572 2102817152 pycaffe.cpp:118] Check failed: dims[2] == blob->height() \n(227 vs. 140) \n```\n\nDoes this mean that the blob size is now correct (4096) but that the dimensions are incorrect because 227 is referenced somewhere?\n\nIf so, where is 227 specified? I can't find it in my setup. Is it somewhere in the trained model?\n\nThanks\nJohn\n"", ""The dimensions of each layer depends on the inputs due to convolution and pooling. So try with 227, and see if it works. \nIf you want to use different input sizes you have to remove the fully connected layers. \n\n> On Mar 30, 2014, at 11:47 PM, John Swan notifications@github.com wrote:\n> \n> Hi,\n> \n> Thanks for the input. I deleted all the bias and weight initialisers, but unfortunately it made no difference. Exactly the same results as before.\n> \n> As I mentioned last time, if I set the image dimensions to 140, then I get a different error:\n> \n> F0331 08:42:01.496572 2102817152 pycaffe.cpp:118] Check failed: dims[2] == blob->height() (227 vs. 140) \n> Does this mean that the blob size is now correct (4096) but that the dimensions are incorrect because 227 is referenced somewhere?\n> \n> If so, where is 227 specified? I can't find it in my setup. Is it somewhere in the trained model?\n> \n> Thanks\n> John\n> \n> \n> Reply to this email directly or view it on GitHub.\n"", '> So try with 227, and see if it works.\n\nThat\'s my original problem. I get this error:\n\n```\ninput: ""data""\ninput_dim: 10\ninput_dim: 3\ninput_dim: 227\ninput_dim: 227\nF0330 04:56:54.609980 2102817152 net.cpp:277] Check failed: target_blobs[j]->width() == source_layer.blobs(j).width() \n(9216 vs. 4096) \n```\n\nI tried cropping the image to various sizes and specifying those, but I just get the Check failed error with various x vs 4096 errors where x is some crazy number with no obvious relationship to anything that I\'ve changed. Very frustrating. I\'m out of ideas.\n\n> If you want to use different input sizes you have to remove the fully connected layers.\n\nI\'m not at all sure how to do that. At least in any way that would leave a functioning system.\n', ""The code in `caffe.imagenet` assumes that your net takes 227x227 input crops (in fact, it's really only intended for use with the provided imagenet net).\n\nThe error you are getting indicates that your trained parameters aren't the same size as needed by `deploy.prototxt` at the fc6 layer. Did you train with differently sized inputs (perhaps 140x140)?\n"", 'Could you share the prototxt file that you are using?\n\nSergio\n\n2014-03-31 14:53 GMT-07:00 John Swan notifications@github.com:\n\n>  So try with 227, and see if it works.\n> \n> That\'s my original problem. I get this error:\n> \n> input: ""data""\n> input_dim: 10\n> input_dim: 3\n> input_dim: 227\n> input_dim: 227\n> F0330 04:56:54.609980 2102817152 net.cpp:277] Check failed: target_blobs[j]->width() == source_layer.blobs(j).width()\n> (9216 vs. 4096)\n> \n> I tried cropping the image to various sizes and specifying those, but I\n> just get the Check failed error with various x vs 4096 errors where x is\n> some crazy number with no obvious relationship to anything that I\'ve\n> changed. Very frustrating. I\'m out of ideas.\n> \n> If you want to use different input sizes you have to remove the fully\n> connected layers.\n> \n> I\'m not at all sure how to do that. At least in any way that would leave a\n> functioning system.\n> \n> ## \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/BVLC/caffe/issues/261#issuecomment-39146923\n> .\n', 'I think that error would be raised if you used a pretrained net and tried to deploy with a prototxt where fc7 takes inputs from pool5 (which has output dimension 9216) rather than fc6 (which has output dimension 4096).  Are you positive your deploy prototxt is the same as imagenet_deploy.prototxt? Did you use diff?\n', ""> The error you are getting indicates that your trained parameters aren't the same size as needed by deploy.prototxt at the fc6 layer. Did you train with differently sized inputs (perhaps 140x140)?\n\nThanks! That was the clue I needed. I looked back and I had indeed cropped the original images to 140x140 during training. This was done because for cudaMalloc was failing for images of 256x256 with my Macbook Pro's GT 650M with 1Gb.\n\nI increased the image dimensions and retrained the model (using the CPU this time). Then detector.py gave me a prediction!\n\nOne thing however, the prediction had 1000 classes (presumably because Imagenet has 1000) but my case has 50 or less. I'm not sure how the training succeeds given that when running create_imagenet.sh I'm supplying way less than 1000 classes in my train.txt and val.txt? Anyway, to see what happens, I naively reduced fc8's num_output from its original 1000 (to match my label count) in each of the prototxts (train, val, deploy), then retrained the model and ran detector.py. I did get the correct number of classes in the output, but the prediction for the first image was repeated for the second and subsequent images - in other words all the predictions were exactly the same for each image. \n\nIs there an easy way to get past this? I'd like to have some predictions for Thursday, but that's looking difficult. :-(\n\nMany thanks for the help so far!\n"", 'Hi,\n\nChanging the number of classes from 1000 isn\'t the problem. I reran with the original 1000 classes and again - the predictions for each image are all the same.\n\nSo I\'m still unable to get a prediction from the basic Imagenet with my own data.\n\nI also noticed that detector.py is defaulting to the imagenet mean file ilsvrc_2012_mean.npy when I don\'t specify one:\n\n```\n  parser.add_argument(\n    ""--images_mean_file"",\n    default=os.path.join(\n      os.path.dirname(__file__), \'../imagenet/ilsvrc_2012_mean.npy\'),\n    help=""Data set image mean (numpy array)."")\n```\n\nI\'m sure that can\'t be having a beneficial effect. \n\nHowever, if I try to substitute my own image mean file (created by make_imagenet_mean.sh) then detector.py crashes because it is expecting a Numpy array, while make_imagenet_mean.sh produces a binaryproto.\n\nIt looks like I\'ve just about ran out of time with this, sad to say I\'ve failed Hopefully this series of posts will be useful to someone else.\n\nCheers\nJ\n', 'Making the same prediction for every input can happen when training fails\nfor data that isn\'t shuffled (making the gradient variance too high) or\ndata that isn\'t class balanced.\n\nRe: the ImageNet mean, it is actually quite effective if you are still\nclassifying run-of-the-mill images from the internet, and certainly far\nbetter than not doing mean subtraction.\n\nGood luck with training.\n\nLe jeudi 3 avril 2014, John Swan notifications@github.com a crit :\n\n> Hi,\n> \n> Changing the number of classes from 1000 isn\'t the problem. I reran with\n> the original 1000 classes and again - the predictions for each image are\n> all the same.\n> \n> So I\'m still unable to get a prediction from the basic Imagenet with my\n> own data.\n> \n> I also noticed that detector.py is defaulting to the imagenet mean file\n> ilsvrc_2012_mean.npy when I don\'t specify one:\n> \n>   parser.add_argument(\n>     ""--images_mean_file"",\n>     default=os.path.join(\n>       os.path.dirname(**file**), \'../imagenet/ilsvrc_2012_mean.npy\'),\n>     help=""Data set image mean (numpy array)."")\n> \n> I\'m sure that can\'t be having a beneficial effect.\n> \n> However, if I try to substitute my own image mean file (created by\n> make_imagenet_mean.sh) then detector.py crashes because it is expecting a\n> Numpy array, while make_imagenet_mean.sh produces a binaryproto.\n> \n> It looks like I\'ve just about ran out of time with this Hopefully this\n> series of posts will be useful to someone else.\n> \n> Cheers\n> J\n> \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/BVLC/caffe/issues/261#issuecomment-39423717\n> .\n', 'Thanks for the information. It sounds like it could be very useful.\n\n> Making the same prediction for every input can happen when training fails\n> for data that isn\'t shuffled (making the gradient variance too high) or\n> data that isn\'t class balanced.\n\nHow do I make sure that the data is shuffled? I noticed back when I was doing this that the docs said something like ""we shuffle the labels but you have to shuffle the files yourself"". I didn\'t (and still don\'t) understand what is meant by this - how can you shuffle files in a random access filesystem? I suspect that this is a stupid question, but I guess I don\'t understand what is meant by shuffling in this context. Is there an example somewhere?\n\n> Re: the ImageNet mean, it is actually quite effective if you are still\n> classifying run-of-the-mill images from the internet, and certainly far\n> better than not doing mean subtraction\n\nThanks. However is there any way to convert my binaryproto to npy so that I can use my own mean?\nI noticed that this question has also been asked today in https://github.com/BVLC/caffe/issues/290\n', 'For binaryproto to npy conversion see https://github.com/BVLC/caffe/issues/290#issuecomment-39486389.\n', '> How do I make sure that the data is shuffled?\n\nIf you are training with a leveldb, you set the last arg (the shuffle flag) to 1 to have the input shuffled for you. As for ""shuffling files,"" my guess is you\'re referring to https://github.com/BVLC/caffe/blob/814a32a/tools/convert_imageset.cpp#L12, which I believe is an out-of-date comment that I\'ll remove shortly.\n', '> If you are training with a leveldb, you set the last arg (the shuffle flag) to 1 to have the input shuffled for you.\n\nI had done that (set it to 1).\n\n> As for ""shuffling files,"" my guess is you\'re referring to https://github.com/BVLC/caffe/blob/814a32a/tools/convert_imageset.cpp#L12, which I believe is an out-of-date comment that I\'ll remove shortly.\n\nYes, it was that comment that confused me no end - I couldn\'t make sense of it:\n\n```\n// You are responsible for shuffling the files yourself.\n```\n\nSo, I did shuffle the data, but still got identical predictions. Unfortunately I ran out of time before I could track the problem down any further (or get any predictions).\n', 'I had the same problem, and I tracked it down to a different cause.\n\nI had renamed the final layer in my train_val.prototxt network from ""fc8"" to ""fc8_landmarks"" (specific to my image data set.  However, I had forgotten to do the same thing in deploy.txt (it was still called ""fc8"").  I didn\'t get any error messages, but all of my classes had the same predicted probability for all items.  By changing the layer name to ""fc8_landmarks"" in deploy.txt (to match train_val.prototxt), I was able to get sensible output.\n', 'Hi \nI am facing a related issue and would appreciate any help in this. \n\nI modified the ResNet prototxt file to have the ROI proposals and was able to fine tune it successfully in 50K iterations on val set \n`Train net output #3: rpn_loss_bbox = 0.0179207 (* 1 = 0.0179207 loss)`\nNow I am trying to use the final caffe model along with the deploy.prototxt for ResNet modified as a test prototxt (removing lr params, top layer and appending the input data layer). However I keep getting this error.\n`File ""./lib/rpn/anchor_target_layer.py"", line 116, in forward (all_anchors[:, 2] < im_info[0][1] ) & # width ValueError: operands could not be broadcast together with shapes (17100,) (600,800)`\n\nI printed a few debug statements but was unsuccessful in trouble shooting. Any help would be appreciated.\n']","["" python\nfrom caffe import imagenet\n# from matplotlib import pyplot\n\n# Set the right path to your model file, pretrained model,\n# and the image you would like to classify.\nMODEL_FILE = 'train.prototxt'\nPRETRAINED = 'train_iter_10000'\nIMAGE_FILE = 'image.jpg'\n\nnet = imagenet.ImageNetClassifier(\n    MODEL_FILE, PRETRAINED)\n\nnet.caffenet.set_phase_test()\n# net.caffenet.set_mode_cpu()\nnet.caffenet.set_mode_gpu()\n\nprediction = net.predict(IMAGE_FILE)\nprint '\\nprediction:'\nprint prediction\nprint '\\n\\nprediction shape:', prediction.shape\npyplot.plot(prediction)\n""]",[],0,0
228,caffe,5881,closed,pycaffe (python3.5) conflicts with python-dateutil<2 ,"In python/reqirements.txt, there is a dependency of python-dateutil (python-dateutil>=1.4,<2), but when I use pycaffe (python3.5), I get an error:
         . 
The error is gone when I update python-dateutil to 2.6.1

",,[],[],"['ValueError, ""Can\'t create weekday with n == 0""', 'pip3 install --upgrade python-dateutil']",0,0
229,caffe,2309,closed,Extract filters and bias ,"Hi all,
I want to know how can i only extract filters and biases from my own caffemodel.
I read the tutorial of "" filter visualization example"", but i dont know how to do when using my own caffemodel.(I dont know which part i should modify in that reference code)
I want to extract filters and bisaes and then save into .mat file for MATLAB.
can anyone help me? please and thanks.
",,"['I used matcaffe (the matlab wrapper) for the same issue\n1) open matlab\n2) make sure the path to your matcaffe (caffe_root/matlab/caffe) is in the defpath. If not, add it manually or write: addpath(your path); in matlab\n3) initialize your caffe Net by writing: caffe(\'init\', \'your_net_definition.prototxt\',\'your_model.caffemodel\').\n4) do a forward pass by writing: caffe(\'forward\', {});\n5) and then extract the weights: weights = caffe(\'get_weights\');\n    ""weights"" will contain the weights and biases of all the layers. You will see it from its structure when you open it\n6) save ""weights"" into a mat file: save(\'path_to_folder/filename.mat\', \'weights\');\n', ""Thanks for your answer!\nI did it step by step, but still have  error :\nError using caffe\nExpected 3 arguments, got 2\n\nError in model (line 4)\ncaffe('init','deploy.prototxt','super_resolution_iter_1000.caffemodel');\n\nAnd the following is my code:\n\naddpath('/home/jensen810814/code/caffe/matlab/caffe/');\naddpath('/home/jensen810814/code/caffe/examples/super_resolution/');\naddpath('/home/jensen810814/code/caffe/examples/super_resolution/Model/');\ncaffe('init','deploy.prototxt','super_resolution_iter_1000.caffemodel');\ncaffe('forward',{});\nweights = caffe('get_weights');\nsave('/home/jensen810814/code/caffe/examples/super_resolution/filter_data.mat','weights');\n\nCan you tell me how to deal with it? thanks a lot. (btw, did the 'your_net_definition.prototxt' mean deploy.prototxt or train_protptxt which i used to train my net?)\n"", 'I meant the train.prototxt (or train_test.prototxt if you defined both train and test nets in one prototxt file). Does it work if you use this prototxt file?\n', 'I tried both files...but  still have same problem QAQ.  \n', 'I solve this question. Thanks  again.\n', '@jensen810814    how did you solve the question that defined both train and test nets in one prototxt file?\n']",[],[],0,0
230,caffe,5284,closed,ERROR:Undefined symbols for architecture x86_64,"When I install caffe in my macbook pro ,there is a problem.

Can anyone meet similar question?
HOW CAN I FIX IT?
Want HELP!!! 
### System configuration
Operating system:MACOS 10.12.3
Compiler:clang
CUDA version (if applicable):no (cpu only)
CUDNN version (if applicable):no
BLAS:
Python or MATLAB version (for pycaffe and matcaffe respectively):python
",,"['Have you got your OpenCV in the right place?\r\n\r\nAnd please seek for such help through [Caffe user mailing list](https://groups.google.com/forum/#!forum/caffe-users) next time. It might distract developers from bug reports and feature requests.', 'I had the same issue using opencv3. Uncommenting OPENCV_VERSION := 3 seems to have fixed it. ', 'From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\r\n\r\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\r\nUse the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.']","['\r\n[ 75%] Linking CXX shared library ../../lib/libcaffe.dylib\r\nUndefined symbols for architecture x86_64:\r\n  ""cv::imread(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int)"", referenced from:\r\n      caffe::WindowDataLayer<float>::load_batch(caffe::Batch<float>*) in window_data_layer.cpp.o\r\n      caffe::WindowDataLayer<double>::load_batch(caffe::Batch<double>*) in window_data_layer.cpp.o\r\n      caffe::ReadImageToCVMat(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, int, bool) in io.cpp.o\r\n  ""cv::imencode(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, cv::_InputArray const&, std::__1::vector<unsigned char, std::__1::allocator<unsigned char> >&, std::__1::vector<int, std::__1::allocator<int> > const&)"", referenced from:\r\n      caffe::ReadImageToDatum(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, int, int, bool, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, caffe::Datum*) in io.cpp.o\r\nld: symbol(s) not found for architecture x86_64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nmake[2]: *** [lib/libcaffe.1.0.0-rc4.dylib] Error 1\r\nmake[1]: *** [src/caffe/CMakeFiles/caffe.dir/all] Error 2\r\nmake: *** [all] Error 2\r\n']",[],0,0
231,caffe,5459,closed,Error when upgrade a train_val.prototxt file for the new version.," I want  to upgrade a train file for eailer version of caffe. But got some errors. anyone could help me  to solve it?

     upgrade_net_proto_text-d.exe D:/net_train_val.prototxt b.prototxt
     [libprotobuf ERROR C:\Users\guillaume\work\caffe-  builder\build_v140_x64\packages\protobuf\protobuf_download- prefix\src\protobuf_download\src\google\protobuf\text_format.cc:298] Error parsing text-format  caffe.NetParameter: 16:15: Message type ""caffe.TransformationParameter"" has no field named ""fixed_crop"".
    E0328 23:01:38.529631 10972 upgrade_net_proto_text.cpp:30] Failed to parse input text file as  NetParameter: D:/net_train_val.prototxt",,"['Are you sure it works for older versions of Caffe (and not a fork)? It seems the error message is pretty straight forward. Where does the fixed_crop parameter come from?\r\n\r\nPlease ask your question on the [Caffe user mailing list](https://groups.google.com/forum/#!forum/caffe-users) or on another website, such as http://stackoverflow.com/.\r\n\r\n> Please use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) for usage, installation, or modeling questions, or other requests for help.\r\n> _Do not post such requests to Issues._ Doing so interferes with the development of Caffe.']",[],[],0,0
232,caffe,1888,closed,How to predict a single digit using Caffe and C++,"I am trying to use Caffe to predict a digit in MNIST dataset. I run a solver to pretrain a net as follow:



I just use LeNet prototxt file from examples to do this. Ok, this stage is crystal clear. Then I found a script which converts mnist dataset (lmdb) to a set of grayscale images (.jpg) each of them is a representation of a handwritten digit. I added Image-Data layer as mention here (https://github.com/BVLC/caffe/issues/499). Therefore, my .prototxt file is (my_lenet_test.prototxt):



Then I construct my net:



and load pre-trained layers from the solver



But on the last stage I got SIGABRT signal from my IDE and got the error:



I would highly appreciate for any help. I am stuck and have no idea what to do... Thank you!
",,['I decided to transfer my question to Caffe Users group. Here is a link: https://groups.google.com/forum/#!topic/caffe-users/WO4gHU8rTCI\n'],"[' cpp\n    // Set to TRAIN Phase\n    caffe::Caffe::set_phase(caffe::Caffe::TRAIN);\n    // set GPU\n    caffe::Caffe::set_mode(caffe::Caffe::GPU);\n    int deviceId = 0;\n    caffe::Caffe::SetDevice(deviceId);\n    LOG(INFO) << ""Using GPU"";\n    // Solver initialization and evaluation\n    caffe::SolverParameter solverParams;\n    caffe::ReadProtoFromTextFileOrDie(""/home/iar/caffe/caffe/examples/mnist/lenet_solver.prototxt"", &solverParams);\n    caffe::Solver<float>* solver = new caffe::SGDSolver<float>(solverParams);\n    solver->Solve();\n', '\nname: ""LeNet""\nlayers {\n  name: ""mnist""\n  type: DATA\n  top: ""data""\n  top: ""label""\n  data_param {\n    source: ""/home/iar/caffe/caffe/examples/mnist/mnist_train_lmdb""\n    backend: LMDB\n    batch_size: 64\n  }\n  transform_param {\n    scale: 0.00390625\n  }\n  include: { phase: TRAIN }\n}\nlayers {\n  name: ""data""\n  type: IMAGE_DATA\n  top: ""data""\n  top: ""label""\n  image_data_param {\n    source: ""/home/iar/caffe/caffe/examples/mnist/file_list.txt""\n    batch_size: 1\n    new_height: 28\n    new_width: 28\n  }\n  include: { phase: TEST }\n}\n\nlayers {\n  name: ""conv1""\n  type: CONVOLUTION\n  bottom: ""data""\n  top: ""conv1""\n  blobs_lr: 1\n  blobs_lr: 2\n  convolution_param {\n    num_output: 20\n    kernel_size: 5\n    stride: 1\n    weight_filler {\n      type: ""xavier""\n    }\n    bias_filler {\n      type: ""constant""\n    }\n  }\n}\nlayers {\n  name: ""pool1""\n  type: POOLING\n  bottom: ""conv1""\n  top: ""pool1""\n  pooling_param {\n    pool: MAX\n    kernel_size: 2\n    stride: 2\n  }\n}\nlayers {\n  name: ""conv2""\n  type: CONVOLUTION\n  bottom: ""pool1""\n  top: ""conv2""\n  blobs_lr: 1\n  blobs_lr: 2\n  convolution_param {\n    num_output: 50\n    kernel_size: 5\n    stride: 1\n    weight_filler {\n      type: ""xavier""\n    }\n    bias_filler {\n      type: ""constant""\n    }\n  }\n}\nlayers {\n  name: ""pool2""\n  type: POOLING\n  bottom: ""conv2""\n  top: ""pool2""\n  pooling_param {\n    pool: MAX\n    kernel_size: 2\n    stride: 2\n  }\n}\nlayers {\n  name: ""ip1""\n  type: INNER_PRODUCT\n  bottom: ""pool2""\n  top: ""ip1""\n  blobs_lr: 1\n  blobs_lr: 2\n  inner_product_param {\n    num_output: 500\n    weight_filler {\n      type: ""xavier""\n    }\n    bias_filler {\n      type: ""constant""\n    }\n  }\n}\nlayers {\n  name: ""relu1""\n  type: RELU\n  bottom: ""ip1""\n  top: ""ip1""\n}\nlayers {\n  name: ""ip2""\n  type: INNER_PRODUCT\n  bottom: ""ip1""\n  top: ""ip2""\n  blobs_lr: 1\n  blobs_lr: 2\n  inner_product_param {\n    num_output: 10\n    weight_filler {\n      type: ""xavier""\n    }\n    bias_filler {\n      type: ""constant""\n    }\n  }\n}\nlayers {\n  name: ""accuracy""\n  type: ACCURACY\n  bottom: ""ip2""\n  bottom: ""label""\n  top: ""accuracy""\n  include: { phase: TEST }\n}\nlayers {\n  name: ""loss""\n  type: SOFTMAX_LOSS\n  bottom: ""ip2""\n  bottom: ""label""\n  top: ""loss""\n}\nlayers {\n  name: ""output""\n  type: ARGMAX\n  bottom: ""loss""\n  top: ""output""\n  include: { phase: TEST }\n}\n', ' cpp\ncaffe::Net<float> mnistLeNet(""my_lenet_test.prototxt"");\n', ' cpp\nmnistLeNet.CopyTrainedLayersFrom(""/home/iar/caffe/caffe/examples/mnist/lenet_iter_10000.caffemodel"");\n', '\nCheck failed: target_blobs[j]->channels() == source_layer.blobs(j).channels() (3 vs. 1) \n']",[],0,0
233,caffe,5159,closed,site outages: dl.caffe.berkeleyvision.org and demo.caffe.berkeleyvision.org,The main Caffe site is up but the auxiliary sites for the demo and downloads (including reference models) are down during maintenance to campus infrastructure at Berkeley. These sites will return on Jan. 9th.,,"['Thanks I was trying for the last few hours and was wondering what was happening. Can we please have a mirror? Say google drive???', 'The sites are now back. #1672 is there to remind us to switch to cloud hosting.']",[],[],0,0
234,caffe,6024,closed,"""BatchNormParameter"" has no field named ""scale_bias""","I try to run a caffe.NetParameter for a example and find **Error parsing text-format caffe.NetParameter**
the logging like this:
[libprotobuf ERROR google/protobuf/text_format.cc:245] Error parsing text-format caffe.NetParameter: 52:15: Message type ""caffe.BatchNormParameter"" has no field named ""scale_bias"".
WARNING: Logging before InitGoogleLogging() is written to STDERR
F1102 09:40:47.271351 37064 upgrade_proto.cpp:122] Check failed: ReadProtoFromTextFile(param_file, param) Failed to parse NetParameter file: /home/zhezhan2/pymodel/train_val_gpu.prototxt
*** Check failure stack trace: ***
run_gpu.sh: line 2: 37064 Aborted                 (core dumped) python compare_two_model.py --tool_1 caffe --file_1 /home/zhezhan2/pymodel/train_val_gpu.prototxt --tool_2 caffe --file_2 /home/zhezhan2/pymodel/train_val_mkl.prototxt
",,"['Please use the [caffe-users list][1] for usage, installation, or modeling questions, or other requests for help.\r\nYou may also post questions on [stackoverflow][3], make sure you tag them with `caffe` tag.  \r\nThere is also [caffe.help][4] documenting the different layers of caffe.\r\nDo not post such requests to Issues. Doing so interferes with the development of Caffe.\r\n\r\nPlease read the [guidelines for contributing][2] before submitting this issue.\r\n\r\n [1]: https://groups.google.com/forum/#!forum/caffe-users\r\n [2]: https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md\r\n [3]: http://stackoverflow.com/questions/tagged/caffe\r\n [4]: http://caffe.help/manual/layers.html']",[],[],0,0
235,caffe,715,closed,How to install caffe on OS X 10.9 with Macports?,"I know the official installation instruction recommends to install caffe on OS X by homebrew. But, I have installed Macports on my laptop for a quite long time (one year...), in which a lot of softwares were installed.

I find a lot of libraries provided by homebrew are also able to be downloaded by macports. So, is there a way to install caffe by macports? Thanks!
",duplicate,['Duplicate of #447; closing for the conversation to continue there.\n'],[],[],0,0
236,caffe,4922,closed,"I'm new here, thanks for your help!","Amenglars-MacBook-Pro:caffe mac$ make runtest
.build_release/tools/caffe
dyld: Library not loaded: @rpath/libmkl_rt.dylib
  Referenced from: /Users/mac/workspace/caffe/caffe/.build_release/tools/caffe
  Reason: image not found
make: **\* [runtest] Abort trap: 6
",,"['Questions like these should be asked on the [Caffe user mailing list](https://groups.google.com/forum/#!forum/caffe-users) or on another website, such as http://stackoverflow.com/ or http://stats.stackexchange.com/. Please **close this issue** and move your question to one of these places.\n']",[],[],0,0
237,caffe,6122,closed,Bug? Caffe doesn't read the HDF5 files for TEST phase (instead reads the path given in TRAIN phase twice),"Although I declare different training and validation txt files (that contains a list of hdf5 files), the 
Net initializes the TEST phase with the path I give for the TRAIN phase. 

For both TRAIN and TEST phase initialization I get:

**_Creating training net_** from net file: /home/caffe/models/det_alexnet/train_val.prototxt
... hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: /home/caffe/examples/det/**_train_h5_list.txt_**
... hdf5_data_layer.cpp:94] **_Number of HDF5 files: 17_**


**_Creating test net (#0)_** specified by net file: /home/caffe/models/det_alexnet/train_val.prototxt
... hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: /home/caffe/examples/det_**/train_h5_list.txt**_
... hdf5_data_layer.cpp:94] **_Number of HDF5 files: 17_**

Although my prototxt (train_val.prototxt) clearly provides different txt files for TRAIN and TEST phases:

layer {
  name: ""data""
  type: ""HDF5Data""
  top: ""imgdata""
  top: ""ph""
  top: ""sm""
  include {
    **_phase: TRAIN_**
  }
   hdf5_data_param {
      source: ""/home/caffe/examples/det/train_h5_list.txt""
      batch_size: 256
      }
}

layer {
  name: ""data""
  type: ""HDF5Data""
  top: ""imgdata""
  top: ""ph""
  top: ""sm""
  include {
    **_phase: TEST_**
  }
   hdf5_data_param {
      source: ""/home/caffe/examples/det/eval_h5_list.txt""
      batch_size: 256
      }
}

And I get this error:


 **_Check failed: data__** 
*** Check failure stack trace: ***
    @     0x7fa264a335cd  google::LogMessage::Fail()
    @     0x7fa264a35433  google::LogMessage::SendToLog()
    @     0x7fa264a3315b  google::LogMessage::Flush()
    @     0x7fa264a35e1e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7fa2651d018b  caffe::Blob<>::mutable_cpu_data()
    @     0x7fa2651ed4a1  caffe::hdf5_load_nd_dataset<>()
    @     0x7fa2650c3f73  caffe::HDF5DataLayer<>::LoadHDF5FileData()
    @     0x7fa2650c21fd  caffe::HDF5DataLayer<>::Next()
    @     0x7fa265214a93  caffe::HDF5DataLayer<>::Forward_gpu()
    @     0x7fa265048a21  caffe::Net<>::ForwardFromTo()
    @     0x7fa265048b27  caffe::Net<>::Forward()
    @     0x7fa2651c7332  caffe::Solver<>::Test()
    @     0x7fa2651c7d4e  caffe::Solver<>::TestAll()
    @     0x7fa2651cb2c7  caffe::Solver<>::Step()
    @     0x7fa2651cb58a  caffe::Solver<>::Solve()
    @           0x40aba4  train()
    @           0x407390  main
    @     0x7fa2639a3830  __libc_start_main
    @           0x407bb9  _start
    @              (nil)  (unknown)
Aborted (core dumped)

 PS: I work on only one GPU (Titan X)",,"[""This seems to be a bug? I really don't understand why it would read the training file instead of the validation file provided at the TEST phase. I would appreciate if someone can look into this.""]",[],[],0,0
238,caffe,1768,closed,`pooling_layer.cu` incorrect computation of index,"Code [here](https://github.com/BVLC/caffe/blob/master/src/caffe/layers/pooling_layer.cu#L31).

During every loop iteration, the amount  changes differ.
",bug,"['No, the code is correct -- each step of the unrolled loop is computing its index once (`bottom_data` is the same for each so the needed offset is calculated and added).\n', 'See #2493 for the fix -- while this bug is currently hidden since all the loops only execute once this deserves fixing. Thanks for the report @hotpxl.\n']",[],['bottom_data'],0,0
239,caffe,6288,closed,failed to make all ,"Makefile:6: *** Makefile.config not found. See Makefile.config.example..  Stop.
zhouyihan@DESKTOP-NHP04OU:/mnt/c/Users//Desktop/caffe/caffe-master/caffe-master$ make all
PROTOC src/caffe/proto/caffe.proto
CXX .build_release/src/caffe/proto/caffe.pb.cc
CXX src/caffe/blob.cpp
CXX src/caffe/common.cpp
CXX src/caffe/data_transformer.cpp
CXX src/caffe/internal_thread.cpp
CXX src/caffe/layer.cpp
CXX src/caffe/layers/absval_layer.cpp
CXX src/caffe/layers/accuracy_layer.cpp
CXX src/caffe/layers/argmax_layer.cpp
CXX src/caffe/layers/base_conv_layer.cpp
CXX src/caffe/layers/base_data_layer.cpp
CXX src/caffe/layers/batch_norm_layer.cpp
CXX src/caffe/layers/batch_reindex_layer.cpp
CXX src/caffe/layers/bias_layer.cpp
CXX src/caffe/layers/bnll_layer.cpp
CXX src/caffe/layers/concat_layer.cpp
CXX src/caffe/layers/contrastive_loss_layer.cpp
CXX src/caffe/layers/conv_layer.cpp
CXX src/caffe/layers/crop_layer.cpp
CXX src/caffe/layers/cudnn_conv_layer.cpp
CXX src/caffe/layers/cudnn_deconv_layer.cpp
CXX src/caffe/layers/cudnn_lcn_layer.cpp
CXX src/caffe/layers/cudnn_lrn_layer.cpp
CXX src/caffe/layers/cudnn_pooling_layer.cpp
CXX src/caffe/layers/cudnn_relu_layer.cpp
CXX src/caffe/layers/cudnn_sigmoid_layer.cpp
CXX src/caffe/layers/cudnn_softmax_layer.cpp
CXX src/caffe/layers/cudnn_tanh_layer.cpp
CXX src/caffe/layers/data_layer.cpp
CXX src/caffe/layers/deconv_layer.cpp
CXX src/caffe/layers/dropout_layer.cpp
CXX src/caffe/layers/dummy_data_layer.cpp
CXX src/caffe/layers/eltwise_layer.cpp
CXX src/caffe/layers/elu_layer.cpp
CXX src/caffe/layers/embed_layer.cpp
CXX src/caffe/layers/euclidean_loss_layer.cpp
CXX src/caffe/layers/exp_layer.cpp
CXX src/caffe/layers/filter_layer.cpp
CXX src/caffe/layers/flatten_layer.cpp
CXX src/caffe/layers/hdf5_data_layer.cpp
src/caffe/layers/hdf5_data_layer.cpp:13:18: fatal error: hdf5.h: No such file or directory
compilation terminated.
Makefile:581: recipe for target '.build_release/src/caffe/layers/hdf5_data_layer.o' failed
make: *** [.build_release/src/caffe/layers/hdf5_data_layer.o] Error 1
",,"['If the problem is due to *Makefile.config not found* then I will refer you back to the [installation tutorial](http://caffe.berkeleyvision.org/installation.html).  \r\nYou can read about the hdf5.h problem on our wiki on [common build issues](https://github.com/BVLC/caffe/wiki/Commonly-encountered-build-issues).\r\n\r\nPlease post usage, installation, or modeling questions, or other requests for help to the [caffe-users list][1] instead of Issues. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe. Please read the [guidelines for contributing][2] before submitting an issue or a pull request.\r\n\r\n [1]: https://groups.google.com/forum/#!forum/caffe-users\r\n [2]: https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md']",[],[],0,0
240,caffe,4113,closed,datum_height == data_mean_.height() when running solver.prototxt?,"Hey,

I'm relatively new to caffe and am trying to run solver.prototxt on my own data (./build/tools/caffe train --solver=path/to/solver.prototxt ) and am currently getting this issue: 

data_transformer.cpp:63] Check failed: datum_height == data_mean_.height() (760 vs. 256) 

So the dimensions of something are wrong but I'm not sure how to fix it. It's probably after the layer conv1. 

Here's my train_val.prototxt and solver.prototxt--slightly modified from what's here. 
My images are 256x256 -- some things are admittedly pretty weird in the files because my dataset is stupid levels of small at this point (I'm mainly using it to familiarize myself with using caffe for my own datasets).
[solver.txt](https://github.com/BVLC/caffe/files/253862/solver.txt)
[train_val.txt](https://github.com/BVLC/caffe/files/253863/train_val.txt)

Any help would be great!
",,"['Please ask usage questions on the mailing list.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n', 'your mean file does not match your pictures, to test that, remove or comment the mean file and test your network. \n']",[],[],0,0
241,caffe,651,closed,Where is EltwiseParameter_EltwiseOp?,"Where is LayerParameter_LayerType_ELTWISE and  EltwiseParameter_EltwiseOp in file caffe\include\caffe\vision_layers.hpp

Find it in proto.
",,"['For reference it is defined by caffe.proto when it generates the C++\nprotobuf includes.\n\nOn Wed, Jul 9, 2014 at 5:41 AM, kyzhao notifications@github.com wrote:\n\n> Closed #651 https://github.com/BVLC/caffe/issues/651.\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/651#event-139537401.\n']",[],[],0,0
242,caffe,3486,closed,Problem with Caffe running on multi-GPUs (8 Titan X),"Hi everyone! I am trying to run imageNet with caffe on multi-GPU today with 8 Titan X and CentOS. I also set --gpu=all, hoping all the 8 GPUs would run in parallel. But, it turned out that only four GPUs could work for my task. Does not caffe support 8-GPUs framework? Or I have to implement some other things in order to make it work? I attached two log file pictures below to help you to better understand my problem. Anyone's kind advice is appreciated and eagerly needed. Thanks.
",,"['IIRC, there was a point where adding GPUs did not increase training speed.\n\nThis is a usage question and belongs on the mailing list.\n\nBR,  \n', 'the Log file Pictures are:\n![s1](https://cloud.githubusercontent.com/assets/11781064/12013149/beb4d414-ad4b-11e5-98c9-0d9772ae7fbf.png)\n![s2](https://cloud.githubusercontent.com/assets/11781064/12013156/f1c79422-ad4b-11e5-82a5-454866771556.png)\n', 'From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> Please do not post usage, installation, or modeling questions, or other requests for help to Issues.\n> Use the caffe-users list instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
243,caffe,2190,closed,python deploy prototxt problem,"Hi, all:

I am trying to use the python to build a model with existing prototxt and caffemodel file. However, I found that I could not successfully build one even with the deploy file and model offered on github unless I delete all the weigth_filler and bias_filler content. 
I run my code on python command and it shows ""Segmentation fault (core dumped)""
Can anyone figure out what's wrong?
",,['please ask usage questions on [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) -- this issues tracker is primarily for Caffe development discussion. Thanks!\n'],[],[],0,0
244,caffe,149,closed,Implement MultiLabel losses and data input,"Start with reference [1].

[1] Deep Convolutional Ranking for Multilabel Image Annotation
Yunchao Gong, Yangqing Jia, Sergey Ioffe, Alexander Toshev, Thomas Leung
http://arxiv.org/abs/1312.4894
",enhancement,"['See also:\n\n[2] J. Weston, S. Bengio, and N. Usunier. Wsabie: Scaling up to large vocabulary image annotation. In\nProceedings of the Twenty-Second international joint conference on Artificial Intelligence-Volume Volume Three, pages 27642770. AAAI Press, 2011.\nhttp://research.google.com/pubs/pub37180.html\n\n[3] A. Frome, G. S. Corrado, J. Shlens, S. Bengio, J. Dean, M. A. Ranzato, and T. Mikolov. Devise: A deep visual-semantic embedding model. In Advances in Neural Information Processing Systems 26, pages 21212129. 2013.\nhttp://research.google.com/pubs/pub41473.html\n', 'Note: HDF5DataLayer in #147 reads in labels as matrices already.\n', 'This issue is opened to be an umbrella of #144 in which @leezl has agreed to contribute back the MultiLabelDataLayer and all the related changes to proto, io etc.\n\nThe ""loss function appropriate to multilabel data needs to be implemented"" that @leezl talked about probably means extending the existing loss layers to support multilabel data. The todo list includes but is not limited to the SoftmaxWithLossLayer that is used by reference [1].\n\nBesides, the WARPLossLayer implementing the ranking loss function in reference [1][2][3] in #126 demands multilabel data. In fact, any ranking loss function inherently requires multilabel data. I will keep synced with the progresses on the data layer.\n', ""@sergeyk, @shelhamer @jeffdonahue @Yangqing  I'm implementing some multi-label losses and accuracy. But I would like to have the following:\nThree different labels {-1,0,1}, which means negative, ignore and positive. Should I use 0 or -1 for negative, and conversely -1 or 0 for ignoring that label?\n"", ""I'd say 0 for ignoring\n"", ""I second that (0 for ignoring).\n\nOn Wed, May 21, 2014 at 6:18 PM, Sergey Karayev notifications@github.comwrote:\n\n> I'd say 0 for ignoring\n> \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/BVLC/caffe/issues/149#issuecomment-43838076\n> .\n\n## \n\nhttp://www.cs.berkeley.edu/~rbg/\n"", 'By multiple label, do you mean ranking loss or one-vs-all style ""attribute""\nclassification? For one-vs-all, I sketched up a loss layer that takes a\nloss type and makes a classifier + loss pair for each class.\n\nIf ranking, or other true multi-class loss, that\'ll be sweet to have!\n\nRe: how to ignore, I vote for 0 too.\n\nLe mercredi 21 mai 2014, Ross Girshick notifications@github.com a crit :\n\n> I second that (0 for ignoring).\n> \n> On Wed, May 21, 2014 at 6:18 PM, Sergey Karayev <notifications@github.com<javascript:_e(%7B%7D,\'cvml\',\'notifications@github.com\');>>wrote:\n> \n> > I\'d say 0 for ignoring\n> > \n> > \n> > Reply to this email directly or view it on GitHub<\n> > https://github.com/BVLC/caffe/issues/149#issuecomment-43838076>\n> > .\n> \n> ## \n> \n> http://www.cs.berkeley.edu/~rbg/\n> \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/BVLC/caffe/issues/149#issuecomment-43846403\n> .\n', ""So the people have spoken, 0 would be for ignoring, -1 for negative and 1 for positive.\n\n@shelhamer right now I'm changing the window_data_layer to generate multiple labels and modifying the cross_entropy for the loss, and creating a new multi-label_accuracy. So not a ranking loss yet. \n\nIf you could share your loss layer with me I would appreciate it.\n"", 'Is this something different from last @sguada plans in https://github.com/BVLC/caffe/pull/523 or could be closed?\n', ""This can be close #149 follow up in #523.\n\nOn Monday, September 22, 2014, bhack <notifications@github.com\n<javascript:_e(%7B%7D,'cvml','notifications@github.com');>> wrote:\n\n> Is this something different from last @sguada https://github.com/sguada\n> plans in #523 https://github.com/BVLC/caffe/pull/523 or could be closed?\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/149#issuecomment-56392951.\n\n## \n\nSergio\n""]",[],[],0,0
245,caffe,67,closed,Add set_device_id to solver prototxt,"It will be nice to be able to set the GPU devide_id to be used in the solver.prototxt instead of being hard_coded. Add to #57 


",interface,"['In pull #69 .\n', 'If you have multiple devices , how do you input the parameter device_id [0,1,2,3] as it is a int32 device_id ?\n']",['\nmessage SolverParameter {\n...\n  // the mode solver will use: 0 for CPU and 1 for GPU. Use GPU in default.\n  optional int32 solver_mode = 17 [default = 1];\n  // the device_id will that will used in GPU mode. Use device_id=1in default.\n  optional int32 device_id = 18 [default = 1];\n}\n'],[],0,0
246,caffe,6510,closed,Makefile:591: recipe for target '.build_release/src/caffe/layers/cudnn_relu_layer.o' failed,"## Important - read before submitting

*Please read the [guidelines for contributing](https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md) before submitting this issue!*

*Please do not post installation, build, usage, or modeling questions, or other requests for help to Issues.*
Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead.
This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.

### Issue summary


### Steps to reproduce


### Tried solutions


### System configuration

* Operating system: ubuntu16.04
* Compiler: 
* CUDA version (if applicable): 8.0
* CUDNN version (if applicable): 7.1
* BLAS: 
* Python version (if using pycaffe): 3.6
* MATLAB version (if using matcaffe): 

### Issue checklist

- [ ] read the guidelines and removed the first paragraph
- [ ] written a short summary and detailed steps to reproduce
- [ ] explained how solutions to related problems failed (tick if found none)
- [ ] filled system configuration
- [ ] attached relevant logs/config files (tick if not applicable)

CXX .build_release/src/caffe/proto/caffe.pb.cc
CXX src/caffe/syncedmem.cpp
CXX src/caffe/common.cpp
CXX src/caffe/layers/spp_layer.cpp
CXX src/caffe/layers/cudnn_deconv_layer.cpp
CXX src/caffe/layers/cudnn_tanh_layer.cpp
CXX src/caffe/layers/cudnn_lrn_layer.cpp
CXX src/caffe/layers/cudnn_relu_layer.cpp
In file included from ./include/caffe/util/math_functions.hpp:11:0,
                 from ./include/caffe/layer.hpp:12,
                 from src/caffe/layers/spp_layer.cpp:4:
./include/caffe/util/mkl_alternate.hpp:14:19: fatal error: cblas.h: No such file or directory
compilation terminated.
In file included from ./include/caffe/util/math_functions.hpp:11:0,
                 from ./include/caffe/layer.hpp:12,
                 from ./include/caffe/layers/cudnn_deconv_layer.hpp:7,
                 from src/caffe/layers/cudnn_deconv_layer.cpp:5:
./include/caffe/util/mkl_alternate.hpp:14:19: fatal error: cblas.h: No such file or directory
compilation terminated.
Makefile:591: recipe for target '.build_release/src/caffe/layers/spp_layer.o' failed
make: *** [.build_release/src/caffe/layers/spp_layer.o] Error 1
make: *** Waiting for unfinished jobs....
Makefile:591: recipe for target '.build_release/src/caffe/layers/cudnn_deconv_layer.o' failed
make: *** [.build_release/src/caffe/layers/cudnn_deconv_layer.o] Error 1
In file included from ./include/caffe/util/math_functions.hpp:11:0,
                 from ./include/caffe/layer.hpp:12,
                 from ./include/caffe/layers/cudnn_lrn_layer.hpp:7,
                 from src/caffe/layers/cudnn_lrn_layer.cpp:4:
./include/caffe/util/mkl_alternate.hpp:14:19: fatal error: cblas.h: No such file or directory
compilation terminated.
In file included from ./include/caffe/util/math_functions.hpp:11:0,
                 from src/caffe/syncedmem.cpp:3:
./include/caffe/util/mkl_alternate.hpp:14:19: fatal error: cblas.h: No such file or directory
compilation terminated.
In file included from ./include/caffe/util/math_functions.hpp:11:0,
                 from ./include/caffe/layer.hpp:12,
                 from ./include/caffe/layers/cudnn_tanh_layer.hpp:7,
                 from src/caffe/layers/cudnn_tanh_layer.cpp:4:
./include/caffe/util/mkl_alternate.hpp:14:19: fatal error: cblas.h: No such file or directory
compilation terminated.
Makefile:591: recipe for target '.build_release/src/caffe/layers/cudnn_lrn_layer.o' failed
make: *** [.build_release/src/caffe/layers/cudnn_lrn_layer.o] Error 1
Makefile:591: recipe for target '.build_release/src/caffe/syncedmem.o' failed
make: *** [.build_release/src/caffe/syncedmem.o] Error 1
Makefile:591: recipe for target '.build_release/src/caffe/layers/cudnn_tanh_layer.o' failed
make: *** [.build_release/src/caffe/layers/cudnn_tanh_layer.o] Error 1
In file included from ./include/caffe/util/math_functions.hpp:11:0,
                 from ./include/caffe/layer.hpp:12,
                 from ./include/caffe/layers/cudnn_relu_layer.hpp:7,
                 from src/caffe/layers/cudnn_relu_layer.cpp:4:
./include/caffe/util/mkl_alternate.hpp:14:19: fatal error: cblas.h: No such file or directory
compilation terminated.
Makefile:591: recipe for target '.build_release/src/caffe/layers/cudnn_relu_layer.o' failed
make: *** [.build_release/src/caffe/layers/cudnn_relu_layer.o] Error 1",,"[""This looks like a build issue, and as such should be posted to caffe-users group. If I'm wrong, please re-read the checklist in the [issue template](https://github.com/BVLC/caffe/blob/master/.github/ISSUE_TEMPLATE.md), complete and reopen your issue accordingly.\r\n\r\nPlease post usage, installation, or modeling questions, or other requests for help to the [caffe-users list][1] instead of Issues. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe. Please read the [guidelines for contributing][2] before submitting an issue or a pull request.\r\n\r\n [1]: https://groups.google.com/forum/#!forum/caffe-users\r\n [2]: https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md""]",[],[],0,0
247,caffe,2060,closed,accuracy layer questions,"it seems that accuracy layer make some changes.And when testing we must go through a argmax layer and then go to accuracy layer.
Is that true?
",,"['A classification task now may goes like this?\n\nlayers {\n  name: ""max""\n  type: ARGMAX\n  bottom: ""conv_final""\n  top: ""top1""\n  include: { phase: TEST }\n} \nlayers {\n  name: ""accuracy""\n  type: ACCURACY\n  bottom: ""top1""\n  bottom: ""label""\n  top: ""accuracy""\n  include: { phase: TEST }\n} \n']",[],[],0,0
248,caffe,3830,closed,Should I need to crop original image to prepare train.txt or val.txt file?,"Suppose I have 1056 x 1056 image. The image contains multiple objects like car, house, tree etc but I want only car as a target object in this case how shall I prepare train.txt file? Should I crop only car from original image and prepare two class which have car denoted by 1 and which dose not have car denote by 0.

or 

should I consider original image(size 1056x1056) having car 1 and doesn't have car 0.

Please explain.
",,"['Please ask the mailing list for help with using caffe.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
249,caffe,4080,closed,replace open by fopen in io.cpp,"Could we replace open by fopen ? I am ready to do it.

Why? faster, more portable, ...
take a look here: http://stackoverflow.com/questions/1658476/c-fopen-vs-open
",,"['Sure, can you submit a PR making this change?\n', 'done https://github.com/BVLC/caffe/pull/4085.\n', 'This issue should be closed.\n', 'Closing as #4085 was made and then closed as unnecessary.\n']",[],[],0,0
250,caffe,349,closed,caffe.pb.o File format not recognized after update,"when I make the newest version of caffe, I get an error returned below:

build/src/caffe/proto/caffe.pb.o: file not recognized: File format not recognized
what can I do to solve this error
",,"['The Caffe protobuf format changed, and it needs to be built after the update. Do `make clean` and `make superclean` to clear out old generated files then `make` once more.\n']",[],[],0,0
251,caffe,2819,closed,PYTHONPATH to import caffe module,"In the tutorial it is written that ""The module dir caffe/python/caffe should be installed in your PYTHONPATH for import caffe"". However, when this path is added, a number of errors appear during the IPython initialization due to the confusion with internal io.py file. It seems like the actual path should be ""caffe/python"", in this case the initialization works well, and the ""caffe"" module can be correctly found.
",documentation,"['Which tutorial says this?  The installation instructions (http://caffe.berkeleyvision.org/installation.html) correctly suggest `export PYTHONPATH=/path/to/caffe/python:$PYTHONPATH`\n', 'It is on the interfaces page http://caffe.berkeleyvision.org/tutorial/interfaces.html\n', ""Thanks, I've made this more clear in de6d444 by using the same language as the installation page.\n""]",[],[],0,0
252,caffe,526,closed,How to manually set the weights of a network ?,"I have some C++ code that uses weights as an array of double, and I would like to interface it with caffe, and transfer the weights back and forth between my code and caffe.
What is the simplest way of doing that ? It doesn't need to be blazing fast.
",question,"['`net.params()` is a list of blobs; for each blob, `blob.mutable_cpu_data()` is a 4d row major array of weights that you can directly read and write to. Note that usually blobs come in pairs, one with weights and one with corresponding biases. You can also access these blobs via `net.layers()`.\n', ""If you check out the dev branch I've made an example of editing networks with the Python wrapper: https://github.com/BVLC/caffe/blob/dev/examples/net_surgery.ipynb\n\nOnce you have manually set the weights you can save the model back to disk. See #455 for details.\n"", 'Thanks, I did something like that :  \n\n``` c++\nint dim = 0;\n  for (int i = 0; i < net_params.size(); ++i) {\n    const Blob<Dtype>* net_param = net_params[i].get();\n    dim += net_param->count();\n  }\n\n  params = new Dtype[dim];\n  int offset = 0;\n  for (int i = 0; i < net_params.size(); ++i) {\n    Blob<Dtype>* net_param = net_params[i].get();\n    net_param->set_cpu_data(params + offset);\n    offset += net_param->count();\n  }\n```\n\nAs long as the blobs are not reshaped it should work.\n']",[],[],0,0
253,caffe,454,closed,homebrew leveldb dyld: Library not loaded (image not found),"The homebrew install of leveldb seems to not properly package the dylib name or else it's missing a symlink. Caffe compiles properly, but crashes instantly:



The solution is to make a libleveldb.dylib.1 symlink to libleveldb.1.15.dylib in /usr/local/opt/leveldb/lib either manually or by appending



to the install method of the leveldb formula by .

An upstream fix is probably best, but I'm merely documenting it here for lack of time.
",compatibility,"['Hi, this issue is present on OSX Yosemite, and the Homebrew formula seems to be the same.\n', 'when I use ""sudo make runtest"",error occured\r\n\r\n**error while loading shared libraries: libhdf5_hl.so.100: cannot open shared object file: No such file or directory make: *** [runtest] error 127**\r\n\r\nThis is my ~/.bashrc text.\r\n\r\n\r\n**export PATH=/usr/local/cuda-8.0/bin${PATH:+:${PATH}}  \r\nexport LD_LIBRARY_PATH=/usr/local/cuda8.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}} \r\nexport CUDA_HOME=/usr/local/cuda\r\n\r\nexport PATH=/home/jesse/software/Matlab2017a/Installer/bin${PATH:+:${PATH}}  \r\n\r\nexport PATH=/home/jesse/anaconda2/bin:$PATH\r\nexport LD_LIBARY_PATH=/home/jesse/anaconda2/lib:$LD_LIBRARY_PATH**\r\n\r\nWhat should i do\r\n\r\n\r\n\r\n\r\n']","['\ndyld: Library not loaded: /usr/local/opt/leveldb/lib/libleveldb.dylib.1\n  Referenced from: /Users/shelhamer/h/desk/caffe/caffe/build/test/test_all.testbin\n  Reason: image not found\nmake: *** [runtest] Trace/BPT trap: 5\n', ""\n    lib.install_symlink lib/'libleveldb.1.15.dylib' => 'libleveldb.dylib.1'\n""]",['brew edit leveldb'],0,0
254,caffe,4439,closed,Caffe Make Installation cuDNN status fail,"During the Caffe installation process, I managed to gone through the ""make all"" and ""make test"" without any error. I got an error as shown below during the ""make runtest"". Would like to seek for some guidance.
![cudnn_fail](https://cloud.githubusercontent.com/assets/20381221/16713251/f94710c0-46d3-11e6-8724-e4163ba28fda.png)

I have already installed CUDA8.0 RC and cuDNN5. My Nvidia GPU is GTX960 should be able to meet the compute capability for cuDNN.
![nvidia_driver](https://cloud.githubusercontent.com/assets/20381221/16713253/fea34480-46d3-11e6-9c8f-3bec37b1975a.png)

My caffe version is as shown below:
![caffe_version](https://cloud.githubusercontent.com/assets/20381221/16713255/017c9f8a-46d4-11e6-8201-fe6d45f2620c.png)

I have already included the cuDNN 5 into the Makefile.config ==> verified by using ""cmake.."" at the /build directory.
![nvidia_cuda](https://cloud.githubusercontent.com/assets/20381221/16713256/062d21b2-46d4-11e6-8b86-f97370d3bb11.png)
",,[],[],[],0,0
255,caffe,608,closed,Does caffe use stochastic gradient descent,"Hi,
I am wondering that does caffe use the stochastic gradient descent? That means update the weights for each batch, so that every iteration will have batch_size times updates.
Or it just updates the weights for each iteration, and all the batches in this iteration will share the same parameters?

I assumed the caffe uses the stochastic gradient descent, and tried to find the code about that part in the .cpp but got nothing. 
I increased and decreased batch_size, and expected different performance under the same iterations, since small batch_size means more updates, but I got all similar results!

Could someone tell me about it?
",,"['Yeah Caffe uses SGD\nhttps://github.com/BVLC/caffe/blob/master/src/caffe/solver.cpp#L230\n\nAt every iteration process one batch and updates the weights. Therefore changing the batch_size not affect the number of updates, but will change the gradients, but still converge if the change is within some reasonable range. \n', ""Hi,\nThanks for comment!\n\nSo the weights will be updated for every batch at each iteration. Then for one iteration, the number of updates will be:\nnumber of updates = number of all samples / batch_size\nSince the number of all samples is constant, then increase the batch_size will decrease the number of updates. And the results of different batch_size under the same iterations should be different, is that right? But I didn't observe the difference.\n\nIs that the batch of samples overlap? In that case, the batch_size will still affect the result under the same iterations.\n"", ""The weights are updated only once per iteration, with mean of the\ngradients. Each iteration process only one batch composed of batch_size\nsamples.\n\nThe batch of samples don't overlap. Even though the gradients are different\nwhen the batch_size changes, the performance can still be similar. So\nchanging the batch size it is not the best way to try to get better\nperformance.\n\nSergio\n\n2014-07-03 14:52 GMT-07:00 Xucong Zhang notifications@github.com:\n\n> Hi,\n> Thanks for comment!\n> \n> So the weights will be updated for every batch at each iteration. Then for\n> one iteration, the number of updates will be:\n> number of updates = number of all samples / batch_size\n> Since the number of all samples is constant, then increase the batch_size\n> will decrease the number of updates. And the results of different\n> batch_size under the same iterations should be different, is that right?\n> But I didn't observe the difference.\n> \n> Is that the batch of samples overlap? In that case, the batch_size will\n> still affect the result under the same iterations.\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/608#issuecomment-47989016.\n"", 'Hi,\n\nI see the problem! \nI thought one iteration will process all the data with each time batch_size samples. Because that what we did for previous work.\n\nThank you for explanation, you really help me a lot!\n\nXucong\n']",[],[],0,0
256,caffe,3203,closed,ELTWISE layer suspected bug,"In the eltwise_layer.cpp you do the following check in the Reshape member function



Meanwhile in other layers like euclidean_loss_layer.cpp you do this:



I think the above mentioned for loop should look something like this:



So if I have to following structure (just a small part):



This will result an error even if I have another memory data layer at the beginning which has batch_size: 10 which then goes thorough some convolutional layer and ends up in the inner inner-product-layer. I assume here you are checking 10*3 == 3 instead of checking 3==3.

I might be wrong and please let me know If I am happened to be wrong and I shouldn't change the checking in my version of caffe for some reason.

Thank you

Tams
",,"['After a quick glance, I think `CHECK(bottom[i]->shape() == bottom[0]->shape())` should be correct.\n\n`bottom[i]->shape()` returns `std::vector<int>`, a array containing the shape of the blob, and `==` for `std::vector` is elementwise. `CHECK(bottom[i]->shape() == bottom[0]->shape())` means all axis of the two blobs have the same dimension\n\nNote: `CHECK(bottom[i]->count(1) == bottom[0]->count(1))` does not compare axis 0 (which is usually the instance number dimension).\n', 'In the case you mentioned above, your `data` should be 10 x 3, so your `input2` also needs to be 10 x 3, so that they can be multiplied element-wise.\n\nNote: element-wise layer does not do numpy-style broadcasting, although we may implement it in the future.\n', 'So you are saying that this net should not work because it is not supported by the element-wise layer?\n\n```\n    layers {\n      name: ""frames-input-layer""\n      type: MEMORY_DATA\n      top: ""frames""\n      top: ""dummy1""\n      memory_data_param {\n        batch_size: 32\n        channels: 4\n        height: 84\n        width: 84\n      }\n    }\n    layers {\n      name: ""target-input-layer""\n      type: MEMORY_DATA\n      top: ""target""\n      top: ""dummy2""\n      memory_data_param {\n        batch_size: 32\n        channels: 18\n        height: 1\n        width: 1\n      }\n    }\n    layers {\n      name: ""filter-input-layer""\n      type: MEMORY_DATA\n      top: ""filter""\n      top: ""dummy3""\n      memory_data_param {\n        batch_size: 32\n        channels: 18\n        height: 1\n        width: 1\n      }\n    }\n    layers {\n      name: ""silence_layer""\n      type: SILENCE\n      bottom: ""dummy1""\n      bottom: ""dummy2""\n      bottom: ""dummy3""\n    }\n    layers {\n      name: ""convolutional-layer-1""\n      type: CONVOLUTION\n      bottom: ""frames""\n      top: ""convolution1""\n      convolution_param {\n        num_output: 16\n        kernel_size: 8\n        stride: 4\n        weight_filler {\n          type: ""gaussian""\n          std: 0.01\n        }\n      }\n    }\n    layers {\n      name: ""conv1_relu_layer""\n      type: RELU\n      bottom: ""convolution1""\n      top: ""convolution1""\n      relu_param {\n        negative_slope: 0.01\n      }\n    }\n    layers {\n      name: ""convolutional-layer-2""\n      type: CONVOLUTION\n      bottom: ""convolution1""\n      top: ""convolution2""\n      convolution_param {\n        num_output: 32\n        kernel_size: 4\n        stride: 2\n        weight_filler {\n          type: ""gaussian""\n          std: 0.01\n        }\n      }\n    }\n\n    layers {\n      name: ""conv2_relu_layer""\n      type: RELU\n      bottom: ""convolution2""\n      top: ""convolution2""\n      relu_param {\n        negative_slope: 0.01\n      }\n    }\n\n    layers {\n      name: ""inner-product-layer-1""\n      type: INNER_PRODUCT\n      bottom: ""convolution2""\n      top: ""inner-product-1""\n      inner_product_param {\n        num_output: 256\n        weight_filler {\n          type: ""gaussian""\n          std: 0.01\n        }\n      }\n    }\n\n    layers {\n      name: ""ip1_relu_layer""\n      type: RELU\n      bottom: ""inner-product-1""\n      top: ""inner-product-1""\n      relu_param {\n        negative_slope: 0.01\n      }\n    }\n\n    layers {\n      name: ""inner-product-layer-2""\n      type: INNER_PRODUCT\n      bottom: ""inner-product-1""\n      top: ""q-values""\n      inner_product_param {\n        num_output: 18\n        weight_filler {\n          type: ""gaussian""\n          std: 0.01\n        }\n      }\n    }\n\n    layers {\n      name: ""eltwise_layer""\n      type: ELTWISE\n      bottom: ""filter""\n      bottom: ""q-values""\n      top: ""filtered-q-values""\n      eltwise_param {\n        operation: PROD\n      }\n    }\n\n    layers {\n      name: ""loss""\n      type: EUCLIDEAN_LOSS\n      bottom: ""filtered-q-values""\n      bottom: ""target""\n      top: ""loss""\n    }\n```\n', 'I guess it is not working because your `filter` is 32 x 18 x 1 x 1 while your `q-values` is 32 x 18. You may use Reshape layer to reshape `filter` to 32 x 18.\n\nThis seems like a usage question than a caffe bug, and should be asked on [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead of here. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']","['\n  for (int i = 1; i < bottom.size(); ++i) {\n             CHECK(bottom[i]->shape() == bottom[0]->shape());\n  }\n', '\n CHECK_EQ(bottom[0]->count(1), bottom[1]->count(1))\n', '\n  for (int i = 1; i < bottom.size(); ++i) {\n             CHECK(bottom[i]->count(1) == bottom[0]->count(1));\n  }\n', '\n    layers {\n        name: ""input2-layer""\n        type: MEMORY_DATA\n        top: ""input2""\n        top: ""dummy2""\n        memory_data_param {\n            batch_size: 10\n            channels: 3\n            height: 1\n            width: 1\n        }\n\n        layers {\n            name: ""inner-product-layer""\n            type: INNER_PRODUCT\n            bottom: ""previous-data""\n            top: ""data""\n            inner_product_param {\n                num_output: 3\n                weight_filler {\n                    type: ""gaussian""\n                    std: 0.01\n                }\n            }\n        }\n\n        layers {\n            name: ""eltwise_layer""\n            type: ELTWISE\n            bottom: ""input2""\n            bottom: ""data""\n            top: ""filtered-q-values""\n            eltwise_param {\n                operation: PROD\n            }\n        }\n']",[],0,0
257,caffe,4130,closed,Return test accuracy during training in Python,"Hi, I'm using the Python interface. There seems to be no way of returning test accuracy during training when test net is specified. The accuracies can only be printed out. Is this correct?
",,"['Please ask usage questions on the mailing list.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n', ""Please, can someone read before closing it without any comment. \n\nI am not referring to the accuracy accessible from the top blob of the Accuracy blob, that's just the acc of a single batch which does not mean much in terms of evaluation. \n\nI am referring to the accuracy of the **WHOLE DATASET** which is only printed to the console but never returned. Now one has to manually test it with a for loop, or access it by parsing the log. \n\nIf this is the way intended by most people, close it as you wish.\n""]",[],[],0,0
258,caffe,5061,closed,It looks like the fps would decrease when run caffe model even the mnist,"### Issue summary
When run the caffe model ,it seems the fps will decrease .And sometimes the fps would not increase untill restart the computer. I try to reinstall ubuntu14.04 and caffe  ,but it can not help .

### Steps to reproduce


### Your system configuration
Operating system:utuntu14.04
Compiler:
CUDA version (if applicable):8.0.44
CUDNN version (if applicable):non
BLAS:
Python or MATLAB version (for pycaffe and matcaffe respectively):MATLAB

I am sorry for I do not know how to find out what the compiler and BLAS is.",,"['Please ask your question on the [Caffe user mailing list](https://groups.google.com/forum/#!forum/caffe-users) or on another website, such as http://stackoverflow.com/.\r\n\r\n> Please use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) for usage, installation, or modeling questions, or other requests for help.\r\n> _Do not post such requests to Issues._ Doing so interferes with the development of Caffe.', 'I am so sorry .I have misunderstood it.Thank you all the way.']",[],[],0,0
259,caffe,264,closed,CommonTest.TestPhase unit test failure,"I managed to successfully compile caffe on my computer. But one of the unit tests seem to fail. (all the other ones pass). Here's the error:

src/caffe/test/test_common.cpp:34: Failure
Value of: Caffe::TRAIN
  Actual: 0
Expected: Caffe::phase()
Which is: 1
[  FAILED  ] CommonTest.TestPhase

What do you think has caused this error?
",,"[""Strange. We once saw this when unit tests weren't careful about initializing their mode and phase and depended on the order of test execution, but that was fixed.\n\nWhich version is this? master, dev, or ?\n"", ""I'm using the master branch.\n"", ""Hmm. I can't reproduce this.\n\nWhich test ran before `CommonTest`?\n"", 'Here\'s a complete log before the failed test:\n\nbuild/src/caffe/test/test_all.testbin 0\nCuda number of devices: 1\nSetting to use device 0\nCurrent device id: 0\n[==========] Running 222 tests from 56 test cases.\n[----------] Global test environment set-up.\n[----------] 5 tests from LRNLayerTest/0, where TypeParam = float\n[ RUN      ] LRNLayerTest/0.TestSetup\n[       OK ] LRNLayerTest/0.TestSetup (272 ms)\n[ RUN      ] LRNLayerTest/0.TestCPUForward\n[       OK ] LRNLayerTest/0.TestCPUForward (9 ms)\n[ RUN      ] LRNLayerTest/0.TestGPUForward\n[       OK ] LRNLayerTest/0.TestGPUForward (10 ms)\n[ RUN      ] LRNLayerTest/0.TestCPUGradient\n[       OK ] LRNLayerTest/0.TestCPUGradient (1381 ms)\n[ RUN      ] LRNLayerTest/0.TestGPUGradient\n[       OK ] LRNLayerTest/0.TestGPUGradient (3495 ms)\n[----------] 5 tests from LRNLayerTest/0 (5167 ms total)\n\n[----------] 5 tests from LRNLayerTest/1, where TypeParam = double\n[ RUN      ] LRNLayerTest/1.TestSetup\n[       OK ] LRNLayerTest/1.TestSetup (0 ms)\n[ RUN      ] LRNLayerTest/1.TestCPUForward\n[       OK ] LRNLayerTest/1.TestCPUForward (0 ms)\n[ RUN      ] LRNLayerTest/1.TestGPUForward\n[       OK ] LRNLayerTest/1.TestGPUForward (0 ms)\n[ RUN      ] LRNLayerTest/1.TestCPUGradient\n[       OK ] LRNLayerTest/1.TestCPUGradient (1381 ms)\n[ RUN      ] LRNLayerTest/1.TestGPUGradient\n[       OK ] LRNLayerTest/1.TestGPUGradient (4280 ms)\n[----------] 5 tests from LRNLayerTest/1 (5661 ms total)\n\n[----------] 3 tests from BlobSimpleTest/0, where TypeParam = float\n[ RUN      ] BlobSimpleTest/0.TestInitialization\n[       OK ] BlobSimpleTest/0.TestInitialization (0 ms)\n[ RUN      ] BlobSimpleTest/0.TestPointers\n[       OK ] BlobSimpleTest/0.TestPointers (0 ms)\n[ RUN      ] BlobSimpleTest/0.TestReshape\n[       OK ] BlobSimpleTest/0.TestReshape (0 ms)\n[----------] 3 tests from BlobSimpleTest/0 (0 ms total)\n\n[----------] 3 tests from BlobSimpleTest/1, where TypeParam = double\n[ RUN      ] BlobSimpleTest/1.TestInitialization\n[       OK ] BlobSimpleTest/1.TestInitialization (0 ms)\n[ RUN      ] BlobSimpleTest/1.TestPointers\n[       OK ] BlobSimpleTest/1.TestPointers (0 ms)\n[ RUN      ] BlobSimpleTest/1.TestReshape\n[       OK ] BlobSimpleTest/1.TestReshape (0 ms)\n[----------] 3 tests from BlobSimpleTest/1 (0 ms total)\n\n[----------] 1 test from ProtoTest\n[ RUN      ] ProtoTest.TestSerialization\nPrinting in binary format.\n\n\x04test\x12dummy\nPrinting in text format.\nname: ""test""\ntype: ""dummy""\n\n[       OK ] ProtoTest.TestSerialization (0 ms)\n[----------] 1 test from ProtoTest (0 ms total)\n\n[----------] 1 test from MultinomialLogisticLossLayerTest/0, where TypeParam = float\n[ RUN      ] MultinomialLogisticLossLayerTest/0.TestGradientCPU\n[       OK ] MultinomialLogisticLossLayerTest/0.TestGradientCPU (4 ms)\n[----------] 1 test from MultinomialLogisticLossLayerTest/0 (4 ms total)\n\n[----------] 1 test from MultinomialLogisticLossLayerTest/1, where TypeParam = double\n[ RUN      ] MultinomialLogisticLossLayerTest/1.TestGradientCPU\n[       OK ] MultinomialLogisticLossLayerTest/1.TestGradientCPU (3 ms)\n[----------] 1 test from MultinomialLogisticLossLayerTest/1 (3 ms total)\n\n[----------] 4 tests from SyncedMemoryTest\n[ RUN      ] SyncedMemoryTest.TestInitialization\n[       OK ] SyncedMemoryTest.TestInitialization (0 ms)\n[ RUN      ] SyncedMemoryTest.TestAllocation\n[       OK ] SyncedMemoryTest.TestAllocation (0 ms)\n[ RUN      ] SyncedMemoryTest.TestCPUWrite\n[       OK ] SyncedMemoryTest.TestCPUWrite (0 ms)\n[ RUN      ] SyncedMemoryTest.TestGPUWrite\n[       OK ] SyncedMemoryTest.TestGPUWrite (0 ms)\n[----------] 4 tests from SyncedMemoryTest (0 ms total)\n\n[----------] 5 tests from PoolingLayerTest/0, where TypeParam = float\n[ RUN      ] PoolingLayerTest/0.TestSetup\n[       OK ] PoolingLayerTest/0.TestSetup (0 ms)\n[ RUN      ] PoolingLayerTest/0.TestCPUGradientMax\n[       OK ] PoolingLayerTest/0.TestCPUGradientMax (387 ms)\n[ RUN      ] PoolingLayerTest/0.TestGPUGradientMax\n[       OK ] PoolingLayerTest/0.TestGPUGradientMax (1103 ms)\n[ RUN      ] PoolingLayerTest/0.TestCPUGradientAve\n[       OK ] PoolingLayerTest/0.TestCPUGradientAve (393 ms)\n[ RUN      ] PoolingLayerTest/0.TestGPUGradientAve\n[       OK ] PoolingLayerTest/0.TestGPUGradientAve (1143 ms)\n[----------] 5 tests from PoolingLayerTest/0 (3026 ms total)\n\n[----------] 5 tests from PoolingLayerTest/1, where TypeParam = double\n[ RUN      ] PoolingLayerTest/1.TestSetup\n[       OK ] PoolingLayerTest/1.TestSetup (0 ms)\n[ RUN      ] PoolingLayerTest/1.TestCPUGradientMax\n[       OK ] PoolingLayerTest/1.TestCPUGradientMax (387 ms)\n[ RUN      ] PoolingLayerTest/1.TestGPUGradientMax\n[       OK ] PoolingLayerTest/1.TestGPUGradientMax (1176 ms)\n[ RUN      ] PoolingLayerTest/1.TestCPUGradientAve\n[       OK ] PoolingLayerTest/1.TestCPUGradientAve (379 ms)\n[ RUN      ] PoolingLayerTest/1.TestGPUGradientAve\n[       OK ] PoolingLayerTest/1.TestGPUGradientAve (1208 ms)\n[----------] 5 tests from PoolingLayerTest/1 (3150 ms total)\n\n[----------] 2 tests from GemmTest/0, where TypeParam = float\n[ RUN      ] GemmTest/0.TestGemm\n[       OK ] GemmTest/0.TestGemm (0 ms)\n[ RUN      ] GemmTest/0.TestGemv\n[       OK ] GemmTest/0.TestGemv (0 ms)\n[----------] 2 tests from GemmTest/0 (0 ms total)\n\n[----------] 2 tests from GemmTest/1, where TypeParam = double\n[ RUN      ] GemmTest/1.TestGemm\n[       OK ] GemmTest/1.TestGemm (1 ms)\n[ RUN      ] GemmTest/1.TestGemv\n[       OK ] GemmTest/1.TestGemv (0 ms)\n[----------] 2 tests from GemmTest/1 (1 ms total)\n\n[----------] 1 test from ConstantFillerTest/0, where TypeParam = float\n[ RUN      ] ConstantFillerTest/0.TestFill\n[       OK ] ConstantFillerTest/0.TestFill (0 ms)\n[----------] 1 test from ConstantFillerTest/0 (0 ms total)\n\n[----------] 1 test from ConstantFillerTest/1, where TypeParam = double\n[ RUN      ] ConstantFillerTest/1.TestFill\n[       OK ] ConstantFillerTest/1.TestFill (0 ms)\n[----------] 1 test from ConstantFillerTest/1 (0 ms total)\n\n[----------] 1 test from UniformFillerTest/0, where TypeParam = float\n[ RUN      ] UniformFillerTest/0.TestFill\n[       OK ] UniformFillerTest/0.TestFill (0 ms)\n[----------] 1 test from UniformFillerTest/0 (0 ms total)\n\n[----------] 1 test from UniformFillerTest/1, where TypeParam = double\n[ RUN      ] UniformFillerTest/1.TestFill\n[       OK ] UniformFillerTest/1.TestFill (0 ms)\n[----------] 1 test from UniformFillerTest/1 (0 ms total)\n\n[----------] 1 test from PositiveUnitballFillerTest/0, where TypeParam = float\n[ RUN      ] PositiveUnitballFillerTest/0.TestFill\n[       OK ] PositiveUnitballFillerTest/0.TestFill (0 ms)\n[----------] 1 test from PositiveUnitballFillerTest/0 (0 ms total)\n\n[----------] 1 test from PositiveUnitballFillerTest/1, where TypeParam = double\n[ RUN      ] PositiveUnitballFillerTest/1.TestFill\n[       OK ] PositiveUnitballFillerTest/1.TestFill (0 ms)\n[----------] 1 test from PositiveUnitballFillerTest/1 (0 ms total)\n\n[----------] 1 test from GaussianFillerTest/0, where TypeParam = float\n[ RUN      ] GaussianFillerTest/0.TestFill\n[       OK ] GaussianFillerTest/0.TestFill (0 ms)\n[----------] 1 test from GaussianFillerTest/0 (0 ms total)\n\n[----------] 1 test from GaussianFillerTest/1, where TypeParam = double\n[ RUN      ] GaussianFillerTest/1.TestFill\n[       OK ] GaussianFillerTest/1.TestFill (0 ms)\n[----------] 1 test from GaussianFillerTest/1 (0 ms total)\n\n[----------] 7 tests from ConvolutionLayerTest/0, where TypeParam = float\n[ RUN      ] ConvolutionLayerTest/0.TestSetup\n[       OK ] ConvolutionLayerTest/0.TestSetup (0 ms)\n[ RUN      ] ConvolutionLayerTest/0.TestSimpleConvolution\n[       OK ] ConvolutionLayerTest/0.TestSimpleConvolution (0 ms)\n[ RUN      ] ConvolutionLayerTest/0.TestSimpleConvolutionGroup\n[       OK ] ConvolutionLayerTest/0.TestSimpleConvolutionGroup (1 ms)\n[ RUN      ] ConvolutionLayerTest/0.TestCPUGradient\n[       OK ] ConvolutionLayerTest/0.TestCPUGradient (311 ms)\n[ RUN      ] ConvolutionLayerTest/0.TestCPUGradientGroup\n[       OK ] ConvolutionLayerTest/0.TestCPUGradientGroup (411 ms)\n[ RUN      ] ConvolutionLayerTest/0.TestGPUGradient\n[       OK ] ConvolutionLayerTest/0.TestGPUGradient (1865 ms)\n[ RUN      ] ConvolutionLayerTest/0.TestGPUGradientGroup\n[       OK ] ConvolutionLayerTest/0.TestGPUGradientGroup (3418 ms)\n[----------] 7 tests from ConvolutionLayerTest/0 (6006 ms total)\n\n[----------] 7 tests from ConvolutionLayerTest/1, where TypeParam = double\n[ RUN      ] ConvolutionLayerTest/1.TestSetup\n[       OK ] ConvolutionLayerTest/1.TestSetup (0 ms)\n[ RUN      ] ConvolutionLayerTest/1.TestSimpleConvolution\n[       OK ] ConvolutionLayerTest/1.TestSimpleConvolution (0 ms)\n[ RUN      ] ConvolutionLayerTest/1.TestSimpleConvolutionGroup\n[       OK ] ConvolutionLayerTest/1.TestSimpleConvolutionGroup (1 ms)\n[ RUN      ] ConvolutionLayerTest/1.TestCPUGradient\n[       OK ] ConvolutionLayerTest/1.TestCPUGradient (313 ms)\n[ RUN      ] ConvolutionLayerTest/1.TestCPUGradientGroup\n[       OK ] ConvolutionLayerTest/1.TestCPUGradientGroup (392 ms)\n[ RUN      ] ConvolutionLayerTest/1.TestGPUGradient\n[       OK ] ConvolutionLayerTest/1.TestGPUGradient (2919 ms)\n[ RUN      ] ConvolutionLayerTest/1.TestGPUGradientGroup\n[       OK ] ConvolutionLayerTest/1.TestGPUGradientGroup (5873 ms)\n[----------] 7 tests from ConvolutionLayerTest/1 (9498 ms total)\n\n[----------] 5 tests from Im2colLayerTest/0, where TypeParam = float\n[ RUN      ] Im2colLayerTest/0.TestSetup\n[       OK ] Im2colLayerTest/0.TestSetup (0 ms)\n[ RUN      ] Im2colLayerTest/0.TestCPU\n[       OK ] Im2colLayerTest/0.TestCPU (0 ms)\n[ RUN      ] Im2colLayerTest/0.TestGPU\n[       OK ] Im2colLayerTest/0.TestGPU (0 ms)\n[ RUN      ] Im2colLayerTest/0.TestCPUGradient\n[       OK ] Im2colLayerTest/0.TestCPUGradient (2386 ms)\n[ RUN      ] Im2colLayerTest/0.TestGPUGradient\n[       OK ] Im2colLayerTest/0.TestGPUGradient (7992 ms)\n[----------] 5 tests from Im2colLayerTest/0 (10378 ms total)\n\n[----------] 5 tests from Im2colLayerTest/1, where TypeParam = double\n[ RUN      ] Im2colLayerTest/1.TestSetup\n[       OK ] Im2colLayerTest/1.TestSetup (0 ms)\n[ RUN      ] Im2colLayerTest/1.TestCPU\n[       OK ] Im2colLayerTest/1.TestCPU (0 ms)\n[ RUN      ] Im2colLayerTest/1.TestGPU\n[       OK ] Im2colLayerTest/1.TestGPU (0 ms)\n[ RUN      ] Im2colLayerTest/1.TestCPUGradient\n[       OK ] Im2colLayerTest/1.TestCPUGradient (2402 ms)\n[ RUN      ] Im2colLayerTest/1.TestGPUGradient\n[       OK ] Im2colLayerTest/1.TestGPUGradient (8105 ms)\n[----------] 5 tests from Im2colLayerTest/1 (10507 ms total)\n\n[----------] 1 test from PlatformTest\n[ RUN      ] PlatformTest.TestInitialization\nMajor revision number:         3\nMinor revision number:         5\nName:                          GeForce GTX 780\nTotal global memory:           3220897792\nTotal shared memory per block: 49152\nTotal registers per block:     65536\nWarp size:                     32\nMaximum memory pitch:          2147483647\nMaximum threads per block:     1024\nMaximum dimension 0 of block:  1024\nMaximum dimension 1 of block:  1024\nMaximum dimension 2 of block:  64\nMaximum dimension 0 of grid:   2147483647\nMaximum dimension 1 of grid:   65535\nMaximum dimension 2 of grid:   65535\nClock rate:                    941000\nTotal constant memory:         65536\nTexture alignment:             512\nConcurrent copy and execution: Yes\nNumber of multiprocessors:     12\nKernel execution timeout:      No\n[       OK ] PlatformTest.TestInitialization (1 ms)\n[----------] 1 test from PlatformTest (1 ms total)\n\n[----------] 18 tests from NeuronLayerTest/0, where TypeParam = float\n[ RUN      ] NeuronLayerTest/0.TestReLUCPU\n[       OK ] NeuronLayerTest/0.TestReLUCPU (0 ms)\n[ RUN      ] NeuronLayerTest/0.TestReLUGradientCPU\n[       OK ] NeuronLayerTest/0.TestReLUGradientCPU (825 ms)\n[ RUN      ] NeuronLayerTest/0.TestReLUGPU\n[       OK ] NeuronLayerTest/0.TestReLUGPU (0 ms)\n[ RUN      ] NeuronLayerTest/0.TestReLUGradientGPU\n[       OK ] NeuronLayerTest/0.TestReLUGradientGPU (2231 ms)\n[ RUN      ] NeuronLayerTest/0.TestSigmoidCPU\n[       OK ] NeuronLayerTest/0.TestSigmoidCPU (0 ms)\n[ RUN      ] NeuronLayerTest/0.TestSigmoidGradientCPU\n[       OK ] NeuronLayerTest/0.TestSigmoidGradientCPU (1018 ms)\n[ RUN      ] NeuronLayerTest/0.TestSigmoidGPU\n[       OK ] NeuronLayerTest/0.TestSigmoidGPU (0 ms)\n[ RUN      ] NeuronLayerTest/0.TestSigmoidGradientGPU\n[       OK ] NeuronLayerTest/0.TestSigmoidGradientGPU (2326 ms)\n[ RUN      ] NeuronLayerTest/0.TestDropoutCPU\n[       OK ] NeuronLayerTest/0.TestDropoutCPU (0 ms)\n[ RUN      ] NeuronLayerTest/0.TestDropoutGradientCPU\n[       OK ] NeuronLayerTest/0.TestDropoutGradientCPU (867 ms)\n[ RUN      ] NeuronLayerTest/0.TestDropoutCPUTestPhase\n[       OK ] NeuronLayerTest/0.TestDropoutCPUTestPhase (0 ms)\n[ RUN      ] NeuronLayerTest/0.TestDropoutGPU\n[       OK ] NeuronLayerTest/0.TestDropoutGPU (9 ms)\n[ RUN      ] NeuronLayerTest/0.TestDropoutGradientGPU\n[       OK ] NeuronLayerTest/0.TestDropoutGradientGPU (2682 ms)\n[ RUN      ] NeuronLayerTest/0.TestDropoutGPUTestPhase\n[       OK ] NeuronLayerTest/0.TestDropoutGPUTestPhase (0 ms)\n[ RUN      ] NeuronLayerTest/0.TestBNLLCPU\n[       OK ] NeuronLayerTest/0.TestBNLLCPU (0 ms)\n[ RUN      ] NeuronLayerTest/0.TestBNLLGradientCPU\n[       OK ] NeuronLayerTest/0.TestBNLLGradientCPU (1193 ms)\n[ RUN      ] NeuronLayerTest/0.TestBNLLGPU\n[       OK ] NeuronLayerTest/0.TestBNLLGPU (0 ms)\n[ RUN      ] NeuronLayerTest/0.TestBNLLGradientGPU\n[       OK ] NeuronLayerTest/0.TestBNLLGradientGPU (2425 ms)\n[----------] 18 tests from NeuronLayerTest/0 (13577 ms total)\n\n[----------] 18 tests from NeuronLayerTest/1, where TypeParam = double\n[ RUN      ] NeuronLayerTest/1.TestReLUCPU\n[       OK ] NeuronLayerTest/1.TestReLUCPU (0 ms)\n[ RUN      ] NeuronLayerTest/1.TestReLUGradientCPU\n[       OK ] NeuronLayerTest/1.TestReLUGradientCPU (826 ms)\n[ RUN      ] NeuronLayerTest/1.TestReLUGPU\n[       OK ] NeuronLayerTest/1.TestReLUGPU (0 ms)\n[ RUN      ] NeuronLayerTest/1.TestReLUGradientGPU\n[       OK ] NeuronLayerTest/1.TestReLUGradientGPU (2251 ms)\n[ RUN      ] NeuronLayerTest/1.TestSigmoidCPU\n[       OK ] NeuronLayerTest/1.TestSigmoidCPU (0 ms)\n[ RUN      ] NeuronLayerTest/1.TestSigmoidGradientCPU\n[       OK ] NeuronLayerTest/1.TestSigmoidGradientCPU (994 ms)\n[ RUN      ] NeuronLayerTest/1.TestSigmoidGPU\n[       OK ] NeuronLayerTest/1.TestSigmoidGPU (0 ms)\n[ RUN      ] NeuronLayerTest/1.TestSigmoidGradientGPU\n[       OK ] NeuronLayerTest/1.TestSigmoidGradientGPU (2330 ms)\n[ RUN      ] NeuronLayerTest/1.TestDropoutCPU\n[       OK ] NeuronLayerTest/1.TestDropoutCPU (0 ms)\n[ RUN      ] NeuronLayerTest/1.TestDropoutGradientCPU\n[       OK ] NeuronLayerTest/1.TestDropoutGradientCPU (883 ms)\n[ RUN      ] NeuronLayerTest/1.TestDropoutCPUTestPhase\n[       OK ] NeuronLayerTest/1.TestDropoutCPUTestPhase (0 ms)\n[ RUN      ] NeuronLayerTest/1.TestDropoutGPU\n[       OK ] NeuronLayerTest/1.TestDropoutGPU (7 ms)\n[ RUN      ] NeuronLayerTest/1.TestDropoutGradientGPU\n[       OK ] NeuronLayerTest/1.TestDropoutGradientGPU (2658 ms)\n[ RUN      ] NeuronLayerTest/1.TestDropoutGPUTestPhase\n[       OK ] NeuronLayerTest/1.TestDropoutGPUTestPhase (0 ms)\n[ RUN      ] NeuronLayerTest/1.TestBNLLCPU\n[       OK ] NeuronLayerTest/1.TestBNLLCPU (0 ms)\n[ RUN      ] NeuronLayerTest/1.TestBNLLGradientCPU\n[       OK ] NeuronLayerTest/1.TestBNLLGradientCPU (1173 ms)\n[ RUN      ] NeuronLayerTest/1.TestBNLLGPU\n[       OK ] NeuronLayerTest/1.TestBNLLGPU (0 ms)\n[ RUN      ] NeuronLayerTest/1.TestBNLLGradientGPU\n[       OK ] NeuronLayerTest/1.TestBNLLGradientGPU (2441 ms)\n[----------] 18 tests from NeuronLayerTest/1 (13563 ms total)\n\n[----------] 1 test from EuclideanLossLayerTest/0, where TypeParam = float\n[ RUN      ] EuclideanLossLayerTest/0.TestGradientCPU\n[       OK ] EuclideanLossLayerTest/0.TestGradientCPU (3 ms)\n[----------] 1 test from EuclideanLossLayerTest/0 (3 ms total)\n\n[----------] 1 test from EuclideanLossLayerTest/1, where TypeParam = double\n[ RUN      ] EuclideanLossLayerTest/1.TestGradientCPU\n[       OK ] EuclideanLossLayerTest/1.TestGradientCPU (3 ms)\n[----------] 1 test from EuclideanLossLayerTest/1 (3 ms total)\n\n[----------] 1 test from DataLayerTest/0, where TypeParam = float\n[ RUN      ] DataLayerTest/0.TestRead\n[       OK ] DataLayerTest/0.TestRead (193 ms)\n[----------] 1 test from DataLayerTest/0 (193 ms total)\n\n[----------] 1 test from DataLayerTest/1, where TypeParam = double\n[ RUN      ] DataLayerTest/1.TestRead\n[       OK ] DataLayerTest/1.TestRead (195 ms)\n[----------] 1 test from DataLayerTest/1 (195 ms total)\n\n[----------] 1 test from HDF5DataLayerTest/0, where TypeParam = float\n[ RUN      ] HDF5DataLayerTest/0.TestRead\n[       OK ] HDF5DataLayerTest/0.TestRead (12 ms)\n[----------] 1 test from HDF5DataLayerTest/0 (12 ms total)\n\n[----------] 1 test from HDF5DataLayerTest/1, where TypeParam = double\n[ RUN      ] HDF5DataLayerTest/1.TestRead\n[       OK ] HDF5DataLayerTest/1.TestRead (6 ms)\n[----------] 1 test from HDF5DataLayerTest/1 (6 ms total)\n\n[----------] 4 tests from TanHLayerTest/0, where TypeParam = float\n[ RUN      ] TanHLayerTest/0.TestForwardCPU\n[       OK ] TanHLayerTest/0.TestForwardCPU (0 ms)\n[ RUN      ] TanHLayerTest/0.TestGradientCPU\n[       OK ] TanHLayerTest/0.TestGradientCPU (28 ms)\n[ RUN      ] TanHLayerTest/0.TestForwardGPU\n[       OK ] TanHLayerTest/0.TestForwardGPU (0 ms)\n[ RUN      ] TanHLayerTest/0.TestGradientGPU\n[       OK ] TanHLayerTest/0.TestGradientGPU (64 ms)\n[----------] 4 tests from TanHLayerTest/0 (92 ms total)\n\n[----------] 4 tests from TanHLayerTest/1, where TypeParam = double\n[ RUN      ] TanHLayerTest/1.TestForwardCPU\n[       OK ] TanHLayerTest/1.TestForwardCPU (0 ms)\n[ RUN      ] TanHLayerTest/1.TestGradientCPU\n[       OK ] TanHLayerTest/1.TestGradientCPU (23 ms)\n[ RUN      ] TanHLayerTest/1.TestForwardGPU\n[       OK ] TanHLayerTest/1.TestForwardGPU (0 ms)\n[ RUN      ] TanHLayerTest/1.TestGradientGPU\n[       OK ] TanHLayerTest/1.TestGradientGPU (65 ms)\n[----------] 4 tests from TanHLayerTest/1 (88 ms total)\n\n[----------] 2 tests from SoftmaxLayerTest/0, where TypeParam = float\n[ RUN      ] SoftmaxLayerTest/0.TestForwardCPU\n[       OK ] SoftmaxLayerTest/0.TestForwardCPU (0 ms)\n[ RUN      ] SoftmaxLayerTest/0.TestGradientCPU\n[       OK ] SoftmaxLayerTest/0.TestGradientCPU (26 ms)\n[----------] 2 tests from SoftmaxLayerTest/0 (26 ms total)\n\n[----------] 2 tests from SoftmaxLayerTest/1, where TypeParam = double\n[ RUN      ] SoftmaxLayerTest/1.TestForwardCPU\n[       OK ] SoftmaxLayerTest/1.TestForwardCPU (0 ms)\n[ RUN      ] SoftmaxLayerTest/1.TestGradientCPU\n[       OK ] SoftmaxLayerTest/1.TestGradientCPU (27 ms)\n[----------] 2 tests from SoftmaxLayerTest/1 (27 ms total)\n\n[----------] 5 tests from FlattenLayerTest/0, where TypeParam = float\n[ RUN      ] FlattenLayerTest/0.TestSetup\n[       OK ] FlattenLayerTest/0.TestSetup (0 ms)\n[ RUN      ] FlattenLayerTest/0.TestCPU\n[       OK ] FlattenLayerTest/0.TestCPU (0 ms)\n[ RUN      ] FlattenLayerTest/0.TestGPU\n[       OK ] FlattenLayerTest/0.TestGPU (0 ms)\n[ RUN      ] FlattenLayerTest/0.TestCPUGradient\n[       OK ] FlattenLayerTest/0.TestCPUGradient (1876 ms)\n[ RUN      ] FlattenLayerTest/0.TestGPUGradient\n[       OK ] FlattenLayerTest/0.TestGPUGradient (5146 ms)\n[----------] 5 tests from FlattenLayerTest/0 (7022 ms total)\n\n[----------] 5 tests from FlattenLayerTest/1, where TypeParam = double\n[ RUN      ] FlattenLayerTest/1.TestSetup\n[       OK ] FlattenLayerTest/1.TestSetup (0 ms)\n[ RUN      ] FlattenLayerTest/1.TestCPU\n[       OK ] FlattenLayerTest/1.TestCPU (0 ms)\n[ RUN      ] FlattenLayerTest/1.TestGPU\n[       OK ] FlattenLayerTest/1.TestGPU (0 ms)\n[ RUN      ] FlattenLayerTest/1.TestCPUGradient\n[       OK ] FlattenLayerTest/1.TestCPUGradient (1904 ms)\n[ RUN      ] FlattenLayerTest/1.TestGPUGradient\n[       OK ] FlattenLayerTest/1.TestGPUGradient (5248 ms)\n[----------] 5 tests from FlattenLayerTest/1 (7152 ms total)\n\n[----------] 10 tests from BenchmarkTest\n[ RUN      ] BenchmarkTest.TestTimerConstructorCPU\n[       OK ] BenchmarkTest.TestTimerConstructorCPU (0 ms)\n[ RUN      ] BenchmarkTest.TestTimerConstructorGPU\n[       OK ] BenchmarkTest.TestTimerConstructorGPU (0 ms)\n[ RUN      ] BenchmarkTest.TestTimerStartCPU\n[       OK ] BenchmarkTest.TestTimerStartCPU (0 ms)\n[ RUN      ] BenchmarkTest.TestTimerStartGPU\n[       OK ] BenchmarkTest.TestTimerStartGPU (0 ms)\n[ RUN      ] BenchmarkTest.TestTimerStopCPU\n[       OK ] BenchmarkTest.TestTimerStopCPU (0 ms)\n[ RUN      ] BenchmarkTest.TestTimerStopGPU\n[       OK ] BenchmarkTest.TestTimerStopGPU (0 ms)\n[ RUN      ] BenchmarkTest.TestTimerMilliSecondsCPU\n[       OK ] BenchmarkTest.TestTimerMilliSecondsCPU (300 ms)\n[ RUN      ] BenchmarkTest.TestTimerMilliSecondsGPU\n[       OK ] BenchmarkTest.TestTimerMilliSecondsGPU (300 ms)\n[ RUN      ] BenchmarkTest.TestTimerSecondsCPU\n[       OK ] BenchmarkTest.TestTimerSecondsCPU (301 ms)\n[ RUN      ] BenchmarkTest.TestTimerSecondsGPU\n[       OK ] BenchmarkTest.TestTimerSecondsGPU (300 ms)\n[----------] 10 tests from BenchmarkTest (1201 ms total)\n\n[----------] 6 tests from CommonTest\n[ RUN      ] CommonTest.TestCublasHandler\n[       OK ] CommonTest.TestCublasHandler (0 ms)\n[ RUN      ] CommonTest.TestVslStream\n[       OK ] CommonTest.TestVslStream (0 ms)\n[ RUN      ] CommonTest.TestBrewMode\n[       OK ] CommonTest.TestBrewMode (0 ms)\n[ RUN      ] CommonTest.TestPhase\nsrc/caffe/test/test_common.cpp:34: Failure\nValue of: Caffe::TRAIN\n  Actual: 0\nExpected: Caffe::phase()\nWhich is: 1\n[  FAILED  ] CommonTest.TestPhase (0 ms)\n[ RUN      ] CommonTest.TestRandSeedCPU\n[       OK ] CommonTest.TestRandSeedCPU (0 ms)\n[ RUN      ] CommonTest.TestRandSeedGPU\n[       OK ] CommonTest.TestRandSeedGPU (15 ms)\n[----------] 6 tests from CommonTest (16 ms total)\n', ""Sorry, this is quite strange and isn't reproducible. Make sure that `git status` doesn't show any changes and perhaps try making again.\n"", 'Closing on the assumption that this is fixed by #366 (only in the dev branch).  Please comment if you still see this failure on the dev branch.\n', 'This harmless failure was explained by the order of the tests differing across machines. gtest runs the tests in different orders (depending on order of linking).\n', 'I still have the problem!\n""src/caffe/test/test_common.cpp:34: Failure\nValue of: Caffe::TRAIN\n  Actual: 0\nExpected: Caffe::phase()""\n', 'Did you update to the latest dev and rebuild the tests?\n\nThe fix isn\'t in master yet. If you are on dev, include the random seed\ngiven at the top of make runtest\'s output.\n\nLe vendredi 9 mai 2014, lxycnu\n<notifications@github.com<javascript:_e(%7B%7D,\'cvml\',\'notifications@github.com\');>>\na crit :\n\n> I still have the problem!\n> ""src/caffe/test/test_common.cpp:34: Failure\n> Value of: Caffe::TRAIN\n> Actual: 0\n> Expected: Caffe::phase()""\n> \n> \n> Reply to this email directly or view it on GitHubhttps://github.com/BVLC/caffe/issues/264#issuecomment-42642486\n> .\n']",[],[],0,0
260,caffe,3406,closed,the relationship of 2 data layer,"datalayer1    data:x11  label: label1
datalayer2    data:y11 label: label2
The data in two datalayer has relationship of their  order
x11 ---> y11
x12---->y12
when train in SGD , can they shuffle in the same order >? ??
",,"['Turn off shuffling and they will be in sync.  Also note that if you use multi-gpu, there is no way to sync them currently, and you either have to use a single data layer (e.g. a custom python layer), or use only one gpu.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
261,caffe,4667,closed,Problems with CPU-ONLY,"After finishing all the steps, finally i run the demo.py under tools/,
Instead I get thsi problem:
...
faster-rcnn/tools/../lib/fast_rcnn/nms_wrapper.py"", line 10, in <module>
    from nms.cpu_nms import cpu_nms
ImportError: No module named cpu_nms

I did everything correctly..
Any help will be appreciate
",,"['Could you give little more details about the problem and steps you did?\n', 'same here. \r\nOn my laptop with Ubuntu 14 everything ran ok (GPU disabled).\r\nOn my desktop however with Ubuntu 15 I receive the same error.\r\n\r\nWhat is this module? Are the some details about it?\r\n\r\nThank you very much in advance!\r\n\r\nUpdate: My isse appeared using this code: https://github.com/tianzhi0549/CTPN/tree/master/caffe\r\nI had to compile the cpu_nms first using\r\n```\r\nmake\r\n```\r\nexecuting\r\n```\r\nall:\r\n\tcython src/utils/cpu_nms.pyx\r\n\tgcc -shared -pthread -fPIC -fwrapv -O2 -Wall -fno-strict-aliasing \\\r\n\t\t-I/usr/include/python2.7 -o src/utils/cpu_nms.so src/utils/cpu_nms.c\r\n\trm -rf src/utils/cpu_nms.c\r\n```\r\n\r\nSo for me its closed. :)\r\n\r\nBTW: Thanks for the awesome framework!\r\n\r\n', 'Please ask issues about forks at the fork and not here. This issue tracker is for BVLC/caffe.', 'Hi @CSJDeveloper \r\nI had a same issue and I solved it by checking the owner and group to use files in nms and nms directory. For me my ownership of cpu_nms was not for me, and I add me in owner and group and it works.\r\n']",[],[],0,0
262,caffe,2593,closed,spp-net first steps,"Did anyone try to reproduce first steps of SPP-Net? What i would like to try is to run first half of alexnet (data -> conv5), define several levels of pyramid with custom maxpool layer in python to output blobs of different sizes, & then run second half (fc6-conv -> fc8-conv) for all the different levels in the pyramid. is there an example somewhere on how to define layers without the proto txt file?
",,"[""It is possible to define network structure in python, see #2086 ( as of yet unmerged). \n\nFor python layers see [here](https://github.com/BVLC/caffe/blob/master/python/caffe/test/test_python_layer.py).\n\nIn case you haven't used caffe a lot please note that a SPP pooling layer was merged recently #2177 so specifying this from a prototxt file would probably be easiest way to get started.\n\nThis is a usage question and would belong on the mailing list.\n\nBR, Max\n"", 'Thanks a lot Max! and Sorry about putting this into issues.\n']",[],[],0,0
263,caffe,1765,closed,Multi label regression in Caffe,"i am extracting 30 facial keypoints (x,y) from an input image as per kaggle facialkeypoints competition.

How do i setup caffe to run a regression and produce 30 dimensional output??. 



How do i setup caffe accordingly?. I am using EUCLIDEAN_LOSS (sum of squares) to get the regressed output. Here is a simple logistic regressor model using caffe but it is not working. Looks accuracy layer cannot handle multi-label output.



Here is the layer file:



I am have seen this topic but really cant get a grasp of it. I see that stable version of caffe can handle only 1 or 2 outputs.
",,"['I think you should use also a EUCLIDEAN_LOSS instead of ACCURACY for the accuracy layer according to this: https://github.com/BVLC/caffe/issues/512\n', 'The problem is loss layer with EUCLIDEAN_LOSS can output 1 value. It cannot output 30 outputs. Lets say INNER_PRODUCT layer gives 30 output, the loss layer computes sum of all 30 outputs to produce loss. Thats not i want. I want to compute 30 losses for 30 outputs .\n', ""The input blob 'label' is only one-dimensional, it needs to be a 30 dimensional as well \nYou can prepare the data accordingly, there once was a pull request which is now out of date:\nhttps://github.com/BVLC/caffe/issues/144\n"", 'The input data hd5 is already 30 dimensional. i read somewhere only hd5 can handle multiple input labels.\n\n![screenshot from 2015-01-21 17 31 13](https://cloud.githubusercontent.com/assets/6329118/5840263/6fa81b06-a194-11e4-8d4a-e39b1612bdf7.png)\n\n i remove the accuracy layer from above, i connect the IP to euclidean loss layer. It runs but i am not entirely convinced. Am i doing it right?  i see loss value but not converging hmmm :( I am still not using test data just training.\n\n```\npbu@pbu-OptiPlex-740-Enhanced:~/Desktop$ ./facialkp.sh\nI0121 17:32:16.788698  2711 caffe.cpp:103] Use CPU.\nI0121 17:32:17.163740  2711 caffe.cpp:107] Starting Optimization\nI0121 17:32:17.163918  2711 solver.cpp:32] Initializing solver from parameters: \nbase_lr: 0.01\ndisplay: 100\nmax_iter: 10000\nlr_policy: ""step""\ngamma: 0.1\nmomentum: 0.9\nweight_decay: 0.0005\nstepsize: 5000\nsnapshot: 10000\nsnapshot_prefix: ""/home/pbu/Desktop/tmp""\nsolver_mode: CPU\nnet: ""/home/pbu/Desktop/facialkp.prototxt""\nI0121 17:32:17.164019  2711 solver.cpp:67] Creating training net from net file: /home/pbu/Desktop/facialkp.prototxt\nI0121 17:32:17.184345  2711 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data\nI0121 17:32:17.184592  2711 net.cpp:39] Initializing net from parameters: \nname: ""LogReg""\nlayers {\n  top: ""data""\n  top: ""label""\n  name: ""fkp""\n  type: HDF5_DATA\n  hdf5_data_param {\n    source: ""train.txt""\n    batch_size: 100\n  }\n  include {\n    phase: TRAIN\n  }\n}\nlayers {\n  bottom: ""data""\n  top: ""ip""\n  name: ""ip""\n  type: INNER_PRODUCT\n  inner_product_param {\n    num_output: 30\n  }\n}\nlayers {\n  bottom: ""ip""\n  bottom: ""label""\n  top: ""loss""\n  name: ""loss""\n  type: EUCLIDEAN_LOSS\n}\nstate {\n  phase: TRAIN\n}\nI0121 17:32:17.195250  2711 net.cpp:67] Creating Layer fkp\nI0121 17:32:17.195312  2711 net.cpp:356] fkp -> data\nI0121 17:32:17.195348  2711 net.cpp:356] fkp -> label\nI0121 17:32:17.195379  2711 net.cpp:96] Setting up fkp\nI0121 17:32:17.195487  2711 hdf5_data_layer.cpp:57] Loading filename from train.txt\nI0121 17:32:17.195663  2711 hdf5_data_layer.cpp:69] Number of files: 1\nI0121 17:32:17.195683  2711 hdf5_data_layer.cpp:29] Loading HDF5 filefacialkp-train.hd5\nI0121 17:32:18.079417  2711 hdf5_data_layer.cpp:49] Successully loaded 4934 rows\nI0121 17:32:18.079493  2711 hdf5_data_layer.cpp:81] output data size: 100,9216,1,1\nI0121 17:32:18.079552  2711 net.cpp:103] Top shape: 100 9216 1 1 (921600)\nI0121 17:32:18.079574  2711 net.cpp:103] Top shape: 100 30 1 1 (3000)\nI0121 17:32:18.079612  2711 net.cpp:67] Creating Layer ip\nI0121 17:32:18.079637  2711 net.cpp:394] ip <- data\nI0121 17:32:18.079668  2711 net.cpp:356] ip -> ip\nI0121 17:32:18.079705  2711 net.cpp:96] Setting up ip\nI0121 17:32:18.081114  2711 net.cpp:103] Top shape: 100 30 1 1 (3000)\nI0121 17:32:18.081243  2711 net.cpp:67] Creating Layer loss\nI0121 17:32:18.081267  2711 net.cpp:394] loss <- ip\nI0121 17:32:18.081290  2711 net.cpp:394] loss <- label\nI0121 17:32:18.081318  2711 net.cpp:356] loss -> loss\nI0121 17:32:18.081346  2711 net.cpp:96] Setting up loss\nI0121 17:32:18.089938  2711 net.cpp:103] Top shape: 1 1 1 1 (1)\nI0121 17:32:18.089965  2711 net.cpp:109]     with loss weight 1\nI0121 17:32:18.090049  2711 net.cpp:170] loss needs backward computation.\nI0121 17:32:18.090068  2711 net.cpp:170] ip needs backward computation.\nI0121 17:32:18.090085  2711 net.cpp:172] fkp does not need backward computation.\nI0121 17:32:18.090101  2711 net.cpp:208] This network produces output loss\nI0121 17:32:18.090122  2711 net.cpp:467] Collecting Learning Rate and Weight Decay.\nI0121 17:32:18.090142  2711 net.cpp:219] Network initialization done.\nI0121 17:32:18.090158  2711 net.cpp:220] Memory required for data: 3710404\nI0121 17:32:18.090208  2711 solver.cpp:41] Solver scaffolding done.\nI0121 17:32:18.090230  2711 solver.cpp:160] Solving LogReg\nI0121 17:32:18.090246  2711 solver.cpp:161] Learning Rate Policy: step\nI0121 17:32:18.172677  2711 solver.cpp:209] Iteration 0, loss = 40128.5\nI0121 17:32:18.172803  2711 solver.cpp:224]     Train net output #0: loss = 40128.5 (* 1 = 40128.5 loss)\nI0121 17:32:18.172847  2711 solver.cpp:445] Iteration 0, lr = 0.01\nI0121 17:32:21.068056  2711 solver.cpp:209] Iteration 100, loss = 164.532\nI0121 17:32:21.068186  2711 solver.cpp:224]     Train net output #0: loss = 164.532 (* 1 = 164.532 loss)\nI0121 17:32:21.068215  2711 solver.cpp:445] Iteration 100, lr = 0.01\nI0121 17:32:23.937835  2711 solver.cpp:209] Iteration 200, loss = 124.259\nI0121 17:32:23.937965  2711 solver.cpp:224]     Train net output #0: loss = 124.259 (* 1 = 124.259 loss)\nI0121 17:32:23.937993  2711 solver.cpp:445] Iteration 200, lr = 0.01\nI0121 17:32:26.836241  2711 solver.cpp:209] Iteration 300, loss = 132.833\nI0121 17:32:26.836433  2711 solver.cpp:224]     Train net output #0: loss = 132.833 (* 1 = 132.833 loss)\nI0121 17:32:26.836462  2711 solver.cpp:445] Iteration 300, lr = 0.01\nI0121 17:32:29.702158  2711 solver.cpp:209] Iteration 400, loss = 161.586\nI0121 17:32:29.702286  2711 solver.cpp:224]     Train net output #0: loss = 161.586 (* 1 = 161.586 loss)\nI0121 17:32:29.702313  2711 solver.cpp:445] Iteration 400, lr = 0.01\nI0121 17:32:32.559435  2711 solver.cpp:209] Iteration 500, loss = 105.922\nI0121 17:32:32.559563  2711 solver.cpp:224]     Train net output #0: loss = 105.922 (* 1 = 105.922 loss)\nI0121 17:32:32.559590  2711 solver.cpp:445] Iteration 500, lr = 0.01\nI0121 17:32:35.418654  2711 solver.cpp:209] Iteration 600, loss = 149.592\nI0121 17:32:35.418781  2711 solver.cpp:224]     Train net output #0: loss = 149.592 (* 1 = 149.592 loss)\nI0121 17:32:35.418810  2711 solver.cpp:445] Iteration 600, lr = 0.01\nI0121 17:32:38.276181  2711 solver.cpp:209] Iteration 700, loss = 131.396\nI0121 17:32:38.276309  2711 solver.cpp:224]     Train net output #0: loss = 131.396 (* 1 = 131.396 loss)\nI0121 17:32:38.276336  2711 solver.cpp:445] Iteration 700, lr = 0.01\nI0121 17:32:41.135144  2711 solver.cpp:209] Iteration 800, loss = 159.562\nI0121 17:32:41.135272  2711 solver.cpp:224]     Train net output #0: loss = 159.562 (* 1 = 159.562 loss)\nI0121 17:32:41.135298  2711 solver.cpp:445] Iteration 800, lr = 0.01\nI0121 17:32:43.993687  2711 solver.cpp:209] Iteration 900, loss = 130.259\nI0121 17:32:43.993819  2711 solver.cpp:224]     Train net output #0: loss = 130.259 (* 1 = 130.259 loss)\nI0121 17:32:43.993846  2711 solver.cpp:445] Iteration 900, lr = 0.01\nI0121 17:32:46.854629  2711 solver.cpp:209] Iteration 1000, loss = 107.512\nI0121 17:32:46.854954  2711 solver.cpp:224]     Train net output #0: loss = 107.512 (* 1 = 107.512 loss)\nI0121 17:32:46.854984  2711 solver.cpp:445] Iteration 1000, lr = 0.01\n```\n', 'Did you resolve your issue?\nIt looks like the network is ""predicting zeros""?\n', 'Thanks @pannous \nnope, there is a problem with dimensions of input data and labels it seems :) \n', '`EUCLIDEAN_LOSS` is the right loss for linear regression -- the scalar output is the sum of squared errors across dimensions, which is the total loss for the regression. It can learn predictions of any blob dimensionality (scalar, vector of 30 like your case, or matrix).\n\nPlease ask modeling questions on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) mailing list.\n', 'i fixed the labels and data dimensions and there is another problem. The network is predicting same output in the fc7 layer, no matter what the input is\n\nI am continuing this thread here: https://groups.google.com/forum/#!topic/caffe-users/o4cpDNylo3Q\n', '@olddocks how did you fix the labels and data dimensions? could you please share the code?\n', '@nayef i fixed the issue by adding bias=1 to the layers. Adding another ip layer also helped.\n', 'So no change was needed in data dimensions?\nOn Feb 18, 2015 8:00 PM, ""olddocks"" notifications@github.com wrote:\n\n> @nayef https://github.com/nayef i fixed the issue by adding bias=1 to\n> the layers. Adding another ip layer also helped.\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/1765#issuecomment-74867569.\n', 'Yes i changed the dimensions needed. It worked :+1: \n', 'What change did you make in dimensions?\nOn Feb 18, 2015 9:03 PM, ""olddocks"" notifications@github.com wrote:\n\n> Yes i changed the dimensions needed. It worked [image: :+1:]\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/1765#issuecomment-74878064.\n', ""@olddocks  I'd also be interested to have a more thorough explanation on how you fixed the issue. Thanks!\n"", 'Have a look here: http://corpocrat.com/2015/02/24/facial-keypoints-extraction-using-deep-learning-with-caffe/\n', 'Hi @olddocks , i am dealing with a similar regression problem. However, my .csv file contains image filename and 3 real values labels. How can I create hdf5 input file? Also, if I use some popular network such as AlexNet, VGG,... to train a regression problem, what should be the appropriate changes in prototxt files?\n', ""Hi, @olddocks I am doing the facial keypoints detection on the dataset: http://mmlab.ie.cuhk.edu.hk/archive/CNN_FacePoint.htm. I used similary network as you, but the output for different image is always the same. Could you give me some suggestions about this problem?\npart 1: dataprocess\nimport os\nimport numpy as np\nimport h5py\nimport cv2\nimport math\n\nnum_cols = 1  \nnum_rows = 3466 #10000 images for train and 3466 images for validation\nheight   = 39    #\nwidth    = 39    #\nlabeldim = 10\ntotal_size = num_cols \\* num_rows \\* height \\* width\ndata=np.zeros([num_rows,num_cols,height,width])\ndata=data.astype(np.float32)\nlabel=np.zeros([num_rows,labeldim])\nlabel=label.astype(np.float32);\n\ndirname  ='/home/deep-learning/caffe/matlab/facial_point_estimation/dataset/face/train/'\nfilename ='/home/deep-learning/caffe/matlab/facial_point_estimation/dataset/face/train/testImageList.txt'\nf = open(filename)\nline = f.readline()\ni=0\nwhile line:\n    print i\n    content=line.split(' ') \n    content[1:]=[float(j) for j in content[1:]]\n    imgname=dirname+content[0]\n    img=cv2.imread(imgname)\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    face=img[int(content[3]):int(content[4]),int(content[1]):int(content[2])]\n    face=cv2.resize(face,(height,width))\n    face=face*(1./255)  \n    face=face.astype(np.float32)\n    data[i,0,:,:]=face\n    #print data[i,0,:,:].shape    \n\n```\nfacewidth =int(content[2])-int(content[1])+1\nfaceheight=int(content[4])-int(content[3])+1\n\nfacepoint=content[5:]\nfacepoint[0::2]=[((float(j-int(content[1]))/(float(facewidth )/39.0))-19.5)/19.5 for j in facepoint[0::2]]\nfacepoint[1::2]=[((float(j-int(content[3]))/(float(faceheight)/39.0))-19.5)/19.5 for j in facepoint[1::2]]\n#print facepoint\nfor j in facepoint:\n    assert(1>=j>=0 or 0>=j>=-1)  \nlabel[i,:]=facepoint\nline = f.readline()\ni+=1\n```\n\nwith h5py.File(os.getcwd()+ '/test_data.h5', 'w') as f:\n        f['data'] = data\n        f['label'] = label\n\nwith open(os.getcwd() + '/test_data_list.txt', 'w') as f:\n        f.write(os.getcwd() + '/test_data.h5\\n')\n""]","['\nInput: 96x96 image\nOutput: 30  (30 dimensional output).\n', '\nI0120 17:51:27.039113  4113 net.cpp:394] accuracy <- label_fkp_1_split_1\nI0120 17:51:27.039135  4113 net.cpp:356] accuracy -> accuracy\nI0120 17:51:27.039158  4113 net.cpp:96] Setting up accuracy\nF0120 17:51:27.039201  4113 accuracy_layer.cpp:26] Check failed: bottom[1]->channels() == 1 (30 vs. 1) \n*** Check failure stack trace: ***\n    @     0x7f7c2711bdaa  (unknown)\n    @     0x7f7c2711bce4  (unknown)\n    @     0x7f7c2711b6e6  (unknown)\n', '\nname: ""LogReg""\nlayers {\n  name: ""fkp""\n  top: ""data""\n  top: ""label""\n  type: HDF5_DATA\n  hdf5_data_param {\n   source: ""train.txt""\n   batch_size: 100\n  }\n    include: { phase: TRAIN }\n\n}\n\nlayers {\n  name: ""fkp""\n  type: HDF5_DATA\n  top: ""data""\n  top: ""label""\n  hdf5_data_param {\n    source: ""test.txt""\n    batch_size: 100\n  }\n\n  include: { phase: TEST }\n}\n\nlayers {\n  name: ""ip""\n  type: INNER_PRODUCT\n  bottom: ""data""\n  top: ""ip""\n  inner_product_param {\n    num_output: 30\n  }\n}\nlayers {\n  name: ""loss""\n  type: EUCLIDEAN_LOSS\n  bottom: ""ip""\n  bottom: ""label""\n  top: ""loss""\n}\n\nlayers {\n  name: ""accuracy""\n  type: ACCURACY\n  bottom: ""ip""\n  bottom: ""label""\n  top: ""accuracy""\n  include: { phase: TEST }\n}\n']",[],0,0
264,caffe,4468,closed,"Hi, anybody know how to transform .caffemodel to .mat?","Hi, does anybody know how to transform .caffemodel to .mat.
My current model was trained using caffe, and the model it saved are .caffemodel type. Now, I hope to do fine tuning using matconvnet, and it requires the model in "".mat"" type. 
",,"['You probably want to take a look at this\nhttps://github.com/vlfeat/matconvnet/blob/master/utils/import-caffe.py\n\nOn Thu, Jul 14, 2016 at 11:56 PM, Wang Chaoqi notifications@github.com\nwrote:\n\n> Hi, does anybody know how to transform .caffemodel to .mat.\n> My current model was trained using caffe, and the model it saved are\n> .caffemodel type. Now, I hope to do fine tuning using matconvnet, and it\n> requires the model in "".mat"" type.\n> \n> \n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/BVLC/caffe/issues/4468, or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AFfrUdSofkkQhnABX6-Gbv6hWemYQyhfks5qVwT-gaJpZM4JNDl5\n> .\n\n## \n\nBest Regards,\nZizhao\n', 'Closing, since this is an issue for matconvnet and not BVLC/caffe.  Please follow up with the matconvnet maintainers.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
265,caffe,1498,closed,why the mvn_layer after inner_product_layer return nan?,"when the cross_channel = true
",,"['It may be a bug addressed by #1797.\n', 'Closing as past numerical instability in MVN layer should be fixed now.']",[],[],0,0
266,caffe,2159,closed,Difference between static linkage and dynamic linkage,"I linked my code against 'libcaffe.a', and the code below:

will generate runtime error message:  


If I switched to 'libcaffe.so', no error message generated. But in previous Caffe library, I can link against static library without any problem.

I cannot understand what difference between the static and dynamic versions of libcaffe.

Could somebody here elucidate this phenomenon?
Thanks.
",,[],"['C++\r\ncaffe::NetParameter params;\r\ncaffe::ReadNetParamsFromTextFileOrDie(net_proto, &params);\r\ncaffe::Net<float> net(params);\r\n']",['layer_factory.hpp:77] Check failed: registry.count(type) == 1 (0 vs. 1) Unknown layer type: Data (known types: )'],0,0
267,caffe,2564,closed,osx: abs not defined absval_layer,"When compiling on osx Yosemite the absval_layer raises a warning stating:
""warning: absolute value function 'abs' given an argument of type 'long long' but has parameter of type 'int' which may cause truncation of value""

I resolved it for me by putting the following code directly after ""namespace caffe {""


",JL,"[""Sorry, I can't reproduce this. It might have been a temporary issue with new tooling while Yosemite was young.""]",['\ninline long abs(long _X) {\n    if (_X < 0) {\n        return -_X;\n    }\n    else {\n        return _X;\n    }\n}\n'],[],0,0
268,caffe,6095,closed,cannot find -lopencv_core,"The command is 

> make all -j$64 && make distribute -j$64

PROTOC src/caffe/proto/caffe.proto
CXX src/caffe/util/cudnn.cpp
CXX src/caffe/util/hdf5.cpp
CXX src/caffe/util/db.cpp
CXX src/caffe/util/db_lmdb.cpp
CXX src/caffe/util/insert_splits.cpp
CXX src/caffe/util/blocking_queue.cpp
CXX src/caffe/util/math_functions.cpp
CXX src/caffe/util/db_leveldb.cpp
CXX src/caffe/util/benchmark.cpp
CXX src/caffe/util/upgrade_proto.cpp
CXX src/caffe/util/im2col.cpp
CXX src/caffe/util/io.cpp
CXX src/caffe/util/signal_handler.cpp
CXX src/caffe/syncedmem.cpp
CXX src/caffe/layer.cpp
CXX src/caffe/internal_thread.cpp
CXX src/caffe/blob.cpp
CXX src/caffe/layer_factory.cpp
CXX src/caffe/solver.cpp
CXX src/caffe/solvers/rmsprop_solver.cpp
CXX src/caffe/solvers/adadelta_solver.cpp
CXX src/caffe/solvers/sgd_solver.cpp
CXX src/caffe/solvers/nesterov_solver.cpp
CXX src/caffe/solvers/adam_solver.cpp
CXX src/caffe/solvers/adagrad_solver.cpp
CXX src/caffe/parallel.cpp
CXX src/caffe/layers/log_layer.cpp
CXX src/caffe/layers/bias_layer.cpp
CXX src/caffe/layers/filter_layer.cpp
CXX src/caffe/layers/loss_layer.cpp
CXX src/caffe/layers/hinge_loss_layer.cpp
CXX src/caffe/layers/cudnn_sigmoid_layer.cpp
CXX src/caffe/layers/cudnn_pooling_layer.cpp
CXX src/caffe/layers/sigmoid_cross_entropy_loss_layer.cpp
CXX src/caffe/layers/input_layer.cpp
CXX src/caffe/layers/elu_layer.cpp
CXX src/caffe/layers/cudnn_lrn_layer.cpp
CXX src/caffe/layers/base_conv_layer.cpp
CXX src/caffe/layers/multinomial_logistic_loss_layer.cpp
CXX src/caffe/layers/pooling_layer.cpp
CXX src/caffe/layers/crop_layer.cpp
CXX src/caffe/layers/relu_layer.cpp
CXX src/caffe/layers/threshold_layer.cpp
CXX src/caffe/layers/cudnn_lcn_layer.cpp
CXX src/caffe/layers/scale_layer.cpp
CXX src/caffe/layers/concat_layer.cpp
CXX src/caffe/layers/spp_layer.cpp
CXX src/caffe/layers/contrastive_loss_layer.cpp
CXX src/caffe/layers/lrn_layer.cpp
CXX src/caffe/layers/split_layer.cpp
CXX src/caffe/layers/inner_product_layer.cpp
CXX src/caffe/layers/batch_reindex_layer.cpp
CXX src/caffe/layers/mvn_layer.cpp
CXX src/caffe/layers/softmax_loss_layer.cpp
CXX src/caffe/layers/tanh_layer.cpp
CXX src/caffe/layers/power_layer.cpp
CXX src/caffe/layers/image_data_layer.cpp
CXX src/caffe/layers/cudnn_conv_layer.cpp
CXX src/caffe/layers/absval_layer.cpp
CXX src/caffe/layers/embed_layer.cpp
CXX src/caffe/layers/window_data_layer.cpp
CXX src/caffe/layers/bnll_layer.cpp
CXX src/caffe/layers/euclidean_loss_layer.cpp
CXX src/caffe/layers/im2col_layer.cpp
CXX src/caffe/layers/parameter_layer.cpp
CXX src/caffe/layers/memory_data_layer.cpp
CXX src/caffe/layers/argmax_layer.cpp
CXX src/caffe/layers/reduction_layer.cpp
CXX src/caffe/layers/data_layer.cpp
CXX src/caffe/layers/dummy_data_layer.cpp
CXX src/caffe/layers/silence_layer.cpp
CXX src/caffe/layers/batch_norm_layer.cpp
CXX src/caffe/layers/conv_layer.cpp
CXX src/caffe/layers/prelu_layer.cpp
CXX src/caffe/layers/slice_layer.cpp
CXX src/caffe/layers/lstm_unit_layer.cpp
CXX src/caffe/layers/hdf5_data_layer.cpp
CXX src/caffe/layers/reshape_layer.cpp
CXX src/caffe/layers/cudnn_tanh_layer.cpp
CXX src/caffe/layers/cudnn_softmax_layer.cpp
CXX src/caffe/layers/infogain_loss_layer.cpp
CXX src/caffe/layers/base_data_layer.cpp
CXX src/caffe/layers/eltwise_layer.cpp
CXX src/caffe/layers/accuracy_layer.cpp
CXX src/caffe/layers/sigmoid_layer.cpp
CXX src/caffe/layers/dropout_layer.cpp
CXX src/caffe/layers/neuron_layer.cpp
CXX src/caffe/layers/recurrent_layer.cpp
CXX src/caffe/layers/tile_layer.cpp
CXX src/caffe/layers/hdf5_output_layer.cpp
CXX src/caffe/layers/softmax_layer.cpp
CXX src/caffe/layers/flatten_layer.cpp
CXX src/caffe/layers/rnn_layer.cpp
CXX src/caffe/layers/exp_layer.cpp
CXX src/caffe/layers/lstm_layer.cpp
CXX src/caffe/layers/cudnn_relu_layer.cpp
CXX src/caffe/layers/deconv_layer.cpp
CXX src/caffe/common.cpp
CXX src/caffe/data_transformer.cpp
CXX src/caffe/net.cpp
NVCC src/caffe/util/math_functions.cu
NVCC src/caffe/util/im2col.cu
NVCC src/caffe/solvers/adagrad_solver.cu
NVCC src/caffe/solvers/sgd_solver.cu
NVCC src/caffe/solvers/adam_solver.cu
NVCC src/caffe/solvers/adadelta_solver.cu
NVCC src/caffe/solvers/nesterov_solver.cu
NVCC src/caffe/solvers/rmsprop_solver.cu
NVCC src/caffe/layers/accuracy_layer.cu
NVCC src/caffe/layers/batch_norm_layer.cu
NVCC src/caffe/layers/softmax_layer.cu
NVCC src/caffe/layers/im2col_layer.cu
NVCC src/caffe/layers/softmax_loss_layer.cu
NVCC src/caffe/layers/base_data_layer.cu
NVCC src/caffe/layers/sigmoid_cross_entropy_loss_layer.cu
NVCC src/caffe/layers/threshold_layer.cu
NVCC src/caffe/layers/log_layer.cu
NVCC src/caffe/layers/cudnn_lcn_layer.cu
NVCC src/caffe/layers/hdf5_data_layer.cu
NVCC src/caffe/layers/crop_layer.cu
NVCC src/caffe/layers/relu_layer.cu
NVCC src/caffe/layers/slice_layer.cu
NVCC src/caffe/layers/lrn_layer.cu
NVCC src/caffe/layers/batch_reindex_layer.cu
NVCC src/caffe/layers/hdf5_output_layer.cu
NVCC src/caffe/layers/elu_layer.cu
NVCC src/caffe/layers/mvn_layer.cu
NVCC src/caffe/layers/lstm_unit_layer.cu
NVCC src/caffe/layers/tanh_layer.cu
NVCC src/caffe/layers/tile_layer.cu
NVCC src/caffe/layers/dropout_layer.cu
NVCC src/caffe/layers/filter_layer.cu
NVCC src/caffe/layers/cudnn_sigmoid_layer.cu
NVCC src/caffe/layers/absval_layer.cu
NVCC src/caffe/layers/bias_layer.cu
NVCC src/caffe/layers/sigmoid_layer.cu
NVCC src/caffe/layers/pooling_layer.cu
NVCC src/caffe/layers/concat_layer.cu
NVCC src/caffe/layers/cudnn_pooling_layer.cu
NVCC src/caffe/layers/power_layer.cu
NVCC src/caffe/layers/exp_layer.cu
NVCC src/caffe/layers/split_layer.cu
NVCC src/caffe/layers/eltwise_layer.cu
NVCC src/caffe/layers/cudnn_softmax_layer.cu
NVCC src/caffe/layers/deconv_layer.cu
NVCC src/caffe/layers/bnll_layer.cu
NVCC src/caffe/layers/reduction_layer.cu
NVCC src/caffe/layers/cudnn_lrn_layer.cu
NVCC src/caffe/layers/scale_layer.cu
NVCC src/caffe/layers/cudnn_relu_layer.cu
NVCC src/caffe/layers/recurrent_layer.cu
NVCC src/caffe/layers/cudnn_tanh_layer.cu
NVCC src/caffe/layers/euclidean_loss_layer.cu
NVCC src/caffe/layers/inner_product_layer.cu
NVCC src/caffe/layers/embed_layer.cu
NVCC src/caffe/layers/prelu_layer.cu
NVCC src/caffe/layers/conv_layer.cu
NVCC src/caffe/layers/silence_layer.cu
NVCC src/caffe/layers/contrastive_loss_layer.cu
NVCC src/caffe/layers/cudnn_conv_layer.cu
CXX tools/upgrade_net_proto_text.cpp
CXX tools/device_query.cpp
CXX tools/caffe.cpp
CXX tools/extract_features.cpp
CXX tools/compute_image_mean.cpp
CXX tools/test_net.cpp
CXX tools/train_net.cpp
CXX tools/convert_imageset.cpp
CXX tools/finetune_net.cpp
CXX tools/upgrade_solver_proto_text.cpp
CXX tools/net_speed_benchmark.cpp
CXX tools/upgrade_net_proto_binary.cpp
CXX examples/cifar10/convert_cifar_data.cpp
CXX examples/siamese/convert_mnist_siamese_data.cpp
CXX examples/cpp_classification/classification.cpp
CXX examples/mnist/convert_mnist_data.cpp
CXX .build_release/src/caffe/proto/caffe.pb.cc
AR -o .build_release/lib/libcaffe.a
LD -o .build_release/lib/libcaffe.so.1.0.0
/usr/bin/ld: cannot find -lopencv_core
collect2: error: ld returned 1 exit status
make: *** [.build_release/lib/libcaffe.so.1.0.0] Error 1
make: *** Waiting for unfinished jobs....
",,"['Please do not post usage, installation, or modeling questions, or other requests for help to Issues. Use the [caffe-users list][1] instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe. Please read the [guidelines for contributing][2] before submitting an issue or a pull request.\r\n\r\nThis is a common error by the way (not related to Caffe but to your linker) which has plenty of solutions readily available if you just look for it.\r\n\r\n [1]: https://groups.google.com/forum/#!forum/caffe-users\r\n [2]: https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md', ""Excuse me,do you solve this problem?I have a similar question like yours.\r\nAR -o .build_release/lib/libcaffe.a\r\nLD -o .build_release/lib/libcaffe.so.1.0.0\r\n/usr/bin/ld: cannot find -l_serial\r\n/usr/bin/ld: cannot find -lopencv_imgcodecs\r\ncollect2: error: ld returned 1 exit status\r\nMakefile:573: recipe for target '.build_release/lib/libcaffe.so.1.0.0' failed\r\nmake: *** [.build_release/lib/libcaffe.so.1.0.0] Error 1\r\n\r\nAnd I have already add opencv_imgcodecs in Makefile's LIBRARYS.\r\nI also install opencv by pip.But now I cannot find how to solve it."", '> Excuse me,do you solve this problem?I have a similar question like yours.\r\n> AR -o .build_release/lib/libcaffe.a\r\n> LD -o .build_release/lib/libcaffe.so.1.0.0\r\n> /usr/bin/ld: cannot find -l_serial\r\n> /usr/bin/ld: cannot find -lopencv_imgcodecs\r\n> collect2: error: ld returned 1 exit status\r\n> Makefile:573: recipe for target \'.build_release/lib/libcaffe.so.1.0.0\' failed\r\n> make: *** [.build_release/lib/libcaffe.so.1.0.0] Error 1\r\n> \r\n> And I have already add opencv_imgcodecs in Makefile\'s LIBRARYS.\r\n> I also install opencv by pip.But now I cannot find how to solve it.\r\n\r\nMay i know how you added the ""-lopencv_imgcodecs"" in the makefile.config']",[],[],0,0
269,caffe,1832,closed,how to debug caffe?,"I want to know how to debug caffe step by step. I can not find the main function
",,"['Hi,\n\nhave a look at ./tools/caffe.cpp, otherwise try using GDB, for example:\ngdb --args ../../install/tools/caffe train --solver=testNet_solver.prototxt\n', ""Reading symbols from /public/home/kli/caffe/.build_release/tools/caffe...(no debugging symbols found)...done.\nwhat's wrong?\n"", 'You have to compile caffe with debug symbols:\n\ncmake -DCMAKE_BUILD_TYPE=Debug\n\nThis is a general gcc/gdb question, you are probably better off having a look around stackoverflow and co for help on this kind of stuff.\n', 'Thank you very much, BIGene. I am not very familiar with linux\n', 'Wait, I messed up I updated my previous comment.\n\nOn Fri, Feb 6, 2015 at 1:18 AM, whjxnyzh notifications@github.com wrote:\n\n> Thank you very much, BIGene. I am not very familiar with linux\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/1832#issuecomment-73164353.\n', 'How to debug C++ in general is out of scope for this, but thanks @BlGene for pointing out that the debug mode of the build needs to be turned on. Please discuss Caffe-specific gdb questions on caffe-users.\n', '@whjxnyzh I have a [post](http://zhaok.xyz/blog/post/debug-caffe/) on this, hope it helps.']",[],[],0,0
270,caffe,3398,closed,Training error loss = NAN in multitask net,"Hi everyone,

I use caffe to train a multitask net which do both classification and regression.
My loss layers are:
layer {
  name: ""loss1""
  type: ""SoftmaxWithLoss""
  bottom: ""fc8_1""
  bottom: ""label1"" //size100 for classfication
  top: ""loss1""
  loss_weight: 2.0
}
layer {
  name: ""loss2""
  type: ""EuclideanLoss""
  bottom: ""fc8_2""
  bottom: ""label2"" //size4 for regression
  top: ""loss2""
}
I finetune it with Caffenet.caffemodel, and the solver.prototxt is:
net: ""/*****_/train_vol.prototxt""
test_iter: 100
test_interval: 1000
base_lr: 0.001
lr_policy: ""step""
gamma: 0.1
stepsize: 20000
display: 20
max_iter: 100000
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: ""**_*********""
solver_mode: GPU

The error is:
Iteration 20, loss = nan
Train net output #0: loss1 = 2.58978 (\* 4 = 10.3591 loss)
Train net output #1: loss2 = nan (\* 1 = nan loss)
Only iteration 0 is without nan:
Iteration 0, loss = 14.9363
Train net output #0: loss1 = 3.10484 (\* 4 = 12.4193 loss)
Train net output #1: loss2 = 2.51693 (\* 1 = 2.51693 loss)
The other iterations are always with nan loss.
I follow https://github.com/BVLC/caffe/issues/409,but it is not helpful for me.
When I set base_lr to 0, nan is gone, but even base_lr is small as 0.0001 there is nan again.

Any advice will be appreciated!
Thanks!
artiit.
",,"['@artiit Hi, I meet the same problem as you, multitask CNN training error loss = nan. How did you solve the problem? can you give me some advice? Thanks a lot.\n', 'I met the same problem, but I solved it by reducing the learning rate from 1e-003 to 1e-007 or below. At the time more iterations were required (>200000) for the convergence of the model.\n', ""Hi,@xyxxyx. Just like @rkakamilan did, the best way is to reduce your learning rate and have a little patience. If it still doesn't work or the learning result is too bad, you should considerate whether your model is correct, and start with a simple net.\n""]",[],[],0,0
271,caffe,3489,closed,Has to re-make after every reboot?,"Hi All,

I am using Caffe with GPU (NVIDIA GTX 590) support. I have installed the NVIDIA Driver 352 (comes with Cuda 7.5 runfile) with no open gl libs and Caffe is working fine.

However, every time I start a new Caffe session after turning my computer on I get the following error ,

WARNING: Logging before InitGoogleLogging() is written to STDERR
E1219 10:42:22.132685 23546 common.cpp:104] Cannot create Cublas handle. Cublas won't be available.
E1219 10:42:22.159312 23546 common.cpp:111] Cannot create Curand generator. Curand won't be available.
F1219 10:42:22.176038 23546 common.cpp:142] Check failed: error == cudaSuccess (30 vs. 0)  unknown error

and have to re-make caffe every time. Do you know a permanent solution for this? It would be of great help... Thanks in advance.
",,"['I believe this question belongs to the Caffe users list.\nAnyway, try `nvidia-modprobe -u -c=0` before starting Caffe.\n', 'It looks like this is a systems issue. From https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> Please do not post usage, installation, or modeling questions, or other requests for help to Issues.\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
272,caffe,1029,closed,Feature extraction problem using python interface,"Hi, I have a puzzle. I used the python interface of the latest release caffe, the features of different images are almostly same.  When I employ the former ""io.py"" instead of this new one, the features seem  
to be Ok. So, could you tell me reason about it?
",downstream problem?,"['Can you close this ticket?\nAll questions about usage, installation, code, and applications should be searched for and asked on the [caffe-users mailing list](https://groups.google.com/forum/#!forum/caffe-users).\n', 'Closing for usage discussion on the [caffe-users mailing list](https://groups.google.com/forum/#!forum/caffe-users) instead.\n\nNote that the Python preprocessing options changed in the last release. Refer to the latest examples for correct usage.\n']",[],[],0,0
273,caffe,3938,closed,Caffe matlab wrapper giving me random outputs for the same input ,"I trained a CNN. I used matcaffe to test it. My code is

data = ones(net.blobs('data').shape);
net.blobs('data').set_data(data);
net.forward_prefilled();
prob = net.blobs('prob').get_data()

the results I am getting is (2 class classification),

0.0001    0.9999    0.0001    0.0000    0.9882  
0.9999    0.0001    0.9999    1.0000    0.0118  

Why I am getting different results for the same input?
",,['Sorry I had some problems with the prototxt file. It contains learning rates. It works fine after commenting the lines contain learning related parameters.\n'],[],[],0,0
274,caffe,4526,closed,fe rnn lstm,,,"['Was this issue a mistake?\n', 'yes. \n']",[],[],0,0
275,caffe,1405,closed,"In manual testing on CIFAR-10 example, prediction error of test set was 90.88%. What happened?","Hi folks.

I followed [this CIFAR-10 tutorial](http://caffe.berkeleyvision.org/gathered/examples/cifar10.html) and got trained model .

In this training, caffe output accuracy on test data set was 



However, once I tried to predict test data set on ipython,  error rate was extremely high (that was 90.88 percent).  My python notebook which I used on this experiment is [here](http://nbviewer.ipython.org/github/everpeace/caffe/blob/master/examples/cifar10_test_error_is_high.ipynb).

I'm not sure what went wrong.  I'm really appreciated if someone gave me help.
",,"[""I didn't subtract mean values of trained data set from test data set.\n\nBelow comment on another issue saved me:\nhttps://github.com/BVLC/caffe/issues/1391#issuecomment-61447715\n\nThanks.\n""]","['\n(git:master) $ tail train_log.txt\nI1105 00:57:46.100651 2106102528 solver.cpp:206]     Train net output #0: loss = 0.482015 (* 1 = 0.482015 loss)\nI1105 00:57:46.100685 2106102528 solver.cpp:403] Iteration 4900, lr = 0.0001\nI1105 00:58:09.639089 2106102528 solver.cpp:317] Snapshotting to examples/cifar10/cifar10_quick_iter_5000.caffemodel\nI1105 00:58:09.645743 2106102528 solver.cpp:324] Snapshotting solver state to examples/cifar10/cifar10_quick_iter_5000.solverstate\nI1105 00:58:09.727504 2106102528 solver.cpp:228] Iteration 5000, loss = 0.565611\nI1105 00:58:09.727572 2106102528 solver.cpp:247] Iteration 5000, Testing net (#0)\nI1105 00:58:16.502969 2106102528 solver.cpp:298]     Test net output #0: accuracy = 0.7491\nI1105 00:58:16.503042 2106102528 solver.cpp:298]     Test net output #1: loss = 0.74817 (* 1 = 0.74817 loss)\nI1105 00:58:16.503067 2106102528 solver.cpp:233] Optimization Done.\nI1105 00:58:16.503078 2106102528 caffe.cpp:121] Optimization Done.\n']",['cifar10_quick_iter_5000.caffemodel'],0,0
276,caffe,4659,closed,caffe-windows   python problem,"win7 install Anaconda2 64 bit,
I compile caffe branch:windows, support python, 
set environment variable PythonPath is f:\caffe-window\Build\x64\Release\pycaffe\,

open Anaconda prompt, 
<d:\Anaconda2 C:\Users\lx> python

> > > import caffe 
> > >  but long time no response,
> > > what's problem?
",,['Closing for lack of detail.'],[],[],0,0
277,caffe,3283,closed,protoc no such file or directory,"Dear developer, 
I get the following error when writing (sudo) make all on MAC OS X
Password:
PROTOC src/caffe/proto/caffe.proto
make: protoc: No such file or directory
make: **\* [.build_release/src/caffe/proto/caffe.pb.cc] Error 1

i find it odd as I clearly see that the file is there..
",,"['Can you make sure all dependencies is installed ? All is linked ? Path is setted ?\n', ""Closing as this looks like an issue with protobuf installation; you're welcome to try caffe-users.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n\nAlso, _please do not build as root_!\n""]",[],[],0,0
278,caffe,4834,closed,Running Caffe on Titan x Pascal - Windows,"Hi,
I have been trying to compile Caffe on Windows with the new GPU Titan X Pascal. I have managed to make it compile by using Cuda 7.5, cuDNN 4, Visual studio 2013 and with Python and Matlab support. However, when I try to train a model, I keep getting the following error:

F1012 08:24:58.364405  6516 math_functions.cu:375] Check failed: status == CURAND_STATUS_SUCCESS (201 vs. 0)  CURAND_STATUS_LAUNCH_FAILURE

I tried the following and also got the same error:
1- I tried disabling cuDNN and then recompiled Caffe which was fine but when I tried to train a model, I got the same error.

2- I uninstalled Cuda, then installed installed Cuda 8.0, cuDNN 5.2. I managed to compile Caffe (with and without cuDNN) but again got the same error when I tried to train a model.

3- I tried to train the same model on a different PC which has Palit NVIDIA GTX TITAN X, Cuda 7.5, cuDNN 4, visual studio 2013, with Python support. Everything was fine and managed to train the same model and got reasonable accuracy on my problem.

4- I tried to train a model using MatConvNet using the Titan X Pascal and Cuda 8 and it worked fine.

If you have any suggestion, please advise. Thanks!

Regards,
",windows,"['@mkyaqub\n\n> 3- I tried to train the same model on a different PC which has Palit NVIDIA GTX TITAN X, Cuda 7.5, cuDNN 4, visual studio 2013, with Python support. Everything was fine and managed to train the same model and got reasonable accuracy on my problem.\n\nDid you rebuild caffe on this machine? If so, to me it looks like nvcc does not compile the cuda code with a compatible architecture. Please review the nvcc compiler flags to make sure that you generate PTX files with the correct architecture.\n\n> 2- I uninstalled Cuda, then installed installed Cuda 8.0, cuDNN 5.2. I managed to compile Caffe (with and without cuDNN) but again got the same error when I tried to train a model.\n\nWere you able to build the windows branch with CUDA 8, and cuDNN 5.2 without making any changes?\n', 'Thanks Willyd,\n\nCan you please elaborate on how to review  the nvcc compiler flags?\n\nYes, I managed to compile Caffe on Windows with Cuda 8.0. The steps are:\nInstall Cuda 8.0, disable cuDNN in the CommonSettings file (apologies I said I succeeded with cuDNN but I did not. I got confused with the many things I tried). Launch the caffe solution in VS2013 and compile. I tested by training an FCN model on the CPU and it was fine.\nHere are the two changes you need to do in the CommonSettings file\n\n```\n<UseCuDNN>false</UseCuDNN>\n        <CudaVersion>8.0</CudaVersion>\n```\n\nBTW, I realized that Titan X Pascal uses compute 6.1 architecture while the older GTX Titan X uses 5.2 architecture so I tried to change cuda architecture tag in the CommonSettings file to 6.1. Caffe compiled fine after a few iterations but I still got the same error.\nI changed this line \n\n```\n<CudaArchitecture>compute_35,sm_35;compute_52,sm_52</CudaArchitecture>\nto \n<CudaArchitecture>compute_61,sm_61</CudaArchitecture>\n```\n', '@mkyaqub \n\nCheck the CUDA C/C++ settings and look for NVCC Compilation Type. \n\nHere is what I think is happening:\n\nCUDA 7.5 does not know about compute_61,sm_61 s changing will either generate an error of fail silently. \n\nSo in order to run on a pascal GPU you need to either build with CUDA 8 or change the nvcc flags so that it generates PTX instead of obj.\n\nSo if you really change the CommonSettings to use CUDA 8 and added the correct 6.1 architecture I have no idea what is wrong here. \n\nCheck the Command Line section in the CUDA C/C++ to make sure what verison of nvcc is called.\n\nAlternatively, you may want to check my PR https://github.com/BVLC/caffe/pull/3990 and try the cmake build instead.\n', 'Thanks willyd,\n\nI was frustrated as I was not been able to resolve this. So I stopped experimenting any other solution and kept my Caffe windows configuration as Cuda 8, no cuDNN, Python and Matlab support. Today, for no obvious reason, I ran a Caffe training code on the GPU and it worked. I am totally surprised but happy. \n\nSorry I don\'t have a proper route to the solution but I can confirm that I managed (after many tries) to compile and run FCN training experiments using Caffe on Windows with Titan X Pascal GPU. Here is the list of packages I used: Caffe from the Window branch, MS visual studio 2013, Cuda 8.0, No cuDNN support, Python and Matlab support.  I had to change the following in the CommonSettings file:\n\n```\n<UseCuDNN>false</UseCuDNN>\n<CudaVersion>8.0</CudaVersion>\n<PythonSupport>True</PythonSupport>\n<MatlabSupport>True</MatlabSupport>\n<CudaArchitecture>compute_61,sm_61</CudaArchitecture> <!-- this is probably the most important thing-->\n\nPropertyGroup Condition=""\'$(PythonSupport)\'==\'true\'"">\n        <PythonDir>C:\\Anaconda2\\</PythonDir>\n        <LibraryPath>$(PythonDir)\\libs;$(LibraryPath)</LibraryPath>\n        <IncludePath>$(PythonDir)\\include;$(IncludePath)</IncludePath>\n    </PropertyGroup>\n\n    <PropertyGroup Condition=""\'$(MatlabSupport)\'==\'true\'"">\n        <MatlabDir>C:\\Program Files\\MATLAB\\R2015b</MatlabDir>\n        <LibraryPath>$(MatlabDir)\\extern\\lib\\win64\\microsoft;$(LibraryPath)</LibraryPath>\n        <IncludePath>$(MatlabDir)\\extern\\include;$(IncludePath)</IncludePath>\n    </PropertyGroup>\n```\n\nI hope this helps\n', 'I had  the same error when i run faster CNN+WIN10+MATLAB2015+CUDA 8.0 GPU  GTX1080.\r\nThe solution was:\r\nhttps://github.com/ShaoqingRen/caffe/tree/faster-R-CNN', 'Closing because the VS build is now deprecated.']",[],[],0,0
279,caffe,1622,closed,cuDNN R2 is available,"CuDNN RC 2 is available for download. https://developer.nvidia.com/cuDNN
They say, it is 40% faster than original cuDNN. However, it breaks a compatibility with caffe-wrappers (more general ways to pass n-d tensors, additional coefficients, etc.) Does anyone know, NVIDIA guys going to support caffe in future, or rewriting cudnn-layers are up to us?
",,"['Failed compilation with R2.\n\na piece from Theano:\nhttps://github.com/Theano/Theano/blob/master/theano/sandbox/cuda/cudnn_helper.h\nhttps://github.com/Theano/Theano/commit/66f946d43652196dfb5580f4f3f3a3bbd7ff9bf7\n', 'While cuDNN R2 has a different interface, the change is quite slight and we will support it soon by a few changes to [include/caffe/util/cudnn.hpp](https://github.com/BVLC/caffe/blob/master/include/caffe/util/cudnn.hpp).\n\nWhile cuDNN R2 is still a release candidate R1 will likely stay the default.\n', 'Maybe you can make a temporary branch for RC2?\n', 'See #1731 for an in-progress cuDNN R2 branch.\n\nThe Caffe crew collaborates with the cuDNN team on roadmap planning and interface design but at the moment the Caffe coding happens at Berkeley and in the open source community.\n', 'Covered by #1731 / #1739 thanks to Simon Layton at NVIDIA.\n']",[],[],0,0
280,caffe,591,closed,"import pycaffe in local Mac OS 10.9 reports ""segmentation fault: 11""","I'm debuging on my local macbook. Before I tried to use the python lib ""pycaffe"" everything works well. 
While when I turn to attempt to write some python scripts relying on the ""_caffe.so"", the following error turns out:

python
import _caffe

Segmentation fault: 11

This should be some problems in compiling the python lib.

Thanks. 
",downstream problem?,"['I had the same error.  You are probably compiling caffe with the default version of python on your mac (2.6) and are now trying to import caffe via python 2.7.  Try upgrading and make sure that boost python is using 2.7.  That fixed it for me. \n', '@nicodjimenez is right.\n\nYou need to install Python 2.7 and our Python dependencies, for which Anaconda is a good choice, then build boost python and pycaffe with it **and not the system Python**.\n', 'I had the same error.\nI can compile Caffe and ""make runtest"" generated no errors.\nBut ""import caffe"" generate segmentation fault unfortunately.\n\nI installed Python by using brew.\nOSX 10.10.2\nPython 2.7.9\nBut since I set ""cpu-only"", I didn\'t changed fomuras to ""-stdlib=libstdc++"".\n\nI tried to install Caffe many times.\nAny help is appreciated. \n', 'I\'m getting the same issue: ""make runtest"" is fine but ""import caffe"" in a python prompt results in ""Segmentation fault: 11"".  Have tried to re-download and reinstall all components several times... please let me know what else I can share to be helpful?  Any help is greatly appreciated.\n\nMacbook Air, OSX 10.10.2, Homebrew and system-wide python are both 2.7.9 (system python symlinks to Homebrew python).  Boost does appear as one of the last calls in the stack per the crash report.\n', 'Same issue with OSX 10.9.4, Python 2.7, libc++, CUDA 7, libs via macports.  Built with cmake.  \n', 'Finally fixed it (painfuly).  Problem (as has been indicated in a few other forum posts) was different versions of python: I had Python 2.7.9 (installed via homebrew in /usr/local/Cellar/python) which was newer than the system\'s python... and the system python\'s libraries (found in /System/Library/Frameworks) would ""sneak in"" during the linking stage and ultimately cause segfaults.\n\nThis is probably not the right way to fix it, but in hope of being helpful my work-around was:\n1) Rename the system python libraries to something else so they wouldn\'t be found by ld.  (""sudo mv /System/Library/Frameworks/Python.framework /System/Library/Frameworks/Python.framework_bak"") \n\n2) Explicitly add the correct library path in caffe\'s Makefile.config (e.g., ""PYTHON_LIB := /usr/local/lib /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib"").  \n\nIf you\'re not sure where your up-to-date python library is then in a shell run ""locate updatedb; locate libpythonX.X"" where X.X is your version of python... use the directory in the output that contains the .dylib and .a files referring to your preferred installation of Python.  \n\nIf you\'re wondering if you suffer from the same problem I did, I was tipped of by a line in OSX\'s problem report that indicated an old version of python sneaking in.  Under the ""Binary Images"" section there was a line that read, ""0x108c69000 -        0x108d5aff7  org.python.python (2.7.6 - 2.7.6) <A5C1B694-31A0-3966-B6BC-C40694DC707F> /System/Library/Frameworks/Python.framework/Versions/2.7/Python)""   ...indicating that the system version of python was being referenced.\n', 'I\'m facing similar issues for quite sometime now and still have not been able to solve it. Any solutions to this problem would really be appreciated. I\'ve tried out most of the solutions posted on various forums across the internet. \n\nSystem:\n\n```\nMacBook Pro\nMAC OSX 10.10.3\nInstalled with CPU_ONLY:=1\n```\n\nSoln-1:\n\n```\nGenerally, setting the PYTHONPATH is what most people forget and land in trouble. My PYTHONPATH variable looks like this.\nexport PYTHONPATH=""<Caffe-Home>/caffe/python:$PYTHONPATH""\n\nError : \nThe python command (on using \'import caffe\') prompt freezes for a few seconds and returns with a ""segmentation fault: 11"" error message with the complete log as pasted below (at the bottom).\n```\n\nSoln-2:\n\n```\nI\'ve also tried the distribute version.\nexport PYTHONPATH=""<Caffe-home>/caffe/distribute/python:$PYTHONPATH""\n\nError : (on the python-command-prompt after using \'import caffe\')\nIt is unable to find the _caffe.so file in the caffe directory however I have manually checked that this file is present in the directory.\n\nTraceback (most recent call last):\n  File ""<stdin>"", line 1, in <module>\n  File ""/Users/Home/research/virginia/CloudCV/caffe/distribute/python/caffe/__init__.py"", line 1, in <module>\n    from .pycaffe import Net, SGDSolver\n  File ""/Users/Home/research/virginia/CloudCV/caffe/distribute/python/caffe/pycaffe.py"", line 13, in <module>\n    from ._caffe import Net, SGDSolver\nImportError: dlopen(/Users/Home/research/virginia/CloudCV/caffe/distribute/python/caffe/_caffe.so, 2): Library not loaded: @rpath/libcaffe.so\n  Referenced from: /Users/Home/research/virginia/CloudCV/caffe/distribute/python/caffe/_caffe.so\n  Reason: image not found\n```\n\n@gp335 : I might not be on the same issue as yours as I don\'t see any ""/System/Library/Frameworks/Python.framework/Versions/2.7/Python"" calls being made in my error-log. To be precise, here it is....\n(error-log on using /caffe/python in PYTHONPATH)\n\n```\nProcess:               Python [761]\nPath:                  /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python\nIdentifier:            Python\nVersion:               2.7.9 (2.7.9)\nCode Type:             X86-64 (Native)\nParent Process:        bash [710]\nResponsible:           iTerm [635]\nUser ID:               501\n\nDate/Time:             2015-05-28 00:28:36.361 +0530\nOS Version:            Mac OS X 10.10.3 (14D136)\nReport Version:        11\nAnonymous UUID:        4D1E2216-6A20-E2AC-00A1-758B0B4AF821\n\nSleep/Wake UUID:       5F600EBD-9CB0-4BD5-A304-C45F57351EEE\n\nTime Awake Since Boot: 18000 seconds\nTime Since Wake:       6800 seconds\n\nCrashed Thread:        0  Dispatch queue: com.apple.main-thread\n\nException Type:        EXC_BAD_ACCESS (SIGSEGV)\nException Codes:       KERN_INVALID_ADDRESS at 0x0000000000000000\n\nVM Regions Near 0:\n--> \n    __TEXT                 0000000106592000-0000000106594000 [    8K] r-x/rwx SM=COW  /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python\n\nThread 0 Crashed:: Dispatch queue: com.apple.main-thread\n0   ???                             000000000000000000 0 + 0\n1   org.python.python               0x00000001080770dd PyEval_GetGlobals + 23\n2   org.python.python               0x000000010808662b PyImport_Import + 137\n3   org.python.python               0x0000000108084d27 PyImport_ImportModule + 31\n4   _caffe.so                       0x00000001072edcf8 caffe::init_module__caffe() + 4328\n5   libboost_python.dylib           0x0000000107f98391 boost::python::handle_exception_impl(boost::function0<void>) + 81\n6   libboost_python.dylib           0x0000000107f993b9 boost::python::detail::init_module(char const*, void (*)()) + 121\n7   org.python.python               0x00000001066332cf _PyImport_LoadDynamicModule + 140\n8   org.python.python               0x0000000106632fb7 import_submodule + 270\n9   org.python.python               0x0000000106632b81 load_next + 280\n10  org.python.python               0x0000000106630d89 PyImport_ImportModuleLevel + 1135\n11  org.python.python               0x00000001066163db builtin___import__ + 135\n12  org.python.python               0x00000001065a10ea PyObject_Call + 99\n13  org.python.python               0x0000000106620d8b PyEval_CallObjectWithKeywords + 93\n14  org.python.python               0x000000010661d065 PyEval_EvalFrameEx + 8375\n15  org.python.python               0x000000010661ad7a PyEval_EvalCodeEx + 1409\n16  org.python.python               0x000000010661a7f3 PyEval_EvalCode + 54\n17  org.python.python               0x000000010662f836 PyImport_ExecCodeModuleEx + 241\n18  org.python.python               0x0000000106632516 load_source_module + 1091\n19  org.python.python               0x0000000106632fb7 import_submodule + 270\n20  org.python.python               0x0000000106632b81 load_next + 280\n21  org.python.python               0x0000000106630d89 PyImport_ImportModuleLevel + 1135\n22  org.python.python               0x00000001066163db builtin___import__ + 135\n23  org.python.python               0x00000001065a10ea PyObject_Call + 99\n24  org.python.python               0x0000000106620d8b PyEval_CallObjectWithKeywords + 93\n25  org.python.python               0x000000010661d065 PyEval_EvalFrameEx + 8375\n26  org.python.python               0x000000010661ad7a PyEval_EvalCodeEx + 1409\n27  org.python.python               0x000000010661a7f3 PyEval_EvalCode + 54\n28  org.python.python               0x000000010662f836 PyImport_ExecCodeModuleEx + 241\n29  org.python.python               0x0000000106632516 load_source_module + 1091\n30  org.python.python               0x00000001066327d7 load_package + 303\n31  org.python.python               0x0000000106632fb7 import_submodule + 270\n32  org.python.python               0x0000000106632b81 load_next + 280\n33  org.python.python               0x0000000106630d89 PyImport_ImportModuleLevel + 1135\n34  org.python.python               0x00000001066163db builtin___import__ + 135\n35  org.python.python               0x00000001065a10ea PyObject_Call + 99\n36  org.python.python               0x0000000106620d8b PyEval_CallObjectWithKeywords + 93\n37  org.python.python               0x000000010661d065 PyEval_EvalFrameEx + 8375\n38  org.python.python               0x000000010661ad7a PyEval_EvalCodeEx + 1409\n39  org.python.python               0x000000010661a7f3 PyEval_EvalCode + 54\n40  org.python.python               0x000000010663a8a2 run_mod + 53\n41  org.python.python               0x000000010663a6be PyRun_InteractiveOneFlags + 353\n42  org.python.python               0x000000010663a1cd PyRun_InteractiveLoopFlags + 192\n43  org.python.python               0x000000010663a077 PyRun_AnyFileExFlags + 60\n44  org.python.python               0x000000010664bc5b Py_Main + 3051\n45  libdyld.dylib                   0x00007fff98d525c9 start + 1\n\nThread 0 crashed with X86 Thread State (64-bit):\n  rax: 0x00000001081252d8  rbx: 0x0000000108406030  rcx: 0x0800bf453c5d2274  rdx: 0x0000000108409050\n  rdi: 0x0000000000000000  rsi: 0x00000001080b90d7  rbp: 0x00007fff5966c050  rsp: 0x00007fff5966c048\n   r8: 0x2000000000000200   r9: 0x0800000000000100  r10: 0x0000000004001049  r11: 0x000000000034dfe4\n  r12: 0x0000000108406030  r13: 0x0000000000000000  r14: 0x0000000000000000  r15: 0x0000000000000000\n  rip: 0x0000000000000000  rfl: 0x0000000000010206  cr2: 0x0000000000000000\n\nLogical CPU:     2\nError Code:      0x00000014\nTrap Number:     14\n\n\nBinary Images:\n       0x106592000 -        0x106593fff +org.python.python (2.7.9 - 2.7.9) <E6A2C746-0CEF-3357-A494-E4951EAF0BA4> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python\n       0x106596000 -        0x106688fff +org.python.python (2.7.9, [c] 2004-2014 Python Software Foundation. - 2.7.9) <37AA20B5-E884-30ED-B70C-34B482099B56> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/Python\n       0x10686a000 -        0x10686cfff +_locale.so (0) <29EFF01B-811A-3630-A6D8-0143809C5048> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_locale.so\n       0x1068ef000 -        0x1068f1fff +readline.so (0) <C5B909D2-8A99-386A-9213-1A90D3563E4F> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/readline.so\n       0x1068f7000 -        0x106917ff7 +libreadline.6.dylib (0) <254C680B-35F9-31BF-9C3B-D7A2768A4E67> /usr/local/opt/readline/lib/libreadline.6.dylib\n       0x10692e000 -        0x106931fff +_collections.so (0) <9A34391A-4CDF-31A6-B364-15E13AA9A89F> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_collections.so\n       0x106936000 -        0x106939fff +operator.so (0) <30570608-5F04-37E9-A637-0DD32B5158C5> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/operator.so\n       0x10693f000 -        0x106944fff +itertools.so (0) <C319423F-0D83-3EB3-8518-0D9C4A24D4E4> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/itertools.so\n       0x10694d000 -        0x10694efff +_heapq.so (0) <79FF4316-7429-3CCC-B264-277305FBB159> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_heapq.so\n       0x106992000 -        0x106995ff7 +math.so (0) <DEF5D1EF-0A78-35A3-8F83-8F382A844AE7> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/math.so\n       0x10699a000 -        0x106a7bfff +multiarray.so (0) <727FB529-9121-3F11-AAC3-9601460BEF51> /usr/local/lib/python2.7/site-packages/numpy/core/multiarray.so\n       0x106ad2000 -        0x106adcfff +datetime.so (0) <73C3B2A8-8E38-3BC1-A674-CD4338A4A0BB> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/datetime.so\n       0x106ae5000 -        0x106b2dfff +umath.so (0) <2DDAADD1-952E-3FF7-AA00-D8A27E056451> /usr/local/lib/python2.7/site-packages/numpy/core/umath.so\n       0x106b83000 -        0x106b8efff +cPickle.so (0) <9FE3D79B-9D73-348E-82B8-E3B8DD88C81D> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/cPickle.so\n       0x106bd4000 -        0x106bd5fff +cStringIO.so (0) <37DDE83B-BE50-3DF7-BB34-CD2593032A88> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/cStringIO.so\n       0x106bda000 -        0x106bdefff +_dotblas.so (0) <36AD9BFC-537B-33B1-95F3-A85F35F1255C> /usr/local/lib/python2.7/site-packages/numpy/core/_dotblas.so\n       0x106be2000 -        0x106be3fff +_functools.so (0) <EE5FF464-4B9D-3448-8435-957D5FAC1818> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_functools.so\n       0x106c26000 -        0x106c40fff +scalarmath.so (0) <4C2CE67C-EBF1-30F3-881E-B05153D59527> /usr/local/lib/python2.7/site-packages/numpy/core/scalarmath.so\n       0x106d49000 -        0x106d4afff +time.so (0) <3720B3AF-7F96-3635-8A4A-494CFA5E22D0> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/time.so\n       0x106d90000 -        0x106d91fff +grp.so (0) <9BBB7FFB-65C9-34D1-B153-B34378B8A6F5> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/grp.so\n       0x106d94000 -        0x106da3fff +_io.so (0) <B4FE2132-E171-3DAB-9750-A128F8DE3D31> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_io.so\n       0x106db4000 -        0x106db7fff +binascii.so (0) <F82DEDCB-9A28-39DE-A8F0-C1DEFD84D503> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/binascii.so\n       0x106dfa000 -        0x106dfcfff +_hashlib.so (0) <77B4105A-BB03-3C8D-A71E-78652E0A984A> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_hashlib.so\n       0x106e00000 -        0x106e3dfff +libssl.1.0.0.dylib (0) <2E0DC1A7-B1BD-3DA2-9AB6-8CF00E12E51F> /usr/local/opt/openssl/lib/libssl.1.0.0.dylib\n       0x106e59000 -        0x106fc948f +libcrypto.1.0.0.dylib (0) <3036BB5F-CF7A-326D-A14C-2F8A87BBC716> /usr/local/opt/openssl/lib/libcrypto.1.0.0.dylib\n       0x107040000 -        0x107041ff7 +_random.so (0) <48AC06E5-E5A3-30AF-891A-C777DF4DF351> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_random.so\n       0x107044000 -        0x107045fff +fcntl.so (0) <0E5E4BF0-D961-38E8-A3D3-173D241C2D25> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/fcntl.so\n       0x107048000 -        0x10704cff7 +_compiled_base.so (0) <BBDB89E9-4F8F-3A3C-8CB8-48CCBF60BDCE> /usr/local/lib/python2.7/site-packages/numpy/lib/_compiled_base.so\n       0x10708f000 -        0x107091fff +lapack_lite.so (0) <A96DC7D9-0041-310E-9255-628A367F649D> /usr/local/lib/python2.7/site-packages/numpy/linalg/lapack_lite.so\n       0x107094000 -        0x1070a3ff7 +_umath_linalg.so (0) <26511FDB-C752-3FBB-B99F-EC7C5B204721> /usr/local/lib/python2.7/site-packages/numpy/linalg/_umath_linalg.so\n       0x1070ea000 -        0x1070eafff +future_builtins.so (0) <6316F416-66B1-3FD1-8D5F-CD4304FD6F4B> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/future_builtins.so\n       0x1070ed000 -        0x1070f4ff7 +fftpack_lite.so (0) <4AC2C802-A00E-33AE-8D0E-3BD0D21AA135> /usr/local/lib/python2.7/site-packages/numpy/fft/fftpack_lite.so\n       0x107137000 -        0x107189ff7 +mtrand.so (0) <28B39BF0-3067-344D-97E7-AFBA28328DCE> /usr/local/lib/python2.7/site-packages/numpy/random/mtrand.so\n       0x107211000 -        0x107220fff +_ctypes.so (0) <6F57E1D8-279C-3F55-B5E1-E0469D0DA41E> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_ctypes.so\n       0x10722b000 -        0x10722efff +_struct.so (0) <1D851534-7819-38F1-8E17-295A89A317D4> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload/_struct.so\n       0x1072ea000 -        0x107343fff +_caffe.so (0) <85CE7193-FB1F-3869-8FFA-45BA2646F679> /Users/USER/*/_caffe.so\n       0x107419000 -        0x107583fff +libcaffe.so (0) <86014A1D-70CF-3BD1-8CFF-04C64DB8D07B> /Users/USER/*/libcaffe.so\n       0x107676000 -        0x10769cff7 +libglog.0.dylib (0) <F761E8DA-978B-3A1A-A15C-414114292AE4> /usr/local/lib/libglog.0.dylib\n       0x1076c0000 -        0x107759ff7 +libprotobuf.9.dylib (0) <D5FDD8D1-CB08-3AF8-A421-AA9E853A7148> /usr/local/lib/libprotobuf.9.dylib\n       0x1077c7000 -        0x1077f4ff7 +libleveldb.1.dylib (0) <C691B11C-30C9-38DA-AE08-1C272705CB1E> /usr/local/lib/libleveldb.1.dylib\n       0x107811000 -        0x107814ff7 +libsnappy.1.dylib (0) <3F633F67-0FC4-3B38-8BDF-C5975334E105> /usr/local/lib/libsnappy.1.dylib\n       0x107818000 -        0x107826fff +liblmdb.dylib (0) <4BB994C0-00A5-3CB0-A104-DE2005EC2F0E> /usr/local/lib/liblmdb.dylib\n       0x10782b000 -        0x10782dff3 +libboost_system.dylib (0) <B027B810-4AD7-3352-8150-55D816859E63> /usr/local/lib/libboost_system.dylib\n       0x107832000 -        0x107847fff +libhdf5_hl.9.dylib (0) <498449E7-BBF3-3B83-95E3-758B180B0931> /usr/local/lib/libhdf5_hl.9.dylib\n       0x107850000 -        0x107a5bfff +libhdf5.9.dylib (0) <661DE0A3-6BEF-350A-8105-9FC16BAFDB3B> /usr/local/lib/libhdf5.9.dylib\n       0x107a95000 -        0x107c46ff7 +libopencv_core.2.4.dylib (0) <DD80EB68-6F3F-3E24-93AB-6BCBE0C8A9B3> /usr/local/lib/libopencv_core.2.4.dylib\n       0x107c9f000 -        0x107cc7fff +libopencv_highgui.2.4.dylib (0) <91065BBD-8AEB-369F-98C5-6EB5536B22D0> /usr/local/lib/libopencv_highgui.2.4.dylib\n       0x107cdf000 -        0x107e70fff +libopencv_imgproc.2.4.dylib (0) <0BEC7CF1-8F5B-37D4-8E2C-E02D7770F87C> /usr/local/lib/libopencv_imgproc.2.4.dylib\n       0x107f57000 -        0x107f65ffb +libboost_thread-mt.dylib (0) <C386440C-49D8-3CC7-8396-F060010C70B0> /usr/local/lib/libboost_thread-mt.dylib\n       0x107f7f000 -        0x107faeff7 +libboost_python.dylib (0) <C978168C-E87B-3A4E-A76C-1F7D07832B10> /usr/local/lib/libboost_python.dylib\n       0x107fed000 -        0x1080deff7  org.python.python (2.7.6 - 2.7.6) <A5C1B694-31A0-3966-B6BC-C40694DC707F> /System/Library/Frameworks/Python.framework/Versions/2.7/Python\n       0x108144000 -        0x10814dfff +libsz.2.dylib (0) <FA48FCCB-899B-3A96-8CBB-433EEC936498> /usr/local/lib/libsz.2.dylib\n       0x108158000 -        0x108184fff +libjpeg.8.dylib (0) <7A528846-854A-370E-AE9A-EEA0842EEC9C> /usr/local/lib/libjpeg.8.dylib\n       0x10818b000 -        0x1081aeff7 +libpng16.16.dylib (0) <78FA9D5B-C0BB-3B57-AA91-B092AE7A58FF> /usr/local/lib/libpng16.16.dylib\n       0x1081b7000 -        0x108210ff7 +libtiff.5.dylib (0) <0601B3BF-B13F-3400-A1B1-069E55830157> /usr/local/lib/libtiff.5.dylib\n       0x10821e000 -        0x108228ff7 +libImath-2_1.11.dylib (0) <73F59E8D-5025-3893-A7B2-105EF546922A> /usr/local/lib/libImath-2_1.11.dylib\n       0x10822d000 -        0x108319fff +libIlmImf-Imf_2_1.21.dylib (0) <059643D9-3318-3E9A-A1FA-0604015140B2> /usr/local/lib/libIlmImf-Imf_2_1.21.dylib\n       0x10836c000 -        0x108371ff7 +libIex-2_1.11.dylib (0) <AA6DD4DC-17A8-3827-8FEF-DEF14C1B215D> /usr/local/lib/libIex-2_1.11.dylib\n       0x10837f000 -        0x1083c0ff7 +libHalf.11.dylib (0) <EAB5D6BB-536E-39F5-9447-11B9E43678A0> /usr/local/lib/libHalf.11.dylib\n       0x1083c3000 -        0x1083c6fff +libIlmThread-2_1.11.dylib (0) <DC634F1B-DBD1-3519-9A13-FB9BC2F810D7> /usr/local/lib/libIlmThread-2_1.11.dylib\n       0x1083cb000 -        0x1083ccfff +libIexMath-2_1.11.dylib (0) <6A43F010-DDC5-3FE1-8B43-5AE2B59FEA9C> /usr/local/lib/libIexMath-2_1.11.dylib\n       0x1083cf000 -        0x1083d1ff3 +libboost_system-mt.dylib (0) <1F805F25-9640-3288-AEC9-23884EDCF5B4> /usr/local/lib/libboost_system-mt.dylib\n    0x7fff68f40000 -     0x7fff68f76837  dyld (353.2.1) <65DCCB06-339C-3E25-9702-600A28291D0E> /usr/lib/dyld\n    0x7fff8ac2f000 -     0x7fff8acc4ff7  com.apple.ColorSync (4.9.0 - 4.9.0) <9150C2B7-2E6E-3509-96EA-7B3F959F049E> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ColorSync.framework/Versions/A/ColorSync\n    0x7fff8adbd000 -     0x7fff8ade1ff7  com.apple.Sharing (328.16 - 328.16) <F96C7040-5FAF-3BC6-AE1E-5BF9CBE786C4> /System/Library/PrivateFrameworks/Sharing.framework/Versions/A/Sharing\n    0x7fff8ade2000 -     0x7fff8ade5fff  com.apple.help (1.3.3 - 46) <CA4541F4-CEF5-355C-8F1F-EA65DC1B400F> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Help.framework/Versions/A/Help\n    0x7fff8adea000 -     0x7fff8adf7ff7  libbz2.1.0.dylib (36) <2DF83FBC-5C08-39E1-94F5-C28653791B5F> /usr/lib/libbz2.1.0.dylib\n    0x7fff8adf8000 -     0x7fff8ae03fff  libcommonCrypto.dylib (60061) <D381EBC6-69D8-31D3-8084-5A80A32CB748> /usr/lib/system/libcommonCrypto.dylib\n    0x7fff8afb9000 -     0x7fff8afc8fff  com.apple.LangAnalysis (1.7.0 - 1.7.0) <D1E527E4-C561-352F-9457-E8C50232793C> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/LangAnalysis.framework/Versions/A/LangAnalysis\n    0x7fff8affc000 -     0x7fff8b027fff  libc++abi.dylib (125) <88A22A0F-87C6-3002-BFBA-AC0F2808B8B9> /usr/lib/libc++abi.dylib\n    0x7fff8b028000 -     0x7fff8b029fff  libDiagnosticMessagesClient.dylib (100) <2EE8E436-5CDC-34C5-9959-5BA218D507FB> /usr/lib/libDiagnosticMessagesClient.dylib\n    0x7fff8b085000 -     0x7fff8b09fff7  liblzma.5.dylib (7) <1D03E875-A7C0-3028-814C-3C27F7B7C079> /usr/lib/liblzma.5.dylib\n    0x7fff8b0a0000 -     0x7fff8b0a9ff7  libsystem_notify.dylib (133.1.1) <61147800-F320-3DAA-850C-BADF33855F29> /usr/lib/system/libsystem_notify.dylib\n    0x7fff8b0aa000 -     0x7fff8b104ff7  com.apple.LanguageModeling (1.0 - 1) <ACA93FE0-A0E3-333E-AE3C-8EB7DE5F362F> /System/Library/PrivateFrameworks/LanguageModeling.framework/Versions/A/LanguageModeling\n    0x7fff8b105000 -     0x7fff8b13efff  com.apple.AirPlaySupport (2.0 - 215.18) <6AF8E973-3643-3FEE-AA8F-541B9F093EEE> /System/Library/PrivateFrameworks/AirPlaySupport.framework/Versions/A/AirPlaySupport\n    0x7fff8b13f000 -     0x7fff8b24eff3  com.apple.desktopservices (1.9.3 - 1.9.3) <FEE11342-5BC4-37A7-8169-DA48BE17B9C9> /System/Library/PrivateFrameworks/DesktopServicesPriv.framework/Versions/A/DesktopServicesPriv\n    0x7fff8b25b000 -     0x7fff8b2a8ff3  com.apple.CoreMediaIO (601.0 - 4760) <B2B71300-A863-30F8-8F00-B852CF843264> /System/Library/Frameworks/CoreMediaIO.framework/Versions/A/CoreMediaIO\n    0x7fff8b2a9000 -     0x7fff8b2d9fff  libsystem_m.dylib (3086.1) <1E12AB45-6D96-36D0-A226-F24D9FB0D9D6> /usr/lib/system/libsystem_m.dylib\n    0x7fff8b2da000 -     0x7fff8b2dafff  com.apple.CoreServices (62 - 62) <C69DA8A7-B536-34BF-A93F-1C170E2C6D58> /System/Library/Frameworks/CoreServices.framework/Versions/A/CoreServices\n    0x7fff8b3b3000 -     0x7fff8b3b8fff  libsystem_stats.dylib (163.20.16) <FBC3F80F-A0FB-3BD6-9A7E-800DE45F092E> /usr/lib/system/libsystem_stats.dylib\n    0x7fff8b3c1000 -     0x7fff8b3cbff7  com.apple.NetAuth (5.2 - 5.2) <2BBD749A-8E18-35B8-8E48-A90347C1CCA7> /System/Library/PrivateFrameworks/NetAuth.framework/Versions/A/NetAuth\n    0x7fff8b3d2000 -     0x7fff8b4c4fff  libxml2.2.dylib (26) <B834E7C8-EC3E-3382-BC5A-DA38DC4D720C> /usr/lib/libxml2.2.dylib\n    0x7fff8b7d6000 -     0x7fff8b7fefff  libsystem_info.dylib (459.20.1) <AEB3FE62-4763-3050-8352-D6F9AF961AE6> /usr/lib/system/libsystem_info.dylib\n    0x7fff8b808000 -     0x7fff8b818ff7  libbsm.0.dylib (34) <A3A2E56C-2B65-37C7-B43A-A1F926E1A0BB> /usr/lib/libbsm.0.dylib\n    0x7fff8b83d000 -     0x7fff8b83dfff  com.apple.Cocoa (6.8 - 21) <EAC0EA1E-3C62-3B28-A941-5D8B1E085FF8> /System/Library/Frameworks/Cocoa.framework/Versions/A/Cocoa\n    0x7fff8b9dc000 -     0x7fff8bb6afff  libBLAS.dylib (1128) <497912C1-A98E-3281-BED7-E9C751552F61> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib\n    0x7fff8bb6b000 -     0x7fff8bb7cff7  libz.1.dylib (55) <88C7C7DE-04B8-316F-8B74-ACD9F3DE1AA1> /usr/lib/libz.1.dylib\n    0x7fff8bbe9000 -     0x7fff8bc6aff7  com.apple.CoreUtils (1.1 - 110.1) <C98E1441-3FCB-3BC6-BB51-5380BD39EA88> /System/Library/PrivateFrameworks/CoreUtils.framework/Versions/A/CoreUtils\n    0x7fff8bd8a000 -     0x7fff8bdd7ff7  com.apple.print.framework.PrintCore (10.3 - 451.1) <DE992474-0841-38A1-B4F6-46D653E454D5> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/PrintCore.framework/Versions/A/PrintCore\n    0x7fff8bdd8000 -     0x7fff8c057ff7  com.apple.CoreData (111 - 526.3) <5A27E0D8-5E5A-335B-B3F6-2601C7B976FA> /System/Library/Frameworks/CoreData.framework/Versions/A/CoreData\n    0x7fff8c058000 -     0x7fff8c060ff7  com.apple.AppleSRP (5.0 - 1) <01EC5144-D09A-3D6A-AE35-F6D48585F154> /System/Library/PrivateFrameworks/AppleSRP.framework/Versions/A/AppleSRP\n    0x7fff8c061000 -     0x7fff8c064fff  com.apple.IOSurface (97.4 - 97.4) <AE11CFBC-4D46-30F3-BEEC-4C8131079391> /System/Library/Frameworks/IOSurface.framework/Versions/A/IOSurface\n    0x7fff8c0f9000 -     0x7fff8c129fff  com.apple.GSS (4.0 - 2.0) <A37BAF76-C262-3292-B82D-F004CAC5F333> /System/Library/Frameworks/GSS.framework/Versions/A/GSS\n    0x7fff8c14f000 -     0x7fff8c1b6ffb  com.apple.datadetectorscore (6.0 - 396.1.1) <9B0B3198-DDBE-36C0-8BA9-3EC89C725282> /System/Library/PrivateFrameworks/DataDetectorsCore.framework/Versions/A/DataDetectorsCore\n    0x7fff8c212000 -     0x7fff8c212fff  com.apple.audio.units.AudioUnit (1.12 - 1.12) <E5335492-7EFE-31EA-BE72-4A9CEE68D58E> /System/Library/Frameworks/AudioUnit.framework/Versions/A/AudioUnit\n    0x7fff8c213000 -     0x7fff8c22dff3  com.apple.Ubiquity (1.3 - 313) <DF56A657-CC6E-3BE2-86A0-71F07127724C> /System/Library/PrivateFrameworks/Ubiquity.framework/Versions/A/Ubiquity\n    0x7fff8c967000 -     0x7fff8c9d9fff  com.apple.framework.IOKit (2.0.2 - 1050.20.2) <09C0518C-90DF-3FC3-96D6-34D35F72C8EF> /System/Library/Frameworks/IOKit.framework/Versions/A/IOKit\n    0x7fff8c9da000 -     0x7fff8cde7ff7  libLAPACK.dylib (1128) <F9201AE7-B031-36DB-BCF8-971E994EF7C1> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLAPACK.dylib\n    0x7fff8cf03000 -     0x7fff8d035ff7  com.apple.MediaControlSender (2.0 - 215.18) <86E901A7-64C3-3D2C-BBD4-E385405831D3> /System/Library/PrivateFrameworks/MediaControlSender.framework/Versions/A/MediaControlSender\n    0x7fff8d036000 -     0x7fff8d1e6ff3  com.apple.QuartzCore (1.10 - 361.18) <ACA61D8F-9535-3141-8FDD-AC3EF6BF0806> /System/Library/Frameworks/QuartzCore.framework/Versions/A/QuartzCore\n    0x7fff8d1e7000 -     0x7fff8d1edfff  libsystem_trace.dylib (72.20.1) <840F5301-B55A-3078-90B9-FEFFD6CD741A> /usr/lib/system/libsystem_trace.dylib\n    0x7fff8d1f7000 -     0x7fff8d211ff7  libextension.dylib (55.2) <3BB019CA-199A-36AC-AA22-14B562138545> /usr/lib/libextension.dylib\n    0x7fff8d27c000 -     0x7fff8d2ebfff  com.apple.SearchKit (1.4.0 - 1.4.0) <80883BD1-C9BA-3794-A20E-476F94DD89A9> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SearchKit.framework/Versions/A/SearchKit\n    0x7fff8d37a000 -     0x7fff8d395ff7  libCRFSuite.dylib (34) <D64842BE-7BD4-3D0C-9842-1D202F7C2A51> /usr/lib/libCRFSuite.dylib\n    0x7fff8d3b2000 -     0x7fff8d3b4ff7  com.apple.securityhi (9.0 - 55006) <5DB5773C-FC07-302C-98FE-4B80D88D481A> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/SecurityHI.framework/Versions/A/SecurityHI\n    0x7fff8d3b5000 -     0x7fff8d69cffb  com.apple.CoreServices.CarbonCore (1108.6 - 1108.6) <8953580E-7857-33B2-AA64-98296830D3A8> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/CarbonCore.framework/Versions/A/CarbonCore\n    0x7fff8d69d000 -     0x7fff8d6a8fff  libGL.dylib (11.1.2) <BF99CC65-215A-3C7D-87D7-3F7EE6E9B3DD> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGL.dylib\n    0x7fff8d6a9000 -     0x7fff8d6b5ff7  com.apple.OpenDirectory (10.10 - 187) <1E07769D-68DE-3BF2-8E9E-A1E98BF70D1B> /System/Library/Frameworks/OpenDirectory.framework/Versions/A/OpenDirectory\n    0x7fff8d733000 -     0x7fff8d7b1fff  com.apple.CoreServices.OSServices (640.4 - 640.4) <20121A5E-7AB5-3624-8CF0-3562F97C8A95> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/OSServices.framework/Versions/A/OSServices\n    0x7fff8d7b2000 -     0x7fff8d7b5fff  com.apple.xpc.ServiceManagement (1.0 - 1) <9E025823-660A-30C5-A568-223BD595B6F7> /System/Library/Frameworks/ServiceManagement.framework/Versions/A/ServiceManagement\n    0x7fff8d84d000 -     0x7fff8d84dfff  com.apple.Carbon (154 - 157) <9BF51672-1684-3FDE-A561-FC59A2864EF8> /System/Library/Frameworks/Carbon.framework/Versions/A/Carbon\n    0x7fff8db10000 -     0x7fff8db10ff7  libkeymgr.dylib (28) <77845842-DE70-3CC5-BD01-C3D14227CED5> /usr/lib/system/libkeymgr.dylib\n    0x7fff8e146000 -     0x7fff8e160fff  com.apple.AppleVPAFramework (1.4.3 - 1.4.3) <AE62A92E-EDA7-37AD-8AF0-7912E9381A1F> /System/Library/PrivateFrameworks/AppleVPA.framework/Versions/A/AppleVPA\n    0x7fff8e1d9000 -     0x7fff8e2cdfff  libFontParser.dylib (134.2) <9F57B025-AB9C-31DD-9D54-2D7AB1298885> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/Resources/libFontParser.dylib\n    0x7fff8e2ce000 -     0x7fff8e318ff7  com.apple.HIServices (1.22 - 522.1) <E8BD41E4-7747-3CAF-807A-5CA9AD16B525> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/HIServices.framework/Versions/A/HIServices\n    0x7fff8e371000 -     0x7fff8e375fff  libpam.2.dylib (20) <E805398D-9A92-31F8-8005-8DC188BD8B6E> /usr/lib/libpam.2.dylib\n    0x7fff8e37a000 -     0x7fff8e397fff  libsystem_kernel.dylib (2782.20.48) <EAFD7BD0-0C30-3E7D-9528-F9916BA0167C> /usr/lib/system/libsystem_kernel.dylib\n    0x7fff8e398000 -     0x7fff8e3deff7  libFontRegistry.dylib (134.1) <CE41D8C2-BEED-345C-BC4F-3775CC06C672> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/Resources/libFontRegistry.dylib\n    0x7fff8e40f000 -     0x7fff8e411fff  com.apple.loginsupport (1.0 - 1) <DAAD7013-A19D-3858-BFF7-DE1DAF664401> /System/Library/PrivateFrameworks/login.framework/Versions/A/Frameworks/loginsupport.framework/Versions/A/loginsupport\n    0x7fff8e46c000 -     0x7fff8e474fff  libsystem_dnssd.dylib (561.1.1) <62B70ECA-E40D-3C63-896E-7F00EC386DDB> /usr/lib/system/libsystem_dnssd.dylib\n    0x7fff8e48e000 -     0x7fff8e48efff  libOpenScriptingUtil.dylib (162.1) <E0605012-0DDB-3150-8FD0-699376FA3CD0> /usr/lib/libOpenScriptingUtil.dylib\n    0x7fff8e48f000 -     0x7fff8e6f9ff7  com.apple.security (7.0 - 57031.20.26) <6568520A-587D-3167-BB79-60CE6FEADC64> /System/Library/Frameworks/Security.framework/Versions/A/Security\n    0x7fff8e737000 -     0x7fff8e74cff7  com.apple.AppContainer (4.0 - 238.20.2) <2AA2EF49-9F38-31F6-8B08-8CC7C26F57F3> /System/Library/PrivateFrameworks/AppContainer.framework/Versions/A/AppContainer\n    0x7fff8e7e7000 -     0x7fff8e7ecffb  libheimdal-asn1.dylib (398.10.1) <A7B6447A-6680-3625-83C3-993B58D5C43F> /usr/lib/libheimdal-asn1.dylib\n    0x7fff8f261000 -     0x7fff8f267ff7  libsystem_networkextension.dylib (167.1.10) <29AB225B-D7FB-30ED-9600-65D44B9A9442> /usr/lib/system/libsystem_networkextension.dylib\n    0x7fff8f268000 -     0x7fff8f28dff7  libJPEG.dylib (1237) <8AC8EFA6-2283-3725-9F28-01537DF51766> /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libJPEG.dylib\n    0x7fff8f28e000 -     0x7fff8f296fff  libsystem_platform.dylib (63) <64E34079-D712-3D66-9CE2-418624A5C040> /usr/lib/system/libsystem_platform.dylib\n    0x7fff8f297000 -     0x7fff8f2a4fff  libxar.1.dylib (255) <7CD69BB5-97BA-3858-8A8B-2F33F129E6E7> /usr/lib/libxar.1.dylib\n    0x7fff8f2a5000 -     0x7fff8f3d5fff  com.apple.UIFoundation (1.0 - 1) <466BDFA8-0B9F-3AB0-989D-F9779422926A> /System/Library/PrivateFrameworks/UIFoundation.framework/Versions/A/UIFoundation\n    0x7fff8f409000 -     0x7fff8f40aff3  libSystem.B.dylib (1213) <CCEC13A5-D0D9-31C5-B0B0-1C564B4A20A6> /usr/lib/libSystem.B.dylib\n    0x7fff8f86b000 -     0x7fff8f8c6ff7  libTIFF.dylib (1237) <690B205E-55D9-3F2C-B4EA-78B1AC3D3231> /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libTIFF.dylib\n    0x7fff8fb72000 -     0x7fff8fd7fff3  com.apple.CFNetwork (720.3.13 - 720.3.13) <69E15385-5784-3912-88F6-03B16F1C1A5C> /System/Library/Frameworks/CFNetwork.framework/Versions/A/CFNetwork\n    0x7fff8fd80000 -     0x7fff8febdfff  com.apple.ImageIO.framework (3.3.0 - 1237) <138A800C-14B7-36C2-AB04-E162602C97E3> /System/Library/Frameworks/ImageIO.framework/Versions/A/ImageIO\n    0x7fff8febe000 -     0x7fff8fefeff7  libGLImage.dylib (11.1.2) <260A4BF3-DC45-369C-A0CD-B667F9D17179> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLImage.dylib\n    0x7fff8feff000 -     0x7fff8ff0dff7  com.apple.opengl (11.1.2 - 11.1.2) <864B35BF-1E76-382B-8D5F-38C7282621E6> /System/Library/Frameworks/OpenGL.framework/Versions/A/OpenGL\n    0x7fff8ff0e000 -     0x7fff8ff0fffb  libremovefile.dylib (35) <3485B5F4-6CE8-3C62-8DFD-8736ED6E8531> /usr/lib/system/libremovefile.dylib\n    0x7fff8ff42000 -     0x7fff8ff47ff7  com.apple.MediaAccessibility (1.0 - 61) <00A3E0B6-79AC-387E-B282-AADFBD5722F6> /System/Library/Frameworks/MediaAccessibility.framework/Versions/A/MediaAccessibility\n    0x7fff8ff48000 -     0x7fff90217ff3  com.apple.CoreImage (10.3.4) <C1AE8252-A95D-3BF4-83B8-BE85E979F2CB> /System/Library/Frameworks/QuartzCore.framework/Versions/A/Frameworks/CoreImage.framework/Versions/A/CoreImage\n    0x7fff90218000 -     0x7fff90267ff7  com.apple.opencl (2.4.2 - 2.4.2) <4A9574ED-15CF-3EBB-B4C0-D30F644D6C74> /System/Library/Frameworks/OpenCL.framework/Versions/A/OpenCL\n    0x7fff9028c000 -     0x7fff902cdfff  libGLU.dylib (11.1.2) <4C54F0D1-2ADC-38A0-92D1-F479E9B99355> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLU.dylib\n    0x7fff902d7000 -     0x7fff90376e27  com.apple.AppleJPEG (1.0 - 1) <6627DDD9-A8FE-3968-B23A-B6A29AA3919A> /System/Library/PrivateFrameworks/AppleJPEG.framework/Versions/A/AppleJPEG\n    0x7fff9068f000 -     0x7fff906e3fff  libc++.1.dylib (120) <1B9530FD-989B-3174-BB1C-BDC159501710> /usr/lib/libc++.1.dylib\n    0x7fff90742000 -     0x7fff9076efff  libsandbox.1.dylib (358.20.5) <C84D0EA1-CE60-3328-A196-D55874BE83D1> /usr/lib/libsandbox.1.dylib\n    0x7fff907d5000 -     0x7fff909cf46f  libobjc.A.dylib (647) <759E155D-BC42-3D4E-869B-6F57D477177C> /usr/lib/libobjc.A.dylib\n    0x7fff919ab000 -     0x7fff919affff  com.apple.TCC (1.0 - 1) <CCA42EE2-3400-3444-9486-BC454E60D944> /System/Library/PrivateFrameworks/TCC.framework/Versions/A/TCC\n    0x7fff92068000 -     0x7fff9224dff7  libicucore.A.dylib (531.48) <3CD34752-B1F9-31D2-865D-B5B0F0BE3111> /usr/lib/libicucore.A.dylib\n    0x7fff92494000 -     0x7fff9249cff3  com.apple.CoreServices.FSEvents (1210.20.1 - 1210.20.1) <84F79D3E-7B5E-3C93-8479-35794A3F125E> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/FSEvents.framework/Versions/A/FSEvents\n    0x7fff9249d000 -     0x7fff924c8fff  com.apple.DictionaryServices (1.2 - 229) <F03DFAC6-6285-3176-9C6D-7CC50F8CD52A> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/DictionaryServices.framework/Versions/A/DictionaryServices\n    0x7fff924d4000 -     0x7fff925edffb  com.apple.CoreText (352.0 - 454.6) <D45790B0-E1A3-3C7D-8BA2-AB71D2CFA7FB> /System/Library/Frameworks/CoreText.framework/Versions/A/CoreText\n    0x7fff925ee000 -     0x7fff92614fff  com.apple.ChunkingLibrary (2.1 - 163.6) <29D4CB95-42EF-34C6-8182-BDB6F7BB1E79> /System/Library/PrivateFrameworks/ChunkingLibrary.framework/Versions/A/ChunkingLibrary\n    0x7fff92615000 -     0x7fff9261aff7  libunwind.dylib (35.3) <BE7E51A0-B6EA-3A54-9CCA-9D88F683A6D6> /usr/lib/system/libunwind.dylib\n    0x7fff92b31000 -     0x7fff92e9cfff  com.apple.VideoToolbox (1.0 - 1562.235) <0E996B8C-BE1C-3749-ACCA-DACBC89AFABB> /System/Library/Frameworks/VideoToolbox.framework/Versions/A/VideoToolbox\n    0x7fff92e9d000 -     0x7fff92ebdfff  com.apple.IconServices (47.1 - 47.1) <E83DFE3B-6541-3736-96BB-26DC5D0100F1> /System/Library/PrivateFrameworks/IconServices.framework/Versions/A/IconServices\n    0x7fff92ecd000 -     0x7fff92f6bfff  com.apple.Metadata (10.7.0 - 917.35) <8CBD1D32-4F4B-3F9A-AC65-76F2B5376FBF> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/Metadata.framework/Versions/A/Metadata\n    0x7fff92f6c000 -     0x7fff92f91ff7  libPng.dylib (1237) <CFBF1344-36AB-3AAE-B2EB-9FC1369F967F> /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libPng.dylib\n    0x7fff92fa2000 -     0x7fff92fdafff  com.apple.RemoteViewServices (2.0 - 99) <C9A62691-B0D9-34B7-B71C-A48B5F4DC553> /System/Library/PrivateFrameworks/RemoteViewServices.framework/Versions/A/RemoteViewServices\n    0x7fff92fdb000 -     0x7fff92fdfff7  libGIF.dylib (1237) <0990002D-CA11-325D-A432-3A333F2CC088> /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libGIF.dylib\n    0x7fff92fed000 -     0x7fff930adff7  com.apple.backup.framework (1.6.4 - 1.6.4) <A67CE7D7-AAE4-3AC0-86B7-EAF403853D09> /System/Library/PrivateFrameworks/Backup.framework/Versions/A/Backup\n    0x7fff930ae000 -     0x7fff930b6ffb  libcopyfile.dylib (118.1.2) <0C68D3A6-ACDD-3EF3-991A-CC82C32AB836> /usr/lib/system/libcopyfile.dylib\n    0x7fff93114000 -     0x7fff93118fff  libcache.dylib (69) <45E9A2E7-99C4-36B2-BEE3-0C4E11614AD1> /usr/lib/system/libcache.dylib\n    0x7fff93119000 -     0x7fff93146fff  com.apple.CoreVideo (1.8 - 145.1) <18DB07E0-B927-3260-A234-636F298D1917> /System/Library/Frameworks/CoreVideo.framework/Versions/A/CoreVideo\n    0x7fff9321a000 -     0x7fff9321aff7  liblaunch.dylib (559.20.9) <FA89A113-696E-3271-8FE1-A0D7324E8481> /usr/lib/system/liblaunch.dylib\n    0x7fff93299000 -     0x7fff932b3ff7  com.apple.Kerberos (3.0 - 1) <7760E0C2-A222-3709-B2A6-B692D900CEB1> /System/Library/Frameworks/Kerberos.framework/Versions/A/Kerberos\n    0x7fff932b4000 -     0x7fff9331bff7  com.apple.framework.CoreWiFi (3.0 - 300.4) <19269C1D-EB29-384A-83F3-7DDDEB7D9DAD> /System/Library/PrivateFrameworks/CoreWiFi.framework/Versions/A/CoreWiFi\n    0x7fff9331c000 -     0x7fff9334cff7  libncurses.5.4.dylib (44) <F09809A4-53B9-3E91-A8FA-D3F584C03AA3> /usr/lib/libncurses.5.4.dylib\n    0x7fff9334d000 -     0x7fff9334dff7  libunc.dylib (29) <5676F7EA-C1DF-329F-B006-D2C3022B7D70> /usr/lib/system/libunc.dylib\n    0x7fff9335a000 -     0x7fff93365fff  com.apple.AppSandbox (4.0 - 238.20.2) <BEFAB7F2-B189-391B-9B2D-FFF3EE2B77B6> /System/Library/PrivateFrameworks/AppSandbox.framework/Versions/A/AppSandbox\n    0x7fff9342f000 -     0x7fff934c3fff  com.apple.ink.framework (10.9 - 213) <8E029630-1530-3734-A446-13353F0E7AC5> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Ink.framework/Versions/A/Ink\n    0x7fff93501000 -     0x7fff93505fff  com.apple.CommonPanels (1.2.6 - 96) <F9ECC8AF-D9CA-3350-AFB4-5113A9B789A5> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/CommonPanels.framework/Versions/A/CommonPanels\n    0x7fff9354d000 -     0x7fff93554fff  com.apple.network.statistics.framework (1.2 - 1) <61B311D1-7F15-35B3-80D4-99B8BE90ACD9> /System/Library/PrivateFrameworks/NetworkStatistics.framework/Versions/A/NetworkStatistics\n    0x7fff9355a000 -     0x7fff9355afff  com.apple.ApplicationServices (48 - 48) <5BF7910B-C328-3BF8-BA4F-CE52B574CE01> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ApplicationServices\n    0x7fff935b4000 -     0x7fff935deff7  libdispatch.dylib (442.1.4) <502CF32B-669B-3709-8862-08188225E4F0> /usr/lib/system/libdispatch.dylib\n    0x7fff93eca000 -     0x7fff93f8dff7  libvMisc.dylib (516) <21497A28-8DCB-3EB8-BDAC-93C93382B0AA> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvMisc.dylib\n    0x7fff93f8e000 -     0x7fff93fe1ffb  libAVFAudio.dylib (118.6) <2441D4C1-D8FB-3DA9-9DD7-914E03413882> /System/Library/Frameworks/AVFoundation.framework/Versions/A/Resources/libAVFAudio.dylib\n    0x7fff93fe2000 -     0x7fff93fe3ff7  libsystem_blocks.dylib (65) <9615D10A-FCA7-3BE4-AA1A-1B195DACE1A1> /usr/lib/system/libsystem_blocks.dylib\n    0x7fff93ff7000 -     0x7fff94020ffb  libxslt.1.dylib (13) <AED1143F-B848-3E73-81ED-71356F25F084> /usr/lib/libxslt.1.dylib\n    0x7fff94021000 -     0x7fff94059fff  libsystem_network.dylib (412.20.3) <589A5F67-BE2A-3245-A181-0ECC9B53EB00> /usr/lib/system/libsystem_network.dylib\n    0x7fff94085000 -     0x7fff940d6fff  com.apple.audio.CoreAudio (4.3.0 - 4.3.0) <450293F7-DAE7-3DD0-8F7C-71FC2FD72627> /System/Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio\n    0x7fff940da000 -     0x7fff940ecff7  com.apple.ImageCapture (9.0 - 9.0) <7FB65DD4-56B5-35C4-862C-7A2DED991D1F> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ImageCapture.framework/Versions/A/ImageCapture\n    0x7fff941a7000 -     0x7fff941c4fff  com.apple.MultitouchSupport.framework (263.9.1 - 263.9.1) <6ABD3AE2-DF6A-3AB2-994B-9C0FB42CE2B7> /System/Library/PrivateFrameworks/MultitouchSupport.framework/Versions/A/MultitouchSupport\n    0x7fff9421e000 -     0x7fff94294fe7  libcorecrypto.dylib (233.1.2) <E1789801-3985-3949-B736-6B3378873301> /usr/lib/system/libcorecrypto.dylib\n    0x7fff942b1000 -     0x7fff943c8fe7  libvDSP.dylib (516) <DFEDB210-49D1-3803-88A2-C61DB6A45C3D> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvDSP.dylib\n    0x7fff943d1000 -     0x7fff943d4ff7  com.apple.Mangrove (1.0 - 1) <6326024D-5C8D-3F59-9468-ACA1E01BC70C> /System/Library/PrivateFrameworks/Mangrove.framework/Versions/A/Mangrove\n    0x7fff9446c000 -     0x7fff94473ff7  libcompiler_rt.dylib (35) <BF8FC133-EE10-3DA6-9B90-92039E28678F> /usr/lib/system/libcompiler_rt.dylib\n    0x7fff94474000 -     0x7fff94476fff  libsystem_configuration.dylib (699.1.5) <20F3B077-179D-3CB0-A3C1-C8602D53B4DB> /usr/lib/system/libsystem_configuration.dylib\n    0x7fff944a7000 -     0x7fff944a8fff  libsystem_secinit.dylib (18) <581DAD0F-6B63-3A48-B63B-917AF799ABAA> /usr/lib/system/libsystem_secinit.dylib\n    0x7fff9456f000 -     0x7fff945ddffb  com.apple.Heimdal (4.0 - 2.0) <7697A837-98B8-3BDB-A7D2-8ED4C9ABC510> /System/Library/PrivateFrameworks/Heimdal.framework/Versions/A/Heimdal\n    0x7fff947fc000 -     0x7fff94cecfff  com.apple.MediaToolbox (1.0 - 1562.235) <9813E9A6-5BD6-3E56-9D20-0023703D5096> /System/Library/Frameworks/MediaToolbox.framework/Versions/A/MediaToolbox\n    0x7fff94ced000 -     0x7fff94e31ff7  com.apple.QTKit (7.7.3 - 2890) <EA6DCA1E-CBAB-328F-B230-1F9B9104E110> /System/Library/Frameworks/QTKit.framework/Versions/A/QTKit\n    0x7fff950c1000 -     0x7fff950ddff7  libsystem_malloc.dylib (53.1.1) <19BCC257-5717-3502-A71F-95D65AFA861B> /usr/lib/system/libsystem_malloc.dylib\n    0x7fff950de000 -     0x7fff950e6fff  libMatch.1.dylib (24) <C917279D-33C2-38A8-9BDD-18F3B24E6FBD> /usr/lib/libMatch.1.dylib\n    0x7fff950e7000 -     0x7fff950f4ff7  com.apple.SpeechRecognitionCore (2.1.2 - 2.1.2) <551322E2-C1E4-3378-A218-F362985E3E3C> /System/Library/PrivateFrameworks/SpeechRecognitionCore.framework/Versions/A/SpeechRecognitionCore\n    0x7fff95135000 -     0x7fff9514eff7  com.apple.CFOpenDirectory (10.10 - 187) <790ED527-EFD2-3EA6-8C97-A8C04E96EBA7> /System/Library/Frameworks/OpenDirectory.framework/Versions/A/Frameworks/CFOpenDirectory.framework/Versions/A/CFOpenDirectory\n    0x7fff9514f000 -     0x7fff95154ff7  libmacho.dylib (862) <126CA2ED-DE91-308F-8881-B9DAEC3C63B6> /usr/lib/system/libmacho.dylib\n    0x7fff95155000 -     0x7fff95157fff  libCVMSPluginSupport.dylib (11.1.2) <6EFEC4A6-2EAC-3C27-820E-C28BE71B9FCB> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCVMSPluginSupport.dylib\n    0x7fff95158000 -     0x7fff9545dff3  com.apple.HIToolbox (2.1.1 - 758.7) <6711FAA9-904A-3B49-9665-FC8D13B93C42> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/HIToolbox.framework/Versions/A/HIToolbox\n    0x7fff9545e000 -     0x7fff95498ffb  com.apple.DebugSymbols (115 - 115) <6F03761D-7C3A-3C80-8031-AA1C1AD7C706> /System/Library/PrivateFrameworks/DebugSymbols.framework/Versions/A/DebugSymbols\n    0x7fff95623000 -     0x7fff956afff7  libsystem_c.dylib (1044.10.1) <86FBED7A-F2C8-3591-AD6F-486DD57E6B6A> /usr/lib/system/libsystem_c.dylib\n    0x7fff956b0000 -     0x7fff95724ffb  com.apple.securityfoundation (6.0 - 55126) <42589E18-D38C-3E25-B638-6E29740C224C> /System/Library/Frameworks/SecurityFoundation.framework/Versions/A/SecurityFoundation\n    0x7fff95725000 -     0x7fff95742ffb  libresolv.9.dylib (57) <26B38E61-298A-3C3A-82C1-3B5E98AD5E29> /usr/lib/libresolv.9.dylib\n    0x7fff95743000 -     0x7fff9574eff7  com.apple.CrashReporterSupport (10.10 - 631) <D87A64FA-64B1-3B23-BB43-ADE173C108C6> /System/Library/PrivateFrameworks/CrashReporterSupport.framework/Versions/A/CrashReporterSupport\n    0x7fff9574f000 -     0x7fff95758fff  libsystem_pthread.dylib (105.10.1) <3103AA7F-3BAE-3673-9649-47FFD7E15C97> /usr/lib/system/libsystem_pthread.dylib\n    0x7fff95774000 -     0x7fff958b6fff  libsqlite3.dylib (168) <7B580EB9-9260-35FE-AE2F-276A2C242BAB> /usr/lib/libsqlite3.dylib\n    0x7fff958b7000 -     0x7fff958bbfff  libCoreVMClient.dylib (79.1) <201EF6DF-5074-3CB7-A361-398CF957A264> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCoreVMClient.dylib\n    0x7fff958bc000 -     0x7fff958befff  libRadiance.dylib (1237) <8F1E898B-74F6-3242-B929-CAF58AFCE319> /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libRadiance.dylib\n    0x7fff958bf000 -     0x7fff9611aff3  com.apple.CoreGraphics (1.600.0 - 779.11) <EFAB294A-B307-38C5-A3B0-159159B41057> /System/Library/Frameworks/CoreGraphics.framework/Versions/A/CoreGraphics\n    0x7fff9611f000 -     0x7fff961a8ff7  com.apple.CoreSymbolication (3.1 - 57020.1) <85707039-0C8A-3409-B0B5-153431CC1841> /System/Library/PrivateFrameworks/CoreSymbolication.framework/Versions/A/CoreSymbolication\n    0x7fff961ae000 -     0x7fff961b4ff7  com.apple.XPCService (2.0 - 1) <AA4A5393-1F5D-3465-A417-0414B95DC052> /System/Library/PrivateFrameworks/XPCService.framework/Versions/A/XPCService\n    0x7fff961d5000 -     0x7fff961defff  libGFXShared.dylib (11.1.2) <0BAF2EA8-3BC4-3BF4-ABB6-A6E0A1F3F6A5> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGFXShared.dylib\n    0x7fff96233000 -     0x7fff96246ff7  com.apple.CoreBluetooth (1.0 - 1) <8D7BA9BA-EB36-307A-9119-0B3D9732C953> /System/Library/Frameworks/CoreBluetooth.framework/Versions/A/CoreBluetooth\n    0x7fff96299000 -     0x7fff9638cff7  libJP2.dylib (1237) <A48C29E6-9E9F-3449-B873-160DE8E94008> /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libJP2.dylib\n    0x7fff963b2000 -     0x7fff964daff7  com.apple.coreui (2.1 - 308.6) <DEA5D3E1-D333-302B-A6CF-7643BFDFAED0> /System/Library/PrivateFrameworks/CoreUI.framework/Versions/A/CoreUI\n    0x7fff964db000 -     0x7fff964e4ff3  com.apple.CommonAuth (4.0 - 2.0) <BA9F5A09-D200-3D18-9F4A-20C789291A30> /System/Library/PrivateFrameworks/CommonAuth.framework/Versions/A/CommonAuth\n    0x7fff964f2000 -     0x7fff964fdff7  libkxld.dylib (2782.20.48) <28EF8328-E3E2-336A-974B-FB1BF119D55A> /usr/lib/system/libkxld.dylib\n    0x7fff966d3000 -     0x7fff966d4fff  liblangid.dylib (117) <B54A4AA0-2E53-3671-90F5-AFF711C0EB9E> /usr/lib/liblangid.dylib\n    0x7fff9678d000 -     0x7fff968eefff  com.apple.avfoundation (2.0 - 889.210) <0CFF0D47-7C6B-388E-87BD-404F43A6B1E0> /System/Library/Frameworks/AVFoundation.framework/Versions/A/AVFoundation\n    0x7fff96a0d000 -     0x7fff96a29fff  com.apple.GenerationalStorage (2.0 - 209.11) <9FF8DD11-25FB-3047-A5BF-9415339B3EEC> /System/Library/PrivateFrameworks/GenerationalStorage.framework/Versions/A/GenerationalStorage\n    0x7fff96a2a000 -     0x7fff96a2cfff  libquarantine.dylib (76.20.1) <7AF90041-2768-378A-925A-D83161863642> /usr/lib/system/libquarantine.dylib\n    0x7fff96a2d000 -     0x7fff96b1fff7  libiconv.2.dylib (42) <2A06D02F-8B76-3864-8D96-64EF5B40BC6C> /usr/lib/libiconv.2.dylib\n    0x7fff96b20000 -     0x7fff96b25fff  com.apple.DiskArbitration (2.6 - 2.6) <0DFF4D9B-2AC3-3B82-B5C5-30F4EFBD2DB9> /System/Library/Frameworks/DiskArbitration.framework/Versions/A/DiskArbitration\n    0x7fff96b26000 -     0x7fff96b77ff7  com.apple.AppleVAFramework (5.0.31 - 5.0.31) <FED294D2-13CB-381D-98D0-BDA909AACA32> /System/Library/PrivateFrameworks/AppleVA.framework/Versions/A/AppleVA\n    0x7fff974cd000 -     0x7fff97539fff  com.apple.framework.CoreWLAN (5.0 - 500.35.2) <5E228544-77A9-3AA5-8355-E8F6626F50E7> /System/Library/Frameworks/CoreWLAN.framework/Versions/A/CoreWLAN\n    0x7fff975df000 -     0x7fff9760aff3  libarchive.2.dylib (30) <8CBB4416-EBE9-3574-8ADC-44655D245F39> /usr/lib/libarchive.2.dylib\n    0x7fff9761a000 -     0x7fff9773eff7  com.apple.LaunchServices (644.56 - 644.56) <20AABB1C-9319-3E4D-A024-51B0DD5FCD3B> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/LaunchServices\n    0x7fff9773f000 -     0x7fff97b16fe7  com.apple.CoreAUC (211.1.0 - 211.1.0) <12645629-E065-388E-A6B5-094A240578CE> /System/Library/PrivateFrameworks/CoreAUC.framework/Versions/A/CoreAUC\n    0x7fff97b2d000 -     0x7fff97b68fff  com.apple.Symbolication (1.4 - 56045) <D64571B1-4483-3FE2-BD67-A91360F79727> /System/Library/PrivateFrameworks/Symbolication.framework/Versions/A/Symbolication\n    0x7fff97b9f000 -     0x7fff97ed0fff  com.apple.Foundation (6.9 - 1153.20) <F0FF3A5D-C5B7-34A1-9319-DE1EF928E58E> /System/Library/Frameworks/Foundation.framework/Versions/C/Foundation\n    0x7fff97ed1000 -     0x7fff97ed8fff  com.apple.NetFS (6.0 - 4.0) <1581D25F-CC07-39B0-90E8-5D4F3CF84EBA> /System/Library/Frameworks/NetFS.framework/Versions/A/NetFS\n    0x7fff97ed9000 -     0x7fff97edbff7  libsystem_coreservices.dylib (9) <41B7C578-5A53-31C8-A96F-C73E030B0938> /usr/lib/system/libsystem_coreservices.dylib\n    0x7fff98174000 -     0x7fff98174fff  com.apple.Accelerate.vecLib (3.10 - vecLib 3.10) <B92888D0-ED3F-3430-8F3A-6E56FD16C5F1> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/vecLib\n    0x7fff98177000 -     0x7fff98219fff  com.apple.Bluetooth (4.3.4 - 4.3.4f4) <A1120885-F31B-3C13-9B0D-2589F391CC7A> /System/Library/Frameworks/IOBluetooth.framework/Versions/A/IOBluetooth\n    0x7fff98225000 -     0x7fff9829dff7  com.apple.SystemConfiguration (1.14 - 1.14) <06A8405D-53BA-30A9-BA8A-222099176091> /System/Library/Frameworks/SystemConfiguration.framework/Versions/A/SystemConfiguration\n    0x7fff9829e000 -     0x7fff982b7ffb  com.apple.openscripting (1.4 - 162.1) <E6B42781-A556-355A-8A49-82A8D2B347FF> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/OpenScripting.framework/Versions/A/OpenScripting\n    0x7fff982e0000 -     0x7fff98377fff  com.apple.CoreMedia (1.0 - 1562.235) <21EB4AB6-2DBC-326B-B17E-E88BAA9E9200> /System/Library/Frameworks/CoreMedia.framework/Versions/A/CoreMedia\n    0x7fff9838c000 -     0x7fff987bcfff  com.apple.vision.FaceCore (3.1.6 - 3.1.6) <C3B823AA-C261-37D3-B4AC-C59CE91C8241> /System/Library/PrivateFrameworks/FaceCore.framework/Versions/A/FaceCore\n    0x7fff98855000 -     0x7fff98860ff7  com.apple.speech.synthesis.framework (5.3.3 - 5.3.3) <A5640275-E2A6-3856-95EF-5F0DC440B10C> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/SpeechSynthesis.framework/Versions/A/SpeechSynthesis\n    0x7fff98897000 -     0x7fff988adff7  com.apple.CoreMediaAuthoring (2.2 - 951) <C3E7D4C1-400D-34FA-9FE1-8C68C03CE969> /System/Library/PrivateFrameworks/CoreMediaAuthoring.framework/Versions/A/CoreMediaAuthoring\n    0x7fff988ae000 -     0x7fff988e9fff  com.apple.QD (301 - 301) <C4D2AD03-B839-350A-AAF0-B4A08F8BED77> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/QD.framework/Versions/A/QD\n    0x7fff988ea000 -     0x7fff98c82ff7  com.apple.CoreFoundation (6.9 - 1153.18) <5C0892B8-9691-341F-9279-CA3A74D59AA0> /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation\n    0x7fff98cc5000 -     0x7fff98cdbff7  libsystem_asl.dylib (267) <F153AC5B-0542-356E-88C8-20A62CA704E2> /usr/lib/system/libsystem_asl.dylib\n    0x7fff98cdc000 -     0x7fff98d28ff7  libcups.2.dylib (408.2) <E8AD18F9-61E4-3791-B840-504468C25556> /usr/lib/libcups.2.dylib\n    0x7fff98d4f000 -     0x7fff98d52ff7  libdyld.dylib (353.2.1) <9EACCA38-291D-38CC-811F-7E9D1451E2D3> /usr/lib/system/libdyld.dylib\n    0x7fff98d53000 -     0x7fff98d55fff  com.apple.SecCodeWrapper (4.0 - 238.20.2) <C6C126F0-6BF4-3E29-A9B7-7BAD8D17EE4F> /System/Library/PrivateFrameworks/SecCodeWrapper.framework/Versions/A/SecCodeWrapper\n    0x7fff98d97000 -     0x7fff98e1bfff  com.apple.PerformanceAnalysis (1.0 - 1) <599AED3E-B689-3C40-8B91-93AD36C97658> /System/Library/PrivateFrameworks/PerformanceAnalysis.framework/Versions/A/PerformanceAnalysis\n    0x7fff98e1c000 -     0x7fff98e4cff3  com.apple.CoreAVCHD (5.7.5 - 5750.4.1) <3E51287C-E97D-3886-BE88-8F6872400876> /System/Library/PrivateFrameworks/CoreAVCHD.framework/Versions/A/CoreAVCHD\n    0x7fff98e5c000 -     0x7fff98ebbfff  com.apple.AE (681.2 - 681.2) <181B3B06-2DC6-3E4D-B44A-2551C5E9CF6F> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/AE.framework/Versions/A/AE\n    0x7fff98ebc000 -     0x7fff9930ffc7  com.apple.vImage (8.0 - 8.0) <33BE7B31-72DB-3364-B37E-C322A32748C5> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vImage.framework/Versions/A/vImage\n    0x7fff993fd000 -     0x7fff99403fff  com.apple.speech.recognition.framework (5.0.9 - 5.0.9) <BB2D573F-0A01-379F-A2BA-3C454EDCB111> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/SpeechRecognition.framework/Versions/A/SpeechRecognition\n    0x7fff99410000 -     0x7fff99743ff7  libmecabra.dylib (666.7) <0ED8AE5E-7A5B-34A6-A2EE-2B852E60E1E2> /usr/lib/libmecabra.dylib\n    0x7fff99804000 -     0x7fff99825fff  com.apple.framework.Apple80211 (10.3 - 1030.71.6) <D3862426-2586-3DF7-BA75-9A184FCD74C4> /System/Library/PrivateFrameworks/Apple80211.framework/Versions/A/Apple80211\n    0x7fff99826000 -     0x7fff9986cff7  libauto.dylib (186) <A260789B-D4D8-316A-9490-254767B8A5F1> /usr/lib/libauto.dylib\n    0x7fff99885000 -     0x7fff998adfff  libxpc.dylib (559.20.9) <D35D0DB2-D7BD-3BE4-8378-062BFE545E1D> /usr/lib/system/libxpc.dylib\n    0x7fff99a16000 -     0x7fff99a18fff  libsystem_sandbox.dylib (358.20.5) <4CF77128-6BE0-3958-B646-707FA9CE61B2> /usr/lib/system/libsystem_sandbox.dylib\n    0x7fff99a19000 -     0x7fff99a2afff  libcmph.dylib (1) <46EC3997-DB5E-38AE-BBBB-A035A54AD3C0> /usr/lib/libcmph.dylib\n    0x7fff99b48000 -     0x7fff99bb9ffb  com.apple.ApplicationServices.ATS (360 - 375.2) <2338AF23-528F-359A-847F-8B04E49E2B84> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/ATS\n    0x7fff99bba000 -     0x7fff99bcbfff  libsystem_coretls.dylib (35.20.2) <6084A531-2523-39F8-B030-811FA1A32FB5> /usr/lib/system/libsystem_coretls.dylib\n    0x7fff99bcc000 -     0x7fff99be3ff7  libLinearAlgebra.dylib (1128) <E78CCBAA-A999-3B65-8EC9-06DB15E67C37> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLinearAlgebra.dylib\n    0x7fff99be4000 -     0x7fff99be4fff  com.apple.Accelerate (1.10 - Accelerate 1.10) <F1B96A61-7E4B-31BD-A35B-BA7EF1F16EF4> /System/Library/Frameworks/Accelerate.framework/Versions/A/Accelerate\n    0x7fff99be5000 -     0x7fff9a766ff7  com.apple.AppKit (6.9 - 1347.57) <B214D528-7D1C-39B2-BE36-821D417A0297> /System/Library/Frameworks/AppKit.framework/Versions/C/AppKit\n    0x7fff9a767000 -     0x7fff9a768ff7  com.apple.print.framework.Print (10.0 - 265) <3BC4FE7F-78A0-3E57-8F4C-520E7EFD36FA> /System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/Print.framework/Versions/A/Print\n    0x7fff9a76c000 -     0x7fff9a8d3ffb  com.apple.audio.toolbox.AudioToolbox (1.12 - 1.12) <5678FC94-456A-3F5F-BA9A-10EB6E462997> /System/Library/Frameworks/AudioToolbox.framework/Versions/A/AudioToolbox\n\nExternal Modification Summary:\n  Calls made by other processes targeting this process:\n    task_for_pid: 0\n    thread_create: 0\n    thread_set_state: 0\n  Calls made by this process:\n    task_for_pid: 0\n    thread_create: 0\n    thread_set_state: 0\n  Calls made by all processes on this machine:\n    task_for_pid: 7559\n    thread_create: 0\n    thread_set_state: 0\n\nVM Region Summary:\nReadOnly portion of Libraries: Total=214.3M resident=134.1M(63%) swapped_out_or_unallocated=80.2M(37%)\nWritable regions: Total=52.5M written=8808K(16%) resident=13.0M(25%) swapped_out=0K(0%) unallocated=39.5M(75%)\n\nREGION TYPE                      VIRTUAL\n===========                      =======\nKernel Alloc Once                     4K\nMALLOC                             42.5M\nMALLOC (admin)                       32K\nSTACK GUARD                        56.0M\nStack                              8192K\nVM_ALLOCATE                          16K\n__DATA                             17.7M\n__IMAGE                             528K\n__LINKEDIT                         76.2M\n__TEXT                            138.1M\n__UNICODE                           552K\nshared memory                         4K\n===========                      =======\nTOTAL                             339.7M\n\nModel: MacBookPro9,2, BootROM MBP91.00D3.B09, 2 processors, Intel Core i5, 2.5 GHz, 4 GB, SMC 2.2f44\nGraphics: Intel HD Graphics 4000, Intel HD Graphics 4000, Built-In\nMemory Module: BANK 0/DIMM0, 2 GB, DDR3, 1600 MHz, 0x80AD, 0x484D54343235533641465236412D50422020\nMemory Module: BANK 1/DIMM0, 2 GB, DDR3, 1600 MHz, 0x80AD, 0x484D54343235533641465236412D50422020\nAirPort: spairport_wireless_card_type_airport_extreme (0x14E4, 0xF5), Broadcom BCM43xx 1.0 (7.15.166.24.3)\nBluetooth: Version 4.3.4f4 15601, 3 services, 18 devices, 1 incoming serial ports\nNetwork Service: Wi-Fi, AirPort, en1\nSerial ATA Device: APPLE HDD HTS545050A7E362, 500.11 GB\nSerial ATA Device: HL-DT-ST DVDRW  GS41N\nUSB Device: Hub\nUSB Device: FaceTime HD Camera (Built-in)\nUSB Device: Hub\nUSB Device: Hub\nUSB Device: Apple Internal Keyboard / Trackpad\nUSB Device: BRCM20702 Hub\nUSB Device: Bluetooth USB Host Controller\nUSB Device: IR Receiver\nThunderbolt Bus: MacBook Pro, Apple Inc., 25.1\n\n```\n\n@shelhamer : any inputs would be of great value.\n\nThanks! :)\n', ""I am seeing two different version of python in your error log:  You're predominantly referencing the one from home-brew: \n0x106592000 -        0x106593fff +org.python.python (2.7.9 - 2.7.9) <E6A2C746-0CEF-3357-A494-E4951EAF0BA4> /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python\n\nBut further down the system version of python is still sneaking in (and it seems to be version 2.7.6 instead of the 2.7.9 that's used by home-brew):\n0x107fed000 -        0x1080deff7  org.python.python (2.7.6 - 2.7.6) <A5C1B694-31A0-3966-B6BC-C40694DC707F> /System/Library/Frameworks/Python.framework/Versions/2.7/Python\n\nI'd suggest trying the steps above and recompiling everything?  \n\nHaving lived with the work-around for a few weeks, it did cause a headache when I updated my command line tools, so I'd probably suggest rather than moving the framework in step #1 to maybe just symlinking it appropriately to the home-brew directory...but for now the original post should still hopefully fix your problems :)  \n\nGood luck and hope it starts working!\n"", ""@gp335 : Thanks for that point out! The different versions on my system python and brewed python was the root of the problem. I fixed the error by changing the PYTHON_LIB variable in my Makefile.config. \n\nPYTHON_LIB := /usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/\n\nThis got me through importing caffe in python. I've also written a small Wiki page to get people through the problems that I faced.\n http://installing-caffe-the-right-way.wikidot.com/\n@gp335 : your suggestions would hold great value :D \n"", 'created my tutorial as well : \nhttp://christopher5106.github.io/big/data/2015/07/16/deep-learning-install-caffe-cudnn-cuda-for-digits-python-on-mac-osx.html\n', ""For me the error log indicated references to /usr/lib/libpython2.7.dylib which links to /System/Library/Frameworks/Python.framework/Versions/2.7/Python.I wanted to use anaconda distribution. \nFix: issue got resolved by linking /usr/lib/libpython2.7.dylib to $ANACONDA_HOME/lib/libpython2.7.dylib.\nNote: I'm using OSX El Captain and had to disable system integrity protection to do same.\n"", '@aniryou :I want to use anaconda too. could you please explain how to link the /usr/lib/libpython2.7.dylib to $ANACONDA_HOME/lib/libpython2.7.dylib.  Thank you.\n', '@junwenchen For my case, I tried to modify **../cmake/Dependencies.cmake**, add corresponding path of **PYTHON_LIBRARY** and **PYTHON_INCLUDE_DIR** before **find_package(PythonLibs 2.7)**.\nThen it works:) \n', '@aniryou I can confirm this fixes the issue :D\n', 'For posterity, I will note that I also ran into this problem, but from a different error:\n\n```\nIn [1]: import caffe\n---------------------------------------------------------------------------\nImportError                               Traceback (most recent call last)\n<ipython-input-1-1cca3aa1f8c5> in <module>()\n----> 1 import caffe\n\n/opt/caffe/python/caffe/__init__.py in <module>()\n----> 1 from .pycaffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, RMSPropSolver, AdaDeltaSolver, AdamSolver\n      2 from ._caffe import set_mode_cpu, set_mode_gpu, set_device, Layer, get_solver, layer_type_list\n      3 from ._caffe import __version__\n      4 from .proto.caffe_pb2 import TRAIN, TEST\n      5 from .classifier import Classifier\n\n/opt/caffe/python/caffe/pycaffe.py in <module>()\n     11 import numpy as np\n     12 \n---> 13 from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\n     14         RMSPropSolver, AdaDeltaSolver, AdamSolver\n     15 import caffe.io\n\nImportError: No module named _caffe\n```\n\nI had to first rename the file that was installed as _caffe.dylib to _caffe.so before I could even get the system to recognize it. Then once that was done, I ran into a SIGSEGV:\n\n```\n# mv /opt/caffe/python/caffe/_caffe.dylib /opt/caffe/python/caffe/_caffe.so\n\n...\nIn [1]: import caffe\nSegmentation fault: 11\n```\n\nI could see by looking at the dynamic linker information for the library that it was linked to the system Python, which did not seem right:\n\n```\n# otool -L /opt/caffe/python/caffe/_caffe.so  |grep -i python\n\n...\n/opt/caffe/python/caffe/_caffe.so:\n    /System/Library/Frameworks/Python.framework/Versions/2.7/Python (compatibility version 2.7.0, current version 2.7.10)\n    /usr/local/opt/boost-python/lib/libboost_python-mt.dylib (compatibility version 0.0.0, current version 0.0.0)\n```\n\nThen I found this thread, which further advanced the notion that it might be a python version mismatch. I was using Anaconda for my Python env and using the cmake method for Caffe compilation, so I checked the output I had from cmake:\n\n```\n# cmake -D CMAKE_CXX_FLAGS=""-I/System/Library/Frameworks/Accelerate.framework/Versions/Current/Frameworks/vecLib.framework/Versions/Current/Headers -Wl,-framework,Accelerate"" -D OpenCV_DIR=/usr/local/opt/opencv3/share/OpenCV ..\n\n...\n-- Python:\n--   Interpreter       :   /Users/martin/anaconda3/envs/dev27/bin/python2.7 (ver. 2.7.10)\n--   Libraries         :   /usr/lib/libpython2.7.dylib (ver 2.7.10)\n...\n```\n\nThis indeed confirmed that the problem was a conflict between Python distributions, so I changed my cmake flags like so:\n\n```\n# cmake -D PYTHON_INCLUDE_DIR=/Users/martin/anaconda3/envs/dev27/include/python2.7 -D PYTHON_LIBRARY=/Users/martin/anaconda3/envs/dev27/lib/libpython2.7.dylib -D CMAKE_CXX_FLAGS=""-I/System/Library/Frameworks/Accelerate.framework/Versions/Current/Frameworks/vecLib.framework/Versions/Current/Headers -Wl,-framework,Accelerate"" -D OpenCV_DIR=/usr/local/opt/opencv3/share/OpenCV ..\n\n...\n-- Python:\n--   Interpreter       :   /Users/martin/anaconda3/envs/dev27/bin/python2.7 (ver. 2.7.10)\n--   Libraries         :   /Users/martin/anaconda3/envs/dev27/lib/libpython2.7.dylib (ver 2.7.10)\n```\n\nAnd rebuilt.\n\nNow, looking at the linker information for the library, I can see that it is no longer linked to the system Python: \n\n```\n# otool -L install/python/caffe/_caffe.dylib  |grep -i python\n\n...\ninstall/python/caffe/_caffe.dylib:\n    libpython2.7.dylib (compatibility version 2.7.0, current version 2.7.0)\n    /usr/local/opt/boost-python/lib/libboost_python-mt.dylib (compatibility version 0.0.0, current version 0.0.0)\n```\n\nThen the next problem was that the libpython2.7.dylib from the Anaconda env could not be found at runtime:\n\n```\nIn [1]: import _caffe\n---------------------------------------------------------------------------\nImportError                               Traceback (most recent call last)\n<ipython-input-1-8f34565b13c7> in <module>()\n----> 1 import _caffe\n\nImportError: dlopen(./_caffe.so, 2): Library not loaded: libpython2.7.dylib\n  Referenced from: /opt/caffe/python/caffe/_caffe.dylib\n  Reason: image not found\n```\n\nSo I next had to update the \n\n```\n# export DYLD_FALLBACK_LIBRARY_PATH=/Users/martin/anaconda3/envs/dev27/lib:$DYLD_FALLBACK_LIBRARY_PATH\n# ipy\nPython 2.7.10 |Continuum Analytics, Inc.| (default, Oct 19 2015, 18:31:17) \nType ""copyright"", ""credits"" or ""license"" for more information.\n\nIPython 4.0.1 -- An enhanced Interactive Python.\n?         -> Introduction and overview of IPython\'s features.\n%quickref -> Quick reference.\nhelp      -> Python\'s own help system.\nobject?   -> Details about \'object\', use \'object??\' for extra details.\n\nIn [1]: import _caffe\n\nIn [2]: \n```\n\nNow finally everything is working.\n', 'Similar to lots of people here I had a mix of system Python and Anaconda Python being linked together.\nI used `install_name_tool` to force `_caffe.so` to use the Anaconda Python, without disabling system integrity protection (I\'m also on El Capitan).\n\nYou can use otool to see which libraries are linked in:\n\n```\notool -L python/caffe/_caffe.so\n```\n\nThere should be one line that links a bare ""libpython2.7.lib"" without any path, I think this is why the system python gets pulled in at runtime.\n\nI used this command to change it:\n\n```\ninstall_name_tool -change ""libpython2.7.dylib"" ""$HOME/anaconda/lib/libpython2.7.dylib"" python/caffe/_caffe.so\n```\n\nNo more seg fault!!\n\nI learned about this strategy from issue #3227 \n', 'If you use Anaconda, try this in terminal before import caffe in Python interactive session:\n\nexport DYLD_FALLBACK_LIBRARY_PATH=$HOME/anaconda/lib\n\nIt works for me. Hope it helps!\n', 'What @dozyc said worked for me as well, but with slightly different invocations. \n\nI was hitting SIGSEGV when calling `import caffe` on OSX  10.11.6 (El Capitan) with python 2.7.12 installed via Homebrew. \n\n I ran:\n\n```\notool -L ./python/caffe/_caffe.so\n```\n\nAnd observed:\n\n```\n/usr/local/opt/boost-python/lib/libboost_python.dylib (compatibility version 0.0.0, current version 0.0.0)\n/System/Library/Frameworks/Python.framework/Versions/2.7/Python (compatibility version 2.7.0, current version 2.7.10)\n/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib (compatibility version 1.0.0, current version 1.0.0)\n```\n\nThe dependency on `Python` from `/System/Library/Frameworks` is bad - this is the OS version of Python, not the version installed via homebrew, hence incompatibility.\n\nI fixed this with:\n\n```\ninstall_name_tool -change /System/Library/Frameworks/Python.framework/Versions/2.7/Python /usr/local/Cellar/python/2.7.12/Frameworks/Python.framework/Versions/2.7/Python ./python/caffe/_caffe.so\n```\n\nOne one system I had to also do the same for the caffe library because I built it with Python layer support:\n\n```\ninstall_name_tool -change /System/Library/Frameworks/Python.framework/Versions/2.7/Python /usr/local/Cellar/python/2.7.12/Frameworks/Python.framework/Versions/2.7/Python ../distribute/lib/libcaffe.so.1.0.0-rc3\n```\n\nHope this helps.\n', 'If you use MacOS El capitan, uncomment this line in MakeConfig file\n`WITH_PYTHON_LAYER := 1`\n', ""I'm facing similar issues. \nAnd can not fix it by the above ways\nMac OS X 10.11.13\n"", 'I had many issues while installation. In my case the real solution was:\n1. Uninstall homebrew, all dependencies, brewed Python and all content in\nusr/local\n2. Install homebrew, Python and all dependencies from scratch\n3. Note: I didn\'t change args DPYTHON in opencv file.\n4. Clone caffe\n5. Modify makefile.config - you have carefully provide PYTHON_PATHs - make\nsure twice that your pathways are correct. Don\'t forget to uncomment \nWITH_PYTHON_LAYER := 1\nDon\'t forget to provide correct pathways in your ~/.bash_profile\n6. Make clean, make all, make test, make runtest. Be aware that you could\nface some errors about abcence opencv3 while compilation. In this case brew\nopencv3.\n7. Make pycaffe. In command line: cd /<your caffe directory>/python\n8. Cross your fingers and input ""import caffe""\n\nMy configuration: Mac OS X 10.11.6\nCPU only\nNo anaconda, no cudnn\n\nTutorials that I used:\nhttps://frankzliu.com/installing-caffe-on-os-x-el-capitan/\nhttp://installing-caffe-the-right-way.wikidot.com/start\n\nOn Friday, 30 September 2016,  notifications@github.com wrote:\n\n> I\'m facing similar issues.\n> And can not fix it by the above ways\n> Mac OS X 10.11.13\n> \n> \n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/BVLC/caffe/issues/591#issuecomment-250650500, or mute\n> the thread\n> https://github.com/notifications/unsubscribe-auth/AF9YWqWr5A49Ho_xBi-YsND7emEncAgAks5qvIKQgaJpZM4CJyGp\n> .\n\n## \n\nSincerely, Yura Vasiliuk\n', '@NightFury13 Your solution just works!']",[],[],0,0
281,caffe,3890,closed,Add FCN example for semantic segmentation,"@shelhamer @longjon From my naive point of view, it looks like the requirements for FCN-x from the model zoo have made it into master; is this true?

I'm eventually hoping to do some fine tuning off of that work, but in the process, I thought I'd try creating a reproducible example of one of the FCN-X's working.  Work started in a separate repo here: https://github.com/developmentseed/caffe-fcn/blob/master/src/fcn-fwd.ipynb -- before I take it further, just wanted to ask if you'd be interested in a PR adding something like this to the examples in this repo?  (If so, I might as well set up a branch and work from there.)
",documentation,"[""I'd like to hear more from this because I am thinking to use FCN-x in my work and it would be nice to have this in master! \n"", ""@anandthakker right, the requirements for FCNs (coordinate mapping + crop layer) were merged in #3613 and #3570\u200b on 03/05. Note however that the old `jonlong/caffe:future` definitions are incompatible since the configuration of the crop layer changed; that said the weightsthe caffemodelsare since the layers with weights are unchanged.\n\nWe're working on posting new reference models with net spec, weights, solver, and scripts soon along with a notebook example.\n"", 'Great, thanks!\n', 'Thanks for the update and explanation, @shelhamer \n', ""While the reference models and example notebook are hammered out you can see the [fcn.berkeleyvision.org repo](https://github.com/shelhamer/fcn.berkeleyvision.org) for master compatible FCNs, solver configurations, and scripts for learning, inference, and scoring. I'll follow up as more models are ported.\n\nHappy brewing.\n"", '@shelhamer I have an FCN model originally created using `jonlong/caffe:future`. My FCN model works really well on a cardiac segmentation dataset using that branch. However, when I try to run the exact same model using the `master` branch with coordinate mapping and nd crop layer, the model gets considerably worse accuracy performance. In fact, I cannot reproduce the level of accuracy performance using the `master` branch. What is the difference in implementation between `caffe-future` and the `master` branch for the crop layer? Has anyone noticed the mismatch in accuracy performance between the two branches?\n', '@vuptran From my testing on the crop from longjon:future versus the master branch, the longjon:future appears to center the crop (computing the offset using the DiagonalAffineMap), while the master branch by default locates the crop with default offset (0,0). This could be a major cause of your accuracy loss, since fusing layers with different crop offsets mean the features become misaligned. For now you can manually compute the offsets and give them like ""crop_param { offset: 9 }"" but this is more tedious to compute manually.\n', '@vuptran @jasonbunk the `master` branch is compatible with `jonlong/caffe:future` networks _as long as you configure the crop layer_. The `master` edition separates out determining the crop coordinatesthe `coord_map` #3613 in Python net specand actually doing the cropping by #3570. The parameters (the `caffemodel`) from the old branch are compatible with `master`, but the definition of the crop layer in the old-style architecture (the `prototxt`) is not.\n\n> but this is more tedious to compute manually\n\nThe point of `coord_map` is to compute this automatically from the net spec. See the [coord_map import](https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/voc-fcn32s/net.py#L3) and [crop definition](https://github.com/shelhamer/fcn.berkeleyvision.org/blob/master/voc-fcn32s/net.py#L62) in the VOC FCN-32s model at fcn.berkeleyvision.org for an example.\n\nWhile you need to generate the proto in Python, you can then use the proto definition however you did before (whether Python or not).\n\n@vuptran I hope that clears it up for you. Happy to hear you were able to make a cardiac segmentation FCN.\n', 'Dear @vuptran\n\nI want to apply FCN on Cardiac MRI dataset and do the segmentation for right and left ventricle(I prepared VOI in .png and mask of ground truth in .png), Can you please kindly tell me how can I prepare them for training with FCN??\n\nThanks in advance.  \n', 'Closing this as addressed by [fcn.berkeleyvision.org](http://fcn.berkeleyvision.org)']",[],[],0,0
282,caffe,2662,closed,how to create a new imagenet.bet.pickle file my own,"I have trained a model myself,I want to use it in a web demo,so I read the example/web_demo/app.py code,
'bet_file': (
            '{}/data/ilsvrc12/imagenet.bet.pickle'.format(REPO_DIRNAME)),

in this line code,i don't kown the 'imagenet.bet.pickle' file how to create, is it necessary,who can tell me how to solve the problem, thanks.
",,"['Closing as this looks like a usage issue/request for help.\n\nThis tracker is reserved for specific Caffe development issues and bugs; please ask usage questions on the [caffe-users](https://groups.google.com/forum/#!forum/caffe-users) list.\n\nFor more information, see our [contributing guide](https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md).\n\nThanks!\n']",[],[],0,0
283,caffe,485,closed,Error compiling lastest dev branch,"Hi,
there is a problem in the latest dev branch. In the dummy_data_layer.cpp there is a call to the non defined Forward method, I suppose it must be the the Forward_cpu method
",bug,"['@jeffdonahue clang++ requires dummy_data_layer.cpp:78 to be `this->Forward(bottom, top);` instead of `Forward(bottom, top);` alone. Could you patch and push to dev?\n\nIf I remember right this same issue came up in the power layer tests.\n', ""@jeffdonahue actually, I'll just push it since I made the edit anyway. Sorry for the pointless comment haha.\n"", 'Sweet, thanks!\n', ""(@shelhamer, didn't see your commit so I fixed it and pushed)\n"", ""Oh, sorrythere was a github outage and my push was blocked and I forgot to\nre-push. Thanks for fixing it.\n\nOn Tue, Jun 10, 2014 at 11:36 AM, Jeff Donahue notifications@github.com\nwrote:\n\n> (@shelhamer https://github.com/shelhamer, didn't see your commit so I\n> fixed it and pushed)\n> \n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/BVLC/caffe/issues/485#issuecomment-45653555.\n""]",[],[],0,0
284,caffe,6224,closed,Build caffe by CLion failed,"### Issue summary

When I typed ""make all"" on terminal trying to install caffe, following information will occur. I already installed gflags. I've tried every solution I found on Google and Github, how can I fix that? Thanks in advance.

If my description is not clear enough, please tell me.

=======================================

Jays-iMac:build jay$ make all
[  1%] Running C++/Python protocol buffer compiler on /Users/jay/documents/caffe/src/caffe/proto/caffe.proto
Scanning dependencies of target caffeproto
[  1%] Building CXX object src/caffe/CMakeFiles/caffeproto.dir/__/__/include/caffe/proto/caffe.pb.cc.o
[  1%] Linking CXX static library ../../lib/libcaffeproto.a
[  1%] Built target caffeproto
Scanning dependencies of target caffe
[  1%] Building CXX object src/caffe/CMakeFiles/caffe.dir/blob.cpp.o
[  1%] Building CXX object src/caffe/CMakeFiles/caffe.dir/common.cpp.o
/Users/jay/documents/caffe/src/caffe/common.cpp:134:5: error: no member named 'gflags' in the global namespace
  ::gflags::ParseCommandLineFlags(pargc, pargv, true);
  ~~^
/Users/jay/documents/caffe/src/caffe/common.cpp:182:7: warning: field 'default_device_' will be initialized after field 'solver_count_' [-Wreorder]
      default_device_(cpu_device_.get()),
      ^
/Users/jay/documents/caffe/src/caffe/common.cpp:323:7: warning: field 'default_device_' will be initialized after field 'solver_count_' [-Wreorder]
      default_device_(cpu_device_.get()),
      ^
2 warnings and 1 error generated.
make[2]: *** [src/caffe/CMakeFiles/caffe.dir/common.cpp.o] Error 1
make[1]: *** [src/caffe/CMakeFiles/caffe.dir/all] Error 2
make: *** [all] Error 2

=======================================

[Makefile.config.txt](https://github.com/BVLC/caffe/files/1711294/Makefile.config.txt)
[CMakeCache.txt](https://github.com/BVLC/caffe/files/1711293/CMakeCache.txt)
[CMakeOutput.log](https://github.com/BVLC/caffe/files/1711300/CMakeOutput.log)



Operating system: OS X 10.12
CUDA version (if applicable): 9.0
Python or MATLAB version (for pycaffe and matcaffe respectively): python3.6
",,[],[],[],0,0
285,caffe,3167,closed,How to extract one image feature?,"I want to extract only one image feature without prototxt file. Not the batch feature. The image is loaded from disk. We don't need configuration file with a set of images path.Thank you!
",,"['Closing as this looks like a request for help.\n\nFrom https://github.com/BVLC/caffe/blob/master/CONTRIBUTING.md:\n\n> _Please do not post usage, installation, or modeling questions, or other requests for help to Issues._\n> Use the [caffe-users list](https://groups.google.com/forum/#!forum/caffe-users) instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\n']",[],[],0,0
